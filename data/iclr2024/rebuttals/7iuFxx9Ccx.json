[
    {
        "title": "Resource Efficient Test-Time Training with Slimmable Network"
    },
    {
        "review": {
            "id": "wShnJ8XkLx",
            "forum": "7iuFxx9Ccx",
            "replyto": "7iuFxx9Ccx",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4376/Reviewer_aCQv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4376/Reviewer_aCQv"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces SlimTTT, a resource-efficient approach for test-time training. The author proposed a practical scenario of TTT under resource constraints. To address such a challenge, the method utilizes slimmable network that can flexibly switch between different widths of sub-networks for adaptive inference and requires no retraining. The method includes width-enhanced contrastive learning, logit consistency regularization, and global feature alignment to promote representation consistency among sub-networks, in both feature and prediction spaces. The method is demonstrated by the experiment against other TTT methods by the adaption to corrupt samples on several datasets. It can achieve superior performance in the same resource constraint and can be generalized with several different backbones."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Proposed a new challenge of resource constraint in such a field, which fits in with realistic demands as a result.\n\n2. Proposed a test-time training method for slimmable neural network. \n\n3. Comprehensive experiments that support the methodology and each sub-module of it.\n\n4. The framework considered comprehensively every part of an image classification pipeline."
                },
                "weaknesses": {
                    "value": "1. The definition \"Efficient\" is vague in the title, that the model result of your method in inference is efficient, but not during the training process\uff08it actually costs more time as claimed in your experiment). Does the efficiency come from utilizing the slimmable models and you proposed a TTT method for them\uff1f\n\n2. There are some basic assumptions that should be explained.\n\n3. The purpose of the TTT is to generalize the model when a distribution shift occurs, as your experiment proves by using corrupt samples. This logical correlation can be straightly pointed out."
                },
                "questions": {
                    "value": "1. In some works about explainable networks, the grad-cam result shows what the model is focusing on and indicates the semantical feature that is used to make decisions. Does the bigger-width network contain the attention information of smaller networks well in all these backbones? If not, is the bigger network always better?\n\n2. In some cases of classification, one class can include several visual patterns (eg. some datasets have coarse classes like \u201cvehicle \u201d including items that do not look exactly the same.) Will these have an impact if you align all networks to the supernet, as it may focus on several instance-level features? I'm also curious if this will have a bigger impact on the contrastive learning that expands the positive data with the different representations from 2 sizes of model.\n\n3. There seems to be a paradox between the purpose of consistency and the ensemble of results in 3.4, if the difference between all subnets to the super net is lowered, will they intend to focus on the same feature? Though it improves the performance, I'm not fully understanding the reason."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4376/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4376/Reviewer_aCQv",
                        "ICLR.cc/2024/Conference/Submission4376/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4376/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698597516372,
            "cdate": 1698597516372,
            "tmdate": 1700705620599,
            "mdate": 1700705620599,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "BHrUtdDNT0",
                "forum": "7iuFxx9Ccx",
                "replyto": "wShnJ8XkLx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4376/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4376/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1-1:** The definition \"Efficient\" is vague in the title, that the model result of your method in inference is efficient, but not during the training process(it actually costs more time as claimed in your experiment).\n\n**A1-1:** Good comment. The term \"Efficient\" in our paper encompasses two key aspects:\n\nFirstly, efficiency is achieved through the ability to seamlessly switch to smaller and more efficient sub-networks. Despite the test-time training process of our slimTTT taking slightly more time than other methods, we can utilize smaller sub-networks as if they were the largest networks (e.g., employing the R-50 (0.75\u00d7) sub-network as the largest network). Remarkably, we observe that the results obtained from the R-50 (0.75\u00d7) sub-network demonstrate comparable performance to TTAC (R-50) and even surpass TTT++ (R-50), offering a more efficient alternative.\n\nSecondly, efficiency is also evident in the streamlined approach of deploying and training only one model containing multiple sub-networks for adaptive switching. In contrast, employing previous TTT methods on real world scenarios necessitates deploying and training several models independently to accommodate varying resource constraints. The uploading, downloading, and training processes associated with multiple models of other methods contribute significantly to resource consumption, further underscoring the efficiency of our approach.\n\n**Q1-2:** Does the efficiency come from utilizing the slimmable models and you proposed a TTT method for them\uff1f\n\n**A1-2:** We indeed address the resource-efficient test-time training challenges by employing slimmable networks. However, simply incorporating slimmable networks into test-time training poses several challenges: 1. Different widths of networks may interfere with each other, leading to inconsistent update directions, preventing models of various widths from achieving optimal optimization. This issue is more pronounced in test-time training due to the lack of ground truth labels as well as the distribution shift. Therefore, we propose WCL and LCR to solve this challenge, which promotes the consistency between different width of networks in both feature space and prediction space. 2. The GFA is applied to ensure that the test features do not deviate far from the source feature distribution during the whole adaptation process and it can apply a restriction over the multi-view features for each width of sub-networks and ensure the correctness of the multi-view representations.\n\nIn the following analytical experiment, we attempt a straightforward application of slimmable networks in test-time training without employing our consistency method (referred to as naive SlimTTT). Unfortunately, this approach yields unsatisfactory results, particularly when applied in an online manner. This is attributed to the fact that our consistency loss functions\u2014WCL, LCR, and GFA\u2014leverage the diverse views captured by sub-networks of varying widths. This facilitates knowledge interaction among slimmable networks, a crucial aspect in the test-time training setting.\n\n| Method | manner | width | Cifar10-C Err. Avg. | manner | width | Cifar10-C Err. Avg. |\n| --- | --- | --- | --- | --- | --- | --- |\n| naive SlimTTT | offline | 1.0 | 10.80 | online | 1.0 | 14.78 |\n|  |  | 0.75 | 11.54 |  | 0.75 | 15.64 |\n|  |  | 0.5 | 12.59 |  | 0.5 | 16.72 |\n|  |  | 0.25 | 15.99 |  | 0.25 | 18.83 |\n| SlimTTT (ours) | offline | 1.0 | **8.33** | online | 1.0 | **10.17** |\n|  |  | 0.75 | **8.63** |  | 0.75 | **10.55** |\n|  |  | 0.5 | **9.12** |  | 0.5 | **11.41** |\n|  |  | 0.25 | **10.68** |  | 0.25 | **14.01** |"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4376/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700354836259,
                "cdate": 1700354836259,
                "tmdate": 1700354836259,
                "mdate": 1700354836259,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MCa7DqCokO",
                "forum": "7iuFxx9Ccx",
                "replyto": "mlgKxgRSlj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4376/Reviewer_aCQv"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4376/Reviewer_aCQv"
                ],
                "content": {
                    "title": {
                        "value": "Reply to the Authors' Responses"
                    },
                    "comment": {
                        "value": "Thanks to the authors for your detailed responses. Some of my concerns have been addressed. Therefore, I will raise my score accordingly."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4376/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700705583424,
                "cdate": 1700705583424,
                "tmdate": 1700705583424,
                "mdate": 1700705583424,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5r5eCefFoT",
            "forum": "7iuFxx9Ccx",
            "replyto": "7iuFxx9Ccx",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4376/Reviewer_yJHx"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4376/Reviewer_yJHx"
            ],
            "content": {
                "summary": {
                    "value": "The authors identify two main shortcomings of existing TTT methods: resource inefficiency during deployment across devices and an inability to handle computational budget variations during testing. To address these, the authors propose SlimTTT, a resource-adaptive test-time training framework. They introduce techniques like Width-enhance Contrastive Learning (WCL), Logits Consistency Regularization (LCR), and Global Feature Alignment (GFA) to promote representation consistency. SlimTTT is reported to achieve state-of-the-art results across various adaptation methods and datasets, with a significant reduction in inference complexity. My main concerns lie on the motivation of SlimTTT and its evaluation protocols."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The proposed method properly integrates Width-enhance Contrastive Learning, Logits Consistency Regularization, and Global Feature Alignment and thus achieves significant performance improvement compared with prior source-free unsupervised domain adaptation methods, such as SHOT. \n\nThe findings of \u201cdifferent width of sub-networks can capture multiple views of the same input data, possessing a talent for enhancing TTT performance\u201d is interesting and provides new insights."
                },
                "weaknesses": {
                    "value": "The motivation for slimmable TTA does not convince me. As all TTA methods are inference-time methods and the adapttion+inference is often conducted on the same device, in Table 1, the computational resource consumption comparison should include both training (GPU memory, wall-clock time) and inference, rather than only #Model Params and Flops during inference. I mean, for a resource-limited device, whether a TTA method can be run is determined by the training resource request, rather than inference.\n\nIn Table 1, ResNet-50(1.0$\\times$)+TENT+ImageNet-C@56.89 is evaluated in an online manner (to my knowledge). So if SilmTTT is evaluated in an offline manner, the comparison would be unfair.\n\nDoes the proposed SlimTTT work well in the online setting? I am curious about the online performance and TTA efficiency (training+inference) comparisons with compared methods.\n\nComparisons with more resource-efficient TTA methods (perfectly under the online setting) are preferred, such as EATA [Efficient Test-Time Model Adaptation without Forgetting. ICML 2022]."
                },
                "questions": {
                    "value": "For all compared methods, are they evaluated in online or offline setting?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4376/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4376/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4376/Reviewer_yJHx"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4376/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698763870415,
            "cdate": 1698763870415,
            "tmdate": 1699636410289,
            "mdate": 1699636410289,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Cph1aXpbCV",
                "forum": "7iuFxx9Ccx",
                "replyto": "5r5eCefFoT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4376/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4376/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1:** The motivation for slimmable TTA does not convince me. As all TTA methods are inference-time methods and the adapttion+inference is often conducted on the same device, in Table 1, the computational resource consumption comparison should include both training (GPU memory, wall-clock time) and inference, rather than only #Model Params and Flops during inference. I mean, for a resource-limited device, whether a TTA method can be run is determined by the training resource request, rather than inference.\n\n**A1:** Thank you for your suggestion. We follow the offline TTT setting from TTT++ and TTAC. In this offline manner, test-time training and the inference phase are separate and independent. Therefore, in this scenario, it is reasonable to consider the resources during training and inference separately.\n\nThe motivation for our SlimTTT actually accounts for both the inference cost and the test-time training cost. As depicted in Fig.1 (left) in our introduction, the blue segment indicates the deployment of networks of various widths after training-time training, where we already take into account the maximum resource constraints of the device during test-time training (e.g., if the maximum resource constraints during test-time training of the device can only support R-50 (0.75\u00d7), we deploy the R-50 (0.75\u00d7) sub-network utilize it as the largest network). After it meets the resource constraint of each device during test-time training,  SlimTTT has the ability to further switch between sub-networks during test-time inference according to the device\u2019s status, as demonstrated in the orange segment.\n\nTo assess the efficacy of our SlimTTT under varying resource constraints during test-time training, we utilize smaller sub-networks as if they were the largest networks (e.g., employing the R-50 (0.75\u00d7) sub-network as the largest network). Remarkably, we observe that the results shown in Fig.3 in our experiment chapter obtained from the R-50 (0.75\u00d7) sub-network demonstrate comparable performance to TTAC (R-50) and even surpass TTT++ (R-50), offering a more efficient alternative during test-time training phase.\n\nThe computational resource consumption comparison and results on ImageNet-C in test-time training phase are shown in the table below.\n\n|Method|Backbone|GPU memory (peak) (G)|wall-clock time (per batch) (s)|FLOPs (G)|Param. (M)|Err. Avg.\n|-|-|-|-|-|-|-\n|TTAC|R-101|>24|2.842|7.8|44.6|43.73\n|TTAC|R-50|23.09|1.885|4.1|25.6|45.71\n|SlimTTT|R-50|22.59|2.253|7.8|25.6|43.98\n|TTAC|R-34|15.98|0.891|3.7|21.8|47.57\n|SlimTTT|R-50 (0.75)|19.81|1.229|3.7|14.7|45.41\n|TTAC|R-18|10.99|0.559|1.8|11.9|51.34\n|SlimTTT|R-50 (0.5)|12.49|0.760|1.3|6.9|48.73\n|SlimTTT|R-50 (0.25)|6.04|0.420|0.2|2.0|58.08\n\nRemarkably, when the available compute changes frequently during test-time training phase, different width of our slimmable network will be updated based on the available compute, while other TTT methods can not conduct test-time training under such dynamic training resource conditions.\n\nWe monitored the sensitivity of the performance in such settings on CIFAR10-C (Gaussian_Noise), as different model parameters are updated based on the available compute. We implemented 12 time steps with dynamic resources throughout the period. For example, the resources change after time step 2, so we need to update the 0.75 parameters of the model rather than the whole model.\n\nComparing the performance on dynamically changing resources (the upper half of the table) to that on constant resources (the lower half of the table), the results below reveal that our SlimTTT exhibits low sensitivity to changes in resources. We believe that this dynamic evaluation you mentioned is both important and practical, and we intend to incorporate these findings into our new paper version to encourage future research.\n\n|Dynamic resources|Time-step|0|1|2|3|4|5|6|7|8|9|10|11|12\n|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-\n||FLOPs (G)|4.1|4.1|4.1|2.3|2.3|1.1|1.1|0.3|0.3|1.1|1.1|2.3|2.3\n||max width|1|1|1|0.75|0.75|0.5|0.5|0.25|0.25|0.5|0.5|0.75|0.75\n||Err. (1.0)|19.53|20.12|17.84|16.31|14.92|14.78|14.73|14.36|13.85|13.55|14.06|13.99|13.82\n||Err. (0.75)|22.27|21.29|18.75|17.19|16.02|15.76|15.74|15.33|14.84|14.49|14.95|14.81|14.78\n||Err. (0.5)|25.00|23.63|20.57|19.14|17.97|17.51|16.96|16.41|15.89|15.35|15.59|15.43|15.38\n||Err. (0.25)|28.13|28.52|25.26|23.93|22.27|21.81|21.04|20.41|19.75|19.18|19.32|18.95|18.96\n|**Constant resources**|**Time-step**|**0**|**1**|**2**|**3**|**4**|**5**|**6**|**7**|**8**|**9**|**10**|**11**|**12**\n||FLOPs (G)|4.1|4.1|4.1|4.1|4.1|4.1|4.1|4.1|4.1|4.1|4.1|4.1|4.1\n||max width |1|1|1|1|1|1|1|1|1|1|1|1|1\n||Err. (1.0)|19.53|20.12|17.84|16.41|15.08|14.84|14.73|14.26|13.76|13.36|13.39|13.38|13.37\n||Err. (0.75)|22.27|21.29|18.75|17.09|16.02|15.76|15.68|15.14|14.54|14.06|14.24|14.16|14.24\n||Err. (0.5)|25.00|23.63|20.57|18.85|17.73|17.51|17.02|16.36|15.76|15.16|15.34|15.10|15.08\n||Err. (0.25)|28.13|28.52|25.26|24.22|22.27|21.68|20.87|20.12|19.31|18.79|18.93|18.59|18.51"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4376/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700353587605,
                "cdate": 1700353587605,
                "tmdate": 1700353587605,
                "mdate": 1700353587605,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "S0isEDGvM1",
            "forum": "7iuFxx9Ccx",
            "replyto": "7iuFxx9Ccx",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4376/Reviewer_1QhS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4376/Reviewer_1QhS"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a varying resource constraint setting for Test-Time training approaches and proposes an architecture based on the Slimmable Network (Yu et al., 2018). The primary assumption made for the targeted varying resource constraints setting is the dynamically changing computational budget (hardware-based computational constraints or dynamic resource allocation to the algorithm) during inference. Slimmable neural network architectures are specifically designed to provide adaptive accuracy-efficiency trade-offs during model inference on various devices with different budgets of computational resources. In this paper, the authors utilize Width-enhanced Contrastive loss and Logit Consistency Regularization for maintaining consistency between the subnetworks in both features and logits space. Further, the paper also introduces an ensembling strategy based on dynamically changing resources to boost the performance of the architecture. The pipeline for the proposed framework can be summarized in 3 modules 1) Source Training Phase: The pretrained backbone is trained on the source dataset with the primary training objective with an additional auxiliary self-supervised learning task. 2) Target Training Phase:  for this phase, the paper proposes maintaining feature consistency between differently augmented views obtained by both slimmable network structure and data augmentation and adds another learning objective of Logits Consistency Regularization where an augmented version of the sample is sent to the largest network for obtaining a pseudo label which is further used to maintain prediction consistency among all the sub-networks. 3) In the last phase, the paper makes use of the predictions available from different slimmable networks to create an ensemble version of the predictions for boosting prediction performance. \n\nThe paper provides empirical results on four widely used benchmarks (ImageNet-C, CIFAR10-C, CIFAR10.1, and CIFAR100-C) with different backbones (ResNet, Mobilienet, and ViT) for four settings of switchable widths in Slimmable Network (1.0\u00d7, 0.75\u00d7, 0.5\u00d7, 0.25\u00d7). The reported results highlight an improvement over the compared baselines and show the computation cost comparison via reporting the FLOPs with prediction accuracies. The paper also provides ablation experiments for highlighting the impact of various components in the design of the proposed framework."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The paper highlights an important issue of dynamically changing resource constraints in test-time training settings for deploying models in the real world. The paper utilizes the architecture of slimmable networks to address this issue, making test-time training approaches to incorporate adaptive accuracy-efficiency trade-offs during model inference on various devices with different budgets of computational resources.\n\n* The paper proposes the WCL, LCR, and GFA for exploiting the slimmable network to ensure consistency between multiple views captured by the architecture. The proposed design choices are sufficiently backed up by suitable ablation experiments. Moreover, as an additional advantage, the paper reports the slimmable network for TTT to be effective when compared with other baselines on the same computation budget.\n\n* The paper presents a detailed empirical study with various backbones (3 backbones) and datasets (4 benchmarks) along with different settings of Switches in Slimmable Network (4 in number), with required performance comparison over the computation cost for fair comparison making the results more reliable."
                },
                "weaknesses": {
                    "value": "* One of the primary claims of the paper is the varying inference budget during the inference (also highlighted as Challenge II in Figure 1). Since the paper targets a practical setting of dynamic resource allocation during inference, it is imperative to consider experiments where the available compute changes frequently during inference (test time training). It would be interesting to monitor the sensitivity of the performance in those settings since different parameters of the model will be updated based on the available compute. Low-performance sensitivity on dynamically changing resources will make the method more reliable for practical use cases. Moreover, it\u2019ll promote future research to address the challenges faced in such a setting. \n\n* The proposed framework highly depends on the source domain training however, the training cost and the convergence rate comparison for various architecture is missing from the paper. It would be good to add a comparison of training times/ convergence rates of the proposed architecture to make the approach more transparent for real-world deployment use cases."
                },
                "questions": {
                    "value": "Minor suggestions:\n* It would be better to update the caption of Table 3 to highlight the explanation of numbers presented in red for easier readability. \n* While making the comparison with existing methods, it would be good to highlight the dependency on the availability of the source dataset. Adding another column for a clear distinction between TTA and TTT approaches will make the paper more transparent."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4376/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4376/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4376/Reviewer_1QhS"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4376/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698838031516,
            "cdate": 1698838031516,
            "tmdate": 1699636410223,
            "mdate": 1699636410223,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "eGjPHrgAoK",
                "forum": "7iuFxx9Ccx",
                "replyto": "S0isEDGvM1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4376/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4376/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1:** It would be interesting to monitor the sensitivity of the performance in those settings since different parameters of the model will be updated based on the available compute. Low-performance sensitivity on dynamically changing resources will make the method more reliable for practical use cases. Moreover, it\u2019ll promote future research to address the challenges faced in such a setting.\n\n**A1:** Good comment. As your suggestion, we conducted experiments on CIFAR10-C (Gaussian_Noise) and CIFAR100-C (Gaussian_Noise) wherein the available compute (e.g., FLOPs) varies frequently during the test-time training phase. In this experiment, we monitored the sensitivity of the performance in such settings, as different model parameters are updated based on the available compute. Specifically, our evaluation spans over 12 time-steps with dynamic resources throughout the period. For example, the resources change after time-step 2 (from 4.1G to 2.3G), so we need to update the 0.75 parameters of the model rather than the whole model.\n\nComparing the performance on dynamically changing resources (the upper half of the table) to that on constant resources (the lower half of the table), the results below surprisingly reveal that our SlimTTT exhibits low sensitivity to changes in resources (i.e., as of time step 12, the performance of the network trained with dynamic resources is comparable to the performance of the network trained with constant resources), while other TTT methods can not conduct test-time training under such dynamic training resource conditions. We believe that this dynamic evaluation you mentioned is both important and practical, and we intend to incorporate these findings into our new paper version to encourage future research. \n\n**CIFAR10-C (Gaussian_Noise):**\n\n|Dynamic resources|Time-step|0|1| 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 |\n|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|\n||FLOPs | 4.1G | 4.1G | 4.1G | 2.3G | 2.3G | 1.1G | 1.1G | 0.3G | 0.3G | 1.1G | 1.1G | 2.3G | 2.3G |\n||max width | 1 | 1 | 1 | 0.75 | 0.75 | 0.5 | 0.5 | 0.25 | 0.25 | 0.5 | 0.5 | 0.75 | 0.75 |\n||Err. (1.0) | 19.53 | 20.12 | 17.84 | 16.31 | 14.92 | 14.78 | 14.73 | 14.36 | 13.85 | 13.55 | 14.06 | 13.99 | 13.82 |\n||Err. (0.75) | 22.27 | 21.29 | 18.75 | 17.19 | 16.02 | 15.76 | 15.74 | 15.33 | 14.84 | 14.49 | 14.95 | 14.81 | 14.78 |\n||Err. (0.5) | 25.00 | 23.63 | 20.57 | 19.14 | 17.97 | 17.51 | 16.96 | 16.41 | 15.89 | 15.35 | 15.59 | 15.43 | 15.38 |\n||Err. (0.25) | 28.13 | 28.52 | 25.26 | 23.93 | 22.27 | 21.81 | 21.04 | 20.41 | 19.75 | 19.18 | 19.32 | 18.95 | 18.96 |\n|**Constant resources** | **Time-step** | **0** | **1** | **2** | **3** | **4** | **5** | **6** | **7** | **8** | **9** | **10** | **11** | **12** |\n||FLOPs | 4.1G | 4.1G | 4.1G | 4.1G | 4.1G | 4.1G | 4.1G | 4.1G | 4.1G | 4.1G | 4.1G | 4.1G | 4.1G |\n||max width | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |\n||Err. (1.0) | 19.53 | 20.12 | 17.84 | 16.41 | 15.08 | 14.84 | 14.73 | 14.26 | 13.76 | 13.36 | 13.39 | 13.38 | 13.37 |\n||Err. (0.75) | 22.27 | 21.29 | 18.75 | 17.09 | 16.02 | 15.76 | 15.68 | 15.14 | 14.54 | 14.06 | 14.24 | 14.16 | 14.24 |\n||Err. (0.5) | 25.00 | 23.63 | 20.57 | 18.85 | 17.73 | 17.51 | 17.02 | 16.36 | 15.76 | 15.16 | 15.34 | 15.1 | 15.08 |\n||Err. (0.25) | 28.13 | 28.52 | 25.26 | 24.22 | 22.27 | 21.68 | 20.87 | 20.12 | 19.31 | 18.79 | 18.93 | 18.59 | 18.51 |\n\n**CIFAR100-C (Gaussian_Noise):**\n\n|Dynamic resources|Time-step| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 |\n|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|\n||FLOPs | 2.3G | 2.3G | 2.3G | 4.1G | 4.1G | 0.3G | 0.3G | 1.1G | 1.1G | 2.3G | 2.3G | 1.1G | 1.1G |\n||max width | 0.75 | 0.75 | 0.75 | 1 | 1 | 0.25 | 0.25 | 0.5 | 0.5 | 0.75 | 0.75 | 0.5 | 0.5 |\n||Err. (1.0) | 64.06 | 60.94 | 59.90 | 57.81 | 55.47 | 53.52 | 51.79 | 51.56 | 50.95 | 49.84 | 49.64 | 48.76 | 48.62 |\n||Err. (0.75) | 62.50 | 58.59 | 55.73 | 55.47 | 53.75 | 52.34 | 50.45 | 50.29 | 49.65 | 48.59 | 48.22 | 47.27 | 47.12 |\n||Err. (0.5) | 63.28 | 59.77 | 58.33 | 58.40 | 56.56 | 54.82 | 52.34 | 52.25 | 51.22 | 50.39 | 50.50 | 49.54 | 49.70 |\n||Err. (0.25) | 75.78 | 73.83 | 72.14 | 69.14 | 66.88 | 65.23 | 62.61 | 61.91 | 60.94 | 59.77 | 59.73 | 58.85 | 59.07 |\n|**Constant resources** | **Time-step** | **0** | **1** | **2** | **3** | **4** | **5** | **6** | **7** | **8** | **9** | **10** | **11** | **12** |\n||FLOPs | 4.1G | 4.1G | 4.1G | 4.1G | 4.1G | 4.1G | 4.1G | 4.1G | 4.1G | 4.1G | 4.1G | 4.1G | 4.1G |\n||max width | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |\n||Err. (1.0) | 62.50 | 58.2 | 56.51 | 54.69 | 52.50 | 50.78 | 48.66 | 48.14 | 47.31 | 46.56 | 46.09 | 45.31 | 45.13 |\n||Err. (0.75) | 62.50 | 58.59 | 55.73 | 55.47 | 53.75 | 52.21 | 50.22 | 49.71 | 48.96 | 48.12 | 47.73 | 46.81 | 46.57 |\n||Err. (0.5) | 63.28 | 59.77 | 58.33 | 58.40 | 56.56 | 54.82 | 52.23 | 51.76 | 50.52 | 49.45 | 49.43 | 48.50 | 48.62 |\n||Err. (0.25) | 75.78 | 73.83 | 72.14 | 69.14 | 66.88 | 65.23 | 62.72 | 62.01 | 61.02 | 59.84 | 59.87 | 59.05 | 59.25 |"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4376/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700352139467,
                "cdate": 1700352139467,
                "tmdate": 1700352139467,
                "mdate": 1700352139467,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nI8YbqtXtF",
                "forum": "7iuFxx9Ccx",
                "replyto": "eGjPHrgAoK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4376/Reviewer_1QhS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4376/Reviewer_1QhS"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for adding the additional results. \n\nThe results of dynamically changing computational budget do reveal a low sensitivity to the dynamic changes for CIFAR10C, and it is somewhat surprising that for a few cases, the model performs better over low dynamic resources. As a suggestion, an average over multiple runs column would make it easier for comparison. \n\nCIFAR10C\n\n| Constant Resource | Dynamic Resource | Error Difference (Constant - Dynamic) |\n|-------------------|------------------|--------------------------------------|\n| 15.39             | 15.52769231      | -0.1376923077                       |\n| 16.40307692      | 16.63230769      | -0.2292307692                       |\n| 17.93153846      | 18.06384615      | -0.1323076923                       |\n| 21.93846154      | 22.11769231      | -0.1792307692                       |\n\nCIFAR100C\n| Constant Resource | Dynamic Resource | Error Difference (Constant - Dynamic) |\n|-------------------|------------------|--------------------------------------|\n| 50.95230769      | 54.06615385      | -3.113846154                        |\n| 52.02846154      | 52.30538462      | -0.2769230769                       |\n| 53.97461538      | 54.39230769      | -0.4176923077                       |\n| 65.13538462      | 65.06769231      | 0.06769230769                       |\n\n\nFor CIFAR100C, the average performance difference seems to be significant. A brief discussion regarding the observation would also be helpful if there are cases where, on a longer range of dynamic resource changes, the model collapses due to massive error accumulation over time. Mentioning these observations clearly will improve the transparency of the work."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4376/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700637251466,
                "cdate": 1700637251466,
                "tmdate": 1700637251466,
                "mdate": 1700637251466,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uYwTtisrx7",
                "forum": "7iuFxx9Ccx",
                "replyto": "fG7WQsvXC3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4376/Reviewer_1QhS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4376/Reviewer_1QhS"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for sharing the results. The additional details, like the requirement for retraining of SSL on source dataset, help improve the paper's clarity."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4376/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700637257883,
                "cdate": 1700637257883,
                "tmdate": 1700637257883,
                "mdate": 1700637257883,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "nCga6tJMYF",
            "forum": "7iuFxx9Ccx",
            "replyto": "7iuFxx9Ccx",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4376/Reviewer_by2E"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4376/Reviewer_by2E"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed to leverage slimmable networks in the scenario of test-time training to allow the model to meet different resource budgets during test-time training. The paper proposed width-enhanced contrastive learning which is to conduct contrastive learning among different network width to learn different representations. The proposed method shows better performance than previous\tworks at different resource budgets"
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThe paper has a clear explanation about the background and objectives of this work. \n2.\tThe proposed method shows better performance than previous works at different resource budgets."
                },
                "weaknesses": {
                    "value": "1.\tIt seems that this work is pretty much slimmable network, but just in the setting of test-time training. I don\u2019t see what are the unique challenges in applying slimmable networks in the test-time training? The test-time training seems to be the same as training-time training, but just without labels. Then the problem seems to be how to apply slimmable networks in the un-supervised setting, which has been studied in previous works [1].\n2.\tThe motivation that different sub-networks could capture different image features has been studied in [2].\n3.\tIn Table 1, the other methods should also use ResNet-50 with different widths to have a fair comparison.\n4.\tThis work finetuned the pre-trained slimmable networks on ImageNet and ImageNet-C, what about other works?\n5.\tIn Table 5, why is the training cost is comparable or even faster than TTT++ and TTAC? The proposed method needs to forward and backward multiple times, I am assuming it should be more training expensive.\n\n\n[1] Slimmable Networks for Contrastive Self-supervised Learning. \n[2] MutualNet: Adaptive ConvNet via Mutual Learning from Different Model Configurations. TPAMI."
                },
                "questions": {
                    "value": "Please see the weakness part"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4376/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698991111669,
            "cdate": 1698991111669,
            "tmdate": 1699636410158,
            "mdate": 1699636410158,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bIQih37hrU",
                "forum": "7iuFxx9Ccx",
                "replyto": "nCga6tJMYF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4376/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4376/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1-1:** The test-time training seems to be the same as training-time training, but just without labels.\n\n**A1-1:** Good comment. Test-time training (TTT) improves the model\u2019s generalization on specific test data distribution in a way that is beyond the capabilities of training-time training. Since the distribution of the test data can be diverse and different from training data distribution, it is highly difficult for training-time training alone to train a model that can generalize to all possible test data distribution. TTT, on the other hand, provides a solution to enhance the model\u2019s generalization on specific test data distribution. Particularly, TTT takes a training-time trained model, and then updates the model using unlabeled test data to directly adapt it towards the test distribution. The adapted model is finally used for inference. Therefore, TTT is quite different to training-time training, regardless of whether it has training labels or not.\n\n**Q1-2:** Then the problem seems to be how to apply slimmable networks in the un-supervised setting, which has been studied in previous works [1].\n\n**A1-2:** In spite of both using unlabeled data, TTT and unsupervised learning are quite different. The goal of TTT is to improve the supervised learning model\u2019s generalization performance on test data by directly adapting the model towards them.  By contrast, unsupervised learning aims to learn robust representation that serves as a decent starting point for downstream tasks. Beyond this fundamental discrepancy, SlimTTT differs from [1] in methods. Firstly, there are distinctions between our contrastive learning approach and [1]. SlimTTT aggregates the multi-views captured by networks of varying widths and employs a multi-positive NCE loss, whereas [1] follows the standard SimCLR-MoCo paradigm to train each sub-networks. Our SlimTTT better facilitates knowledge interaction among networks of different widths. Secondly, we employ LCR and GFA to additionally promote the consistency of these multi-views, enhancing the networks' ability to handle distribution shifts.\n\nTo further demonstrate the superiority of TTT compared to unsupervised/self-supervised pretraining in the scenario of adapting to specific test distribution, we consider the following alternative involving [1]. We replace our supervised training-time training on CIFAR10 (C10) by unsupervised learning on both C10 and C10-C (Gaussian Noise (G_N)) using [1] and then finetune on C10. We do not conduct test-time training for this alternative and directly test on C10-C (G_N). Nevertheless, the results reveal that the method proposed in [1] struggles to handle distribution shifts in this process, leading to subpar performance on C10-C (G_N). Additionally, it's worth noting that our SlimTTT is adaptable to an online TTT setting, a capability not present in the approach proposed in [1].\n\n|Method|Protocol|Training-time training|Test-time training|Inference|Width|Err. (G_N)|\n|-|-|-|-|-|-|-\n|[1]|Self-supervised|unsupervised|None|on C10-C|1.0|16.06\n|||on C10 + C10-C|||0.75|15.44\n|||then supervised|||0.5|15.69\n|||on C10|||0.25|16.91\n|SlimTTT|Test-time training|supervised|unsupervised|on C10-C|1.0| **10.41**\n|||on C10|on C10-C||0.75| **11.04**\n||||||0.5| **11.80**\n||||||0.25| **13.96**\n\n**Q1-3:** what are the unique challenges in applying slimmable networks in the test-time training?\n\n**A1-3:** Simply incorporating slimmable networks into TTT poses several challenges: 1. Different widths of networks may interfere with each other, leading to inconsistent update directions, preventing models from achieving optimal optimization. This issue is more pronounced in TTT due to the lack of labels as well as the distribution shift. Therefore, we propose WCL and LCR to solve this challenge, which promotes the consistency between different width of networks. 2. The GFA is applied to ensure that the test features do not deviate far from the source feature distribution and it can apply a restriction over the multi-view features for each width of networks.\n\nIn the following analytical experiment on C10-C, we attempt a straightforward application of slimmable networks in test-time training without employing our consistency method (referred to as naive SlimTTT). Unfortunately, this approach yields unsatisfactory results, particularly when applied in an online manner. This is attributed to the fact that our consistency loss functions\u2014WCL, LCR, and GFA\u2014leverage the diverse views captured by networks of varying widths. This facilitates knowledge interaction among slimmable networks, a crucial aspect in the test-time training setting.\n\n|Method|width|manner|Err. Avg.|manner|Err. Avg.\n|-|-|-|-|-|-\n|naive SlimTTT|1.0|offline|10.80|online|14.78\n||0.75||11.54||15.64\n||0.5||12.59||16.72\n||0.25||15.99||18.83\n|SlimTTT|1.0|offline|**8.33**|online|**10.17**\n||0.75||**8.63**||**10.55**\n||0.5||**9.12**||**11.41**\n||0.25||**10.68**||**14.01**"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4376/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700351189236,
                "cdate": 1700351189236,
                "tmdate": 1700351189236,
                "mdate": 1700351189236,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RyniuqVjni",
                "forum": "7iuFxx9Ccx",
                "replyto": "bIQih37hrU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4376/Reviewer_by2E"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4376/Reviewer_by2E"
                ],
                "content": {
                    "title": {
                        "value": "Follow up quesstions"
                    },
                    "comment": {
                        "value": "Q1-2: I still didn't see the fundamental difference between the proposed method and unsupervised slimmable networks such as [1]. The WCL is combining the multi-positive NCE loss in contrastive learning with slimmable network. LRC is the same as the loss in slimmable network (largest network to supervise sub-networks). GFA is also proposed in previous works. Prediction ensemble is also a widely used tricks for improved performance. And the method is the combination of these techniques. I don't think there are many technical contributions. And for comparison, I think the author could apply some unsupervised slimmable networks works to the test-time training stage in their to see the difference.\n\nAnother question: Table 2 shows that GFA gives most of the improvements. It is proposed in previous works and not clearly explained how it is applied in the proposed method."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4376/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700361761646,
                "cdate": 1700361761646,
                "tmdate": 1700361761646,
                "mdate": 1700361761646,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]