[
    {
        "title": "Z-score Normalized SAC Plus Behavioural Cloning for Offline Reinforcement Learning"
    },
    {
        "review": {
            "id": "7gFRksTpfO",
            "forum": "2nrn8LRpex",
            "replyto": "2nrn8LRpex",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2894/Reviewer_Q6ES"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2894/Reviewer_Q6ES"
            ],
            "content": {
                "summary": {
                    "value": "Authors claim that replacing TD3 in TD3 + BC with SAC improves the performance and additionally propose modification for actor update which mitigate BC hyperparameter choice by normalizing Q value functions."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "Proposed modification is motivated and potentially can be useful on practice. Author's experiments show that it is beneficial when applied to SAC+BC."
                },
                "weaknesses": {
                    "value": "**Results presentation**\n\nTable 1 contains only mean values without stds which must be included in RL tables.\n\nFigure 2 is intended to present main author's results but it is really hard to read. Please report results in the table format in the main text and put training curves into appendix. I would also recommend to split this figure into multiple figures (e.g. by environment) and add dataset name as the title of each plot.  \n\nPlease also add scores averaged over datasets.\n\n**TD3 + BC scores**\n\nScores for TD3 + BC in the Table 1 are very strange. I've never seen it performing that bad. Could you please explain why this results are so different from other papers? SAC + BC scores seem to be close to the TD3 + BC scores I saw in other works which makes claim about SAC improvement questionable.\n\nhttps://arxiv.org/abs/2110.06169\nhttps://arxiv.org/abs/2206.04745\nhttps://arxiv.org/abs/2210.07105\nhttps://arxiv.org/abs/2305.09836\n\n**Baselines choice**\n\nIQL is the only strong base which authors compare against. For example, recent work ReBRAC (https://arxiv.org/abs/2305.09836), which is missed relevant work, modified TD3 + BC by applying some design choices from other algorithms resulting into much better performance while being TD3 + BC in fact. \n\nThere are also ensemble-based approaches like SAC-N/EDAC (https://arxiv.org/abs/2110.01548) or RORL (https://arxiv.org/abs/2206.02829) which are the strongest baselines for MuJoCo tasks. If would be fine if you used domains beside MuJoCo and compared only with ensemble-free baselines but only MuJoCo is used.\n\n\n**Limited evaluation**\n\nAuthors tested their algorithm using only MuJoCo datasets which are not enough today in my opinion. For example, SAC-N/EDAC perform great in this domain but fails to learn anything on AntMaze. Please consider running your approach on more challenging D4RL domains like AntMaze, Adroit or Kitchen. \n\n\n**Limited ablation study**\n\nModification for actor loss is tested only for SAC + BC. \n\nWhat if we apply it to TD3 + BC? Can it boost ReBRAC's performance even further?\n\nWill it benefit algorithm like IQL or CQL where we don't have the same BC term in actor's loss?\n\nIs SAC + BC better in offline-online setup? \n\nDoes your loss modification benefit offline-to-online setup?\n\n**Novelty**\n\nFrom my point of view there is not enough novelty in the paper. Claim about SAC benefits is questionable because of TD3 + BC problems (see **TD3 + BC scores**). And loss modification is the only thing that can be seen as something useful. It could have been compensated with broader evaluation and ablations which are also very limited."
                },
                "questions": {
                    "value": "All of the questions are taken from **Weaknesses**. I understand that not all of them can be answered during the short rebuttal phase but I kindly ask you to run more experiments in order to answer at least part of them.\n\n* Could you please explain why TD3 + BC results are so different from other papers?\n\n* What is the performance of your approach on AntMaze/Adroit/Kitchen D4RL tasks?\n\n* What if we apply it to TD3 + BC? Can it boost ReBRAC's performance even further?\n\n* Will it benefit algorithm like IQL or CQL where we don't have the same BC term in actor's loss?\n\n* Is SAC + BC better in offline-online setup? \n\n* Does your loss modification benefit offline-to-online setup?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2894/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698163349274,
            "cdate": 1698163349274,
            "tmdate": 1699636232994,
            "mdate": 1699636232994,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "9iTpmihPiE",
            "forum": "2nrn8LRpex",
            "replyto": "2nrn8LRpex",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2894/Reviewer_mezX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2894/Reviewer_mezX"
            ],
            "content": {
                "summary": {
                    "value": "This paper aims to solve the inaccurate value estimation issue of the out-of-distribution actions. Compared with previous methods, this work gives a more accurate balance of the relative weight between RL and BC. The authors conduct experiments on standard benchmark and they find that BC term can be added to the policy update of SAC algorithm to get extensively better performance with proper weight adjustment and self-adaption."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1.\tThis paper is written well and easy to follow. The authors present a simple method to improve the current offline methods.\n2.\tThis paper conducts corresponding experiments to preliminary verify their ideas."
                },
                "weaknesses": {
                    "value": "1.\tThere is no detailed motivation for this paper. Why we need z-score normalization in offline RL? \n2.\tThe experimental presentation is very poor. The label of figure 2 is very small. The paper does not have detailed ablation experiments.\n3.\tThe paper does not rigorously verify the author's claims. The article is only 7 pages long. I believe that this paper is not ready for publication at this conference."
                },
                "questions": {
                    "value": "1.\tWhy we need SAC+BC rather than TD3+BC? What is the difference between these two methods?\n2.\tWhy we need z-score normalization? The paper claims that \u2018Firstly, the distribution of z-score normalized modified Q-value is close to standard normal distribution, so that it can be balanced to suit the value of BC term\u2019 and \u2018Secondly, the approximated standard normal distribution can avoid the sensitivity to the absolute value of Q-value \u2018. Could you please provide theoretical verification or experimental results to support this claim?\n3.\tThe details of the experiment are not stated in the paper, such as Table 1."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2894/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2894/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2894/Reviewer_mezX"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2894/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698714721832,
            "cdate": 1698714721832,
            "tmdate": 1699636232892,
            "mdate": 1699636232892,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "PUdlPQDkqE",
            "forum": "2nrn8LRpex",
            "replyto": "2nrn8LRpex",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2894/Reviewer_jNsi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2894/Reviewer_jNsi"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes ZNSAC-BC, a new offline reinforcement learning algorithm that combines soft actor-critic (SAC) with behavioral cloning. It applies z-score normalization to balance the RL and BC terms and make the Q-values more standard normal distributed, avoiding sensitivity to magnitudes. The trainable variance adapts policy gradients to mitigate extrapolation error. Experiments show ZNSAC-BC outperforms selected prior methods on some D4RL benchmarks, especially for lower expert datasets. The approach extends the TD3-BC framework with a simple but effective trick, providing an incremental improvement to the state-of-the-art. However, the gains seem modest and the paper lacks rigorous comparisons to prior methods. More benchmarking is needed to conclusively demonstrate superiority over existing algorithms. Overall, it makes an interesting contribution but needs stronger empirical validation."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Builds on simple and effective TD3-BC by changing the base RL algorithm to SAC. Makes intuitive sense.\n\nZ-score normalization of Q-values is a nice trick to balance terms and adapt gradients. \n\nOverall a straightforward extension of prior work with clear improvements."
                },
                "weaknesses": {
                    "value": "While better than TD3-BC, the gains seem somewhat incremental, not a dramatic breakthrough.\n\nLack of comparisons with SOTA methods \n\nThe experimental evaluation is very limited (only \"easy\" MuJoCo tasks) and  empirical results are underwhelming when compared to similar approaches\n\nMore analysis and intuition explaining why the z-score normalization helps would strengthen the approach.\n\nThe writing could be tightened up and made easier to follow in some parts."
                },
                "questions": {
                    "value": "Report numerical results for ZNSAC-BC and baseline methods on the D4RL benchmarks. \n\nThe limited reported results look fine when compared to your chosen algorithms, but fall short of those in other recent papers.  This is particularly the case for medium-replay and medium datasets where it looks like you do well when compared to TD3-BC, SAC-BC and IQL, but are inferior to other algorithms particularly for hopper/walker2d. \n\nProvide tables aggregating final performance across multiple runs with standard deviations, to show statistical significance of the improvements, and add quantitatively compare performance to the published state-of-the-art results on these benchmarks from prior papers, to put the gains in context."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No concerns"
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2894/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2894/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2894/Reviewer_jNsi"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2894/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698766328854,
            "cdate": 1698766328854,
            "tmdate": 1699636232813,
            "mdate": 1699636232813,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "0OPksucMWg",
            "forum": "2nrn8LRpex",
            "replyto": "2nrn8LRpex",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2894/Reviewer_whc9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2894/Reviewer_whc9"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a new algorithm called z-score normalized SAC-BC (ZNSAC-BC), tackling the overestimation issue in offline reinforcement learning. ZNSAC-BC uses a behavioral cloning (BC) term to constrain the learned policy to not bootstrap from out-of-distribution actions, thus mitigating the overestimation. The paper also introduces a normalization term of the action value to balance the value estimation and the BC term in the policy improvement step."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper aims to mitigate the overestimation issue in offline reinforcement learning. The problem it focuses on is meaningful and useful. \n\n- The method proposed is novel and empirically showed a reasonable performance."
                },
                "weaknesses": {
                    "value": "- The paper is inconsistent. It seems like the main algorithm introduced in the paper is ZNSAC-BC, which is an offline learning algorithm for mitigating the overestimation issue caused by out-of-distribution action. However, the conclusion section talks about a totally different algorithm called AAAC, which mainly focuses on a state-dependent adaptive temperature for stabilizing training. Meanwhile, the abstract indicates the proposed method is called \\emph{SAC-BC}. ZNSAC-BC performed better than SAC-BC empirically, according to the experiment section, so I think it might be better to claim the main contribution is ZNSAC-BC instead of SAC-BC in the abstract.  \n\n- The labels in Figure 2 are small and hard to read. The color in subplot b is inconsistent with other subplots, and the result for SAC-BC is missing.\n\n- Detailed experiment settings are not provided. The missing information reduces the reproducibility of the experiment.\n\nA Small Thing:\n\n- For the left quotation mark, you may use `` instead of \u201c."
                },
                "questions": {
                    "value": "- ZNSAC-BC introduces a new parameter, $\\rho$, which seems manually selected and remains constant during training. The paper mentions $\\rho$ is set to 2.5 in the experiment, without explaining how this number was selected. It could be better if the paper includes either an empirical study regarding how sensitive the method is to $\\rho$, or a guide on how to select this parameter.\n\n- The algorithm maintains target networks for the actor and the critic. Both target networks are used when calculating the bootstrapping target for the critic. Usually, only maintaining a target network for the critic is enough for learning. That is, the next action is sampled from the learning actor network instead of the target actor network. I would like to ask if the authors investigate the advantage of sampling the next action from the target actor network, comparing to sampling it from the learning actor network. Moreover, in the experiment section, did all baselines use the same setting, i.e., maintaining target networks for both actor and critic networks, and sampling action from the target actor network when calculating the bootstrapping target?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2894/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698772300300,
            "cdate": 1698772300300,
            "tmdate": 1699636232742,
            "mdate": 1699636232742,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]