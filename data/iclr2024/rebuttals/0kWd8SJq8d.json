[
    {
        "title": "MINDE: Mutual Information Neural Diffusion Estimation"
    },
    {
        "review": {
            "id": "P45fmNHBkz",
            "forum": "0kWd8SJq8d",
            "replyto": "0kWd8SJq8d",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1719/Reviewer_a1nb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1719/Reviewer_a1nb"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces Mutual Information Neural Diffusion Estimation as a family of mutual information estimation models based on estimating the difference of score functions.\nThe authors introduce and evaluate 4 variants based on the modeled scores (joins vs conditional) and the use of a standard normal as a reference for entropy computation.\nAn experimental section validates the theory on common mutual information estimation benchmarks, comparing MINDE against modern alternatives in literature and assessing self-consistency and compositionality."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1) The paper provides a solid, detailed derivation for MINDE rooted in SDE theory.\n\n2) The experimental section effectively demonstrates the effectiveness of the proposed estimators on common benchmarks.\n\n3) Although a Related Work section is missing, to the best of the reviewer\u2019s knowledge, the paper includes references to all the relevant literature.\n\nOverall I believe in the relevance and novelty of the submission and I am willing to increase my score whenever the authors address my main concerns."
                },
                "weaknesses": {
                    "value": "# Main concerns\n1) The experimental section benchmarks the estimators against common discriminative estimators such as MINE, NWJ, D-V, and InfoNCE which are designed as lower bounds of mutual information, but no comparison against generative estimators based on difference of entropies is provided [1,2]. Since MINDE, and in particular MINDE-$\\sigma$, is based on the same principle, such a comparison seems natural.\n\n2) The paper mentions previous similar work on diffusion-based mutual information estimation [3], which differs in the derivation and modeling choices. Nevertheless, this work is not included in the experimental comparison, and the advantages of MINDE are not further elaborated.\n\n3) No discussion regarding the computational cost or challenges of training MINDE compared to the other models in the literature is included in the main text.\n\n### Minor Remarks\n1) The main text includes in-depth technical details with an extensive notation. If on one hand, this helps to verify the soundness of the derivation, on the other, it makes following the main derivation more difficult. I believe that submission could benefit by including additional intuition to guide the reader.\n\n2) The plots in Figures 1 and 2 are quite small and difficult to read\n\n### References\n[1] McAllester, David, and Karl Stratos. \"Formal limitations on the measurement of mutual information.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2020.\n\n[2] Song, Jiaming, and Stefano Ermon. \"Understanding the limitations of variational mutual information estimators.\" ICLR, 2020.\n\n[3] Kong, Xianghao, Rob Brekelmans, and Greg Ver Steeg. \"Information-Theoretic Diffusion.\" ICLR, 2023."
                },
                "questions": {
                    "value": "1) How does MINDE perform compared to classic generative estimators based on the difference of cross-entropies based on normalizing flows such as DoE in [1] and GM in [2]?\n\n2) Can the author elaborate on the differences between MINDE and the work in [3]?\n\n3) What are the main challenges when training the MINDE models? How does the training and inference cost (in terms of memory and computing) compare to the other neural estimators?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1719/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1719/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1719/Reviewer_a1nb"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1719/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697897220135,
            "cdate": 1697897220135,
            "tmdate": 1700486801892,
            "mdate": 1700486801892,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "nVuoRLHMfR",
                "forum": "0kWd8SJq8d",
                "replyto": "P45fmNHBkz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1719/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1719/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the positive feedback, which acknowledges soundness of the work and the relevance of experimental results. We submitted a new version of the manuscript, where the additional experiments and changes requested by the reviewer have been included. \n\n*Weaknesses: Main concerns\n1.\tThe experimental section benchmarks the estimators against common discriminative estimators such as MINE, NWJ, D-V, and InfoNCE which are designed as lower bounds of mutual information, but no comparison against generative estimators based on difference of entropies is provided [1,2]. Since MINDE, and in particular MINDE-  is based on the same principle, such a comparison seems natural.*\n\nThe connection between our generic estimator ( eq. (13) ) and the work of McAllester & Stratos [2020], is acknowledged in the submitted version of our paper (\u201cThis property, frees our estimation guarantees from the pessimistic results of McAllester & Stratos [2020]\u201d). We do not consider this work as a competitor, but rather as a key literature resource which can help understanding, from a different perspective, one of the reasons why the estimator we propose has such good performance! \n\nNevertheless, we do agree with the reviewer that an extra comparison with a generative approach using a DoE estimator could enrich our work. For this reason, we included a new direct comparison between MINDE variants and the official implementation of DoE (this appears both in the main paper, and in all Appendices). Even in this case, our method MINDE outperforms DoE, corroborating the idea that, while having an estimation which is neither an upper nor a lower bound has statistical advantages, a flexible model based on score functions is also key for the success of MINDE. \n\n*2.The paper mentions previous similar work on diffusion-based mutual information estimation [3], which differs in the derivation and modeling choices. Nevertheless, this work is not included in the experimental comparison, and the advantages of MINDE are not further elaborated.*\n\nAs stated in our submitted version of the paper \"a related estimator has recently appeared in the literature [Kong et al., 2022], although the technical derivation and objectives are different than ours\". \n\nThe work by Kong et al., which focuses mainly on likelihood estimation (with entropy estimation  being discussed as an interesting by-product), can be understood as a particular case of our generic framework. \n\nIndeed, our result: i) is immediately applicable to **any** forward SDE (whereas Kong et al. 2022  only focus on $ z_\\gamma=\\sqrt{\\gamma}x+ \\epsilon$ ) ii) is valid for generic KL divergences (we are not forced to estimate MI as difference of entropies, or difference outside, but also directly using the difference inside formulation) iii) allows to leverage SDE theory literature results about the convergence to 0 for large $T$ of the KL term between terminal distributions iv) allows the definition of a new method based on joint diffusion processes. While we believe that in principle the results of Kong et al. 2022 could be extended, to do so without explicitly introducing SDE theory would be cumbersome.  Summarizing, one way to look at the literature discussed in this answer is to consider the combination of the entropy estimator by Kong et al. 2022 and the technique of DoE to be an individual, particular instance of our proposed family of estimators. \n\n*3.No discussion regarding the computational cost or challenges of training MINDE compared to the other models in the literature is included in the main text.*\n\nPlease see also a comment (and our answer) shared by Reviewer QLQ9. In summary, all neural based methods have comparable architectures, model sizes in terms of parameter count, and training times. Non parametric models, on the other hand, while being computationally efficient fail when distributions are complex, and high dimensional.\n\nIt is very important to notice that our MINDE variants do not require the simulation of backward dynamics of a diffusion process, which is what is done in the literature for generative purposes. \n\nAn additional note is in order. In the new results in Appendix F, we show an application use-case for our MINDE method, conditional version. In that case, training time is exactly 0, since we can use a pre-trained score model to estimate MI between real-world data (image and text prompts)."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1719/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700388958893,
                "cdate": 1700388958893,
                "tmdate": 1700388958893,
                "mdate": 1700388958893,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8QC1Rl2RPC",
                "forum": "0kWd8SJq8d",
                "replyto": "Lh1xL7GK5V",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1719/Reviewer_a1nb"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1719/Reviewer_a1nb"
                ],
                "content": {
                    "comment": {
                        "value": "I want to thank the authors for their comprehensive response, which satisfactorily addresses my primary concerns, and for the inclusion of additional experiments in their study. While I appreciate the updates, I note that the use of unimodal logistic and normal distributions in the DoE model might not adequately represent the complexity of the distributions in the benchmark. I suggest considering more flexible models, such as normalizing flows (specifically spline or NVP, as mentioned in [2]), to establish a stronger baseline for the DoE estimators.\nDespite this, I acknowledge the improvements made in the updated submission and I have increased my evaluation score accordingly.\n\nAdditionally, I recommend that the author integrate their responses to questions 1 and 2 into the main text of the paper. This would provide future readers with immediate insights into these critical aspects of the research, further enhancing the paper\u2019s role with respect to the existing literature."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1719/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700486769446,
                "cdate": 1700486769446,
                "tmdate": 1700486769446,
                "mdate": 1700486769446,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "EJi5bVTcYf",
            "forum": "0kWd8SJq8d",
            "replyto": "0kWd8SJq8d",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1719/Reviewer_QLQ9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1719/Reviewer_QLQ9"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes mutual information (MI) estimators based on diffusion models. This is achieved by representing MI as quantities that incorporate KL divergence which itself can be written as equations that involve score functions. Theoretical arguments justifying these claims are presented in the paper and experimental evaluation is performed on a recent benchmark dataset proposed for assessing MI estimators from multiple viewpoints (sparsity, dimensionality, long tails, and transformations). The results suggest that the developed estimator (MINDE) outperforms alternatives in most of these settings."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The problem considered is of critical importance in several applied and theoretical fields. Existing estimators either fail in high dimensions or require large amounts of data to provide precise estimates.\n\nThe results are quite impressive, the proposed estimator seems to outperform alternatives in most settings.\n\nSeveral aspects of MI estimation that make the estimation challenging that were originally introduced in [1] such as sparsity, dimensionality, long tails, transformations, data processing, and consistency are considered in the experimental section making the empirical aspect of the paper strong.\n\n[1] https://arxiv.org/abs/2306.11078"
                },
                "weaknesses": {
                    "value": "The organization of the paper makes it hard to follow. The measure theoretical notations make the paper inaccessible to the broader audience interested in using the estimator in applied settings.\n\nThe contributions are not fully clear. The connections between score, KL, MI, and H existed before. In addition, it's an established fact that diffusion process models are more powerful density estimators specifically in higher dimensions making it less surprising that the MI and H estimators are superior.\n\nThe comparisons lack several important aspects specifically in the context of MI estimation. The wall-clock runtime and the dataset size requirements are not particularly elaborated on in the paper."
                },
                "questions": {
                    "value": "How does the method scale with the number of data points used for training? Can you make a plot of the test error as a function of the number of training data points used? The number of training data points can vary between 100, 1K, 10K, and 100K. Can you do this for a varying number of dimensions as well and report results for different estimators?\n\nInfoNCE seems to be doing a very good job, can you come up with an overall score to rank the methods? Does InfoNCE also require a large dataset with the same size as yours?\n\nCan you include time comparisons between different models? I assume learning the score functions from a diffusion process for the joint probability distribution would be an overkill if one only cares about the MI or H. What\u2019s the training time comparison between different models and how do the authors account for computational resources used by various models?\n\nDiffusion processes are known to outperform other density estimators in various settings. Therefore it\u2019s no surprise if it achieves better an estimation of MI and H. That said, I\u2019m having a hard time determining what the main contributions are. I imagine that the main contributions are representing MI and H as quantities that incorporate score functions. However, the connections between KL, score, MI, H are known results in the information theory literature [cite]. Is the extension of those results to the diffusion process (as opposed to generic densities) non-trivial? Is there something critical that I\u2019m missing?\n\nThe paper would benefit from reorganization in my opinion. The notations used in the paper as well as the organization of the sections make it difficult to follow the arguments of the paper. The contributions start appearing very late in the paper and there is a large amount of background which might not be necessary for the main arguments. I suggest the following organization:\n* Simple intro to diffusion models (no need to include the measure theoretical notation as it\u2019s mainly used for the proofs and can be transported to the supplementary).\n* Introducing the joint diffusion model (4.1) and MINDE.\n* Making connections between MI and H, score functions, and KL divergence.\n\nA recent paper [1] discusses that the absolute continuity assumption made in the paper might not hold given the architecture of the neural network used for approximating the score function (the cited paper discusses it in the context of functional variational inference but intuitively the same arguments should hold for diffusion process). In this case, the KL divergence will be infinity and the MI and H estimators developed will be ill-defined. Can the authors articulate the underlying assumptions further and explain what datasets can benefit from the estimators developed in the paper?\n\n[1] https://arxiv.org/abs/2011.09421"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1719/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1719/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1719/Reviewer_QLQ9"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1719/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698781912071,
            "cdate": 1698781912071,
            "tmdate": 1700598584550,
            "mdate": 1700598584550,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fGHT9YYAHG",
                "forum": "0kWd8SJq8d",
                "replyto": "EJi5bVTcYf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1719/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1719/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "We thank the reviewer for appreciating our efforts in conducting an extensive experimental campaign. We hope that our careful rebuttal, as well as the new version of the manuscript will contribute in clarifying the reviewer's doubts.\n\n*Weaknesses:\nThe organization of the paper makes it hard to follow. The measure theoretical notations make the paper inaccessible to the broader audience interested in using the estimator in applied settings.*\n\nThe complexity of the measure theoretic notation is a shared concern, which we understand. However, our goal was to produce a rigorous, technical paper, and the theory which we build upon from the literature requires such rigor. Nevertheless, we do understand that making the paper more accessible to practitioners could greatly improve the impact of our work. For this reason, we prepared a new version of the paper including an extended section in Appendix D.1, D.2, where we include pseudo-code algorithms (Algorithms 1,2,3,4) for both training and estimation, and we included the anonymized source code, which will be made public in later stages. \nFinally, we also added new qualitative and quantitative results in Appendix F, showcasing a tangible application of MINDE to study complex, real-life datasets, in the context of the analysis of information dynamics of prompt-based generative models like Stable Diffusion.\n\n*The contributions are not fully clear. The connections between score, KL, MI, and H existed before. In addition, it's an established fact that diffusion process models are more powerful density estimators specifically in higher dimensions making it less surprising that the MI and H estimators are superior.*\n\nWe are well aware that some of the \u201cingredients\u201d of our work have been studied in the large body of work that exists on diffusion models, and we did our best to properly cite our sources. For the sake of producing a self-contained technical paper, we built upon existing, scattered connections and reunited them with a unique notation, to pave the way for our main contributions. Indeed, to the best of our knowledge, our MI estimator (and our variants) we propose in the paper was not known in the Machine Learning/ Statistics community before. Given the impressive empirical performance we obtained in our experimental campaign, we think our work is a useful contribution to the literature.\nWe also add two new results in Appendix F and Appendix G. First, we showcase an application of MINDE by presenting new qualitative and quantitative results about the study of information dynamics of prompt-based generative models, which is a tangible application of MINDE to complex, real-life datasets (see Appendix F).\nFurthermore, we demonstrate that the theoretical contribution of our work, which allowed us to define the joint variant of MINDE, allows computing MI between more than two random variables, which is a property that to the best of our knowledge no other MI estimator shares. Our illustrative results use simple distributions for which computing the exact MI is possible (see Appendix G).\n\n*The comparisons lack several important aspects specifically in the context of MI estimation. The wall-clock runtime and the dataset size requirements are not particularly elaborated on in the paper.*\n\nPlease, refer to answers to your questions below, where we elaborate on this comment.\n\n*Questions:\nHow does the method scale with the number of data points used for training? Can you make a plot of the test error as a function of the number of training data points used? The number of training data points can vary between 100, 1K, 10K, and 100K. Can you do this for a varying number of dimensions as well and report results for different estimators? InfoNCE seems to be doing a very good job, can you come up with an overall score to rank the methods? Does InfoNCE also require a large dataset with the same size as yours?*\n\nThank you for the suggestion. In the new version (see Appendix E.3 \u201cTraining size ablation study\u201d) of the paper we include an extended experimental campaign varying the training size in the range 5k-10k-50k-100k. Overall, while InfoNCE performs well on larger training sizes, we observe that MINDE is robust to smaller training sizes when dealing with challenging distributions (see for example Figure 8 in Appendix E.3)."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1719/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700388330819,
                "cdate": 1700388330819,
                "tmdate": 1700388330819,
                "mdate": 1700388330819,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "X7zI72uPU4",
                "forum": "0kWd8SJq8d",
                "replyto": "EJi5bVTcYf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1719/Reviewer_QLQ9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1719/Reviewer_QLQ9"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for replying to my comments revising the manuscript and performing the new experiments. The authors successfully addressed some of my concerns (scalability of the model in terms of its run time and its performance wrt the number of data points and dimensions).\n\nGiven that the authors are aware of the existing theoretical connections used as the building blocks of their work, I suggest having a short paragraph or sentence and clearly mentioning what existed before and what's new in the paper. Although the references are included in various parts of the paper, the current manuscript might not precisely reflect the contributions made by the authors.\n\nI'll slightly increase my score because some of my concerns are not properly addressed. Specifically: (1) I still find the organization of the paper inaccessible. Although a new section in the appendix is added with the algorithmic description, this will not satisfactorily allow readers (even statisticians who are not familiar with stochastic processes and measure-theoretic notation) to follow the main ideas. (2) The results show that some of the existing estimators (such as Info-NCE) are on par with MINDE. They outperform MINDE in some datasets and provide lower variance estimates, while on other datasets MINDE does a better job. Given the new results presented in the appendix I find the authors' argument \"while InfoNCE performs well on larger training sizes, we observe that MINDE is robust to smaller training sizes when dealing with challenging distributions\" inaccurate.\n\nRegarding my last comment about absolute continuity, aren't the authors assuming that the neural net architecture is capable of estimating the density of the data distribution? Even if the true distributions of two variables $X$, $Y$ are absolutely continuous wrt one another, it might still be possible that the model does not capture that since the distributions that are achievable by the model given its underlying architecture might not be absolutely continuous wrt the data distributions. This is more of an intuitive comment rather than a precise mathematical argument, and given that the model is already working on a large number of datasets you can ignore this."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1719/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700598532488,
                "cdate": 1700598532488,
                "tmdate": 1700598759835,
                "mdate": 1700598759835,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "AaawTjzVbJ",
            "forum": "0kWd8SJq8d",
            "replyto": "0kWd8SJq8d",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1719/Reviewer_hHbr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1719/Reviewer_hHbr"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes *Mutual Information Neural Diffusion Estimation (MINDE)*, a novel method to estimate the mutual information (MI) between random variables. By first decomposing the KL divergence between two generic measures into two terms via its disintegration properties, then utilizing the Girsanov Theorem, MINDE provides a recipe that incorporates score-based diffusion models into the estimation of MI. The work provides four variants of MINDE, each based upon either conditional or joint diffusion processes, and presents experimental results that not only show the effectiveness in estimating MI accurately, especially on more challenging tasks (*e.g.*, spiral diffeomorphism), but also illustrate the robustness and reliability of the proposed method via self-consistency tests (including independency test, data-processing test, and additivity test) on the MNIST dataset."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The construction of the basic building blocks that establish the estimation of KL divergence and of the entropy is well organized and clearly written.\n2. It\u2019s interesting to see the SDE framework of diffusion models being used under the setting of MI estimation, which could inspire the research community to investigate diffusion models in new directions."
                },
                "weaknesses": {
                    "value": "1. While the utilization of score-based diffusion models can be justified by the Girsanov Theorem, it\u2019s unclear how they are used as **generative models** (*i.e.*, using the reverse-time SDE to generate samples) \u2014 it seems that only forward diffusion SDEs are needed, in order to train the score networks. Therefore, it\u2019s a bit confusing when the authors wrote \u201cwe explore the problem of estimating MI using generative models\u201d (Page 1), instead of something like \u201cwe explore the problem of estimating MI using score functions\u201d.\n2. Source code for the experiments is not provided."
                },
                "questions": {
                    "value": "1. Could the authors discuss the connection between this work and MINE (Belghazi et al., 2018)? The title of this work seems to suggest a close connection with MINE, but the paper only provides the experimental results of MINE as one of the baseline models for MI estimation.\n2. In Section 5.1, it is mentioned that using a larger training size shall \u201cavoid confounding factors\u201d. What do authors mean by \u201cconfounding factors\u201d?\n3. Might be a typo in Page 3: \u201cRadon-Nikodyim derivative\u201d shall be \u201cRadon-Nikodym derivative\u201d."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1719/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1719/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1719/Reviewer_hHbr"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1719/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699264012097,
            "cdate": 1699264012097,
            "tmdate": 1699636100654,
            "mdate": 1699636100654,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "cAsoNCImTd",
                "forum": "0kWd8SJq8d",
                "replyto": "AaawTjzVbJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1719/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1719/Authors"
                ],
                "content": {
                    "title": {
                        "value": "rebuttal"
                    },
                    "comment": {
                        "value": "Thank you very much for your observations, and for noticing our original use of diffusion models for tasks beyond synthetic data generation.\n\n*Weaknesses:\n1.\tWhile the utilization of score-based diffusion models can be justified by the Girsanov Theorem, it\u2019s unclear how they are used as generative models (i.e., using the reverse-time SDE to generate samples) \u2014 it seems that only forward diffusion SDEs are needed, in order to train the score networks. Therefore, it\u2019s a bit confusing when the authors wrote \u201cwe explore the problem of estimating MI using generative models\u201d (Page 1), instead of something like \u201cwe explore the problem of estimating MI using score functions\u201d.\nWe apologize for the confusion, as our sentence \u201cwe use generative models,  but with an original twist\u201d might be misinterpreted indeed. Clearly, in our work we do not need the generative capabilities of diffusion models. The backward dynamics are however necessary to justify our central results, which allow estimating MI using score functions.*\n\nWe modified the introduction, by referring to the distinction defined by the literature between discriminative and generative approaches (instead of models).\n\n\n*2.Source code for the experiments is not provided*\n\nWe now include in the supplementary material an anonymized version of the source code. To further enhance reproducibility and clarity of the manuscript we also extended the Appendix D.1, D.2, with additional pseudo code (Algorithms 1,2,3,4) for the training and sampling procedures (see also concerns shared by Reviewer N2Vu).\n\n*Questions:\n1.\tCould the authors discuss the connection between this work and MINE (Belghazi et al., 2018)? The title of this work seems to suggest a close connection with MINE, but the paper only provides the experimental results of MINE as one of the baseline models for MI estimation*\n\nWe consider MINE as an important contribution from the literature, and it indeed constitutes a strong baseline according to our experiments. There is however no direct connection between our method MINDE and that of MINE, it is just that the acronyms are similar, with the \u201cD\u201d indicating the use of \u201cdiffusion processes\u201d.\n\n\n*2.\tIn Section 5.1, it is mentioned that using a larger training size shall \u201cavoid confounding factors\u201d. What do authors mean by \u201cconfounding factors\u201d?*\n\nNot all the methods are equally resilient to smaller training sizes. In particular, the competitors we consider in our experiments perform worse than our MINDE variants for smaller (5k,10k,50k) training sizes (see also comments by  Reviewer QLQ9). In our submission, our goal was to perform a fair comparative analysis, and we chose the large training size regime to boost the performance of our competitors. We now present a new set of experimental results (see Appendix E.3 \u201cTraining size ablation study\u201d), where we show that MINDE variants outperform competitors in a wide range of training sizes.\n\n\n*3.Might be a typo in Page 3: \u201cRadon-Nikodyim derivative\u201d shall be \u201cRadon-Nikodym derivative\u201d.*\n\nThanks for spotting the typo! We fixed it."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1719/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700387832681,
                "cdate": 1700387832681,
                "tmdate": 1700387832681,
                "mdate": 1700387832681,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xBeoycOpgK",
                "forum": "0kWd8SJq8d",
                "replyto": "cAsoNCImTd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1719/Reviewer_hHbr"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1719/Reviewer_hHbr"
                ],
                "content": {
                    "title": {
                        "value": "Thank You Authors"
                    },
                    "comment": {
                        "value": "Thank you for your responses to my review $-$ my questions have been sufficiently addressed. I will keep my current score as the rating is already positive."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1719/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700585139191,
                "cdate": 1700585139191,
                "tmdate": 1700585139191,
                "mdate": 1700585139191,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "dHboY3HaK8",
            "forum": "0kWd8SJq8d",
            "replyto": "0kWd8SJq8d",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1719/Reviewer_N2Vu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1719/Reviewer_N2Vu"
            ],
            "content": {
                "summary": {
                    "value": "The authors derive an estimator of mutual information using neural diffusion."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "I really like that the authors used the Czyz benchmark data, and also the consistency tests. \nI also appreciate the creativity of the theoretical advancement, though I don't understand it (see below)."
                },
                "weaknesses": {
                    "value": "I was super excited to read this paper, because I love thinking about mutual information and entropy, and have recently been working on some related issues.   The ideas are intriguing, and the results are impressive. So, the rest of this review will focus on the issues for me understanding the methods and results.\n\n1. The biggest issue for me is that I almost immediately got lost.  I know information theory pretty well, I learned it from Fred Jelinek before he died. That said, I know very little about diffusion processes and SDEs. My main confusion with this paper was about connecting the math on diffusion processes to the process of estimating MI. There is a leap, which I am willing to believe is justified, that I completely missed.  Why are we talking about a filtration and an Ito process at all?  How do they related to the joint distribution F_{X,Y}? I read the words in Section 2-4, but was completely lost.  To be fair, I was also lost the first time I read the KSG paper (https://journals.aps.org/pre/abstract/10.1103/PhysRevE.69.066138).  I imagine lots of people might have followed the logic and derivation completely. But not me, I just didn't get it. And I spent some time trying to figure it out, as I'd like to get it, it seems cool, and within the realm of possibilities that I did get it, but I didn't. I thought maybe reading Appendix D would help me, but it didn't really help either.  In the end, I don't quite know what you did, or why you did it.  I would love something like Algorithm 1 and 2, which perhaps points to subroutines for how each relevant quantity is computed. For example, I don't see how to do \"r.h.s. Eq. (16)\". Where does 'g' come from, or k, or T? etc.\n\n2. In terms of the numerical results, I think I understand them, which was exciting for me! Figure 1 shows that MINDE works about as well as other things on relatively easy problems where there is enough data, and slightly better on a spiral dataset when MI is high.  That's cool as far as it goes.  I'm always interested in *finite sample properties* for my estimators, because I always have finite data.  In particular, I often work on biomedical problems, in which sample sizes are typically hundreds.  So, I would be much more interested in seeing plots showing accuracy as a function of sample size, especially for the \"easy\" ones where many different estimators are getting the right answer. This introduces additional information about convergence rates. The fact that 2 high-dimensional simulations showed it does as well as other things, and one showed it is slightly better for some parametrization, I found not that compelling.\n\n3. I understand why the authors say that the benchmark consists of 40 tasks.  However, in my opinion, this wording is confusing and misrepresenting the work. I would say that there are about 10 different tasks, with an average of 4 different parameterizations per task. Consider, for example, our paper https://elifesciences.org/articles/41690. We describe 20 tasks, but in Figure 2, we should many different parameterizations (dimensions) per task. Claiming that we had more than 20 tasks, in my opinion, would not be in integrity.  Varying parameters, dimensions, and sample sizes for a particular task is important, but claiming that each different parameterization is a different task seems inappropriate to me. Of note, the Czyz et al paper from which the tasks are extracted never seems to make such a claim. Rather, they name about 10 different tasks explicitly.\n\n4. The claim that MINDE outperforms other approaches on 35/40 tasks I also question. No errorbars are provided.  While this is typical in machine learning benchmark comparisons, I think the practice is ill-advised and misleading.  Without errorbars, there is no evidence that if one ran the exact same code again, how likely is it that the results would be similarly ordered.  There is a rich history of non-parametric tests for evaluating whether one estimator tends to be better than another, and I would encourage the authors to only claim something is better when there is statistical evidence supporting the claim. \n\n5. Directly using kernel density estimators and plugging them into the MI equations, or using the standard approaches to estimating mutual information (eg, KSG, which is included in sklearn), to compare with the neural methods, would also be important."
                },
                "questions": {
                    "value": "Things that would inspire me to increase the score: \n1. Explain (more/better) why they are talking about SDEs for estimating MI.\n2. Perform statistical analyses and/or errorbars indicating whether MINDE is significantly better than anything else on any particular simulation.\n3. Clarify how many different settings were considered, and discuss from that perspective.\n4. More clear/complete pseudocode."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1719/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1719/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1719/Reviewer_N2Vu"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1719/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699295378483,
            "cdate": 1699295378483,
            "tmdate": 1700683212186,
            "mdate": 1700683212186,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SfkRbxizao",
                "forum": "0kWd8SJq8d",
                "replyto": "dHboY3HaK8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1719/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1719/Authors"
                ],
                "content": {
                    "title": {
                        "value": "rebuttal"
                    },
                    "comment": {
                        "value": "We thank the reviewer for acknowledging the originality of our method, and the high relevance of the experimental results. We hope our rebuttal, along with the revised version of our paper, will clarify all doubts and questions of the reviewer.\n\n*Weaknesses:\nI was super excited to read this paper, because I love thinking about mutual information and entropy, and have recently been working on some related issues. The ideas are intriguing, and the results are impressive. So, the rest of this review will focus on the issues for me understanding the methods and results.\n1.\tThe biggest issue for me is that I almost immediately got lost. I know information theory pretty well, I learned it from Fred Jelinek before he died. That said, I know very little about diffusion processes and SDEs. My main confusion with this paper was about connecting the math on diffusion processes to the process of estimating MI. There is a leap, which I am willing to believe is justified, that I completely missed. Why are we talking about a filtration and an Ito process at all? How do they related to the joint distribution F_{X,Y}? I read the words in Section 2-4, but was completely lost. To be fair, I was also lost the first time I read the KSG paper (https://journals.aps.org/pre/abstract/10.1103/PhysRevE.69.066138). I imagine lots of people might have followed the logic and derivation completely. But not me, I just didn't get it. And I spent some time trying to figure it out, as I'd like to get it, it seems cool, and within the realm of possibilities that I did get it, but I didn't. I thought maybe reading Appendix D would help me, but it didn't really help either. In the end, I don't quite know what you did, or why you did it. I would love something like Algorithm 1 and 2, which perhaps points to subroutines for how each relevant quantity is computed. For example, I don't see how to do \"r.h.s. Eq. (16)\". Where does 'g' come from, or k, or T? etc.*\n\t\nWe apologize with the reviewer for the dense and rather involved notation of our paper, it is indeed not an easy paper to digest! The technical introduction of measure theoretic quantities serves the purpose of being able to rigorously assess validity of the central claims of our work (equation (10) and the estimator equation (11) ). Indeed, central to the technical derivation of the estimator, are path measures of diffusion processes, their time reversal, and the *ratio* of such paths (expressed thanks to Girsanov Theorem). All these results, which are built on a growing body of work from the literature, require the rigorous definitions used in our paper. We also made a particular effort in harmonizing and unifying the notation, which is intended to simplify life for the reader, instead of asking readers to dive into several other articles from the literature, each with their own notation.\nOur work sets the basis to estimate the KL divergence between ANY pair of measures, and we focus in particular on the case of Mutual Information. This can be cast as the KL between joint and marginals, or the KL between conditional and marginals (with an extra expected value). All the different formulations correspond to variants of MINDE that we experimentally validate.\nWe do understand that our stylistic choice, while necessary for a technically sound paper, can harm accessibility of our work to a broader audience. For this reason, as correctly hinted by the reviewer, we included in the new version of the manuscript (see Appendix D.1, D.2, Algorithms 1,2,3,4) an extended version of the pseudocode for our methods where i) we clarify explicitly how to use \u201cr.h.s of (16)\u201d and ii) we accurately describe the training subroutines, referring to the equations in the main paper. \nFinally, concerning  \u201cWhere does $g$ come from, or $k$, or $T$? etc.\u201d, these are parameters which have been introduced throughout the manuscript. In particular $g_t$ is the diffusion coefficient (eq. (1)), $k_t$ is defined in the paragraph after eq. (14) (at the end of \u201c Now, the score function\u2026\u201d) and $T$ is the duration of the diffusion process, introduced at the very beginning before eq. (1). In practical experiments, we adopt one of the standard SDE typically adopted in the literature (VP-SDE, [Song2021]) for which the aforementioned quantities have very simple expressions."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1719/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700387096043,
                "cdate": 1700387096043,
                "tmdate": 1700387096043,
                "mdate": 1700387096043,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UHmnTyzIeD",
                "forum": "0kWd8SJq8d",
                "replyto": "SfkRbxizao",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1719/Reviewer_N2Vu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1719/Reviewer_N2Vu"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "It is clearer (to me) now, the appendix revisions helped.  However, it is still not clear.  I invite you to inquire about the following comment:\n\n\"We do understand that our stylistic choice, while necessary for a technically sound paper, can harm accessibility of our work to a broader audience. \"\n\nIs your style choice truly \"necessary\" for a technically sound paper?  I do not believe that is the case.  I believe the stylistic choice you have made renders the paper inaccessible for a large subset of the intended community.  \n\nFurther changes I would recommend:\n\n1. Section 2 comes out of nowhere for me, it is only justified to look at diffusion processes after we understand that you are using them in Section 3, so I'd re-order the contents.\n2. All terminology be define prior to its first use.  eg, you introduce \\mu^A as a generic measure, and then start writing about \\mathbb{P}^{\\mu^A}, without defining it first (or maybe ever). Similarly for \"#\", and the hat notation. \n3. Restrict yourselves to 1 superscript, not 2.\n\nIf you made all those changes, maybe I'd be able to understand.  Please note that I really *want* to understand, and I've invested a lot of energy in understanding, and still failed.  I firmly believe you are capable of writing in a way that I would understand, and want you to, both for my sake, and yours."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1719/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700678913521,
                "cdate": 1700678913521,
                "tmdate": 1700678913521,
                "mdate": 1700678913521,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "O2FzyiO23Y",
                "forum": "0kWd8SJq8d",
                "replyto": "hQPgYu1zDe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1719/Reviewer_N2Vu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1719/Reviewer_N2Vu"
                ],
                "content": {
                    "title": {
                        "value": "Numerical results are clearer"
                    },
                    "comment": {
                        "value": "I commend the authors for improving the clarity of the numerical results. However, there are now *many* new figures, each with *many* columns, and with very small fonts, and using boxplots.  It is too much for me to parse easily.  Things I want instead:\n\n1. I want a main figure showing accuracy vs sample size that summarizes all that stuff. \n2. Never show boxplots, they obscure the details, if there are 10 simulations, simply show jittered scatterplots or beeswarm plots.\n3. Make all text in figures no less than 1-2 points smaller than the main body fonts, including legends, tick labels, etc.\n4. Use standard methods to show errorbars in tables, eg, show them in parentheses.\n5. Only color things that are significantly different."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1719/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700679272735,
                "cdate": 1700679272735,
                "tmdate": 1700679272735,
                "mdate": 1700679272735,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pF81YNK0QD",
                "forum": "0kWd8SJq8d",
                "replyto": "Y2ZbYFCc3D",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1719/Reviewer_N2Vu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1719/Reviewer_N2Vu"
                ],
                "content": {
                    "title": {
                        "value": "Addressed some concerns"
                    },
                    "comment": {
                        "value": "1. Is not yet satisfactory for me, I desire further re-writes\n2. Analysis is performed, I desire more effective summaries\n3. Satisfied\n4. Better, though the equations in the pseudocode were confusing to me, as I did not understand where they all came from. What would be great would be if all equations that showed up in the pseudocode showed up in the main text with explanations, and then the pseudocode simply pointed to it.  For example, eq. 16 shows up in the main text, and something else shows up in the pseudocode, without an explanation of how to get from eq. 16 to that.  \n\nI will revise your scores accordingly.  That said, I hope that you significantly revise the text, and get another critical pair of eyes on it, because I believe the impact of your work is currently limited by the writing style."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1719/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700683119427,
                "cdate": 1700683119427,
                "tmdate": 1700683119427,
                "mdate": 1700683119427,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]