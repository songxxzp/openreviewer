[
    {
        "title": "SPTNet: An Efficient Alternative Framework for Generalized Category Discovery with Spatial Prompt Tuning"
    },
    {
        "review": {
            "id": "tKqjIZFDiL",
            "forum": "3QLkwU40EE",
            "replyto": "3QLkwU40EE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4541/Reviewer_E8qj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4541/Reviewer_E8qj"
            ],
            "content": {
                "summary": {
                    "value": "- Generalized Category Discovery (GCD) is the problem of leveraging information from known classes in labeled data to automatically identify known and unknown classes in unlabeled data. Authors propose a two stage aporoach, named SPTNet for GCD. \n- SPTNet iteratively optimizes \"model\" parameters of large self-supervised networks and \"data\" parameters (i.e. prompt tuning methods). The former adapts the model to the data while the latter adapts the data to improve the model's capability of identifying categories. \n- Authors propose a novel Spatial Prompt Tuning (SPT) method that enables the model to focus on object parts an show remarkable improvements across several GCD benchmarks with very few additional trainable parameters."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- The idea of optimizing the model and data parameters to improve GCD has some merit especially for discovery in fine-grained datasets. \n- The experiments section supports most of the claims (except a few discussed in weaknesses) made in the paper and show the merit of the proposed approach."
                },
                "weaknesses": {
                    "value": "**Interpretability of SPT**:\n- Authors claim that SPT enables the model to focus on parts of objects, but the way it is designed, there are learnable parameters around each patch. Are the learned parameters, after convergence, sparse in nature? Are there more non-zero values around discriminative regions of objects and zero around patches belonging to background? The SPT setup in its current form is not very interpretable and the experiments certainly do not validate the claim that SPT is better than Bahng et al. because it enables the model to focus on object parts. \nCan this claim be validated/negated if, instead of around a patch, SPT is applied as learnable horizontal or vertical stripes in the image (maintaining the same number of parameters as the original SPTNet). If these experiments achieve the same performance, then the claim made by the authors is not true. I would like to hear the authors' thoughts on this.\n**Ablation experiments**:\n- Table-4 is not presented efficiently in my opinion and needs more attention. From rows 6 and 7, without Global prompting, SPT-S is better than SPT-P. But there is no experiment which uses Global + SPT-S with alternate training in the table. \n- I recommend adding one component at a time to the baseline, makes the table more readable than its current form. I believe most of the experiments are in there and all one would need is to rearrange the rows accordingly. \n- Also the accompanying text to Table-4 has some mistakes which make it harder to read the table. For example. Rows 5,6 compare the effect of alternate training. But in the text, authors explain that these two rows show the benefit of global prompting. Kindly make the table and text consistent and readable to improve reading experience.\n**Alternate training**: \n- In Fig. 3(a), for each k, are epochs adjusted accordingly? I believe this is important because authors report that with smaller k, the model underfits. But what about the experiment of training the model parameters to convergence, followed by training the SPT to convergence (k=1). This experiment is crucial to understand why the alternate training is required. Please provide the details of this experiment. \n**Qualitative results**:\nAuthors show attention maps in Fig. 4b and claim that with SPT, the heads cover the object. I do not see a difference between visualizations of SimGCD and SPTNet to be honest. Instead of showing 4 examples with all the heads, I recommend authors to be more specific and show exactly (by highlighting the region) what they want the readers to focus on. In its current form Fig. 4 does not add anything new to the discussion and can be removed entirely to make space for more important experiments (suggested above)."
                },
                "questions": {
                    "value": "**Suggestions**:\n- The writing of the paper can be improved. Few sections (ablation, Section 3.2) need improvement. \n- Font of text in Fig.1 font is too small and I recommend increasing that. \n- Difference between SPTNet and SPTNet-P is not clear in the main paper. Readers have to look to supplementary to get clarity. Since this is an important part of the contribution, its better authors move Fig. 5 to the main paper. Also provide an example of computing total number of parameters of SPT in the supplementary. \n\n**Questions**:\n- What happens when you train Bahng et. al's Global prompts by increasing the number of parameters to match SPT? I understand its not a whole lot of parameters but how much would that change the performance of using Global prompts?\n- In the paragraph below **Stage 2: Fix p_{1:n}...**, authors present that they use the spatial prompts as augmentations. But by using learned prompts as augmentation, you are asking the network to be invariant to it, how does this help? The intuition behind using this and why would it improve the performance? How much does it improve the performance of contrastive loss? If that is a significant improvement, then that would be a good result for self-supervised literature.\n\n**Please address all the concerns and questions raised above for me to improve my ratings**"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "I do not foresee any immediate ethical concerns with this work."
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4541/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4541/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4541/Reviewer_E8qj"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4541/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698425687724,
            "cdate": 1698425687724,
            "tmdate": 1700696603644,
            "mdate": 1700696603644,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "24LsmT2mKp",
                "forum": "3QLkwU40EE",
                "replyto": "tKqjIZFDiL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4541/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4541/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer #E8qj"
                    },
                    "comment": {
                        "value": "> Authors claim that SPT enables the model to focus on parts of objects, but the way it is designed, there are learnable parameters around each patch. Are the learned parameters, after convergence, sparse in nature? Are there more non-zero values around discriminative regions of objects and zero around patches belonging to background? The SPT setup in its current form is not very interpretable and the experiments certainly do not validate the claim that SPT is better than Bahng et al. because it enables the model to focus on object parts. Can this claim be validated/negated if, instead of around a patch, SPT is applied as learnable horizontal or vertical stripes in the image (maintaining the same number of parameters as the original SPTNet).\n\n\nThanks for the comments. To validate the sparsity of our learned prompts, we visualize and analyze the learned prompts in Appendix E. It can be seen that after learning, the majority of learned prompts are activated, so the learned prompts are not sparse. \n \nAs discussed in General Response -Q1, SPT serves as a learned data augmentation technique while data augmentation is very important for contrastive learning in GCD. Therefore, more activated prompt parameters means a stronger augmentation; while sparsely activated prompt parameters means a weaker augmentation, which is unlikely to enhance the representation learning much.\nThe effectiveness of the learned spatial prompts is also validated by the attention maps, as shown in Fig. 4(b), which demonstrate more diverse attention maps across different heads (top right subfigure). \n\n\nWe follow the suggestion to apply learnable horizontal and vertical stripes separately and the results are shown in Table S2, with the \"width\" of the prompt, $s$, set to 2, leading to 0.2 \"data\" parameters. Note that the $s$ for SPT-Net is set to 1, leading to 0.1M learnable `data\u2019 parameters. If we set $s$ for the stripe veraints, there will be 0.03M learnable parameters. Hence, we choose $s=2$ in this experiment for better capacity of the stripe variants. As can be seen from Table S2, Despite having slightly more parameters than SPTNet, these two variantes are still outperformed by SPTNet, indicating that the improvement is due to the design rather than parameters. \n\nTable S2: Evaluation on SSB. Bold values represent the best results.\n|                             | # Trainable parameters(#model parameters + #data parameters) | All      | Old      | New      |\n|-----------------------------|--------------------------------------------------------------|----------|----------|----------|\n| SimGCD                      | **14.1M+0M**                                                 | 56.1     | 65.5     | 51.5     |\n| SPTNet (horizontal)         | 14.1M+0.102M                                                   | 59.0     | 68.1     | 54.3     |\n| SPTNet (vertical)           | 14.1M+0.102M                                                   | 59.4     | 68.2     | 54.8     |\n| SPTNet (alternate training) | 14.1M+0.100M                                                   | **61.4** | **69.9** | **57.5** |\n\n> Table-4 is not presented efficiently in my opinion and needs more attention. From rows 6 and 7, without Global prompting, SPT-S is better than SPT-P. But there is no experiment which uses Global + SPT-S with alternate training in the table. \n\n\nThanks for the suggestion. We added the experiment for Global + SPT-S and rearranged rows in Table-4 to show the influence of different components step by step in the revised paper. We create Table S3 here by selecting relevant results from Table-4 in the main paper for convenience. The comparison of SPT-P and SPT-S with global prompting reveals that SPT-P outperforms SPT-S, indicating that  SPT-P is also more effective than SPT-S when coupled with the global prompting and alternative training.\n\nTable S3: Evaluation on SSB. Bold values represent the best results.\n|                      | All      | Old      | New      |\n|----------------------|----------|----------|----------|\n| SimGCD               | 56.1     | 65.5     | 51.5     |\n| Global + SPT-S+Alter | 60.9     | 69.0     | 57.3     |\n| Global + SPT-P+Alter | **61.4** | **69.9** | **57.5** |\n\n> In Fig. 3(a), for each k, are epochs adjusted accordingly? I believe this is important because authors report that with smaller k, the model underfits. But what about the experiment of training the model parameters to convergence, followed by training the SPT to convergence (k=1). This experiment is crucial to understand why the alternate training is required. Please provide the details of this experiment. \n\n\nThanks for the suggestions. We have provided the the suggested experiments and analysis in General Response - Q3."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4541/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700584335320,
                "cdate": 1700584335320,
                "tmdate": 1700584335320,
                "mdate": 1700584335320,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sMshpKcDMK",
                "forum": "3QLkwU40EE",
                "replyto": "DrHwcWU3kA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4541/Reviewer_E8qj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4541/Reviewer_E8qj"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors' comments"
                    },
                    "comment": {
                        "value": "I thank the reviewer for the detailed responses and additional experiments. \n- I believe the authors' point of SPT being better than Global prompt because it can focus on object parts was not addressed sufficiently. I recommend authors to support that statement with additional analysis or remove that claim from the paper. \n- Empirically authors show that the learnt \"data\" parameters work better when designed in a grid like fashion than using either horizontal or vertical stripes. I am not sure I fully understand why this is the case. I strongly suggest the authors perform additional analysis or atleast discuss (with supporting analysis) why this works better than other alternate strategies.\n\nI am fully satisfied with the authors' rebuttal and would like to improve my rating."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4541/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700696587040,
                "cdate": 1700696587040,
                "tmdate": 1700696587040,
                "mdate": 1700696587040,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "YKfPHA76rX",
            "forum": "3QLkwU40EE",
            "replyto": "3QLkwU40EE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4541/Reviewer_Pson"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4541/Reviewer_Pson"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses the Generalized Category Discovery (GCD) problem, which involves training on labeled images from seen classes to classify both seen and unseen class images. The authors propose an alternative training method for prompts and model parameters, specifically introducing a spatial prompt tuning method that adds image prompts on a patch-wise basis. Their approach achieves a significant performance improvement of about 10% over existing methods using fewer parameters."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- The method proposed is both simple and highly effective, appearing easy to implement.\n\n- Overall, except for the lack of method reasoning, the text is readable and has high-quality writing.\n\n- Comprehensive evaluations across various datasets and against state-of-the-art methods are conducted, with thorough ablation studies and analyses supporting the proposed method."
                },
                "weaknesses": {
                    "value": "- The paper's main weakness lies in the lack of a detailed explanation of why the proposed method significantly improves GCD performance. While the alternative training of model and prompt, which enables more fine-grained augmentation, is acknowledged, the paper does not thoroughly describe how this relates to the GCD problem and why it leads to better performance. \n\n- The reasoning behind why SPTNet outperforms Global Prompt in GCD is supported only by experimental results and not by direct consideration of object parts, with insufficient evidence contrary to Vaze et al. (2022)'s findings. \n\n- The paper needs analysis of how alternative training induces changes and what benefits it has over end-to-end or completely separate two-stage learning strategies in terms of Expectation-Maximization (EM) learning aspects."
                },
                "questions": {
                    "value": "The paper could strengthen its reasoning and analysis linking the simple strategy proposed to the task of GCD. While it demonstrates a substantial performance increase with a straightforward approach, there is a lack of analysis or reasoning provided in the paper, making it difficult to directly correlate the performance improvements with their causes."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4541/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4541/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4541/Reviewer_Pson"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4541/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699438600992,
            "cdate": 1699438600992,
            "tmdate": 1699636431272,
            "mdate": 1699636431272,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bhTUfiUDTQ",
                "forum": "3QLkwU40EE",
                "replyto": "YKfPHA76rX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4541/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4541/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer #Pson"
                    },
                    "comment": {
                        "value": "> Lack of a detailed explanation of why the proposed method significantly improves GCD performance\u2026The paper does not thoroughly describe how this relates to the GCD problem and why it leads to better performance.\n\nWe thank the reviewer for the comment. Indeed our design is specialized for GCD. Please refer to General Response - Q{1,2,3} for further discussion, more qualitative analysis, and more quantitative study to demonstrate the specialty of our method for GCD. \n\n> The reasoning behind why SPTNet outperforms Global Prompt in GCD is supported only by experimental results and not by direct consideration of object parts, with insufficient evidence contrary to Vaze et al. (2022)'s findings.\n\nThanks for the suggestion. We have followed the suggestion to provide direct consideration of objects parts by qualitative analysis. Please refer to General Response - Q2. \n\n> The paper needs analysis of how alternative training induces changes and what benefits it has over end-to-end or completely separate two-stage learning strategies in terms of Expectation-Maximization (EM) learning aspects.\n\nThanks for the suggestion. We have followed the suggestion to provide additional quantitative analysis in General Response - Q3 to further demonstrate the effectiveness of our EM-inspired alternative learning design.\nAdditionally, in Appendix E and F, we qualitatively demonstrate the impact of alternative training on both data parameters and model parameters. Our results reveal that compared to end-to-end training, alternative training effectively prevents prompt to be zero and thus ensures the diversity of augmentation for contrastive learning. We also provide theoretical analysis from the perspective of EM for the reason using alternative training in Appendix G, which shows that end-to-end training is not equivalent to alternate training.\nMeanwhile, our alternative training design separates the training model parameters and data parameters into different training steps, resulting in reduced training time and a manageable number of learnable parameters in each training step. Consequently, this approach alleviates the training difficulty.\n\n\n> The paper could strengthen its reasoning and analysis linking the simple strategy proposed to the task of GCD. While it demonstrates a substantial performance increase with a straightforward approach, there is a lack of analysis or reasoning provided in the paper, making it difficult to directly correlate the performance improvements with their causes.\n\nWe appreciate the suggestion. We follow this suggestion to include more reasoning and analysis, both empirically and theoretically for GCD. Particularly, we provide more quantitative analysis on the alternative training in General Response - Q3, qualitative analysis on the spatial prompt learning in Appendix E, qualitative analysis on the learned representation in Appendix F, and theoretical analysis in Appendix G. All these consistently demonstrate the effectiveness of our design for GCD. Additionally, the results and discussion in Table S2, S3, and S4 for addressing the comments of Reviewer E8qj further strengthens the reasoning of our design and links to GCD."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4541/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700584120553,
                "cdate": 1700584120553,
                "tmdate": 1700584120553,
                "mdate": 1700584120553,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9WnW4wG8s4",
            "forum": "3QLkwU40EE",
            "replyto": "3QLkwU40EE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4541/Reviewer_bfKG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4541/Reviewer_bfKG"
            ],
            "content": {
                "summary": {
                    "value": "This paper approaches Generalized Category Discovery (GCD) from an alternate perspective, which optimizes data and model parameters by prompt learning and finetuning, respectively. To this end, they propose a visual prompt learning method that learns data representation to better focus on object parts for generalizability. They achieve further performance improvement compared with the previous arts and investigate their approach with sufficient experimental analyses."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is well-organized to present their approach. They first tackle the previous GCD methods and redefine the problem with their own perspective. Then, they show their proposed methods based on their objective. It is easy to follow their objective that they propose spatial prompt tuning for better generalization on both seen and unseen classes.\n- The authors demonstrate the effectiveness of SPNet in their framework with sufficient experimental analysis. Their in-depth analysis shows that their proposed method clearly contributes to performance improvement."
                },
                "weaknesses": {
                    "value": "- Although the authors explain the necessity of an alternative training strategy by referring to the EM algorithm, this reviewer did not reach the reasoning behind this explanation. This reviewer can agree that the authors demonstrate this training strategy empirically. It does not seem to be a specialized method for GCD. This reviewer recommends explaining in more detailed reasoning to choose this strategy if the authors have more reasons than the only empirical observation.\n- Even though the authors investigate the alternative training strategy by ablation study, this reviewer suggests presenting the visualization of representation during training at each switch to show the representation is enhanced as the objective of their approach.\n- As far as this reviewer\u2019s understanding, their framework can be utilized for zero-shot learning tasks such as open-set recognition and open-vocabulary semantic segmentation, which evaluate the model on both seen and unseen classes, not only GCD. This reviewer agrees that their results show efficiency and efficacy. This reviewer believes that the experiment results on the closely related task strengthen their study."
                },
                "questions": {
                    "value": "The questions are naturally raised in the weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4541/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4541/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4541/Reviewer_bfKG"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4541/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699530182144,
            "cdate": 1699530182144,
            "tmdate": 1699636431161,
            "mdate": 1699636431161,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qE76WsygEE",
                "forum": "3QLkwU40EE",
                "replyto": "9WnW4wG8s4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4541/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4541/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer #bfKG"
                    },
                    "comment": {
                        "value": ">  It does not seem to be a specialized method for GCD. This reviewer recommends explaining in more detailed reasoning to choose this strategy\n\n\nWe thank the reviewer for the comment. Indeed our design is specialized for GCD. Please refer to General Response - Q{1,2,3} for further discussion, more qualitative analysis, and more quantitative study to demonstrate the specialty of our method for GCD\n\n\n> Presenting the visualization of representation during training at each switch to show the representation is enhanced as the objective of their approach.\n\nThanks for the suggestion. We follow the suggestion to conduct visualization to verify the effectiveness of our alternate training strategy for representation learning on CIFAR-10 dataset (Please refer to the newly added Appendix F). Specifically, we present the model representations at the $20^{th}$, $100^{th}$, $200^{th}$, and $400^{th}$ epochs before switching . With the increase of  epoch, we observe clearer boundaries between semantic categories and increased compactness within each cluster. This confirms that our alternate training strategy leads to more robust representation.\nIn addition, we provide more discussion in General Response -Q1, more qualitative analysis in General Response -Q2, and more quantitative analysis in General Response -Q3.\n\n> Their framework can be utilized for zero-shot learning tasks such as open-set recognition and open-vocabulary semantic segmentation, which evaluate the model on both seen and unseen classes, not only GCD. This reviewer agrees that their results show efficiency and efficacy. This reviewer believes that the experiment results on the closely related task strengthen their study.\n\nWe appreciate the reviewer's recognition of the efficiency and efficacy of our framework and the suggestions on potential applications of our framework beyond GCD. \nIndeed, as discussed and analyzed in General Response - Q{1,2,3}, the strengths of our methods are designed on purposely to favor the GCD problem. Other prompt tuning approaches (Jia et al., 2022; Bahng et al., 2022) have been developed to enhance fully supervised learning. However, our patch-based design is to realize the unique ``part transfer\u2019\u2019 insight for GCD. We will consider further exploring the other possible applications of our design in the future work."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4541/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700584047149,
                "cdate": 1700584047149,
                "tmdate": 1700584047149,
                "mdate": 1700584047149,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]