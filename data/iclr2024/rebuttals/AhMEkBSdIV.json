[
    {
        "title": "LCA-on-the-Line: Benchmarking Out-of-Distribution Generalization with Class Taxonomies"
    },
    {
        "review": {
            "id": "3XPvPdZSY3",
            "forum": "AhMEkBSdIV",
            "replyto": "AhMEkBSdIV",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4697/Reviewer_CuPJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4697/Reviewer_CuPJ"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on addressing the challenge of assessing model generalization under out-of-distribution conditions. They reintroduce the Least Common Ancestor (LCA) distance. Particularly, they utilize the LCA to measure the taxonomic distance between labels and predictions, presenting it as a benchmark for model generalization. In the experiments, the proposed method is evaluated on multiple datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "It is interesting to address the challenge of assessing model generalization under out-of-distribution conditions."
                },
                "weaknesses": {
                    "value": "1. The Introduction Section is not clear. The authors indicate that most methods involve modeling correlations with in-domain accuracy or agreement. And many studies evaluate generalization on OOD datasets that feature limited visual shifts. These interpretations are very unclear. I am not clear the concrete meaning. I recommend the authors modify their paper carefully.\n\n2. The authors indicate that to address the analyzed issues, they introduce a method to benchmark model generalization, i.e., using the taxonomy loss. Firstly, the authors do not interpret whether the research is meaningful clearly. Secondly, the authors do not sufficiently introduce the advantages of the taxonomy loss. I recommend the authors draw a figure to clearly describe the motivation.\n\n3. In Table 1, the evaluated methods are somewhat old. The authors should verify the effectiveness of the proposed method on more state-of-the-art methods, e.g., the works from CVPR 2023, ICLR 2023. Meanwhile, the experiments are somewhat unclear. The authors only evaluate the classification performance. I recommend the authors evaluate the proposed method on other tasks, e.g., object detection and semantic segmentation. Finally, for Fig. 1, the authors should give more interpretations."
                },
                "questions": {
                    "value": "See Weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4697/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697530643166,
            "cdate": 1697530643166,
            "tmdate": 1699636451281,
            "mdate": 1699636451281,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1nbDjtmcSW",
                "forum": "AhMEkBSdIV",
                "replyto": "3XPvPdZSY3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4697/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4697/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thanks reviewer for appreciate the interestingness of our paper and raising concerns about the clarity of the presentation, motivation and relevancy toward other field. \n\n**Q: The Introduction Section is not clear, especially about the description of \u2018most methods involve modeling correlations with in-domain accuracy or agreement. And many studies evaluate generalization on OOD datasets that feature limited visual shifts.\u2019 These interpretations are very unclear. I am not clear the concrete meaning.**\n\n- Please let us know if there\u2019s any other place remain unclear and we are happy to take the advice to rephrase those sentences in paper at the end of the discussion!\n\n- We want to echo that our main motivation is to establish \u2018a unified benchmarking metric robustly applicable across both VM and VLM, to assess model generalization (use in domain measurement to predict model\u2019s OOD performance). \n\n- **most methods involve modeling correlations with in-domain accuracy or agreement.** -> \nPrior work, notable, \u2018accuracy-on-the-line\u2019[1] and \u2018agreement-on-the-line\u2019[2], are two highly influenced papers in the field. The former is the first work to establish a strong baseline that the models with better ID accuracy are likely to have better OOD accuracy, while the latter adopted model ensemble and argued that OOD agreement between the predictions of any two pairs of neural networks shows linear correlation with their ID agreement. Those two works setup important base tune for followup works. However, those two work did not explicitly evaluated models of different modality(VM & VLM) in comparison. Our results shows that those two well-acknowledged measurement are less robust when comparing models under different settings.\n\n- **many studies evaluate generalization on OOD datasets that feature limited visual shifts.** -> Many prior work( as referred in the introduction), where they found strong linear relationship between ID and OOD accuracy, are adopting OOD dataset that are visually similar to ID dataset, for instance, ImageNet-v2 or ImageNet-C. Our work argue that those dataset, did\u2019t reflect more realistic distribution shrift, make then more like \u2018another pool of ID dataset rather than realistic OOD dataset\u2019(please also refer to section 4 for discussion.)  We instead focus on a more realistic distribution shift involving semantic concept shrift(like cartoon Dog and animal Dog) or orientation variance(like fallen chair in ObjectNet). We shows that LCA as a benchmark could predict model\u2019s generalization on those realistic OOD dataset across both VM and VLMs..\n\n**Q: Firstly, the authors do not interpret whether the research is meaningful clearly. Secondly, the authors do not sufficiently introduce the advantages of the taxonomy loss.**\n\n- We thanks reviewer for raising concerns of our motivation. We would like to echo here to the main motivation of our work. \n- 1. Since the early year of ImageNet (2011) datasets,  LCA distance was proposed but largely dismissed as it was widely believed to follow the same ordering as Top 1 accuracy. This metric have been revisit many times in follow-up papers of hierarchical classification but the concept that \u2018LCA don\u2019t provide much information besides Top1 accuracy\u2019 are still largely accepted. In our work, we want to challenge this prevailing notion and shows that LCA could provide strong signal to model\u2019s feature learning in the era of Vision Language Model. This could provide some pointer of why VLM with lower ID accuracy are having a higher OOD compared to SOTA VM model.\n- 2. We then shows how LCA could solve the problem that haven\u2019t been solved in prior work. In summary, prior work predicting model generalization are using 1.(VLM or VM) and 2.(visually similar dataset like ImageNet-v2 as OOD for ImageNet). This even include two highly influenced work [1][2]. We targeting on a more realistic setup of 1(VLM and VM) and 2. Various realistic OOD datasets like ImageNet-R/S/A/ObjectNet. \n- 3. We then provide some exploration on how\u2018LCA-on-the-line\u2019 could be used to improve model\u2019s generalization by applying taxonomy loss. This is introduced in 3.4 ENHANCING GENERALIZATION THROUGH CLASS TAXONOMY ALIGNMENT. We consider applying taxonomy loss similar to \u2018alignment to human knowledge\u2019 during model training.\n- For adding a figure indicating motivation as reviewer suggestion, Figure 2 is well motivated by our main motivation."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4697/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699848951043,
                "cdate": 1699848951043,
                "tmdate": 1699848951043,
                "mdate": 1699848951043,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "p2bnpzizOE",
                "forum": "AhMEkBSdIV",
                "replyto": "3XPvPdZSY3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4697/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4697/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q: In Table 1, the evaluated methods are somewhat old. The authors should verify the effectiveness of the proposed method on more state-of-the-art methods, e.g., the works from CVPR 2023, ICLR 2023.**  \n\n- We want to point out that in our work, the main motivation is to identify a problem for which prior arts is suffering catastrophically( correlation of [1] drop from 0.9->0.01 in Table2) , and how LCA could still be robust under this settings. To the best of our knowledge, the only work that trying to address similar problem is one concurrent work, (Shi et al., 2023)[3](NeurIPS 2023), which argued to use multiple OOD test set as model generalization indicator. We have discussed this work in the introduction for sharing similar motivation.\n\n**Q: The authors only evaluate the classification performance. I recommend the authors evaluate the proposed method on other tasks, e.g., object detection and semantic segmentation.** \n\n- We thanks reviewer for suggesting promising investigation towards other field. We want to point that object detection and semantic segmentation, specifically, involved both localization and classification uncertainty. We believe the discussion of localization uncertainty are out of scope of this paper and could become a potential impactful future work that require full investigation. LCA mainly deal with semantic understanding of feature learning thus only related to classification uncertainty. We thanks reviewers again for the suggestion and will include this in the future work section. \n\n**Q: For Fig. 1, the authors should give more interpretations.**\n- We thanks reviewer for identifying clarity of Fig. 1. We will make sure to rephrase it to make it easier to understand. In a high level, Fig 1 shows that prior art fail to maintain a straight correlation line when involved both VM and VLM, while LCA as measurement achieved a straight line on ImageNet S/R/A/O. This is aligning with numeric value in table 2. Please feel free to provide more suggestion where you feel appropriate!\n\n[1] John P Miller, Rohan Taori, Aditi Raghunathan, Shiori Sagawa, Pang Wei Koh, Vaishaal Shankar, Percy Liang, Yair Carmon, and Ludwig Schmidt. Accuracy on the line: on the strong correlation between out-of-distribution and in-distribution generalization. In International Conference on Machine Learning, pp. 7721\u20137735. PMLR, 2021.\n\n[2] Christina Baek, Yiding Jiang, Aditi Raghunathan, and J Zico Kolter. Agreement-on-the-line: Predicting the performance of neural networks under distribution shift. Advances in Neural Information Processing Systems, 35:19274\u201319289, 2022.\n\n[3] Zhouxing Shi, Nicholas Carlini, Ananth Balashankar, Ludwig Schmidt, Cho-Jui Hsieh, Alex Beutel, and Yao Qin. Effective robustness against natural distribution shifts for models with different training data. arXiv preprint arXiv:2302.01381, 2023."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4697/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699848962544,
                "cdate": 1699848962544,
                "tmdate": 1699851009711,
                "mdate": 1699851009711,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pM9aCrHeJy",
                "forum": "AhMEkBSdIV",
                "replyto": "3XPvPdZSY3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4697/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4697/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer\nWe had modified our paper in detail, especially on introduction based on your suggestions. We have also include 7 more plots to improve readability. Please refer to our updated draft for detail. Please also refer to general comment we have for all reviewers, which include summary of our change and detail summary of our work. If you think the presentation have been improved and appreciate our change in the updated submission, please raise rating score. We understand it's approaching to the end of reviewer-author discussion, please review our updates for your decision in the AC-reviewer discussion stage. Thank you!"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4697/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737107481,
                "cdate": 1700737107481,
                "tmdate": 1700737242844,
                "mdate": 1700737242844,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "HGpIOapkaD",
            "forum": "AhMEkBSdIV",
            "replyto": "AhMEkBSdIV",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4697/Reviewer_r8af"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4697/Reviewer_r8af"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the Least Common Ancestor (LCA) distance via the WordNet hierarchy is employed to measure the taxonomic distance between labels and predictions, utilizing it as a benchmark for model generalization. Extensive experiments are performed on model evaluation, including vision-only and vision-language models on natural distribution shift datasets. A strong linear correlation is observed between in-domain ImageNet LCA scores and out-of-domain (OOD) Top1 performance across many variants of ImageNet."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "A thorough experimental analysis of the relationship between Out-of-Distribution (OOD) detection performance and Least Common Ancestor (LCA) distance for image classifiers is provided in this paper. The following are key strengths of the work:\n\n(1) Experiments are conducted on a diverse set of neural network architectures, including ResNet, VGG, EfficientNet, Vision Transformer (ViT), and Vision-Language Models (VLMs), enabling conclusions that potentially generalize across problem domains. The rigor and comprehensiveness of the methodology are underscored by the scale of experiments, involving up to 75 network variants.\n\n(2) A major point about this submission is the analysis that demonstrates a correlation between OOD detection performance and LCA distances in the classifier. For instance, it is quantitatively shown how images from OOD datasets with more distant LCA relationships to the training data tend to be easier to detect as anomalies. The intuitive justification provided is that greater separation between the semantics of the origin dataset and OOD dataset in the hierarchical LCA structure leads to more separable distributions."
                },
                "weaknesses": {
                    "value": "Major:\n\n(1) The paper does not evaluate multiple OOD scoring methods like energy scores[1], ODIN[2], Mahalanobis distance[3], and ReAct[4], which would have provided insights into the validity of the key conclusions across different anomaly scoring approaches. The interaction between the choice of scoring method and LCA distance remains unclear. Understanding how these scoring methods affect OOD performance from the perspective of the LCA distance is important. It should be noted that the calculation of this LCA distance is limited to variants of ImageNet considering the WordNet hierarchy used.\n\n(2) The claim is made that the findings offer \"invaluable insights and actionable techniques\" to enhance robustness and generalization. However, no concrete solutions leveraging the LCA distance are proposed or analyzed. Further theoretical or empirical analysis that establishes a connection between these insights and improved generalization would be beneficial.\n\n\nMinor:\n\n\u201cGiven two classes, y (the ground truth class) and y\u2032, we define the LCA distance according to (Bertinetto et al., 2020) as lcad(y\u2032, y) := f(y) \u2212 f(lca(y, y\u2032), where f(y) \u2265 f(lca(y, y\u2032) and\nlca((y\u2032, y) denotes\u2026\u201d All formulations lose the right brackets.\n\n\u201cAs highlighted in Fig 1 (indicated in red), when adhering to \u2019accuracy on the line\u2019,\u201d Wrong quotes.\n\nIn summary, the rigorous experiments and novel analysis of OOD detection vs. LCA distance are valuable contributions, but additional evaluation of alternative scoring methods and practical applications of the findings could further strengthen the work.\n\n\n[1] Liu, Weitang, et al. \"Energy-based out-of-distribution detection.\" Advances in neural information processing systems 33 (2020): 21464-21475.\n\n[2] Liang, Shiyu, Yixuan Li, and Rayadurgam Srikant. \"Enhancing the reliability of out-of-distribution image detection in neural networks.\" ICLR 2018.\n\n[3] Ren, Jie, et al. \"A simple fix to mahalanobis distance for improving near-ood detection.\" arXiv preprint arXiv:2106.09022 (2021).\n\n[4] Sun, Yiyou, Chuan Guo, and Yixuan Li. \"React: Out-of-distribution detection with rectified activations.\" Advances in Neural Information Processing Systems 34 (2021): 144-157."
                },
                "questions": {
                    "value": "Please see the weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4697/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698770337719,
            "cdate": 1698770337719,
            "tmdate": 1699636451208,
            "mdate": 1699636451208,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NYr2nIdjh8",
                "forum": "AhMEkBSdIV",
                "replyto": "HGpIOapkaD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4697/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4697/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thanks reviewer for appreciating our rigor and comprehensive experiment. \n\nFor the (2) in strengths, we believe there\u2019s some misunderstandings about our experiment setup. **Our paper didn\u2019t try to target OOD detection or anomalies detection(separate ID data from and OOD data, binary classification), but to predict whether a model could perform better on OOD dataset by only looking at its in-domain measurement**(correlation of model top1 accuracy between ID and OOD). There\u2019s a difference in the problem setup. We could like to point reviewer to Table 2 for reference. \n- **it is quantitatively shown how images from OOD datasets with more distant LCA relationships to the training data tend to be easier to detect as anomalies.** -> We actually trying to show model that have a lower LCA distance on ID will have a higher top 1 accuracy on OOD. \n\n- **The intuitive justification provided is that greater separation between the semantics of the origin dataset and OOD dataset in the hierarchical LCA structure leads to more separable distributions.** -> Please refer to our answer below about assumption. \n\n**Q: Understanding how these scoring methods affect OOD performance from the perspective of the LCA distance is important. It should be noted that the calculation of this LCA distance is limited to variants of ImageNet considering the WordNet hierarchy used.**: \n\n- We thanks reviewer for point to scoring function. We will make sure to cite those work in our revision. Here\u2019s our interpretation of suggested work and please feel free to suggest more!\n\n- The suggested works are targeting out-of-distribution detection, which trying to tell which data are OOD and which data have been seemed during training. This is a different task from our paper. Pleaser refer to answer above.\n- Different from our focus, the main targets of those methods is to **separate feature between ID and OOD data**, which our focus is more detail, to identify within ID feature, how does model learned to separate class semantically? Under the assumption that **ID and OOD data should lands on a share feature distribution, rather than two separate ones**. Assuming two separate distribution is what being assumed in OOD detection. However, we still believe this is an interesting difference worth to mention in the discussion as related work and will make sure to include citation of those work.\n\n**Q: It should be noted that the calculation of this LCA distance is limited to variants of ImageNet considering the WordNet hierarchy used.**\n- We want to point reviewer to section 3.4. In order to extends our metric beyond ImageNet and WordNet, we proposed to infer pseudo latent class taxonomy using K-Means Clustering as a replacement to replying on WordNet hierarchy. Our result in table 4 shows that our latent taxonomy are equally robust to the experiment in Table 2 among 75 different latent taxonomy. \n\n**Q: However, no concrete solutions leveraging the LCA distance are proposed or analyzed.**\n- We want to point reviewer to section 3.4 and F.1 in appendix. In section 4 we have adopt our idea LCA-on-the-line as a taxonomy loss,  and explore how it could used to improve model\u2019s generalization. Similarly in F.1, we shows that how this idea could be used on prompting. We have also analyzed the underlying connections between why LCA are suitable generalization metric in 3.3. Please feel free to ask more question where you consider less clear.\n\n\n**Q: Minor error:**\n- Thanks for identifying typo in brackets, we will update accordingly.\n- For \u201cAs highlighted in Fig 1 (indicated in red), when adhering to \u2019accuracy on the line\u2019,\u201d Wrong quotes.\u201d, sorry we don\u2019t understand. Could you provide more detail on why this is wrong quotes? Thanks!"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4697/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699848902895,
                "cdate": 1699848902895,
                "tmdate": 1699848902895,
                "mdate": 1699848902895,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "R3CACSE3lh",
                "forum": "AhMEkBSdIV",
                "replyto": "HGpIOapkaD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4697/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4697/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4697/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4697/Reviewers",
                    "ICLR.cc/2024/Conference/Submission4697/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4697/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Citation updated in introduction."
                    },
                    "comment": {
                        "value": "Dear reviewer\nWe have updated our submission by including reference of works in OOD detection and proper citation in the introduction. Please let us know with other questions\uff01"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4697/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700530880711,
                "cdate": 1700530880711,
                "tmdate": 1700530880711,
                "mdate": 1700530880711,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "RCxriyCuW5",
            "forum": "AhMEkBSdIV",
            "replyto": "AhMEkBSdIV",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4697/Reviewer_5fCB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4697/Reviewer_5fCB"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on evaluating the Out-of-Distribution (OOD) generalization by using Least Common Ancestor (LCA) distance based on the WordNet hierarchy. LCA measures the taxonomic distance between labels and predictions, and the paper shows that LCA is a better measure of OOD generalization than top-1 accuracy (when both LCA and top-1 accuracy are computed on in-domain data). Intuitively, LCA is able to better evaluate how well a model has learned semantic knowledge of the classes (since lower LCA indicates that the model\u2019s wrong predictions are semantically closer to the true class). This enables LCA to be a better measure of OOD performance compared to top-1 accuracy which only considers whether the prediction is correct or not. Specifically, they test 75 different models (including both vision models and vision-language models) and find a linear correlation between ImageNet LCA and OOD accuracy across 4 standard ImageNet-OOD datasets. They also use the pairwise LCA between classes as soft labels for linear probing over pretrained models, and find that OOD performance can be improved at the cost of in-domain performance."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "* The idea of using LCA for evaluating OOD generalization is simple, intuitive, well-motivated, and effective.\n\n* The paper is fairly well-written (except some typos which can be fixed).\n\n* The experimental analyses are quite extensive. The contributions of this work will likely be quite significant for industry applications where predicting OOD performance ahead of deployment tends to be important."
                },
                "weaknesses": {
                    "value": "* Explanation of LCA is complicated\n    * A visual illustration of LCA computation with a small part of the WordNet hierarchy and 2-3 example pairs of classes would help readers to quickly and better understand the LCA distance measure.\n    * Maybe a figure in the main paper like Fig. 3 (in Suppl.) but with some actual classes and example LCA values for a few pairs of classes.\n\n* Fig. 1 is very difficult to read and understand\n    * The legend is too small. It would be better to show only top-1 here (first row) with larger font sizes (match caption size, roughly) and show the full figure in supplementary.\n\n* Implementation of inferred class taxonomy is difficult to understand\n    * It is unclear what \"establishing the cluster level where both classes share the same cluster as the height of LCA\" means. Please clarify and try to simplify it.\n    * A figure illustrating the method would be ideal to help readers understand it better."
                },
                "questions": {
                    "value": "* Please see the weaknesses section.\n\n* Minor comments\n    * Abstract (second paragraph) has a typo: \u201cBeside\u201d \u2192 \u201cBesides\u201d.\n    * Introduction (second paragraph): \u201ceffective robustness(Taori et al., 2020)\u201d space needed between robustness and the citation.\n    * Above the contributions list, typo: \u201cin measure model\u2019s semantic awareness\u201d \u2192 \u201cin measuring a model\u2019s semantic awareness\u201d.\n    * Sec. 2 (second paragraph): extra or less brackets in three equations in this paragraph.\n    * In many places in the paper, quotes are used incorrectly in LaTeX. Please use ` ' in LaTeX (i.e. backtick and quote instead of both quotes).\n    * Paragraph below Table 3 has a typo: \u201cAs illustrated in Table3\u201d \u2192 \u201cAs illustrated in Table 3\u201d, i.e. add space.\n    * Sec. 3.3 (last paragraph) has a typo: \u201cnatural image(ImageNet)\u201d \u2192 \u201cnatural image (ImageNet)\u201d, i.e. add space."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4697/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4697/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4697/Reviewer_5fCB"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4697/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698977555937,
            "cdate": 1698977555937,
            "tmdate": 1699636451139,
            "mdate": 1699636451139,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fZgBfIVRRU",
                "forum": "AhMEkBSdIV",
                "replyto": "RCxriyCuW5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4697/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4697/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We highly appreciate reviewer for identifying our work as \u2018simple, intuitive, well-motivated, and effective\u2019, well-written, extensiveness of our work and potential significant impact. We also thanks reviewer for proving detail for improvement.\n\n**Q: Explanation of LCA is complicated**\n- Thanks for the suggestion! We will point reader more directly to plot in appendix, and provide an actual class example in appendix plot. \nA simple intuition would be, \nanimal have children of cat and dog;\nDog have children of chihuahua and Husky;\nEtc.\n\n**Q: Fig. 1 is very difficult to read and understand**\n- Thanks for identify the lack of legibility of Fig1. We have included original png of Figure 1 in the supplementary zip folder for reference. We will also make sure to enlarge the text in our revision. \n\n**Q: Implementation of inferred class taxonomy is difficult to understand**\n- Thanks for the suggestion, we will make sure to include a algorithm pseudocode in our revision. \n- **establishing the cluster level where both classes share the same cluster as the height of LCA** -> Similar to idea of LCA in FIgure3 in appendix, we form a hierarchical tree by using different number of clustering in each layers. For instance, in level 1 we have all the class, in level 2 we have two tree node(result from K-mean of 2 cluster), in level 3 we have 4 tree node(result from K-mean of 4 cluster), etc. \n\n**Q: Minor typo/grammar issue**\n- We appreciate for noticing those minor issue and we have corrected them all in the revision."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4697/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699848666009,
                "cdate": 1699848666009,
                "tmdate": 1699848675828,
                "mdate": 1699848675828,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "X8b6ElIRI8",
                "forum": "AhMEkBSdIV",
                "replyto": "RCxriyCuW5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4697/Reviewer_5fCB"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4697/Reviewer_5fCB"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "I thank the authors for their efforts during the discussion period. The response has mostly addressed my concerns and I keep my already positive score of 8: accept, good paper."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4697/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700707756141,
                "cdate": 1700707756141,
                "tmdate": 1700707774805,
                "mdate": 1700707774805,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oGJplxhsdq",
                "forum": "AhMEkBSdIV",
                "replyto": "RCxriyCuW5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4697/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4697/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are glad that our reply had addressed reviewer\u2019s concern! We hope reviewer also consider raising score on presentation if you believe our revision have improved the clarity of paper presentation.\nThanks!"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4697/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700708670425,
                "cdate": 1700708670425,
                "tmdate": 1700708744632,
                "mdate": 1700708744632,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]