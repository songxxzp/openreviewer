[
    {
        "title": "Language as Kernels"
    },
    {
        "review": {
            "id": "gwd8Wn8GVc",
            "forum": "QBlegfNZNE",
            "replyto": "QBlegfNZNE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission655/Reviewer_hAMM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission655/Reviewer_hAMM"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes an efficient kernel function for large language models and prompt engineering, to speed up the generation process. The proposed methods are useful for resource-constrained environments."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper is well-written and well-organized.\n- Using kernel functions for Large Language models is a pretty interesting topic."
                },
                "weaknesses": {
                    "value": "- Since it is a rapidly growing area, comparing it with just one \"prompting\" baseline in 2020 is pretty unfair. I hope the author could introduce more recent baselines for comparison.\n- I do not see any discussion or experiment in terms of a resource-constrained environment, where the paper claims to be beneficial with the proposed method.\n- The necessity for introducing Theorem 3.1 and 3.2. The two theorems are not that relevant to the main contribution of this work. The concepts introduced in the two theorems are also not well explained."
                },
                "questions": {
                    "value": "Could you also list more recent baselines to enrich Table 2?\nCould you consider adding an experiment on a resource-constrained environment, like a no-GPU laptop, or GPU with only 4GB graphic memory?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission655/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698021254113,
            "cdate": 1698021254113,
            "tmdate": 1699635993013,
            "mdate": 1699635993013,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "2DZUT9UGsX",
            "forum": "QBlegfNZNE",
            "replyto": "QBlegfNZNE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission655/Reviewer_cZbU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission655/Reviewer_cZbU"
            ],
            "content": {
                "summary": {
                    "value": "This paper presented `Support Vector Generation` which leverages generative capability of LLMs to better utilize kernel machines for thrift computation. This paper also mathematically demonstrated equivalence of zero-shot learning and kernel machines so that this method can be used for zero-shot task data argumentation. Experiments on GLUE showed comparable or better performance on multiple downstream tasks compared to prompting methods, and runs pretty fast on CPU."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper introduces a novel method for zero-shot learning, referred to as Support Vector Generation. It harnesses the generative capabilities of Large Language Models (LLMs) to enhance kernel machines, achieving highly accurate results while maintaining low computational resource requirements. The experiments conducted across multiple tasks in the GLUE Benchmark show promising results, and the paper also provides insights into the computational complexity, highlighting the effectiveness of this approach. Overall, this innovation has the potential to significantly improve the computational efficiency of zero-shot learning."
                },
                "weaknesses": {
                    "value": "There is still uncertainty regarding whether this method can be advantageous in scenarios beyond zero-shot learning or other specific tasks. While the authors assert the computational efficiency of their approach, no direct numerical comparisons are provided to substantiate this claim. Additionally, as a data augmentation method, it's not explicitly clarified whether the improved performance primarily stems from the data sampling process or the kernel machine technique itself. Further clarification on these aspects would enhance the paper's findings and their broader applicability."
                },
                "questions": {
                    "value": "1. Can this method be extended outside zero-shot learning?\n2. Can you please explain with a more concrete example how SVG improved performance based on LLM?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission655/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698817708092,
            "cdate": 1698817708092,
            "tmdate": 1699635992925,
            "mdate": 1699635992925,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "KQ5zC3LZRa",
            "forum": "QBlegfNZNE",
            "replyto": "QBlegfNZNE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission655/Reviewer_9mKW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission655/Reviewer_9mKW"
            ],
            "content": {
                "summary": {
                    "value": "The study explores the application of kernel methods to transformer-based embeddings. The approach involves utilizing these embeddings to train a kernel machine for (potentially) a new task, employing an iterative process that retains only the \"support vectors\" instead of the entire dataset. However, they claimed they mathematically showed kernel methods are zero-shot learners. (quote: \"mathematical equivalence of zero-shot learning and kernel machines\"!!)"
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. The iterative method for selecting support vectors using a probabilistic approach seems interesting. However, the current description lacks sufficient detail to fully understand the specifics of the algorithm."
                },
                "weaknesses": {
                    "value": "The paper is not understandable. I had a very hard time to follow the main message and the claims. for instance:\n\n1. what is the main message of the paper? how is this connected to zero-shot learning.\n2. Theorem 3.1 makes no sense. I might be missing something, but are you trying to prove representer theorem? What is the optimization over? any possible f? or you mean f in the Hilbert space corresponding to K? even in the proof, I saw that you have shown K is positive definite but how is K even related to the optimization problem in equation (3)?!!\n3. The main algorithm (SVG) is very vague. What is \\theta? what is p_{\\theta}? what is q_{\\theta}? why non of them formally introduced? Why A is a good criteria for accepting?!\n\nI cannot trust the experiment result or any part of this paper."
                },
                "questions": {
                    "value": "See weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission655/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission655/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission655/Reviewer_9mKW"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission655/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698862180399,
            "cdate": 1698862180399,
            "tmdate": 1699635992846,
            "mdate": 1699635992846,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Fo7VFLvRr9",
                "forum": "QBlegfNZNE",
                "replyto": "KQ5zC3LZRa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission655/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission655/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Are you trolling?"
                    },
                    "comment": {
                        "value": "Thank you for your review.\n\nFirstly, in my experience, a rating of 1 is given to papers that are underpaginated or not well formatted. This paper has taken a considerable amount of time and money, and experiments have been carried out. In your review, it seems to me that you have only highlighted minor errors and I can see no rational reason to give it the lowest possible rating. Of course, we take comments in common with other reviewers seriously, but the wording of the content appears to be trolling, and depending on the subsequent response, we may consider reporting it to the ACs.\n\nSecondly, you state that you do not understand the content of Algorithm 1, but are you not familiar with Metropolis Hastings, which has been used in a lot of web research and would also contribute to the LLM community. If you say you don't understand it, it is likely that you simply don't have enough expertise to understand the content, so please take action, such as just lowering your confidence score.\n\nThirdly, although we would not de-anonymise, some of the authors' team have a track record of getting accepted by ICLR as a single author, and they should be writing with an awareness of their contribution to the community. Although it is slightly grey to reveal the authors' attributes, we have made the disclosure because we are surprised by the very subjective and disrespectful comments. We consider this to be an acceptable level of disclosure, as we have recently been publishing some of our work on Arxiv ahead of time.\n\nIn any case, whatever the reason, we are sorry for the confusion itself. The authors, as well as the reviewers, are carrying out the submission free of charge. We hope that we can work together to develop the ML community."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission655/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699842105163,
                "cdate": 1699842105163,
                "tmdate": 1699842105163,
                "mdate": 1699842105163,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "nlggtEqWkw",
            "forum": "QBlegfNZNE",
            "replyto": "QBlegfNZNE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission655/Reviewer_USwM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission655/Reviewer_USwM"
            ],
            "content": {
                "summary": {
                    "value": "In order to relieve the computational resource requirement of learning with LLMs, this paper proposes a support vector generation (SVG) method on the embeddings produced by LLMs. This approach can also solve some classification tasks in an zero-shot manner. For example, in this framework, the sentiment prediction task can be conducted by $\\phi(x)^T [\\phi(\"positive\") - \\phi(\"negative\")]$, where $x$ is the input text, and $\\phi(\\cdot)$ is the embedding produced by the LLM. The authors claim this method is able to work on CPUs."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "I don't see clear strengths on this paper."
                },
                "weaknesses": {
                    "value": "* The overall story and the problem in this paper are similar to a bunch of existing work on zero-shot learning with pretrained BERT and other LLMs, e.g., [1][2], and so forth, but they are not sufficiently discussed and compared with the proposed approach.\n* In the experiment, the only baseline is adapting a few-shot learning approach into the zero-shot setting, without any zero-shot approaches that are related more closely, e.g. such as [1][2] mentioned in the last point. \n* The comparison in the experiment looks unfair, the baseline \"prompting\" uses RoBERTa as its backbone LLM, while the proposed method uses OpenAI cloud API, which should be much stronger than RoBERTa. \n* The proposed method doesn't solve the problem as it claims. This paper is motivated by alleviating the computing resource constraints, but the claim of \"working on CPUs\" is actually achieved by using the OpenAI webAPI. This is not a contribution of the proposed method. Instead, the bottleneck of computing is producing the embedding from the backbone LLM. If the embeddings from WebAPIs are already there, a normal linear layer can be also \"on CPUs only\".\n\n\n[1] Meng, Yu, et al. \"Text classification using label names only: A language model self-training approach.\", EMNLP 2020.\\\n[2] Zhao, Xuandong, et al. \"Pre-trained language models can be fully zero-shot learners.\" ACL 2023."
                },
                "questions": {
                    "value": "From Table 2, on MNLI, your approach doesn't outperform the baseline significantly. Is this because your approach only work well on binary classification? How is your performance on tasks with more labels, e.g., SST-5, SNLI, TREC, etc.?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission655/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698903930765,
            "cdate": 1698903930765,
            "tmdate": 1699635992752,
            "mdate": 1699635992752,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]