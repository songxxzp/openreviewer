[
    {
        "title": "High-dimensional Bayesian Optimization via Semi-supervised Learning with Optimized Unlabeled Data Sampling"
    },
    {
        "review": {
            "id": "Y1EkUHj1wH",
            "forum": "CY9f6G89Rv",
            "replyto": "CY9f6G89Rv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4183/Reviewer_r1KM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4183/Reviewer_r1KM"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes TSBO, a Bayesian optimization algorithm that employs semi-supervised learning through a teacher-student model which generates optimized synthetic data, which is incorporated into  a conventional surrogate model. The aim is to improve surrogate model generalization, and thereby enhance sample efficiency. The semi-supervised learning process involves a bi-level optimization scheme, which iteratively optimizes the mariginal log likelihood of synthetic data of the student and a weighted sum of. Results show improved performance on three chemical design tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "__Novel idea:__ Self-supervised learning has not thoroughly been explored in a BO context, and so the proposed idea explores a novel niche.\n\n__Addressing model accuracy:__ Addressing BO efficiency from the standpoint of producing a more accurate surrogate is a good approach - one that I believe deserves attention.\n\n__Multiple relevant ablations:__ With a large number of components to the algorithm, substantial resources have been dedicated towards ablations.\n\n__Figure 1:__ This effectively communicates the proposed method in a clear and pedagogical manner."
                },
                "weaknesses": {
                    "value": "While the proposed approach is interesting, I believe that there is a substantial amount of complexity that is currently unjustified. Moreover, little is offered in terms of intuition as to why the involved components are jointly able to produce a more accurate surrogate model. I believe the paper has potential, but these outstanding issues would have to be addressed in a satisfactory manner for the paper to be accepted. Specifically,\n\n(To avoid confusion, I will denote the BO surrogate as the BO GP and the student as the SGP)\n\n### __1. The complexity of the method:__ \nIn addition to the Vanilla GP, there are three learnable components.\n- The teacher, trained on two real and synthetic data based on its own classification ability and the student's performance\n- The student, trained on synthetic data and validated on real data (synthetic and real)\n- The synthetic data generation process, which is optimized to minimize the feedback loss of the first two\n\nThis nested scheme makes it difficult to discern whether synthetic data are sensible, are classified correctly and what drives performance - essentially why this process makes sense. As such, plots demonstrating the fit of the student model, the synthetically generated data or anything else which boosts intuition is paramount. As of now, the method is not sufficiently digestible.\n\n\n\n### __2. The concept of adding synthetic data:__ \n In BO, The (GP) surrogate models the underlying objective in a principled manner which yields calibrated uncertainty estimates, assuming that it is properly trained. Since the GP in itself is principles, I am not convinced that adding synthetic data is an intrinsically good idea. The proposed approach suggests that the GP is either un-calibrated or does not sufficiently extrapolate the observed data. While this seems possible, there is no insight into which possible fault (of the GP) is being addressed, nor how the added synthetic data accomplishes it. Is it\n1. The teacher MLP that aggressively (and accurately) extrapolates in synthetic data generation?\n2. That the vanilla GP is simply under-confident, so that adding synthetic data acts to reduce the uncertainty by adding more data?\n3. Some other reason/combination of the two\n\nNote that I am specifically asking for intuition as to how the _modeling_ (and not the BO results) can improve by adding synthetic data.\n\n### __3. The accuracy and role of the teacher:__\nIf the teacher is able to generate accurate data (synthetic or real), why not use it as a surrogate instead of the conventional GP? Comments like\n\n#### _\"Evaluating the performance of the student that is trained with random unlabeled data far away from the global optimum, may not provide relevant feedback for tuning the teacher toward finding the global optimum.\"_\n\nsuggest that it is the teacher's (and not the BO loop's) task to find the global optimum. If the teacher adds data that it believes is good to the BO surrogate, the teacher is indirectly conducting the optimization.\n\n### __4. The role of the student:__ \nIf the student is trained only on synthetic data, validated on a (promising) subset of the true data, and its loss is coupled with the teacher's. As such, the student's only role appears to be as a regularizer (i.e. to incorporate GP-like smoothness into the MLP) while producing approximately the same predictions on labeled data. Can the authors shed light on the role on whether this is true, and if so, what difference the student offers as opposed to conventional regularization.\n\n### __5. Few tasks in results:__ \nThree benchmarks constitutes a fairly sparse evaluation. Does the proposed method make sense on conventional test functions, and can a couple of those be added?\n\n\n### __6. Missing references:__ \nThe key idea of 5.1 is _very_ similar to MES (Wang and Jegelka 2017), and so this is a must-cite. They also use a GEV (specifically a Gumbel) to fit $p(y^*)$. \n\n__Minor:__\n- App. B1: proposes -->purposes, remove \", however\"\n- Sec 5.0 of systematically sample --> of systematically sampling\n- Legend fontsize is tiny, Fig.1 fontsize is too small as well"
                },
                "questions": {
                    "value": "- Is the synthetically generated data added as with any other data point, or are they added with additional noise?\n- Is the synthetically generated data ever replaced or substituted?\n- How (qualitatively) does the SGP differ from the BO GP in its prediction?\n- Does the parametrized sampling distribution discriminate regions that are believed to be good (like the GEV)?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4183/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4183/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4183/Reviewer_r1KM"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4183/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698655608157,
            "cdate": 1698655608157,
            "tmdate": 1699636384402,
            "mdate": 1699636384402,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XPNIiAt2XQ",
                "forum": "CY9f6G89Rv",
                "replyto": "Y1EkUHj1wH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4183/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4183/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer r1KM, Part 1"
                    },
                    "comment": {
                        "value": "We are grateful to the reviewer for their insightful feedback and thorough analysis of TSBO. This has prompted a deeper examination of the roles and interactions of each module within our system. In response to the reviewer's concerns, we present the following points:\n\n## Response to Weakness\n\n**The concept of adding synthetic data:**\n\nWe concur with the reviewer\u2019s suggestion on viewing the proposed teacher-student model, which includes the student\u2019s feedback to the teacher, as a mechanism for providing proper regularization to the teacher. This is a good way of looking at TS-BO. On the other hand, we want to emphasize that the regularization of the teacher is tailored specifically for the sequential optimization in BO. As such, we term it as \u201cselective regularization\u201d to distinguish it from other more commonly used regularizes.  \nWe elaborate on this \u201cselective regularization\u201d perspective further in the response to Point 4 below. \n\nIn response to the current question, we believe that the synthetic data offers advantages in  both areas highlighted by the reviewer:\n\n(a) The \"selective regularization\" improves the teacher's extrapolation power on synthetic data, more specifically, on the potentially high-value data points. This enhancement is a result of the combined efforts of the teacher, the unlabeled data sampler, and the student model. The sampler generates synthetic data which are potentially of high values. The student model, trained on the synthetic data, provides feedback to the teacher, effectively regularizing the teacher's predictions on these data points.\n\n(b) Vanilla Gaussian Processes (GPs) often exhibit overly conservative behavior when dealing with scarce data, leading to poor extrapolation capabilities [1, 2]. In TSBO, the selective regularization mechanism empowers the teacher to produce more precise synthetic data in regions potentially with high target value. This process increases the accuracy of the predicted label of the synthetic data. As a result, leveraging such synthetic data as additional data to train the data query GP can help reduce its uncertainty in regions that attain a high target value, which well aligns with the goal of Bayesian optimization."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4183/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700734766255,
                "cdate": 1700734766255,
                "tmdate": 1700734766255,
                "mdate": 1700734766255,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UbcU8wmbsh",
                "forum": "CY9f6G89Rv",
                "replyto": "Y1EkUHj1wH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4183/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4183/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer r1KM, Part 2"
                    },
                    "comment": {
                        "value": "**The accuracy and role of the teacher:**\n\nThis point raised by the reviewer brings up two important issues with respect to the role of teacher which we discussed as below:\n\n(a) Direct utilization of the Teacher Model as the BO Surrogate: \n\nWe've conducted an additional experiment to address whether the teacher model can be directly utilized as the surrogate in TSBO. We evaluate three different methods on Expression and Chemical Design. The first method is T-LBO, as the baseline. The second model is the proposed TSBO in the main paper and the third model is a variant of the proposed TSBO where the BO surrogate is the teacher model.\n\nFor all model, the hyper-parameter settings are the same as in the paper. The best evaluations of Expr and Penalized LogP after 250 queries among 5 seeds are reported in the table below.\n\nWe've also added this experiment with detailed setting in the Appendix in our revised version for further reference.\n\n|Method| Sorrogate|  Expr ($\\downarrow$ ) | Penalized LogP ($\\uparrow$ ) |\n| - | - | - | -|\n|T-LBO (baseline)          | GP|  0.572\u00b10.268 | 5.695\u00b11.254 |\n|TSBO  | GP| **0.240\u00b10.168** | **25.02\u00b14.794** |\n|TSBO  | Teacher| 0.432\u00b10.235 | 23.574\u00b13.017 |\n\nAs shown in the table, even though the teacher are directly adopted as a data query model, TSBO still outperforms T-LBO. \n\nThis suggests that the quality of the teacher is better than that of the GP surrogate in more standard BO methods that do not incorporate a teacher-student model.  We could use this teacher to replace the surrogate GP in these more standard BO methods to get better results. \n\nMeanwhile, most of existing BO methods prefer using GPs as the surrogate model due to their principled approach to calibrated uncertainty estimation. Though our teacher model could be more accurate than the standard GP surrogates, its uncertainty calibration is not as robust as that of GPs. Therefore, in our main paper, we proposed to supplement the teacher model with an additional data query GP. This GP incorporates both the synthetic data generated by the teacher and the labeled data. Empirically, this hybrid approach combines the best of the two worlds; it not only retains the improved accuracy of the teacher model but also enhances uncertainty estimation. The above experiment validates that this hybrid approach achieves the best final BO results.\n\n(b) Intuition Behind the Teacher Model's Role: \n\nWe concur with the reviewer\u2019s suggestion on viewing the proposed teacher-student model, which includes the student\u2019s feedback to the teacher, as a mechanism for providing proper regularization to the teacher. The teacher\u2019s role can be understood in this \"selective regularization\" perspective, which will be elaborated in our response to the next question on \u201cThe role of the student\u201d.\n\nIn brief, we posit that the superiority of the teacher model over traditional GPs as a BO surrogate stems from its enhanced ability to predict the labels of the data in regions of high target value. This is achieved by our BO-specific \"selective regularization\" of the teacher, implemented by combining the student model with an unlabeled data sampling strategy."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4183/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700734798080,
                "cdate": 1700734798080,
                "tmdate": 1700734798080,
                "mdate": 1700734798080,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mFnOM8eZCJ",
                "forum": "CY9f6G89Rv",
                "replyto": "Y1EkUHj1wH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4183/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4183/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer r1KM, Part 3"
                    },
                    "comment": {
                        "value": "**The role of the student:**\n\nIn agreement with the reviewer's perspective, the proposed teacher-student model, which includes the student\u2019s feedback to the teacher, can be viewed as a mechanism for providing proper regularization to the teacher. On the other hand, we want to emphasize that the regularization of the teacher is tailored specifically for the sequential optimization in BO. As such, we term it as \u201cselective regularization\u201d to distinguish it from other more commonly used regularizes.\n\nThe BO context awareness in this \u201cselective regularization\u201d is implemented by incorporating the student\u2019s feedback and an unlabeled data sampling procedure that is optimized for BO. \n\nTo achieve the goal of BO, it is desirable to train the teacher model so that it can better predict data points that have high target value. We may achieve this objective by imposing regularization focusing on points of interest in the BO process, rather than indiscriminately across the entire optimization landscape. We achieve this through our unlabeled data sampling technique, which proposes potentially optimal points in the current optimization step. The student model, trained specifically on these points, provides selective feedback to the teacher, effectively fine-tuning it. This process can be thought of as a self-evaluation by the teacher-student model on potential high-value points before performing actual data querying.\n\n**Few tasks in results:**\n\nWe evaluate TSBO on an additional challenging high-dimensional global optimization task: Topology Shape Fitting Task, first considered in T-LBO [3]. The goal is to find a pre-defined target binary topology image $\\boldsymbol{\\mathrm{x}}^* \\in \\{0, 1\\}^{1\\times 40\\times40}$. The objective function is the cosine similarity between the target $\\boldsymbol{\\mathrm{x}}^*$ and an input image $\\boldsymbol{\\mathrm{x}}$: $f(\\boldsymbol{\\mathrm{x}})=\\boldsymbol{\\mathrm{x}}^T\\boldsymbol{\\mathrm{x}}^*/(\\lVert \\boldsymbol{\\mathrm{x}}\\rVert_2 \\lVert \\boldsymbol{\\mathrm{x}}^*\\rVert_2)$. The VAE used in this task is a convolutional neural network [3] with a latent space of dimension 20. It is pre-trained on 10,000 unlabeled topology pictures in the dataset from [4].\n\n\n|Method | Topology ($\\uparrow$ ) |\n| -  | -|\n|Sobol  |  0.781\u00b10.007 |\n|LS-BO  |  0.834\u00b10.021 |\n|W-LBO  |  0.842\u00b10.012 |\n|T-LBO  |  0.840\u00b10.032 |\n|TSBO | **0.862\u00b10.022** |\n\nWe compare TSBO with all baselines considered in the manuscript. Each method starts with 100 labeled images, uniformly sampled from the dataset in [4]. We report the best score after 250 new queries, averaged across 3 random seeds. The hyper-parameter settings are the same as in the paper.\n\nAs shown in the table above, TSBO significantly outperforms baselines, demonstrating its effectiveness and versatility in global optimization tasks.\n\n**Missing references:**\n\nWe will add the mentioned paper in our revised version and provide a review of it.\n    \n## Response to Questions\n\n**1.** The synthetic data are treated as other labeled data, i.e., no additional predicted noises involved in fitting the data query GP.\n\n**2.** Yes, the synthetic data are re-sampled at the beginning of each BO iteration. The computational overhead of sampling is relatively neglectable in light of costly efforts for data evaluations.\n\n**3.** The student GP (SGP) is fitted on synthetic data with pseudo labels. Its accuracy on labeled data tends to be worse than the vanilla BO GP. Thus, the student is only utilized to provide an effective regularization to the teacher via the feedback loss.\n\n**4.** Yes, the data sampled by our parametrized sampling distribution tend to have higher evaluation values than the initial training data or data sampled randomly. For instance, in the final BO iteration for the molecule design task, the highest Penalized LogP value among the synthetic data generated by our sampler is larger than 20, whereas the maximal value of real molecules in the ZINC250 dataset is smaller than 4.\n\n## Reference\n[1] Kusner, M. J., Paige, B., & Hern\u00e1ndez-Lobato, J. M. (2017, July). Grammar variational autoencoder. In International conference on machine learning (pp. 1945-1954). PMLR.\n\n[2] Jin, W., Barzilay, R., & Jaakkola, T. (2018, July). Junction tree variational autoencoder for molecular graph generation. In International conference on machine learning (pp. 2323-2332). PMLR.\n\n[3] Grosnit, A., Tutunov, R., Maraval, A. M., Griffiths, R. R., Cowen-Rivers, A. I., Yang, L., ... & Bou-Ammar, H. (2021). High-dimensional Bayesian optimisation with variational autoencoders and deep metric learning. arXiv preprint arXiv:2106.03609.\n\n[4] Sosnovik, I., & Oseledets, I. (2019). Neural networks for topology optimization. Russian Journal of Numerical Analysis and Mathematical Modelling, 34(4), 215-223."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4183/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700734822196,
                "cdate": 1700734822196,
                "tmdate": 1700734822196,
                "mdate": 1700734822196,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "aj54qP9XhO",
            "forum": "CY9f6G89Rv",
            "replyto": "CY9f6G89Rv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4183/Reviewer_tpuF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4183/Reviewer_tpuF"
            ],
            "content": {
                "summary": {
                    "value": "The paper considers the problem of developing Bayesian optimization (BO) algorithm for optimizing `high-dimensional` black-box functions. The main proposal is to improve the surrogate modeling component of BO for high-dimensional spaces with a semi-supervised learning approach titled `TSBO` where the key idea is to leverage un-labeled data in the latent space BO framework by learning a pseudo-label dependent uncertainty-aware teacher-student model. \n\nThe teacher model is a multilayer perceptron that outputs a (mean, variance) pair which is used by a Gaussian process  based student model. A bilevel optimization problem is defined as the training objective of the student and teacher model. The teacher model parameters are updated with a combination of i. labeled data fitting loss and ii. feedback loss from the optimized student GP model. The student GP model parameters are optimized over the unlabeled dataset. This model is then used to generate the feedback loss for the teacher model based on a labeled validation set. The paper also proposes two different sampling approaches for picking the unlabeled dataset.\n\nOnce the teacher-student model is trained, the labeled dataset is combined with teacher-model predicted pseudo-labels for unlabeled inputs to train the main GP surrogate model (referred as data query GP model in the paper) for BO. Experiments are performed on a arithmetic expression task and two chemical design tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper considers an important problem with many real-world applications.\n\n- The overall idea of leveraging unlabeled data is nice and a nice broader insight to study as it can be instantiated in multiple different ways. \n\n- Overall BO results on the three domains are promising and the proposed method outperforms existing baseline approaches."
                },
                "weaknesses": {
                    "value": "- I have a broad top-view question. The premise of the paper is very reasonable in suggesting that the bottleneck for existing BO methods is the limited amount of labeled data available. However, labeled data is still required for training all the new components introduced in the paper (teacher model/parametrized sampling distribution). If semi-supervised learning is the key source for getting such improved results, why wouldn't any other semi-supervised learning approach (manifold/laplacian regularization etc) work equally well?\n\n- The ablation described in section 6.3 is critical for showing the performance improvement in surrogate modeling. I think a better way to do it is by evaluating the test performance on original data (for e.g. get a set of molecules from the chemical design and compute their latent embeddings) rather than points sampled from the latent space. In the end, we want the GP surrogate to be better at modeling points which resemble the original input space rather than any general point in the latent space. Please consider running this ablation in this manner. \n\n- There is a large body of work on both high-dimensional BO and latent space BO that is not discussed in the paper. Please see some references below. It is not necessary to compare with them experimentally but they deserve proper discussion in the paper as they are directly relevant to the studied problem. In fact, reference [9] below even considers including semi-supervised learning via an auxiliary network. Reference [6] is one of the key baselines because it re-trains the GP surrogate along with VAE parameters as we get more data.  \n\nBO over high dimensional inputs\n\n[1] Eriksson, D., Pearce, M., Gardner, J., Turner, R. D., & Poloczek, M. (2019). Scalable global optimization via local Bayesian optimization. Advances in neural information processing systems, 32.\n\n[2] Eriksson, D., & Jankowiak, M. (2021, December). High-dimensional Bayesian optimization with sparse axis-aligned subspaces. In Uncertainty in Artificial Intelligence (pp. 493-503). PMLR.\n\n[3] Papenmeier, L., Nardi, L., & Poloczek, M. (2022). Increasing the scope as you learn: Adaptive Bayesian optimization in nested subspaces. Advances in Neural Information Processing Systems, 35, 11586-11601.\n\n[4] Letham, B., Calandra, R., Rai, A., & Bakshy, E. (2020). Re-examining linear embeddings for high-dimensional Bayesian optimization. Advances in neural information processing systems, 33, 1546-1558.\n\n[5] Nayebi, A., Munteanu, A., & Poloczek, M. (2019, May). A framework for Bayesian optimization in embedded subspaces. In International Conference on Machine Learning (pp. 4752-4761). PMLR.\n\nLatent space BO\n\n[6] Maus, N., Jones, H., Moore, J., Kusner, M. J., Bradshaw, J., & Gardner, J. (2022). Local latent space bayesian optimization over structured inputs. Advances in Neural Information Processing Systems, 35, 34505-34518.\n\n[7] Deshwal, A., & Doppa, J. (2021). Combining latent space and structured kernels for bayesian optimization over combinatorial spaces. Advances in Neural Information Processing Systems, 34, 8185-8200.\n\n[8] Notin, P., Hern\u00e1ndez-Lobato, J. M., & Gal, Y. (2021). Improving black-box optimization in VAE latent space using decoder uncertainty. Advances in Neural Information Processing Systems, 34, 802-814.\n\n[9] Eissman, S., Levy, D., Shu, R., Bartzsch, S., & Ermon, S. (2018, January). Bayesian optimization and attribute adjustment. In Proc. 34th Conference on Uncertainty in Artificial Intelligence."
                },
                "questions": {
                    "value": "Please see weaknesses section above. I am more than happy to increase my score if the questions are answered appropriately."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4183/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698727694194,
            "cdate": 1698727694194,
            "tmdate": 1699636384305,
            "mdate": 1699636384305,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hPB4DoHJ5f",
                "forum": "CY9f6G89Rv",
                "replyto": "aj54qP9XhO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4183/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4183/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer tpuF, Part 1"
                    },
                    "comment": {
                        "value": "We appreciate the reviewers' constructive comments and feedbacks. Based on your suggestions, we provide  detailed responses as follows:\n\n## Reponses to Weakness\n\n**1.** Manifold Regularization and Laplacian Regularization are predicated on specific data assumptions. For instance, Laplacian Regularization penalizes the norm of the model's gradient when the density of unlabeled data is large. \n\nWhile these methods can potentially improve the modeling of the data geometry and hence improve the data query process when applied to Bayesian Optimization, the regularizations are applied across the entire data manifold and do not specifically target high-value regions, which are crucial in BO. In contrast, TSBO introduces a more nuanced, context-aware regularization (detailed in the next paragraph), particularly focused on areas with potentially high values. This targeted approach, as we hypothesize, is likely to be more effective within the scope of Bayesian Optimization.\n\nThe generation and utilization of unlabeled data within TSBO can be regarded as a form of BO specific \"selective regularization\" imposed on the teacher model. This enhancement is achieved by the combined efforts of the teacher, the unlabeled data sampler, and the student model: The sampler generates synthetic data which are potentially of high values. The student model, trained on the synthetic data, provides feedback to the teacher, effectively regularizing the teacher's predictions on these data points. This specialized form of regularization enables the teacher model to better extrapolate in regions of potential high values, providing valuable synthetic data that diminishes the uncertainty of the surrogate GP model. Consequently, this leads to improved sample efficiency, as demonstrated in our study.\n\n**2.** As the reviewer suggested, we test the generalization of the data query GP of TSBO for real molecules instead of sampled synthetic data and compare with a GP which is solely trained on  labeled data. The experimental settings are the same as in Section 6.3, expect the testing data. We uniformly sample 100 testing data points from the ZINC250K dataset and report the Negative Marginal Log-likelihood (NMLL, lower the better) of both GPs in the table below.\n\n|Data Query Model   | Penalized LogP |Ranolazine MPO |\n|-| - | - | \n|GP w/o pseudo labels   | 2.196 | -1.186 |\n|GP w pseudo labels  | **2.194** | **-1.197** |\n\nThe results show that there is a consistent improved generalization by utilizing pseudo labels for both Penalized LogP and Ranolazine MPO molecule profiles on the real test data points. \n\n**Further discussion:** while GP trained with pseudo labels improves the generalization on the labeled test data, we expect the improvement to be marginal since their corresponding values are very low. As mentioned in the response to weakness 1, the selective regularization targets on improving the teacher's extrapolation performance on potentially high values points, and the surrogate GP model, which utilizes these synthetic data and labeled data, is expected to show improved generalization ability especially on real data with high values.\n\nIn this case, an ideal test situation is to evaluate and compare the generalization ability of the TSBO GP and vanilla GP on real data points that of high values. Unfortunately, in the labeled dataset, the maximum value of labeled data is around 4 and the optimized value is 26. In other word, real data that are close to optimal values are not accessible in the provided dataset, making this ideal test difficult to implement in practice.\n\nTo further demonstrate the GP surrogate trained with pseudo labels has improved generalization particularly in high value regions, we design another experiment to evaluate the GPs with \"synthetic high value\" data directly in the latent space, which has not been demonstrated in the previous setting in Section 6.3, where we evaluate the generalization ability over the whole latent space. The setup is detailed as below:\n\nThe test data points are 100 synthetic data which are sampled in the latent space, from a small neighborhood of the best synthetic molecule's latent representation after 250 new queries. The sampling distribution is $\\mathcal{N} (\\mathrm{z}_{opt}, \\sigma^2 I_d)$, where $\\sigma$ is 0.01. The performance for the two GPs are reported as below:\n\n|Data Query Model   | Penalized LogP |Ranolazine MPO |\n|-| - | - | \n|GP w/o pseudo labels   | 4.228 | -2.086 |\n|GP w pseudo labels   | **1.388** | **-2.391** |\n\nAs demonstrated in the preceding table, the introduction of pseudo labels markedly reduces the GP's NMLL loss on testing data. This reduction highlights enhanced generalization, particularly around the optimum points."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4183/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700734166498,
                "cdate": 1700734166498,
                "tmdate": 1700734166498,
                "mdate": 1700734166498,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MsZOR0WaFV",
                "forum": "CY9f6G89Rv",
                "replyto": "aj54qP9XhO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4183/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4183/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer tpuF, Part 2"
                    },
                    "comment": {
                        "value": "**3.** We appreciate you for mentioning recent reference highly related to TSBO. All of them will be properly introduced in Section \"Related Work\" of an updated manuscript. Moreover, recent released Latent Space BO work will be discussed as well, such as [1, 2, 3]. \n\nHerein, we discuss the two VAE-based Latent Space BO approach that you specifically concerned: BO with attribute adjustment [4] ([9] in your reference order) and LOLBO [5] ([6] in your reference order). In convenience, we denote the first method as AABO. \n\nAt a high-level, AABO and LOLBO introduce new loss functions to the VAE in the context of BO. AABO utilizes a target predictor in the latent space, and trains the VAE to simultaneously maximize the standard unlabeled ELBO objective and minimize the supervised MSE loss of the predictor. LOLBO, on the other hand, optimizes its VAE to maximize the standard ELBO and the supervised NMLL loss of the data query GP.\n\nBoth approaches aim to leverage semi-supervised learning to train a better VAE, and have achieved promising experimental results. However, TSBO focuses on systematically integrating unlabeled data with their predicted pseudo labels into the data query GP. We believe the proposed techniques in TSBO are complementary to the existing VAE-based Latent Space BO work. Furthermore, [6] and [9] can be integrated into the TSBO framework with ease.\n\n## Reference\n\n[1] Maus, N., Lin, Z. J., Balandat, M., & Bakshy, E. (2023). Joint Composite Latent Space Bayesian Optimization. arXiv preprint arXiv:2311.02213.\n\n\n[2] Stanton, S., Maddox, W., Gruver, N., Maffettone, P., Delaney, E., Greenside, P., & Wilson, A. G. (2022, June). Accelerating bayesian optimization for biological sequence design with denoising autoencoders. In International Conference on Machine Learning (pp. 20459-20478). PMLR.\n\n[3] Maus, N., Wu, K., Eriksson, D., & Gardner, J. (2022). Discovering Many Diverse Solutions with Bayesian Optimization. arXiv preprint arXiv:2210.10953."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4183/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700734199259,
                "cdate": 1700734199259,
                "tmdate": 1700734199259,
                "mdate": 1700734199259,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ecI55A9ulg",
            "forum": "CY9f6G89Rv",
            "replyto": "CY9f6G89Rv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4183/Reviewer_QKF7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4183/Reviewer_QKF7"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a novel Bayesian Optimization (BO) procedure aimed at improving performances under a high dimensional data and low example setting.\nThe procedure circumvent the high number of example typically needed in latent space BO by using a \"Teacher-Student\" update loop to generate pseudo-labels during training. This loop requires sampling unlabeled data which is cheaper. \nThey empirically demonstrate the efficiency of their procedure and how their proposed optimization of each step of the procedure are key to performance improvement. \nThe four qualitative improvements demonstrated empirically are the following:\n- Pseudo-Label prediction improves performance even for baseline models.\n- The teacher-student method is efficient at optimizing the parameters using pseudo labels\n- The Uncertainty awareness part of the teacher-student method consistently ensures better performances\n- Optimized unlabeled sampling improves performance even for baseline models"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The method proposed in the article is robust to parameter changes and significantly improves past performances of other models such as .-LBO methods.\nThe methods trained with limited data even outperforms baseline models with unlimited access to data. \nThus the experiments tend to show that this method paves the way for novel applications where labelled and even unlabelled data is scarce."
                },
                "weaknesses": {
                    "value": "The articles doesn't present the performances of the method with access to larger parts of the dataset. This is coupled with a lack of theoretical analysis of the convergence of the algorithm weakens the presentation of the asymptotic behavior of the method."
                },
                "questions": {
                    "value": "Is there a class of functions for which the method converges towards the maximum? \nCan we expect any rate of convergence?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4183/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4183/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4183/Reviewer_QKF7"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4183/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698772521846,
            "cdate": 1698772521846,
            "tmdate": 1699636384226,
            "mdate": 1699636384226,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oqOBezzGsL",
                "forum": "CY9f6G89Rv",
                "replyto": "ecI55A9ulg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4183/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4183/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer QKF7"
                    },
                    "comment": {
                        "value": "We extend our gratitude to the reviewer for the useful concerns raised. In response, we would like to address the following points:\n\n## Response to Weakness\nWe evaluate TSBO starting with more intital data on the Chemical Design task to maximize the Penalized LogP objective. The experimental setting are the same as the paper, except that $n_{init}$ is 400.\n\n\n|Data Query Model|  $n_{init}$ |  $n_{query}$=100 |  $n_{query}$=250|\n|-| - | - | -|\n|T-LBO|200|-|5.695\u00b11.254|\n|T-LBO|250K|-|\u226426.11 (at $n_{query}$=500)|\n|TSBO   |200|14.865\u00b16.134| 25.020\u00b14.794 |\n|TSBO  | 400|21.213\u00b112.826| **26.246\u00b12.731** | \n\nThe results indicate that more initial labeled data significantly boost TSBO in the beginning 100 evaluations, and improve the final performance and robustness of TSBO. Moreover, TSBO starting with 400 initial data even outperforms T-LBO beginning with the full ZINC250K dataset, demonstrating the superior data efficiency of our method.\n\n## Response to Question\nAnalysis of convergence rate for BO has been studied in [1,2]. For VAE-based Latent Space BO, the coupling of deep neural networks requires more sufficient assumptions to derive theoretical deduction. For instance, T-LBO [3] manages to prove a probabilistic guarantee for a cumulative regret at rate $1/n$ over the assumptions that 1) the smoothness of the objective function, 2) the bounded posterior variance, and 3) the constant zero-mean Gaussian noise.\n\nWhile establishing a theoretical framework for convergence is challenging, empirical evidence suggests that TSBO exhibits superior sample efficiency and a faster rate of convergence. This observation is consistent across multiple datasets and various initial conditions, suggesting its potential as a robust and effective approach for BO.\n\n## Reference\n\n[1] Bull, A. D. (2011). Convergence rates of efficient global optimization algorithms. Journal of Machine Learning Research, 12(10).\n\n[2] Wang, Z., Hutter, F., Zoghi, M., Matheson, D., & De Feitas, N. (2016). Bayesian optimization in a billion dimensions via random embeddings. Journal of Artificial Intelligence Research, 55, 361-387.\n\n[3] Grosnit, A., Tutunov, R., Maraval, A. M., Griffiths, R. R., Cowen-Rivers, A. I., Yang, L., ... & Bou-Ammar, H. (2021). High-dimensional Bayesian optimisation with variational autoencoders and deep metric learning. arXiv preprint arXiv:2106.03609."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4183/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700733924539,
                "cdate": 1700733924539,
                "tmdate": 1700733924539,
                "mdate": 1700733924539,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]