[
    {
        "title": "Stability and Generalization in Free Adversarial Training"
    },
    {
        "review": {
            "id": "wKi1YpMCts",
            "forum": "N5ID99rsUq",
            "replyto": "N5ID99rsUq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4972/Reviewer_wev8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4972/Reviewer_wev8"
            ],
            "content": {
                "summary": {
                    "value": "This work utilizes the stability generalization framework to quantify the generalization bound of the Free Adversarial Training algorithm. Additionally, it shows that Free AT has a smaller generalization gap (but test error may not be smaller) and provides some theoretical intuitions."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This work offers important insights into the convergence properties of free AT. Additionally, the authors highlight intuitive relationships between \"more simultaneous\" gradient updates during training and the resulting generalization capability. These results can inspire further improvements in robust training algorithms to alleviate overfitting. The paper is generally well-presented and easy to follow."
                },
                "weaknesses": {
                    "value": "- The theoretical support for FreeAT having a smaller generalization gap than VanillaAT could be more rigorous. Specifically, while Theorem 2 presents pessimistic results for the convergence of VanillaAT, it is unclear whether this bound is tight. It is unclear whether the convergence difference between vanilla and free AT is due to the algorithm itself or some artifacts of the proof technique. While experiment results support this intuition, the paper would benefit from some additional explanations. It would be even better if some lower bounds could be provided for $\\mathcal{E}\\_{\\textrm{gen}} (A\\_{\\textrm{Vanilla}})$.\n- The relationship between a smaller generalization gap and better transferability is unclear. The motivation for the experiment setting of transferring attacks from a robust model to a standard model is weak. I suggest moving the transferability analysis to the Appendix (it's still good to have them) and making space for Table 2, which supports your main claim.\n- Figure 1 should use different line styles for train and test. In the current form, it's hard to distinguish them.\n- Since the proposed convergence bounds depend on the dataset size $n$, this paper would benefit from some empirical comparisons between free and vanilla AT with different $n$ values.\n\nI believe that the value of the theoretical bound on FreeAT's convergence outweighs the above weaknesses. Hence, a rating of 6 is given."
                },
                "questions": {
                    "value": "- Do the theoretical results also apply to the $\\ell_\\infty$ case?\n- Has there been any work that empirically estimates the Lipschitz and smoothness constants in Assumptions 1 and 2?\n- Can smoothness and Lipschitzness assumptions (1 and 2) be relaxed? Specifically, instead of having this condition for all pairs of $\\delta, \\delta'$, is it possible to define Lipschitzness and smoothness over $\\delta$ w.r.t. the nominal point ($\\delta = 0$)? This relaxation will make the conditions more realistic.\n- What is Free-4 in Table 2 and some of the figures (including Figure 1)?\n- Theorem 3 lower-bounds $\\mathbb{E}[ || w(S) - w(S') || ]$. However, does a large $\\mathbb{E}[ || w(S) - w(S') || ]$ necessarily translate to large $\\mathcal{E}\\_{\\textrm{gen}}$? Isn't it the case that neural networks with very different weights can have similar behavior?\n- In practice, the attack loss function and the training loss function may not be the same, and using different losses has been empirically shown to decrease the generalization gap. Examples include TRADES [1] and ALP [2]. It's probably a stretch goal, but is it possible to extend the analysis to this scenario?\n\n[1] Zhang, Hongyang, et al. \"Theoretically principled trade-off between robustness and accuracy.\" International conference on machine learning. PMLR, 2019. \\\n[2] Harini Kannan, Alexey Kurakin, and Ian Goodfellow. \"Adversarial logit pairing.\" arXiv preprint\narXiv:1803.06373, 2018."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4972/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4972/Reviewer_wev8",
                        "ICLR.cc/2024/Conference/Submission4972/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4972/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697676183362,
            "cdate": 1697676183362,
            "tmdate": 1700360437000,
            "mdate": 1700360437000,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "UVJPDD8dhS",
                "forum": "N5ID99rsUq",
                "replyto": "wKi1YpMCts",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4972/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' Response to Reviewer wev8 (Part 1)"
                    },
                    "comment": {
                        "value": "We thank Reviewer wev8 for his/her time and constructive feedback and suggestions. Below is our response to the questions and comments in the review. \n\n**1- Tightness of the generalization bound**\n\n**Re**: The reviewer is right that the generalization bound in Theorems 2 and 4 could be pessimistic in the sense that we only assume bounded Lipschitz and smoothness coefficients of the learning objective function. We would like to clarify that we did not make a definite theoretical statement on the generalization comparison of vanilla and free adversarial training, since our stability-based generalization bounds *only suggest* a lower expected generalization gap for free AT in comparison to vanilla AT. As pointed out by the reviewer, a generalization lower-bound would shed light on the tightness of the bounds in Theorems 2, 4. However, to the best of our knowledge, the question of a non-trivial lower-bound on the *expected* generalization gap (the quantity bounded in the stability-based approach) is still an open problem for both nonconvex-concave and nonconvex-nonconcave min-max learning problems. \n\nTo investigate the discussed implications of our theoretical bounds, we performed numerical experiments on standard datasets and neural net architectures, which is similar to other theoretical works on the generalization of adversarial learning algorithms. The results of the numerical experiments are consistent with our hypothesis on the comparison of generalization error between vanilla and free AT algorithms. \n\n**2- Postponing the numerical results on transferability to the Appendix**\n\n**Re**: As recommended by the reviewer, we deferred the numerical results on the attack transferability to the Appendix, and used the space to present the numerical results on the role of the size of training set $n$, which was suggested by the reviewer.\n\n**3- Line styles in Figure 1 for train and test qunatities**\n\n**Re**: We thank the reviewer for pointing out the identical line styles in Figure 1. We have changed the line style for test accuracy in the revision. \n\n**4- Empirical comparison between free and vanilla AT with different dataset size $n$ values**\n\n**Re**: Following the reviewer\u2019s suggestion, we performed numerical experiments by randomly sampling a subset of size $n \\in \\lbrace 10000, 20000, 30000, 40000, 50000\\rbrace$ from CIFAR-10 and CIFAR-100 training sets, and trained ResNet18 neural nets using those training sets. The numerical results of our comparison of the generalization gaps between free and vanilla AT are presented in Figure 4 and Appendix B.3 of the revised submission. The results indicate that the generalization gap of free AT is decreasing considerably faster than vanilla AT with dataset size $n$. We thank the reviewer for the great suggestion.\n\n**5- \u201cDo the theoretical results also apply to the $L_{\\infty}$ case?\u201d**\n\n**Re**: Our theoretical analysis concerns only the $L_2$-norm bounded perturbations. As a Hilbert-space norm induced by an inner product, the $L_2$-based projection reduces to a standard normalization of the input vector which preserves the vector\u2019s direction. This property allows us to leverage the theory of linear dynamical systems to track the changes following the two different datasets $S,S\u2019$ and bound the stability degree of AT algorithms. On the other hand, the $L_\\infty$-norm would lead to a sign-based projection that can completely alter the direction of an input vector. Therefore, a similar stability analysis of the $L_\\infty$-based AT would lead to a highly non-linear dynamical system which would be difficult to analyze using existing control and optimization theory frameworks. \n\n**6- \"Has there been any work that empirically estimates the Lipschitz and smoothness constants in Assumptions 1 and 2?\"**\n\n**Re**: To the best of our knowledge, computing the exact Lipschitz and smoothness coefficients of overparameterized neural networks is a computationally challenging problem. The related works [3,4] used SDP relaxation to compute the Lipschitz constant of neural networks, but the computational cost of a SDP-based method would be unaffordable for overparameterized neural networks such as standard ResNets. Another line of work [5] attempted to bound the Lipschitz constants and smoothness by using standard matrix-based norm for the neural net\u2019s weight matrices; however, these upper-bounds could be significantly loose in application to standard neural net architectures and image datasets.  \n\n**7- Relaxation of smoothness and Lipschitzness assumptions**\n\n**Re**: We note that our stability-based generalization results will hold if the bounded gradient and Hessian norm assumptions hold only for every input vector within an $\\epsilon$-distance from the support set of the underlying distribution of random vector $X$. We have clarified this point in the revised text."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700305923485,
                "cdate": 1700305923485,
                "tmdate": 1700306437904,
                "mdate": 1700306437904,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EpFr9rB8qf",
                "forum": "N5ID99rsUq",
                "replyto": "wKi1YpMCts",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4972/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' Response to Reviewer wev8 (Part 2)"
                    },
                    "comment": {
                        "value": "**8- \"What is Free-4 in Table 2 and some of the figures?\"**\n\n**Re**: We added footnote 1 for clarity. Throughout our work, \u2018\u2018Free-$m$\u2019\u2019 means the free AT algorithm with $m$ free steps, and following from [8] and [9], we use \u2018\u2018Free\u2019\u2019 without specification to denote Free-4 by default. \n\n**9- Relationship between $\\mathbb{E}[|| w(S) - w(S\u2019) ||]$ and $\\mathcal{E}_{gen}$**\n\n**Re**: We agree with the reviewer that a higher stability degree does not necessarily imply a lower generalization gap. Our generalization analysis follows the standard analysis for stochastic gradient-based optimization algorithms (please see the discussion in [7] for more details), and, as the reviewer pointed out, can be pessimistic for a general nonconvex-nonconcave minimax problem. Similar to other theoretical works on generalization of deep learning models, our bounds only suggest a hypothesis for the generalization comparison, which we attempt to validate using numerical experiments.  \n\n**10- Extension of the analysis to other AT algorithms**\n\n**Re**: We thank the reviewer for the constructive feedback. In Appendix B.6 of our revision, we have performed numerical experiments on a similar \u201dfree\u201d variant of the TRADES algorithm [6] (which we call Free-TRADES). Following our theoretical discussion, the simultaneous optimization updates in Free-TRADES could help lower the generalization gap. Our numerical results indicate that Free-TRADES can also reduce the generalization error. The theoretical analysis of the generalization behavior of Free-TRADES is an interesting direction for future exploration. \n\n\n[1] Yue Xing, Qifan Song, and Guang Cheng. On the algorithmic stability of adversarial training. Advances in neural information processing systems, 2021.\n\n[2] Jiancong Xiao, Yanbo Fan, Ruoyu Sun, Jue Wang, and Zhi-Quan Luo. Stability analysis and generalization bounds of adversarial training. Advances in Neural Information Processing Systems, 2022b.\n\n[3] Mahyar Fazlyab, Alexander Robey, Hamed Hassani, Manfred Morari, and George Pappas. Efficient and accurate estimation of lipschitz constants for deep neural networks. Advances in Neural Information Processing Systems, 2019.\n\n[4] Zhouxing Shi, Yihan Wang, Huan Zhang, J Zico Kolter, and Cho-Jui Hsieh. Efficiently computing local lipschitz constants of neural networks via bound propagation. Advances in Neural Information Processing Systems, 2022.\n\n[5] Bohang Zhang, Du Jiang, Di He, and Liwei Wang. Rethinking lipschitz neural networks and certified robustness: A boolean function perspective. Advances in Neural Information Processing Systems, 2022.\n\n[6] Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, and Michael Jordan. Theoretically principled trade-off between robustness and accuracy. In International Conference on Machine Learning, 2015.\n\n[7] Moritz Hardt, Benjamin Recht, and Yoram Singer. Train faster, generalize better: Stability of stochastic gradient descent. arXiv preprint arXiv:1509.01240, 2015.\n\n[8] Ali Shafahi, Mahyar Najibi, Mohammad Amin Ghiasi, Zheng Xu, John Dickerson, Christoph Studer, Larry S Davis, Gavin Taylor, and Tom Goldstein. Adversarial training for free, Advances in Neural Information Processing Systems, 2019.\n\n[9] Eric Wong, Leslie Rice, and J Zico Kolter. Fast is better than free: Revisiting adversarial training. International Conference on Machine Learning, 2020."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700306233965,
                "cdate": 1700306233965,
                "tmdate": 1700306233965,
                "mdate": 1700306233965,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5BJJIQk9Ls",
                "forum": "N5ID99rsUq",
                "replyto": "EpFr9rB8qf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4972/Reviewer_wev8"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4972/Reviewer_wev8"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the response."
                    },
                    "comment": {
                        "value": "Thank you for the response, which clarified most of my questions.\n\nThis paper presents an interesting and sound analysis, with plenty of empirical evidence after the revision. Therefore, I believe that it is clearly *above the acceptance threshold*.\n\nThat being said, some of the theoretical results are less practical and meaningful (such as the relationship between $\\mathbb{E} [|| w(S) - w(S') ||]$ and $\\mathcal{E}_{gen}$) due to the technical difficulties. As a result, I am keeping my rating of 6."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700361154064,
                "cdate": 1700361154064,
                "tmdate": 1700361154064,
                "mdate": 1700361154064,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ElWES9T99r",
            "forum": "N5ID99rsUq",
            "replyto": "N5ID99rsUq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4972/Reviewer_T7Bj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4972/Reviewer_T7Bj"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the generalization of free adversarial training (AT) which was proposed in Shafahi et al. (2019). \n The authors use the algorithmic stability approach to analyze its generalization behavior and it provides its comparison of the generalization bounds against the vanilla, fast AT methods.  It claims that the free AT algorithm could have a lower generalization bound than the vanilla AT one."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This seems to be the first-ever-known result that addressed the generalization of the free AT method using the algorithmic stability approach in the setting of mini-max formulation."
                },
                "weaknesses": {
                    "value": "While the stability results for the free AT method are first-ever-known, the proof techniques seem to be incremental and the paper did not illustrate clearly what the main technical contribution is, particularly considering there is a considerable amount of work on stability analysis.\n \nThe generalization bound in Theorem 4 relies on the restrictive assumption that the gradient $\\nabla_\\delta h(w,\\delta; x,y)$ is lower-bounded by $1 / \\psi$ during the training process.  There is no discussion about when this critical condition holds true."
                },
                "questions": {
                    "value": "It is not clear to me what the free AT method aims to minimize or optimize.  The objective function of the vanilla AT method is given on page 3, i.e. $R_S(w)$ or $R(w)$.  From the pseudo-code of Algorithm 3,  there are two random samplings--one for mini-batch and one for $\\{\\delta_j\\}$ and then the $w$ and $\\delta$ are updated by gradient descent and ascent, respectively.  In this sense, does the free AT methods aim to minimize the following objective \n$$ \\min_w \\max_\\delta {1\\over n } \\sum_{j=1}^n \\int_{\\delta_j\\in \\Delta} h(w,\\delta_j; x_j,y_j)$$ \nThe objective functions seem to be very different from each other for the free AT method and the vanilla AT one.   Indeed, the objective function of the free AT method is a low-bound relaxation of the vanilla one.   Could you explain more about this point?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4972/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697813704821,
            "cdate": 1697813704821,
            "tmdate": 1699636484499,
            "mdate": 1699636484499,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "DEjzKnJUxl",
                "forum": "N5ID99rsUq",
                "replyto": "ElWES9T99r",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4972/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' Response to Reviewer T7Bj"
                    },
                    "comment": {
                        "value": "We thank Reviewer T7Bj for his/her time and feedback. Below is our response to the questions and comments in the review. \n\n**1- Technical contributions of the work**\n\n**Re**: Free AT is a widely used variant of adversarial training, mainly due to its higher speed in application to large-scale learning problems. While the free AT method has been extensively used in many applications, the existing theory literature on adversarial training methods has not focused on the specific properties of free AT algorithm. In our work, we focus on the generalization analysis of models learned by free AT, which, to the best of our knowledge, has not been studied in previous works.\n\nRegarding the reviewer\u2019s comment on our work\u2019s technical contribution, we note that our generalization guarantee for free AT (Theorem 4) does not follow from any existing stability-based generalization bound for min-max learning frameworks. Specifically, our generalization analysis accounts for the following properties of the free AT method, which have not been considered in the related works: \n\n1- Re-initialization of the max variable (adversarial perturbations) after the completion of optimization steps for every batch of training data\\\n2- Utilizing the normalized gradient (instead of vanilla gradient) for the gradient ascent step of solving the maximization sub-problem\\\n3- Using mini-batch stochastic optimization for updating min and max variables at every iteration\n\nThe generalization analysis under the above conditions and the comparison of generalization performance between vanilla vs. free adversarial training are our work\u2019s main technical contributions, which we believe are novel results that do not follow from any existing bound in the literature.\n\n**2- The assumption on bounded gradient norm $\\Vert\\nabla_\\delta h(w,\\delta;x,y)\\Vert$ in Theorem 4**\n\n**Re**: We note that the bounded-gradient-norm assumption is only needed for the points within an $\\varepsilon$-distance from the training samples. Based on this comment, we numerically evaluated the gradient norm in the application of free-AT to CIFAR-10 and CIFAR-100 datasets, indicating that the minimum gradient norm on training data is constantly lower-bounded by $\\mathcal{O}(10^{-3})$ in those experiments. We refer the reviewer to Figure 11 in the revised Appendix B.5 for the statistics of the gradient norm evaluation in the experiments.\n\n**3- The objective that the free AT method aims to optimize**\n\n**Re**: The free AT algorithm has been originally proposed in [3] to solve the standard min-max formulation of adversarial training problems. The reviewer\u2019s question points to an interesting research direction on the effects of the optimization steps in free AT on the target min-max optimization problem. While this problem sounds an interesting direction to explore on free AT, we think our stability-based generalization analysis is orthogonal to this research direction.\n\nPlease note that our main objective is to compare the generalization error of free vs. vanilla AT methods, and to perform a fair comparison we should use the same generalization error metric for both these AT algorithms. According to the standards in the adversarial learning literature, we chose this generalization metric to be the difference between the worst-case training and test error under norm-bounded perturbations. Therefore, to ensure a fair comparison between free and vanilla adversarial training, we have to use the same generalization metric for the analysis of free AT. Any different selection of the generalization metric for free AT would have led to an unfair comparison of the generalization error between the two methods.\n  \n\n[1] Yue Xing, Qifan Song, and Guang Cheng. On the algorithmic stability of adversarial training. Advances in neural information processing systems, 2021.\n\n[2] Jiancong Xiao, Yanbo Fan, Ruoyu Sun, Jue Wang, and Zhi-Quan Luo. Stability analysis and generalization bounds of adversarial training. Advances in Neural Information Processing Systems, 2022.\n\n[3] Ali Shafahi, Mahyar Najibi, Mohammad Amin Ghiasi, Zheng Xu, John Dickerson, Christoph Studer, Larry S Davis, Gavin Taylor, and Tom Goldstein. Adversarial training for free, Advances in Neural Information Processing Systems, 2019."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700305418990,
                "cdate": 1700305418990,
                "tmdate": 1700305418990,
                "mdate": 1700305418990,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Bt3tO2KlnX",
            "forum": "N5ID99rsUq",
            "replyto": "N5ID99rsUq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4972/Reviewer_ge9g"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4972/Reviewer_ge9g"
            ],
            "content": {
                "summary": {
                    "value": "This work studies the role of min-max optimization algorithms in the generalization performance of adversarial training methods. It leverages the algorithmic stability framework to compare the generalization behavior of adversarial training methods. The developed generalization bounds suggest that not only can the free AT approach lead to a faster optimization compared to the vanilla AT, but also it can result in a lower generalization gap between the performance on training and test data."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This work provides some theoretical results.\n- The theoretical conclusions are easy to follow."
                },
                "weaknesses": {
                    "value": "- What is the definition of $\\Delta$?\n- What is the definition of randomized algorithm $A(\\cdot)$? A mapping? If yes, then what is the definition of $\\mathbb{E}_A$?\n- Given $S$, $w=A(S)$ is a random variable or constant\uff1f\n- What's the definition of $S'$ here?\n- What is the definition of \"$A$ is $\\epsilon$-uniformly stable\"?\n- Unclear definition in Theorem 1?\n- I **guess** the theory is developed over \"randomized algorithm $A$\" (and Gibbs loss?), i.e., the output of $A(S)$ is random weights, which is distributed by a posterior. However, this paper only presents empirical results based on deterministic weights. How can these empirical findings provide support for the theoretical results?\n- If $A(S)$ is a random variable, given $S$, what are the specific posterior distributions of $A_{AVanilla}(S)$ and $A_{Free}(S)$? What is the difference between these posterior distributions? Where does the randomness of $A_{AVanilla}(S)$ come from? \n- It seems there are not some interesting insights from the theoretical and empirical results in this work. \n\n(Please correct me if I have some mistakes.)"
                },
                "questions": {
                    "value": "See weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4972/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4972/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4972/Reviewer_ge9g"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4972/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698566089284,
            "cdate": 1698566089284,
            "tmdate": 1700319615708,
            "mdate": 1700319615708,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6hkxiXVhix",
                "forum": "N5ID99rsUq",
                "replyto": "Bt3tO2KlnX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4972/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer ge9g"
                    },
                    "comment": {
                        "value": "We thank Reviewer ge9g for his/her time and feedback. Below is our response to the questions and comments in the review. \n\n**1- \u201cWhat is the definition of $\\Delta$?\u201d**\n\n**Re**: As we stated at the beginning of Section 3.1, $\\Delta$ is the set of all possible perturbations, which is usually an $L_2$-norm or $L_\\infty$-norm bounded ball of some radius $\\varepsilon$. \n\n**2- \u201cWhat is the definition of randomized algorithm $A(\\cdot)$? What is the definition of $\\mathbb{E}_A$? Given $S$, $w=A(S)$ is a random variable or constant?\u201d**\n\n**Re**: As we stated in Section 3, $A$ is a potentially randomized algorithm that takes a dataset $S$ as input and outputs model parameter $w=A(S)$. Since the randomness of $A$ may come from random initialization or random batch selection, $\\mathbb{E}_A$ is taking the expectation over such randomness, and $w=A(S)$ will therefore be a random vector. \n\n**3- \u201cWhat's the definition of $S\u2019$ here?\u201d**\n\n**Re**: Following our statement in Definition 1, $S\u2019$ is any dataset that has the same size as $S$ and differs from $S$ in at most one example. \n\n**4- \u201cWhat is the definition of \"$A$ is $\\epsilon$-uniformly stable\"?\u201d**\n\n**Re**: Please refer to Definition 1 for the formal definition of \u201c$\\epsilon$-uniformly stable\u201d, which follows from references [1,2]. \n\n**5- \u201cUnclear definition in Theorem 1?\u201d**\n\n**Re**: We wish the reviewer could be more specific about his/her observed unclarities in Theorem 1. We will be happy to answer any follow-up question on this point.\n\n**6- \u201cWhere does the randomness of $A_{Vanilla}(S)$ come from?\u201d**\n\n**Re**: In our analysis, both $A_{Vanilla}$ and $A_{Free}$ are stochastic optimization algorithms and the training dataset is also random. So the randomness of $A$ could come from both random initialization and random batch selection. \n\n \n**7- Insights from the theoretical and empirical results.**\n\n**Re**: Free AT is a widely used variant of adversarial training methods due to its higher speed in training the neural net classifier. While the free AT method has been extensively used in several applications, the existing theoretical analysis of adversarial training have not focused on the properties of free AT algorithm. In our work, we focus on the generalization analysis of models learned by the free AT approach, which, to the best of our knowledge, has not been studied in the literature. We show that due to the simultaneous updating nature of free AT, it has significantly better generalization performance compared to vanilla AT in theoretical analysis, and the numerical results are consistent with the theory. Please see our response to the first comment of Reviewer T7Bj for more information about our technical contributions. \n\n[1] Yue Xing, Qifan Song, and Guang Cheng. On the algorithmic stability of adversarial training. Advances in neural information processing systems, 2021.\n\n[2] Jiancong Xiao, Yanbo Fan, Ruoyu Sun, Jue Wang, and Zhi-Quan Luo. Stability analysis and generalization bounds of adversarial training. Advances in Neural Information Processing Systems."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700305087956,
                "cdate": 1700305087956,
                "tmdate": 1700305087956,
                "mdate": 1700305087956,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WZa3HIWQkp",
                "forum": "N5ID99rsUq",
                "replyto": "6hkxiXVhix",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4972/Reviewer_ge9g"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4972/Reviewer_ge9g"
                ],
                "content": {
                    "title": {
                        "value": "response"
                    },
                    "comment": {
                        "value": "Dear Authors,\n\nThank you for your response.\n\nAfter reviewing your clarifications, I have a better understanding of the manuscript. However, I still believe that clear definitions could benefit from further elucidation. For example, $\\Delta$ is introduced early in Section 3, but its definition appears later. It would be better to explicitly define what is a randomized algorithm. Does this include all forms of randomness during training, such as dropout, all initial weight distributions, and so on? Does the bound hold under any randomness of training?\n\nAccording to the rebuttal, I have adjusted my score to 6 and decreased my confidence to 3. All in all, **I stand on the fence for this manuscript**.\n\nReviewer ge9g"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700319591973,
                "cdate": 1700319591973,
                "tmdate": 1700319591973,
                "mdate": 1700319591973,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "fI0C2keEQX",
            "forum": "N5ID99rsUq",
            "replyto": "N5ID99rsUq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4972/Reviewer_iGFe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4972/Reviewer_iGFe"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies stability and generalization of vanilla, free, and fast adversarial training from an algorithmic stability perspective. The generalization error gap bounds are derived for those adversarial training methods, and numerical results are also provided to show the generalization performance and robustness against black-box attacks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper is well-motivated and well-written. The novelty and contributions are clearly stated and organized. The theoretical findings are provided in a rigorous manner, together with some validation numerical results. In general, the theoretical findings are interesting to the community."
                },
                "weaknesses": {
                    "value": "1. This paper is dedicated to generalization performance analysis of existing adversarial training methods and reveals some interesting points. Nevertheless, there is a lack of deep insights on the new advanced designs of adversarial training from the generalization bounds. The authors should have discussed the insights/guidance from the theoretical findings, or discussed certain limitations of the algorithmic stability approach itself.\n2. From the experimental results, e.g., Figure 1, it appears that the reduced generalization error gap of free adversarial training is mainly due to the higher training error. Assuming the generalization error gap maintains, it is unclear if the test error can be further reduced when the training error is reduced. The authors should add some comments on this.\n3. It would expect that new training/regularization methods could be proposed given the obtained generalization error bounds. Otherwise, the impact of the theoretical findings of this work is quite limited. A thorough discussion would be helpful and beneficial. It would be also interesting to know the potential connection between generalization gap and the robustness against adversarial attacks."
                },
                "questions": {
                    "value": "See the Weaknesses above. \n\nAdd some comments on the practical usefulness of the theoretical findings with respect to the design of adversarial training methods. The limitations of the algorithmic stability approach for studying generalization performance could be also discussed."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4972/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698672262767,
            "cdate": 1698672262767,
            "tmdate": 1699636484319,
            "mdate": 1699636484319,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "uncJSo31ld",
                "forum": "N5ID99rsUq",
                "replyto": "fI0C2keEQX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4972/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' Response to Reviewer iGFe"
                    },
                    "comment": {
                        "value": "We thank Reviewer iGFe for his/her time and constructive feedback. Below is our response to the questions and comments in the review. \n\n**1- Practical implications of the theoretical generalization bounds**\n\n**Re**: In the revised version, we have added a remark after Theorem 4 to discuss the implications of the theoretical bound on Free AT. We note that Theorem 4 suggests how the stepsize parameters for the max and min variables affect the generalization gap of free AT, where by reducing the number of maximization steps $m$ and step size $\\alpha_\\delta$ one can achieve a lower generalization error. \n\n\n**2- The relationship between generalization gap and training error**\n\n**Re**: We agree with the reviewer that if we continue training the neural networks by applying free AT for more epochs, the training error might further decrease and the generalization gap might be larger. This phenomenon is essentially consistent with the stability analysis \u2013 our stability-based generalization bounds consider the number of iterations $T$ as a parameter and grow sublinearly with $T$. To make a fair comparison between free and vanilla AT from the stability perspective, we use the same number of training iterations in our experiments, and we observe a lower generalization gap and sometimes 2%-5% improvement on the robust test accuracy by free AT. Please note that the dependence of the generalization gap on the iteration number $T$ is consistent with the numerical findings of the references (e.g. the discussion in [1]). \n\n\n**3- Improved adversarial training/regularization methods based on the generalization analysis**\n\n**Re**: The simultaneous nature of min-max updates of free AT can be extended to other established robust training methods such as TRADES [2]. Based on this comment, we have performed numerical experiments on the application of a similarly defined \u2018\u2018free\u2019\u2019 version of TRADES (which we call Free-TRADES). The results of our numerical experiments are presented in the revised Appendix B.6. The numerical results indicate that Free-TRADES can similarly gain a better generalization performance using the simultaneous min and max optimization steps. The theoretical analysis of the proposed Free\u2013TRADES will be an interesting future direction to our work, which we have discussed in the revised conclusion section.\n\n[1] Leslie Rice, Eric Wong, and Zico Kolter. Overfitting in adversarially robust deep learning. In International Conference on Machine Learning, 2020.\n\n[2] Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, and Michael Jordan. Theoretically principled trade-off between robustness and accuracy. In International conference on machine learning, 2019."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700305645371,
                "cdate": 1700305645371,
                "tmdate": 1700305671602,
                "mdate": 1700305671602,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]