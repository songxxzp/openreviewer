[
    {
        "title": "Trustless Audits without Revealing Data or Models"
    },
    {
        "review": {
            "id": "cZbKql1ezI",
            "forum": "bgyWXX8HCk",
            "replyto": "bgyWXX8HCk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2901/Reviewer_Ww1n"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2901/Reviewer_Ww1n"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a method for privately auditing machine learning models as well as their training data based on the use of cryptographic commitments and zero-knowledge proofs. More precisely, the audit framework proposed is composed of two phases: one in which the training data as well as the model weights are cryptographically committed and one in which an audit function F is computed on the data along with a zero-knowledge proof of the result. To realize this, a novel zero-knowledge protocol for computing the backward pass of the training of a neural network is also proposed."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper proposes an interesting approach to be able to audit machine learning models such as neural networks in a privacy-preserving manner. In addition, the use of ZK-SNARKS provides strong security and privacy properties. \n\nOne of the main novelty of the paper is the design of an approach for computing the backward pass of a stochastic gradient descent algorithm based on ZK-SNARK. Several optimisation tricks are also proposed to be able to make the approach more efficient and control the computation-utility trade-off. Overall, this enables to prove the training in privacy-preserving manner while previous works were only focusing on inference.\n\nOverall, the paper is well-written although the addition of an outline at the end of the introduction would help to clarify its structure."
                },
                "weaknesses": {
                    "value": "In the introduction, there is a bit of confusion between the issue of training the model privately using secure multiparty computation vs performing an audit in a collaborative manner. The description of ZK-SNARKs in Section 2 is also a bit too concise for a reader that is not already familiar with this concept. I suggest to add a few concrete examples of what x and w could be, in particular within the context of privacy-preserving machine learning. Similarly, an intuitive example would help to understand what information or properties could be encoded in the 2D grid of arithmetic intermediate representations. Similarly more details are needed to understand the concepts of KZG commitments, inner-products arguments or structured-reference strings. Otherwise, the paper is going to be difficult to follow for a reader that does not have already a strong cryptographic background\n\nThe limit on which functions can (or cannot) be audited with the proposed approach is not clear. For instance, it is not clear for me if the proposed approach could be used to prove fairness properties about the model. A generic discussion on the applicability but also limits of the method would help.\n\nThe experiments are conducted on a limited number of datasets and architectures and thus it is not clear how the approach would scale. For instance, I suggest to the authors to provide additional experiments with classical datasets such as MNIST and CIFAR and architecture such as Resnet. In addition, one shortcoming of the current experiments is that they only report the training accuracy but not the test accuracy. The cost should be also reported in terms of computational time in addition of the monetary cost to be more meaningful."
                },
                "questions": {
                    "value": "-The notion of trust should be more specifically defined in the paper, in particular as the focus of the paper is to argue that the proposed approach is \u00ab\u00a0trusttless\u00a0\u00bb.\n-How does a traversal ordering attacks works? \n-What are the test accuracies obtained for the different conducted experiments?\n-How does the use of salt to prevent dictionary attacks when hashing the weights combine with the ZK-SNARKS?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2901/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2901/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2901/Reviewer_Ww1n"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2901/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698572613601,
            "cdate": 1698572613601,
            "tmdate": 1700687900749,
            "mdate": 1700687900749,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jpwJpHu7Tu",
                "forum": "bgyWXX8HCk",
                "replyto": "cZbKql1ezI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2901/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2901/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear reviewer,\n\nThank you for your detailed comments. We have conducted additional experiments on CIFAR-10 and MNIST and have updated the draft to address your concerns. \n\n## Presentation of ZK-SNARKs\n\nWe have incorporated your suggestions on the presentation of ZK-SNARKs into the updated draft. Due to the limited space, we present an extended discussion in the Appendix, including four examples of using AIRs and further discussion on ZK-SNARKs.\n\n\n## Limit on audit functions\n\nIn principle, any computable function can be used as the audit function. Fairness properties can easily be checked with the same overhead as the copyright audit. We have updated the draft to clarify this point (Section 6).\n\n\n## Experiments on CIFAR-10, MNIST\n\nWe compared our method to semi-honest MPC published this year [1]. Note that this semi-honest MPC is not secure against malicious adversaries. We computed the proving times and costs for the semi-honest MPC and ZkAudit. For the semi-honest MPC, we _only_ measured the egress fees. \n\nCIFAR-10 HiNet\n\n[1]: 100,827 minutes, 5,280,375 GB, 475,234 dollars\n\nZkAudit: 113,311 minutes | 2,417 dollars\n\nMNIST FFFNN\n\n[1]: 626 minutes, 30,820 GB, 2773.8 dollars\n\nZkAudit: 13,226 minutes, 282 dollars\n\n\nOur method is up to 196x cheaper than secure MPC and takes approximately the same amount of time to prove on CIFAR10. Although MNIST is slower, it is substantially cheaper.\n\n[1]  https://www.usenix.org/system/files/sec23fall-prepub-212-rathee.pdf \n\n\n## Test accuracy\n\nAll accuracies reported are the _test_ accuracy after the training procedure. We have clarified this in the draft (Section 5). \n\n\n## Notion of trust\n\nIn this work, trust means that a third party must assume the model provider acts according to the protocol. A malicious adversary may deviate from the protocol. Under mild cryptographic assumptions, ZkAudit does not require the model provider to act honestly as the model provider will be caught if attempting to deviate from the protocol.\n\n\n## Traversal ordering attack\n\nA traversal ordering attack allows a trainer to change the model outputs in undetectable ways by simply changing the order the data is seen at training time [1].\n\n[1] https://arxiv.org/abs/2204.06974 \n\n\n## Salt and dictionary attacks\n\nDenote the weights of the model as W. A salt appends _random_ bits R to W. Then, under mild assumptions on hash functions, H(W || R) is not susceptible to dictionary attacks, since the padding R is random (so the output of the hash will appear random)."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2901/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700092510001,
                "cdate": 1700092510001,
                "tmdate": 1700092559700,
                "mdate": 1700092559700,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GYQ6wWejcw",
                "forum": "bgyWXX8HCk",
                "replyto": "jpwJpHu7Tu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2901/Reviewer_Ww1n"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2901/Reviewer_Ww1n"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their responses that have clarified some of the points I had. Thus, I am willing to upgrade a bit my rating to the paper."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2901/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687861946,
                "cdate": 1700687861946,
                "tmdate": 1700687861946,
                "mdate": 1700687861946,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "oyhdD6hpRM",
            "forum": "bgyWXX8HCk",
            "replyto": "bgyWXX8HCk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2901/Reviewer_TAmM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2901/Reviewer_TAmM"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a new method, ZkAudit, for enabling auditing of deep learning models without revealing data or weights using zero-knowledge proofs. The method is separated into two parts: ZkAudit-T, which can be used to prove that a particular set of weights was the result of training with SGD on a particular dataset; and ZkAudit-I, which can be used to verifiably compute an audit function on the datasets and weights. The methods are all based on ZK-SNARKs. The authors implement several optimizations to make the method work with SGD: rounded division, an improved softmax function, and lowered precision throughout the network. In benchmarking on both an image classification task and a recommender system task, the authors show that ZkAudit can be implemented with relatively low cost compared to other methods for audit questions such as copyright censorship detection."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper\u2019s primary strength is in its identification of an important problem - the reluctance of model owners to share their models for auditing purposes - and the optimizations that the authors implement to improve the method\u2019s performance over existing work. The evaluation on two different kinds of tasks also shows the promise of the method overall."
                },
                "weaknesses": {
                    "value": "The primary weakness of the paper is that, while it shows that the technique has some promise, it is difficult to tell how practical the implementation would be in a real-world setting. The paper shows improvements in cost and performance over existing methods, but there is no comparison to non ZK-based methods. The paper could be improved by showing how far away ZkAudit is from the cost/time it would take if the auditors had access to the model and dataset or even if they were in an SMPC setting as the authors cite early in the paper. While I expect that ZkAudit will be slower or more costly than these other scenarios, it would be useful to know by how much - is it several orders of magnitude? Additionally, I believe the paper needs more discussion of the limitations of the method and how that would implement the practicality of the method. In the next questions section, I have some questions that could help the authors expand on this discussion."
                },
                "questions": {
                    "value": "In the results sections, the authors show the cost of various experiments they ran. Can the paper provide more reference points for how these compare to prior work and alternative methods?\n\nThe fact that the model architecture cannot be shared seems like a major limitation. How does this restrict the types of audit questions and functions that can be shared?\n\nThe method is set up to not reveal the training data and weights, but it does reveal the output of the audit function $F$. Are there ways to limit the amount of information that the audit function reveals? For example, could I pass an audit function that would leak information that the owner would not want to share? Or does the fact that $F$ needs to be implemented as a ZK-SNARK prevent that?\n\nOne very common audit task is to detect demographic disparities in model performance. I think answering this question would be precluded by the fact that model architecture is not shared, but I am curious to hear more discussion on this task and how it fits in with ZK-Audit.\n\nHow would an output privacy method like differential privacy stack up against ZK-Audit in terms of its capabilities and tradeoffs? It would be nice to see some discussion of what ZK-Audit offers over those methods (for example, I imagine that there is no way to verify that a particular model was trained on a particular dataset with differential privacy, even if you released noisy weights and data)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2901/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698623935461,
            "cdate": 1698623935461,
            "tmdate": 1699636233640,
            "mdate": 1699636233640,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tlz9wm1Z44",
                "forum": "bgyWXX8HCk",
                "replyto": "oyhdD6hpRM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2901/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2901/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear reviewer,\n\nThank you for your detailed comments. We have responded to the questions below and have updated our paper to address your questions.\n\n## Cost comparison to secure MPC\n\n_Secure_ MPC is unfortunately slow and expensive. For example, work published this year on semi-honest, secure MPC, which is not even secure against malicious adversaries, takes _100,827 minutes_ and _5,280,375 gigabytes_ of communication to train _on epoch_ on CIFAR10 [1]. The data egress fees alone would cost _$475,233.75_.\n\nWe took the models in [1] and compared the total cost of _just_ data egress fees compared the cost of computing the ZK-SNARK proofs for CIFAR10.\n\nCIFAR-10 HiNet\n\n[1]: 100,827 minutes, 5,280,375 GB, 475,234 dollars\n\nZkAudit: 113,311 minutes | 2,417 dollars\n\nMNIST FFFNN\n\n[1]: 626 minutes, 30,820 GB, 2773.8 dollars\n\nZkAudit: 13,226 minutes, 282 dollars\n\nOur method is up to 196x cheaper than secure MPC and takes approximately the same amount of time to prove on CIFAR10. Although MNIST is slower, it is substantially cheaper.\n\n[1] https://www.usenix.org/system/files/sec23fall-prepub-212-rathee.pdf \n\n\n## Cost comparison to prior work\n\n_No_ prior work for ZK-SNARKs for ML can perform training, since no prior work can compute the softmax function. We are the first method to be able to perform training on modern DNNs.\n\nTo compare the cost of prior work, we removed the softmax and estimated the time for the remainder of the operations. Even without the softmax, the prior work is up to 94x costlier than our proposed method.\n\n\n## Model architecture\n\nThe model architecture must be shared with the verifier. We have clarified this point in the updated draft (Section 3).\n\n\n## Audit function \n\nThe audit function itself must be computed within a ZK-SNARK for full security (this is the purpose of ZkAudit-I). The model provider can choose to participate in an audit. So, if an audit leaks sensitive information (such as the model weights itself), the model provider can choose to not participate in the audit. Moreover, note that the ZK-SNARK can be configured to reveal only whether an audit passes or not, so that only a single bit of information is revealed to the verifier. We have clarified this point in the updated draft (Section 6).\n\n\n## Demographic disparities\n\nComputing demographic disparities _only_ requires access to the outputs of the model, not the model architecture itself. We can compute demographic disparities with the same cost as the copyright audit. \n\nNonetheless, ZkAudit requires the architecture to be shared. We have clarified both points in an updated draft (Section 6).\n\n\n## Comparison to differential privacy\n\nAs you point out, there is no way to verify that a model was trained on a particular dataset with differential privacy. Differential privacy is thus orthogonal to our work and can be even combined with ZkAudit-T."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2901/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700092498138,
                "cdate": 1700092498138,
                "tmdate": 1700092498138,
                "mdate": 1700092498138,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vXJNdufx71",
            "forum": "bgyWXX8HCk",
            "replyto": "bgyWXX8HCk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2901/Reviewer_uRaA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2901/Reviewer_uRaA"
            ],
            "content": {
                "summary": {
                    "value": "The work describes methods with which a model can be trained in a manner that can later be\nscrutinized in a zero-knowledge manner. That is, the training (and inferences) results in a proof\nwith which the trainer can prove to verifiers (presumably users who want to perform inferences but\ncannot have the model itself) any desired property about the data, training, (and inference) they\nmight be interested in like presence of undesired data in the training dataset, without revealing\nanything else about the training data or model parameters. Importantly, there are no trust\nassumptions with regards to the prover. To achieve this (with reasonable performance), the work\nintroduces number representations with configurable precision/scale to be used in the ZK-SNARK\napproach which are required for the backwards network passes in the training process. The paper\nalso describes a performant means of computing softmax.\n\nExperimental evaluations using relatively small recommender and image classification models are\nthen presented showing: (1) scalability of the approach in terms of the numerical representation\nprecision, (2) accuracy/cost tradeoffs where the cost is a function of numerical precision, and (3)\nrelative loss of precision as compared to typical 32-bit floating point models (i.e. baselines).\nThree types of queries or \"audits\" are also demonstrated alongside their estimated costs which are\nsaid to be within \"reason\" though I cannot tell what sorts of costs are to be expected."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ Work makes it possible to audit both training and inference as well as any audit-relevant\n  property of data and the trained model without revealing either.\n\n+ Quite general auditing capabilities. All three auditing examples are compelling."
                },
                "weaknesses": {
                    "value": "- Novelty/contribution may be limited (or unclearly stated). Backwards pass work includes numerical\n  representation adjustments and a better implementation of softmax. The structure of the paper\n  thus makes it looks like these two bits of work were the missing pieces of zk-SNARK work that\n  prevented them from being realistically applied to SGD. These are presumed to be \"optimizations\"\n  as in the related work statement:\n\n    \"All of the work we are aware of focuses on optimizing inference, so all of this work omits the\n     softmax computation and does not optimize the backward pass. In this work, we leverage ideas\n     from inference to optimize the forward pass but show how to compute full SGD in ZK-SNARKs and\n     optimize the softmax.\"\n\n  This suggests that while other works can perform SGD, its backwards pass, and/or softmax, but\n  just not efficiently. The title of the work and other statements, however, suggests that this is\n  the first work that can handle these computations at all.\n\n  Further, the contributions in the numerical representations do not seem significant and softmax\n  may be even omitted from model training (or inference) without significant changes to training or\n  inference. There thus appears some incongruity with the stated contribution and methods achieving\n  those contributions.\n\n  Suggestion: clarify whether the work presents the first verification systems that includes\n  data/model training and that to achieve this within the frameworks from prior works, only changes\n  to numerical representation (and softmax) were needed. Alternatively, if there was more necessary\n  to achieve the goal, describe them in more detail. Alternatively, it may be that prior works\n  already achieved the goal with less performant system in which case the title of the work and\n  contributions need to be clarified. In this last case, comparisons of accuracy and efficiency\n  need to be provided (as in Figures 1, 2).\n\nSmaller thing / suggestions.\n\n- Model parameters are not revealed to verifiers but model architectures are. This is noted but the\n  abstract is unqualified, please adjust the abstract to make this clear.\n\n- Some tabular results do not state which operation they are measuring and whether it is of a\n  single instance of that operation (for inference) or multiple / entire dataset. Please include\n  this.\n\n- For prior techniques which do not handle softmax at all or well, consider including versions of\n  models without softmax alongside the softmax ones. By this I don't mean to merely use an existing\n  softmax implementation as done in Section 5.3, but instead remove the entire softmax operation\n  from the model.\n\n- Table 3: include units in table or description.\n\n- Some results that depend on dataset size could be better presented in terms of cost per instance\n  (Copyright audit is one example). The currently noted \"$108\" is not\n\n- Please include a bit more how operations are implemented via AIR in its background section."
                },
                "questions": {
                    "value": "- Question A: With regards to the weakness noted in the weaknesses section, please provide noted\n  clarifications.\n\n- Question B: How does this work compare: Efficient Representation of Numerical Optimization\n  Problems for {SNARKs}. Angel et al. 2022. I also see several papers in federated learning that\n  leverage SNARKs for enhancing trust. If models involving softmax or similar steps to the\n  presently-experimented ones were used, I imagine they would have similar accuracy problems. Are\n  their solutions applicable?\n\n- Question C: Can the numerical representation work described in the paper by applied to other\n  verified computation problems beyond model training?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2901/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2901/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2901/Reviewer_uRaA"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2901/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699075264921,
            "cdate": 1699075264921,
            "tmdate": 1699636233566,
            "mdate": 1699636233566,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Uugqxru4Oc",
                "forum": "bgyWXX8HCk",
                "replyto": "vXJNdufx71",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2901/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2901/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear reviewer,\n\nThank you for your detailed comments. We have addressed them in an updated version of the paper and summarized our changes along with answers to your questions below.\n\n## Requiring the softmax\n\nAll methods we are aware of for doing multi-class classification require performing a complex non-linearity such as a softmax or multi-class hinge. Thus, _no_ prior work is able to perform training. For example, it is unclear how to perform even the exponential function in the prior work for ZK-SNARKs for ML.\n\nInference can be done by removing the softmax layer and taking the argmax of the logits instead, which is what prior work does. ZkAudit-I leverages prior work. We have made these points more clear in the paper.\n\n\n## Comparison to Angel et al (2022)\n\nThe \u201cnumerical optimization problems\u201d Angel et al (2022) address are constrained optimizations via linear programming and semidefinite programming. Neither of these is applicable to DNN training, which we focus on. In fact, Angel et al do not show how to perform the forward pass or backward pass for DNNs. We have included a discussion in the related work section.\n\n\n## Does our work apply to other verified computation problems?\n\nYes, our work applies to other verified computation problems. Our work is most applicable to optimization problems that need to perform complex non-linear functions as part of their optimization (e.g., the softmax, exponentials). \n\n\n## Assorted suggestions\n\nWe have addressed your smaller suggestions:\n1. We have updated the abstract to mention model architectures are revealed.\n2. We updated table captions to mention if the results were for a single operation or for the entire dataset.\n3. We do compare our work against prior work estimates when removing the softmax. However, training would not work without the softmax.\n4. We have included units in Table 3.\n5. We have clarified how the audits scale with the size of the dataset. \n6. We have included more information about how operations are implemented within the AIR in the background section."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2901/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700092233448,
                "cdate": 1700092233448,
                "tmdate": 1700092233448,
                "mdate": 1700092233448,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]