[
    {
        "title": "Non-Vacuous Generalization Bounds for Large Language Models"
    },
    {
        "review": {
            "id": "waweZBUyak",
            "forum": "GY1fKFXG5i",
            "replyto": "GY1fKFXG5i",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5752/Reviewer_GeY3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5752/Reviewer_GeY3"
            ],
            "content": {
                "summary": {
                    "value": "The authors derive generalization bounds for auto-regressive\nlanguage models pre-training combining four ingredients:\n\n1.  a non-uniform hypothesis prior in the PAC-bound\n2.  the intrinsic dimension to bound the complexity of the neural model\n3. a form of label smoothing (prediction-smoothing) for bounding the\nnegative log-likelihood\n4. subsampling to reduce the cost\nof empirical risk estimation. \n\nThey also propose to combine LoRA with\nsubspace fine-tuning for finding the intrinsic dimension more\nefficiently. The empirical part demonstrates their generalization bounds by\nperforming experiments on GPT-2-style models with less than 200M parameters."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. A simple and elegant proposal, prediction smoothing, to accomodate the unbounded NLL loss in deriving generalization bounds.\n\n2. A novel proposal that combines LoRA with subspace training for pre-training on a lower dimensional subspace.\n\n3. An empirical verification of the effect that text structure has on generalization bounds."
                },
                "weaknesses": {
                    "value": "1. The paper seems to lack a thorough comparison to previous theoretical work that\n  highlights the novel theoretical contributions. For example, the cited\n  **Aghajanyan et. al (2020)** proves a generalization bound for\n  classifiers that have been obtained by fine-tuning a pre-trained\n  language model. Their bound already relies on intrinsic dimension\n  (Ingredient 2) to reduce the hypothesis space and what seems to me a version of Ingredient 1 for compression based on **Arora et al**: *Stronger Generalization Bounds for Deep Nets via a Compression Approach*. Ingredients (1, 2) and a version of Ingredient (4) seem to be present in **Lofti et. al**.\n  \n* Exposition could be improved if the main generalization results\n  were stated as a Theorem with a discussion of the proof ingredients.\n  \n* Experiments are carried out on small model sizes (from the Appendix it seems\n  < 200M). It is then unclear if these findings would generalize to\n  large LMs, e.g. to the > 10B scale. The bounds for NLL seem\n  to improve in the tested scales, but it is unclear how these are related\n  to the generalization abilities in the few-shot or instruction following\n  capabilities that large LMs exhibit."
                },
                "questions": {
                    "value": "My initial rating inclines towards rejection because I have some\nconcerns regarding:\n\n1. the novelty of the bounds and the theoretical arguments wrt to previous work\n2. the empirical part seems limited to small model sizes\n3. the benefits of SubLoRA in downstream applications are not clear.\n\nI am leaving some questions that would help me to improve\nmy assessment and in case increase the initial rating.\n\n**Questions**:\n\n1. Could you highlight the novel contributions and comparison to the work discussed in Weaknesses 1?\n\n2. What was the biggest model you trained and using how many tokens?\n\n3. In Table 1 is it the case that Subspace only is enough to achieve non-vacuous generalization bounds?\n\n 4. What is the tradeoff between SubLoRA and standard pre-training?\n \n5. If a pre-trained model exhibits few-shot capabilities, does its counterpart that was pre-trained with SubLoRA exhibits the same\n    abilities?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5752/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5752/Reviewer_GeY3",
                        "ICLR.cc/2024/Conference/Submission5752/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5752/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698404441677,
            "cdate": 1698404441677,
            "tmdate": 1700638001435,
            "mdate": 1700638001435,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ibse7ZLhTi",
                "forum": "GY1fKFXG5i",
                "replyto": "waweZBUyak",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5752/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5752/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer GeY3 1/2"
                    },
                    "comment": {
                        "value": "We thank you for your detailed and thoughtful feedback. First, we address the comparison with prior work and clarify which elements of our bounds are novel (including how they relate to other methods) and which are not.\n\nWe would first like to point out that ingredients (1) and (2), i.e., using a non-uniform hypothesis prior and the intrinsic dimensionality to compress neural networks, are not novel to our paper, and we build on these techniques as most closely done in Lotfi et al. (2022) [1], but these techniques have been used to differing extents in other papers such as in [2, 3, 4]. We note that Aghajanyan et. al (2020) [3] does not actually prove any new bounds, or evaluate any existing bounds on LLMs, but instead highlights how intrinsic dimensionality could be used for such a purpose. We have made an effort to clarify the relation with these works in the updated draft.\n\nIn terms of the novel ingredients of our bounds, we would like to emphasize (3,4) that you identify as well as (5) the overall approach to handling the non-IID token level structure, and (6) the use of LoRA in the compressed parametrization. (3) is a novel approach, and other existing approaches for handling unbounded objectives are not well suited to LLMs. For example, in [5] the authors introduce a hypothesis dependent range $\\sup_x R(h,x) \\le K(h)$ for some function $K(h)$, then $K(h)$ can essentially be used in place for the bounded range. However for neural networks, $K(h)$ grows exponentially in the number of layers of the network and relates to the Lipschitz constant for a fixed network, which is far too large to be making bounds on large networks like LLMs. We have added discussion of this and other theoretical techniques for handling unbounded objectives, explaining why they are not well suited to LLMs.\n\nYou state that ingredient (4) exists in some form in Lotfi et al. (2022), however this is not the case. Perhaps some confusion arises in the case of the data dependent bounds which reserve a fraction of the training data for computing a data dependent prior, however this is of a very different nature than the subsampling bounds which we employ here. For the full training dataset of size $m$, our subsampling bounds allow us to compute the empirical risk on a subsample of size $n<<m$ while maintaining the dominating complexity term $\\frac{\\log 1/P}{2m}$ using $m$ from the full dataset for a data independent bound. In contrast, for the data dependent priors a small fraction $(m-n)$ is reserved for training the prior, but the bound complexity scales as $\\frac{\\log 1/P}{2n}$ because only $n$ are considered as the training data points for adapting the prior to posterior. For this reason in data dependent bounds, $n$ should be chosen not much smaller than $m$ so as to preserve the tightness of the bound, and these subsampling bounds serve an entirely different purpose to our subsampling bounds (which are data independent). The subsampling bounds that we introduce reduce the bound evaluation time dramatically from *3 days on a 8 GPUs in parallel* to *45 minutes on a single GPU*.\n\nBelow, we address your other questions and comments."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5752/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700522753367,
                "cdate": 1700522753367,
                "tmdate": 1700522835894,
                "mdate": 1700522835894,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rflBlf9znV",
                "forum": "GY1fKFXG5i",
                "replyto": "waweZBUyak",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5752/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5752/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer GeY3 2/2"
                    },
                    "comment": {
                        "value": "**Model scale and few shot capabilities:**\n\nIn this work, we focus on constructing the first non-vacuous bounds for LLMs. We have added additional results for larger variants of GPT-2 of sizes of size **354M** (GPT-2 medium), **458M**, **773M** (GPT-2 large), and **849M** parameters; we report the results below. The biggest model we trained previously was nanoGPT, also known as GPT small, of size 124M parameters trained on the OpenWebText dataset that contains about 9B tokens (9,035,582,198). However, these are still far smaller than the most capable LLMs. Training LLMs of 10B or larger requires significant computational resources, not to mention the tremendous engineering and infrastructure effort required. While we do believe that constructing bounds for such large models is valuable, our work is merely the first effort at constructing non-vacuous bounds for LLMs and it may be prudent to await several advancements in bound construction that are likely soon to come before expanding such an investment. We believe that our paper can lay the groundwork for such later improvements. Most of the zero, few-shot, and instruction-following capabilities of LLMs don\u2019t emerge until model sizes significantly larger than GPT-2. Thus while the questions of how generalization bounds relate to these capabilities are definitely of interest, they cannot straightforwardly be answered for models this size, and we are optimistic about addressing these questions in future work.\n\n**Bounds for larger models:**\n\nNote that for the new experiments involving larger models, our approach yields **non-vacuous bounds**, even for models with **nearly a billion parameters**. Moreover, we see that the smallest model, where we previously performed experiments and tuned our hyperparmeters, actually achieves the worst bound on bits per dimension.  \n\nIt is important to note that due to time and computational constraints, we pretrain these models with SubLoRA only for a **single hyperparameter setting** in contrast to the 124M model for which we did a thorough hyperparameter sweep; we also did fewer optimization steps for larger models given the time constraints. Therefore, it is likely that the tightest empirically achievable bounds are much stronger for the new large models than what we report in the table below.  The main conclusions that we draw from these results are: (1) our approach extends naturally to much larger language models; (2) it is possible to achieve tighter bounds as we increase the size of the model.\n\n| Model Size| Bits per Dimension | Top-1 Error (%) | Top-10 Error (%) | Top-100 Error (%) | \n| --- | --- | --- |  ---  | --- |  \n| 124M params. (GPT-2 small) |   12.09  | 96.17   |   78.18     |     58.72         |                 \n| 354M params (GPT-2 medium)  | 12.02 |   96.62  |   78.13  |    58.86|            \n| 458M params | 11.99  | 96.31 | 77.96  | 58.65  |            \n| 773M params (GPT-2 large) | 12.08   | 97.60  |  79.71 |    59.98 |            \n| 849M params  |12.04   | 96.55  | 78.40 | 58.86 |          \n\n\n**Subspace only is enough to achieve non-vacuous bounds in table 1:**\n\nThat is correct. When combined with our ingredients (3,4,5), subspace-only bounds (aka 1,2) are sufficient to achieve non-vacuous bounds in many cases. However, adding SubLoRA (6) substantially improves these bounds.\n\n**Tradeoff between SubLoRA and standard pre-training:**\n\nSubLoRA converges much faster in practice than standard pretraining. While there are no memory gains, we effectively have a more compressed delta between the randomly initialized weights and the final model, leading to tighter bounds. \n\nThank you again for your review and suggestions. We believe your feedback has improved our paper. We made a significant effort to run additional experiments and address your questions and would appreciate it if you would consider raising your score in light of our response.  Please let us know if you have any additional questions we can address.\n\n____________\nReferences:\n\n[1]  Lotfi, S., Finzi, M., Kapoor, S., Potapczynski, A., Goldblum, M. and Wilson, A.G., 2022. PAC-bayes compression bounds so tight that they can explain generalization. Advances in Neural Information Processing Systems, 35, pp.31459-31473. \n\n[2]  Zhou, W., Veitch, V., Austern, M., Adams, R.P. and Orbanz, P., 2018. Non-vacuous generalization bounds at the imagenet scale: a PAC-bayesian compression approach. arXiv preprint arXiv:1804.05862. \n\n[3] Aghajanyan, A., Zettlemoyer, L. and Gupta, S., 2020. Intrinsic dimensionality explains the effectiveness of language model fine-tuning. arXiv preprint arXiv:2012.13255. \n\n[4] Arora, S., Ge, R., Neyshabur, B. and Zhang, Y., 2018, July. Stronger generalization bounds for deep nets via a compression approach. In International Conference on Machine Learning (pp. 254-263). PMLR.\n\n[5] Haddouche, M., Guedj, B., Rivasplata, O. and Shawe-Taylor, J., 2021. PAC-Bayes unleashed: Generalisation bounds with unbounded losses. Entropy, 23(10), p.1330."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5752/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700523198702,
                "cdate": 1700523198702,
                "tmdate": 1700523284301,
                "mdate": 1700523284301,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BAJlNckw6n",
                "forum": "GY1fKFXG5i",
                "replyto": "rflBlf9znV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5752/Reviewer_GeY3"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5752/Reviewer_GeY3"
                ],
                "content": {
                    "title": {
                        "value": "Reviewer Reply"
                    },
                    "comment": {
                        "value": "Thanks. I raise my score by one point in light of the additional experiments and comparison to previous work. I agree with the reviewer TUxG assessment that more novelty would be needed for a higher score."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5752/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700637948088,
                "cdate": 1700637948088,
                "tmdate": 1700637948088,
                "mdate": 1700637948088,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "CeKoiHxrtn",
            "forum": "GY1fKFXG5i",
            "replyto": "GY1fKFXG5i",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5752/Reviewer_DsFt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5752/Reviewer_DsFt"
            ],
            "content": {
                "summary": {
                    "value": "This paper derives a compression bound that is valid for the unbounded log-likelihood loss using\nprediction smoothing, and we extend the bound to handle subsampling, accelerating bound computation on massive datasets. Using this approach, we find that larger models have better generalization bounds and are more compressible than\nsmaller models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This paper provides the first non-vacuous generalization bounds for LLM\npertaining by using extreme levels of model compression. The bounds suggest that compression\nbounds present new possibilities for understanding how and why language models generalize.\n2. The experiments verify their theoretical results."
                },
                "weaknesses": {
                    "value": "None"
                },
                "questions": {
                    "value": "None"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5752/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5752/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5752/Reviewer_DsFt"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5752/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698582789717,
            "cdate": 1698582789717,
            "tmdate": 1699636603595,
            "mdate": 1699636603595,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5BDpkZycpl",
                "forum": "GY1fKFXG5i",
                "replyto": "CeKoiHxrtn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5752/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5752/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer DsFt"
                    },
                    "comment": {
                        "value": "Thank you for your supportive feedback; we appreciate it! Inspired by all the reviews, we have improved the clarity of our paper and run additional experiments to extend our generalization bounds from the nanoGPT model of size **124M** parameters (GPT-2 small) to much larger GPT-2 variants. We also obtained classification error bounds for fine-tuning tasks on the GLUE datasets [2], highlighting the generalization implications of pretraining LLMs.\n\n**Generalization bounds for much larger models:**\nWe use SubLoRA to obtain generalization bounds for much larger variants of GPT-2 of sizes **354M** (GPT-2 medium), **458M**, **773M** (GPT-2 large), and **849M** parameters.  Note that our approach yields non-vacuous bounds, even for models with nearly a billion parameters. Moreover, we see that the smallest model, where we previously performed experiments and tuned our hyperparmeters, actually achieves the worst bound on bits per dimension.  \n\nIt is important to note that due to time and computational constraints, we pretrain these models with SubLoRA only for a **single hyperparameter setting** in contrast to the 124M model for which we did a thorough hyperparameter sweep; we also did fewer optimization steps for larger models given the time constraints. Therefore, it is likely that the tightest empirically achievable bounds are much stronger for the new large models than what we report in the table below.  The main conclusions that we draw from these results are: i. our approach extends naturally to much larger language models; ii. it is possible to achieve tighter bounds as we increase the size of the model.\n\n| Model Size      | Bits per Dimension | Top-1 Error (%)  |  Top-10 Error (%)   | Top-100 Error (%) | \n| ---                                                 | ---         | ---             |  ---                 | ---        |  \n| 124M params. (GPT-2 small)    |   12.09  | 96.17   |   78.18     |     58.72         |                 \n| 354M params (GPT-2 medium)   |     12.02       |   96.62       |   78.13           |    58.86         |            \n| 458M params                               |     11.99        |     96.31      |      77.96        |     58.65       |            \n| 773M params (GPT-2 large)        |    12.08      |    97.60       |     79.71        |    59.98         |            \n| 849M params                                |    12.04   |    96.55      |    78.40      |   58.86     |          \n\n**Generalization bounds for downstream tasks:** \n\nFor fine-tuning experiments, we consider two binary classification tasks on the QQP and Cola datasets from GLUE [2]. We contrast the bounds that we obtain for fine-tuning a pretrained GPT-2 small model [3], to training from scratch the same model on the two datasets. For both the pretrained and randomly initialized GPT-2 large models, we fine-tune using SubLoRA with rank = 8 and intrinsic_dim=30000 and perform fine-tuning. We run the fine-tuning for 5 epochs with a learning rate of 2e-5. We obtain the following non-vacuous classification accuracy bounds for both QQP and Cola: \n\n| Dataset | Error Bound for pretrained LLM (%) | Error Bound for trained from scratch LLM (%)   | Random Guess (%)  |\n| ---       | ---          | ---        |  ---         | \n| QQP     |    **35.27**      |     71.72      |     50       | \n| Cola     |     **38.89**    |    53.42    |    50    | \n\nAs we can see, using pretrained LLMs leads to tighter, non-vacuous bounds in contrast with training from scratch. Our bounds thereby provide a theoretical certification on the value of pretraining LLMs."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5752/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700522697392,
                "cdate": 1700522697392,
                "tmdate": 1700522697392,
                "mdate": 1700522697392,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "NYQRjGgVmh",
            "forum": "GY1fKFXG5i",
            "replyto": "GY1fKFXG5i",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5752/Reviewer_TUxG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5752/Reviewer_TUxG"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors aim to establish non-vacuous generalization bounds for large language models (LLMs) by employing a compression-based approach. The challenges they address include (1) dealing with the non-iid nature of tokens, (2) handling unbounded loss, and (3) managing extremely large model parameters. To tackle these issues, the authors propose specific solutions: for (1), leveraging entire sequences to treat tokens as iid; for (2), introducing a smoothed model to manage unbounded loss; and for (3), developing SubLoRA, a novel technique that combines LoRA and subspace training during the training process. Notably, the authors demonstrate the non-vacuous nature of the derived bound for GPT-2.\n\nIn consideration of the fact that this represents the first non-vacuous generalization bound in the context of Large Language Models (LLMs), I have assigned a moderately favorable score. It's important to note that I have not conducted an exhaustive investigation to confirm whether this is indeed the inaugural non-vacuous bound, and I am relying on the authors' assertion in this regard.\nMy reasons for not awarding a higher score can be attributed to the following factors:\n\n1. I hold the perspective that the existence of vacuous bounds in LLMs during the pretraining phase might not be of paramount significance.\n2. The authors primarily synthesize existing techniques rather than introducing fundamentally novel methods. It should be acknowledged that this does not necessarily translate to incremental progress since discovering these techniques is not a straightforward endeavor. However, a higher rating is withheld due to the absence of groundbreaking or distinctly tailored contributions to LLMs."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The authors pioneer the introduction of a non-vacuous generalization bound for LLMs in the pretraining phase.\n2. The SubLoRA method, which amalgamates LoRA and subspace training, enhances model compressibility.\n3. The paper highlights and addresses various challenges in deriving generalization bounds for LLMs.\n4. Experimental verification of the proposed bounds adds credibility to the research."
                },
                "weaknesses": {
                    "value": "1. While the authors emphasize the importance of non-vacuous bounds during the pretraining phase, a more detailed justification of its significance *within the LLM context* would enhance the paper's impact. At least I am not sure that for LLM, generalization in the pretraining phase is such important. \n2. Given the point 1, I wish to see some novel techniques. However, it seems that the techniques in this paper are not very novel. The methods presented in this paper largely combine existing techniques (e.g., SubLoRA). \n3. The paper claims that tokens exhibit non-iid behavior but resolves this issue by considering entire sequences, which might be considered a somewhat coarse approach.\n\nThe three points stop me from giving a higher score."
                },
                "questions": {
                    "value": "See weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5752/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698756129341,
            "cdate": 1698756129341,
            "tmdate": 1699636603489,
            "mdate": 1699636603489,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oUX0fYEJ4b",
                "forum": "GY1fKFXG5i",
                "replyto": "NYQRjGgVmh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5752/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5752/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer TUxG"
                    },
                    "comment": {
                        "value": "Thank you for your supportive, constructive, and detailed feedback. We address your comments and questions below. \n\n**The value of non-vacuous bounds for LLMs:**\n\nAs we mentioned in the general comment, obtaining non-vacuous bounds for LLMs is of paramount significance given the debate about their ability to generalize to unseen data. While empirical non-vacuous bounds in the literature and in our work are looser than the validation error, their existence tells us that the model\u2019s performance is not trivial in expectation for _any_ data coming from the same distribution as the training data. This theoretical guarantee settles the debate about LLMs\u2019 ability to generalize. Another fundamental question for the ML community is whether bigger LLMs are more likely to merely memorize their training samples and not perform any meaningful generalization. We show using our non-vacuous bounds that larger models are _in fact_ more compressible and lead to better bounds. Finally, our work is merely the first step towards a deeper investigation of the generalization capabilities of LLMs through the lens of generalization bounds, and we expect future work to uncover more insights, in the same fashion Lotfi et al. (2022) did for vision.\n\n **Fundamentally novel contributions:**\n\nWe want to clarify that our work *does* provide contributions that are *distinctly tailored* to LLMs. While we were able to bound the top-1 error for next token prediction using existing PAC-Bayes bounds, we strived to design generalization bounds that extend to the BPD continuous and unbounded loss since it is the metric of interest in LLMs. Our subsampling bounds are also specifically designed to accommodate for the massive datasets that LLMs are trained on. In fact, we reduce the bound evaluation time from *3 days using 8 GPUs in parallel* to *45 minutes using a single GPU*. While SubLoRA is a combination of existing methods, it comes from our novel observation that pretraining using LoRA on the last fully connected layer in addition to the attention layers \u2013 used exclusively for LoRA fine-tuning \u2013 leads to a non-trivial performance. Another major challenge in applying existing bounds to LLMs lies in the autoregressive nature of LLMs, and how the tokens themselves are not i.i.d. To address this challenge, we first observed that unlike some models where sequences draw on the previous history that lies outside the context window, such as with Transformer-XL or Mistral-7B, the GPT2 model takes in these sequences without considering any previous history. Then, we made the choice to divide the training data into *non-overlapping* sequences of size equal to the context length and randomly select from those sequences. The bounds that we obtained for LLMs in this work would not have been possible to achieve without addressing each of these challenges. \n\n**Significance of the results with the I.I.D assumption:**\n\nWe believe that our bounds are still of practical significance and are informative about generalization despite considering entire sequences to satisfy the I.I.D assumption.In fact, the bits-per-dimension for a given sequence can be computed as the average error for each token in the sequence given previous tokens, where the token error here refers to the negative log-likelihood $\\mathrm{BPD}(h, X):= -\\log_2 p_h(X)/L = - \\sum_i^L \\log_2 p_h(x_i|x_{<i}) /L$. Therefore, an upper bound on the expected BPD error still reflects a guarantee on the average performance of the model at the token level, conditioned on previous tokens within independent sequences, and is a common quantity of interest in language modeling. \n\nThank you again for your review and suggestions. We hope that we were able to address all of your questions. We also ran new experiments that we detail in the general comment, including non-vacuous generalization bounds for very large models with up to 849 million parameters and non-vacuous generalization bounds for LLMs fine-tuned on downstream benchmark tasks. Please let us know if you have any additional questions we can address."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5752/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700522642444,
                "cdate": 1700522642444,
                "tmdate": 1700527504188,
                "mdate": 1700527504188,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "efGCvd9FRv",
                "forum": "GY1fKFXG5i",
                "replyto": "oUX0fYEJ4b",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5752/Reviewer_TUxG"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5752/Reviewer_TUxG"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "I read the response carefully and keep my score unchanged. \n\nI agree that the facts the authors provide in reponse are correct. I agree that the techniques are somehow novel, and I agree that deriving the non-vacuous bound in LLM is important. But I still hold the opinion that this is not novel enough for me to give a higher score. Thank you again for your response."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5752/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700536609292,
                "cdate": 1700536609292,
                "tmdate": 1700536609292,
                "mdate": 1700536609292,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "iAVimBweyo",
            "forum": "GY1fKFXG5i",
            "replyto": "GY1fKFXG5i",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5752/Reviewer_9VJi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5752/Reviewer_9VJi"
            ],
            "content": {
                "summary": {
                    "value": "The paper aims to compute non-vacuous generalization bounds that apply to LLM pre-training. The authors employ a compression-based PAC-Bayes approach to achieve this goal. To obtain good compression they employ both LoRA and subspace training. Further, they apply a trick to bound the prediction probability of tokens so that the NLL becomes bounded, making it amenable to standard PAC-Bayes analysis. Finally, their experimental results show that their approach outperforms state-of-the-art generalization bounds."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The authors compute non-vacuous generalization bounds for LLM which can be challenging. \n- The paper is well-structured and the language is good. \n- The experimental results seem to outperform the current state of the art."
                },
                "weaknesses": {
                    "value": "- While the paper is well-written for the most part, some parts are confusing. \n- The technical contribution is moderate on the conceptual part is fair, however, engineering a working non-vacuous bound can be challenging."
                },
                "questions": {
                    "value": "- In Equation (2) it seems that LoRA is applied to $Pw$, it is not clear to me how that can be implemented, in particular, how the weights can have the forms $Pw$ and $UV$ simultaneously. It might, however, be just a typo and the equation should be $P \\cdot LoRA(w)$. \n- In section 4.4, it is not clear why we can assume that $\\hat{R}_{\\sigma_{i}}(h)$ are independent. In general, taking a random sample of a sequence does not make such a random sub-sample independent.\n\nA minor typo:\n$Q_1, Q_2 \\sim \\mathcal{N}(0,1)^{\\sqrt{D}\\times d}$ ----> $Q_1, Q_2 \\sim \\mathcal{N}(0,1)^{\\sqrt{D}\\times \\sqrt{d}}$"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5752/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5752/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5752/Reviewer_9VJi"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5752/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698840173309,
            "cdate": 1698840173309,
            "tmdate": 1699636603364,
            "mdate": 1699636603364,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XnJN3e86xJ",
                "forum": "GY1fKFXG5i",
                "replyto": "iAVimBweyo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5752/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5752/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 9VJi"
                    },
                    "comment": {
                        "value": "Thank you for your feedback. According to your feedback and feedback from the other reviewers, we have made updates to the PDF to help clarify the construction of the SubLoRA parametrization, the IID assumption requirements in both the full and subsampling bounds, and small typos such as the one you point out for the matrices $Q_1$ and $Q_2$.\n\n**SubLoRA implementation:** \n\nFor equation (2) and SubLoRA, the expression is not a typo. In the forward pass of the model, first the matrix P is applied to the reduced dimension weights w to project to a space with dimension equal to the number of LoRA parameters. These LoRA parameters are in the form of biases and matrices to be multiplied together to form the low edits to the random initialization. If $v=Pw$, $\\mathrm{LoRA}(v)$ reshapes $v$ into a list of these biases and low rank factors, multiplies the factors and then reshapes the result back into a vector (with ordering so that when used by the network the biases and weight matrices will be in the right places).\n\n**Subsampling bounds:** \n\nIn Section 4.4 with the subsampling bounds, the essential point is that we only require that $\\hat{R}\\_{\\sigma(i)}(h)$ for different $i$ are independent when conditioned on $X$. In this setting, the only randomness in $\\hat{R}\\_{\\sigma(i)}(h)$ is over $\\sigma(i)$. With this in mind, we can rewrite the quantity $\\hat{\\hat{R}}$ as merely the sum of $n$ randomly chosen elements from the set of deterministic elements $\\{ c_i \\}\\_{i=1}^m$ where $c_i:=\\hat{R}\\_{\\sigma(i)}(h)$. This random choice can be with replacement (to strictly be independent) or without replacement (Hoeffding inequalities also apply to this setting).\n\n**Technical contributions of our paper:** \n\nAs we mentioned in the general responses, we make several technical contributions to address challenges that are specific to large language models. First, the loss function of interest in LLMs is the number of bits-per-dimension, which is neither bounded nor discrete. Therefore, the PAC-Bayes bounds used by Lotfi et al. (2022) are no longer valid in this setting. In contrast with other generic approaches for handling unbounded objectives, our bounds can be practically applied to the BPD objective of LLMs. Moreover, the bound evaluation for the massive datasets that LLMs are trained on is very computationally expensive. For instance, it takes about 3 days to evaluate our bounds on the OpenWebText dataset using 8 GPUs in parallel. The subsampling bounds that we propose in this work bring down that evaluation time to 45 minutes on a single GPU, while paying a very small penalty on the tightness of the bound. Besides these theoretical contributions, we also provide a practical method to achieve non-linear subspace compression for LLMs, while noting from Figure 1 and Table 1 that LoRA alone is not sufficient to achieve non-vacuous top-1 error bounds. \n\nAs you highlighted, engineering a working non-vacuous bound can be challenging. In particular, we had to choose our instances to correspond to entire non-overlapping sequences in order to preserve the I.I.D assumption and to select an optimal subset of layers to apply SubLoRA to, which involved both the attention layers and the final fully connected layer. We believe that our work is highly significant to the machine learning community, as it provides the first theoretical certification that large language models are capable of generalization beyond their training data, and that as their size increases, they become more compressible and lead to better bounds, in line with observed performance benefits of bigger models. \n\nThank you again for your review and suggestions. We made a significant effort to address your questions and also have run new experiments that we detail in the general comment, including non-vacuous generalization bounds for very large models with up to 849 million parameters and non-vacuous generalization bounds for LLMs fine-tuned on downstream benchmark tasks. We would appreciate it if you would consider raising your score in light of our response. Please let us know if you have any additional questions we can address."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5752/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700522364426,
                "cdate": 1700522364426,
                "tmdate": 1700529144106,
                "mdate": 1700529144106,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RGdAVjijKh",
                "forum": "GY1fKFXG5i",
                "replyto": "XnJN3e86xJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5752/Reviewer_9VJi"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5752/Reviewer_9VJi"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thank you very much for your hard work and the more experiments. \nI acknowledge that clarification on the SubLoRA implementation is very useful to understanding the technique. Thank you for that.\n\nHowever, I still believe the argument on the IID sub-sampling is still inaccurate. Theorem 1 require independence in $X$. The argument of conditioning on $X$ does not apply here. The argument in the appendix requires the application of Theorem 1 first to allow conditioning on $X$, However, Theorem 1 can not be applied without independence assumption on $X$.\n\nBased on this, I will keep my score."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5752/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659025092,
                "cdate": 1700659025092,
                "tmdate": 1700659025092,
                "mdate": 1700659025092,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "s9ciWh5QAI",
            "forum": "GY1fKFXG5i",
            "replyto": "GY1fKFXG5i",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5752/Reviewer_dFjh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5752/Reviewer_dFjh"
            ],
            "content": {
                "summary": {
                    "value": "Low Rank Adaption where parameter updates $\\Delta W$ is taken to be a product of two lower rank matrices that can be learnt; is combined with subspace training that uses  a projection to/from lower dimension subspace and arithmetic coding; to propose a combination of the two suitable for LLMs. Under i.i.d. assumption, risk generalization bounds are derived for LLMs on token prediction task. These bounds (that depend on empirical risk) are computed for several methods, with the bounds, and the empirical performance is shown to be best for the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Compression bounds obtained with a neat smoothing trick\n- Code provided and also one that does not require industrial grade resources (but see Questions)\n- Very nicely written and presented\n- Improves upon previously reported bounds\n- Context of research contributions and related work reviewed very well\n- A bound is given where the empirical risk can be computed over a small subsample of the dataset\n- Bounds computed for some  methods, bounds best for SubLoRA"
                },
                "weaknesses": {
                    "value": "**Task and Error**\n- I would suggest better clarity about what the task is (token prediction) early on in the paper and also in the abstract and methodology section.\n- Also perhaps more clarity about errors. When it is said top-1 error, do you mean the worst sequence, or the worst token? \n\n**I.I.D. Assumption**\n\t- i.i.d assumption is a very strong assumption\n\t- but then a workaround is found which considers sequences not tokens, but then it's unclear how the parameter L is chosen"
                },
                "questions": {
                    "value": "**Artifact**\n- It seems the provided code is running the glue suite, and the code involves LoRA, but not subLoRA? And the other folder seems to be from nanoGPT?\n\t- Glue suite seems to be unrelated to the task in paper: token prediction?\n- At first because of the copyright line in the provided file, I was going to make a comment how it seems double blindness of the review is compromised as it seemed the submission was from the Hugging Face Team, but then I realized it is a minor modification of the same file from the Hugging Face Repository\n- Can you please check if the provided code is what you intended to submit? And let me know if I am missing something? And also some rough system specifications on which it can be run?\n\n**Comparison with Other Methods**\n- when comparing LoRA and Subspace (e.g. in figure 1) we see a comparison of train error, but not test error. Is there a reason for that?\n\n**I.I.D Assumption**\n- Can you please comment on why, despite the i.i.d. assumption, these results are still significant?\n\n**Possible Minor Typos / Formatting / Clarity** \n- page 6. 'payed'\n- abbreviation NLL used without definition\n- references need to be reviewed for formatting\n- page 4, second last line, shouldn't it be \"u: = flatten( ...)\" instead of \"LoRA(u) := flatten ( ... )\"\n- page 6, last paragraph says we use \"several\" values for r, giving the impression they are more than two, but the appendix mentions two values {1,4}\n- page 14, second last paragraph: \"Choosing an overall ... \". Please recheck this for clarity.\n\n\nIn summary the only major reservations I have are about the provided code and the i.i.d assumption, to the best of my knowledge. I apologize if I overlooked something important. Please feel free to correct me for any errors I may have made while reviewing; and to address these concerns. Thank you.\n\nMy vote is to for strong accept, conditional on addressing concerns regarding the prototype code."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5752/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5752/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5752/Reviewer_dFjh"
                    ]
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5752/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698991771903,
            "cdate": 1698991771903,
            "tmdate": 1699636603232,
            "mdate": 1699636603232,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tLRvSnZQOQ",
                "forum": "GY1fKFXG5i",
                "replyto": "s9ciWh5QAI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5752/Reviewer_dFjh"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5752/Reviewer_dFjh"
                ],
                "content": {
                    "title": {
                        "value": "Supplementary Material Update"
                    },
                    "comment": {
                        "value": "Hi, Any updates about the supplementary material?"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5752/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700513553280,
                "cdate": 1700513553280,
                "tmdate": 1700513553280,
                "mdate": 1700513553280,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "36429aH805",
                "forum": "GY1fKFXG5i",
                "replyto": "s9ciWh5QAI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5752/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5752/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer dFjh"
                    },
                    "comment": {
                        "value": "We thank you for your detailed and supportive review. We respond to your questions below. \n\n**Task and Top1 error:**\n\nIndeed, we consider the token level error averaged over the sequence chunk as the empirical risk which we bound. In the case of top1 error, this is the top1 error per token averaged over the chunk $R(h,X_k) = \\frac{1}{L} \\sum_{i=1}^L 1[{\\mathrm{argmax} \\ p(x_{i}|x_{<i})=x_{i}^k}]$, where the upper index $k$ denotes the chunk index and the lower index denotes the position within the chunk.\n\n**I.I.D assumption and choice of $L$:**\n\nWe satisfy the I.I.D assumption by dividing the data into non-overlapping chunks/sequences of size L, and then randomly selecting from those sequences. Unlike some models where the input sequences draw on the previous history that lies outside the context window, such as with Transformer-XL or Mistral-7B, the GPT2 model takes in these sequences without considering any previous history. In this setup, it makes sense to set the size of the sequence L to be equal to the context length (which is 1024 by default for nanoGPT/gpt-2 small). This value of L ensures both the computation of the complete joint distribution $p_h(X) := \\Pi_i^L p_h(x_i|x_{<i})$ for each sequence and the preservation of the I.I.D assumption.\n\n**Clarification about the code:**\n\nWe apologize for the confusion about the code. The Glue code was used to run some fine-tuning experiments that we did not report in the paper initially, but that we report in the rebuttal as shown in the general comment. The nanoGPT folder contains all the code required to reproduce our experiments. To pretrain using SubLoRA, you can run the file `train.py` with the configuration file `config/train_gpt2_LoRA_better_hparams.py` using the following command, where the provided hyperparameters lead to the best SubLoRA bound: \n`python train.py config/train_gpt2_LoRA_better_hparams.py --intrinsic_dim=25000 --learning_rate=5e-3 --attention_linear_lora_r=4 --linear_head_lora_r=4`. \n\nTo compute the bounds for the trained checkpoint, you can run the file `bound_pipeline.py` with the configuration file `train_gpt2_LoRA_bounds.py` using the following command, where again, the provided hyperparameters lead to the best SubLoRA bound: \n`python bound_pipeline.py config/train_gpt2_LoRA_bounds.py --intrinsic_dim=25000 --learning_rate=5e-3 --levels=17 --best_checkpoint_path=$PATH_TO_CHECKPOINT`\n\nWe provided a ReadMe file in the zipped code to facilitate navigating it. Your point about the Hugging Face Repository is correct, since we copied it without removing the copyright but removed any other information that can reveal our identity.\n\n **Validation loss for the different methods:**\n\nWhen comparing LoRA, linear subspace training, and SubLoRA, we use the training error because it contributes directly to the bound, as it constitutes the first term in the bound. To give you an idea about how the test error compares between the 3 methods, we report below the BPD test values for the LoRA, linear subspace, and SubLoRA for the models that yield the best bounds. Note however that we are not optimizing for the validation loss, but rather for the error bound. \n\n| Metric | SubLoRA | LoRA Only  | Subspace Only  | \n| ---       | ---          | ---        |  ---         | \n|  Training Loss (NLL)    |   7.20    |   6.42    |  8.85   |    \n|  Validation Loss (NLL)    |   7.19     |    6.48      |  8.85    |           \n\n**Significance of the results with the I.I.D assumption:**\n\nWe satisfy the I.I.D assumption by considering instances to be non-overlapping sequences of size equal to the context length instead of single tokens.  This procedure is precisely how training data is sampled when training language models in practice. Moreover, the bits-per-dimension for a given sequence can be computed as the average error for each token in the sequence given previous tokens, where the token error here refers to the negative log-likelihood $\\mathrm{BPD}(h, X):= -\\log_2 p_h(X)/L = - \\sum_i^L \\log_2 p_h(x_i|x_{<i})/L$. Therefore, an upper bound on the expected BPD error still reflects a guarantee on the average performance of the model at the token level, conditioned on previous tokens within independent sequences, and is a common quantity of interest in language modeling. \n\nThank you for pointing out the minor typos and unclear sentences in the text, we have updated the paper to reflect these corrections and also add clarifications about the task, the top-k errors, and the I.I.D assumption. We also run new experiments that we detail in the general comment, including non-vacuous generalization bounds for very large models with up to 849 million parameters and non-vacuous generalization bounds for LLMs fine-tuned on downstream benchmark tasks. \n\nThank you again for your feedback, we believe it has positively impacted our paper. We hope that we have been able to address your points, We would also be happy to further engage to answer other questions you may have."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5752/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700522150112,
                "cdate": 1700522150112,
                "tmdate": 1700527113784,
                "mdate": 1700527113784,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]