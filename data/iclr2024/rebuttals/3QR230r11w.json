[
    {
        "title": "Multi-Fidelity Active Learning with GFlowNets"
    },
    {
        "review": {
            "id": "z5ogxCNYpH",
            "forum": "3QR230r11w",
            "replyto": "3QR230r11w",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5600/Reviewer_5Rpa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5600/Reviewer_5Rpa"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces an algorithm using Multi-Fidelity Active Learning with GFlowNets. This algorithm effectively finds varied, top-performing options in fields like science and engineering. The authors point out that while there's a surge in data generation in these fields, present machine learning techniques struggle with efficiently querying a detailed, unknown target function.\n\nTo combat this, their algorithm employs a multi-tiered system, merging both basic and detailed reviews of the target function. It incorporates GFlowNets, a generative model, to grasp a simpler depiction of the data for efficient querying. The authors highlight that their method outdoes RL-based models in terms of data use and adaptability.\n\nTo test their algorithm, the authors chose tasks related to discovering molecules, like searching for drugs and studying materials. The results are encouraging, with the algorithm spotting a range of top-performing options using fewer queries compared to other techniques. They've outlined the algorithm's steps in a section named Algorithm 1 and have gone into depth about it in Appendices A and B. Essential experiment details are covered in Section 4, including data portrayal and benchmark task measures. Further experimental particulars are found in Appendix C, ensuring clarity and easy replication. Additionally, they've made their algorithm's code publicly available."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1. Novelty: The proposed algorithm for Multi-Fidelity Active Learning with GFlowNets is a novel approach that addresses the challenge of querying a high fidelity, black-box objective function in scientific and engineering applications. The use of GFlowNets, a generative flow-based model, to efficiently query the objective function is also a novel contribution.\n\n2. Evaluation: The authors evaluate the proposed algorithm on several molecular discovery tasks, including drug discovery and materials science. The evaluation shows promising results, with the algorithm discovering diverse, high-scoring candidates with fewer queries than other methods.\n\n3. Reproducibility: The authors provide a detailed procedure of the steps of the algorithm in Algorithm 1, and additional details about the algorithm in Appendices A and B. They provide the most relevant information about the experiments in Section 4, including a description of the data representation and the oracles for each of the benchmark tasks. The rest of the details about the experiments are provided in Appendix C for the sake of better clarity, transparency, and reproducibility. Finally, the authors include the original code of their algorithm and experiments, which has been developed as open source.\n\n4. Clarity: The paper is well-written and easy to understand, even for readers who are not experts in the field. The authors provide clear explanations of the concepts and methods used in the paper, and the figures and tables are well-designed and informative."
                },
                "weaknesses": {
                    "value": "One potential weakness of this paper is that the evaluation is limited to molecular discovery tasks, and it is unclear how well the proposed algorithm would perform on other types of scientific and engineering applications. Additionally, while the authors provide a detailed procedure of the steps of the algorithm and additional details about the algorithm in Appendices A and B, some readers may find the paper to be too technical and difficult to follow. Finally, the authors do not provide a detailed discussion of the limitations of their approach or potential future directions for research."
                },
                "questions": {
                    "value": "What is the main challenge in scientific discovery that current machine learning methods cannot efficiently tackle?\n\nHow does the proposed algorithm with GFlowNets address the challenge of querying a high fidelity, black-box objective function?\n\nWhat are the advantages of multi-fidelity active learning with GFlowNets compared to RL-based alternatives?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5600/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698709416846,
            "cdate": 1698709416846,
            "tmdate": 1699636577340,
            "mdate": 1699636577340,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "zBj6UzYlhK",
                "forum": "3QR230r11w",
                "replyto": "z5ogxCNYpH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5600/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5600/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response to Reviewer 5Rpa"
                    },
                    "comment": {
                        "value": "Dear Reviewer 5Rpa, we appreciate your review of our manuscript. We are glad to read that you have appreciated the novelty of our work, the breadth of the evaluation, the clarity of the manuscript and our efforts regarding the reproducibility of our work. We are happy to also address your comments and questions below.\n\n> One potential weakness of this paper is that the evaluation is limited to molecular discovery tasks, and it is unclear how well the proposed algorithm would perform on other types of scientific and engineering applications.\n\nWe would like to note that besides the tasks on molecular discovery, we have included experiments with DNA aptamers and antimicrobial peptides, whose data representation and target functions are substantially different than the small molecules tasks. Furthermore, we have also included results on two well-studied synthetic functions (Appendix C.4).\n\n> [T]he authors do not provide a detailed discussion of the limitations of their approach or potential future directions for research.\n\nSection 5 Conclusions, Limitations and Future Work includes a discussion of the future directions for research and the limitations of our work. \n\n### Questions\n\n> What is the main challenge in scientific discovery that current machine learning methods cannot efficiently tackle?\n\nThis question is addressed explicitly in the second paragraph of the introduction (\u201d[\u2026] Such scenarios present serious challenges even for the most advanced current machine learning methods\u201d) as well as in the the subsequent paragraphs.\n\n> How does the proposed algorithm with GFlowNets address the challenge of querying a high fidelity, black-box objective function?\n\nTo address the challenge of querying a high fidelity, black-box function efficiently, in this work we have proposed a multi-fidelity active learning algorithm which leverages the availability of additional black-box functions with lower fidelity but much lower costs. This is the central element of our work.\n\n> What are the advantages of multi-fidelity active learning with GFlowNets compared to RL-based alternatives?\n\nAs discussed in the introduction and reflected in the results of our experiments, RL-based approaches are effective at optimisation but lack diversity in the batch of discovered candidates. The multi-fidelity active learning algorithm we propose learns to sample from the acquisition function instead of optimising it, by means of the use of GFlowNets. This approach achieves both diversity and high scores in the batch of candidates."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5600/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700493596126,
                "cdate": 1700493596126,
                "tmdate": 1700493596126,
                "mdate": 1700493596126,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "8EqM9r0kSj",
            "forum": "3QR230r11w",
            "replyto": "3QR230r11w",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5600/Reviewer_TJ42"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5600/Reviewer_TJ42"
            ],
            "content": {
                "summary": {
                    "value": "This paper designed an Active Learning algorithm to address the challenges of \"needle-in-a-haystack\" problems in scientific discovery, where the goal is to discover multiple, diverse candidates with high values of the target function, rather than just finding the optimum. The proposed method was evaluated on multiple tasks like DNA and Antimicrobial tasks, and molecular tasks. The experimental results were shown to outperform its single-fidelity counterpart while maintaining diversity, demonstrating its effectiveness in dealing with high-dimensional scientific data."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- This work is a good combination of active learning and GFlowNets.\n\n- The experimental results demonstrate the effectiveness of the proposed model in dealing with high-dimensional scientific data.\n\n- Instead of merely concerning the model performance (e.g., accuracy), this work focuses more on selecting more diverse samples with high values of the target function."
                },
                "weaknesses": {
                    "value": "- The baselines are quite simple, just compare between multi-fidelity active learning and single-fidelity active learning. The author could consider comparing it with other typical query synthesis active learning methods like [r1].\n\n- The performance of the proposed method on tasks and domains beyond those covered in this study remains uncertain due to the limitations of the tested benchmarking datasets. \n\n\n[r1] Schumann R, Rehbein I. Active learning via membership query synthesis for semi-supervised sentence classification[C]//Proceedings of the 23rd conference on computational natural language learning (CoNLL). 2019: 472-481."
                },
                "questions": {
                    "value": "Would the data samples selected be out-of-distribution samples? Since the evaluation considers mean top-K score and top-K diversity, it is still possible to select out-of-distributions samples."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5600/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698735185800,
            "cdate": 1698735185800,
            "tmdate": 1699636577235,
            "mdate": 1699636577235,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Bbs0f5F18K",
                "forum": "3QR230r11w",
                "replyto": "8EqM9r0kSj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5600/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5600/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response to Reviewer TJ42"
                    },
                    "comment": {
                        "value": "Dear Reviewer TJ42, thank you for the review of our submission. We are happy to read that you positively valued the results presented in our manuscript, taking into account both metrics, the average scores and diversity. In your review, you also mention a couple of weaknesses and a question that we are happy to address in what follows.\n\n> The baselines are quite simple, just compare between multi-fidelity active learning and single-fidelity active learning.\n\nFirst, we would like to note that besides the (GFlowNet-based) single-fidelity active learning baseline, we also include a multi-fidelity algorithm which optimises the BO acquisition function via the widely used reinforcement learning method PPO. This method can therefore be regarded as a multi-fidelity Bayesian optimisation method that optimises the acquisition function via reinforcement learning. This a strong baseline that is actually effective at discovering samples with high value of the target black-box function, as is reflected by the results of our experiments. However, we also observe that it exhibits low diversity in the discovered samples. The algorithm we propose, which uses a multi-fidelity GFlowNet, addresses this limitation, as you acknowledge in your review.\n\nThe remaining baselines are designed to help us gain understanding about the novel aspects of our proposed method. Specifically, the contribution of multi-fidelity versus single-fidelity active learning and the advantages of a GFlowNet sampler that selects the fidelity alongside the sample. Moreover, we include a baseline with random samples ranked by the acquisition function, which is known to be a strong baseline in Bayesian optimisation. \n\nThe baselines are described in Section 4.2\n\n> The author could consider comparing it with other typical query synthesis active learning methods like [r1].\n\nUnfortunately, it would not be straightforward to adapt the methods in [r1] for our tasks, since the active learning algorithm in [r1] does not consider multiple oracles and the task at hand is classification of sentences, while our tasks are regression problems with substantially different data. Nonetheless, we appreciate the reference as we may be able to derive a suitable baseline from it in future work.  \n\n> The performance of the proposed method on tasks and domains beyond those covered in this study remains uncertain due to the limitations of the tested benchmarking datasets.\n\nThere will always be uncertainty about the performance of any method on tasks and domains on which it has not been tested. Nonetheless, in the case of our experimental setup, we would like to argue that we have offered results in four tasks, using three distinct scientific discovery domains (DNA, antimicrobial peptides and small molecules), plus two additional sets of experiments on well-studied synthetic functions (Appendix C.4). Furthermore, we have performed robustness analyses of the impact of the oracle costs (Appendix E.2), the acquisition size (Appendix E.3) and the size of the final batch (Appendix E.4). In all the experiments, we have found highly consistent results, where the proposed algorithm MF-GFN is able to find high-scoring candidates with less budget than the baselines, while keeping high diversity, unlike the multi-fidelity PPO baseline.\n\n> Would the data samples selected be out-of-distribution samples? Since the evaluation considers mean top-K score and top-K diversity, it is still possible to select out-of-distributions samples.\n\nWe are not sure of having understood this question correctly, so we would appreciate a clarification. In particular, do you mean out-of-distribution with respect to what distribution? In general, the search space in our tasks is vast, therefore the chances are that the selected samples will be out of distribution, with respect to the initial data data set on which the surrogate is trained."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5600/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700493492679,
                "cdate": 1700493492679,
                "tmdate": 1700493492679,
                "mdate": 1700493492679,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Odwxc7JRXd",
                "forum": "3QR230r11w",
                "replyto": "Bbs0f5F18K",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5600/Reviewer_TJ42"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5600/Reviewer_TJ42"
                ],
                "content": {
                    "title": {
                        "value": "response"
                    },
                    "comment": {
                        "value": "Dear authors,\n\nI asked the last question because I noticed this paper https://arxiv.org/pdf/2210.12928.pdf"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5600/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700509138509,
                "cdate": 1700509138509,
                "tmdate": 1700509138509,
                "mdate": 1700509138509,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Wk1YsnBQqA",
                "forum": "3QR230r11w",
                "replyto": "yFMQBH9nkI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5600/Reviewer_TJ42"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5600/Reviewer_TJ42"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response, I decided to keep my score towards acceptance."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5600/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700694979896,
                "cdate": 1700694979896,
                "tmdate": 1700694979896,
                "mdate": 1700694979896,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5QD7BbGJV7",
            "forum": "3QR230r11w",
            "replyto": "3QR230r11w",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5600/Reviewer_Cu6t"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5600/Reviewer_Cu6t"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose to extend the GFlowNet-AL paper, ICML 2022 paper by M. Jain et al., to the multi-fidelity setting. While the extension seems straightforward, and the general novelty contribution of the paper is limited, the paper falls short in demonstrating the effectiveness of the multi-fidelity setting on real-world applications. The authors somehow convert the existing experiments of GFlowNet-AL to a multi-fidelity setting with some synthetic simulations."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Active learning setting is an important problem and using GFN shows to be effective in this setting."
                },
                "weaknesses": {
                    "value": "There are a couple of weaknesses with this paper:\n\n- The novelty of this paper is very limited in terms of the model development. To cover this limitation, the paper needs to be more robust in terms of its application. However, the experiments do not support this, as they are primarily simulation-based.\n\n- The paper is not well-written in general. 1) The plots in the experiments are densely packed, making them difficult to understand. 2) While the paper includes a lot of basic information about the \"importance of new scientific discovery\" in the introduction, which is not directly relevant, it lacks a proper description of the multi-fidelity problem. Additionally, GFlowNet and Active Learning in the method section are not closely related, and it would be better to refer to GFlowNet-AL as a preliminary section. Doing so may clarify the paper's novelty.\n\n- The tasks used in the experiments are not based on real-world scenarios, which raises questions about the problem's practical importance. In general, I'm not familiar with multi-fidelity, and I didn't find the paper very clear in this respect, neither in the method nor in the experiments.\n\n- The sequences are very short, leading to questions about the method's applicability for longer sequences.\n\n- The method can also be viewed as an ensemble modeling approach, but it's not clear what the main advantage is. In the end, it seems that there is a single, expensive objective, which is the case in most real-world scenarios. And when we approximate them with multiple oracle, why they might be hard to get query from all of them?"
                },
                "questions": {
                    "value": "Could you please elaborate on the main challenge of this model and how you addressed it?\n\nCould you please provide more details about the statement, \"cheap online simulations take a few minutes\"? What exactly are considered as \"cheap simulations\" in the context of sequence design?\n\nI would appreciate seeing the benefits of your approach on larger sequences and molecules (e.g. antibodies).\n\nI'd like to see at least one real-world application where you have multiple fidelity levels with varying costs.\n\nIt's not clear to me what the term \"cost\" is referring to. Is it related to validation experiments or the process of querying the black box?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5600/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698862883654,
            "cdate": 1698862883654,
            "tmdate": 1699636577128,
            "mdate": 1699636577128,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mCAGj2v2cI",
                "forum": "3QR230r11w",
                "replyto": "5QD7BbGJV7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5600/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5600/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response to Reviewer Cu6t (part 1)"
                    },
                    "comment": {
                        "value": "Dear Reviewer Cu6t, thank you for reviewing our submission. The review mentions a number of concerns that we are happy to address below.\n\n> The novelty of this paper is very limited in terms of the model development.\n\nThe review does not provide many details explaining the assessment of the novelty of our submission, so we will here provide a general overview of the novel contributions of our paper. Our paper is, to our knowledge, the first work to propose a multi-fidelity active learning algorithm using GFlowNets. Single-fidelity active learning with GFlowNets has been explored before at least by Bengio et al. (2021), Jain et al. (2022) and Jain et al. (2023a). The multi-fidelity aspect of the algorithm is far from trivial as it implied, among other things, proposing a novel extension of GFlowNets to sample the fidelity alongside the candidate; training a multi-fidelity Bayesian surrogate with multi-fidelity data; incorporate a multi-fidelity acquisition function; regarding the evaluation, assessing the contribution of the multi-fidelity aspect on average scores, diversity, the impact of costs, etc.\n\nMoreover, our paper is, also to the best of our knowledge, the first work presenting multi-fidelity active learning results for DNA aptamers, antimicrobial peptides and molecular design. As we discuss in our paper, the reason is that these problems present a number of challenges for existing methods, such as traditional Bayesian optimisation and reinforcement learning.\n\nIn the review, you state that \u201cthe experiments [\u2026] are primarily simulation-based.\u201d We would like to recall that the experiments with small molecules (Section 4.3.3) are not simulations. In these tasks, we use the semi-empirical quantum chemistry method XTB with various levels of geometry optimisation as oracles. These oracles are used in practically relevant problems by the scientific community. Furthermore, the costs of the oracles are set such that they are proportional to their computational running time, as it would be done in practice. The results in these two tasks (Figure 3) demonstrate the effectiveness of MF-GFN at finding high-scoring, diverse candidates, outperforming the studied baselines, including a multi-fidelity Bayesian optimisation method using PPO as the optimiser of the acquisition function (MF-PPO). These results are consistent with the rest of the results in the paper (DNA, AMP and synthetic functions).\n\n> The plots in the experiments are densely packed\n\nWhile the plots could admittedly be less packed, removing information would likely harm the completeness in the presentation of our results. Do you have a suggestion for an alternative form of presentation?\n\n> [The paper] lacks a proper description of the multi-fidelity problem\n\nThe multi-fidelity problem is described in Section 3.2 Multi-fidelity Active Learning. The desccription builds upon the preceding section, which describes the single-fidelity scenario. The multi-fidelity problem and the algorithm are also illustrated in Figure 1, and detailed formally in Algorithm 1.  What details are missing, in your opinion, to make the description more proper?\n\n> GFlowNet and Active Learning in the method section are not closely related, and it would be better to refer to GFlowNet-AL as a preliminary section.\n\nSection 3.1 Background introduces first the necessary background on GFlownets and then describes the (single-fidelity) active learning problem, explaining the specific case where a GFlowNet is used as a sampler, as done by Jain et al. (2022) with GFlowNet-AL. We have added a sentence referring explicitly to GFlowNet-AL and the corresponding citation. We have also included the name GFlowNet-AL in the description of the single-fidelity baseline, for further clarification. Do these changes address your comment?\n\n> The tasks used in the experiments are not based on real-world scenarios, which raises questions about the problem's practical importance\n\nWe refer to our discussion above, answering your comment about novelty and the experiments being \u201csimulation-based\u201d. Furthermore, we would like to note that the kind of experiments included in this paper are similar to those found in the literature (Angermueller et al., 2020, Zhang et al., 2022). Please let us know if this aspect needs further clarification.\n\n### References\n\n- Bengio et al. Flow network based generative models for non-iterative diverse candidate generation. NeurIPS, 2021\n- Jain et al. Biological sequence design with GFlowNet. ICML, 2022\n- Jain et al. Multi-objective GFlowNets. ICML, 2023a\n- Angermueller et al. Model-based reinforcement learning for biological sequence design. ICLR 2020.\n- Zhang et al. Unifying Likelihood-free Inference with Black-box Optimization"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5600/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700493242748,
                "cdate": 1700493242748,
                "tmdate": 1700493242748,
                "mdate": 1700493242748,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BGZiWVxwGA",
                "forum": "3QR230r11w",
                "replyto": "6OVZLJPtRo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5600/Reviewer_Cu6t"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5600/Reviewer_Cu6t"
                ],
                "content": {
                    "comment": {
                        "value": "Thank the authors for their response! While the responses addressed some of my concerns, I still would like to further discuss the practical advantages of the proposed method.\n\nBefore delving into the detailed discussion, I would like to point out that: 1) I'm not familiar with the Multi-fidelity topic, and 2) based on my understanding, the main goal of the paper is the application of GFlowNet-AL in a multi-fidelity setting. Considering these two points, I believe the paper couldn't convince me that the combination of AL and multi-fidelity is actually a need in practice. In the related works, the authors only mentioned, \"interestingly, the literature on multi-fidelity active learning (Li et al., 2022a) is scarcer\"; however, they didn't mention why the topic is scarce (while there are more works on the multi-fidelity problem in general) and what the advantages and disadvantages of the previous method are and how the proposed GFlowNet-based method could address them.\n\n**Re: Novelty:** In my opinion, the primary advantage of the paper is extending/applying GFlowNet-AL for the multi-fidelity problem. However, the novelty of the paper from a theoretical perspective is somewhat limited. Although I agree with the authors that it is not trivial, the main claim of this paper is \"the first work to propose a multi-fidelity active learning algorithm using GFlowNets.\" Based on this, I think the paper should be much more mature/solid with respect to the experiments. Specifically, the authors should include related works on multi-fidelity active learning problems, state their drawbacks, and explain how they addressed them. In the experiments, the authors need to demonstrate that what they are achieving with the proposed method is practically sound. More specifically, they need to point out the computational complexity of each oracle and mention how much they could save. In an active learning setting, when we have costly and time-consuming wet-lab oracles, active learning makes total sense. Here, the authors state that the computational complexity of different oracles (which are black-box) is different but fail to highlight how much they could save in computational costs and how much complexity their method adds. \n\nEven in section 4.3.3, the authors did not convincingly demonstrate the practical usefulness of their approach. Including such a study would make the contribution clear. In my point of view, one of the simplest baselines could involve using GFlowNet-AL on each fidelity separately and observing the advantages.\n\n**Re multi-fidelity problem:** That section is your description of multi-fidelity for active learning. For someone like me, adding multi-fidelity as a background would be gratefully appreciated. \n\n**Re larger molecules:** Something that I'm not sure about the proposed method is how much is cost of GFlowNet and how it can help to reduce the cost of querying the oracles. To me, the main issue is that I think computational analysis is missed!\n\n**Re Ensemble modeling:** One can frame the problem as querying all the oracles and ensembling the results. The question then is: What would be the computational benefit of the proposed method?\n\nI will await the authors' response, engage in discussion with the other reviewers, and adjust my score accordingly."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5600/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700589423963,
                "cdate": 1700589423963,
                "tmdate": 1700589423963,
                "mdate": 1700589423963,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VrhAhKfB7C",
                "forum": "3QR230r11w",
                "replyto": "QFfVVsUJ3H",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5600/Reviewer_Cu6t"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5600/Reviewer_Cu6t"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the reply! \n\nThank you for your response!\n\nI already have checked the plots and Table 1 in the Appendix. For me, it is hard to find a connection between \\lambda and the running time or real cost. As I mentioned in my initial comment, interpreting the plots is very difficult due to their density. While I observe that \\lambda is proportional, the actual running time or computational cost remains unclear. For example, a 25% improvement in the DNA task raises the question of how this translates to an improvement in running time. The central concern is understanding the extent to which the complexity of your training/inference model has increased in comparison to the original approach, and if that cost is lower than the cost of multiple fidelities. From my perspective, these questions remain unanswered by the authors.\n\nRegarding related works, I sought to determine if others have addressed this problem previously. I found **MAPS and MAPS-SE** relevant, aligning closely with my viewpoint of the issue in a real-world context. Could you please clarify the distinctions between multi-fidelity and these approaches? Additionally, I am curious why a comparison with MAPS and MAPS-SE wasn't explored as a potential baseline.\n\n[MAPS and MAPS-SE] \"Active Policy Improvement from Multiple Black-box Oracles,\" ICML 2023."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5600/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700633768551,
                "cdate": 1700633768551,
                "tmdate": 1700633768551,
                "mdate": 1700633768551,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wktHb32uLL",
                "forum": "3QR230r11w",
                "replyto": "wIeSP8pmRa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5600/Reviewer_Cu6t"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5600/Reviewer_Cu6t"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the clarification! I will raise my score!\n\nOne question which still is not clear to me: You achieved the same results with 25% of the budget. Therefore, you reduced the cost from 262.5s to 106s. Could you please let me know how much additional computational cost your model added compared to the simpler model during training and/or inference? The cost you are referring to is the cost of oracles, and I can see that you can improve it (although, to me, it is not impressive because it still is nothing compared to wet-lab costs.). However, based on my understanding, your model is more computationally expensive during training/inference as well. So, could you add that to the account and point out the savings?"
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5600/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700673441800,
                "cdate": 1700673441800,
                "tmdate": 1700673441800,
                "mdate": 1700673441800,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "xpRn3KauH2",
            "forum": "3QR230r11w",
            "replyto": "3QR230r11w",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5600/Reviewer_EtrP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5600/Reviewer_EtrP"
            ],
            "content": {
                "summary": {
                    "value": "This paper describes a multi-fidelity optimization algorithm which uses GFlowNets to optimize the acquisition function of a multi-fidelity deep-kernel Gaussian process. Experimentally the proposed algorithm seems to outperform a number of GFlowNet baselines."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "I don't think my analysis of this paper fits nicely into the strengths/weaknesses format requested in the review form, so I will first give general feedback and then describe strengths and weaknesses.\n\nI think the paper proposes an interesting method, but in generally seems a bit... distorted. In my opinion it gives too much detail on unimportant bits (context of drug discovery) and not enough detail on the important bits (e.g. the actual method). The main emphasis is on GFlowNets, which actually don't seem to be the most important part of the method: I think a more appropriate title for the paper would be \"multi-fidelity Bayesian optimization with deep kernel Gaussian processes\". To me, the most important question for the paper to answer is \"does the method work, and if so why.\" I didn't feel like the paper came even close to answering this question.\n\nStrengths of the paper:\n- The writing was clear (at least what the authors chose to write about was clear, although I think they chose to write about the wrong things in the paper).\n- The proposed method is sensible and arguably has some novelty (although the exact degree of novelty was unclear)\n- Experiments were fairly comprehensive (at least for the questions they investigated, which in my opinion were the wrong questions)"
                },
                "weaknesses": {
                    "value": "- _Related work_: the paper touches on a bunch of topics which are already very well-researched: multi-fidelity optimization (e.g. [1-3]), GFlowNets [4-7], and diverse optimization (e.g. [8-10]). I did not think the paper contextualized its contributions well.\n  - I think BO was dismissed too hastily by claiming that BO only cares about finding a single optimum. First, this is not true: see [9,10]. Second, diverse solutions may be found _incidentally_ by when performing single-objective BO via its exploration, so it is inappropriate to dismiss BO even if diversity is not built into the objective. In fact, the method proposed in this paper also appears to have no built-in diversity objective: it just relies on GFlowNets incidentally generating a diverse set of points.\n  - Active search and quality-diversity optimization are mentioned in section 2, but never again. Does the proposed method have any advantages over these approaches? Would these not be sensible baselines for experimental comparison.\n  - The authors mention the existence of a lot of prior literature on multi-fidelity optimization, but dismiss it by saying \"the literature is still scarce probably because most approaches cannot tackle the specifics of scientific discovery, such as the need for diverse samples.\" This is pure speculation, and I highly doubt that it is true. One cannot conclude that existing methods are insufficient just because you don't see many papers on them!\n  - In the past 2 years there has been a huge flood of papers about GFlowNets. The relationship between this paper and all the other papers is not clearly stated. [4,6] seem particularly relevant. The authors should clearly state the novelty (if any) from the existing GFlowNet literature.\n- _Surrogate model/acquisition functions_: the main emphasis of the paper is on the GFlowNets, but the method also critically relies on a GP surrogate model and an acquisition function. In my experience, these choices are also incredibly important important, but they are not really explored or discussed much in this work. For example, I am aware that the deep kernel GPs used by the authors as a surrogate model are very prone to overfitting [11]. Is this an issue? The training of the surrogate model is not really discussed in the text when presumably it is very important!\n- _Flawed metrics_: the authors follow previous works and examine the scores and diversity of the top K outputs. I think this is a flawed metric which doesn't reflect how these models will be used in practice, which is to propose a set of candidate points that will be taken forward to the next stage in screening. This implies _extracting_ a diverse subset from all outputs, not simply looking only at the top K outputs and seeing how diverse they are. I recommend instead that the authors look at a monotonic diversity metric, such as #circles (Xie et al 2022).\n- _Experiments mainly compare against weak baselines_: the experiments contrast the authors' method with some baseline methods, which in my opinion are fairly weak (few variations of random search and PPO, which is probably not sample efficient). Critically, the authors don't compare against any other sort of BO method. I think the experiments section should really be trying to answer whether this setup has any advantage over a reasonable other BO-like setup (e.g. multi-fidelity GPs with [domain-specific] standard kernels and basic multi-fidelity acquisition functions like expected improvement / cost).\n- _Origin of diversity unclear_: another question which is not addressed theoretically or experimentally is why this method produces more diverse outputs (or whether it even does). Is it the surrogate model? Is it the GFlowNets? This seems like the key claimed advantage of the method, so it feels odd to me that it is not investigated more.\n\n[1] A General Framework for Multi-fidelity Bayesian Optimization with Gaussian Processes\n\n[2] Multi-Fidelity Bayesian Optimization via Deep Neural Networks\n\n[3] Review of multi-fidelity models\n\n[4] Multi-Objective GFlowNets\n\n[5] Gflownet foundations\n\n[6] Biological sequence design with gflownets\n\n[7] GFlowNets for AI-driven scientific discovery\n\n[8] Quality-diversity optimization: a novel branch of stochastic optimization\n\n[9] Discovering Many Diverse Solutions with Bayesian Optimization\n\n[10] Bayesian algorithm execution: Estimating computable properties of black-box functions using mutual information\n\n[11] The promises and pitfalls of deep kernel learning"
                },
                "questions": {
                    "value": "Some specific questions are:\n\n- How does this differ from previous work on GFlowNets?\n- How does this method differ from a BO method which one could create by taking a model/acquisition model directly from existing papers?\n- What are the results of a GP baseline using Matern kernel (toy tasks), string kernel (DNA task), and Tanimoto kernel (models) with EI/cost acquisition function and GFlowNets as the acquisition function optimizer?\n\nAlso, I have some writing suggestions if you revise the paper:\n- The abstract contains ~3 sentences of introduction. I would cut this to ~1 sentence. It's good to keep the abstract short.\n- The introduction contains a lot of description of black box optimization in general. While I think this is good, 9 pages is fairly short, and I think the paper does not even have enough space to properly describe the method at the moment. I would cut this down to ~1 paragraph, reference some works which discuss the problem in more detail, and try to keep the introduction to < 1 page.\n- I would put the related work _after_ the method. I recommend this slide deck by Simon Peyton Jones (a creator of Haskell) which explains why: https://www.microsoft.com/en-us/research/academic-program/write-great-research-paper/"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5600/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698953318124,
            "cdate": 1698953318124,
            "tmdate": 1699636577023,
            "mdate": 1699636577023,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hGtBlgPXMF",
                "forum": "3QR230r11w",
                "replyto": "xpRn3KauH2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5600/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5600/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response to Reviewer EtrP (part 1)"
                    },
                    "comment": {
                        "value": "Dear Reviewer EtrP,\n\nThank you for your thorough review. We appreciate that you have found our proposed algorithm interesting and sensible, and the overall article well-written and comprehensive. We understand that you disagree with several aspects of our paper, therefore in what follows we will gladly address your comments and concerns one by one.\n\n## Related work\n\nA major concern in your review seems to be that our paper did not \u201ccontextualized its contributions well\u201d. We would like to first note that out of the 10 citations that you provide as examples of the well-researched topics that our paper touches upon, 7 of them are already cited in our manuscript. Of the remaining 3, citation [3] is a review of multi-fidelity models but it doesn\u2019t cover deep learning, Bayesian optimisation and active learning; citation [10] is a Bayesian optimisation method but it does not seem to tackle the diversity problem; citation [9], in contrast, seems very relevant, as it is a Bayesian optimisation method for finding diverse solutions. Accordingly, we have added a sentence at the end of the second paragraph of Section 2 acknowledging this work.\n\n### Bayesian optimisation\n\n> BO was dismissed too hastily by claiming that BO only cares about finding a single optimum. First, this is not true: see [9,10].\n\nOur paper states that \u201cBayesian optimisation and reinforcement learning are designed to\nfind the optimum of the target function\u201d (Section 1). In Section 2, we state that \u201c[t]he main difference between BO and the problem we tackle in this paper is that we are interested in finding multiple, diverse samples with high value of $f$ and not only the optimum\u201d. In our opinion, this is not dismissing Bayesian optimisation but describing its goal and explaining why it is not directly suited for the problems we tackle in our paper. Rather than an opinion or a controversial claim, this is simply the problem statement found in the Bayesian optimisation literature (Frazier, 2018; Garnett, 2023). As a matter of fact, this aspect of BO is mentioned as the motivation in [9], which you cite: \u201cthe fact that BO traditionally seeks a single best optimizer may be a significant limitation\u201d. From this standpoint, [9] (AISTATS, 2023) proposes a variant of Bayesian optimisation to discover diverse solutions.\n\nOur paper could similarly be regarded as a BO variant: Not only do we not dismiss Bayesian optimisation, but rather our method strongly builds upon it. Specifically, our algorithm relies on a Bayesian surrogate (DKL) to model the data and a BO acquisition function (multi-fidelity max-value entropy search) for the exploration of the search space\u2014the two key ingredients of BO. Note that the manuscript makes this connection explicitly:\n\n> Optionally, we can instead train a probabilistic surrogate $p(f | \\mathcal{D})$ and use as reward the output of an acquisition function $\\alpha(x, p(f | \\mathcal{D}))$ that considers the epistemic uncertainty of the surrogate model, as typically done in Bayesian optimisation (Jain et al., 2022).\n\nA crucial difference between our algorithm and traditional BO is that instead of optimising the acquisition function, GFlowNets learn to sample from it, which results in enhanced diversity (see below). We have added a sentence in the Active Learning section of 3.1 to further clarify this idea.\n\nYou mention that BO may also find diverse solutions \u201cincidentally\u201d. While we agree that this may be the case, our goal is to find diverse solutions rather *systematically*, since diversity is an important objective in certain scientific discovery applications, as it is also discussed in [9]. \n\n> the method proposed in this paper also appears to have no built-in diversity objective: it just relies on GFlowNets incidentally generating a diverse set of points.\n\nWe respectfully disagree with this view. GFlowNets do have built-in diversity in their objective and diversity is at the core of the method, as is discussed in most \u201cGFlowNets papers\u201d, including the article where the method was introduced (Bengio et al., 2021). GFlowNets achieve diversity by learning to sample proportionally to the reward distribution. Therefore, diversity is not *incidental*, but *systematic*. The importance of diversity and its connection with GFlowNets is discussed throughout our paper and in particular the technical mechanisms are in described in Section 3.1. We also note that the ability of GFlowNets to systematically sample diverse solutions has been established in a number of prior works including but not limited to the following: Malkin et al., 2022, Zhang et al., 2023, Jain et al., 2023a,b."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5600/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700507849074,
                "cdate": 1700507849074,
                "tmdate": 1700507849074,
                "mdate": 1700507849074,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mwFhXAfbw6",
                "forum": "3QR230r11w",
                "replyto": "y9PC8YkIR6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5600/Reviewer_EtrP"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5600/Reviewer_EtrP"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for detailed response"
                    },
                    "comment": {
                        "value": "I have read your detailed response to my questions and concerns: thank you for making a clear case for the significance of your work.\n\n- **Related work / significance:** thanks for the additional description, I will reconsider. Please note though that citing papers $\\neq $ providing context!\n- **Baselines/metrics**: no further questions.\n- **GFlowNet diversity:** the mere fact of sampling from a distribution does not imply diversity! I think the GFlowNet papers you cite all make an implicit assumption that the distribution of inputs with $p(x)\\propto R(x)$ will be diverse. While this may often be the case in practice, it is easy to produce counterexamples which show this will not always be the case. When GFlowNets are applied to problems it is in my opinion usually unclear whether $p(x)\\propto R(x)$ is actually a diverse distribution, and for this reason I personally consider their diversity to be incidental, although I acknowledge that it is not *always* incidental.\n- **Origins of diversity:** I'm not sure that you understood my comment here. When comparing two algorithms, usually there are many changes and it is not clear which factors are important for diversity. This is what makes the origins of diversity unclear. For example, changing the acquisition function optimizer from PPO to GFlownets simultaneously changes what kind of molecules are produced (influenced perhaps by the model architecture), but also the degree to which the acquisition function is maximized (e.g. the maximum values found may be quite different) and, if I understand correctly, also whether you select inputs by \"sampling\" values proportional to acquisition function value or whether you choose greedily.\n- **Question about Matern/string/Tanimoto GPs**: this suggested experiment was intended to disentangle which factors were responsible for the performance. All of your experiments used similar model types (deep kernel GPs) which made this less clear. I do not necessarily expect you to perform the experiment, it was just a suggestion.\n\nOverall I am thinking about your arguments and will continue to think about them during the reviewer-AC discussion phase."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5600/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700517503098,
                "cdate": 1700517503098,
                "tmdate": 1700517503098,
                "mdate": 1700517503098,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]