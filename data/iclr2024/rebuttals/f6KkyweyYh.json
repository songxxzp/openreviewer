[
    {
        "title": "Biological Sequence Analysis Using B \u0301ezier Curve"
    },
    {
        "review": {
            "id": "cama00m4VZ",
            "forum": "f6KkyweyYh",
            "replyto": "f6KkyweyYh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3543/Reviewer_TS9L"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3543/Reviewer_TS9L"
            ],
            "content": {
                "summary": {
                    "value": "The authors describe an algorithm for representing sequences of amino acids as a collection of Bezier Curves in the plane, and show that using these as inputs for classification tasks is superior to using other 1D and 2D representations of the sequence."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- well written\n- extensive exploration of different representations of their Bezier curve method"
                },
                "weaknesses": {
                    "value": "- For a paper about 2D images, there are very few images. The algorithm is complicated enough to warrant at least one example where the authors illustrate the creation an image from a simple sequence. Moreover, they could compare this to other image production methods and demonstrate why they think their images are superior.\n- Train time is a rather weak method for understanding the compute requirements of each method, it would be better to report training flops, and even scatter plot by training flops."
                },
                "questions": {
                    "value": "- What about a transformer on the sequence itself, rather than just a ViT on images? Seems like an important comparison to make."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3543/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698773350888,
            "cdate": 1698773350888,
            "tmdate": 1699636308468,
            "mdate": 1699636308468,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pUcja07cPN",
                "forum": "f6KkyweyYh",
                "replyto": "cama00m4VZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3543/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3543/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors Response to the Reviewers Comments"
                    },
                    "comment": {
                        "value": "We thank the reviewer for appreciating our work and giving us valuable feedback. Please find below our response to the reviewers comments\n\n```\nFor a paper about 2D images, there are very few images. The algorithm is complicated enough to warrant at least one example where the authors illustrate the creation an image from a simple sequence. Moreover, they could compare this to other image production methods and demonstrate why they think their images are superior.\n```\n\nWe agree with the reviewer for the inclusion of more images. The main reason for not including more images was the page size issue during the original submission. In the revised version of the paper, we have now included an image for the Spike2CGR baseline in Figure 7 in the appendix. Similarly, we also include the images for different methods in Figures 8, 9, and 10 for the Human DNA, Music, and SMILES string datasets, respectively (in the appendix). We will further include more images in the camera-ready version including a visualization showing how the image is created from start to end. Since such an interactive image would not work in the PDF format, we will include that on our website, which we cannot do right now to maintain anonymity.\n\n```\nTrain time is a rather weak method for understanding the compute requirements of each method, it would be better to report training flops, and even scatter plot by training flops.\n```\n\nThe training time is just to get an idea regarding how the vision model behaves for different types of images as input along with how they behave compared to each other in terms of runtime vs. classification results. Since the vision models are just used for downstream task and are not part of our image representation learning idea, that is why we did not included training flops for those models.\n\n```\nWhat about a transformer on the sequence itself, rather than just a ViT on images? Seems like an important comparison to make.\n```\n\nWe want to mention that we tried the ``ProteinBERT`` model on the sequences but the results were not very encouraging compared to the baseline results shown in the paper. Therefore, we decided to use other models as shown in the paper. Moreover, the transformer architectures are domain-specific. Since our idea can be generalized to different types of sequence data, we believe that such a comparison would not be that important. Also, the main focus of this paper is to observe the performance of vision models in terms of sequence classification. Therefore, considering all scenarios, we decided to not include transformer models that take sequences as input.\n\n\nReferences:\n\n[1] Brandes N, Ofer D, Peleg Y, Rappoport N, Linial M. ProteinBERT: a universal deep-learning model of protein sequence and function. Bioinformatics. 2022 Apr 15;38(8):2102-10."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3543/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700448853707,
                "cdate": 1700448853707,
                "tmdate": 1700450481226,
                "mdate": 1700450481226,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XhVJNWuWag",
                "forum": "f6KkyweyYh",
                "replyto": "cama00m4VZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3543/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3543/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Second Response To The Reviewer's Comments"
                    },
                    "comment": {
                        "value": "Dear reviewer, as the end of the discussion period is fast approaching, please do let us know if you have any further suggestions or concerns to which we can respond. We'd be interested to hear if our response and changes to the manuscript helped answer your questions. If you are satisfied with our response, we would kindly request you to increase your score if possible, so that we have more chances of paper acceptance."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3543/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700598843934,
                "cdate": 1700598843934,
                "tmdate": 1700598886139,
                "mdate": 1700598886139,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TobY4BYJ8k",
                "forum": "f6KkyweyYh",
                "replyto": "XhVJNWuWag",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3543/Reviewer_TS9L"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3543/Reviewer_TS9L"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your replies"
                    },
                    "comment": {
                        "value": "Thank you for your replies to my questions. I look forward to seeing more images, especially the dynamic visualization you mentioned. I also appreciate the expansion of the paper to other sequence types, though including lots of large tables of results is a poor use of space - much of this could have been added to the appendix, which would have made space for additional exposition of the method.\n\nWhile I think this representation method is interesting by itself, I still assert that for it to be taken seriously, it needs to be benchmarked against SOTA sequence models on these tasks, not just benchmarked against other similar methods. Stating that ProteinBERT didn't work well is a start, but a more systematic comparison is needed to decide whether to use this method at all when approaching other practical problems.\n\nIn looking over the other reviews, I want to mention that I'm sympathetic to Reviewer B9o8's comments about this not actually being a learning algorithm and therefore not appropriate for ICLR. I thought about this too, but decided to be liberal in my interpretation. I am now wondering if that was the right choice. I will keep my rating as is for now, but would look to other reviewers and the AC to help inform this point."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3543/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659313111,
                "cdate": 1700659313111,
                "tmdate": 1700659313111,
                "mdate": 1700659313111,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "S5exJsMFj0",
                "forum": "f6KkyweyYh",
                "replyto": "TobY4BYJ8k",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3543/Reviewer_TS9L"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3543/Reviewer_TS9L"
                ],
                "content": {
                    "title": {
                        "value": "Minor stylistic comments"
                    },
                    "comment": {
                        "value": "- it is SMILES, not SMILE\n- It is ResNet-50, not RESNET50"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3543/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659840091,
                "cdate": 1700659840091,
                "tmdate": 1700659840091,
                "mdate": 1700659840091,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qIZn9ReaWk",
            "forum": "f6KkyweyYh",
            "replyto": "f6KkyweyYh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3543/Reviewer_B9o8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3543/Reviewer_B9o8"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a methodology for encoding protein sequences as images in a 2D plane with the use of B\u00e9zier curves. Protein and DNA sequences have been mapped into images in the past to take advantage of machine learning methods, including CNNs, and the proposed approach brings a novel transformation that preserves meaningful biological information."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The paper addresses an important problem, which is the representation of biological sequences.\n* The results indicate that the proposed approach has clear advantages over prior methodologies, both quantitatively and qualitatively.\n* The benchmarking exercise is extensive. The paper evaluates various architectures and tests several baseline approaches in different datasets."
                },
                "weaknesses": {
                    "value": "* From the machine learning perspective, the paper does not have a significant contribution. While the problem is important and the results are very promising, the technical novelty is limited. Perhaps this piece of work can be better appreciated by the bioinformatics community.\n* The proposed approach is not a learning algorithm, where the representation is learned automatically. Instead, the approach is a transformation of individual data points into a different representation, which is shown to be more effective for machine learning algorithms. \n* The resulting images are not presented, even though the manuscript claims that these are more interpretable and meaningful. A qualitative comparison of how the images look like with respect to previous attempts for a given sequence (or a portion of it), would be helpful.\n* The paper devotes much space in tables with dataset and methods descriptions. This space could be better utilized with different analysis and other results."
                },
                "questions": {
                    "value": "Unfortunately, I don't think the paper is a good fit for this venue. This does not mean that the paper is incorrect or has major mistakes, it is just that the audience may not be the correct community to present and discuss its true value. The idea is great, and I encourage the authors to consider submitting to a bioinformatics journal or similar, where the machine learning contribution is not expected to be the central contribution of the manuscript."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3543/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698792645949,
            "cdate": 1698792645949,
            "tmdate": 1699636308386,
            "mdate": 1699636308386,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "sqB5OyjcQ3",
                "forum": "f6KkyweyYh",
                "replyto": "qIZn9ReaWk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3543/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3543/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors Response to the Reviewers Comments 1/2"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their comments. Please find below our detailed response to each comment\n\n```\nFrom the machine learning perspective, the paper does not have a significant contribution. While the problem is important and the results are very promising, the technical novelty is limited. Perhaps this piece of work can be better appreciated by the bioinformatics community.\n```\n\nWe respectfully would like to disagree with the reviewer. The main idea of this paper is to transform any type of sequence into an image-based representation so that we can open the doors of applying vision models for better classification. Since there is more sequence-based data available for the biological sequences, we decided to use different types of such protein sequences to show the performance of the proposed method. However, the prove thethe relevance to ICLR community point, we did the following modifications\n\nTo show the generalizability, we now included three more datasets that are non-protein sequences. Their details are shown in Table 1 in the revised paper. Firstly, we use human DNA data, which contains nucleotide sequences. The second data that we use now comprises SMILES strings, which are comprised of drug molecules. The third data that we use is the music sequence data, where the audio sequences belong to 10 unique music genres. Now, using protein sequences (as in the initial submission) along with the nucleotide sequences, SMILES strings, and music sequences datasets helps us to show that the proposed method can generalize on sequences from different domains. Here please note that the majority of the baselines (other than RandomCGR) cannot operate on SMILES and Music data since the number of unique characters is>20 and the baseline methods cannot operate on such complex datasets by design. The results for the human DNA data, SMILES string data, and Music sequence data are shown in Table 5, 6, and 7 in the revised version. Compared to Spike2CGR, we can observe that the proposed method outperforms in the majority of the scenarios. Similarly, on all new datasets, the proposed method performance significantly improves for the pre-trained vision models.\n\nConsidering that the ICLR community is interested in the \"Learning Representation\" work, we are proposing a \"representation learning\" method that takes sequences as input and transforms it into image-based \"Representation\", which can then be used for downstream classification task. However, to better show a connection to the machine learning domain, we now included Spike2CGR[1] as one of the baselines (detail included in Table 2 in the revised paper), which works on a similar problem domain for the protein sequences and has recently been published in the \"Springer Machine Learning Journal\". We believe that considering such a method as a baseline could help to justify that the problem is indeed important for the machine learning community as that work is published in one of the highly rated machine learning journals.\n\nWe now believe that considering a recent method as a baseline from ML journal along with the new datasets from non-protein sequence domain could help to show the generalizability of proposed method and relevance to the ICLR community.\n\n\n```\nThe proposed approach is not a learning algorithm, where the representation is learned automatically. Instead, the approach is a transformation of individual data points into a different representation, which is shown to be more effective for machine learning algorithms.\n```\n\nWe would like to clarify that the learning of images from the sequences is done in a completely unsupervised way. We proposed an algorithm that \"learns\" a representation in the form of the image where we have sequences as an input.\n\n```\nThe resulting images are not presented, even though the manuscript claims that these are more interpretable and meaningful. A qualitative comparison of how the images look like with respect to previous attempts for a given sequence (or a portion of it), would be helpful.\n```\n\nWe already presented the images for the Bezier curve in Figure 5 in the appendix. Moreover, we provide more images for the baselines as well in Figure 7 in the appendix. We would request the reviewer to please check the images along with further results and discussion mentioned in the appendix. We did not mention such an analysis in the main paper due to space limitations."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3543/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700443613393,
                "cdate": 1700443613393,
                "tmdate": 1700443648225,
                "mdate": 1700443648225,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "urd6BkuTrW",
                "forum": "f6KkyweyYh",
                "replyto": "qIZn9ReaWk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3543/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3543/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors Response to the Reviewers Comments 2/2"
                    },
                    "comment": {
                        "value": "```\nThe paper devotes much space in tables with dataset and methods descriptions. This space could be better utilized with different analysis and other results.\n```\n\nThe reviewer rightfully pointed out that some tables can go to the appendix and space could be better utilized with different analyses. In our initial submission, we tried to include important information in the main paper and moved the remaining content to the appendix. However, since we now included new results for the three new datasets along with further discussion based on the reviewer's comments, we will adjust the content as per instructions in the final camera-ready version.\n\n```\nUnfortunately, I don't think the paper is a good fit for this venue. This does not mean that the paper is incorrect or has major mistakes, it is just that the audience may not be the correct community to present and discuss its true value. The idea is great, and I encourage the authors to consider submitting to a bioinformatics journal or similar, where the machine learning contribution is not expected to be the central contribution of the manuscript.\n```\nWe thank the reviewer for appreciating the quality of our work. As we mentioned in our detailed response, we believe that we proposed a \"representation learning\" idea that can take any type of sequence-based data as input e.g. protein sequences, nucleotide sequences, SMILES strings, and Music sequences. Moreover, we use a recently proposed method from ML journal as a baseline to show relevance to the machine learning community along with the \"representation learning\" community. We hope that our argument will be enough to convince the reviewer to reconsider their decision. If there any any other points that the reviewer would like to mention, we would be very interested in considering those.\n\n\nReferences:\n\n[1] Murad T, Ali S, Khan I, Patterson M. Spike2CGR: an efficient method for spike sequence classification using chaos game representation. Machine Learning. 2023 Aug 28:1-26."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3543/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700443638561,
                "cdate": 1700443638561,
                "tmdate": 1700447871860,
                "mdate": 1700447871860,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Rh6Km8IHUY",
                "forum": "f6KkyweyYh",
                "replyto": "sqB5OyjcQ3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3543/Reviewer_B9o8"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3543/Reviewer_B9o8"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the comments + more questions"
                    },
                    "comment": {
                        "value": "I want to thank the authors for addressing my concerns and for adding more experiments and results to the paper. It is indeed great to see that the method can work with other types of sequences. I still have a few more questions to make sure I understand the responses and the claims of the paper:\n\n1. Is reusing vision models to improve classification performance the main motivation to transform sequences into images? I find the reasoning a bit strange, as the goal of processing sequences should be to do better computation and better understand the sequences. \n2. Have you considered comparing against other sequence (not image-based) models to solve these tasks?\n3. Is the transformation from sequence to image invertible or reversible?\n4. What is the learning mechanism of the proposed approach? Maybe I missed this, but I thought the transform was based on single data points rather than learned from a dataset and transferred to new data points. The optimization in Algorithm 1 and Figure 1 seems to depend on a single sequence rather than a training set, which makes me think that there is no training (no loss function), and therefore, no learning. I agree that the there is a representation change (from sequence to image) but I don't see it being learned. \n\nI appreciate if the authors can clarify these additional questions.\nThank you!"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3543/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700526554241,
                "cdate": 1700526554241,
                "tmdate": 1700526554241,
                "mdate": 1700526554241,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uzyIeSHYEd",
                "forum": "f6KkyweyYh",
                "replyto": "qIZn9ReaWk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3543/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3543/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Second Response To The Reviewer's Comments"
                    },
                    "comment": {
                        "value": "Dear reviewer, as the end of the discussion period is fast approaching, please do let us know if you have any further suggestions or concerns to which we can respond. We'd be interested to hear if our response and changes to the manuscript helped answer your questions. If you are satisfied with our response, we would kindly request you to increase your score if possible, so that we have more chances of paper acceptance."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3543/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700598787124,
                "cdate": 1700598787124,
                "tmdate": 1700598902277,
                "mdate": 1700598902277,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "RTWEqrjdqL",
            "forum": "f6KkyweyYh",
            "replyto": "f6KkyweyYh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3543/Reviewer_Bdp5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3543/Reviewer_Bdp5"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose an approach to transform biological sequences into images using Bezier curves for element mapping. A core motivation is enhancing the representation of sequence information in the generated images, as traditional methods like CGR tends to map elements to a limited set of pixels. Through experiments on three protein sequence datasets for tasks including subcellular localization and host prediction, the authors demonstrate the superiority of the proposed Bezier curve encoding method, with significant gains in accuracy over baselines. \n\nAdditionally, the smooth interpolation of control points enabled by Bezier curves is cited as improving interpretability of the visualizations. Overall, encoding sequences as Bezier curve images appears promising as it provides richer representations that translate to markedly improved performance on downstream classification tasks."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- The proposed sequence-to-image transformation technique is novel and a key contribution that could prove widely applicable and beneficial in the field. The simple and straightforward image generation process based on standard Bezier curve equations is clearly explained.\n- The authors introduce careful methodological choices; e.g., introducing controlled randomness via deviations to reveal hidden patterns, to overcome limitations of fixed mappings in CGR.\n- The authors demonstrated the usefulness of their information-rich curve-based image representations by validating on multiple protein sequence datasets for subcellular localization task. The proposed approach substantially improved classification performance over baseline CGR, highlighting the benefits of the Bezier representation. In addition, the authors also explored the potential of the smoother Bezier curve interpolations in improving interpretability compared to sparse CGR images.\n-encoding method is agnostic to the choice of downstream classifier, allowing flexible integration with existing pipelines.\n- The proposed approach could generalize well to other types of biological sequences like DNA beyond tested protein use cases."
                },
                "weaknesses": {
                    "value": "- The proposed representations might not encode signal about sequential information as amino acid order is not explicitly encoded, which may prove to be necessary in some usecases. \n- Limited ablation studies were performed to analyze the impact of key parameters like number of control points and deviations. \n- (minor) There is a notable computational overhead to the proposed approach, although at a benefit of improved performance."
                },
                "questions": {
                    "value": "- How does the performance scale with much longer input sequences? At what sequence length does the image encoding become unwieldy?\nOpensourcing the code will help reproducibility efforts and also drive adoption of this approach."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3543/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698812555738,
            "cdate": 1698812555738,
            "tmdate": 1699636308313,
            "mdate": 1699636308313,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GXXK7rhte2",
                "forum": "f6KkyweyYh",
                "replyto": "RTWEqrjdqL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3543/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3543/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors Response to the Reviewers Comments"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for appreciating our work and giving us a valuable response. Please find below our response to the comments.\n\n```\nThe proposed representations might not encode signal about sequential information as amino acid order is not explicitly encoded, which may prove to be necessary in some usecases.\n```\n\nThe reviewer rightfully pointed out that order information could be important in some cases, e.g. virus classification where there are virus and non-virus mutations in the biological sequences. However, we want to mention that our the specific scenario, the order of the sequence is not important. The order information comes into play when we want to design numerical vector-based representation. For the image transformation, we are only interested in capturing the mutations, which are a kind of differentiating factor among different class images. \n\n```\nLimited ablation studies were performed to analyze the impact of key parameters like number of control points and deviations.\n```\n\nWe will add detailed plots to show the impact of the mentioned parameter on predictive performance in the camera-ready version of the paper.\n\n\n```\n(minor) There is a notable computational overhead to the proposed approach, although at a benefit of improved performance.\n```\n\nWe thank the reviewer for pointing this out. We want to mention that the proposed method is not parameter-heavy. Since we only use two parameters, i.e.  $m$ (the number of points along each curve) and $ite$ (line 10 in Algorithm 1), which is the number of deviation pair points, the image generation using the proposed method is very fast.\n\n```\nHow does the performance scale with much longer input sequences? At what sequence length does the image encoding become unwieldy? Open sourcing the code will help reproducibility efforts and also drive the adoption of this approach.\n```\n\nSince the proposed method does not have a lot of parameters, having longer-length sequences does not affect scalability performance much. The maximum length for any sequence we tried is for the Human DNA dataset (included in Table 1 of the revised version), where the max length is $18921$. On such bigger length sequences, the image generation time was not affected much. We also want to mention that we do plan to make our code open-source. The main reason for not doing it as part of submission is to maintain anonymity. In the final camera-ready version of the paper, we will provide a URL to the GitHub repository containing our code."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3543/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700443028681,
                "cdate": 1700443028681,
                "tmdate": 1700448781819,
                "mdate": 1700448781819,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ENaazMC1NB",
            "forum": "f6KkyweyYh",
            "replyto": "f6KkyweyYh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3543/Reviewer_FrGV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3543/Reviewer_FrGV"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a new method to transform biological sequences, like protein or DNA sequences, into images using Bezier curves. This allows applying deep learning image models to analyze the sequences. The authors mention that existing/traditional methods convert sequences into numerical features or use Chaos Game Representation (CGR) to create images. But these have limitations like sparsity, high dimensionality, poor representation of sequence information in images.\n\nThe proposed method maps each element (amino acid, nucleotide) of a sequence onto a Bezier curve to create an image. Multiple points on the curve represent each element. This captures more information and patterns in the image compared to traditional CGR-based methods where elements map to fixed pixels. Experiments on three protein datasets for classification tasks show the Bezier method outperforms baselines like FCGR and RandomCGR images, and numerical embedding methods.\n\nIn the results, the authors demonstrate that for subcellular protein localization dataset, Bezier images achieve 40% higher accuracy than FCGR using CNNs. Furthermore, cluster visualization and histograms also show Bezier embeddings preserve structure better. Overall, the paper demonstrates biological sequence analysis benefits from transforming sequences into images via Bezier curves before applying deep learning models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "+ The paper describes a new idea of using Bezier curves to create visual representations of biological sequences. \n+ The results also demonstrate improved performance over baseline methods on several protein sequence classification tasks."
                },
                "weaknesses": {
                    "value": "- In its current format, the paper may not be a good fit for ICLR audience, and the featurization is specific to a small domain of problem.\n- The demonstrated evaluation is limited to only protein sequence datasets related to subcellular localization, virus hosts, etc. It was not clear to me how this idea generalizes to broader range of biological problems."
                },
                "questions": {
                    "value": "1) How much hyper-parameter optimization is needed for this approach? Are these B'ezier features easy to generate\n2) Can this idea be generalized to other areas beyond biological approach? Please comment on the generality of the featurization and fit with ICLR audience."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3543/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699118940976,
            "cdate": 1699118940976,
            "tmdate": 1699636308237,
            "mdate": 1699636308237,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PHix93dXDL",
                "forum": "f6KkyweyYh",
                "replyto": "ENaazMC1NB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3543/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3543/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors Response to the Reviewers Comments"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their comments. Below, please find our detailed response to each of the comment.\n\n```\nIn its current format, the paper may not be a good fit for ICLR audience, and the featurization is specific to a small domain of problem.\n```\n\nWe respectfully would like to disagree with the reviewer. The main idea of this paper is to transform any type of sequence into an image-based representation so that we can open the doors of applying vision models for better classification. Since there is more sequence-based data available for the biological sequences, we decided to use different types of such protein sequences to show the performance of the proposed method. However, the prove the generalizability and the relevance to ICLR community point, we did the following two modifications\n\n``Generalizability``: To show the generalizability, we now included three more datasets that are non-protein sequences. Their details are shown in Table 1 in the revised paper. Firstly, we use human DNA data, which contains nucleotide sequences. The second data that we use now comprises SMILES strings, which are comprised of drug molecules. The third data that we use is the music sequence data, where the audio sequences belong to 10 unique music genres. Now, using protein sequences (as in the initial submission) along with the nucleotide sequences, SMILES strings, and music sequences datasets helps us to show that the proposed method can generalize on sequences from different domains. Here please note that the majority of the baselines (other than RandomCGR) cannot operate on SMILES and Music data since the number of unique characters is>20 and the baseline methods cannot operate on such complex datasets by design. The results for the human DNA data, SMILES string data, and Music sequence data are shown in Table 5, 6, and 7 in the revised version. Compared to Spike2CGR, we can observe that the proposed method outperforms in the majority of the scenarios. Similarly, on all new datasets, the proposed method performance significantly improves for the pre-trained vision models.\n\n``Relevance to ICLR community:`` Considering that the community is interested in the \"Learning Representation\" work, we are proposing a \"representation learning\" method that takes sequences as input and transforms it into image-based \"Representation\", which can then be used for downstream classification task. However, to better show a connection to the machine learning domain, we now included Spike2CGR[1] as one of the baselines (detail included in Table 2 in the revised paper), which works on a similar problem domain for the protein sequences and has recently been published in the \"Springer Machine Learning Journal\". We believe that considering such a method as a baseline could help to justify that the problem is indeed important for the machine learning community as that work is published in one of the highly rated machine learning journals.\n\nWe now believe that considering a recent method as baseline from ML journal along with the new datasets from non-protein sequence domain could help to show the generalizability of proposed method and relevance to the ICLR community.\n\n```\nThe demonstrated evaluation is limited to only protein sequence datasets related to subcellular localization, virus hosts, etc. It was not clear to me how this idea generalizes to broader range of biological problems.\n```\nAs described above, we now expanded our experimental setting by using broader range of biological datasets including nucleotide and SMILES string based sequences as well as Music sequences datasets.\n\n```\nHow much hyper-parameter optimization is needed for this approach? Are these B'ezier features easy to generate\n```\nFor the B\u00e9zier Curve Based Image Generation, there are only two parameters. The first parameter is $m$, which is the number of points along each curve. The second parameter is $ite$ (line 10 in Algorithm 1), which is the number of deviation pair points. Hence our model is not parameter-heavy. However, please note that the hyperparameters for the vision models is different from the B\u00e9zier Curve model as the vision models are only used for the downstream classification task. The details regarding hyperparameters of vision models is already given in Section 4.3.1.\n\n```\nCan this idea be generalized to other areas beyond biological approach? Please comment on the generality of the featurization and fit with ICLR audience.\n```\nThe proposed method can work on any type of sequence data. We already demonstrated that in our above response and in the revised submission, where we included results for nucleotides, SMILES, and Music-based sequence datasets.\n\n\nReferences:\n\n[1] Murad T, Ali S, Khan I, Patterson M. Spike2CGR: an efficient method for spike sequence classification using chaos game representation. Machine Learning. 2023 Aug 28:1-26."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3543/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700441902620,
                "cdate": 1700441902620,
                "tmdate": 1700443670830,
                "mdate": 1700443670830,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]