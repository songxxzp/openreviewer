[
    {
        "title": "BOSS: Diversity-Difficulty Balanced One-Shot Subset Selection for Data-Efficient Deep Learning"
    },
    {
        "review": {
            "id": "KSyojiFzg5",
            "forum": "QcgvtqxRhI",
            "replyto": "QcgvtqxRhI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4411/Reviewer_AoWq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4411/Reviewer_AoWq"
            ],
            "content": {
                "summary": {
                    "value": "This paper inspects the coreset selection problem. A balanced core-set loss bound is first established to depict the generalization loss of the model trained on the subset. The authors claim that the bound is composed of two terms, one corresponds to the \u201cdiversity/coverage\u201d of the coreset, and the other counts for the \u201cdifficulty\u201d of the samples. The bound naturally unifies the diversity-based as well as the difficulty-based works developed previously, and the paper further provides an expressive importance function to optimally balance them. The authors find that the optimal balance is related to the subset size. In the data-scarce regime, the subset is supposed to be representative enough (diverse), while in the data-abundance regime, difficult samples are preferred. The resulting coreset selection strategy is named diversity-difficulty Balanced One-shot Subset Selection (BOSS), Experiments on both synthetic and real datasets are conducted to justify the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.\tUtilizing coreset selection to improve data efficiency is important for machine learning practices. The paper may be valuable to the community trying to address this problem. \n\n2.\tThe paper is clearly written, and the authors do a good job presenting their intuitions developing the method.\n\n3.\tI appreciate the efforts the authors made connecting the core-set loss bound, subset diversity, and sample difficulty, which naturally unified the diversity-based as well as the difficulty-based works developed in previous literature. \n\n4.\tExperiments are conducted on both synthetic dataset and real-world datasets, validating the effectiveness of the proposed method in certain settings."
                },
                "weaknesses": {
                    "value": "1.\tRather than rigorously derived from the balanced core-set loss bound, equation (5) seems to be simply a hand-crafted heuristic selection strategy combining the diversity-based method and the difficulty-based method. In theroem2, the authors claim that EL2N lower bound the label variability in difficult regions. I wonder if this holds for other regions as EL2N/difficulty is universally used in Equation (5). Besides, to minimize Equation (1), for the label variability term, we should minimize something upper bounds $|| \\boldsymbol{y}_i -  \\boldsymbol{y}_j ||$ instead of something lower bounds it like EL2N.\n\n2.\tThe authors claim that the subset size will affect the optimal diversity-difficulty balance, in data data-scarce regime, the diversity dominates while as the subset budget increases, more difficult samples should be picked. While intuitively true and the authors give intuitive explanations, I can\u2019t directly justify the statement directly from the core-set loss bound. More discussion will greatly strengthen the paper.\n\nI will be happy to increase my score if the problems are addressed."
                },
                "questions": {
                    "value": "Please see the weakness part above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4411/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698726141212,
            "cdate": 1698726141212,
            "tmdate": 1699636415103,
            "mdate": 1699636415103,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YFBcitrgva",
                "forum": "QcgvtqxRhI",
                "replyto": "KSyojiFzg5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4411/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4411/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the constructive feedback. \n\n**Q1: Rather than rigorously derived from the balanced core-set loss bound, Equation (5) seems to be simply a hand-crafted heuristic selection strategy combining the diversity-based method and the difficulty-based method**\n\nWe would like to clarify that Equation 5 closely follows our theoretical result in Theorem 1 that decomposes the overall loss bound into the input similarity and label variability. As mentioned in our general response, the involvement of the label variability makes our method substantially different from existing methods (e.g., those based on feature/gradient similarity or the standard facility location function as commented by other reviewers). Another major novelty also comes from the importance function $I(\\cdot)$ that goes beyond a difficulty based metric. It has a much richer functional form that connects the label variability (difficulty) and subset size. This allows us to achieve a dynamic balance between the input similarity and label variability based upon the subset size.  The importance function also bridges the theoretical objective of loss bound given in Theorem 1 and the empirical objective of submodular maximization of Equation 5. It is worth to note that this connection is essential because Equation 1 cannot be directly implemented as the model property ($\\lambda^{\\boldsymbol{\\eta}}$) is unknown.  \n\n**In theorem 2, the authors claim that EL2N lower bound the label variability in difficult regions. I wonder if this holds for other regions as EL2N/difficulty is universally used in Equation (5)** \n\nThe *label variability* is mostly important when we want to select samples from difficult regions or points near the decision boundary. When we move towards the easier region both the EL2N score and label variability are significantly lower compared to the difficult region (as verified in the visualization of synthetic datasets).  So among the easier samples, we only focus on selecting representative samples, and the values of label variability will be small anyway. \n\n**Q2: Besides, to minimize Equation (1), for the label variability term, we should minimize something upper bounds $||{\\bf y}_i-{\\bf y}_j||$ instead of something lower bounds it like EL2N** \n\nThis is a great question! Please refer to our general response regarding \"Connecting label variability with EL2N score\".\n\n**Q3: The authors claim that the subset size will affect the optimal diversity-difficulty balance, in data data-scarce regime, the diversity dominates while as the subset budget increases, more difficult samples should be picked. While intuitively true and the authors give intuitive explanations, I can\u2019t directly justify the statement directly from the core-set loss bound** \n\nThank you for this insightful question! To more clearly show how the subset size impacts the balanced core-set loss bound, we conduct additional experiments on the synthetic data, aiming to quantify and visualize the two major components in the loss bound: $\\sum_i||{\\bf x}_i-{\\bf x}_j||$ and $\\sum_i||{\\bf y}_i-{\\bf y}_j||$, which essentially captures the feature distance and label distance between the selected subset and the full set, respectively. As can be seen from Figure 9 (a) in the Appendix of the revised paper, for a small subset size, when choosing the subset based on the label variability (or difficulty), it can help to quickly reduce the label distance. However,  it also leads to a very large feature distance that makes the overall bound large. Figure 9 (b) further confirms this because the selected samples misses some major regions of the data distribution as stated in the main paper. In contrast, when focusing on choosing samples based on the first component (i.e., diversity), the feature distance drops significantly as shown in Figure 9 (c), which implies that the selected subset can represent the entire data distribution well. This is further confirmed by  Figure 9 (d), which visualizes the distribution of the selected data samples. As more samples are selected, they will start to cover the difficult regions, which can effectively bring down the label distance as shown in Figure 9 (c)."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4411/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700335125907,
                "cdate": 1700335125907,
                "tmdate": 1700350623238,
                "mdate": 1700350623238,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mE5ZxTnktt",
                "forum": "QcgvtqxRhI",
                "replyto": "KSyojiFzg5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4411/Reviewer_AoWq"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4411/Reviewer_AoWq"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the clarification"
                    },
                    "comment": {
                        "value": "Thanks for the clarification, which has addressed most of my questions.  I like the endeavor made to combine the diversity-based method and the difficulty-based method. I understand the intuition relating the bound to the final method, However, I still feel that the method is not directly (rigorously) derived from the theoretical analysis."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4411/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700589783846,
                "cdate": 1700589783846,
                "tmdate": 1700589867953,
                "mdate": 1700589867953,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "8fnLXbX5Nz",
            "forum": "QcgvtqxRhI",
            "replyto": "QcgvtqxRhI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4411/Reviewer_BNoZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4411/Reviewer_BNoZ"
            ],
            "content": {
                "summary": {
                    "value": "One major drawback of standard subset selection is that the subset cannot accurately reflect the join data distribution. To tackle this drawback, BOSS aim to construct an optimal subset for data-efficient traning.\nSamples are chosen for the subset with the goal of minimizing a balanced core-set loss bound.\nA trade-off exists between feature similarity and label variability in the balanced core-set loss bound. To this end, it can take into account subset size, data type, variety, and difficulty."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed method is supported by prior evidence and is well stated.\n- They balance the variety and difficulty of subset selection given a subset size.\n- There are considerable performance improvements using the proposed methods"
                },
                "weaknesses": {
                    "value": "- For a fixed number of epochs, the entire dataset must be used to train a model.\n- Absence of variety in experiments. ResNet is insufficient on its own to verify the efficacy of the proposed method. To validate their approach, it is necessary to conduct experiments on more models.\n- There is no comparison between the entire train duration and the time required to generate a subset. The problem with the proposed process is that all of the data must be trained so that authors should perform experiments with computation complexity."
                },
                "questions": {
                    "value": "- It is difficult to discern what the author intended when they write, \"missed some critical regions(upper middle area)\", as Figure 1(a) on page 2. \n- What does the symbol gamma represent in Theorem.1 on page 4? \n- What is the rationale behind the paper's assertion that \"CCS still does not strike the right balance between diversity and the difficulty of subset selection\"?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4411/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698741793000,
            "cdate": 1698741793000,
            "tmdate": 1699636414918,
            "mdate": 1699636414918,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "yxc5V56ANS",
                "forum": "QcgvtqxRhI",
                "replyto": "8fnLXbX5Nz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4411/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4411/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the constructive feedback. \n\n**Q1: the entire dataset must be used to train a model for a fixed number of epochs** \n\nWe would like to clarify that it is a common practice for one-shot subset selection methods to perform initial training on full data for the first few epochs. This is followed by all the major one-shot subset methods, including CCS, LCMAT, Moderate, EL2N, and Forgetting. Such initial full-set training is essential to obtain necessary information (e.g., gradients, features, EL2N scores) about the data before subset selection can be performed. Furthermore, since the initial training only takes a few epochs, it introduces limited overhead (see our response to Q3 for details). \n\nWhen compared with the dynamic subset selection, although a small number of samples is used to train the model at a time, the dynamic subset selection will be conducted using a large fraction of data throughout the training. This is not feasible in applications such as continual learning where the full data is accessible only once.\n\n**Q2: experiments on more models** \n\nThank you for this great suggestion! We have conducted additional experiments on both EfficientNet [1] and ViT [2]. Overall, we have used four models ResNet18 (for SVHN, CIFAR10, and CIFAR100), ResNet34 (for TinyImageNet), EfficientNet, and ViT (for CIAFR100). We are able to show the effectiveness and consistent trend of our method as compared with competitive baselines for all of these models. \n\n[1] Tan, Mingxing, and Quoc Le. \"Efficientnet: Rethinking model scaling for convolutional neural networks.\" Proceedings of the 36th International Conference on Machine Learning, PMLR 97:6105-6114, 2019.\n\n[2] Dosovitskiy, Alexey, et al. \"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.\" International Conference on Learning Representations. 2021.\n\nViT Result (CIFAR100):\n| Subset | Random | Moderate | CCS | BOSS |\n|--------|--------|----------|-----|------|\n| 10%    | 78.49 \u00b1 0.7| 50.41 \u00b1 0.7| 78.62 \u00b1 0.3| **79.97 \u00b1 0.4**|\n| 20%    | 81.87 \u00b1 0.7| 69.81 \u00b1 0.5| 81.95 \u00b1 0.8| **83.19 \u00b1 0.1**|\n| 30%    | 83.98 \u00b1 0.2| 77.66 \u00b1 0.5| 84.93 \u00b1 0.1| **85.08 \u00b1 0.1**|\n| 50%    | 85.88 \u00b1 0.1| 84.19 \u00b1 0.0| 85.88 \u00b1 0.1| **86.55 \u00b1 0.1**|\n\nEfficient Net Result (CIFAR100):\n| Subset | Random | Moderate | CCS | BOSS |\n|--------|--------|----------|-----|------|\n| 10%    | 30.51 \u00b1 1.0| 32.59 \u00b1 1.3| 36.91 \u00b1 2.2| **42.64 \u00b1 0.6**|\n| 20%    | 43.52 \u00b1 1.9| 42.04 \u00b1 2.2| 46.53 \u00b1 3.7| **53.39 \u00b1 0.3**|\n| 30%    | 55.48 \u00b1 0.7| 55.26 \u00b1 1.7| 56.89 \u00b1 0.3| **60.37 \u00b1 0.4**|\n| 50%    | 64.05 \u00b1 0.7| 63.91 \u00b1 0.3| 63.59 \u00b1 0.5| **68.27 \u00b1 0.5**|\n\n**Q3: comparison between train time and selection time; experiments with computation complexity** \n\nWe compare the time taken for *Subset Selection*, and *Subset Training*. The *Subset Selection* consists of initial training for 10 epochs on the full set, and the lazy greedy algorithm to select the subset. The *Subset Selection* time is shorter compared to training on the subset (*Subset Training*) and is much more efficient compared to training on the full set (*Full Set Training*). The time for the subset selection algorithm (time excluding the initial training) is significantly small compared to the initial training time and this step does not require GPU computation. \nWe measure the time in seconds using NVIDIA RTX A6000 GPU for CIFAR10 and CIFAR100 datasets.\n\nTime comparison results\n| Dataset   | Subset Size | Subset Selection (Initial Training) | Subset Selection (Selection Algorithm) | Subset Training | Full Set Training |\n|-----------|-------------|-------------------------------------|-----------------------------------------|------------------|-------------------|\n| CIFAR100  | 10%         |                                     | 9                                   | 346              |                   |\n|           | 20%         | 219                                 | 13                                  | 587              | 4387              |\n|           | 30%         |                                     | 14                                  | 800              |                   |\n|           | 50%         |                                     | 15                                  | 1816             |                   |\n| CIFAR10   | 10%         |                                     | 11                                  | 342              |                   |\n|           | 20%         | 173                                 | 19                                  | 571              | 3468              |\n|           | 30%         |                                     | 22                                  | 801              |                   |\n|           | 50%         |                                     | 27                                  | 1244             |                |\n\n**To be continued...**"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4411/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700334952153,
                "cdate": 1700334952153,
                "tmdate": 1700336984264,
                "mdate": 1700336984264,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "U3493f97CB",
                "forum": "QcgvtqxRhI",
                "replyto": "8fnLXbX5Nz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4411/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4411/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Continuing...**\n\n**Q4: meaning of \"missed some critical regions\", Figure 1(a)** \n\nThe critical regions refer to the regions near the boundary. We have annotated those regions in Figure 1 on page 2 of the revised paper. \n\n**Q5: what does $\\gamma$ represent in Theorem 1?** \n\nThis term is related to Hoeffding's bound. $\\gamma$ is the probability that the bound does not hold true.  $1 - \\gamma$ is the probability that the bound holds true.\n\n**Q6: rationale behind \"CCS still does not strike the right balance between diversity and difficulty\"** \n\nAs we have shown with the theoretical analysis (please see our general response for more details), the optimal selection requires targeting different difficulty levels according to the subset size, which is impossible for CCS."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4411/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700334989735,
                "cdate": 1700334989735,
                "tmdate": 1700336918340,
                "mdate": 1700336918340,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7ZlHMfLcon",
                "forum": "QcgvtqxRhI",
                "replyto": "8fnLXbX5Nz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4411/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4411/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate your feedback, and we hope our responses have addressed your queries and clarified any confusion related to our work. Following your suggestion, we conducted experiments on additional models beyond ResNet. Additionally, in an attempt to show the computational complexity, we have included a table comparing the time taken to select and train on the subset. The main paper has been revised in accordance with your recommendations. We hope that these answers meet your expectations, and we kindly ask for your consideration in updating your assessment. Please let us know if you have any further concerns, we would be more than happy to provide any additional information."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4411/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700602058496,
                "cdate": 1700602058496,
                "tmdate": 1700602058496,
                "mdate": 1700602058496,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "meljsuyMbG",
            "forum": "QcgvtqxRhI",
            "replyto": "QcgvtqxRhI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4411/Reviewer_jBvt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4411/Reviewer_jBvt"
            ],
            "content": {
                "summary": {
                    "value": "The proposed method tackles the problem of data efficient subset selection. They claim that existing methods underperform in terms of generalization since they aim to find subsets that are either diverse or difficult. They propose a new technique called BOSS (diversity-difficulty Balanced One-shot Subset Selection) which aims to find an optimal subset that faithfully represent the joint data distribution which is comprised of both feature and label information. They do so by optimizing a novel balanced core-set loss."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is well written and clearly illustrates the underlying problem and the proposed solution.\n- The paper covers a good chunk of related work in Sec 1\n- The experiments are on multiple datasets\n- Ablations studies help answer trade offs between diversity, difficulty and cutoff."
                },
                "weaknesses": {
                    "value": "My main concern is the novelty of the work which can be improved by reinforcing the effectiveness of the proposed method. A few questions and suggestions are as follows:\n\n- The proposed function is very similar to the standard facility location function, which is $\\sum_{i \\in V} max_{j \\in A} Sim(x_i, x_j).$ The function additionally has the I(.) term which is the main contribution in my opinion. To fully understand the effect of the additional I(.) term, the authors should compare with the facility location submodular function.\n\n- The authors discuss multiple relevant papers in this work but do not add comparison with many of them in the experiments. It would be great to compare with a few more method, e.g., Grad Match.\n\n- The 'balanced' aspect of the proposed loss is still not clear to me. It would be imperative to add some experiments to show how the selected subsets are balanced. It would be even better if the authors can show some experiments on class imbalanced data. Most datasets currently in the experiments barely have any imbalance, which makes this analysis difficult."
                },
                "questions": {
                    "value": "- Questions are mainly listed in the weaknesses section. Please refer them."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4411/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699253418340,
            "cdate": 1699253418340,
            "tmdate": 1699636414830,
            "mdate": 1699636414830,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XEQHy3TypM",
                "forum": "QcgvtqxRhI",
                "replyto": "meljsuyMbG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4411/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4411/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the constructive feedback. \n\n**Q1: The novelty of the work** \n\nPlease refer to the general response as we distinguish the proposed method from the standard facility location function.\n\n**Q2: To fully understand the effect of the additional $I(\\cdot)$ term, the authors should compare with the facility location submodular function.** \n\nThank you for the suggestion. In the ablation study, we present subset selection using only the diversity component, which is the same as the standard submodular facility location function as suggested by the reviewer. Our result shows that by maximizing the combination of the *standard facility location function* (diversity) and the *importance function* (function of difficulty and subset size), we can achieve significant improvement compared to only using the *standard facility location submodular function* (diversity).  \n\nAdditionally, we want to emphasize that the importance function $I(\\cdot)$ itself is not the only main contribution of our work. Our contribution also lies in the theoretical work bringing together the input similarity, label variability, and subset size, which justifies the need to maximize the joint objective of the importance function and submodular function (Equation 5) in order to minimize the loss bound in Equation 1.\n\nWe also compare with other baselines such as CRAIG and Adacore which are also based on the submodular location function but use the gradients instead of the features.\n\n**Q3: Compare with more method, e.g., Grad Match** \n\nFollowing the reviewer's suggestion, we have compared with two additional baselines, including GradMatch and Adacore. The complete table is updated in the revised paper (see Table 1 on page 8). Our proposed method shows a clear advantage over these two baselines on all settings, which further justifies its effectiveness. We would also like to clarify that the representative-based subset selection methods are not initially used for one-shot subset selection but rather for dynamic subset selection. Therefore, the performance cannot be directly compared to the respective papers as we are evaluating them in a one-shot setting. \n\n| Dataset       | Subset | GradMatch | Adacore | BOSS(Ours) |\n|---------------|--------|-----------|---------|------------|\n| Tiny ImageNet | 10%    | 23.68 \u00b1 1.5| 24.12 \u00b1 1.5| **33.22 \u00b1 0.5**|\n|               | 20%    | 38.20 \u00b1 1.3| 37.94 \u00b1 0.6| **45.73 \u00b1 0.4**|\n|               | 30%    | 44.93 \u00b1 0.6| 44.72 \u00b1 0.5| **51.75 \u00b1 0.4**|\n|               | 50%    | 53.81 \u00b1 0.2| 53.37 \u00b1 0.4| **57.88 \u00b1 0.2**|\n| CIFAR 100     | 10%    | 36.68 \u00b1 0.6| 37.65 \u00b1 0.8| **47.58 \u00b1 0.5**|\n|               | 20%    | 53.16 \u00b1 2.2| 52.79 \u00b1 0.8| **61.44 \u00b1 0.7**|\n|               | 30%    | 63.02 \u00b1 1.2| 62.28 \u00b1 1.2| **67.89 \u00b1 0.2**|\n|               | 50%    | 70.68 \u00b1 0.4| 71.19 \u00b1 0.3| **74.03 \u00b1 0.3**|\n| CIFAR 10      | 10%    | 72.26 \u00b1 0.5| 72.65 \u00b1 0.9| **79.47 \u00b1 0.5**|\n|               | 20%    | 84.30 \u00b1 0.9| 84.30 \u00b1 1.2| **87.82 \u00b1 0.9**|\n|               | 30%    | 88.47 \u00b1 0.6| 88.37 \u00b1 1.2| **92.15 \u00b1 0.6**|\n|               | 50%    | 91.89 \u00b1 0.4| 92.67 \u00b1 0.5| **94.36 \u00b1 0.2**|\n| SVHN          | 8%     | 84.31 \u00b1 1.8| 82.31 \u00b1 2.6| **89.52 \u00b1 0.8**|\n|               | 12%    | 88.99 \u00b1 1.0| 88.41 \u00b1 1.3| **93.18 \u00b1 0.5**|\n|               | 16%    | 90.42 \u00b1 0.8| 90.34 \u00b1 0.8| **94.31 \u00b1 0.3**|\n|               | 20%    | 91.56 \u00b1 0.4| 91.95 \u00b1 0.8| **95.08 \u00b1 0.3**|\n\n**Q4: the 'balanced' aspect of the proposed loss; experiments on class imbalanced data** \n\nWe would like to clarify that the 'balanced' keyword in our work refers to the interaction of the *input similarity* component and the *label variability* component of the loss bound as derived in Theorem 1 with respect to the subset. Specifically, focusing on improving one component might make another component worse thus there is a need for balancing between those two components. \n\nIn our evaluation, we follow the standard setting of most existing works, where the methods are primarily evaluated on balanced data. However, we understand that in a real-life scenario, the data could be imbalanced. So we can certainly evaluate our method in some class imbalance setting.\n\nWe have employed two ways of creating imbalanced data: exponential and step-wise. In exponential, we decrease the class size using exponential decay $N_{c_i}\\times e^{-0.01i}$ where $N_{c_{i}}$ is the number of samples for class $c_i$. In step-wise imbalance, we prune 80\\% of data from 20\\% of classes. For the baselines, we chose the most recent competitive methods (CCS and Moderate) in addition to the random method. As can be seen, the results show our method consistently outperforms the competitive baselines under different class imbalance settings. \n\n**To be continued...**"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4411/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700334476709,
                "cdate": 1700334476709,
                "tmdate": 1700336865091,
                "mdate": 1700336865091,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8bnAwHgpZj",
                "forum": "QcgvtqxRhI",
                "replyto": "meljsuyMbG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4411/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4411/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Continuing...**\n\nImbalance result for CIFAR 100, exponential\n| Subset | Random | Moderate | CCS | BOSS |\n|--------|--------|----------|-----|------|\n| 10%    | 27.39 \u00b1 0.9| 25.37 \u00b1 1.7| 29.41 \u00b1 0.5| **36.63 \u00b1 0.9**|\n| 20%    | 42.82 \u00b1 1.1| 40.57 \u00b1 0.6| 44.36 \u00b1 1.7| **50.91 \u00b1 0.6**|\n| 30%    | 52.51 \u00b1 0.7| 50.00 \u00b1 3.0| 50.87 \u00b1 1.4| **57.15 \u00b1 0.5**|\n| 50%    | 63.03 \u00b1 0.6| 61.76 \u00b1 0.2| 61.86 \u00b1 0.5| **66.72 \u00b1 0.1**|\n\nImbalance result for CIFAR 100, step-wise\n| Subset | Random | Moderate | CCS | BOSS |\n|--------|--------|----------|-----|------|\n| 10%    | 31.66 \u00b1 0.7| 27.02 \u00b1 0.7| 33.60 \u00b1 0.9| **38.72 \u00b1 0.9**|\n| 20%    | 47.36 \u00b1 0.9| 41.77 \u00b1 2.9| 46.82 \u00b1 0.6| **53.75 \u00b1 0.3**|\n| 30%    | 56.64 \u00b1 0.2| 52.31 \u00b1 0.6| 52.81 \u00b1 1.1| **58.37 \u00b1 0.4**|\n| 50%    | 62.19 \u00b1 0.9| 59.96 \u00b1 0.7| 60.25 \u00b1 0.2| **66.03 \u00b1 0.2**|"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4411/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700334586863,
                "cdate": 1700334586863,
                "tmdate": 1700336964245,
                "mdate": 1700336964245,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1MVptgkgCg",
                "forum": "QcgvtqxRhI",
                "replyto": "meljsuyMbG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4411/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4411/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely appreciate your effort in reviewing our paper and the valuable feedback that you have provided. We hope that we have thoroughly addressed your inquiries and cleared any confusion regarding our work. We took into account your suggestion to incorporate additional baselines, conducted an evaluation of our work on an imbalanced dataset, and have accordingly made updates to the main paper. We hope that these responses align with your expectations, and we would be grateful if you would consider revisiting your assessment. We are happy to address any further concerns or queries you may have."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4411/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700602025820,
                "cdate": 1700602025820,
                "tmdate": 1700602025820,
                "mdate": 1700602025820,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]