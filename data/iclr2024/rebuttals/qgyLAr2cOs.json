[
    {
        "title": "Fixed-Budget Best Arm Identification with Variance-Dependent Regret Bounds"
    },
    {
        "review": {
            "id": "T0qqnJHpN8",
            "forum": "qgyLAr2cOs",
            "replyto": "qgyLAr2cOs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9273/Reviewer_qfgN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9273/Reviewer_qfgN"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers Best Arm Identification problem under the fixed-budget setup. It aims at minimizing the expected simple regret, i.e., the expected difference between the oracle best arm and the recommended arm. An asymptotic worst-case lower bound concerning the variances of the arms is provided. An algorithm AS-AIPW strategy is devised with almost matching worst-case upper bounds. Compared to the existing literature, it utilizes more information of the distribution (i.e., the variance) to refine the arm allocation rules. Additionally, it considers the benefit of taking contextual information into account. Experiments are also conducted to illustrate the empirical performances."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper extends the BAI problem under the fix-budget setup to the context-aware setup. Both the lower bounds and upper bounds involve a context-aware variables that tighten the bounds.\n\n- The lower bound result is appreciated. While the proof is complicated, the result yields theoretical foundations on why we should pull the arms according to the allocation proportional to their variances in order to hit the lower bound. It also resolves the remaining lower bound problem in [1] to some extent (as [1] considers the misidentification probability instead of the expected simple regret). I believe this is the main novelty of the paper and is of theoretical interest.\n\n- An algorithm AS-AIPW is designed whose upper bound asymptotically matches the lower bound in the worst-case up to a factor of $log K$. A non-asymptotic upper bound is also given, which helps us to understand the convergence rate.\n\n- Empirical studies of the algorithm are carried out to illustrate the performance.\n\n[1] Lalitha, A., Kalantari, K., Ma, Y., Deoras, A., and Kveton, B. Fixed-budget best-arm identification with heterogeneous reward variances. In Conference on Uncertainty in Artificial Intelligence, 2023."
                },
                "weaknesses": {
                    "value": "- While experiments are conducted to compare multiple algorithms, little improvement has been observed of the proposed algorithm compared to the existing ones, even in the case where the variances are heterogeneous (which is claimed to be favorable for the proposed algorithm). In addition, the algorithm design is somewhat expected given the G-optimal design and the intuition in [1].\n\n- [1] also considers incorporating variances into the algorithm. The proposed algorithm is similar to [1] under the sole context case in the sense that both pull arms according to the (empirical) variances. So a more detailed discussion/comparison with [1] in terms of the algorithm design, the bounds (on the misidentification probability and expected simple regret) and the empirical performances is appreciated.\n\nMinors:\n- Page 3 Line 3: Instead of \"$A_t$ is $\\mathcal{F}_t$-measurable\", I think $A_t$ is only $\\sigma(X_1,A_1,Y_1,\\dots,X_t)$-measurable. Please kindly check.\n- Is $\\pi^{Uniform-EBM}$ a typo? Should be $\\pi^{Uniform-EBA}$\n- Page 6, Line 3 in subsection 4.1, the numerator of the allocation for arm 1 is $\\sigma^1$ \n- Page 6, Line 2 after Theorem 3.8, I suppose $X_t$ should be $X$ in the inequalities? In addition, I do not follow why $E^X[\\frac{(\\sigma^1(X))^2}{w(1|X)}+\\frac{(\\sigma^2(X))^2}{w(2|X)}]\\geq\\max_{a\\in[2]}\\sqrt{E^X[\\frac{(\\sigma^a(X))^2}{w(a|X)}}]$, as $\\frac{1}{8}+\\frac{1}{8}<\\sqrt{1/8}$."
                },
                "questions": {
                    "value": "- Can you give more explanations on $\\underline{C}$ at the end of Page 4? From my understanding, in [2], the forced exploration is a design of the algorithm. And in [3], $\\beta$ is also a hyper parameter (thus, a design) of the algorithm. But here $\\underline{C}$ is an assumption on the problem instance, so I think they are not similar.\n- Given that the optimal allocation is known, is it possible to adopt a tracking sampling rule, i.e., sampling the arms in a way such that the empirical arm allocation approaches the optimal allocation. As indicated by section 2.3 in [4], sampling according to a distribution can make the convergence speed slow. Can you give comments on the allocation rule?\n- It would be better if you describe the experiment designs in more detail. In particular, \n\t- for the Sequential Halving-based algorithm, it only recommends an arm at the end of the experiment, how to compute the simple regret of the arm at $t\\in \\{ 1000,\\dots,50000 \\}$? And it would also be interesting to see how SHAdaVar behaves without contextual information while the other algorithms have access to contextual information in App. I.2.\n\t- for the other algorithms, how you incorporate contextual information in the original algorithm.\n\nPlease also refer to the Weaknesses section. I'd appreciate it if you can resolve my concerns.\n\n[2] Garivier, A. and Kaufmann, E. Optimal best arm identification with fixed confidence. In Conference on Learning Theory, 2016.\n\n[3] Russo, D. Simple bayesian algorithms for best-arm identification. Operations Research, 68(6), 2020.\n\n[4] Fiez, T., Jain, L., Jamieson, K. G., & Ratliff, L. Sequential experimental design for transductive linear bandits.\u00a0_Advances in neural information processing systems_,\u00a032, 2019."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9273/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9273/Reviewer_qfgN",
                        "ICLR.cc/2024/Conference/Submission9273/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9273/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698128130472,
            "cdate": 1698128130472,
            "tmdate": 1700529482711,
            "mdate": 1700529482711,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2fRzuGf5o8",
                "forum": "qgyLAr2cOs",
                "replyto": "T0qqnJHpN8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9273/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9273/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Re: Official Review of Submission9273 by Reviewer qfgN"
                    },
                    "comment": {
                        "value": "We appreciate your comments and will revise our manuscript accordingly during this rebuttal phase.\n\nWe first answer the reviewer's comment on the comparison with [1].\n\n[1] Lalitha, A., Kalantari, K., Ma, Y., Deoras, A., and Kveton, 2023.\n\n-----------------------------------------------\n\n> a more detailed discussion/comparison with [1] in terms of the algorithm design, the bounds (on the misidentification probability and expected simple regret), and the empirical performances is appreciated.\n\nWe introduced [1] as a recent existing work and compared our algorithm with the algorithm proposed by [1] in simulation studies. We also briefly discussed [1] in the Appendix as follows:\n\n> Therefore, ... Lalitha et al. (2023) also provide variance-dependent BAI strategies, but their\noptimality needs to be clarified.\n\n> Only when variances are known ... However, Lalitha et al. (2023) proposes using\nthe ratio of variances with successive halving, ....\n\nThus, we have already sufficiently discussed [1].\n\n---------------\n\nRegarding [1], we limit our analysis due to ambiguities in existing literature. Our concerns:\n- [1] is not the first work of BAI with heterogeneous variances. For example, given known variances, many existing studies, such as [2,3.4.5,6], have already proposed algorithms using heterogeneous variances. \n- However, the lower bounds have been unknown when $K\\geq 3$ with general distributions. That is, although there are various methods, it has been unclear which algorithm is optimal. \n- When $K=2$ and variances are known, [3] gives an asymptotically optimal algorithm for Gaussian distributions with heterogeneous variances.\nHow we interpret the results in the existing literature is an open issue.\n\n[2] Glynn, P. and Juneja, S. A large deviations perspective on ordinal optimization, 2004.  \n[3] Kaufmann, E., Capp\u00e9, O., and Garivier, A. On the complexity of best-arm identification in multiarmed bandit models, 2016.  \n[4] Adusumilli, K. Risk and optimal policies in bandit experiments, 2021.  \n[5] Armstrong, T. B. Asymptotic efficiency bounds for a class of experimental designs, 2022.  \n[6] Chen C-H, Lin J, Y\u00fccesan E, Chick SE, Simulation budget allocation for further enhancing the efficiency of ordinal optimization, 2000.   \n\n---------------\n\nFurther issues with [1]:\n- It is unknown how [1] relates to existing studies using heterogenous variances. \n- When $K =2$ and variances are known, the algorithm of [1] does not match an existing optimal algorithm, known as the Neyman allocation.\n- It seems that [1] does not match existing conjectures of optimal algorithms, such as Example 1 of [1]. \n- It seems that the upper bound of [1]' algorithm does not align with the lower bound provided by [3]. \n- For example, [7] recently derives a lower bound for minimization of the probability of misidentification from the results of [3] under a small-gap regime. According to the result, the target allocation ratio is given as\n$$w^*(a^*(P)) = \\frac{\\sigma^{a^*(P)}}{\\sigma^{a^*(P)} + \\sqrt{\\sum_{b\\in[K]\\setminus \\{a^*(P)\\}}}(\\sigma^b(P))^2}$$ \nand \n$$w^*(a) = (1 w^*(a^*(P)))\\frac{(\\sigma^b)^2}{\\sum_{b\\in[K]\\setminus \\{a^*(P)\\}}(\\sigma^b(P))^2}.$$\nThis target allocation ratio is also different from the one in [1]. \n\n[7] Kato (2023), Locally Optimal Best Arm Identification with a Fixed Budget.\n\n---------------\n\nFurthermore, it is known that algorithms would be significantly different between cases where variances are known and unknown [3]. When variances are unknown and need to be estimated, the probability of misidentification is significantly affected by the estimation error.\n\n-----------------------------------------------\n\nWe categorize existing work as\n1. Unknown variance with asymptotic analysis. \n    - We give an answer for this problem in a case with expected simple regret minimization. \n    - In minimization of the probability of misidentification, it is still an open issue.\n2. Unknown variance with non-asymptotic analysis.\n3. Known variance with asymptotic analysis \n     - When $K=2$, optimal algorithms are known.\n     - When $K\\geq 3$, there are several conjectures, but it is still an open issue.\n4. Known variance with asymptotic analysis.\n\nNote that optimality in fixed-budget BAI itself is an open issue [8]. If [1] is optimal, we conjecture that it is optimal in case 4. However, it is still unsolved. \n\n[8] Qin, C. Open problem: Optimal best arm identification with fixed-budget, 2022.\n\n---------------\n\nOur study was conducted independently of [1]. We will clarify it to the meta-reviewer.\n\nWe recognize [1]'s contributions, especially in incorporating variances into the successive halving algorithm. However, theoretical gaps and limited comparative analysis in [1] pose challenges. While we can incorporate these points into our manuscript, a detailed analysis of [1] is beyond our scope; we referenced it as a recent study."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9273/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700260087180,
                "cdate": 1700260087180,
                "tmdate": 1700260087180,
                "mdate": 1700260087180,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UqWv2eS6Oy",
                "forum": "qgyLAr2cOs",
                "replyto": "T0qqnJHpN8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9273/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9273/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Re2: Official Review of Submission9273 by Reviewer qfgN"
                    },
                    "comment": {
                        "value": "We then reply to each question raised by the reviewer as follows. We also thank you for pointing out typos. We will fix them in the next update. \n\n------------------\n\n**Q1**.  \n> Comparison with [1]\n\n**A1**. \nIn addition to the points raised by us in the previous post, there are the following differences between our study and their study.\n1. Objective function: While we minimize the expected simple regret, [1] minimizes the probability of misidentification. Although the evaluation of the probability of misidentification has several open issues, as raised by [8], we can still address the minimization of the expected simple regret as well as [9] and [10]. \n2. Contribution: We do not think that the proposition of variance-dependent algorithms itself is a strong contribution because there are several existing works. Our contribution lies in the proposition of a variance-dependent algorithm with lower bounds.\n3. Incorporation of contextual information as a generalization of BAI without contextual information.\n\nWe will not add the contents in the previous post because they are still our conjectures and open issues. Instead, we mention the above differences in the next update in this rebuttal phase.\n\n[9] Bubeck, S., Munos, R., and Stoltz, G. Pure exploration in finitely-armed and continuous-armed bandits, 2011.  \n[10] Komiyama, J., Ariu, K., Kato, M., and Qin, C. Rate-optimal bayesian simple regret in best arm identification, 2023.\n\n------------------\n\n**Q2**.  \n> Why $E^X[\\frac{(\\sigma^1(X))^2}{w(1|X)}+\\frac{(\\sigma^2(X))^2}{w(2|X)}]\\geq\\max_{a\\in[2]}\\sqrt{E^X[\\frac{(\\sigma^a(X))^2}{w(a|X)}}]$?\n\n**A2**. \nThis is our typo. Thank you for pointing it out. It should be $\\inf_w E^X[\\frac{(\\sigma^1(X))^2}{w(1|X)}+\\frac{(\\sigma^2(X))^2}{w(2|X)}]\\geq \\inf_w  \\max_{a\\in[2]}\\sqrt{E^X[\\frac{(\\sigma^a(X))^2}{w(a|X)}}]$; that is, the optimization for $w$ is lacked. \n\n------------------\n\n**Q3**. \n> From my understanding, in [2], the forced exploration is a design of the algorithm. And in [3], $\\beta$ is also a hyper parameter (thus, a design) of the algorithm. But here $\\underline{C}$ is an assumption on the problem instance.\n\n**A3**.   \nWe can interpret that $\\beta$ is an assumption on the problem instance, while $\\underline{C}$ can be interpreted as a hyperparameter. When showing the optimality in the top two algorithms, we need to assume that $\\beta$ matches the allocation ratio of the best arm, which means that we need to make an assumption between $\\beta$ and the problem instance (allocation ratio depends on the problem instance). In contrast, when we consider that $\\underline{C}$ is a hyperparameter, we remove the assumption about $\\underline{C}$ from the definition of bandit models and put assumptions in deriving the upper bound.\n\nRegarding an assumption of $\\underline{C}$, it is also used to define the KL divergence in the top two algorithms. If $\\underline{C} = 0$, we cannot appropriately define the KL divergence, which is needed in various parts of the top two algorithms. \n\n------------------\n\n**Q4**.  \n> Given that the optimal allocation is known, is it possible to adopt a tracking sampling rule, i.e., sampling the arms in a way such that the empirical arm allocation approaches the optimal allocation. \n\n\n**A4**. \nIf the optimal allocation is known, we just assign each arm with the ratio without adaptive exploration when there is no contextual information; that is, we assign first $\\lceil Tw^*(1)\\rceil$ observations to arm $1$,..., and $\\lceil Tw^*(K)\\rceil$ observations to arm $K$. When contextual information is available, there are several ways for arm draws. For example, we can draw arms as well as Hahn et al. (2011). \n\n------------------\n\n**Q5**.  \n> for the Sequential Halving-based algorithm, how to compute the simple regret of the arm at each $t\\in { 1000,\\dots,50000 }$? \n\n**A5**.  \nThank you for your suggestion. As you pointed out, we conducted a new independent trial for the Sequential Halving-based algorithm for each $t$. We clarify this point in the next update.\n\n------------------\n\n**Q6**.  \n> And it would also be interesting to see how SHAdaVar behaves without contextual information.\n\n**A6**. \nWe will add the experiments. If possible, we will update the manuscript, including the new experiments, during the rebuttal phase. Otherwise, we will add them when they are camera-ready.\n\n------------------\n\n**Q7**.  \n> for the other algorithms, how you incorporate contextual information in the original algorithm.\n\n**A7**.  \nIn the experiments in the Appendix, we only use contextual information for our proposed algorithm. For fairness, we do not use contextual information both for our proposed and existing algorithms in the experiments of the main text. We clarify these points in the next revision. Note again that the proposition of contextual BAI algorithm is also our contribution, and to the best of our knowledge, there is no appropriate competitors that use contextual information."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9273/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700264545204,
                "cdate": 1700264545204,
                "tmdate": 1700265410247,
                "mdate": 1700265410247,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "eFQWS6npSE",
                "forum": "qgyLAr2cOs",
                "replyto": "UqWv2eS6Oy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9273/Reviewer_qfgN"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9273/Reviewer_qfgN"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks a lot for your detailed response and most of my concerns have been properly addressed!\n\nIn terms of the second question in my initial review:\n> Given that the optimal allocation is known, is it possible to adopt a tracking sampling rule, i.e., sampling the arms in a way such that the empirical arm allocation approaches the optimal allocation. As indicated by section 2.3 in [4], sampling according to a distribution can make the convergence speed slow. Can you give comments on the allocation rule?\n\nlet me clarify my question: here the ``optimal allocation'' refers to the computed allocation based on the empirical estimates, e.g., the empirical variances. In Algorithm AS-AIPW, it samples an arm according to the empirical optimal allocation. According to [4], sampling according to a distribution can have slow convergence speed. Therefore, is it possible or better to use a tracking-type sampling rule, which samples the arm $ A_t = \\arg\\min_{a} T_t(a|X_t)-t \\hat{w}_t(a|X_t)$ (where $T_t(a|X_t)$ is the number of times arm $a$ is sampled under $X_t$ up to time step $t$)? \n\nHope this clarifies and can you please comment on this?"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9273/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700463935547,
                "cdate": 1700463935547,
                "tmdate": 1700463935547,
                "mdate": 1700463935547,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sHBQwMcgSV",
                "forum": "qgyLAr2cOs",
                "replyto": "T0qqnJHpN8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9273/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9273/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Re: Official Comment by Reviewer qfgN"
                    },
                    "comment": {
                        "value": "We sincerely appreciate your feedback, and thank you for clarifying your second question.\n\n**Q**. \n> here the ``optimal allocation'' refers to the computed allocation based on the empirical estimates ... Therefore, is it possible or better to use a tracking-type sampling rule, which samples the arm $A_t = \\arg\\min_{a} T_t(a|X_t)-t \\hat{w}_t(a|X_t)$ (where $T_t(a|X_t)$ is the number of times arm $a$ is sampled under $X_t$ up to time step $t$)?\n\n**A**. \nThank you for your suggestion. We conjecture that it works. However, the derivation of the upper bound requires more high-level techniques. We explain the background of the AIPW estimator as follows.\n\n----------------\n\nFor simplicity, assume that there is no contextual information. Recall that the AIPW estimator: $\\hat{\\mu}^{AIPW, a}_T$ is given as\n\n$$\\frac{1}{T}\\sum_t\\Big(\\frac{1[A_t = a](Y_t - \\hat{\\mu}^a_{t-1})}{w_t(a)} +  \\hat{\\mu}^a_{t-1}\\Big).$$\n\nHere, our proof is based on the martingale property, depending on $\\mathbb{E}[1[A_t = a] | \\mathcal{F}_{t-1}] = w_t(a)$.\n\nIf we apply the tracking-based algorithm, we need to reconsider the definition of the AIPW estimator. Depending on the definition, there are some technical issues. For example, consider using the same definition of the AIPW estimator in the main text. Then, $w_t$ is an estimator of the optimal allocation, and $A_t$ is an actual arm draw. Then, $\\mathbb{E}[1[A_t = a] | \\mathcal{F}_{t-1}] = w_t(a)$ does not hold. Therefore, we cannot employ the martingale property. \n\n----------------\n\nHowever, we consider that there is a possibility that we can show the same property between the AIPW estimator with random sampling in our manuscript and tracking-based sampling in your proposition. To derive an upper bound of the AIPW estimator using the  tracking-based sampling, we can consider the following decomposition:\n$$ \\hat{\\mu}^{AIPW, a}_T = \\hat{\\mu}^{AIPW, a}_T - \\tilde{\\mu}^{AIPW, a}_T +\\tilde{\\mu}^{AIPW, a}_T,$$ \nwhere we define $\\tilde{\\mu}^{AIPW, a}_T$ as \n\n$$\\frac{1}{T}\\sum_t\\Big(\\frac{1[B_t = a](Y_t - \\hat{\\mu}^a_{t-1})}{w_t(a)} +  \\hat{\\mu}^a_{t-1}\\Big),$$\n\nand define $B_t \\in [K]$ as a hypothetical arm assignment indicator when an arm is drawn following the probability $w_t$. Then, we aim to show \n\n$$ \\hat{\\mu}^{AIPW, a}_T - \\tilde{\\mu}^{AIPW, a}_T = o_P(1/\\sqrt{T})$$\n\nand apply the martingale central limit theorem for $\\tilde{\\mu}^{AIPW, a}_T$, where $\\mathbb{E}[1[B_t = a] | \\mathcal{F}_{t-1}] = w_t(a)$. \n\n----------------\n\nThe above conjecture is based on the existing work, such as [1] and [2]. \n\n[1] Hahn, J., Hirano, K., and Karlan, D. Adaptive experimental design using the propensity score, 2011.\n[2] Kato, M., Adaptive Doubly Robust Estimator from Non-stationary Logging Policy under a Convergence of Average Probability, 2021.\n\nHowever, to conduct the proof procedure we mentioned above, there are several restrictions. For example, [1] only considers a two-stage adaptive experiment, where we draw each arm with the equal ratio in the first stage and draw each arm to track the empirical optimal allocation ratio. Here, we cannot update $w_t$ in the second stage; that is, we can update the sampling rule $A_t$ only once between the first and second experiments. [2] makes complicated assumptions that are not easily verified. Showing the upper bound under the tracking-based algorithm without restricting the sampling rules or making additional assumptions is an open issue.\n\n----------------\n\n> According to [4], sampling according to a distribution can have slow convergence speed. \n\nWe agree with your points. On the other hand, we raise the following three points:\n- Although the sample average of $A_t$ will converge with a faster speed, we may not construct an unbiased estimator for $\\mu^a(P)$. Therefore, there might be a trade-off between the convergence of $A_t$ and the bias of an estimator of $\\mu^a(P)$.\n- We can show that our proposed AS-AIPW strategy and that with the sampling rule, we mentioned in the previous post (that is, we assign first $\\lceil Tw^*(1)\\rceil$ observations to arm $1$,..., and $\\lceil Tw^*(K)\\rceil$ observations to arm $K$). have the same asymptotic distribution. From this result, we conjecture that the AS-AIPW estimator with the tracking-based algorithm also has the same distribution if it can be shown. \n- Existing studies (e.g., [1] and [3]) imply that we can conduct theoretical analysis for the AS-AIPW estimator with random sampling more easily than with the tracking sampling, owing to the martingale property.\n\n[3] van der Laan, M. J. The construction and analysis of adaptive group sequential designs, 2008.\n\n----------------\n\nIn summary, we agree with your point that tracking-based strategies will outperform random-sampling-based strategies. However, under such a strategy, we cannot employ the martingale property (= unbiasedness), which makes the theoretical analysis difficult. Revealing the theoretical properties of such an estimator is an open issue."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9273/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700511966667,
                "cdate": 1700511966667,
                "tmdate": 1700519714137,
                "mdate": 1700519714137,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DJvFfmPvAT",
                "forum": "qgyLAr2cOs",
                "replyto": "sHBQwMcgSV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9273/Reviewer_qfgN"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9273/Reviewer_qfgN"
                ],
                "content": {
                    "comment": {
                        "value": "Great thanks for your detailed comment! Please consider organizing your above response and adding it to the appendix. It would be beneficial to the community. Thanks a lot!"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9273/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700529335568,
                "cdate": 1700529335568,
                "tmdate": 1700529335568,
                "mdate": 1700529335568,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "l15y55O2Nx",
            "forum": "qgyLAr2cOs",
            "replyto": "qgyLAr2cOs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9273/Reviewer_dvWZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9273/Reviewer_dvWZ"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers the problem of fixed budget best arm identification, with the goal of minimising the expected simple regret. Asymptotic lower bounds of the worst-case expected simple regret are provided, where the bound depends on the variances of potential outcomes. The bound gives possible analytical solutions for the target allocation ratio, based on which, the authors proposed Adaptive-Sampling Augmented Inverse Probability Weighting (AS-AIPW) strategy. AS-AIPW relies on the adaptive estimation of variances. AS-AIPW is proved to be asymptotically minimax optimal. The proposed algorithm is evaluated in simulation studies."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper presents the first asymptotic lower bounds for the worst-case expected simple regret based on the variances of potential outcomes, contributing to the theoretical foundation of the field.\n- The introduction of the Adaptive-Sampling Augmented Inverse Probability Weighting (AS-AIPW) strategy, using the target allocation ratio from the lower bounds\n- The theoretical proof of AS-AIPW being asymptotically minimax optimal provides strong theoretical support for the proposed algorithm's performance.\n- The paper includes simulation studies comparing the proposed algorithm to baselines, enhancing the practical understanding of its performance."
                },
                "weaknesses": {
                    "value": "- only asymptotic theoretical results are provided. For fixed budget settings, non-asymptotic bounds can provide a better understanding of algorithm performance under a fixed budget. \n- The proposed algorithm AS-AIPW highly depends on the variance estimation. It is unclear how poor estimations at the early stage and for more general distributions influence non-asymptotic performance. A discussion can be provided. \n- The experimental results verify the above concern, the proposed algorithm tends to outperform baselines when variances significantly vary across arms. It is worth showing how variances and different variance estimators influence the performance of the proposed algorithm."
                },
                "questions": {
                    "value": "- can you define w(a|x) in Theorem 3.4? \n- A related work: On Best-Arm Identification with a Fixed Budget in Non-Parametric Multi-Armed Bandits, Barrier et al 2023. Can you discuss this? \n- in Figure 1, can you also draw the standard deviation of the independent trials?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9273/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698335231559,
            "cdate": 1698335231559,
            "tmdate": 1699637168044,
            "mdate": 1699637168044,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ULjcou9xV6",
                "forum": "qgyLAr2cOs",
                "replyto": "l15y55O2Nx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9273/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9273/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Re: Official Review of Submission9273 by Reviewer dvWZ"
                    },
                    "comment": {
                        "value": "Thank you for your insightful comments. We will update our manuscript based on your feedback during this rebuttal phase.\n\nBefore updating the manuscript, we reply to your comments below.\n\n-------------\n**Q1**.  \n> non-asymptotic bounds can provide a better understanding of algorithm performance under a fixed budget.\n\n**A1**.  \nWe showed the non-asymptotic upper bound in Appendix H. For the lower bound, we consider it is not easy to derive non-asymptotic results for the following reasons.\n1. Although the estimation error of the variances can be ignored in the worst-case asymptotic analysis, it affects the lower bound in the non-asymptotic analysis. However, the analysis of variance estimation will be too complicated to analyze.\n2. Our technique is based on the information-theoretic lower bound provided by Kaufmann et al. (2016) and semiparametric efficiency bounds. Both techniques are used for asymptotic analysis. Therefore, we need to develop completely different approaches for non-asymptotic analysis.\n3. We deal with general distribution by approximating the KL divergences. If we focus on the non-asymptotic analysis, we need to restrict the class of distributions to specific distributions, such as the Gaussian distribution, even if possible.\n\nOne of the promising approaches for lower bounds is to employ lower bounds provided by Carpentier and Locatteli (2016). However, this lower bound is based on the boundedness of $Y^a_t$. Without the boundedness, non-asymptotic analysis would be more difficult. Additionally, the definitions of optimality might be changed to deal with the uncertainty of variance estimation. Thus, although the non-asymptotic upper bound has been derived, deriving non-asymptotic lower bounds requires different techniques and is not straightforward, even if possible. We will explain this open issue in the next update.\n\nCarpentier, A. and Locatelli, A. Tight (lower) bounds for the fixed budget best arm identification bandit problem, 2016.\n\n-------------\n\n**Q2**.  \n> It is unclear how poor estimations at the early stage and for more general distributions influence non-asymptotic performance of the AS-AIPW. \n\n**A2**.  \nAs we answered in A1 and you pointed out, the non-asymptotic performance will be affected by variance estimation. We showed the non-asymptotic upper bound in Appendix H by assuming the convergence rate of the variance estimation. Unless we assume that a specific convergence rate is given for the variance estimation or variances are known, it is difficult to derive asymptotic results. We will explain this limitation more clearly in the next update. \n\n-----------\n\n**Q3**.  \n> The experimental results verify the above concern...\n\n**A3**. \nWe appreciate your suggestion. We will add additional experimental results in the next update using different distributions with various variances. \n\n-----------\n\n**Q4**.  \n> define w(a|x) in Theorem 3.4\n\n**A4**.\nIt is defined as a element of $\\mathcal{W}$, which is defined in the above of Theorem 3.4.\n\n-----------\n\n**Q4**.  \n> Can you discuss Barrier et al 2023?\n\n**A4**. \nFirst of all, while we consider the expected simple regret minimization, that work considers minimization of the probability of misidentification. These two settings are related but require different analyses for lower bounds. See Komiyama et al. (2023).\n\nAdditionally, there are the following critical differences between our study and theirs in non-parametric analysis using the KL divergence of Kaufmann et al. (2016).\n - In the lower bound, our study approximates the KL divergence by the Fisher information (semiparametric influence function) around the gaps between the best and suboptimal arms are zero $\\Delta^a(P) \\to 0$. We do not assume the boundedness of $Y^a_t$. In the upper bound, we utilize the central limit theorem for deriving tight results. \n- Barrier et al. (2023) assumes the boundedness of $Y^a_t$. Then, bounding the KL divergences using the boundedness without using the small gap (fixed $\\Delta^a(P)$).\n\nBecause we employed the worst-case analysis, which implies $\\Delta^a(P) \\approx 1/\\sqrt{T}$ (see Section 3), we could naturally develop non-parametric results. However, we cannot employ such an approximation in Barrier et al. (2023) because it considers lower and upper bounds under a fixed $P$ or fixed $\\Delta^a(P)$. Furthermore, unlike the expected simple regret minimization, the optimality in minimization of the probability of misidentification is still an open issue. Also see Komiyama et al. (2023) and Qin (2022). We remark on these differences in the next update.\n\nKomiyama, J., Ariu, K., Kato, M., and Qin, C. Rate-optimal bayesian simple regret in best arm identification, 2023.  \nQin, C. Open problem: Optimal best arm identification with fixed-budget, 2022.  \n\n-----------\n\n**Q5**.  \n> in Figure 1, can you also draw the standard deviation?\n\n**A5**. \nThank you for your suggestion. We will add the standard deviations or the boxplot in the next update."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9273/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700351749614,
                "cdate": 1700351749614,
                "tmdate": 1700351775356,
                "mdate": 1700351775356,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "guUjr1Yeyr",
            "forum": "qgyLAr2cOs",
            "replyto": "qgyLAr2cOs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9273/Reviewer_65vH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9273/Reviewer_65vH"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers the fixed-budget best-arm identification problem in (contextual) multi-armed bandits and takes simple regret minimization as the objective. It first derives an asymptotic minimax lower bound that depends on the variance of the reward distribution. Then, it proposes an algorithm called **AS-AIPW** that nearly achieves this lower bound asymptotically. Finally, sanity check experiments are also provided to validate the effectiveness of the proposed algorithm."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The variance dependent asymptotic lower bound is considered to be highly novel.\n- Under specific scenarios, the optimal allocation strategy has closed-form expression.\n- The proposed algorithm nearly achieves the lower bound."
                },
                "weaknesses": {
                    "value": "One weakness is that the current Theorem 3.8 in this paper does not generalize to the case with $K\\geq 3$ and it is not clear whether the difficulty is technical or fundamental.\n\nAnother weakness is that most provided experiment results do not show advantages of **AS-AIPW** over variance-unaware algorithms. Although the paper conjectures that the superiority of **AS-AIPW** can only appear when $K$ is small, from my perspective, the number of arms should not be the essential factor. In particular, the worst-case regret of variance-unaware algorithms scales with the magnitude of the reward while that of **AS-AIPW** scales with the standard deviation of the reward. Therefore, if my understanding is correct, the advantage of **AS-AIPW** should appear if we run it on a hard instance with large reward magnitude but small variance. Is that possible to design and run experiments on such an instance?\n\n### Suggestions on Writing\n- 3rd line of page 7, \"$w^*(a\\vert X_t)$\" -> \"$(\\sigma^a_t(X_t))^2$\".\n- There is probably no need to explain how to sample an arm $a$ with probability $\\widehat{w}_t(a\\vert X_t)$ at the beginning of Section 4.2.\n- The main context can contain a sketch of techniques used for proving the lower bound and a brief discussion of its novelty."
                },
                "questions": {
                    "value": "- In the sixth requirement of Definition 3.2, does \"$\\mu^a(P)(x)\\rightarrow \\mu^a(P^\\sharp)$\" means that there exists a sequence of bandit models $\\lbrace P_n\\rbrace$ such that $\\lim_{n\\rightarrow\\infty} \\mu^a(P_n)(x)= \\mu^a(P^\\sharp)$?\n- Based on the given results, it seems quite tempting to conjecture that Theorem 3.8 can be generalized to the case with $K\\geq 3$. Is this fundamentally not doable or does it just require more sophisticated techniques?\n- What are the disadvantages of using $\\arg\\max_{a\\in[K]}\\widehat{\\mu}^a_T$ as the arm recommendation rule? Do these disadvantages exist when there is no context information?\n- If my understanding is correct, when there is no context information, we have $\\widehat{\\mu}^a_t=\\frac{1}{t}\\sum_{s=1}^{t}\\mathbf{1}\\lbrace A_s=a\\rbrace Y_s$. Then, it looks weird that $\\widehat{\\mu}^{\\mathrm{AIPW}, a}\\_T$ contains the term $$\\frac{1} {T}\\sum_{t=1}^{T}\\widehat{\\mu}^a_t=\\frac{1}{T}\\sum_{t=1}^{T}\\left(\\sum_{s=t}^{T}\\frac{1}{s}\\right)\\mathbf{1}\\lbrace A_t=a\\rbrace Y_t,$$ since it means that more weights are explicitly put on earlier samples. Why will this happen?\n- Suppose there are not many possible contexts and we can encounter each contexts for sufficiently many times, can we treat **AS-AIPW** as doing BAI for each context independently? That is, if we define $$\\widehat{a}^{\\mathrm{AIPW}}\\_T(x)=\\arg\\max_{a\\in[K]}\\frac{1}{T}\\sum_{t=1}^{T}\\mathbf{1}\\lbrace X_t=x\\rbrace \\varphi^a_t(Y_t, A_t, X_t),$$ can we bound the simple regret condition on $X=x$ by $$\\max_{a, b\\in[K]: a\\neq b}\\sqrt{\\log(K)\\left(\\frac{(\\sigma^a(x))^2}{w^*(a\\vert x)}+\\frac{(\\sigma^b(x))^2}{w^*(b\\vert x)}\\right)}+o(1)?$$"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9273/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9273/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9273/Reviewer_65vH"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9273/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698484124022,
            "cdate": 1698484124022,
            "tmdate": 1700714232525,
            "mdate": 1700714232525,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9NCynaPqTB",
                "forum": "qgyLAr2cOs",
                "replyto": "guUjr1Yeyr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9273/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9273/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Re: Official Review of Submission9273 by Reviewer 65vH"
                    },
                    "comment": {
                        "value": "Thank you for your insightful comments. We updated our manuscript based on your feedback. We also make additional sections in the Appendix to answer the technical questions the reviewer raised (Q2--Q5 below) during this phase. \n\nOur brief replies to your comments are listed as follows.\n\n---------------------------\n**Q1**.    \n> Does \"$\\mu^a(P)(x)\\to \\mu^a(P^\\sharp)$\" means that there exists a sequence of bandit models $\\{P_n\\}$ such that $\\lim_{n\\to\\infty}\\mu^a(P_n)(x) = \\mu^a(P^\\sharp)$?\n\n**A1**.  \nWe appreciate your comment. Yes, we assume the existence of such a sequence of bandit models $\\{P_n\\}$. We will update our manuscript following your more rigorous definition. \n\n---------------------------\n\n**Q2**.  \n> It seems quite tempting to conjecture that Theorem 3.8 can be generalized to the case with $K\\geq 3$. \n\n**A2**.  \nWe agree with the reviewer's comment and also consider that extending Theorem 3.8 for $K\\geq 3$ is an important open issue. To address this issue, we believe that current assumptions for distributions and restrictions for strategies are insufficient. We need to add more assumptions and develop additional tools for this problem. \n\nFor example, the framework of the limit of experiments (van der Vaart, 1998) is one of the promising directions. This framework is expected to allow us to derive tight lower and upper bounds by using the asymptotic normality. However, to apply the results, we need to restrict strategy class and underlying distribution appropriately.  \n\nRecently, Kato (2023) derived results similar to Theorem 3.8 for $K \\geq 3$ in minimization of the probability of misidentification ($\\mathbb{P}_P(\\hat{a}_T \\neq a^*(P))$). However, the results are limited to cases with known variances, minimization of the probability of misidentification, and Gaussian distributions. It is an open issue how we derive similar results for expected simple regret minimization.\n\nKato (2023), Locally Optimal Best Arm Identification with a Fixed Budget. \n\nWe summarize this problem as an open issue. \n\n---------------------------\n\n**Q3**.  \n> What are the disadvantages of using $\\arg\\max_{a\\in[K]}\\hat{\\mu}^a_T$? \n\n**A3**..       \nWe conjecture that both $\\hat{\\mu}^a_T$ and $\\hat{\\mu}^{AIPW, a}_T$ have almost the same theoretical properties when there is no contextual information. However, proving the regret upper bound for $\\hat{\\mu}$ requires a more complicated proof procedure compared to $\\hat{\\mu}$ or requires some additional assumptions. This problem is related to theories of empirical process and martingales, as discussed in Hirano et al. (2003) and Hahn et al. (2011). \n\nWe believe that showing it is not straightforward and an open issue, even though it is probably possible . We also summarize this problem as an open issue in another reply or the Appendix. \n\n---------------------------\n\n**Q4**.   \n> It looks weired that $\\hat{\\mu}^{AIPW}$ contains the term $\\frac{1}{T}\\sum^T_{t=1}\\hat{\\mu}^a_t$.\n\n**A4**.   \nThis term is introduced for variance reduction with keeping the martingale properties for $\\frac{1}{T}\\sum^T_{t=1}\\hat{\\mu}^a_t$. Here, an effect of $\\frac{1}{T}\\sum^T_{t=1}\\hat{\\mu}^a_t$ vanishes very quickly because of the existence of the product\n$|\\hat{w}(a) - w^*(a)||\\hat{\\mu}^a(P) - \\hat{\\mu}^a_t|$ in theoretical analysis, which accelerates the vanish of the estimation error of $w^*$ and $\\mu^a(P)$. That is, the introduction of $\\frac{1}{T}\\sum^T_{t=1}\\hat{\\mu}^a_t$ reduces the variance of the main estimator without increasing bias (asymptotically). This technique is used in different literatures, such as van der Laan (2008) and Chernohukov et al. (2018), which are recently called double machine learning.\n\nThis property is related to the Q3 the reviewer raised. We add more explanations on this problem in the Appendix.\n\n---------------------------\n\n**Q5**.   \n> Suppose there are not many possible contexts and we can encounter each contexts for sufficiently many times, can we treat AS-AIPW as doing BAI for each context independently?\n\n**A5**.  \nYes. We can conduct context-specific treatment recommendation is possible when there are not many discrete contextual information. \n\nWe are now extending the result for policy learning with BAI; that is, given a set $\\Pi$ of policies $\\pi:[K]\\times\\mathcal{X} \\to (0, 1)$ such that $\\sum_{a\\in[K]}\\pi(a|x) = 1$ (and potentially continuous contextual information), we train a policy $\\pi\\in\\Pi$ to minimize the regret. Consider we restrict a policy class $\\Pi$ to the one such that we discretize the contextual information and recommend an arm within each discretized contextual information. Then, such a strategy aligns with the strategy that the reviewer suggested. \n\nThe remaining open issue is how we bound the regret for general $\\Pi$. Because samples are non-i.i.d., we cannot directly apply the standard complexity measure such as the Rademacher complexity. This open problem has garnered attention in this literature, and we summarize it in the next update."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9273/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700169111277,
                "cdate": 1700169111277,
                "tmdate": 1700169111277,
                "mdate": 1700169111277,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kmejmPCawb",
                "forum": "qgyLAr2cOs",
                "replyto": "9NCynaPqTB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9273/Reviewer_65vH"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9273/Reviewer_65vH"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thank you very much for your reply! Could you also update the pdf and color the added details that you plan to elaborate (such as more discussions about the estimator and context-specific BAI)?\n\nMeanwhile, could you also discuss what your opinion is about the second weakness mentioned in my initial review?"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9273/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700264029258,
                "cdate": 1700264029258,
                "tmdate": 1700264029258,
                "mdate": 1700264029258,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HP7BGVugzl",
                "forum": "qgyLAr2cOs",
                "replyto": "FGZRMSpvKW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9273/Reviewer_65vH"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9273/Reviewer_65vH"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thanks for the response. My concerns on the theoretical side are mostly addressed. However, I do believe it's important to have some empirical evidence showing the advantage of being variance-aware under certain scenarios. Nevertheless, I'm still inclilned to acceptance given the theoretical contribution. Therefore, I decide to lower my score to 6."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9273/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700714170255,
                "cdate": 1700714170255,
                "tmdate": 1700714170255,
                "mdate": 1700714170255,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "YbBzEpqAQ8",
            "forum": "qgyLAr2cOs",
            "replyto": "qgyLAr2cOs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9273/Reviewer_ZfPN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9273/Reviewer_ZfPN"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a work in the field of fixed-budget best arm identification for multi-armed bandits when contextual information is available, with the goal of minimizing the expected simple regret.\nThe authors derive asymptotic lower bounds on the expected simple regret depending on the variances of the potential outcomes rather than considering outcomes with bounded supports. The lower bound is provided in both the cases in which contextual information is available and when it is not.\nMoreover, they provide an algorithm, namely AS-AIPW, showing that it matches (asymptotically) the lower bound.\nFinally, the authors present a numerical validation of the presented results just on synthetic data."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The proposed work faces the problem of best arm identification in MABs. The authors discuss the theoretical differences when contextual information are available or not.\nMoreover, the work presents two asymptotic lower bounds (one with and the other without contextual information) and an algorithm, which asympotically matches the lower bounds. \n\nThe analysis seems to be done properly, but I have not checked the correctness of all the proofs."
                },
                "weaknesses": {
                    "value": "A weakness I found in the paper is linked to the feeling that the authors did not pay great attention to the details. \n\nIndeed:\n- The abstract is not so clear since it does not introduce the fact that the setting at hand will consider contextual information and that it will compare it with the case in which contextual information is not available;\n- The introductory section is not clear;\n- I would appreciate (at least a paragraph) on some motivating examples (also in the appendix) with some comments.\n- Some crucial quantities are not commented on, such as the meaning of the AIPW estimator.\n\nIn the experimental section (even in Appendix I) I found too simple experimental settings. Even if I have appreciated the comparison with fixed-budget BAI when no contextual information is available, I do not believe that it is fair to compare the same baselines (that are not thought for contextual settings) with the proposed algorithm. I suggest employing at least another algorithm thought for the same setting proposed by the authors if present (and if no competitors are available, please write it)."
                },
                "questions": {
                    "value": "Besides the concerns related to the \"weaknesses\" section, here are other questions:\n1. is it possible to adapt the lower and upper bounds not to be asymptotic?\n2. will you release the code of the experiments to assess if the numerical validation is reproducible?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9273/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9273/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9273/Reviewer_ZfPN"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9273/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698919865703,
            "cdate": 1698919865703,
            "tmdate": 1699637167837,
            "mdate": 1699637167837,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GFIwf910iq",
                "forum": "qgyLAr2cOs",
                "replyto": "YbBzEpqAQ8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9273/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9273/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Re: Official Review of Submission9273 by Reviewer ZfPN"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer's detailed feedback. A revised manuscript will be submitted shortly. Below is a preliminary response to the comments:\n\nBefore answering each question the reviewer raised, we remark that our research addresses both scenarios: with and without contextual information. We have:\n- Developed the best arm identification (BAI) strategy that leverages variances.\n- Proposed a BAI strategy that can utilize contextual information in fixed-budget BAI.\nThe novelty lies in using variances (first point) and utilizing contextual information to BAI (second point). Even without contextual information, our study has a novelty in proposal BAI strategies using the variances. Our results cover both scenarios with and without contextual information, as non-contextual cases are inherently included in the contextual ones. Page limitation precluded separate discussions for each setting. However, on page 2, we noted, \"Note that this setting is a generalization of fixed-budget BAI without contextual information, and our result holds novelty even in the absence of contextual information.\"\n\nWe answer each question below. \n\n-------------------------------\n\n**Q1**. \n> The abstract is not so clear since it does not introduce the fact that the setting at hand will consider contextual information and that it will compare it with the case in which contextual information is not available;\n\n**A1**.  \nWe do **not** focus on comparing our method with contextual information with existing methods with contextual information. Our study proposes strategies for **both** cases with and without contextual information. In Section 3.4 and Section 7, we compare our method with existing methods in a case where we cannot use contextual information in both methods. \n\n-------------------------------\n\n**Q2**. \n> Even if I have appreciated the comparison with fixed-budget BAI when no contextual information is available, I do not believe it is fair to compare the same baselines (not thought for contextual settings) with the proposed algorithm. \n\n> I do not believe that it is fair to compare the same baselines (that are not thought for contextual settings) with the proposed algorithm.\n\n**A2**. \nIn our main text experiments, **we compare our method with existing methods, both without using contextual information,** as stated in the third line of Section 7: \"We investigate two setups with K = 2, 3 without contextual information for these strategies.\" This ensures a fair comparison. \n\nIn the Appendix, we compare our method that uses contextual information with existing methods that do not use contextual information.\n\n-------------------------------\n\n**Q3**. \n> I suggest employing at least another algorithm thought for the same setting proposed by the authors if present (and if no competitors are available, please write it).\n\n**A3**. \nTo the best of our knowledge, this setting has no appropriate competitors. In BAI, it is still unclear how we formulate the problem if contextual information is available, and it is an open issue. We will make it clearer in the next update.\n\n-------------------------------\n\n**Q4**. \n> Is it possible to adapt the lower and upper bounds not to be asymptotic?\n\n**A4**. \nAdapting the lower and upper bounds to non-asymptotic conditions seems unfeasible. The finite-sample analysis will be more complicated by the estimation error of the variances, which can be ignored in an asymptotic analysis. Our lower bound is based on the semiparametric efficiency bound, an extension of the Cramer-Rao lower bound, typically used for asymptotic optimality. Addressing finite-sample optimality would require novel and other methodologies.\n\n-------------------------------\n\n**Q5**.  \n> will you release the code of the experiments to assess if the numerical validation is reproducible?\n\n**A5**. \nWe plan to release our experiment code, ensuring it complies with the review process's anonymity requirements. It will be available during the rebuttal phase.\n\n-------------------------------\n\n**Q6**.  \n> Some crucial quantities are not commented on, such as the meaning of the AIPW estimator.\n\n**A6**. \nWe explained the details about the AIPW estimator in Section 4.3.  The name comes from the augmentation of the inverse probability of weighting estimator. We add some brief history of this estimator in the next update. \n\n-------------------------------\n\nLastly, our study contributes to two open problems in BAI:\n- Integrating variances into BAI.\n- Utilizing contextual information in BAI.\nWe approach these with asymptotic lower bounds via semiparametric analysis and a BAI strategy focusing on the highest marginalized expected reward across contextual distributions. The first point alone stands as an independent contribution. Although we show an approach for the second issue, how we use contextual information is still an open issue. Also, see our Russac et al. (2021) and our rebuttal to the Reviewer 65vH."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9273/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700072134489,
                "cdate": 1700072134489,
                "tmdate": 1700164789583,
                "mdate": 1700164789583,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0uqN1yXMQ1",
                "forum": "qgyLAr2cOs",
                "replyto": "GFIwf910iq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9273/Reviewer_ZfPN"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9273/Reviewer_ZfPN"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response. \n\nI think that the problem faced is interesting and that the paper, technically, presents a good contribution. I agree that a lower bound depending on the time budget is hard to be derived in the setting you are considering.\nHowever, my points are related to the fact that all the strengths of your work do not emerge clearly. For instance, the fact that you face both settings with and without contextual information is a strength of the work, thus it should also be highlighted in the abstract. \nMoreover, the motivating examples are just cited and not discussed properly. I would like to see at least one truly motivating example fully explained.\n\nI remark that I appreciate the work itself, but the presentation should be improved."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9273/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700584640766,
                "cdate": 1700584640766,
                "tmdate": 1700584640766,
                "mdate": 1700584640766,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]