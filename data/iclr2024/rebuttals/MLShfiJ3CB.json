[
    {
        "title": "Towards Reliable Backdoor Attacks on Vision Transformers"
    },
    {
        "review": {
            "id": "gABGY2hxhJ",
            "forum": "MLShfiJ3CB",
            "replyto": "MLShfiJ3CB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4969/Reviewer_Vd1v"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4969/Reviewer_Vd1v"
            ],
            "content": {
                "summary": {
                    "value": "This paper examines the prevalent backdoor attacks and defenses, revealing an over-optimistic perception arising from the improper adaptation of defenses from CNNs to ViTs. With appropriate inheritance from CNNs, existing backdoor attacks can be effectively mitigated. Additionally, the paper introduces a more robust attack method: a minor perturbation on the trigger significantly enhances the resilience of existing attacks against diverse defenses."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "It reveals an over-optimistic perception arising from the improper adaptation of defenses from CNNs to ViTs. \n\nThis paper introduces a more robust attack method against ViTs."
                },
                "weaknesses": {
                    "value": "When testing existing backdoor attacks against ViT, the authors only use CNN-based backdoor attacks without ViT-specific backdoor attack methods. Thus, the possibility exists that existing ViT-specific backdoor attacks can also evade well-adapted backdoor defenses.\n\nWhen testing existing backdoor defenses, the authors only consider purified-based backdoor defenses. How about the detection-based backdoor defenses? Are they also over-estimated?\n\nLack of enough baselines to prove the effectiveness of the proposed attack method. After proposing a new backdoor attack, the authors should compare it with SOTA backdoor attacks, especially advanced ViT-specific backdoor attacks, to show its superiority.\n\nThere is insufficient evaluation to explore whether the proposed attack can evade the SOTA backdoor defenses designed for ViT.\n\nThere is a lack of enough complex datasets, such as Imagenet, to evaluate the effectiveness of the proposed attacks."
                },
                "questions": {
                    "value": "See the concerns in weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4969/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4969/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4969/Reviewer_Vd1v"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4969/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697790257367,
            "cdate": 1697790257367,
            "tmdate": 1699636484139,
            "mdate": 1699636484139,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TqMXgzsDwz",
                "forum": "MLShfiJ3CB",
                "replyto": "gABGY2hxhJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4969/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4969/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Vd1v (Part1)"
                    },
                    "comment": {
                        "value": "Dear reviewer Vd1v:\n\nThank you for your valuable feedback. We are very sorry for the ambiguity in section 5.2. We have re-organized this section to make it easier to read. \n\n**Q1:**  Thus, the possibility exists that existing ViT-specific backdoor attacks can also evade well-adapted backdoor defenses.\n\n**A1:** TrojViT [1] and DBIA [2] are the existing two kinds of ViT-specific attacks. **In Table 5 and Table 10 in the paper, we have shown that both of them fail to evade well-adapted backdoor defenses**: they only achieve a very low ASR (<1%) across all model-agnostic defense approaches while the benign accuracy maintains a relatively high level (>75%). Here we further illuminate that our proposed adapted approaches remain essential for better defending TrojViT and DBIA. The experiments are performed on ImageNet. The ASR and ACC before and after adaptations are shown as follows:\n\n**ASR** (%)\n\nTrojViT:\n\n|                    | Before | FT   | FP   | NAD  | ANP  | AWM  |\n| ------------------ | ------ | ---- | ---- | ---- | ---- | ---- |\n| Before adaptations | 91.58  | 0.16 | 0.19 | 0.19 | 0.29 | 0.00 |\n| After adaptations  | 91.58  | 0.14 | 0.14 | 0.16 | 0.46 | 0.18 |\n\nDBIA:\n\n|                    | Before | FT   | FP   | NAD  | ANP  | AWM  |\n| ------------------ | ------ | ---- | ---- | ---- | ---- | ---- |\n| Before adaptations | 99.58  | 0.07 | 0.10 | 0.24 | 0.13 | 0.06 |\n| After adaptations  | 99.58  | 0.09 | 0.07 | 0.10 | 0.10 | 0.05 |\n\n**ACC** (%)\n\nTrojViT:\n\n|                    | Before | FT        | FP        | NAD       | ANP       | AWM       |\n| ------------------ | ------ | --------- | --------- | --------- | --------- | --------- |\n| Before adaptations | 80.59  | 68.92     | 69.00     | 69.88     | 69.72     | 0.10      |\n| After adaptations  | 80.59  | **76.82** | **76.93** | **77.55** | **76.31** | **77.18** |\n\nDBIA:\n\n|                    | Before | FT        | FP        | NAD       | ANP       | AWM       |\n| ------------------ | ------ | --------- | --------- | --------- | --------- | --------- |\n| Before adaptations | 79.52  | 69.36     | 64.05     | 67.51     | 71.04     | 57.00     |\n| After adaptations  | 79.52  | **78.30** | **75.20** | **77.18** | **76.49** | **78.94** |\n\nThe results demonstrate that although vanilla settings can successfully decrease the ASR, they also impair the benign function of the backdoored models a lot. In contrast, our proposed adaptations better preserve the benign ACC. For example,  AWM achieves the ACC of 77.18% after adaptations against TrojViT while it totally collapses without any adaptations. \n\n**Q2:**  The authors only consider purified-based backdoor defenses. How about the detection-based backdoor defenses? Are they also over-estimated?\n\n**A2:** Actually,  the detection-based defenses are underestimated for current attacks, but our proposed CAT can better bypass those defenses. Take NC [3] as an example, which is one of the most popular detection-based backdoor defenses. It is composed of two stages: It first searches the possible trigger through outlier detection. Then, the backdoor model is mitigated through unlearning with the reversed trigger. Performing experiments on the CIFAR-10 dataset for ViT-B, we explore the performance of NC by dividing the two stages separately:\n\n**Stage 1: Detection**\n\nNC reconstructs potential triggers for each class and uses an anomaly index to determine if one of them is a valid trigger. The larger the anomaly index, the more likely it is to be a real backdoor trigger. Here, we calculate the anomaly indexes of the attack with or without CAT for comparison:\n\n|         | Badnets | Blend | CLB  | SIG  |\n| ------- | ------- | ----- | ---- | ---- |\n| Vanilla | 7.45    | 3.14  | 7.13 | 2.26 |\n| +CAT    | **5.04**    | **1.60**  | **2.48** | **0.90** |\n\nThe results show that CAT can always obtain lower anomaly indexes: for example, the vanilla badnets attack obtains the anomaly indexes of 7.45 which is quite larger than those after combing CAT (5.04). It means CAT can help existing attacks better bypass the detection of NC.\n\n**Stage 2: Unlearning**\n\nNext, the defenders use the reconstructed triggers to mitigate the backdoor behavior once the reconstructed triggers are identified. Specifically, they fine-tune the model to predict ground-truth labels in the presence of the triggers, i.e., unlearning the backdoor behavior. Here, we explore whether CAT makes existing attacks more resistant to unlearning. According to previous research [1] which observes that the unlearning process of NC with CNNs\u2019 default settings will decrease the benign acc a lot (~50%), we make the following adaptations based on the observations in our paper:   \n\n- Use AdamW optimizer to unlearn the backdoored models.\n- Unlearn the backdoored model only for 20 epochs."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4969/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700464451451,
                "cdate": 1700464451451,
                "tmdate": 1700464899603,
                "mdate": 1700464899603,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JhOwbm201l",
                "forum": "MLShfiJ3CB",
                "replyto": "gABGY2hxhJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4969/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4969/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Vd1v (Part2)"
                    },
                    "comment": {
                        "value": "We summarize the results as follows:\n\nASR (%)\n\n|         | Badnets   | Blend     | CLB      | SIG       |\n| ------- | --------- | --------- | -------- | --------- |\n| Vanilla | 1.08      | 0.66      | 0.36     | 5.64      |\n| CAT     | **99.99** | **53.49** | **6.25** | **43.79** |\n\nACC (%)\n\n|         | Badnets | Blend | CLB   | SIG   |\n| ------- | ------- | ----- | ----- | ----- |\n| Vanilla | 96.85   | 96.61 | 96.78 | 96.78 |\n| CAT     | 97.22   | 97.08 | 96.75 | 97.06 |\n\nWe first observe that NC successfully mitigates the effect of all existing attacks and maintains high ACC.  Secondly, CAT can help current attacks bypass the unlearning process better: for example, the ASR of Badnets is improved from 1.08% to 99.99%.\n\n**Q3:** After proposing a new backdoor attack, the authors should compare it with SOTA backdoor attacks, especially advanced ViT-specific backdoor attacks, to show its superiority.\n\n**A3:**  **In fact, we have compared CAT with two ViT-specific attacks: TrojViT [1] and DBIA [2] in Table 5 and 10 in the paper.**  We summarize the average ASR of all attack methods after performing five model-agnostic defenses in the following table.\n\n|                | DBIA | TrojViT | badnets+CAT | blend+CAT |\n| -------------- | ---- | ------- | ----------- | --------- |\n| Average ASR(%) | 0.08 | 0.21    | 44.12       | 32.84     |\n\nThe results demonstrate that current ViT-specific attacks can not be immune to the adapted defenses and  CAT can outperform them with a higher ASR.  \n\n**Q4:** There is insufficient evaluation to explore whether the proposed attack can evade the SOTA backdoor defenses designed for ViT.\n\n**A4:** **In Table 5 and Table 10 in the paper, we have shown that CAT can evade the AB (Attention block) [5] which is one of the ViT-specific backdoor defenses.** Here we further perform experiments on patch-processing [6] which is another ViT-specific defense.  Following their original paper, we select TPR (the proportion of benign samples that are successfully identified) and TNR (the proportion of backdoor samples that are successfully detected) as our metrics. The experiments are performed on ImageNet with ViT-B architecture. \n\n|           | TPR   | TNR   |\n| --------- | ----- | ----- |\n| Blend     | 80.12 | 13.03 |\n| Blend+CAT | 81.09 | **5.15**  |\n\nCompared to the model-agnostic defense in Table 5, patch-processing only obtains limited performance on both Blend and Blend+CAT. We speculate this is because ImageNet is a large and complex dataset. It makes the classification results more susceptible to change if certain patches of the image are masked, thereby increasing the difficulty of distinguishing between clean and backdoor images. In addition, combining with CAT helps Blend obtain lower TNR, representing the backdoor samples are harder to detect. We also perform experiments on CIFAR-10 to further investigate whether CAT can provide better robustness on small datasets. The experiments are also performed on ViT-B:\n\n|           | TPR   | TNR   |\n| --------- | ----- | ----- |\n| Blend     | 83.08 | 97.11 |\n| Blend+CAT | 84.11 | **48.69** |\n\nSimilar to the experiments on Imagenet, combining with CAT can obtain comparable TPR and lower TNR (<50%). This demonstrates that CAT can evade the SOTA backdoor defenses designed for ViT.\n\n**Q5:** There is a lack of enough complex datasets, such as ImageNet, to evaluate the effectiveness of the proposed attacks. \n\n**A5:** **We actually perform experiments on ImageNet in Section 5.2 in the paper.** The results show that our proposed attacks are still effective on large datasets. \n\nWe really hope our explanation can eliminate your doubts. We are happy for the further discussion with you if any concerns remain. \n\n[1] TrojViT: Trojan Insertion in Vision Transformers, Mengxin Zheng et al., In CVPR 2023.\n\n[2] Dbia: Data-free backdoor injection attack against transformer networks, Peizhuo Lv et al., In Arxiv 2021.\n\n[3] Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks, Bolun Wang et al., In S&P 2019. \n\n[4] BackdoorBench: A Comprehensive Benchmark of Backdoor Learning, Baoyuan Wu et al., In NeurIPS 2022.\n\n[5] Backdoor attacks on vision transformers. Akshayvarun Subramanya et al., In Arxiv 2022.\n\n[6] Defending Backdoor Attacks on Vision Transformer via Patch Processing, Khoa D. Doan et al., in AAAI 2023."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4969/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700464721341,
                "cdate": 1700464721341,
                "tmdate": 1700464843165,
                "mdate": 1700464843165,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "sZQ3EanazY",
            "forum": "MLShfiJ3CB",
            "replyto": "MLShfiJ3CB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4969/Reviewer_FbZc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4969/Reviewer_FbZc"
            ],
            "content": {
                "summary": {
                    "value": "This paper first conducts a comprehensive evaluation of existing backdoor attacks on ViT and reveals the reason they can bypass existing defense is due to the inappropriate use of optimizer, e.g., SGD. After refining the existing backdoor defense, the experiment results show that existing backdoor attacks on ViT will no longer achieve effective attack after defense. Therefore, the authors propose a more reliable attack by adding special adversarial perturbations into the trigger pattern. The results show their method can achieve a stable attack after some type of defense."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The authors revisit the existing backdoor defense methods on ViT and find that these defense methods don\u2019t work well because of the misuse of the optimizer, i.e. SGD.\n\nThe authors conduct comprehensive experiments and ablation studies."
                },
                "weaknesses": {
                    "value": "The hypothesis lacks enough evidence. Firstly, the authors claim \u201cViTs are typically trained by AdamW while its fine-tuning defense is trained by SGD (NOT AdamW, maybe inheriting from CNNs). This discrepancy in optimizers raises the possibility that the perceived vulnerability of ViTs (with defense) might be overstated, i.e., the success of attacks on ViTs with defense may be questionable.\u201d However, the authors don\u2019t cite papers that use SGD to mitigate backdoors in ViT. And when transferring the defense methods on CNN to ViT, the most straightforward scheme is to use the same optimizer as when training the model, i.e., SGD for CNN and AdamW for ViT. Secondly, the authors claim that the misuse of the optimizer in fine-tuning leads to suboptimal defense performance and conduct experiments in Table 2 to show the effect of optimizers. However, the attack methods used in Table 2 are all CNN-specific attack methods. Authors should conduct experiments on ViT-specific backdoor attacks [2,3,4] because they are investigating backdoor defense on ViTs.\n\n\nThe \u201cbackdoor defense\u201d in the paper only denotes the \u201cmitigation\u201d aspect. And the design of their reliable attack is based on \u201cthe difference in the intermediate-level representations between the inputs with and without triggers\u201d. It is not clear if this attack can bypass detection technologies that don\u2019t rely on the difference in activation, such as Neural Cleanse[1] which is based on reverse engineering and outlier detection."
                },
                "questions": {
                    "value": "Is the proposed attack only effective on ViT? Is it possible that it also works well on CNN, since the proposed method doesn\u2019t leverage ViT\u2019s unique features compared to CNN? \n\nSame with weakness 2, is it possible that the authors can provide results of the attacks against backdoor detection techniques such as Neural Cleanse [1]?\n\n[1] B. Wang et al., \"Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks,\" 2019 IEEE Symposium on Security and Privacy (SP), San Francisco, CA, USA, 2019, pp. 707-723, doi: 10.1109/SP.2019.00031.\n\n[2] Zheng, Mengxin, Qian Lou, and Lei Jiang. \"Trojvit: Trojan insertion in vision transformers.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n\n[3] Zheng, Runkai, et al. \"Data-free backdoor removal based on channel lipschitzness.\" European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2022.\n\n[4] Akshayvarun Subramanya, Aniruddha Saha, Soroush Abbasi Koohpayegani, Ajinkya Tejankar, and Hamed Pirsiavash. Backdoor attacks on vision transformers. arXiv preprint arXiv:2206.08477, 2022a."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4969/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698812757030,
            "cdate": 1698812757030,
            "tmdate": 1699636484026,
            "mdate": 1699636484026,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bsnQYwC3tZ",
                "forum": "MLShfiJ3CB",
                "replyto": "sZQ3EanazY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4969/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4969/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer FbZc (Part1)"
                    },
                    "comment": {
                        "value": "Dear reviewer FbZc:\n\nThanks very much for your constructive and detailed comments. Here are our responses to address your concerns:\n\n**Q1:**  The hypothesis lacks enough evidence. However, the authors don\u2019t cite papers that use SGD to mitigate backdoors in ViT. When transferring the defense methods on CNN to ViT, the most straightforward scheme is to use the same optimizer as when training the model, i.e., SGD for CNN and AdamW for ViT.\n\n**A1:** We apologize for the confusion in Section 3.2. In fact, we cited previous research [1], which used the SGD for defensive fine-tuning while Adam for pretraining. To avoid misunderstanding, we revised our paper and discussed previous research in section 3.2 on page 4. Note that the earliest work [2], which first introduced transformers to computer vision, used AdamW for pre-training and SGD for fine-tuning. Following studies [3, 4, 5] naturally inherit this strategy. Unfortunately, in backdoor defense, we found that this natural choice caused issues. We want to use this article to remind everyone to pay attention to making reasonable choices rather than blindly adopting default or natural options.\n\n**Q2:** The attack methods used in Table 2 are all CNN-specific attack methods. Authors should conduct experiments on ViT-specific backdoor attacks [6,7,8].\n\n**A2:** Thank you for your suggestion. First, we argue that these backdoor attacks in Table 2 are actually model-agnostic and general rather than CNN-specific. Second, we conduct experiments on ViT-specific attacks to make our conclusion more convincing. Here, we consider the effect of the optimizer on FT for TrojViT [6] and DBIA attacks [7]. We do not include previous research [8] since it proposed to use attention to alleviate the backdoor effect for defense.\nThe results are shown in the following table. The model is DeiT-B, and all experiments are performed on ImageNet. It is easily found that for ViT-specific attacks, AdamW is also a better choice, which better preserves the ACC and reduces the ASR to an extremely low level. This phenomenon is the same as those with model-agnostic attacks in Table 2.\n\nASR (%)\n\n|            | TrojViT  | DBIA     |\n| ---------- | -------- | -------- |\n| No defense | 91.08    | 99.58    |\n| SGD        | 0.37     | 0.12     |\n| AdamW      | **0.14** | **0.09** |\n\nACC (%)\n\n|            | TrojViT   | DBIA      |\n| ---------- | --------- | --------- |\n| No defense | 80.59     | 79.52     |\n| SGD        | 69.63     | 70.26     |\n| AdamW      | **76.82** | **78.30** |\n\n**Q3:** It is not clear if this attack can bypass detection technologies that don\u2019t rely on the difference in activation, such as Neural Cleanse [9] which is based on reverse engineering and outlier detection. \n\n**A3:** Here, we use Neural Cleanse (NC) as an example. NC is a backdoor consisting of two steps: (1) It first reconstructs all possible triggers through optimization and determines whether a backdoor attack exists via outlier detection. (2) it mitigates backdoor behavior through unlearning with the reconstructed trigger, i.e., restoring the performance even with the presence of the trigger. We examine whether CAT can better bypass NC in these two stages, and all experiments are performed on the CIFAR-10 dataset under ViT-B.\n\n**Stage 1: Detection**\n\nNC reconstructs potential triggers for each class and uses an anomaly index to determine if one of them is a valid trigger. The larger the anomaly index, the more likely it is to be a real backdoor trigger. Here, we calculate the anomaly indexes of the attack with or without CAT for comparison,\n\n|         | Badnets | Blend | CLB  | SIG  |\n| ------- | ------- | ----- | ---- | ---- |\n| Vanilla | 7.45    | 3.14  | 7.13 | 2.26 |\n| +CAT    | 5.04    | 1.60  | 2.48 | 0.90 |\n\nThe results show that CAT can always lower anomaly indexes, making the attack stealthier. For example, the vanilla badnets attack obtains anomaly indexes of 7.45, which is larger than those after combing CAT (5.04). It means CAT can help existing attacks better bypass the detection of NC."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4969/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700464173296,
                "cdate": 1700464173296,
                "tmdate": 1700464369364,
                "mdate": 1700464369364,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7LHvCuxbRg",
            "forum": "MLShfiJ3CB",
            "replyto": "MLShfiJ3CB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4969/Reviewer_jtUw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4969/Reviewer_jtUw"
            ],
            "content": {
                "summary": {
                    "value": "This paper study backdoor attack on Vision Transformers. They show that existing defenses successfully defend against backdoor attacks in ViT-B and CIFAR10 dataset. Moreover, they proposed Channel Activation attack (CAT). They show that CAT attack is more effective on CIFAR10 dataset."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "[+] CAT attack can transfer to other Vision transformers on Table 4 in CIFAR10 dataset."
                },
                "weaknesses": {
                    "value": "[-] Study of backdoor attack with only CIFAR10 and single vision transformer architecture is not convincing, and any conclusion based on these limited settings won\u2019t be accurate. Note that study of backdoor attack on the Vision Transformer has been conducted before.\n\n[-] What is your thread model in your proposed attack? Do you assume that adversary have access to the model during training? Current setting is confusing to me since there are two thread models: 1. Both source and target being same model 2. Source and target are different\n\n\n[-] In ImageNet experiments, both source and target are ViT-B. Does this means that adversary has access to model architecture and its parameters. This is not a practical scenario in my opinion and limits the impact of the paper."
                },
                "questions": {
                    "value": "-"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4969/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4969/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4969/Reviewer_jtUw"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4969/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698817799184,
            "cdate": 1698817799184,
            "tmdate": 1699636483935,
            "mdate": 1699636483935,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wKBjj346P3",
                "forum": "MLShfiJ3CB",
                "replyto": "7LHvCuxbRg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4969/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4969/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer jtUw (Part1)"
                    },
                    "comment": {
                        "value": "Dear reviewer jtUw:\n\nThank you for your invaluable reviews. For your concerns, our replies are as follows:\n\n**Q1:** The study of backdoor attacks with only CIFAR10 and single vision transformer architecture is not convincing, and any conclusion based on these limited settings won\u2019t be accurate. Note that study of backdoor attack on the Vision Transformer has been conducted before.\n\n**A1:**  Firstly, we would like to reclaim our contributions compared to previous works [1-4] studying the backdoor robustness for ViTs:\n\n- **Backdoor Attack:** Zheng et al. in [1] and Lv et al. in [2] propose two ViT-specific attacks respectively: TrojViT and DBIA. However, our works show that both of them fail to evade the backdoor defenses after adaptations. **Only our proposed CAT can maintain a high ASR.**\n- **Backdoor Defense:** In [3], they first apply model-agnostic backdoor defense on ViTs. However, due to the lack of any adaptation, they either significantly reduce ACC or are unable to reduce ASR. Therefore, they conclude that: the effective defense that has been verified on the CNN architecture may not be suitable for the ViT architecture. In contrast to their conclusions, **we find that with proper adaptation, current defense methods are still demonstrated to be effective on ViTs.** Subramanya et al. in [4] propose a ViT-specific defense: AB (Attention Blocking). We show that **CAT can improve the ASR even for ViT-specific defense like AB.**\n\nFurthermore, to illustrate that our conclusion is general and convincing, we conduct experiments on the CIFAR-100 dataset with the ViT-B and Swin-B architectures as follows:\n\n**Comparison of Optimizers**\n\nWe perform FT using SGD and AdamW optimizer, respectively in the following tables:\n\nViT-B\n\n|        | Before | SGD   | AdamW     |\n| ------ | ------ | ----- | --------- |\n| ACC(%) | 89.54  | 42.76 | **69.12** |\n| ASR(%) | 100.00 | 1.37  | 2.31      |\n\nSwin-B\n\n|        | Before | SGD  | AdamW     |\n| ------ | ------ | ---- | --------- |\n| ACC(%) | 92.24  | 2.81 | **78.56** |\n| ASR(%) | 100    | 0    | 1.39      |\n\nWhile the SGD optimizer can reduce the ASR to almost zero, it will significantly sacrifice the benign ACC, which makes the purified models unusable. By contrast, the ACC for fine-tuning using AdamW (69.12%) is much higher than the ACC for fine-tuning using SGD (42.76%). This observation is consistent with our findings on the CIFAR-10 dataset.\n\n**Comparison of Fine-tuning Epochs**\n\nOn CIFAR-100, we also fine-tuned ViT-B and Swin-B with various epochs to investigate the effect of longer training on ViTs\u2019 performance. The benign accuracy is shown in the following table,\n\n|        | Before | 20 epoch  | 100 epoch |\n| ------ | ------ | --------- | --------- |\n| ViT-B  | 89.54  | **69.12** | 58.93     |\n| Swin-B | 92.24  | **78.56** | 72.66     |\n\nwhere we find the severe overfitting issue caused by longer training. For example, the ACC drop of 100 epochs with ViT-B is more than 10% (69.12 \u2192 58.93). This is consistent with the phenomenon in our paper.\n\n**Comparison of Puning Granularity**\n\nTaking AWM as an example, we investigate the impact of pruning granularity on the performance of defense approaches. Here, we compare the default granularity and our adapted granularity on CIFAR-100 with both ViT-B and Swin-B in the following tables.\n\nViT-B\n\n|        | Before | Vanilla | Adapted   |\n| ------ | ------ | ------- | --------- |\n| ACC(%) | 89.54  | 61.04   | **82.07** |\n| ASR(%) | 100.00 | 1.17    | 1.18      |\n\nSwin-B\n\n|        | Before | Vanilla | Adapted   |\n| ------ | ------ | ------- | --------- |\n| ACC(%) | 92.24  | 39.97   | **81.81** |\n| ASR(%) | 100.00 | 0.41    | 2.60      |\n\nSimilarly, our proposed coarse granularity (pruning the output channel of the linear projection layer) surpasses the default granularity (pruning ViTs using an element-wise mask) in preserving ACC. For example, our proposed adaptation improves ACC of ViT-B by a notable margin (61.04% \u2192 82.07%) while keeping the ASR almost unchanged. The results demonstrate that pruning the output channel is a better choice across datasets or architectures."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4969/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700463931244,
                "cdate": 1700463931244,
                "tmdate": 1700463931244,
                "mdate": 1700463931244,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "O6DJvhMWqi",
            "forum": "MLShfiJ3CB",
            "replyto": "MLShfiJ3CB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4969/Reviewer_FJ73"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4969/Reviewer_FJ73"
            ],
            "content": {
                "summary": {
                    "value": "The article identifies shortcomings in existing defense methods against backdoor attacks on Neural Networks, specifically focusing on Vision Transformers (ViT). It highlights deficiencies in fine-tuning-based defense and pruning-based defense on ViT and proposes adjustments to enhance their performance. Additionally, the authors introduce a new backdoor attack method, CAT, designed to bypass these defenses with increased robustness. CAT involves adding special adversarial perturbations to the trigger pattern to minimize noticeable channel activation differences between benign and triggered input."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This paper is easy to understand.\n- The article observes the use of different optimizers for training Convolutional Neural Networks (CNNs) and ViTs, suggesting a potential overstatement of ViTs' vulnerability to attacks with defense.\n- The CAT attack seems effective in attacking the ViT models."
                },
                "weaknesses": {
                    "value": "- The contributions of this paper seem incremental, especially in the defense part. The experiments indicate that optimizing the choice of optimizer, adjusting epoch numbers, and selecting appropriate granularity for pruning can improve defense performance on ViT. To apply fine-tuning-based methods to ViT, the authors adjust optimizers and epochs. However, these improvements are based on experimental trials, and there is no methodology to guide us on how to pick good hyperparameters.\n- In Section 3.2, the impact of the epoch on fine-tuning defense is explored. The curve for the first 20 epochs differs significantly from the first 20 epochs when setting the experiment to 100 epochs, particularly in the left plot of (a) left. The variability in experimental results raises concerns about the reliability of the findings, considering the potential instability.\n- Table 4 illustrates that the CAT attack method improves ASR, but the enhancement is limited, as most unsuccessful attacks do not become successful.\n- Some symbols used in the formulas lack explanations. Appendix C Figure 7 should refer to Table 7."
                },
                "questions": {
                    "value": "See my comments above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4969/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699201744538,
            "cdate": 1699201744538,
            "tmdate": 1699636483866,
            "mdate": 1699636483866,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Xxjsl1Kkoy",
                "forum": "MLShfiJ3CB",
                "replyto": "O6DJvhMWqi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4969/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4969/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer FJ73 (Part1)"
                    },
                    "comment": {
                        "value": "Dear reviewer FJ73:\n\nFirst, I would like to express my gratitude to you for your insightful feedback. For your raised questions, here are our responses:\n\n**Q1:** The contributions of this paper seem incremental, especially in the defense part. There is no methodology to guide us on how to pick good hyperparameters. \n\n**A1:** We believe that when solving problems, the greatest contribution to the community is to explore the fundamental issues and solve them with straightforward strategies, rather than a seemingly novel and complex approach. Here, we attribute the failure of the current defense to the following two points:\n\n- **The mismatch between training and defense**: In fact, the first paper proposing ViTs [1] uses AdamW for pretraining and finetuning with SGD. Therefore, multiple works such as [2] adopt this strategy as default and they only obtain 42.00% ACC. We first identify this problem and propose that the AdamW optimizer is essential for fine-tuning-based defense.\n- **The overfitting problem during the defense:** There is a typical problem when only a small amount of data is available for defense. In this situation, fine-tuning a large-capacity model is risky as it can easily lead to overfitting, especially for ViTs which are known to lack inductive bias [1]. Therefore, applying coarser granularity to reduce the number of learnable parameters and decreasing the number of iterations to lower the actual exploration parameter space can both reduce overfitting issues.\n\nTherefore, we believe that our approaches provide the community with sufficient insight and contributions. From our investigations, there are three methodologies that can be concluded to guide us in picking good hyperparameters.\n\n- If the defense methods are based on fine-tuning, the AdamW optimizer is recommended.\n- If the defense methods are based on pruning, pruning the channel of the linear layer might be a good choice.\n- For all defense methods, additional measures are needed to be taken to prevent overfitting.\n\n**Q2:** The curve for the first 20 epochs differs significantly from the first 20 epochs when setting the experiment to 100 epochs, particularly in the left plot of (a) left. The variability in experimental results raises concerns about the reliability of the findings, considering the potential instability.\n\n**A2**: This is because we employ a cosine learning rate (lr) schedule, which starts with a very large learning rate (0.0003) and gradually decreases until it reaches 0 in the final epoch. lr decreases at a different pace between training for 20 epochs and training for 100 epochs. Specifically, in the former case, lr drops to 0 at the 20th epoch (20 epochs in total), whereas in the latter case, it still keeps a large value (0.000274) at the 20th epoch (100 epochs in total). As a result, the curve seems quite different for the first 20 epochs.\n\nIn addition, we repeated our experiments 3 times with various numbers of epochs in the following table, in which we can find our method is stable with small variability and the findings are reliable.\n\n**Badnets Attack**\n\n| fine-tuning epoch | 20          | 40          | 60          | 80          | 100         |\n| ----------------- | ----------- | ----------- | ----------- | ----------- | ----------- |\n| ACC               | 93.71 $\\pm$ 0.14 | 92.42 $\\pm$ 0.10 | 92.23 $\\pm$ 0.14 | 91.25 $\\pm$ 0.10 | 90.48 $\\pm$ 0.17 |\n| ASR               | 2.08 $\\pm$ 0.60  | 1.92 $\\pm$ 0.49  | 1.70 $\\pm$ 0.28  | 1.62 $\\pm$ 0.52  | 1.54 $\\pm$ 0.10   |\n\n**Q3:** The enhancement of CAT is limited. \n\n**A3**: Note that even a single successful attack can lead to substantial losses. When ASR increases from 1% to 10%, the incident frequency becomes 10 times larger, turning a negligible risk into a significant threat. In contrast, models with ACC of either 1% or 10% are both considered unusable in practice.\n\nIn the following table, we have listed the average improvement of CAT against various defense algorithms under a given attack method, along with the changes in the incident frequency. It is evident that our method significantly increases the incident frequency. Notably, it even increases the incident frequency of BadNets to ~34 times larger compared to its original value.\n\n| ASR (Average over five defense)   | BadNets | Blend | CLB   | SIG   |\n| --------------------------------- | ------- | ----- | ----- | ----- |\n| Vanilla                           | 1.41    | 8.00  | 6.13  | 2.23  |\n| CAT                               | 47.80   | 46.28 | 14.18 | 27.18 |\n| Improvement of indecent frequency | 33.9x   | 5.8x  | 2.3x  | 12.2x |"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4969/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700463512347,
                "cdate": 1700463512347,
                "tmdate": 1700463859139,
                "mdate": 1700463859139,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iCWXi8Ax5T",
                "forum": "MLShfiJ3CB",
                "replyto": "O6DJvhMWqi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4969/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4969/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer FJ73 (Part2)"
                    },
                    "comment": {
                        "value": "**Q4:** Some symbols used in the formulas lack explanations. Appendix C Figure 7 should refer to Table 7. \n\n**A4:**  Thank you for the correction. We have read the entire paper word by word and two minor errors have been corrected (The corrections are highlighted in blue.):\n\n- In Appendix C, we substitute \u201cFigure 7\u201d with \u201cTable 7\u201d. Figure 7 is correctly referred to and explained in Appendix G.\n- In Section 4, we correct \u201cthere exists\u201d with \u201cthere exist\u201d.\n\nWe sincerely hope that our response could answer your questions and you could reconsider your rating. Look forward to your replies!\n\n[1] An Image is Worth 16$\\times$16 Words: Transformer for Image Recognition at Scale, Dosovitskiy et al, in ICLR 2021.\n\n[2] BackdoorBench: A Comprehensive Benchmark of Backdoor Learning, Baoyuan Wu et al., In NeurIPS 2022."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4969/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700463638183,
                "cdate": 1700463638183,
                "tmdate": 1700463685220,
                "mdate": 1700463685220,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]