[
    {
        "title": "COLLIE: Systematic Construction of Constrained Text Generation Tasks"
    },
    {
        "review": {
            "id": "Vq04LCvSvv",
            "forum": "kxgSlyirUZ",
            "replyto": "kxgSlyirUZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6849/Reviewer_p51c"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6849/Reviewer_p51c"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose COLLIE, a grammar-based framework for probing the performances of LLMs on constrained text generation tasks. COLLIE realizes the constraints on different levels (word, paragraph, passage) and imposes requirements on various aspects, e.g., character count, word count, and positions of a specific text. Experiments are conducted on instructions built from three sources and on various strong LLMs (GPTs, PaLMs, and etc.). The results suggest that GPT-4 generally outperforms other compared models but still performs poorly on a subset of the tasks. \n\nOverall, while the concept of this task is simple, the challenges posed to existing LLMs are non-trivial, clearly pointing out the incapabilities of these models. I believe COLLIE has the potential to drive further developments of existing models on more nuanced tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The paper is well-written and easy-to-understand.\n* COLLIE is a conceptually simple but scientifically non-trivial method, and is beneficial to further development of LLMs.\n* The experiments and analyses are comprehensive, including evaluations on current state-of-the-art models.\n* The authors also provide complementary code which helps verify their approach."
                },
                "weaknesses": {
                    "value": "I have one question regarding to the instructions obtained from different sources. Since the grammar is translated into natural language instruction to prompt the model, how do the instructions from different source datasets differ from one another?"
                },
                "questions": {
                    "value": "See weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6849/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698505407840,
            "cdate": 1698505407840,
            "tmdate": 1699636793809,
            "mdate": 1699636793809,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4bmyolZzHk",
                "forum": "kxgSlyirUZ",
                "replyto": "Vq04LCvSvv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6849/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6849/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks"
                    },
                    "comment": {
                        "value": "The format of the instructions (i.e., constraint types) are identical across different sources, e.g., \"Generate a passage with $n$ sentences.\" \n\nHowever, the distribution of constraint values (e.g., $n$ in the previous constraint) differ for different sources. For instance, Wiki has twice the average number of sentences compared to CC-News (See Fig. 3(c)). \n\nLet us know if you have further questions, thanks!"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6849/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700163380358,
                "cdate": 1700163380358,
                "tmdate": 1700163380358,
                "mdate": 1700163380358,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7grLGMKxQz",
            "forum": "kxgSlyirUZ",
            "replyto": "kxgSlyirUZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6849/Reviewer_6Jty"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6849/Reviewer_6Jty"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a framework, COLLIE, that allows researchers to build constrained text generation benchmark using different combinations of generation levels and modeling challenges (tasks), and a benchmark, COLLIE-v1, which is constructed using that framework and consists of 20,80 data instances comprising 13 structures.\nThe value of this paper lies in that it provides a method which allows future work to construct data of their interest in a scalable manner, and the analyses that the this paper conducts provide insights to researchers who are focusing on developing LLMs with better logical, reasoning, and compositional capacities."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This paper provides a method which allows future work to construct data of their interest in a scalable manner.\n2. The analyses that the this paper conducts provide insights to researchers who are focusing on developing LLMs with better logical, reasoning, and compositional capacities.\n3. This paper is generally well-written and easy to follow."
                },
                "weaknesses": {
                    "value": "There is no great weaknesses that I can find - but there is a minor one:\n\nAlthough I understand that the authors are focusing on more \"basic\" units, such as tokens, sentence, etc, so this paper can be more practical and useful for downstream applications, such as pretraining and evaluating LLMs, most of current work on constrained text generation seem to focus on text summarization, including controllable text summarization (e.g., MACSum Zhang et al, 2023). However this paper does not mention any of this, and does not discuss any potential that the proposed method can be applied to those constrained text generation (summarization) tasks. I personally suggest that the authors provide some discussion or explain on this issue.\n\nZhang, Yusen, Yang Liu, Ziyi Yang, Yuwei Fang, Yulong Chen, Dragomir Radev, Chenguang Zhu, Michael Zeng, and Rui Zhang. \"Macsum: Controllable summarization with mixed attributes.\" Transactions of the Association for Computational Linguistics 11 (2023): 787-803."
                },
                "questions": {
                    "value": "Please see weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6849/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698586376062,
            "cdate": 1698586376062,
            "tmdate": 1699636793706,
            "mdate": 1699636793706,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xKNa4YBjqO",
                "forum": "kxgSlyirUZ",
                "replyto": "7grLGMKxQz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6849/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6849/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks"
                    },
                    "comment": {
                        "value": "Thanks for your great suggestion! We have incorporated the related work and discussion in the draft!"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6849/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700163275107,
                "cdate": 1700163275107,
                "tmdate": 1700163275107,
                "mdate": 1700163275107,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qmWxOmaztO",
            "forum": "kxgSlyirUZ",
            "replyto": "kxgSlyirUZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6849/Reviewer_PuAQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6849/Reviewer_PuAQ"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a framework to automatically extract samples from large unlabeled text corpora for constrained text generation. Specifically, they manually craft rules/constraints and find satisfying texts as references. For example, a constraint can be \"the third last word being mankind\". They then evaluate off-the-shelf LLMs on this extracted dataset."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The authors evaluated different off-the-shelf LLMs and showed that they don't fully solve this task."
                },
                "weaknesses": {
                    "value": "1. The idea is not very novel, and similar ideas have already been explored. For example, [1] also constructed a dataset using similar constraints for instruction fine-tuning.\n2. The dataset may not be very useful. Specifically, because the rules are too vague/arbitrary, the extracted ground truth is not useful for the evaluation process: the authors only use them for comparing fluency. In addition, since the rules can be arbitrarily designed, this compiled dataset does not hold much value, because many similar datasets can be compiled with different engineering details.\n\n[1] Controlled text generation with natural language instructions. https://proceedings.mlr.press/v202/zhou23g/zhou23g.pdf"
                },
                "questions": {
                    "value": "In the limitations, the authors mentioned potential problems with filtering and processing functions. Could the authors elaborate on what issues might exist for the extraction process?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6849/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6849/Reviewer_PuAQ",
                        "ICLR.cc/2024/Conference/Submission6849/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6849/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698809012458,
            "cdate": 1698809012458,
            "tmdate": 1700505932479,
            "mdate": 1700505932479,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "78edv3xZOc",
                "forum": "kxgSlyirUZ",
                "replyto": "qmWxOmaztO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6849/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6849/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks"
                    },
                    "comment": {
                        "value": "Thanks for your feedback! Let us know if your have followup questions.\n\n1. **The idea is not very novel, and similar ideas have already been explored. For example, [1] also constructed a dataset using similar constraints for instruction fine-tuning.**\n\n    * Thanks for bringing up this concurrent work, which we have cited and discussed in the revised paper! \n    * It focuses on turning constraints into NL instructions and fine-tuning smaller language models such as T5-11B, and the constraints themselves are fairly simple and limited (only 5 types). In contrast, Collie focuses on making constrained text generation more flexible, customizable, and harder, challenging even SoTA LLMs like GPT-4. \n    * We believe these two efforts are orthogonal and can be complementary --- we can use these harder and more flexible constraints from Collie-v1 and other Collie constructed datasets to diagnose and analyze LMs (as shown in the paper), and improve the instruction tuning of LMs.\n\n2. **The dataset may not be very useful. Specifically, because the rules are too vague/arbitrary, the extracted ground truth is not useful for the evaluation process: the authors only use them for comparing fluency. In addition, since the rules can be arbitrarily designed, this compiled dataset does not hold much value, because many similar datasets can be compiled with different engineering details.**\n\n    * The extracted ground truth text is not only useful for comparing fluency, but also to ensure the extracted constraint values are solvable using natural text. We believe it is actually  important to evaluate constraint satisfaction using the constraints instead of the extracted text, as there could be very diverse generations that all satisfy the same constraints. \n    * As stated in the paper, our main contribution is twofold: the Collie framework for constructing constrained text generation tasks, and the Collie-v1 dataset using a concrete and preliminary set of constraint types. The facts that \u201crules can be arbitrarily designed\u201d and \u201cmany similar datasets can be compiled with different engineering details\u201d are exactly the merit of our proposed Collie framework --- while previous datasets feature a fixed set of simple constraints and ad-hoc pipelines for data collection, the Collie framework allows automatic and scalable construction of arbitrary grammar-expressible constraints. \n\n3. **In the limitations, the authors mentioned potential problems with filtering and processing functions. Could the authors elaborate on what issues might exist for the extraction process?**\n    * Every text corpus has artifacts (e.g., tables, footnotes, references, headings that might not be natural sentences or paragraphs). We design filtering and processing functions to patch or eliminate passages with these artifacts. However, it is impossible to design a filtering system that is perfect, so there could be downstream reference texts or constraints that look unnatural. This is more of a fundamental limitation with any approach that leverages text in the wild, and not a limitation specific to Collie or CTG construction. We have revised the limitation part to better explain this, thanks!"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6849/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700163245608,
                "cdate": 1700163245608,
                "tmdate": 1700163245608,
                "mdate": 1700163245608,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iLQt6s8EJD",
                "forum": "kxgSlyirUZ",
                "replyto": "78edv3xZOc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6849/Reviewer_PuAQ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6849/Reviewer_PuAQ"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the detailed response!\nAlthough I do not entirely agree, I am willing to raise my score from 5 to 6."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6849/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700506031903,
                "cdate": 1700506031903,
                "tmdate": 1700506031903,
                "mdate": 1700506031903,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "pAA8lNaBa4",
            "forum": "kxgSlyirUZ",
            "replyto": "kxgSlyirUZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6849/Reviewer_nWAg"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6849/Reviewer_nWAg"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a grammar based framework called COLLIE for constrained text generation at varying levels of specifications. Additionally it proposes a development tool for automated extraction of task instances given a constraint structure and text corpus. Furthermore, the paper constructs a dataset from three sources - Wikipedia, CCNews, and Project Gutenberg using the previously mentioned framework and calls it COLLIE-v1. The resultant dataset COLLIE-v1 is constructed using manually crafted constraints and is used to analyze LLM performances as well as highlight their shortcomings. The paper focuses on five of the most prominent LLMs, namely GPT-3.5,GPT-4,PaLM, Vicuna-7B and Alpaca-7B.\n\nInterestingly, the COLLIE framework enables flexible, extensible and dynamic constraint construction that can co-evolve with the upcoming LLMs and help in understanding their shortcomings to better solve them.\n\nCOLLIE can thus help in not only evaluating and benchmarking LLMs but also help in constraint text generation independently."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1. Well written paper with evaluation on competitive LLM baselines.\n    \n2. Combination of rule based and neural based generation enables NLP grounded generations\n    \n3. Open-sourcing of code and the related dataset for promoting further research.\n    \n4. Comprehensive analysis to highlight the shortcoming of current LLMs that needs to be addressed."
                },
                "weaknesses": {
                    "value": "1. Some important details for instruction rendering should be moved to the main paper.\n    \n2. The paper mentions that the technique can be used for constraining words, word blacklisting, however a qualitative analysis is missing for the same in the current version."
                },
                "questions": {
                    "value": "Section 5: Performance enhancement through feedback - It might help to list down the details of how the feedback is being used."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "10: strong accept, should be highlighted at the conference"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6849/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698834638080,
            "cdate": 1698834638080,
            "tmdate": 1699636793455,
            "mdate": 1699636793455,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "57BmTL4swS",
                "forum": "kxgSlyirUZ",
                "replyto": "pAA8lNaBa4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6849/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6849/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks"
                    },
                    "comment": {
                        "value": "Thanks for your positive comments! Let us know if you have further feedback.\n\n1. **Some important details for instruction rendering should be moved to the main paper.**\n\n    * As per your suggestion, we have moved more details for instruction rendering to the main paper (section 3, in blue).\n\n2. **The paper mentions that the technique can be used for constraining words, word blacklisting, however a qualitative analysis is missing for the same in the current version.**\n\n    *  By word blacklisting we mean something similar to constraint para02: \"Generate a paragraph with at least 4 sentences, but do not use the words \u201cthe\u201d, \u201cand\u201d or \u201cof\u201d.\" We have complete model outputs in our supplementary material, but we can also add some of these examples to the appendix. Thank you for the suggestion. \n\n3. **Section 5: Performance enhancement through feedback - It might help to list down the details of how the feedback is being used.**\n\n    * Thanks! We have moved some details for use of feedback to the main paper, as per your suggestion (section 5.1, in blue)."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6849/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700162346165,
                "cdate": 1700162346165,
                "tmdate": 1700162346165,
                "mdate": 1700162346165,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]