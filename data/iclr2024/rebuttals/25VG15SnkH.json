[
    {
        "title": "United We Train, Divided We Fail! Representation Learning for Time Series by Pretraining from 75 Datasets at Once"
    },
    {
        "review": {
            "id": "cqDVgWRtRX",
            "forum": "25VG15SnkH",
            "replyto": "25VG15SnkH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5599/Reviewer_4uSe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5599/Reviewer_4uSe"
            ],
            "content": {
                "summary": {
                    "value": "Authors propose a self-supervised pre-training method for time-series data encompassing various domains and temporal dynamics and show that it leads to significant performance gains for finetuning on small datasets. The problem is well-motivated as time-series occurs in domains such as traffic, weather, finance, etc and in many cases labelled data is limited.\n\nGiven a time-series $x \\in R^T$ authors propose to encode it as a sequence $z \\in R^{K \\times d}$ via a simple convnet. For this, authors collect various labelled and unlabelled time-series datasets (>75) and pretrain on all of them. Pretraining consists of various objectives from prior works and some novel components. At a high level, the encoder is trained to predict $z_K$ from the context $z[<K]$. During finetuning $z_K$ is used to classify $x$. For better generalization, during pretrianing, a different time-series $y$ is chosen from the batch and a convex combination $\\lambda x + (1-\\lambda)y$ is used for learning a continuous latent space between samples from various datasets. Training losses are designed to learn representations that are robust to augmentations such as magnitude scaling, permutation and jitter.\n\nAuthors demonstrate the utility of the method on a large collection of timeseries datasets over various modalities."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The experimental evaluation is comprehensive and the empirical gains over supervised training are significant, clearly demonstrating the utility of the proposed method for prertaining on diverse datasets."
                },
                "weaknesses": {
                    "value": "1. The novelity of the method is limited and the main components such as augmentations and TC loss are borrowed from previous works such as TS-TCC.\n\n2. The significance of the novel contribution, SICC loss, isnt made fully clear. In Table 1 the experiments are performed on a limited number of datasets and data, and it seems that including the SICC loss helps. In contrast, Table 2 and Figure 6 suggets that finetuning on all available data, excluding the SICC loss (essentially resulting in the TS-TCC model from prior work) doesnt hurt the performance significantly.\n\n3. The TS-TCC framework is itself not intuitive to begin with - what exactly is the need for such data augmentations and contrived losses derived from these? Why to only use the last vector $z_K$ to be predicted from context $c$ - why not predict $z_t$ from $z_{t-1}$ for every $t$? How is $c$ formed? Not clear if this pipeline cannot be replaced with a much simpler training pipeline assuming more data is available."
                },
                "questions": {
                    "value": "Typo: pg 6 \"in contrary\" -> \"in contrast\""
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5599/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698798019354,
            "cdate": 1698798019354,
            "tmdate": 1699636577238,
            "mdate": 1699636577238,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "RWqAn2Y4cb",
                "forum": "25VG15SnkH",
                "replyto": "cqDVgWRtRX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5599/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5599/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank you for your very thoughtful review and for pointing out positive aspects as well as open opportunities, which we try to address in the following.\n\nWe agree that we provided a very extensive overview of current approaches and their comparability to supervised learning.\n\nYour raised points have greatly helped us to improve our manuscript. \nWe address all your concerns below.\n\n> XIT only provides minor novelty over TS-TCC.\n\nXIT's core encoder and TC module are derived from TS-TCC. We substitute its previous NT-Xent loss, integrating multiple runs of their TC loss. This configuration solely employs the cross-prediction task, presenting entirely novel inputs and outputs. Dismissing its novelty would be akin to disallowing the use of a Convolutional ResNet as a backbone in a new model. The underlying concept emphasizes the explicit need for both intra- and inter-dataset structuring tasks simultaneously.\n\nThe application of mixup on time series by Wickstr\u00f8m et al. (2022), on the other hand, is mainly a data augmentation method with the goal of learning a representation by predicting the mixing lambda. This is challenging for intra-dataset pretext tasks. For inter-dataset tasks, the model tends to learn to differentiate between datasets, which is not the goal of this task. We tackle this by ensuring that the lambda is not simply predicted but that the latent space corresponds to the time domain in terms of mixing distance. This ensures that we can really leverage cross-dataset information. Our experimental evaluation shows that this intuition carries over into practice.\nAs a side note: In initial probings, we did not see any meaningful effect by simply predicting the lambda as proposed by Wickstr\u00f8m et al. (2022).\n\n> The significance of the SICC loss is not made clear in the ablations\n\nThank you for pointing that out. We updated the paper to make this more clear, see Table 3 (Pg. 8). The evaluation indeed shows that we need all of our proposed methods to improve the performance. More details are in the Global Response 3.\n\n> The TS-TCC framework is itself not intuitive to begin with - what exactly is the need for such data augmentations and contrived losses derived from these?\n\nThe need for weak and strong augmentations is already extensively discussed in the TS-TCC paper (see section 3.1 and ablations in section 5.4). The general motivation is that for a model to learn strong representations, one needs to pose a real challenge by means of the loss formulation. This is exactly what TS-TCC does, as predicting the weak from the strong augmented variant (and vice versa) can indeed be challenging. We, however, agree that simpler models should also be studied in further work.\n\n>  Is it possible to predict z_t from z_t-1 for every t?\n\nWhile it is possible, it would also increase the required memory tremendously. The SICC loss uses the predicted context of all elements in the batch. Building the required distance matrix of all pairs is fairly expensive, which one likely would not want to repeat for each time window. Furthermore, it is sometimes likely not an expressive task for time series with lots of leading padding.\n\n> Is it possible to replace this pipeline with a much more simple one?\n\nPlease see the second part of our answer to question one. However, in essence, simple mixup was not enough, and this is why we wanted to induce specific latent structuring methods for this specific challenge. However, making it easier is an interesting course of action and will be on our list of future work.\n\n>  How is the context vector formed?\n\nWe utilize a sequence transformer (summarization model $\\mathcal{S}$) taking the previous $z_k$, where $k \\in [0, t-1]$ as input and producing a \u201cforecast\u201d of the context vector (see section 2.2). To get a more visual explanation, please see Figure 2 of our paper. For implementation details, please refer to \u201cEncoder & Summarization Model\u201d in appendix A.2.\n\nWe hope that we have clarified your concerns and that you can reconsider our rating. Do let us know if you have any further questions or comments."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5599/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700143082658,
                "cdate": 1700143082658,
                "tmdate": 1700143301758,
                "mdate": 1700143301758,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oBO6GKcX3w",
                "forum": "25VG15SnkH",
                "replyto": "RWqAn2Y4cb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5599/Reviewer_4uSe"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5599/Reviewer_4uSe"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for the detailed and convincing clarifications - the updated tables look clearer. I'm maintianing my score as I find the contrbutions made by the authors to be non-trivial. While I'm not fully certain if the method has a wide-enough appeal (and I might be completely wrong), I'll be supporting it during the discussion phase among the reviewers.\nIn case the paper isn't accepted, I urge the authors to work towards simplifying the writing (and the method itself if possible) and resubmit to a different venue as the reviews might have been overtly harsh - I believe the paper deserves better scores."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5599/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700258822629,
                "cdate": 1700258822629,
                "tmdate": 1700258822629,
                "mdate": 1700258822629,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qWO2THH2Ky",
            "forum": "25VG15SnkH",
            "replyto": "25VG15SnkH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5599/Reviewer_Gxh9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5599/Reviewer_Gxh9"
            ],
            "content": {
                "summary": {
                    "value": "The paper summarizes a way to pre-train a model on multiple datasets to learn representations which are useful for downstream tasks such as classification. The authors propose modifications to an earlier method called TS-TCC, which introduces weak and hard augmentations to time-series. The authors propose a novel loss function SICC which ensures that augmented time-series contexts are similar to the time-series contexts from which they are interpolated."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is well written and easy to follow. \n2. To the best of my knowledge, pre-training on multiple time-series datasets has not been explored. \n3. I like the vision behind the experimental section, as well as its organization into research questions."
                },
                "weaknesses": {
                    "value": "1. **Contributions:** It is unclear how significant the contributions of the study are beyond training on multiple datasets. It seems to be an incremental improvement over TS-TCC and the experimental setup of TF-C. Could the authors experimentally demonstrate why it is infeasible to use TS-TCC (and TF-C) for pre-training on multiple datasets?\n2. **Experimentation:** I like how the authors have structure their experimentation in terms of research questions. However, I feel that the results are not convincing due to several reasons: (1) Multiple baselines including recent works such as TS2Vec [1], older techniques such as T-Loss [2] and TST [3], and statistical methods such as Dynamic Time Warping-based Nearest Neighbors (see [1]) were missing. (2) The experiment framework differs from some prior work, where the representations are used to train a downstream classifier such as SVM for classification (see [1] and [2] for example). I wonder whether, how and why is the fine-tuning and subsequent evaluation different from that of prior work, including the metrics used to compare the methods (i.e. accuracy). Also see section on Clarity below. (3) The ablation results in Table 2 seem insignificant since the variances of the models are overlapping. I would be interested in seeing a critical difference diagram to see if the differences between the proposed method and ablations are indeed significant. \n3. **Clarity:** Some important details in experimentation were missing, for example, how were the models fine-tuned? I see from the appendix that cross-entropy loss was used, but it is unclear what was the structure of the model. \n\nReferences:\n[1] Yue, Zhihan, et al. \"Ts2vec: Towards universal representation of time series.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 36. No. 8. 2022.\n[2] Franceschi, Jean-Yves, Aymeric Dieuleveut, and Martin Jaggi. \"Unsupervised scalable representation learning for multivariate time series.\" Advances in neural information processing systems 32 (2019).\n[3] Zerveas, George, et al. \"A transformer-based framework for multivariate time series representation learning.\" Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data mining. 2021."
                },
                "questions": {
                    "value": "1. How are the models fine-tuned? \n2. Could you please report critical difference diagrams of fine-tuning performance on all datasets? Could you show the impact of pre-training, as how sample efficient the fine-tuning procedure is? \n3. Also see questions above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5599/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698810773163,
            "cdate": 1698810773163,
            "tmdate": 1699636577100,
            "mdate": 1699636577100,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XABt3OVHKL",
                "forum": "25VG15SnkH",
                "replyto": "qWO2THH2Ky",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5599/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5599/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "The authors thank the reviewer for the very extensive review, highlighting strengths and raising opportunities for improving our manuscript. This really helped us to improve upon our previous manuscript and helped to provide an even clearer scientific story.\n\nWe address all your concerns below.\n\n> Could the authors experimentally demonstrate why it is infeasible to use TS-TCC (and TF-C) for pre-training on multiple datasets?\n\nWe provided an intuition in Table 1, but in addition to that, we made a much more extensive experimental evaluation in Table 2. Next to even other baselines, it illustrates the superiority of XIT compared to the other methods.\n\n> Multiple standard baselines are missing.\n\nWe thank you for pointing that out. We provided 3 more baselines beyond TS-TCC and TF-C, as shown in the newly added Table 2. Namely, we evaluate TS2Vec (Yue et al., 2022), TNC (Tonekaboni et al., 2020), and T-Loss (Franceschi et al., 2019):\n\n| Target Dataset     \t\t | XIT      \t\t | TS-TCC   \t\t | TF-C      \t\t | TS2Vec   \t\t | TNC      \t\t | T-Loss   \t\t |\n|-----------------------------|-------------------|-------------------|--------------------|-------------------|-------------------|-------------------|\n| Average Macro F1 $\\uparrow$ | **54.4\u00b13.2** | 51.1\u00b13.5 \t\t | 43.1\u00b16.1  \t\t | 53.7\u00b12.5 \t\t | 36.4\u00b19.1 \t\t | 34.2\u00b14.7 \t\t |\n| Rank $\\downarrow$  \t\t | **2.10\u00b11.2** \t\t | 3.06\u00b11.6 \t\t | 3.56\u00b11.8  \t\t | 2.82\u00b11.6 \t\t | 4.48\u00b11.0 \t\t | 4.98\u00b11.1 |\n\nThe results strengthen the empirical effectiveness of our method.\n\n> The experiment framework differs from some prior work, where the representations are used to train a downstream classifier such as SVM for classification. \t\n\nWhile TS2vec indeed follows a slightly different scheme, we adhere to the standard linear benchmarking evaluation approach by Oord et al. (2018) and Chen et al. (2020), consistent with the evaluation methodology of TS-TCC and TF-C. In particular, we train a linear classifier (single MLP layer) on top of a frozen self-supervised pretrained encoder model.\n\n> Why didn\u2019t you include accuracy in your evaluation?\n\nWe provided exemplary accuracy scores in the appendix for Table 1. However, especially with unbalanced datasets (UEA + low data sampling), accuracy may not be a reliable metric. Therefore, in line with TS-TCC, we also presented AUROC and Macro-F1 scores.\n\n> What was the structure of the model?\n\nRefer to our response in question 3. Additionally, we have adjusted the manuscript for improved clarity.\n\n> The ablation results seem insignificant.\n\nThank you for pointing that out. The ablation results were indeed not presented in full clarity. To improve, we revamped our results in the new Table 3 by applying ranking after Dem\u0161ar et al. (2006).\n| Pretraining Component  \t| AUROC rank $\\downarrow$ | Accuracy rank $\\downarrow$ | Macro F1 rank $\\downarrow$ |\n|----------------------------|-------------------------|----------------------------|----------------------------|\n| XD-MixUp + SICC + TC (XIT) | **1.800 \u00b10.91**\t| **1.780 \u00b10.89**   \t| **1.780 \u00b10.84**   \t|\n| XD-MixUp + SICC        \t| 3.560 \u00b10.87         \t| 3.700 \u00b10.56            \t| 3.580 \u00b10.79            \t|\n| XD-MixUp + TC          \t| 2.060 \u00b10.94         \t| 1.920 \u00b10.84            \t| 1.980 \u00b10.91            \t|\n| TC                     \t| 2.580 \u00b10.91         \t| 2.600 \u00b10.78            \t| 2.660 \u00b10.81            \t|\n\n> How are the models fine-tuned?\n\nFor the experiments in Table 1, we fine-tuned on 2.5% of the data. For the subsequent experiments, we fine-tuned on 100% of the hold-out dataset since many UCR datasets are already challengingly small.\n\nWe trained for 2000 steps with early stopping. For details, we provide a paragraph on \u201cImplementation details\u201d in Appendix A.2.\n\nFor the best possible outcome, we run a thorough hyperparameter search for the optimal classifier config. Finally, we ran the experiments on multiple seeds.\n\n>  How sample efficient is the fine-tuning procedure?\n\nThis is the main challenge that we want to tackle with this paper. We particularly leverage the structures of multiple datasets in situations when large amounts of labeled data are not available. Therefore, the finetuning procedure is very sample efficient. Namely, the results in Table 1. were obtained from fine-share\ntuning on as little as 147 time series (HAR).\n\nWe hope that we have clarified your concerns and that you can reconsider our rating. Do let us know if you have any further questions or comments."
                    },
                    "title": {
                        "value": "Comment by the Authors"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5599/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700142919574,
                "cdate": 1700142919574,
                "tmdate": 1700143330343,
                "mdate": 1700143330343,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "E5HheZWlYr",
                "forum": "25VG15SnkH",
                "replyto": "qWO2THH2Ky",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5599/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5599/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking Forward to Feedback on Our Response"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nWe appreciate the time and effort that you have taken to provide us with your insightful review. We would like to ask if the reviewer has any further concerns or is satisfied by our responses to the original review.\n\nWe are looking forward to any further discussion with the reviewer and would like to thank the reviewer again for helping make our paper better.\n\nRegards,\nThe Authors"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5599/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700490259844,
                "cdate": 1700490259844,
                "tmdate": 1700490259844,
                "mdate": 1700490259844,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cIsjclOrPX",
                "forum": "25VG15SnkH",
                "replyto": "E5HheZWlYr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5599/Reviewer_Gxh9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5599/Reviewer_Gxh9"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the rebuttal!"
                    },
                    "comment": {
                        "value": "Dear Authors, \nI appreciate the rebuttal. Thanks for answering some of my questions. I do believe that the paper is stronger given the comparison with TS2Vec and other methods. \n\nQuick question: What does \"we fine-tuned on 100% of the hold-out dataset\" mean? I am assuming you are referring to 100% of the training set.\n\nAlso I apologize for the late response, but it is hard to follow changes in the paper if they are not done in a different ink. \n\nMy request on using critical difference diagrams for comparisons was not answered -- I would like to note that comparing models via critical difference diagram is common practice in this field. There are some other questions and recommendations which were also not answered, for e.g., comparison with dynamic time warping and nearest neighbors methods.\n\nGiven these, and the reviews from the other reviewers, I am inclined to stick with my current score. If the experimentation was made stronger, I would have been willing to increase my score."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5599/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700682129891,
                "cdate": 1700682129891,
                "tmdate": 1700682129891,
                "mdate": 1700682129891,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "MNghIN1VGq",
            "forum": "25VG15SnkH",
            "replyto": "25VG15SnkH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5599/Reviewer_kMWa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5599/Reviewer_kMWa"
            ],
            "content": {
                "summary": {
                    "value": "The paper challenges the common belief that pretraining is ineffective for time series data due to source-target mismatch. The authors introduce a novel approach called XIT, combining XD-MixUp, SICC, and Temporal Contrasting, to create a shared latent representation from up to 75 diverse unlabeled time series datasets, which outperforms supervised training and other self-supervised methods, especially in low-data scenarios. The work demonstrates the feasibility and effectiveness of multi-dataset pretraining for time series, debunking the prevailing myth and paving the way for further advancements in leveraging multiple datasets for improved time series classification and analysis."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper excels in its clear and effective communication of key concepts, ensuring a coherent and easily-followed narrative. It tackles a significant and intriguing challenge within time series analysis: the development of a pre-trained model by leveraging multiple diverse datasets. Furthermore, the paper rigorously examines the individual components of the proposed method through ablations, providing valuable insights into how each element influences downstream performance."
                },
                "weaknesses": {
                    "value": "1. The novelty of the proposed method is constrained, as it heavily relies on TS-TCC (Eldele et al., 2021). The SICC loss, derived from previous works (Sohn, 2016) and (Chen et al., 2020), bears resemblance to the one used in TS-TCC and essentially facilitates soft alignments. While the authors claim XD-MixUp as a novel contribution, it closely resembles the mixup data augmentation scheme introduced by (Zhang et al., 2018) and previously applied in the time series domain by (Wickstr\u00f8m et al., 2022).\n2. The method's evaluation is limited in scope, as it only compares against two pre-trained methods, one of which is closely related to the proposed approach. Notably, the paper overlooks significant baseline models such as TS2Vec (Yue et al., 2022), CoST (Woo et al., 2022a), and One Fits All (OFA) (Zhou et al., 2023)."
                },
                "questions": {
                    "value": "Is there any particular reason why some recent methods, like the ones described above, were not presented as baselines in the paper?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5599/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698880397260,
            "cdate": 1698880397260,
            "tmdate": 1699636577016,
            "mdate": 1699636577016,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "shw4qn0eYP",
                "forum": "25VG15SnkH",
                "replyto": "MNghIN1VGq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5599/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5599/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for reading our paper and pointing out its strengths and opportunities for improvement.\n\nWe are pleased to see you agree that the topic is highly relevant and exciting, that the paper is written clearly, and that you find the ablation studies sound. We further improved the presentation of the ablation study to make the results clearer to interpret and even more convincing (see Global Response 3). We answer your concerns next.\n\n> More recent baselines\n\nThank you for bringing this up. We have now added many more recent baselines in the revised manuscript for a fair comparison.\n\nIn particular, we follow your suggestion to compare with TS2Vec (Yue et al., 2022). However, we use different models than CoST (Woo et al., 2022a) and OFA (Zhou et al., 2023). The first is exclusively introduced as a forecasting model, whereas we focus on classification. The latter was released after the paper submission, and we therefore exclude it and will happily investigate it in future work. Instead, we first evaluated the already included TF-C (Zhang et al., 2022) and TS-TCC (Eldele et al., 2021) models on the UCR dataset, each across three seeds and with their respective ranks.\n\nGoing even further, *we added three other self-supervised time series pretraining models* that are typically used for classification. Namely, we compared to TS2Vec (Yue et al., 2022), TNC (Tonekaboni et al., 2020), and T-Loss (Franceschi et al., 2019). Please see the Global Response (2. part) for the table of results of XIT and the in total five baselines.\n\nWe can see that in light of this significantly extended comparison, our method performs favorably and further supports the necessity of our method.\n\n>  Novelty\n\nWe discussed this in general in the Global Response (1.). Specifically regarding your assessment, we want to point out that Sohn (2016) and Chen et al. (2020) laid the groundwork for a large family of different pertaining methods, of which XIT is indeed a member. This, however, makes it no less novel, especially given that soft alignments, as in SICC, are not typically used there.\n\nRegarding the novelty of XD-MixUp, we want to point out that we reference both the original mixup idea by (Zhang et al., 2022) and the work of  Wickstr\u00f8m et al. (2022) in section 2.1. To contextualize it further: XD-MixUp serves a very different purpose than the variant of MixUp in both publications. In the original one, it was introduced as a data augmentation and for soft labels in classification tasks. We, however, employ it to structure the (intermediate) latent space and effectively connect separated datasets into a coherent shared representation. Wickstr\u00f8m et al. (2022) proposed a completely separate learning approach with a different loss that promotes correctly predicting the mixing factor $\\lambda$. However, this does not explicitly structure the latent space and instead relies on its implicit effects. In the initial probings of our research, we did not find this approach to be working in the face of the more challenging multi-dataset setting we tackle.\n\nWe hope that we have clarified your concerns and that you can reconsider our rating. Do let us know if you have any further questions or comments."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5599/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700142844254,
                "cdate": 1700142844254,
                "tmdate": 1700143350211,
                "mdate": 1700143350211,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bpQ2NAHc92",
                "forum": "25VG15SnkH",
                "replyto": "MNghIN1VGq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5599/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5599/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking Forward to Feedback on Our Response"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nWe appreciate the time and effort that you have taken to provide us with your insightful review. We would like to ask if the reviewer has any further concerns or is satisfied by our responses to the original review.\n\nWe are looking forward to any further discussion with the reviewer and would like to thank the reviewer again for helping make our paper better.\n\nRegards,\nThe Authors"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5599/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700490219675,
                "cdate": 1700490219675,
                "tmdate": 1700490219675,
                "mdate": 1700490219675,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "pczOqSiNiy",
            "forum": "25VG15SnkH",
            "replyto": "25VG15SnkH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5599/Reviewer_KhAg"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5599/Reviewer_KhAg"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a new pretraining procedure for time-series datasets. It leverages two ideas in prior work, namely point wise MixUp and Temporal Contrastive loss. On top of these ideas the authors propose to adapt the sample contrastive loss from TS-TCC to take into account the sampled MixUp ratio. Experiments on common time series datasets show that the method outperforms the very related TS-TCC baseline. Moreover, additional experiments with multiple datasets show that there is an improvement the more datasets that are used and ablation studies on each component of the proposed method show that they contribute towards a better performance."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The idea is well presented and makes use of two methods that have shown to provide significant improvements in time-series modeling.\n\nThe paper has a thorough experimental setup with multiple datasets that are popular in this field. In addition, the authors perform multiple runs and report the standard deviation for all experiments."
                },
                "weaknesses": {
                    "value": "Given that this paper proposes a relatively small change in prior work the experimental results need to be strong and clearly show that this change provides an improvement over the baseline. However, for the first experiment which is the same setting as TS-TCC, the paper firstly reports a different metric and secondly significantly lower performance than the one reported in the TS-TCC paper. Moreover, table 1 reports AUROC significantly <0.5 for Epilepsy which is a binary classification problem.\n\nOne of the main premises of the paper is that this method allows pretraining on multiple datasets. It is that the experiment on the UCR datasets does provide some improvement when using more datasets for pretraining. However, the standard deviations are so high that it makes the result very minor. Moreover, there is no evidence provided that this would not apply to TS-TCC. On the contrary, in table 1 TS-TCC seems to improve with more datasets more often than XIT.\n\nFinally the standard deviation in the ablation study is so large that it makes it hard to draw conclusions regarding the benefit of the components of the method. For instance one could argue that MixUp and TC are as good as XIT."
                },
                "questions": {
                    "value": "What is the performance of XIT for table 1 using the same setting as TS-TCC for their table 2 and fig 3?\n\nHow can the area under the ROC curve for binary classification be ~0.2 on table 1 last column for TF-C?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5599/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699299791274,
            "cdate": 1699299791274,
            "tmdate": 1699636576929,
            "mdate": 1699636576929,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mlQUHseNaE",
                "forum": "25VG15SnkH",
                "replyto": "pczOqSiNiy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5599/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5599/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the extensive review and depicting the strong points as well as pointing out opportunities for improvement.\n \nYour raised points have greatly helped us to improve our manuscript. We address your concerns below.\n\n>  XIT only provides minor novelty over TS-TCC and MixUp.\n\nXIT's core encoder and TC module are derived from TS-TCC. We substitute its previous NT-Xent loss, integrating multiple runs of their TC loss. This configuration solely employs the cross-prediction task, presenting entirely novel inputs and outputs. Dismissing its novelty would be akin to disallowing the use of a Convolutional ResNet as a backbone in a new model. The underlying concept emphasizes the explicit need for both intra- and inter-dataset structuring tasks simultaneously.\n\nApplication of mixup on time series by Wickstr\u00f8m et al. (2022) is mainly a data augmentation method with the goal of learning a representation by predicting the mixing $\\lambda$. This is challenging for intra-dataset pretext tasks. For inter-dataset tasks, the model tends to learn to differentiate between datasets. We tackle this by ensuring that $\\lambda$ is not simply predicted but the latent space corresponds to the time domain in terms of mixing distance. This ensures that we can really leverage cross-dataset information. Our experimental evaluation shows that this intuition carries over into practice.\n\nIn initial probings, we did not see any meaningful effect by simply predicting the lambda as proposed by Wickstr\u00f8m et al. (2022).\n\n> The paper follows the same experimental setting as TF-C, however, reports a significantly lower performance and different metric than the reported one in the previous work.\n\nYes, in favor of greater comparability, we followed the experimental setup of TF-C as an initial experiment in Tab. 1. Furthermore, this experiment illustrates that TF-C exhibits unstable training, prone to worsening or erratic behavior with each new dataset, leading to unpredictable performance. In contrast, XIT demonstrates robustness, with minimal decreases and significant increases across all cases. TS-TCC performs adequately with 5 datasets but lacks robustness, exhibiting similar instability to TF-C when more data is leveraged. In datasets like ECG, consistent increases are observed across all models, yet XIT benefits the most.\nThis motivates our new scaling experiment, shown in Tab. 2 of the paper. A small excerpt is shown in the global response 2.\n\nWe ran our experiments on the provided open-source code of TS-TCC as well as TF-C. However, the scores provided in the paper were not just reproducible. Also, note that we padded the time series to equal lengths, which was not performed in the respective initial publications. Similar difficulties were observed in the very extensive survey by Ma et al. (2023), see Table 13. There, the claimed superiority of TS-TCC could not be confirmed. Sadly, our attempts to contact the authors of TF-C were not responded to.\n\n> Table 1 reports an AUROC significantly lower than 0.5 for Epilepsy, which is a binary classification problem.\n\nThis is indeed surprising, but not impossible. The model performs way worse than random guessing, which is the case when the model overfits on a single class, as an example. This is especially the case for imbalanced datasets.\n\n> The standard deviation of Table 2. is very high, which makes it hard to reason about the result.\n\nFor this, we provided novel experiments (See answer 2).\n\n>  Moreover, there is no evidence provided that this would not apply to TS-TCC and it even seems to improve with more datasets.\n\nWe provided more insights into the results of Tab. 1 in global answer 2. Furthermore, we ran additional experiments to show that TS-TCC does not scale to multiple datasets.\n\n>  Standard deviations in ablation\n\nThank you for pointing this out. We improved the presentation of the results to make it easier to interpret them.See Global Response 3.\n\n>  What is the performance of XIT for Table 1 using the same setting as TS-TCC for their table 2 and fig 3?\n\nOur method makes inherent use of multiple datasets (specifically, through XD-MixUp and SICC). In contrast, Table 2 in Eldele et al. (2021) is a homogenous one-to-one experiment, e.g., HAR to HAR, which is not applicable in our case. Furthermore, their experiments assume an abundance of data, where supervised learning excels. We therefore evaluate a more challenging task, namely many-to-one training, e.g., in Tab. 1 and 2.\n\nWe also report on the experiments of scaling dataset amounts (in our case, in the many-to-one setting) in the appendix Fig. 5. We went as low as forming a single batch was still possible. We can hereby confirm the intuitively convincing findings of TS-TCC that in the face of high finetuning data amounts, supervised learning becomes increasingly feasible.\n\nWe hope that we have clarified your concerns and that you can reconsider our rating. Do let us know if you have any further questions or comments."
                    },
                    "title": {
                        "value": "Comment by Authors"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5599/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700142792799,
                "cdate": 1700142792799,
                "tmdate": 1700143770450,
                "mdate": 1700143770450,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DZt7eNplen",
                "forum": "25VG15SnkH",
                "replyto": "pczOqSiNiy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5599/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5599/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking Forward to Feedback on Our Response"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nWe appreciate the time and effort that you have taken to provide us with your insightful review. We would like to ask if the reviewer has any further concerns or is satisfied by our responses to the original review.\n\nWe are looking forward to any further discussion with the reviewer and would like to thank the reviewer again for helping make our paper better.\n\nRegards,\nThe Authors"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5599/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700490173929,
                "cdate": 1700490173929,
                "tmdate": 1700490173929,
                "mdate": 1700490173929,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]