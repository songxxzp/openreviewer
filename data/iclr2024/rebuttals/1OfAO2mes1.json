[
    {
        "title": "Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized Scaled Prediction Consistency"
    },
    {
        "review": {
            "id": "Oyk5jPSlOL",
            "forum": "1OfAO2mes1",
            "replyto": "1OfAO2mes1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7677/Reviewer_nd7k"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7677/Reviewer_nd7k"
            ],
            "content": {
                "summary": {
                    "value": "MSPCThis paper proposed a backdoor data detection method called Mask-aware SPC (MSPC). It is inspired by existing work scaled prediction consistency (SPC). Based on the observation that SPC is not robust to the extreme pixel values (near 0 and 1), the proposed method uses a mask and hyperparameter to dynamically adjust the range. Based on the mask, MSPC proposes a bi-level optimization that can detect backdoor samples without the need to specify a threshold. The experiment results show the proposed method is effective in detecting several existing backdoor attacks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The motivation for adding masks and the linear shift $\\tau$ is well explained. It is an interesting observation for applying SPC on images. \n- Experiments are comprehensive and include most of the existing attacks; results demonstrated the proposed MSPC is effective in detecting them."
                },
                "weaknesses": {
                    "value": "- For condition P2: Free of Detection Threshold, MSPC is an optimized threshold selection method. The \"Free\" detection threshold seems ill-defined for the backdoor data detection method, which is essentially a binary classification. Essentially, MSPC still needs to use loss value as the score, except the threshold is optimized through Eq 5. \n- After relaxing the mask to continue values, Eq.4 is very similar to CD (Huang et al., 2023). It seems the difference is to replace the absolute difference with the KL divergence. It would be great to include the CD in the experiments for comparison, as well as recent works Meta-SIFT (Zeng et al., 2022) and ASSET (Pan et al., 2023).\n- The motivations based on insight 1/2 are constrained by the input bounded from 0 to 1. What happens to SPC if the input is not constrained to 0 to 1 or the input is normalized? \n- It has been observed in existing works such as SPECTRE (Hayase et al., 2021) that the detection method is sensitive towards the poisoning rate. It would be more comprehensive to include experiments with lower poisoning rates."
                },
                "questions": {
                    "value": "- Is it possible to incorporate Eq 5 with other detection methods, such as STRIP or ABL?\n- What if there are no backdoor samples? What is the FPR in this situation?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7677/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7677/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7677/Reviewer_nd7k"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7677/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697872406979,
            "cdate": 1697872406979,
            "tmdate": 1700693532562,
            "mdate": 1700693532562,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "buuung2Y4Y",
                "forum": "1OfAO2mes1",
                "replyto": "Oyk5jPSlOL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7677/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7677/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank you for your valuable time and comments. We will alleviate your concerns in this rebuttal as follows.\n\n> **The \"Free\" detection threshold seems ill-defined for the backdoor data detection method, which is essentially a binary classification.** \n\n\nWe'd like to highlight that the baseline methods propose determining this threshold either by utilizing a statistic from a subset of clean data distribution or by employing knowledge of the poisoning ratio or through heuristic methods.\n\nFor example, methods like SPECTRE and Spectral Signature assume the knowledge of some upper bound of the poisoning ratio. On the other hand, CD suggests calculating the threshold from the mean and standard deviation of a subset of clean samples. We provide the various existing thresholding methods in Table A1 in the Appendix.\n\nThus, we think that a backdoor data detection method (which assign scores to training data samples) cannot be trivial unsupervised binary clustering. For example, the scores (which are scalar values) may have multimodal distributions. \n\n> **Essentially, MSPC still needs to use loss value as the score, except the threshold is optimized through Eq 5.**\n\nWe would like to point out that the MSPC loss values are used as the score **only after the optimization of Eq. 5 is over**. This is in general not possible if the mask $\\mathbf m$ is not optimized. \n\nMoreover, the threshold is **not selected by users** - it is fixed at 0 (by definition) as given by Eq. 2. However, that threshold will not work if we do not have a good mask, which leads to our proposed bilevel formulation of Eq. 5. \n\n\n> **After relaxing the mask to continue values, Eq.4 is very similar to CD (Huang et al., 2023). It seems the difference is to replace the absolute difference with the KL divergence.**\n\n\nWe strongly disagree with this statement.\n\nFirstly, the mask in (Huang et al., 2023) represents the minimal mask that is responsible for the same prediction before and after applying the mask, while the mask in Eq.4 is responsible for maintaining the scaled prediction consistency signature. \n\nNotably, Eq.4 includes the variable $\\mathbf w$. Based on the fact that the scaled invariance property **is only true for backdoor samples**, Eq. 4 will work if we only consider the backdoor samples. This is the reason why $\\mathbf w$ is an important part of the equation and the bilevel formulation of Eq.5 is a natural consequence of moving towards finding that optimal $\\mathbf w$.\n\n\n\n> **It would be great to include the CD in the experiments for comparison, as well as recent works Meta-SIFT (Zeng et al., 2022) and ASSET (Pan et al., 2023).**\n\n\nWe include results with CD in the general response.\nHowever, we would like to emphasize that in light of the practical conditions (Section 1 and General response), these are not comparable. \n\nWe have highlighted the disadvantage of Meta-SIFT in this problem in Section 5.2 and Figure 5. \n\nIt should be noted that Meta-SIFT is developed to identify a small set of **clean samples from the dataset** (as explained in Section 1). To identify backdoor samples accurately, Meta-SIFT needs to identify all clean samples accurately. However, as shown in Fig. 5, it fails to do so (% of Clean Samples Selected = 100) because of the high NCR value. \n\nWe should also note that both Meta-SIFT and ASSET violate the practical conditions. \n\n\n\n> **What happens to SPC if the input is not constrained to 0 to 1 or the input is normalized?**\n\nWe provide the AUROCs obtained with SPC if the input is not constrained to 0 and 1. \n\n| Badnet         | Blend     |\n| -------------- | --------- |\n| 0.5028 (0.004) | 0.5 (0.0) |\n\nSPC completely fails in such a scenario.\n\n\n> **lower poisoning rates.**\n\n1. We have performed experiments with low poisoning rates ($\\gamma = 0.05$). We have provided these additional results in Appendix G (Fig A3, Table A3).\n2. Moreover, we point to the Adaptive Blend attack (Table 1, row 8). This attack was specifically designed to work with an extremely low poisoning rate ($\\gamma = 0.003$). Our method achieves an AUROC of 0.9046, where all other baselines fail."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7677/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700587016635,
                "cdate": 1700587016635,
                "tmdate": 1700587016635,
                "mdate": 1700587016635,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "N3snz8IUr5",
                "forum": "1OfAO2mes1",
                "replyto": "buuung2Y4Y",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7677/Reviewer_nd7k"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7677/Reviewer_nd7k"
                ],
                "content": {
                    "title": {
                        "value": "Response to the authors"
                    },
                    "comment": {
                        "value": "Thanks to the authors for the detailed response. The authors addressed my concerns and questions. I have read all reviews from other reviewers and the author's response. I agree with reviewer wHYC that automatic filtering is a good contribution. \n\nThe proposed MSPC incorporates the idea of the mask used in CD with SPC loss (e.g. replace the same output to scaled prediction consistency signature). This seems to limit its novelty. However, considering the contribution of automatic filtering and solving the limitations of pixel scales in SPC, the reviewer believes the merit outweighs the weaknesses. As a result, I will increase my score to 6."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7677/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700692347505,
                "cdate": 1700692347505,
                "tmdate": 1700692347505,
                "mdate": 1700692347505,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RE66AAZKBs",
                "forum": "1OfAO2mes1",
                "replyto": "Oyk5jPSlOL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7677/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7677/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you."
                    },
                    "comment": {
                        "value": "Dear Reviewer nd7k, \n\nThank you very much for the careful review and the valuable comments. It is our great pleasure to learn that your concerns have been addressed and the rating is increased. We will try our best to further improve our paper based on your suggestion.\n\nThank you very much,\n\nAuthors"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7677/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700694964662,
                "cdate": 1700694964662,
                "tmdate": 1700695367066,
                "mdate": 1700695367066,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "33FXBsndqx",
            "forum": "1OfAO2mes1",
            "replyto": "1OfAO2mes1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7677/Reviewer_wHYC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7677/Reviewer_wHYC"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes an optimization framework to improve an existing backdoor sample detecting method Scaled Prediction Consistency (SPC). It identifies two limitations of SPC, in terms of the unusual SPC values of backdoor vs. clean samples. It addresses the limitations of SPC by introducing a pre-shift and a learnable mask into SPC, and proposes to use a bilevel optimization framework to first find a small mask and then only scale up the masked region of the image. The new loss function is named Mask-aware SPC (MSPC).  The way to find the minimal mask is similar to the Cognitive Distillation method introduced in (Huang et al. 2023), which should be able to accurately locate the backdoor trigger position. With the learned mask and scaling factor $n$, the authors further propose to automatically identify the backdoored samples from a training dataset with the help of binary variable $w_i$ ($w=1$ for backdoored sample whilst $w=0$  for clean sample). Eventually, if the MSPC loss is >0, then $w_i$ should be 1 to minimize the overall loss $(1-w_i)\\cdot L_{MSPC}$. I.e., counting samples with non-negative MSPC loss or $w_i=1$ yields the final backdoor samples. Experiments with 8 backdoor attacks on three datasets demonstrate the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The proposed method addresses the limitations of an existing work SPC;\n\n2. The experimental results are promising;\n\n3. The method can automatically differentiate backdoor from clean samples via the bilevel optimization framework."
                },
                "weaknesses": {
                    "value": "1. The paper is poorly written, it takes the reviewer to read many times to get the core idea. The relationship to existing works SPC and Cognitive Distillation (CD) should be accurately summarized and discussed. The fundamental/technical difference should be clearly explained.\n\n2. At the beginning of Section 4, it explains why SPC fails the two cases. Yet this was not systematically or quantitatively analyzed. Those are just conjectures.\n\n3. The key technical novelty is the introduction of a learnable mask into the MSPC loss, however, the technique is very similar to an existing backdoor detection method proposed by (Huang et al. 2023). \n\n4. The automatic filtering variable $w_i$ seems unnecessary, as at the end of Section 4, the authors stated that \"backdoor samples will simply be the ones with MSPC loss greater than 0\".\n\n5. The two proposed practical conditions: 1) free of clean data; and 2) free of detection threshold, look both ok to me. Many defense works assume the availability of a small subset of clean samples, which is quite practical in real-world scenarios. The reviewer understands it is nice to satisfy both conditions but does not think this makes the proposed method fundamentally superior to other detection methods. For condition 2, if all training samples with MSPC loss greater than 0 should be removed, the detector will remove many clean samples when the dataset is extremely clean or dirty (extremely low/high poisoning rates). \n\n6. Strong adaptive attacks should know the mask, it then can adapt itself to have low MSPC loss with multiple surrogate models rather than one, in case to overfit the current model as it did in the \"Resistance against Potential Adaptive Attacks.\" experiments. In other words, generating strong poisons should also be done in a bilevel manner.\n\n7. In Table 1, the detection performance shown on CIFAR-10 is worse than that reported in the Cognitive Distillation (CD) paper (Huang et al. 2023) (their AUC is above 90%), and the results on test (and poisoned) samples should also be reported.   This means the use of CD in the proposed way actually hurts the detection performance, which may be caused by the automatic search process with $w_i$ and the SPC loss."
                },
                "questions": {
                    "value": "See weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No Ethics Concerns."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7677/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7677/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7677/Reviewer_wHYC"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7677/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698746991621,
            "cdate": 1698746991621,
            "tmdate": 1700662019330,
            "mdate": 1700662019330,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "F5fhVIsQ8N",
                "forum": "1OfAO2mes1",
                "replyto": "33FXBsndqx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7677/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7677/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank you for your valuable time and comments. We will alleviate your concerns in this rebuttal as follows.\n\n> **The paper is poorly written, it takes the reviewer to read many times to get the core idea.**\n\nThank you for this feedback. We respectfully disagree. We have made a substantial effort to improve the presentation of the paper, including clarifying practical assumptions, providing more illustrative examples, and illustrating the rationals behind our proposal.  However, we are always eager to learn and would greatly appreciate any specific suggestions you might have on how we can enhance our writing. \n\nAdditionally, we would like to gently mention that Reviewer YD42 and Reviewer V1zd have commended our paper for being well-written and easy to follow.\n\n\n> **key technical novelty is the introduction of a learnable mask into the MSPC loss**\n\nWe would like to point out that the **we introduce the MSPC loss**. So the key technical novelty are: \n1. Introduction of the MSPC loss (Eq 2)\n2. Development of the bilevel formulation (Eq 5), which finds the optimal mask and automatically identifies backdoor datapoints.\n**We also highlight our overall contributions at the end of Section 1.**\n\n> **the technique is very similar to an existing backdoor detection method proposed by (Huang et al. 2023).**\n\nWe would strongly disagree with this statement.\n\nWe would like to point out that the only similarity with (Huang et al. 2023) is that we also penalize the l1 norm of the mask. \n\nAs mentioned before, our key technical contributions are the introduction of the novel MSPC loss and the novel bilevel formulation. This also helps us in satisfying P1 and P2, whereas (Huang et al. 2023) assumes the presence of clean data for identifying backdoor datapoints (thus violating P1).\n\n\n> **The automatic filtering variable  seems unnecessary, as at the end of Section 4, the authors stated that \"backdoor samples will simply be the ones with MSPC loss greater than 0\".**\n\nWe would emphasize that the statement \"backdoor samples will simply be the ones with MSPC loss greater than 0\" is only true **after** the optimization of Eq 5 is complete. \n\nWe introduce the automatic filtering problem as a bilevel problem in Eq. 3, which contains the variable $\\mathbf w$. Without this variable, it would be impossible to formulate our problem as a bilevel optimization. \n\n> **The reviewer understands it is nice to satisfy both conditions but does not think this makes the proposed method fundamentally superior to other detection methods.**\n\nWe elucidate the importance of the practical conditions in the General response. \nGiven the existence of scenarios where it can be difficult / impossible to collect clean data, we believe that algorithms satisfying P1 and P2 will be favourable to practitioners. \n\n\n> **In Table 1, the detection performance shown on CIFAR-10 is worse than that reported in the Cognitive Distillation (CD) paper (Huang et al. 2023) (their AUC is above 90%), and the results on test (and poisoned) samples should also be reported.** \n\n\n1. We would like to point out that our AUROC for CIFAR-10 is also more than 90% for all attacks other than DFST. \n2. We aim to identify backdoor datapoints from the *training set*. If identified correctly, the user can either remove those backdoor data or unlearn them (as mentioned in 'Model Retraining Effect.' in Section 5.2). \n\n\n> **This means the use of CD in the proposed way actually hurts the detection performance, which may be caused by the automatic search process with  and the SPC loss.**\n\nFirstly, we would like to emphasize that we **do not** use CD. Our contributions include introduction of the MSPC loss (Eq 2) and development of the bilevel formulation (Eq 5).\n\nWe added experiments using CD in our general response and compared its performance with ours. We would like to highlight the following points:\n1. CD performs well in cifar10. However, **CD fails completely for the recently introduced attack Adaptive Blend**. However, our method maintains an AUROC > 90% for this attack.\n2. Our method performs **better than CD in all attacks for both TinyImagenet and Imagenet200**. \n3. Most importantly, CD violates P1 from our practical conditions. Backed by our discussion of practical conditions (Section 1, Table 1 and General Response), we emphasize the fact that we cannot compare CD and our method fairly because CD uses clean data to find the threshold but ours do not."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7677/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700586924263,
                "cdate": 1700586924263,
                "tmdate": 1700586924263,
                "mdate": 1700586924263,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gspEr40DX7",
                "forum": "1OfAO2mes1",
                "replyto": "F5fhVIsQ8N",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7677/Reviewer_wHYC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7677/Reviewer_wHYC"
                ],
                "content": {
                    "title": {
                        "value": "Response to the authors"
                    },
                    "comment": {
                        "value": "Thanks to the authors for the detailed response. Although I realized certain misunderstandings of the proposed idea with the clarifications, the authors are still encouraged to make the idea clearer at the beginning of the paper. E.g., without sufficient reasoning, it is hard to accept the two conditions but rather to believe they are tricks to avoid comparison to existing works. I.e., automatic filtering can be made into an independent process on top of any detection methods. But I agree with the authors that having an automatic detection method free of hyperparameters can be a good contribution to the community. Considering the MSPC loss is prosed in this work, I am ok to increase my rating."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7677/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700661938683,
                "cdate": 1700661938683,
                "tmdate": 1700661938683,
                "mdate": 1700661938683,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VJBbquparr",
                "forum": "1OfAO2mes1",
                "replyto": "33FXBsndqx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7677/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7677/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "Dear Reviewer wHYC,\n\nThank you very much for the careful review and the valuable comments. It is our great pleasure to learn that your concerns have been addressed and the rating is increased.  We are happy to know that you consider our proposed automated detection is a good contribution. We will try our best to further improve our paper based on your suggestion.\n\nThank you very much,\n\nAuthors"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7677/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700695138163,
                "cdate": 1700695138163,
                "tmdate": 1700695500504,
                "mdate": 1700695500504,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "iU4kSrOEJc",
            "forum": "1OfAO2mes1",
            "replyto": "1OfAO2mes1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7677/Reviewer_V1zd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7677/Reviewer_V1zd"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a method for backdoor detection that identifies poisoned samples based on prediction invariance after scaling. The method designed a new bi-level optimization-based approach to improve the performance of the existing SPC method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The manuscript is well-organized and straightforward, facilitating easy comprehension.\n- The empirical results are compelling and substantiate the paper's claims effectively.\n- I had previously reviewed this work for an earlier conference. Given the improvements the authors have made\u2014specifically, the expansion of datasets and attack baselines\u2014I am inclined to give it a \u201cmarginally above the acceptance threshold\u201d."
                },
                "weaknesses": {
                    "value": "- Despite some improvements in this submission, my primary concern remains: the core idea behind the proposed method is still closely aligned with the existing Scaled Prediction Consistency (SPC) approach, limiting the paper's technical novelty and contribution.\n- Extending the experiments to include more diverse model architectures, such as attention-based ViT, would bolster the robustness of the findings. Currently, only one model architecture (ResNet-18) is used for experimental evaluation."
                },
                "questions": {
                    "value": "No further questions at this time."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7677/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698749555636,
            "cdate": 1698749555636,
            "tmdate": 1699636933934,
            "mdate": 1699636933934,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2x93HNx33k",
                "forum": "1OfAO2mes1",
                "replyto": "iU4kSrOEJc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7677/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7677/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank you for your valuable time and positive feedback. We will alleviate your concerns in this rebuttal as follows.\n\n> **closely aligned with the existing Scaled Prediction Consistency (SPC) approach**\n\nWe would like to argue that our work leverages this signature and provides a non-trivial algorithm to identify backdoor data samples without any additional assumptions as discussed in Section 1 , Table 1, General Response.\n\n1. Our proposed algorithm shows massive amounts of improvements over SPC across a variety of attacks as shown in Table 1. \n2. We argue that our work propose in a novel algorithm that can identify backdoor data obeying the practical conditions, while SPC is incapable of doing so.\n\n\n\n> **Extending the experiments to include more diverse model architectures, such as attention-based ViT**\n\n\nWe have included results with ViT-Ti/16 [1] in the general response. As shown in the results, our method achieves similar AUROC values (sometimes better) when compared to Resnet18. This demonstrates the robustness of our method across different architectures. \n\n\n1. Touvron, Hugo, et al. \"Training data-efficient image transformers & distillation through attention.\" International conference on machine learning. PMLR, 2021."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7677/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700586372322,
                "cdate": 1700586372322,
                "tmdate": 1700586372322,
                "mdate": 1700586372322,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4dmOdBDH3v",
                "forum": "1OfAO2mes1",
                "replyto": "2x93HNx33k",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7677/Reviewer_V1zd"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7677/Reviewer_V1zd"
                ],
                "content": {
                    "title": {
                        "value": "Reply to authors"
                    },
                    "comment": {
                        "value": "Thank the authors for their response. Although I have doubts about the novelty and technical contribution of this work, considering the improvement in effectiveness, I am slightly inclined to accept this paper."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7677/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700653031692,
                "cdate": 1700653031692,
                "tmdate": 1700653031692,
                "mdate": 1700653031692,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hTrlhWPUy8",
            "forum": "1OfAO2mes1",
            "replyto": "1OfAO2mes1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7677/Reviewer_YD42"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7677/Reviewer_YD42"
            ],
            "content": {
                "summary": {
                    "value": "This study focuses on automatically detecting backdoor data in poisoned machine learning datasets, without requiring clean data or predefined thresholds. It leverages the scaled prediction consistency (SPC) technique, introducing a unique SPC-based loss function for precise identification. This research addresses limitations in the traditional SPC method and develops a bi-level optimization approach for accurate backdoor data detection. The proposed method is evaluated on several datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The problem of backdoor sample identification is of sufficient interests for the community.\n2. The paper is well-written and easy to follow."
                },
                "weaknesses": {
                    "value": "1. Regarding the AUROC performance, where a comprehensive threshold iteration is conducted, the proposed method exhibits only marginal improvements over the STRIP method. Notably, in the case of CIFAR-10, the proposed method significantly outperforms the STRIP method solely under the AdapBlend (\u03b3 = 0.3%) condition. Surprisingly, in the context of Tiny ImageNet, the STRIP method even surpasses the proposed method.\n2. Could you provide a runtime analysis of the algorithms employed to solve the bi-level optimization problem? Additionally, it would be valuable to understand the optimization process for the discrete variable w?\n3. While it is acknowledged that running the STRIP method on ImageNet 200 presents time complexity challenges, I would like to point out that this method does not appear to encounter runtime issues comparable to your proposed methods, which require solving a discrete bi-level optimization problem. In the STRIP method, the procedure only involves *superimposing two images and forwarding them to the backdoored model to obtain the outputs*.\n\nIn light of the aforementioned observations, it appears that the proposed method does not introduce significant advantages, either in terms of computational complexity or performance enhancement, when compared to the STRIP method. Consequently, I recommend rejection."
                },
                "questions": {
                    "value": "Please see my comments above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7677/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698784974447,
            "cdate": 1698784974447,
            "tmdate": 1699636933822,
            "mdate": 1699636933822,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VbnBZjnmPA",
                "forum": "1OfAO2mes1",
                "replyto": "hTrlhWPUy8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7677/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7677/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank you for your valuable time and comments. We will alleviate your concerns in this rebuttal as follows.\n\n> **Notably, in the case of CIFAR-10, the proposed method significantly outperforms the STRIP method solely under the AdapBlend (\u03b3 = 0.3%) condition. Surprisingly, in the context of Tiny ImageNet, the STRIP method even surpasses the proposed method.**\n\nWe would like to point out that this is in fact **incorrect**.\n1. Our method surpasses STRIP in both Wanet and AdapBlend for CIFAR-10. Notably, STRIP completely fails in AdapBlend (AUROC = 0.1378). \n2. In Tinyimagenet, our method is better than STRIP for both Badnet and Wanet.\n3. For Imagenet200, our method outperforms STRIP on average (as given in the general response).  STRIP's performance considerably suffers for Badnet attack on Imagenet when compared to our method.\n\n> **Could you provide a runtime analysis of the algorithms employed to solve the bi-level optimization problem?**\n\nWe provide runtime (in mins) for our algorithm for different datasets.\n\nWe would like to point out that our runtime is dependant on the number of epochs we perform for solving the inner optimization (Epoch_in) and the number of overall epochs (Epoch_out) for solving the bilevel optimization. \n\nWe present the time and AUROC values for Badnet attack for different datasets and different configurations of numbers of epochs. We find that our method maintains high AUROC values across various configurations of epoch numbers.\n\n\n\n| Dataset      | Epoch_in | Epoch_out | AUROC           | Time (mins) |\n| ------------ | -------- | --------- | --------------- | ----------- |\n| TinyImagenet | 5        | 4         | 0.9983 (0.0004) | 147         |\n| TinyImagenet | 2        | 2         | 0.9998 (0.0006) | 37.2        |\n| Imagenet200  | 5        | 4         | 0.9980 (0.0004) | 164.71      |\n| Imagenet200  | 2        | 2         | 0.9977 (0.0005) | 40.9        |\n| cifar10      | 10       | 2         | 0.9514 (0.0043) | 35.64       |\n| cifar10      | 2        | 2         | 0.9562 (0.006)  | 4.8         |\n\n\n\n> **STRIP runtime**\n\nWe have included new results for STRIP with the Imagenet200 dataset (given in the general response). For comparison, this takes about 70 minutes. \n\n\n> **proposed method does not introduce significant advantages, either in terms of computational complexity or performance enhancement, when compared to the STRIP method.**\n\nWe strongly disagree with this statement. We introduce two key innovations: \n1. Introduction of the MSPC loss (Eq 2)\n2. Development of the bilevel formulation (Eq 5), which finds the optimal mask and automatically identifies backdoor datapoints.\n\n**We also highlight our overall contributions at the end of Section 1.**\n\nWe are not claiming advantages of computation complexity nor massive performance gains. As explained in Section 1 , Table 1 and in our general response, our method satisfies the practical constraints which other baseline methods do not. Even while doing so, *our  approach often outperforms or performs at par with baseline methods (which do not satisfy the practical constraints)*."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7677/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700586311645,
                "cdate": 1700586311645,
                "tmdate": 1700586311645,
                "mdate": 1700586311645,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SbuQX9PNzv",
                "forum": "1OfAO2mes1",
                "replyto": "VbnBZjnmPA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7677/Reviewer_YD42"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7677/Reviewer_YD42"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the authors' rebuttal; further questions"
                    },
                    "comment": {
                        "value": "I would like to thank for the authors' respones for my comments as well as additional experiments. \n\nIn simple terms, I think the two assumptions the literature relies on are okay, as pointed out by others too. So what I'm really looking at is how well it performs and the computational side of things. When it comes to performance and computational aspects, I have doubts about some of the claims made by the authors\u2014they're not very exact, especially without proper statistical backing.\n\n\n- I would like to first respond certain points in response for the authors' reply:\n\n\n> 'In Tinyimagenet, our method is better than STRIP for both Badnet and Wanet.'\n\nThis may not hold true. Looking at the means and stds reported for Badnet and Wanet in Table 2, your statement might not have statistical significance. To illustrate, if you conduct independent experiments ten times and run a t-test with a set significance level of 0.05, you won't be able to reject the null hypothesis. This result indicates that there's no statistically significant difference between the AUROC means of your method and STRIP, making your assertion invalid.\n\nCould you kindly share the number of independent runs for further clarification?\n\n\n> `Our method surpasses STRIP in both Wanet and AdapBlend for CIFAR-10. Notably, STRIP completely fails in AdapBlend (AUROC = 0.1378).'\n\nWhile it's true that your approach performs better than STRIP Wanet and AdapBlend for CIFAR-10, your Table 2 indicates that the STRIP method surpasses your approach in five other attacks (Blend, LC, TUAP, Trojan, and DFST). Although your method currently shows higher averaged scores than STRIP, this is primarily due to AdapBlend's failure case. When considering a broader range of attacks, it's not necessarily guaranteed that your method will outperform STRIP in terms of overall performance.\n\nMoreover, in terms of failure cases, your method can also falter under the DFST attack. Hence, at least from an effectiveness standpoint, your method doesn't seem superior to STRIP. I acknowledge that your method is built on less stringent assumptions, but for a more accurate interpretation of your results, it's crucial to articulate your claims precisely and rigorously.\n\n\n- I have additional inquiries. Could you provide the training loss curve for your optimization procedure? I am concerned that your choice of both inner and outer rounds is relatively small, which may lead to insufficient convergence of the training loss. Consequently, it seems that your method may still face a substantial computational burden.\n\nIf the authors can address my concerns above, I will raise my score."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7677/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700664918839,
                "cdate": 1700664918839,
                "tmdate": 1700664918839,
                "mdate": 1700664918839,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YuoCWLHEB4",
                "forum": "1OfAO2mes1",
                "replyto": "hTrlhWPUy8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7677/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7677/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their reply and valuable comments. We hope to alleviate the additional concerns in this rebuttal.\n\n\n> **Looking at the means and stds reported for Badnet and Wanet in Table 2, your statement might not have statistical significance.** \n> \n> **Could you kindly share the number of independent runs for further clarification?**\n\nThank you very much for the suggestion. Currently, our results are obtained over 3 independent runs. Encouraged by the comments, we conducted 2 more runs and performed a Welch's one-tailed t-test between the AUROC values of Badnet and Wanet. Our results have a significance level of 0.08 and 0.06 (<0.1) for these attacks in Tinyimagenet, respectively. \n\nWe will confirm this significance result with 10 independent runs later and can update it upon the reviewer's request.\n\n\n> **Hence, at least from an effectiveness standpoint, your method doesn't seem superior to STRIP. I acknowledge that your method is built on less stringent assumptions, but for a more accurate interpretation of your results, it's crucial to articulate your claims precisely and rigorously.**\n\n\nThank you for this suggestion. We want to clarify that we did **not** intend to assert any advantages in terms of computational efficiency or promise absolute massive performance gains. As the reviewer pointed out, \"I acknowledge that your method is built on less stringent assumptions,\" and as we explained in Section 1, our achieved performance, which is on par with or potentially outperforming baseline methods, is contingent upon practical conditions. It's important to note that the baseline methods may not necessarily meet these same conditions. In this context, it holds particular significance for us because our method, which relies on fewer assumptions, manages to achieve highly competitive performance.\n\n \n\n**About STRIP**: \nPlease allow us to make further clarifications on this matter. \nThe AUROC (Area Under the Receiver Operating Characteristic) is determined by calculating the area under the curve of the True Positive Rate (TPR) and False Positive Rate (FPR) across various detection thresholds. Consequently, when employing a backdoor identification method, it is not necessary to find a precise detection threshold for AUROC computation\n\n\nThe STRIP work suggests to find this detection boundary **using the mean and variance of the entropy distribution of clean samples**. In contrast, our method can automatically detect the backdoor samples without the necessity of clean samples.\n\nTherefore, the computation of AUROC values for STRIP does not require detection boundary computation. Consequently, in scenarios where clean samples are absent, this limitation does not manifest in the AUROC values, as they are computed by directly utilizing the entropy values of all samples.\n\nConsidering the fact that AUROC offers a limited representation of the overall problem, we posit that relying solely on this performance metric may not be a comprehensive measure of the success of our method. We appreciate your consideration of these points.\n\n\n\n\n\n\n\n> **Could you provide the training loss curve for your optimization procedure? I am concerned that your choice of both inner and outer rounds is relatively small, which may lead to insufficient convergence of the training loss.** \n\nThank you for raising this question. We consider 2 epochs of outer optimization and 2 epochs of inner optimization. \n\nWe present the masking loss convergence curve for CIFAR10 in this [Figure](https://ibb.co/QNVNTH6) and in this [Figure](https://ibb.co/QPNYZV2) for TinyImagenet. For CIFAR10, each epoch contains 50 iterations, resulting in a total of 200 iterations, while for TinyImagenet, there are a total of 400 iterations because of 100 iterations per epoch.\nWe will present similar loss curves for Imagenet200 soon, if needed."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7677/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700704272355,
                "cdate": 1700704272355,
                "tmdate": 1700719548857,
                "mdate": 1700719548857,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]