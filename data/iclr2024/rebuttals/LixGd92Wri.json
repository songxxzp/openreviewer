[
    {
        "title": "GDL-DS: A Benchmark for Geometric Deep Learning under Distribution Shifts"
    },
    {
        "review": {
            "id": "cIXT8a6UDZ",
            "forum": "LixGd92Wri",
            "replyto": "LixGd92Wri",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7496/Reviewer_1MFG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7496/Reviewer_1MFG"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses the challenge of distribution shifts in Geometric Deep Learning (GDL), a topic that has seen limited research focus despite GDL's prominence in various scientific applications. The authors introduce GDL-DS, a comprehensive benchmark designed to evaluate the performance of GDL models across scenarios that encounter distribution shifts. They provide a comprehensive evolution on several datasets from different fields; particle physics, materials science, and biochemistry, and categorize distribution shifts into three types: conditional, covariate, and concept shifts. Furthermore, they explore three levels of out-of-distribution (OOD) information access and evaluate multiple GDL backbones and learning algorithms. The benchmark consists of 30 experiment settings, and the findings provide valuable insights for researchers and practitioners in the GDL domain."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- The paper presents a comprehensive benchmark for GDL models, covering a spectrum of scientific domains and distribution shifts. Such a benchmark fills an existing gap in the literature.\n\n- The authors leverage the causality inherent in scientific applications to classify distribution shifts into conditional, covariate, and concept shifts, providing a clearer understanding of the challenges faced.\n\n- By exploring three distinct levels of OOD information, the paper offers a nuanced understanding of the impact of OOD data on model performance, addressing disparities in previous works.\n\n- The paper conducts a myriad of experiments, with 30 different settings, evaluating various GDL backbones and learning algorithms, ensuring a robust and holistic evaluation.\n\n- The results yield key takeaways that can guide the selection of practical solutions based on the availability of OOD data, serving as a valuable resource for researchers and practitioners."
                },
                "weaknesses": {
                    "value": "Given the disparities in previous benchmarking studies across various domains,, there's a compelling case to expand this benchmark study to encompass both CV and NLP tasks to provide a holistic and unified perspective on performances across diverse tasks."
                },
                "questions": {
                    "value": "- How do the findings of this study compare with earlier research on CV and NLP tasks concerning distribution shifts?\n\n- What is the rationale behind the choice of the considered GL backbones? Would incorporating more diverse GDL backbones or learning algorithms significantly alter the conclusions drawn from this study?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7496/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698610601172,
            "cdate": 1698610601172,
            "tmdate": 1699636905033,
            "mdate": 1699636905033,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AdI3F4nbF8",
                "forum": "LixGd92Wri",
                "replyto": "cIXT8a6UDZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7496/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7496/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We express our sincere gratitude to reviewer 1MFG for reviewing our paper, appreciating our work and raising valuable comments.  We address your questions as follows.\n\n  **1). How do the findings of this study compare with earlier research on CV and NLP tasks concerning distribution shifts?**\n\nFirstly, we\u2019d like to appreciate earlier OOD works on CV and NLP tasks, many of which have shed valuable insights into our research. We have meticulously connected our multiple conclusions with the existing OOD work in CV and NLP and put details in the appendix. The details are as follows.\n\n- In Sec. 4.2, we observe that fine-tuning can sometimes result in negative effects when the labeled OOD data is quite limited. **This is consistent with catastrophic forgetting in [1]. To mitigate this issue, the strategy of surgical fine-tuning raised in [2]** is a potential solution for this problem.\n\n- In Sec. 4.2, we observe that multiple OOD generalization methods in our No-Info level find it hard to provide significant improvement across various applications. We can find **similar observations in existing CV/NLP works, including [3], [4]**. Actually, this could be even **more severe in GDL compared to CV tasks**, considering the intricate nature of irregularity and geometric prior (information on the structure space and symmetry properties like invariance or equivariance) inherent in geometric data.   \n\n- In Sec. 4.3, we conclude that \u201cFor the OOD generalization methods to learn robust representations, the more informatively the groups obtained by splitting the source domain $S$ indicate the distribution shift, the better performance these methods may achieve.\u201d This is **consistent with previous CV works like [5]**, which revealed the importance of appropriate subgroup partitioning for invariant learning. And we note that **[6] proposed to leverage** additional auxiliary variables for enhancing OOD generalization. This may also shed insights into future research on scientific GDL. \n\nMoreover, certain shifts in scientific GDL are different from common shifts in CV/NLP, which leads to challenges when addressing these shifts with methods initially proposed for CV/NLP tasks. Here are some examples in our work:\n\n- Shifts related to graph/geometric structure: For instance, the I-conditional shift can be interpreted as a size shift (the number of nodes in data), where the model trained in data with smaller sizes is to generalize to data with larger sizes. We observed that the methods designed for CV struggle to perform well. In addition, the features in GDL additionally incorporate the geometric structure. The methods in CV work on feature representations without explicitly handling the change in geometric structure, which may result in suboptimal solutions. \n\n- Fidelity shift, which indicates the change of causal correlation between $X_c$ and Y, corresponds to a significant challenge in material property prediction. However, we rarely encounter the shift in the causal relationship in CV, so most methods in our benchmark find it hard to handle such a shift, except the pertaining-finetuning strategy. \n\nThe above two points of **difference indicate the necessity to develop OOD methods specifically designed for GDL**.\nOverall, We thank the reviewer\u2019s suggestion and the comparisons made above would enhance the connection between our findings with earlier research in CV/NLP domains and shed more insights for future research.\n\n[1] Kirkpatrick, James, et al. \"Overcoming catastrophic forgetting in neural networks.\" Proceedings of the national academy of sciences 114.13 (2017): 3521-3526.\n\n[2] Lee, Yoonho, et al. \"Surgical Fine-Tuning Improves Adaptation to Distribution Shifts.\" ICLR, 2022.\n\n[3] Gulrajani, Ishaan, and David Lopez-Paz. \"In Search of Lost Domain Generalization.\" ICLR, 2020.\n\n[4] Koh, Pang Wei, et al. \"Wilds: A benchmark of in-the-wild distribution shifts.\" ICML, 2021.\n\n[5] Creager, Elliot, J\u00f6rn-Henrik Jacobsen, and Richard Zemel. \"Environment inference for invariant learning.\" ICML, 2021.\n\n[6] Lin, Yong, et al. \"ZIN: When and How to Learn Invariance Without Environment Partition?.\" NeurIPS, 2022."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7496/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700254839855,
                "cdate": 1700254839855,
                "tmdate": 1700254839855,
                "mdate": 1700254839855,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CG9IasjcxL",
                "forum": "LixGd92Wri",
                "replyto": "rqlkUGi7Mu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7496/Reviewer_1MFG"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7496/Reviewer_1MFG"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks to the authors for their comprehensive and detailed response to the concerns I raised. Following a thoughtful review of your response, I have concluded to keep my initial score unchanged. Your efforts in addressing these issues are greatly appreciated and have contributed meaningfully to the review process."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7496/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700694143633,
                "cdate": 1700694143633,
                "tmdate": 1700694143633,
                "mdate": 1700694143633,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "kk9yVY0MEx",
            "forum": "LixGd92Wri",
            "replyto": "LixGd92Wri",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7496/Reviewer_GGxS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7496/Reviewer_GGxS"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a OOD benchmark for geometric deep learning in science. The authors curate datasets from 3 scientific domains, identify several shifts in each dataset, and conduct 3 OOD splits for each shift. Then each setting is used to evaluate 3 GDL backbones and several OOD methods."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper focuses a a very compelling topic. OOD datasets and benchmarks for geometric deep learning in science are innovative and meaningful research.\n\n2. The paper presentation includes rich contents, with tables and figures well organized.\n\n3. The selected data presents practical tasks. The conducted experiments look correct and sufficient experimental analyses are given."
                },
                "weaknesses": {
                    "value": "1. The use of critical terms should be better considered. Concept drift is a well-established term in the study of causality and distribution shift. As defined in [1], which the authors also cited, the only constraint for concept drift is \"changes in $p(y|X)$\". To avoid any confusions to readers, this conventional definition should be followed without modifications like $P(Y|X_c)$. Similarly for the definition of covariate shift. If the authors attempt to define a more specific kind of shift, another term should be used.\n\n2. The causal statements are problematic.\n    - The statement that $X$ consists of two disjoint parts and $X_i \u22a5Y |X_c$ does not hold. A easy violation would be $X_c \u2192Y \u2192X_i$. Intrinsically, $Y$ is often a property of the input and therefore $X$ cannot be divided into two disjoint parts that are causal/independent, but there would exist a part of $X$ that is statistically associated with $Y$ while non-causal to $Y$. A classic example is the PIIF and FIIF causal modeling, such as the analysis in [2].\n    - Following the above point, even for $X \u2192 Y$, $P(Y|X)P(X) = P(Y|X_c)P(X)$ does not hold. For $X \u2192 Y$, there can be a case where $P_S(Y |X_i)\\neq P_T (Y |X_i)$, which will also result in a \"conditional shift\". It is also included by the definition of concept shift. Constraining $Y \u2192 X$ does not seem like a necessity for conditional shift.\n    - Overall, as the foundation of the whole paper, 3.1 appears to be logically unclear and farraginous and needs major corrections.\n\n3. Contribution overclaimed and related works not well addressed. In the comparison with existing benchmarks, the authors claim no existing OOD benchmarks consider conditional shift, which is not true. OoD-Bench, GDS, and GOOD all include the Cmnist dataset, which is clearly conditional shift. GOOD also constructed conditional shift for each dataset. Also, though benchmarks like WILDS do not use test labeled/unlabeled data for algorithm learning, these OOD info are available. Therefore, Table 1 gas multiple overclaiming issues, and the authors should treat existing works properly.\n\n4. Experimental setting not fair. Some methods are trained solely on the Train-ID dataset, while DA algorithms are trained on both Train-ID and OOD input data, and TLs also learn labeled Train-OOD data. This does not seem like a fair setting since different methods are trained on even different numbers of data samples. Given that the analyses are conducted based on comparing all these methods together, a fair evaluation setting is certainly needed.\n\n5. Baselines out-of-date. These years many new OOD methods including new sota have been proposed. The benchmark should include more recent methods as baselines. For learning algorithms the sota methods on the Wilds leaderboard should be considered. For graph OOD methods, many recent methods can easily outperform DIR. Also, geometric methods specifically developed for scientific tasks should be considered.\n\n6. The benchmark includes only 3 datasets. Though more than one shift is identified for each dataset, this number seems a bit few for a benchmark. Given that the datasets are not newly collected, possibly more discussions on contributions like curating 3D coordinate can make up for the overall contribution.\n\n\n[1] A survey on concept drift adaptation\n\n[2] Invariant risk minimization"
                },
                "questions": {
                    "value": "See Weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Legal compliance (e.g., GDPR, copyright, terms of use)"
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "The license for each dataset is not addressed in the paper."
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7496/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698773087038,
            "cdate": 1698773087038,
            "tmdate": 1699636904876,
            "mdate": 1699636904876,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bEEW8i8PZP",
                "forum": "LixGd92Wri",
                "replyto": "kk9yVY0MEx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7496/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7496/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank reviewer GGxS for recognizing the compelling aspect of our work in developing OOD benchmarks for GDL in science, well-organized contents, and sufficient experimental analyses. Based on the review, we acknowledge that the reviewer has read our paper thoroughly and pointed out questions, in particular identifying our improper underemphasis of some previous works\u2019 coverage. However, we respectfully disagree with the reviewer\u2019s comments on the soundness of our assumption of categorizing various distribution shifts and concerns regarding our experiment settings. We summarize the reviewer\u2019s concerns and provide our detailed explanations in the following response.\n\n  **1). Use of terms: \u201cThe use of critical terms should be better considered.\u201d**\n\nWe thank the reviewer for raising this confusion based on our paper presentation. We are not aiming to modify the existing well-established terms. Instead, we would like to further explain and extend the common definition of these well-established terms under the context of our selected application datasets. We have clarified in our refined draft by first following the well-established definitions of these distribution shifts and then highlighting that we further extend the definition to what we present in the paper given our assumption.\n\n**2).\tSoundness of causal statements in section 3.1**\n\t\nOverall, the reviewer mentioned some alternatively correct definitions of causal relationships that are not covered by this paper. However, the existence of those alternative definitions does not imply the lack of soundness of our ways of definitions. Note that our definitions in Sec. 3.1 are to model the scientific GDL datasets benchmarked in this work, which indicate how these datasets were curated and how their distribution shifts are like. Our definitions are not to cover all possible causality relationships. The alternative definitions mentioned by the reviewer, though existing in theory, either are not reflected by those datasets or may introduce more confusion. We are sorry for not clarifying this point in Sec. 3.1, which caused such confusion. In the following, we respond to each bullet point raised by the reviewer and have adjusted the exposition in Sec. 3.1 accordingly to avoid the similar confusion made by the reviewer.\n \n- 2.1 \tsoundness of causal statements: \u201cThe statement that $X$ consists of two disjoint parts and $X_i \\bot Y|X_c $ does not hold\u201d \n\nThis review confuses \u201cthe settings this work is targeting\u201d and \u201cother possible settings that this work is not to cover\u201d. Note that such conditional independence just describes the settings approximately indicated by our datasets. We agree that there exist other types of dependence, while they are out of the scope of this work because we did not find interesting scientific GDL datasets that reflect those types of dependence. Moreover, limiting the scope properly allows for more in-depth study without losing much generality.\n\nFirst, such conditional independence is derived from real-world scientific application and holds in our established scenarios. Take our track Dataset in particle physics as an example. The entire point cloud can be split into 2 parts, namely the signal part used to determine whether there is a specific signal we are looking for (determine the label), and the background part, which itself is independent of the label given the signal part. This exactly follows the conditional independence assumption as $X_i \\bot Y|X_c$. The other two datasets also comply with the assumption that the label is determined by only a part of the data entry, with another part being statistically correlated but conditionally independent of the label given the causal part. Therefore, we respectfully disagree with the argument that \u201cX cannot be divided into two disjoint parts that are causal/independent\u201d, which is at least properly reflected by the datasets considered in this work. \n\nSecond, this setting of conditional independence is of a broad range of research interest to the machine learning community. For instance, we can find similar formulations in DIR [1], Invariant Rationalization [2], etc. Take DIR for example, Equation 1 in this paper indicates the conditional-independence property of the oracle rationale, where $S$ is \u201cstatistically associated with $Y$ but non-causal to $Y$\u201d, and is independent of $Y$ given the causal part $C$.\n\nIn a word, the example $X_c\\to Y\\to X_i$ raised by the reviewer exists, but it is beyond the scope of this work, especially when we did not find a scientific GDL dataset that obeyed such a setting. We are happy to enrich our benchmark in the future if the reviewer may suggest some scientific GDL datasets that reflect the settings the reviewer would like to cover.  \n\n[1] Wu, Yingxin, et al. \"Discovering Invariant Rationales for Graph Neural Networks.\" ICML, 2021.\n\n[2] Chang, Shiyu, et al. \"Invariant rationalization.\" ICML, 2020."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7496/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700250021512,
                "cdate": 1700250021512,
                "tmdate": 1700250021512,
                "mdate": 1700250021512,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FfDsjRVfcq",
                "forum": "LixGd92Wri",
                "replyto": "kk9yVY0MEx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7496/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7496/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to your feedback"
                    },
                    "comment": {
                        "value": "Dear reviewer GGxS,\n\nAfter carefully considering your comments, we provide point-to-point answers to address all your concerns. As the discussion period is closing, we would appreciate it if you could give some feedback. Your participation is important to  the review process.\n\nthe authors"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7496/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700703508241,
                "cdate": 1700703508241,
                "tmdate": 1700703508241,
                "mdate": 1700703508241,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2lSaxMgo3j",
                "forum": "LixGd92Wri",
                "replyto": "FfDsjRVfcq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7496/Reviewer_GGxS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7496/Reviewer_GGxS"
                ],
                "content": {
                    "title": {
                        "value": "Response to rebuttal"
                    },
                    "comment": {
                        "value": "Many thanks to the detailed rebuttal from the authors. \nI have checked and appreciate the response and paper revision. However, most of my concerns are not addressed. \nThe causal modeling and math in 3.1 is still rough with no major changes. The concept shift and conditional shift notions for related works are not clear. The shifts in OoD-Bench, GDS, and GOOD are conceptually closer to the conditional shift defined in this work than concept shift, since $P(Y|X_c)$ does not change at all in those works. This is also why I believe a rigorous causal modeling is vital as the theoretical foundation, considering all the potential misconceptions. Also, an obvious unfairness in experimental settings, as I mentioned, is that comparisons are made given that different numbers of data samples are used to train different methods. How can the influence of OOD info be demonstrated when the number of data samples is not controlled? Finally, I still believe SOTA methods of the field should be considered for newly proposed benchmarks. Given the aforementioned reasons, I have to maintain my rating of this work for now."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7496/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700722471551,
                "cdate": 1700722471551,
                "tmdate": 1700722471551,
                "mdate": 1700722471551,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1P1TJh8RcC",
                "forum": "LixGd92Wri",
                "replyto": "kk9yVY0MEx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7496/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7496/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors"
                    },
                    "comment": {
                        "value": "Many thanks to the response of the reviewer. We will also give more explanations in the first concern:\n\nThe reviewer comments \"The shifts in OoD-Bench, GDS, and GOOD are conceptually closer to the conditional shift\". However, \nthe original papers formalized the shift by using a concept shift notion: In OoD-bench, the authors formalized $p(y | z) \\ne q(y | z)$ and in GOOD, the authors formalized $P ^{train}(Y |X) \\ne P ^{test}(Y |X)$. These are concept shifts according to their explicit formulations, and we tried to follow their notions. \n\nThank you for your response!"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7496/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700727025296,
                "cdate": 1700727025296,
                "tmdate": 1700741788616,
                "mdate": 1700741788616,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Efzji3Hbhy",
            "forum": "LixGd92Wri",
            "replyto": "LixGd92Wri",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7496/Reviewer_xYh1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7496/Reviewer_xYh1"
            ],
            "content": {
                "summary": {
                    "value": "The paper effectively addresses the challenge of evaluation of deep learning models generalization abilities under distribution shift in geometric deep learning (point cloud data). It categorizes various sources of distribution shift between training and testing domains and introduces a new benchmark dataset spanning three distinct domains: particle collision physics, chemistry, and material science. The paper further evaluates multiple models, drawing conclusions and recommendations regarding which methods generalize better in specific scenarios"
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The introduction of a new benchmark dataset that spans different domains and types of distribution shifts is a noteworthy contribution. This dataset allows for a more nuanced comparison of deep learning methods based on the specific type of shift, making it practically significant and important for the research community.\n\nThe paper's coverage of various scientific fields, including particle collision physics, chemistry, and material science, broadens its applicability and relevance, potentially opening up opportunities for interdisciplinary research.\n\nThe paper is clearly written and technically sound."
                },
                "weaknesses": {
                    "value": "It's crucial to include detailed information about the characteristics of the new benchmark datasets and of the already existing datasets. Providing information on data size and other characteristics would enhance the reader's understanding of the datasets' properties and its applicability."
                },
                "questions": {
                    "value": "n/a"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7496/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698806714641,
            "cdate": 1698806714641,
            "tmdate": 1699636904711,
            "mdate": 1699636904711,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "RTRK0phScy",
                "forum": "LixGd92Wri",
                "replyto": "Efzji3Hbhy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7496/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7496/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We express our gratitude to reviewer xYh1 for acknowledging the contribution of our benchmark and recognizing the clarity and technical soundness of our paper. We also appreciate the valuable advice provided by the reviewer regarding the inclusion of more detailed information about the characteristics of the datasets in our benchmark. Basic dataset information, including data size and strategies for domain/subgroup splits, has been included in Appendix C. In our refined draft, we will provide more granular information that better reflects the characteristics of the constructed datasets and distribution shift. This will involve details covering:\n\n1) the average number of tracks and particles for each pileup level in Pileup Shift (Track Dataset)\n2) the average signal radius of each type of signal in Signal Shift (Track Dataset)\n3) the average number of atoms for ID and OOD Dataset in Size Shift (DrugOOD-3D Dataset)\n4) the average band gap value for each fidelity level in Fidelity Shift (QMOF Dataset)\n\nWe will collect and add the above 4 types of information to the refined draft before the deadline for rebuttal. Feel free to let us know if more details should be provided."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7496/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700249146698,
                "cdate": 1700249146698,
                "tmdate": 1700249146698,
                "mdate": 1700249146698,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]