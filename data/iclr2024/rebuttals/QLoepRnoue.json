[
    {
        "title": "Decodable and Sample Invariance Continuous Object Encoder"
    },
    {
        "review": {
            "id": "yMpq42Z4bw",
            "forum": "QLoepRnoue",
            "replyto": "QLoepRnoue",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1026/Reviewer_jCpW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1026/Reviewer_jCpW"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes Hyper-Dimensional Function Encoding (HDFE), which does not require training and maps continuous objects for embedding space. The proposed method enables processing continuous objects. Experiments show that the proposed method can be plugged into and improve PointNet-based architectures."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1. Encoding continuous signals is an important research topic. The paper is clear and well-organized.\n2. The proposed method does not require any-training and can be plugged into existing structures, which makes it easy to apply in practice and could have wide applications.\n3. Evaluation is thorough and solid. The method shows advantages over various prior works, across different datasets and settings."
                },
                "weaknesses": {
                    "value": "1. In Table 1, some metrics did not show improvement when comparing to the prior work HSurf-Net.\n2. The encoding capacity of the proposed method might be limited."
                },
                "questions": {
                    "value": "Can the proposed method be applied for any-resolution image encoder for complex natural images, e.g. ImageNet? What would the main challanges be for applying the method to the image domain?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1026/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698820725862,
            "cdate": 1698820725862,
            "tmdate": 1699636028837,
            "mdate": 1699636028837,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NaokAMB02m",
                "forum": "QLoepRnoue",
                "replyto": "yMpq42Z4bw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1026/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1026/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are sincerely grateful for your positive feedback on our research topic, contributions, and the organization of the paper. Your insightful questions have not only deepened our understanding but also guided us towards future research directions. We are pleased to address your concerns as follows:\n\n> Weakness 1: In Table 1, some metrics did not show improvement when comparing to the prior work HSurf-Net.\n\nWe acknowledge the reviewer's observation regarding Table 1's metrics in comparison to HSurf-Net. We understand the importance of this concern and have provided a detailed analysis in the global response section. This analysis explores the potential reasons behind these findings and their broader implications.\n\n> Weakness 2: The encoding capacity of the proposed method might be limited.\n\nWe recognize the concern about HDFE's limited encoding capacity for extensive input spaces, a point we also note in our conclusions. To address this, we propose partitioning the input space into disjoint subspaces and concatenating their respective encodings. While our current focus has been on low-dimensional functions, where capacity is less of an issue, expanding HDFE\u2019s capacity for broader applications presents a significant future research direction.\n\n> Question 1: Can the proposed method be applied for any-resolution image encoder for complex natural images, e.g. ImageNet? What would the main challanges be for applying the method to the image domain?\n\nThe application of HDFE to complex natural image tasks, such as those involving ImageNet, introduces specific challenges, particularly its lack of translation invariance. This means the HDFE encoding for an image and its shifted version would differ significantly, making it less suitable for tasks requiring translation invariance like classification and detection. Nonetheless, HDFE may be well-suited for image-related tasks that do not necessitate translation invariance, such as image-to-image translation or image super-resolution. This area presents exciting avenues for future exploration, and we are grateful for your question, which has stimulated further consideration of HDFE's potential in image processing."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1026/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700193809357,
                "cdate": 1700193809357,
                "tmdate": 1700193809357,
                "mdate": 1700193809357,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "UHNXVDcosf",
            "forum": "QLoepRnoue",
            "replyto": "QLoepRnoue",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1026/Reviewer_421T"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1026/Reviewer_421T"
            ],
            "content": {
                "summary": {
                    "value": "This submission propose a module, namely Hyper-Dimension Function Encoding (HDFE), to map a continuous object (data sample) into a fixed-dimension vector without any training.\nThe author asserts that the proposed approach possesses four key characteristics: (1) sample distribution invariance (2) sample size invariance (3) explicit representation (4) decodability.\nTo obtain the fixed-length vector representation, the input data for HDFE must adhere to Lipschitz continuity and will be transformed into a high-dimensional space, where a weighted average will be computed."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The manuscript demonstrates excellent organization, a well-defined research problem, clear logic, and skillful writing.\n\n2. The topic holds significant importance: a method that can map data samples with varying distributions and sizes to fixed-length sequences may be highly appealing for pre-training models that utilize cross-domain data.\n\n3. The theory effectively connects with the experiment: the utilization of a weighted average operation has the potential to reduce noise effectively."
                },
                "weaknesses": {
                    "value": "1. It is necessary to provide a clear definition of \"implicit representation\" and \"explicit representation\" in the manuscript. Some reviewers may intuitively refer to the fixed-length vector representation of a data sample as \"implicit representation\" since it may not be human-friendly. However, in this manuscript, the fixed-length vector representation is referred to as the \"explicit representation.\"\n2. The proposed method (HDFE) relies on the assumption that the input data follows Lipschitz continuity. While the reviewer agrees that point cloud data intuitively follows Lipschitz continuity, it would be beneficial for the manuscript to include an analysis of the types of input data that adhere to Lipschitz continuity.\n\n3. As a module that doesn't require any training, it is important to provide detailed guidance on selecting hyperparameters. This includes guidance on choosing the size of the fixed-length vector representation (denoted as $N$) and determining the hyperparameters $\\alpha$ and $\\beta$ in Equation 5, which are influenced by the receptive field $\\epsilon_0$ and the Lipschitz continuous constant $c$.\n\n4. 2The selection of weights ($w_i$ in Equation 1), hyperparameters ($\\alpha$ and $\\beta$), and the mapping functions $E_X$ and $E_Y$ are highly dependent on the dataset. This means that if the task or input data changes, all these variables need to be carefully decided and tested.\n\n5. There is a small concern regarding the experimental results on the PCPNet dataset. The proposed HDFE method is demonstrated to outperform the PCPNet model (the baseline in 2018) simply by replacing PointNet with HDFE. However, it is only comparable to the current state-of-the-art (SOTA) method, outperforming it in four out of twelve metrics, albeit with a slight drop in average performance. It would be valuable to provide insights or explanations for these observations and discuss any potential limitations or implications of the results."
                },
                "questions": {
                    "value": "1. In line 7 of page 2, why is the representation learned by PointNet (Qi et al., 2017a) not easily decodable? For instance, in their original paper (https://arxiv.org/pdf/1612.00593.pdf) in Figure 2, it seems possible to set m=3 and obtain normalized point clouds. Additionally, other works like [1] may also be able to 'decode' the input from the vector representation. Is there any difference between this manuscript and those works?\n\n2. When experimenting with batches, should the model visit all data samples to decide hyperparameters? According to Equation 3, the decoding step should visit all $\\bm Y$.\n\n3. By curious: why a high-dimensional input does not affect the size of the fixed-length vector representation $N$. Could the author provide further explanation, possibly an extension of the paragraph on 'Scale to high-dimensional input'?\n\n4. in Section 2.3, the manuscript only shows the picking of $E_X$ and $E_Y$ when the function output y is scalar. Are there more cases that can be considered?\n\n5. Although HDFE is a deterministic function, is there any empirical result available to estimate the information loss from the raw input to the fixed-length vector representation?\n\n\n\n[1] Learning Representations and Generative Models for 3D Point Clouds. PMLR"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1026/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698830536383,
            "cdate": 1698830536383,
            "tmdate": 1699636028754,
            "mdate": 1699636028754,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jhCpTfbcVj",
                "forum": "QLoepRnoue",
                "replyto": "UHNXVDcosf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1026/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1026/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answering Questions raised by Reviewer 421T"
                    },
                    "comment": {
                        "value": "> Question 1: Why is the representation learned by PointNet (Qi et al., 2017a) not easily decodable?\n\nThank you for your insightful question. We claim that PointNet's representations are not easily decodable based on our experiments where PointNet, as a function encoder, struggled to minimize reconstruction loss and failed to yield reasonable reconstructions. Detailed findings are presented in **Appendix B: PointNet as Function Encoder**.\n\nWhile previous works like [1] may encode implicit functions (e.g., point cloud inputs) effectively, our analysis suggests **they lack the capability for decodable representation of explicit functions**, as evidenced in Appendix B. Additionally, these methods **may not produce encoding invariant to sample distribution changes**. For instance, if trained on uniformly sampled point clouds and tested on varied sampling distributions, their performance could deteriorate, as discussed in Appendix I.4.\n\nWe are thankful for this question, which has enhanced the completeness of our manuscript, and we are open to any further inquiries regarding our experiments or arguments.\n\n[1] Learning Representations and Generative Models for 3D Point Clouds. PMLR\n\n> Question 2: When experimenting with batches, should the model visit all data samples to decide hyperparameters?\n\n**The hyperparameters $\\alpha$, $\\beta$, and the mappings $E_X$, $E_Y$ are predetermined and remain constant during both training and testing.** The selection process, particularly for $\\alpha$, involves identifying hyperparameters that minimize the function reconstruction loss. Once selected, these hyperparameters are fixed, eliminating the need for adjustments across batches. It's important to note that for meaningful comparisons of function encodings, they must be generated using consistent hyperparameters.\n\n> Question 3: why a high-dimensional input does not affect the size of the fixed-length vector representation. Could the author provide further explanation, possibly an extension of the paragraph on 'Scale to high-dimensional input'?\n\nOur conclusion regarding the negligible impact of high-dimensional input on the size of the fixed-length vector representation is based on empirical findings. Detailed in Appendix I.6, our experiments assess the influence of input dimension and function complexity on reconstruction error. These studies reveal that **while function complexity significantly affects the reconstruction error, the input dimension appears to have a minimal impact**. This leads us to conjecture that HDFE can effectively encode high-dimensional data without incurring information loss due to increased data dimension.\n\nWe appreciate the reviewer's interest in this topic, aligning with our discussion in the \"Scale to high-dimensional input\" section. Our intention is to highlight a promising research avenue and provide a foundational understanding of its viability.\n\n> Question 4: in Section 2.3, the manuscript only shows the picking of and when the function output y is scalar. Are there more cases that can be considered?\n\nThank you for prompting further consideration of HDFE's application scope. To address functions with vector outputs, HDFE can be easily adapted by reshaping the $\\Psi$ matrix in Equation 6. For cases where function inputs or outputs cannot be directly vectorized using Equation 6, we propose pretraining the input/output mappings $E_X$, $E_Y$ to align with the properties outlined in Section 2.1. This approach would enable HDFE to handle non-vector functions by employing customized mappings, as the principles for designing these mappings are thoroughly discussed in Section 2.1.\n\n> Question 5: Although HDFE is a deterministic function, is there any empirical result available to estimate the information loss from the raw input to the fixed-length vector representation?\n\nTo address the query about HDFE's information loss, we've included **Appendix I.5: Information Loss of HDFE** in our manuscript. Our empirical analysis reveals a linear relationship between information loss (quantified by reconstruction error) and function complexity, where complexity is measured by the integral of the absolute gradient. Interestingly, we observe that the reconstruction $R^2$ value appears uncorrelated with complexity in cases of sufficiently high input dimension. We trust this analysis will be insightful for the reviewer. We are grateful for this question, which has contributed to the manuscript's comprehensiveness."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1026/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700193664442,
                "cdate": 1700193664442,
                "tmdate": 1700194205152,
                "mdate": 1700194205152,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dQA0IctSmv",
                "forum": "QLoepRnoue",
                "replyto": "UHNXVDcosf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1026/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1026/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Addressing Weaknesses raised by Reviewer 421T"
                    },
                    "comment": {
                        "value": "We are grateful for the careful attention and time you have dedicated to reviewing our manuscript. Your constructive feedback is invaluable, and we have made concerted efforts to address each of your concerns, incorporating additional experiments and clarifications into the revised manuscript.\n\n> Weakness 1: It is necessary to provide a clear definition of \"implicit representation\" and \"explicit representation\" in the manuscript.\n\nThank you for highlighting the need for clearer definitions of \"implicit representation\" and \"explicit representation\" in our manuscript. We acknowledge the potential confusion among readers regarding these terms. In response to your suggestion, we have revised the definition of explicit representation in the Introduction's second paragraph: \"Explicit representation refers to frameworks that generate outputs with fixed dimensions, such as fixed-length vectors.\" To enhance clarity, we have also included a brief comparison between explicit and implicit representations, elucidating their distinct roles and applications in our research context. This modification should provide readers with a more comprehensive understanding and eliminate ambiguities related to these key terms.\n\n> Weakness 2: The proposed method (HDFE) relies on the assumption that the input data follows Lipschitz continuity. It would be beneficial for the manuscript to include an analysis of the types of input data that adhere to Lipschitz continuity.\n\nThank you for highlighting this aspect. In response, we have included **Appendix D: Suitable Input Types for HDFE**, detailing various input types that conform to Lipschitz continuity. This addition aims to clarify the characteristics of appropriate inputs, offering both theoretical understanding and practical guidance for researchers applying our method.\n\n> Weakness 3: As a module that doesn't require any training, it is important to provide detailed guidance on selecting hyperparameters.\n\nWe concur that providing guidance for hyperparameter selection is crucial for HDFE's usability. We contend, however, that hyperparameter tuning should not pose a significant barrier to users. HDFE's simplicity is characterized by minimal hyperparameter requirements. Specifically, for dimensionality, higher values invariably yield superior representations, obviating the need for intricate tuning. \nThe primary hyperparameter, the receptive field, is governed by the $\\alpha$ parameter in Equation 6. Typically, $\\alpha$ ranges from 10 to 30 for normalized inputs between $(0,1)$, simplifying the selection process. \nMoreover, we plan to release HDFE's source code along with comprehensive documentation, including hyperparameter guidance. We also envision incorporating automated mechanisms for receptive field optimization based on user-specific datasets, further reducing the tuning burden.\n\n> Weakness 4: The selection of weights ($w_i$ in Equation 1), hyperparameters ($\\alpha$ and $\\beta$), and the mapping functions and are highly dependent on the dataset. This means that if the task or input data changes, all these variables need to be carefully decided and tested.\n\nWe appreciate the opportunity to clarify potential misunderstandings:\n\n**Task Change vs. Input Functions**: If the task changes (e.g., from classification to regression) but the input functions remain constant, the hyperparameters need not be altered. Only the downstream neural network requires modification.\n\n**Weights $w_i$**: These are not hyperparameters but are determined through iterative refinement during input function encoding, thereby eliminating the need for user tuning.\n\n**Hyperparameter $\\beta$**: This remains constant as long as the function's range is normalized between 0 and 1. For functions normalized within $(0,1)$, we set $\\beta$ to 2.5, ensuring the gradient of $\\langle E_Y(y_1), E_Y(y_2)\\rangle$ stays positive, as detailed in the manuscript.\n\n**Changes in Input Functions**: The reselection of the $\\alpha$ value (in Equation 4) is only necessary if there's a significant change in the input functions (e.g., shifting from 1D to 2D functions) or in the Lipschitz constant.\n\nPlease note that the hyperparameters $\\alpha$, $\\beta$, and the mappings $E_X$, $E_Y$ are fixed across both training and testing phases to ensure comparability of function encodings.\n\n> Weakness 5: There is a small concern regarding the experimental results on the PCPNet dataset. It is only comparable to the current state-of-the-art (SOTA) method, outperforming it in four out of twelve metrics, albeit with a slight drop in average performance.\n\nWe acknowledge the reviewer's concern regarding the experimental results with the PCPNet dataset. To address this, we have conducted a thorough analysis of the HDFE's performance compared to both the baseline and current state-of-the-art methods. For a comprehensive understanding, we invite the reviewer to refer to our detailed analysis presented in the global response section."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1026/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700193749514,
                "cdate": 1700193749514,
                "tmdate": 1700194167376,
                "mdate": 1700194167376,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "fHogBLwig7",
            "forum": "QLoepRnoue",
            "replyto": "QLoepRnoue",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1026/Reviewer_oyrE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1026/Reviewer_oyrE"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes Hyper-Dimensional Function Encoding (HDFE), which encodes a continuous object (eg, functions) into a fixed-size explicit vector representation without requiring training. While it maintains the benefits of vector function architecture (VFA), satisfying sample invariance and decodability, it relaxes the strict assumption on the function form in VFA into Lipschitz functions by introducing a novel iterative refinement process. While HDFE serves as a general interface for a continuous object encoder without training, substituting HDFE for domain-specific algorithms in experiments on mesh-grid data and sparse data shows comparable performance. \nThe main contributions of the papers are: \n\n(1) The authors propose a novel function encoding method that satisfies key properties of VFA while relaxing the strict assumption on function space to  Lipschitz continuity. \n\n(2) Theoretical foundations and empirical analysis support the validity of HDFE on key properties. \n\n(3) Experimental results confirm that replacing domain-specific algorithms with HDFE maintains competitive performance and robustness to the noise perturbation."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is well written and easy to follow. \n\n- The formulation of the decodable encoder and iterative refinement process for sample invariance seems interesting and convincing. Also, theoretical analysis on each component is clear and supports the claims.\n\n- Despite the general and straightforward formulation, empirical results demonstrate the effectiveness of HDFE."
                },
                "weaknesses": {
                    "value": "Method\n\n- One concern is the computational cost of HDFE induced by the iterative refinement process. In order to employ function representation for the downstream tasks, computational costs of HDFE is important. it may hinder application to large-scale tasks. \n\nExperiment\n\n- Overall, it\u2019s convincing that HDFE is a reasonable and general interface for processing continuous objects, supported by the experiments. However, it\u2019s less convincing why we should use HDFE instead of other domain-specific encoding methods. The authors claim that sample invariance is a crucial property for the machine learning tasks throughout the paper, but it lacks the supporting experiment revealing HDFE\u2019s efficacy in those scenarios (i.e., sample distributions are different in training and test dataset). It would make the paper stronger if it presents the experiments with scenarios having disparate sample distributions between training and test datasets and compares the performance of HDFE compared to the baselines. \n\n- In the experiment section, it lacks the analysis why HDFE is more beneficial than the counterparts (e.g., PointNet) in terms of the performance. It would improve the understanding of HDFE if analysis on which component leads to the performance gap even when the noise is absent is provided."
                },
                "questions": {
                    "value": "- How long does the HDFE take compared to the baselines (eg, pointNet in Experiment 3.2)? Is the iterative refinement process applicable to a large number of samples? How long does it take for convergence in the process? \n\n- In the formulation on decoding, (i.e., equation between eq. (2) and eq.(3)), can you please clarify on why orthogonality property ensures that $E_X(x_i) \u2298 E_X(x_0) $ will produce a vector orthogonal to $E_X(x_0)$ when the distance between two samples is large? Also what does the noise mean? Does it mean that it\u2019s near zero so that it is a negligible component?\n\n- In the formulation on decoding, (i.e., equation between eq. (2) and eq.(3)), it seems it misses $w_i$. \n\n- For an unbinding operation, element-wise division of complex vectors is used. But I don't think this operation is commutative, which violates the assumption. Can you please clarify on this? \n\n- In experiment 3.1, how does the function prediction error is measured? Is it measured in embedding space? And the paper states that \u201cwhen decoding is not required, our approach achieves lower error than FNO\u201d, but how can we compare to FNO, which directly predicts the solution? \n\n- While the authors claim that HDFE is robust to point perturbation, the experiments on  [PCPNet - PointNet + HDFE] in Table 1 shows that the performance boost becomes much less as the noise level increases. Can you please elaborate on this?\n\n- [Possible Typo] In the last sentence in section 2.1, \u201cappendix F.1\u201d should be \u201cappendix E.1\u201d."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1026/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1026/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1026/Reviewer_oyrE"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1026/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699541835132,
            "cdate": 1699541835132,
            "tmdate": 1699636028682,
            "mdate": 1699636028682,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PYUub7IB1z",
                "forum": "QLoepRnoue",
                "replyto": "fHogBLwig7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1026/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1026/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Addressing Weaknesses raised by Reviewer oyrE"
                    },
                    "comment": {
                        "value": "We are grateful for the time and attention you have devoted to carefully reading our manuscript. We are eager to address your constructive concerns and have incorporated additional experiments and clarifications in the revised manuscript. We intent to make our replies elegant and concise for easy understanding, and we encourage Reviewer oyrE to refer to the corresponding sections in the updated manuscript for detailed experimental insights.\n\n> Weakness 1: One concern is the computational cost of HDFE induced by the iterative refinement process.\n\nWe acknowledge that the need for iterative refinement, which entails additional computational effort, presents a significant challenge for large-scale tasks. However, in fact, **the refinement process can be efficiently executed in a single iteration, yielding a highly accurate estimation of the sample invariant function encoding**.\n\n**Details:** The motivation of the iterative refinement is to balance the weights between dense and sparse samples. Such motivation can also be achieved by another cheaper one-shot refinement. After obtaining the initial function encoding by averaging the sample encoding, we compute the similarity between this initial encoding and all the sample encodings. The similarity can serve as a rough estimation of the sample density at a particular point. Therefore, if we were to balance the weights between dense and sparse samples, we can simply recompute the weights by the inverse estimated density. It turns out that **this one-shot refinement can achieve similarity of > 0.95 when sample distribution varies.** **The computational cost is only 8.0 ms on an NVIDIA Titan-X GPU.**\n\nWe kindly refer Reviewer oyrE to **Appendix I.3: Practical Consideration of Iterative Refinement** in the updated manuscript for the detailed procedure of one-shot refinement and experiments demonstrating its effectiveness. We highly appreciate your very constructive question that induces us to complete the manuscript.\n\n---\n\n> Weakness 2: The authors claim that sample invariance is a crucial property for the machine learning tasks throughout the paper, but it lacks the supporting experiment revealing HDFE\u2019s efficacy in those scenarios.\n\nWe heartly agree that experiments supporting HDFE's efficacy on sample invariance are important. **We will show HDFE is significantly more robust to distribution variation than PointNet through two experiments**: 1. point cloud normal estimation; 2. a synthetic function parameters regression problem.\n\n1. **Point Cloud Normal Estimation**\n\n   In our updated experiments, **HDFE significantly outperforms the PointNet counterpart when sample variance exists.** Specifically, HDFE achieves 4.79/7.37/0.52/0.46 lower errors than its PointNet counterpart in the setting of Density-Gradient (i.e. the density of the input point cloud varies) in the two baseline comparisons and two benchmark datasets. Through the comparison with the baseline, it is convincing that the significant improvement is attribute to HDFE's sample invariance property and the augmentation of the HDFE encoding.\n\n   We highly appreciate your very constructive feedback and we have added a paragraph \"**HDFE promotes stronger robustness to point density variance**.\" in the **Section 3.2: Unoriented Surface Normal Estimation** to make the analysis and discussion explicit to readers.\n\n2. **Synthetic Function Parameters Regression**.\n\n   We generate random functions parametrized by four coefficients and the task is to predict the four coefficients using the function samples. We artificially control the sample distribution to be varied or not varied across the training and testing phase. It turns out that **PointNet's prediction $R^2$ decreases from 0.978 to 0.513** when switching from no variation to variation, while **HDFE maintains its $R^2$ at > 0.9975** in both settings. We kindly refer the Reviewer oyrE to **Appendix I.4: Effectiveness of Sample Invariance** in the updated manuscript for the experiment details and analysis.\n\nThese experiments demonstrate HDFE's superior performance in scenarios with sample variance, thereby validating our claims about its efficacy in machine learning tasks. We highly appreciate your very constructive question that induces us to complete the manuscript.\n\n---\n\n> Weakness 3: In the experiment section, it lacks the analysis why HDFE is more beneficial than the counterparts (e.g., PointNet) in terms of the performance. It would improve the understanding of HDFE if analysis on which component leads to the performance gap even when the noise is absent is provided.\n\nWe agree on your concern and we have investigated into the cause. We kindly refer the reviewer to the posted global response, where we explain our analysis in details."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1026/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700228716245,
                "cdate": 1700228716245,
                "tmdate": 1700228716245,
                "mdate": 1700228716245,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "p8R1RdBY36",
                "forum": "QLoepRnoue",
                "replyto": "fHogBLwig7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1026/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1026/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answering Questions from Reviewer oyrE, Part 2/2"
                    },
                    "comment": {
                        "value": "> Question 6: While the authors claim that HDFE is robust to point perturbation, the experiments on [PCPNet - PointNet + HDFE] in Table 1 shows that the performance boost becomes much less as the noise level increases. Can you please elaborate on this?\n\nWe believe it is caused by the trade-off between accuracy and robustness to noises. In Table 1, we present the result obtained by $\\alpha=20$, which minimizes the average error. However, this parameter, compared with other selections of $\\alpha$, does not obtain lowest error at all noise levels. Kindly refer to Appendix K, where we find a larger receptive field makes HDFE more robust to noise, while a smaller receptive field makes HDFE more accurate in clean inputs. We can increase HDFE's robustness to noise by choosing a large receptive field, but we will lose some accuracy when the input is clean.\n\n> Question 7: [Possible Typo]\n\nThanks for your catch! We have corrected the typo."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1026/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700228840381,
                "cdate": 1700228840381,
                "tmdate": 1700228840381,
                "mdate": 1700228840381,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qxgM91kIJw",
                "forum": "QLoepRnoue",
                "replyto": "fHogBLwig7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1026/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1026/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answering Questions raised by Reviewer oyrE, Part 1/2"
                    },
                    "comment": {
                        "value": "> Question 1: How long does the HDFE take compared to the baselines (eg, pointNet in Experiment 3.2)? Is the iterative refinement process applicable to a large number of samples? How long does it take for convergence in the process?\n\nWhile the details are in the response to Weakness 1, we would like to mention that HDFE is much faster than PointNet. For an input of shape $5000\\times 3$, assuming the complexity of multiplying an $m\\times n$ matrix with an $n\\times p$ matrix is $mnp$, then HDFE only has has complexity $5000\\times3\\times1024\\approx1.5e7$. The computational cost of the one-shot refinement is negligible here. But PointNet has complexity $5000\\times3\\times64+5000\\times64\\times128+5000\\times128\\times1024\\approx 70e7$.   \n\n> Question 2: In the formulation on decoding, (i.e., equation between eq. (2) and eq.(3)), can you please clarify on why orthogonality property ensures that will produce a vector orthogonal to when the distance between two samples is large? Also what does the noise mean? Does it mean that it\u2019s near zero so that it is a negligible component?\n\nWe recognize that the noise argument may not be straight-forward from the orthogonal property. For better rigor, clarification and readability, we replace the orthogonal property as similarity-preserving property, without affecting the correctness of HDFE:\n\n\u200b\tsimilarity preserving: \u27e8x \u2297 y, x \u2297 z\u27e9 = \u27e8y, z\u27e9.\n\nWhen $d_X(x_0, x_i)$ is large, $\\langle E_X(x_0)\\otimes E_Y(f(x_0)), E_X(x_i)\\otimes E_Y(f(x_i)) \\rangle\\approx 0$. Since the unbinding operation is similarity preserving, we have $\\langle E_Y(f(x_0)), E_X(x_i)\\otimes E_Y(f(x_i)) \\oslash E_X(x_0)\\rangle\\approx 0$. Therefore, $\\mathbf{F}\\oslash E_X(x_0)$ can be decomposed into $E_Y(f(x_0))$ and the sum of vectors that are orthogonal to it. Consequently, when we search for the $y$ to maximize the $\\langle \\mathbf{F}\\oslash E_X(x_0), E_Y(y) \\rangle$, those orthogonal vectors will not bias the optimization.\n\nNote that the Fractional Power Encoding does satisfy the similarity preserving property, so the entire HDFE formulation is still correct. We have rewritten the **decoding** section based on the new definition and put the argument in **Appendix E: Derivation of Decoding**. We highly appreciate your constructive question for helping us improve the manuscript.\n\n> Question 3: In the formulation on decoding, it seems it misses $w_i$.\n\nThanks for your catch! We have corrected the typo.\n\n> Question 4: For an unbinding operation, element-wise division of complex vectors is used. But I don't think this operation is commutative, which violates the assumption. Can you please clarify on this?\n\nThis is a very sharp catch! We admit it is an overlook by us when we draft the manuscript. You are correct that the element-wise division of complex vectors is not commutative. Actually the commutative property is not required when deducing the decoding formulation, so the HDFE formulation is still correct. We have revised the definition of our binding and unbinding operations to address this (and Question 2) and ensure the logical consistency of our methodology.\n\n> Question 5: In experiment 3.1, how does the function prediction error is measured?\n\nThe function prediction error is computed by the mean absolute error between the predicted function and the ground-truth function, as mentioned in the Section 3.1 -> Dataset.\n\n> Question 5: And the paper states that \u201cwhen decoding is not required, our approach achieves lower error than FNO\u201d, but how can we compare to FNO, which directly predicts the solution?\n\nWe first encode the ground-truth solution into a vector and then decode the vector to reconstruct the solution. From this, we obtain a reconstruction loss $error_1$, which is visualized by the shallow red bars (Reconstruction Error) in Figure 3. Then we decode the predicted function vector to reconstruct the solution. From this, we obtain the error between the predicted solution and the ground-truth solution, denoted by $error_2$, which is visualized by the stack of Reconstruction Error and Function Prediction Error.\n\nOur argument is, $error_2$ consists of two components. The first component arises when reconstructing the function from the encoding, which is measured by $error_1$. The second component arises when predicting the function encoding, which cannot be measured directly. But since $error_2$ only consists of two components, we can estimate the error arised from the second component by $error_2-error_1$, which is visualized as the Function Prediction Error in Figure 3."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1026/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700228924517,
                "cdate": 1700228924517,
                "tmdate": 1700228924517,
                "mdate": 1700228924517,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]