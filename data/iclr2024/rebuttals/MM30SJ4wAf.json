[
    {
        "title": "Point Neighborhood Embeddings"
    },
    {
        "review": {
            "id": "baZA9OyYRd",
            "forum": "MM30SJ4wAf",
            "replyto": "MM30SJ4wAf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1713/Reviewer_BoSJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1713/Reviewer_BoSJ"
            ],
            "content": {
                "summary": {
                    "value": "This paper gives a comprehensive study on a variety of existing point neighborhood embedding in a controlled setting. Accordingly, it concludes several practical suggestions regarding designing the neighborhood embedding. The paper validates it\u2019s suggestions in the recent point transformer and show the improvement."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "The paper provides a comprehensive and extremely insightful investigation about the point aggregation module -- the core in point cloud architecture where, given a target point, how we aggregate information from other source points. \n\nThis paper fills a blank of this point convolution area -- i.e.Which type of point aggregation is the best? From my viewpoint, most existing works on point cloud architecture like PointNet++ PointConv and KPConv are trying to improve this convolution module in terms of different subtle details like neighborhood querying, kernel function etc. Even the recent point transformer falls in this scope by replacing conv-based aggregation with attention-based way under a mild assumption that the feature of target point is known whereas the point conv doesn\u2019t require it.  Although those works gradually improve the performance on the common benchmark, comprehensive study is still missing -- in other words, different modules are not compared in a controlled setting -- and leads to the best design choice unknown. Because of this, I\u2019ve been bothered so many times by having no idea about which modules are better. So from my perspective, this paper fixes this problem in this area and I believe it can inspire future works like mine. \n\nThe derived suggestions are very useful. It includes: no ReLU in MLP, ball-query better KNN and kernel point is better than MLP. For the latter two, I think it\u2019s not surprising as I also observe this. But it\u2019s still useful to have a fair comparison to show it. And for the first one, it\u2019s something new to me. \n\nAlso, from my viewpoint,  the formula presented by the author is easy to follow. I would consider using the same formula -- it summarizes the most of existing convolution in a unified way-- when I teach a lecture about point convolution next time."
                },
                "weaknesses": {
                    "value": "The paper has several weaknesses which I\u2019ll detail below. \n\nMore modules could be considered -- for example like the very powerful PAConv that defines the convex kernel function. Also the recent PointMLP [1] defines an interesting local aggregation module that relies on normalization. I think the author can further improve the paper by including more options. \n\nThe paper utilizes the KPConv with fixed kernel point location which is suboptimal in original KPConv paper. So I would recommend discussing how the deformable KPConv fits in the formula. This would make the paper more comprehensive. \n\nI\u2019m not very sure if I can agree with the argument made in Eq. 1 where the Point transformer is not a convolution. From my perspective,  it also has a similar formula if we consider the query point\u2019s features. But this is my personal viewpoint. I wouldn\u2019t convince authors to convey point transformers in a convolution way. However, given that the author doesn\u2019t consider the point transformer as a kind of convolution, it\u2019s a bit weird to validate the proposed tips derived from convolution into the point transformer. So I think the author might want to clarify it a bit in the paper. \n\nThe paper didn\u2019t use the ModelNet40. Although it\u2019s a synthetic dataset that is highly saturated by lots of existing methods, I believe that it\u2019s still a proper dataset to fairly investigate the different subtle modules in point convolution. Or the paper needs to justify why the paper doesn\u2019t use the popular ModelNet40 in my opinion. \n\n[1]Ma, Xu, et al. \"Rethinking network design and local geometry in point cloud: A simple residual MLP framework.\"  ICLR 22."
                },
                "questions": {
                    "value": "Please address the questions above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1713/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698702332015,
            "cdate": 1698702332015,
            "tmdate": 1699636100093,
            "mdate": 1699636100093,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5yBY1OGgO4",
                "forum": "MM30SJ4wAf",
                "replyto": "baZA9OyYRd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1713/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1713/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Additional activation function and discussions"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for appreciating the relevance of our work and for all the suggestions. In the following paragraphs, we would like to address the main concerns of the reviewer:\n\n**Including more options such as PAConv designs**\n>We have experimented with other MLP designs by including the Softmax activation function in our MLP-based embeddings in a similar way as done in the Score module for PAConv.\n>The results of this experiment can be seen in the following table:\n\n|  Neigh | Task  | Metric  | Softmax | ReLU | GELU | Sin |\n|---|---|---|---|---|---|---|\n|  BQ |  Class |  Acc. | 89.8 | 91.1 | **92.8** | 91.9 |\n|   |  |  mAcc | 88.9 | 89.6 | **91.4** | 90.6 |\n||||||||\n|   | Seg. |  mIoU | 70.8 | 71.4 | 71.9 | **72.4** |\n|   |  |  mAcc | 78.6 | 79.4 | 80.0 | **80.1** |\n||||||||\n|   | Det. |  AP@25 | 52.5 | 58.1 | **58.3** | 56.5 |\n|   |  |  AP@50 | 29.5 | 37.0 | **38.0** | 33.9 |\n||||||||\n| KNN  | Class. |  Acc | 90.1 | 89.9 | 91.0 | **92.2** |\n|   |  |  mAcc | 88.9 | 88.0 | 89.8 | **90.6** |\n||||||||\n|   | Seg. |  mIoU | 71.6 | 71.0 | 71.0 | **72.1** |\n|   |      |  mAcc | 79.6 | 78.9 | 79.1 | **79.8** |\n||||||||\n|   | Det. | AP@25 | 51.6 | **56.2** | 55.9 | 55.3 |\n|   |      | AP@50 | 29.7 | **33.7** | 33.6 | 33.2 |\n\n>We can see that an MLP-based embedding with a Softmax activation function, unfortunately, does not provide an improvement over the other activation functions tested.\n>However, in the future, it will be interesting to analyze other design decisions of the PAConv operation, such as the aggregation method (MAX instead of SUM) or the addition of global coordinates as input to the embedding function, which might result in a better performance when combined with Softmax.\n\n**Deformable KPConv**\n>We thank the reviewer for pointing this out, we have included a discussion regarding deformable kernel points in the paper\n\n**Transformer is not a convolution**\n>We regret we did not communicate this properly.\n>We agree with the reviewer that PointTrasnformer is a convolution since it aggregates information from a local neighborhood using the relative position between points.\n>Our statements after Eq. (1) intended to describe that these operations, such as PointTransformer, cannot be defined with Eq(1) as we presented it, but this did not mean that our Eq(1) can represent all possible definitions of convolution.\n>We have made this point clearer in the revised version of the paper.\n\n**Validation on ModelNet40**\n>We have chosen to validate on ScanObjNN because of the problems pointed out by the reviewer, performance is saturated by many models and it might be difficult to measure the improvements between embeddings.\n>Therefore, due to the limited time of the rebuttal phase and as suggested by another reviewer, we have chosen instead to incorporate the task of object detection on ScanNet to increase our evaluation."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1713/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700641879502,
                "cdate": 1700641879502,
                "tmdate": 1700641879502,
                "mdate": 1700641879502,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PiydIdgyaY",
                "forum": "MM30SJ4wAf",
                "replyto": "5yBY1OGgO4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1713/Reviewer_BoSJ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1713/Reviewer_BoSJ"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the feedbacks"
                    },
                    "comment": {
                        "value": "Thanks for the feedback and sorry for the late. \nI think rebuttal addressed most of my concerns. And I'll adjust my rating combining comments from other reviewers."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1713/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700685591990,
                "cdate": 1700685591990,
                "tmdate": 1700685591990,
                "mdate": 1700685591990,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "kKLd26qtAA",
            "forum": "MM30SJ4wAf",
            "replyto": "MM30SJ4wAf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1713/Reviewer_HsUz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1713/Reviewer_HsUz"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a comprehensive study in the performances of various Point Neighborhood Embeddings (PNE) mechanisms in point convolutional neural network architectures, and further offers recommendations for improving model designs based on the findings. They validated that their recommendations can outperform most existing methods in several tasks with simple design and can improve existing complex convolution operations."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Their findings and recommendations can benefit future arch design of point clouds\n2. They did comprehensive experiments to explore the different design choices and validate their recommendations.\n3. The writing is good with detailed introduction and analysis."
                },
                "weaknesses": {
                    "value": "-"
                },
                "questions": {
                    "value": "-"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1713/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698728802334,
            "cdate": 1698728802334,
            "tmdate": 1699636100026,
            "mdate": 1699636100026,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Rs6dZcHc7U",
                "forum": "MM30SJ4wAf",
                "replyto": "kKLd26qtAA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1713/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1713/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We thank the reviewer for possitive assesment"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the positive assessment of our work. We also hope that our work, as indicated by the reviewer, can benefit future architectural designs of point clouds."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1713/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700641377168,
                "cdate": 1700641377168,
                "tmdate": 1700641377168,
                "mdate": 1700641377168,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "4ZvQuzLNtB",
            "forum": "MM30SJ4wAf",
            "replyto": "MM30SJ4wAf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1713/Reviewer_n5A1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1713/Reviewer_n5A1"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents extensive study that analyzes point cloud embeddings based on activation functions used, correlation functions used, MLP vs Kernel points embeddings, etc. The paper also talks about different convolution operation and the neighbourhood election based on ball query vs k-NN. The authors performed two downstream tasks classification and segmentation on two benchmark datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. The paper is well-written and provides a good analysis of point cloud embeddings. \n2. This can help build new algorithms/architectures to improve embeddings. \n3. The study provides interesting results.\n4. The architecture includes simple modification and not expensive operations like transformers."
                },
                "weaknesses": {
                    "value": "1. This paper can be seen as a good experimental study paper which is not up to the level of ICLR. This is like a review paper although in a different direction where it provides extensive study on multiple points. \n2. The paper is very weak in novelty and makes some claims without evidence or explanations except results. \n3. The work mentions a lot of comparisons between activation functions, MLP vs. KP, etc. However, the whole paper lacks in explaining \u201cwhy\u201d something is better or worse. For example, kNN vs BQ talks about having high variance with kNN. It does not explain why. \n4. Support of the embedding is not clearly defined. I believe the receptive field is neighbourhood. \n5. There is no fixed proposed architecture in the paper. The results are not generalized based on a particular setting. The architecture used is the existing architecture mentioned in 5.1 with some changes like activation function, using KP/MLP, and different correlation function based on KP embeddings."
                },
                "questions": {
                    "value": "Why validation set is used for PNE and the validation+test set is used for other methods?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "Not Applicable"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1713/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698812344064,
            "cdate": 1698812344064,
            "tmdate": 1699636099925,
            "mdate": 1699636099925,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "cYFKfTVeOY",
                "forum": "MM30SJ4wAf",
                "replyto": "4ZvQuzLNtB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1713/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1713/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Addressing main concerns"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the feedback and hope we can address the main concerns in the following paragraphs.\n\n**Weak novelty and not up to the level of ICLR**\n>Novelty is a very subjective matter, and it can be difficult to rebut.\n>However, we would like to point out that no other reviewer had this concern, and provided instead encouraging remarks such as \"The paper provides a comprehensive and extremely insightful investigation about the point aggregation module.\", \"This paper fills a blank of this point convolution area\", or \"Their findings and recommendations can benefit future arch design of point clouds\".\n>We believe our work goes far beyond a simple review paper and provides several findings that can help move forward the field of learning on point clouds.\n\n\n**kNN vs BQ talks about having high variance with kNN by does not explain \"why\"**\n>Unfortunately, we were not able to communicate this properly.\n>The reason why the high variance might hurt performance was described in the paragraph kNN vs BQ.\n>Large variance will result in a large embedding norm for some MLP-based embeddings, ReLU and GELU, making training difficult. \n>Moreover, large variance will also result in some outlier points being not part of the support for some KP-based embeddings, *Gauss* and *Trian*, making them irrelevant for these computations.\n>We have updated this paragraph to make the point clearer.\n\n\n**Support of the embedding is not clearly defined. I believe the receptive field is neighbourhood.**\n>We regret that this was not clear in the paper.\n>The support of the embedding is the same as the support in any function: \" subset of the function domain containing the elements which are not mapped to zero\".\n>\n>The receptive field of the convolution for point clouds is the same as for discrete convolutions, the area around the point that affects the resulting feature computation.\n>This term is adopted from neuroscience where it is defined as: \"The receptive field of an individual sensory neuron is the particular region of the sensory space (e.g., the body surface, or the visual field) in which a stimulus will modify the firing of that neuron. \"\n\n\n**There is no fixed proposed architecture in the paper.**\n>Regretfully, we did not understand this specific concern of the reviewer.\n> We believe the reviewer meant that our architecture is not original.\n>However, this was not the aim of the paper.\n>We aim to analyze and compare existing convolution designs from which we were able to gather new insights that help future designs of architectures for point clouds.\n\n\n**Why validation set is used for PNE and the validation+test set is used for other methods?**\n>The labels for the test set of ScanNet are hidden and one is required to upload the predictions to their system.\n>The system only allows uploading a set of predictions once every two weeks and only allows for a method per institution.\n>Therefore, it was impossible for us to perform the PNE comparison on the test set."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1713/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700641339918,
                "cdate": 1700641339918,
                "tmdate": 1700641339918,
                "mdate": 1700641339918,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4z5VSZl39C",
                "forum": "MM30SJ4wAf",
                "replyto": "cYFKfTVeOY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1713/Reviewer_n5A1"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1713/Reviewer_n5A1"
                ],
                "content": {
                    "title": {
                        "value": "Thanks"
                    },
                    "comment": {
                        "value": "Thanks for the feedback. I went through the answers to my concerns. I will consolidate these in the final comments and rating."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1713/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700716969915,
                "cdate": 1700716969915,
                "tmdate": 1700716969915,
                "mdate": 1700716969915,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "6wMwrxkPil",
            "forum": "MM30SJ4wAf",
            "replyto": "MM30SJ4wAf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1713/Reviewer_1sX7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1713/Reviewer_1sX7"
            ],
            "content": {
                "summary": {
                    "value": "This paper discusses different types of embeddings and aggregation methods for neighboring 3D point clouds. By experimenting with different combinations on ScanObjNN and ScanNet, the author summarizes a set of best practices for designing new PNE."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The review of previous 3D point cloud embeddings is comprehensive and logical.\n\n2. The experiments and analysis on two tasks (classification and segmentation) are careful and in-depth."
                },
                "weaknesses": {
                    "value": "The improvement is not obvious compared to existing methods in Table 2 compared to 3. Does this mean the effect of PNE is less important when training data is less? I recommend to experiment on larger-scale 3D datasets for classification, such as Objverse, or other 3D tasks, such as indoor/outdoor 3D object detection. The two experiments on the paper is not sufficient enough to demonstrate the conclusion."
                },
                "questions": {
                    "value": "One related work investigating Sin for 3D classification is expected to be included and discussed: *Starting from Non-Parametric Networks for 3D Point Cloud Analysis* accepted by CVPR 2023."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1713/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698869384816,
            "cdate": 1698869384816,
            "tmdate": 1699636099819,
            "mdate": 1699636099819,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PUMF5a5dvb",
                "forum": "MM30SJ4wAf",
                "replyto": "6wMwrxkPil",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1713/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1713/Authors"
                ],
                "content": {
                    "title": {
                        "value": "New object detection task"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for the positive feedback and suggestions. In the following paragraphs, we would like to address the main concerns of the reviewer:\n\n**Improved not clear on Table 2**\n>We regret we were not able to communicate this point clearly.\n>In this paper, we do not aim to propose a new architecture or convolution to improve over existing methods.\n>We show instead that simple convolution for point clouds can provide competitive performance when compared to more recent and *complex* operations such as transformer architecture which use self-attention in their layers.\n>However, when compared to other architectures without self-attention, our method outperforms those by a significant margin (MinkowskiNet and lower).\n\n\n**Other 3D tasks**\n>Following the suggestion of the reviewer, we have trained our model with all PNE used in the paper on the task of object detection on the ScanNet dataset.\n>The results of this experiment are presented in the following table:\n\n|  Neigh | Emb.  | Type  |AP@25|AP@50|\n|---|---|---|---|---|\n|  BQ |  KP |  Box | 60.6  |  40.9 |\n|   |   | Trian  | 61.1  | 42.1  |\n|   |   | Gauss  |  **62.7** |  **42.2** |\n| | | | | |\n|   | MLP  | ReLU  | 58.1  | 37.0  |\n|   |   | GELU  |  **58.3** |  **38.0** |\n|   |   |  Sin |  56.5 |  33.9 |\n| | | | | |\n|   |  None |   |  56.5 | 34.4  |\n| | | | | |\n|  KNN | KP  | Box  | 61.3 |  40.2  |\n|   |   | Trian  | 62.0 |  40.0  |\n|   |   |  Gauss | **62.2** |  **42.2**  |\n| | | | | |\n|   |  MLP |  ReLU |  **56.2** |  **33.7**  |\n|   |   |  GELU | 55.9 |  33.6S  |\n|   |   |  Sin | 55.3 |  33.2  |\n| | | | | |\n|   | None  |   | 52.5 |  28.3  |\n\n>In this task, we can see the same trends reported for the tasks of classification and semantic segmentation. \n>KP embeddings provide an increased performance when compared to MLP-based embeddings. \n>Moreover, the continuous correlation function *Gauss* performs better in all cases compared to *Trian* for KP embeddings. \n>For the MLP embeddings, contrary to other tasks, *ReLU* activation function performs almost equally well as *GELU* activation function, and *Sin* under-performs.\n>Lastly, when we compare neighborhood selection, BQ still provides slightly better results than kNN as experienced in other tasks.\n>We have included such experiments in the Appendix.\n\n**Related work: Starting from Non-Parametric Networks for 3D Point Cloud Analysis**\n> We thank the reviewer for pointing out this relevant work.\n>We have included this reference when describing the sin activation function."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1713/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700641162307,
                "cdate": 1700641162307,
                "tmdate": 1700641162307,
                "mdate": 1700641162307,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]