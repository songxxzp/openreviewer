[
    {
        "title": "Unifying User Preferences and Critic Opinions: A Multi-View Cross-Domain Item-sharing Recommender System"
    },
    {
        "review": {
            "id": "T0U944SFuK",
            "forum": "Z7OWaSze0V",
            "replyto": "Z7OWaSze0V",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3010/Reviewer_c3D1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3010/Reviewer_c3D1"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors propose a Multi-View Cross-domain Item-sharing Recommendation (MCIR) framework that synergizes user preferences with critic opinions. The proposed MCIR achieves state-of-the-art performance on several real-world datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Utilizing critic review information for knowledge sharing across domains is interesting. \n\n- The proposed MCIR achieves state-of-the-art performance on several real-world datasets."
                },
                "weaknesses": {
                    "value": "- There are many incorrect formula details in the article. For example, the authors obtain covariance $\\Sigma$ via $W_T\u2019h_T + b_T\u2019 = diag(\\Sigma_t)$. However, $\\Sigma$ should be positive values. How to guarantee the output of $W_T\u2019h_T + b_T\u2019$ could be always positive? \n\n- Some model details are missing. For example, the authors adopt $g(\\cdot)$ as the activation function in Eq.(1). However, what kind of activation function do you use in the experiments? ReLU or Sigmoid? Moreover, the authors adopt the dropout layer in the Eq.(1). How about the dropout ratio for this layer? \n\n- Some formulas are completely wrong. For example, the authors obtain user distribution as $p(u_i|R_i) \\sim N(\\mu_i, \\Sigma_i)$. However, the reparameterization process in the paper is $u_i = \\mu_i+\\epsilon \\Sigma_i$. It is completely wrong. The correct answer is $u_i = \\mu_i+\\epsilon \\sqrt{\\Sigma_i}$.\n\n- The methodology is hard to follow with too many notations. I strongly encourage the authors to provide the pseudo algorithm table.\n\n- Some important baselines are missing, e.g., PTUPCDR.\n\n- The authors emphasize that critic reviews are much more valuable than common reviews. However, how to define whether the reviews are critic or not? \n\n- The dataset statistics are missing key information, e.g., number of overlapped users.\n\n- Can the proposed method handle different ratios of overlapped users (e.g., only 10% users are overlapped across domains)?\n\n======\nUpdate: \n\nI acknowledge that I have read the authors response. Although the idea of this paper is interesting, it still needs major revision on technically details (e.g., formula and symbol corrections) to make it more precise."
                },
                "questions": {
                    "value": "Please refer to the Weakness above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3010/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3010/Reviewer_c3D1",
                        "ICLR.cc/2024/Conference/Submission3010/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3010/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698157243559,
            "cdate": 1698157243559,
            "tmdate": 1700709958163,
            "mdate": 1700709958163,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ia6dFmBujb",
                "forum": "Z7OWaSze0V",
                "replyto": "T0U944SFuK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3010/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3010/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer c3D1"
                    },
                    "comment": {
                        "value": "We are thankful for your review and the opportunity to clarify aspects of our paper. Here are our responses to your concerns:\n\n1. Sorry for the confusion on data. First we want to clarify that, as detailed in Sections 1 and 4.1, and the Appendix, critic and user reviews in our dataset, sourced from Metacritic, are distinctly labeled, eliminating the need to differentiate between expert and amateur reviews. This dataset will be made publicly available upon paper acceptance.\n\n2. Also we want to clarify that there are no user overlaps in our datasets. As stated in the paper, our work focuses on cross-domain recommendations where different domains share items but not users or critics. The cross-domain in this paper means we leveraging auxiliary information from critic domain data for making better predictions in the user domain. Here 'domain' is defined on the item-level relevance, i.e., there are common items and different users between the targeted and auxiliary domains, as illustrated in the survey paper [1,2]. The auxiliary domain is critic domain and the targeted domain is user domain in this paper. We concur that this specific area remains relatively untapped compared to traditional user-sharing cross-domain recommendation, thus underscoring the significance of our contribution. We will add more explanation in the paper for revision.\n\nThe following is our responses to your questions:\n\nWeakness 1. The confusion regarding $diag{\\Sigma_{i}}$ is regrettable. In our code, $W_{T}'h_{T}+b_{T}'$ outputs the log variance, which we then convert to positive variance values using the 'torch.exp' function. This is a very frequently used trick in VAE style code. Since this is a common code trick, we did not mention it in the paper. We will add more explanations in the Appendix for revision.\n\nWeakness 2. The activation function in Eq.(1) is tanh in our experiments. We will add more details about it for revision. \nAs introduced in Section 4.1, we set the dropout ratio as 0.5 for the user-rating embedding network. \n\nWeakness 3. We appreciate your correction on the reparameterization formula. This will be amended in the revised paper.\n\nWeakness 4. Thanks for your suggestion. We will incorporate a pseudo algorithm table in the revised paper.\n\nWeakness 5. PTUPCDR assumes that there is overlapping users and no shared items, which is opposite to our focused scenario, i.e., item-sharing and no user overlaps. Therefore, PTUPCDR cannot be directly applied in our problem settings and not included in our baseline methods. \n\nWeakness 6. As mentioned, the distinction between critic and user reviews is inherent in our dataset with labels, negating the need for manual detection.\n\nWeakness 7. In our experiments, there are no overlapping users.\n\nWe sincerely appreciate your time and effort in reviewing our work. We hope our responses have satisfactorily addressed your queries. Given the initial misunderstanding regarding the data and cross-domain definition, if you find our clarifications adequate, we kindly request you to consider revising the rating for our paper.\n\n[1] Zang T, Zhu Y, Liu H, et al. A survey on cross-domain recommendation: taxonomies, methods, and future directions[J]. ACM Transactions on Information Systems, 2022, 41(2): 1-39. \n\n[2] Zhu F, Wang Y, Chen C, et al. Cross-domain recommendation: challenges, progress, and prospects[J]. arXiv preprint arXiv:2103.01696, 2021."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3010/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700088420761,
                "cdate": 1700088420761,
                "tmdate": 1700088420761,
                "mdate": 1700088420761,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "FS4loYjD1W",
            "forum": "Z7OWaSze0V",
            "replyto": "Z7OWaSze0V",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3010/Reviewer_3TsF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3010/Reviewer_3TsF"
            ],
            "content": {
                "summary": {
                    "value": "The authors introduced a multi-view cross-domain item-sharing recommendation algorithm to involve critic comment from users. They involved many techniques (e.g., GCN and contrastive learning etc) to obtain the user item aligned embeddings. Various baseline methods and datasets were investigated in the experiments. Results show the advantages of the proposed."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "S1. critic comment is a good idea to enhance recommendation in general\n\nS2. sufficient baselines were selected in experiments\n\nS3. Comprehensive experiments were conducted"
                },
                "weaknesses": {
                    "value": "W1. hard to follow the methodology\n\nW2. unclear definitions\n\nW3. critic comment is the one of the main contribution but it's not clear about how to define and how to detect critic comments"
                },
                "questions": {
                    "value": "Q1. It's hard to follow the methodology sections. Figure 2 doesn't help make it clearer. Instead it makes it more complicated to understand without knowing the meaning of letters and captions. I hope reading through text would help my understanding. However I still don't know why many steps are necessary and why so much components and techniques are required. For example, for definitions, what user-rating network, user-comment network, and critic embedding network. It seems that the final goal is to obtain user and item embeddings aligned in the same latent space. But by nature critic comment is hard to define and detect (please refer to the following question). It seems that contrastive loss and GCN are also included, but by checking Figure 2 are the left and right boxes decoupled? Do they have relationship? And what's their relationship?\n\nQ2. \u201cExperts Write More Complex and Detached Reviews, While Amateurs More Accessible and Emotional Ones\u201d How to know which review is written by an expert or an amateur? Or how to quantify the critic metric for a comment. The statement is also related to Section \"Critic Embedding Network\" where it mentioned critic rating prediction task. It seems to be based on the inner product of v_j and w_l^c. What does the latent critic-rating vector w_j^c come from?\n\n==========================\nI acknowledge that I have read the authors response. I appreciate the authors efforts. But it didn't address my concerns. I would keep my original rating."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3010/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3010/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3010/Reviewer_3TsF"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3010/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698796994147,
            "cdate": 1698796994147,
            "tmdate": 1700688387344,
            "mdate": 1700688387344,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "EbOnYG8Nji",
                "forum": "Z7OWaSze0V",
                "replyto": "FS4loYjD1W",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3010/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3010/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 3TsF"
                    },
                    "comment": {
                        "value": "Thank you for your response. We have checked them carefully and we have the following responses:\n\n1. Sorry for the confusion on data. First we want to clarify that, as detailed in Sections 1 and 4.1, and the Appendix, critic and user reviews in our dataset, sourced from Metacritic, are distinctly labeled, eliminating the need to differentiate between expert and amateur reviews. This dataset will be made publicly available upon paper acceptance.\n\n2. We apologize for any prior ambiguities regarding the components of the MCIR framework. \nThe MCIR framework is composed of four integral components, each contributing significantly to the methodology:\n\n* User Embedding Networks: This includes two sub-components - the user-rating embedding network and the user-comment embedding network. Their primary function is to learn latent user embeddings from both rating and comment perspectives, respectively.\n\n* Critic Embedding Networks: These networks are designed to concurrently learn latent critic embeddings from both rating and comment perspectives. This dual approach ensures a comprehensive representation of critic opinions.\n\n* Attentive Integrated Mechanism: This mechanism focuses on learning latent item embeddings. It plays a crucial role in transferring auxiliary critic text information into the user domain by enabling shared item embeddings.\n\n* Cross-View Unified Learning with Contrastive Learning: This component is essential for leveraging neighborhood information across user and critic domains. The incorporation of contrastive learning here enhances the effectiveness of using cross-domain neighborhood information to refine the latent user and item embeddings.\n\nThe attentive integrated mechanism and cross-view unified learning collectively ensure a robust transfer and utilization of critic information from both the text and graph views.\nWe have provided a comprehensive ablation study in Section 4.3 and the Appendix, which demonstrates the importance of each component.\nIn response to your concerns, we will clarify the main components of the MCIR framework and add more intuitive and descriptive explanations when introducing the modules' details in the revised version of our paper.\n\n3. Regarding Figure 2, the left and right boxes are interconnected via the final latent embeddings $p_i$ and $q_j$, which are trained through both the VAE loss in Equation 9  and the contrastive learning loss in Equation 13.\nWe will try to modify the Figure 2 for better illustration.\n\n4. As outlined in Section 3.3, the latent critic-rating vector $w_l^c$ is derived from the latent critic vector $u_l^c$ using a single-layer MLP network ($w_l^c = f_w(u_l^c)$). The vector $u_l^c$ is initially randomly initialized and then refined through iterative learning.\n\nIt appears that there may be some misunderstandings about our work. We sincerely hope that our responses have addressed your concerns and clarified any points of confusion. If you have any further questions or require additional clarification, please do not hesitate to reach out to us."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3010/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700088224633,
                "cdate": 1700088224633,
                "tmdate": 1700088376696,
                "mdate": 1700088376696,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Ck7tohYdfj",
            "forum": "Z7OWaSze0V",
            "replyto": "Z7OWaSze0V",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3010/Reviewer_Pmes"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3010/Reviewer_Pmes"
            ],
            "content": {
                "summary": {
                    "value": "The authors proposed to explore a less explored scenario: cross-domain recommendation with distinct user groups, sharing only item-specific data. Towards this end, they proposed a multi-view cross-domain item-sharing recommendation framework that leverages user reviews, critic comments, item summaries, user ratings, and critic ratings. They collected a dataset with three domains, namely Game, Movie, and Music from Metacritic and compared with multiple baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The cross-domain recommendation problem with distinct users across domains is an interesting yet overlooked problem. The authors took a look at this problem and proposed a complicated model that uses multiple types of data to solve it.\n2. The proposed model showed good performance under the authors' setting and outperformed all baselines. Modeling-wise, this provides some insight into what is worth trying and effective in similar problems and can inspire more innovative solutions."
                },
                "weaknesses": {
                    "value": "1. First of all, the authors did not do a good job of clearly formulating the problem they want to solve. I felt confused after I went over the paper for the first two times. When I first read it, I thought they were trying to do cross-domain recommendations when different domains shared items but not users, which is counter-intuitive. Then I realized it's critic that is shared by different domains. I recommend the authors state this very explicitly and use some space to formulate the problem using some formulas. Besides, the phrase \"item-sharing\" in the title is quite misleading.\n2. In experiments, did the authors use data from two datasets for training and then predict the rating for the 3rd dataset? How does the evaluation of \"Cross-domain\" recommendation work in this paper? I did not quite understand after reading Section 4.1.\n3. Besides the experiment section, this paper also needs more clarity in its description of the proposed model can be further improved to get better readability. Questions related to this can be found in the next section."
                },
                "questions": {
                    "value": "1. Shouldn't the $y_{lj}$ in the left up corner of Figure 2 be $y^c_{lj}$?\n2. In the user embedding network, why is $R_i$ used to construct $u_i$ instead of the other way around, using $u_i$ to generate $R_i$? The authors may have their rationale for designing the model in this way. But they failed to explain it clearly to the readers.\n3. The explanation of the \"attentive integrated mechanism\" seems to be over-complicated to me. It actually follows the standard design of the attention mechanism with $v_j$ as the query vector and $w^c_l$ as the key and value vector. The introduction of $L_j$ and $w^c_0 = v_j$ does not seem to be necessary and only added complexity.\n4. In the same section, the first sentence says \"Given that only the items are shared between the critic and user domains\". I believe the word \"domain\" does not mean the cross-domain studied in this paper is trying to cross the \"user\" and \"critic\" domains.  Am I right?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3010/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3010/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3010/Reviewer_Pmes"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3010/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699343687071,
            "cdate": 1699343687071,
            "tmdate": 1700499964970,
            "mdate": 1700499964970,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3kpzrSDvCu",
                "forum": "Z7OWaSze0V",
                "replyto": "Ck7tohYdfj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3010/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3010/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Pmes"
                    },
                    "comment": {
                        "value": "We are grateful for the opportunity to clarify key points in our paper. Below, we address your concerns and provide further explanations:\n\n1. First, we are sorry for any ambiguity regarding the term 'cross-domain' in our context. Our work indeed focuses on cross-domain recommendations where different domains share items but not users or critics. Critics are not shared by different domains. \n\nTraditionally, cross-domain recommendations have been usually defined in the way that users are sharing across different domains in the literature. However, as evidenced by the survey paper [1] and [2] (please see the Figure 1 and Table 1 in [1]), it's essential to recognize that recommendations integrating distinct user groups with full item overlap also fall under the cross-domain recommendation umbrella [1][2][3]. As stated in the paper, the cross-domain in this paper means we leveraging auxiliary information from critic domain data for making better predictions in the user domain. Here 'domain' is defined on the item-level relevance, i.e., there\nare common items and different users between the targeted and auxiliary domains, as illustrated in the survey paper [2]. The auxiliary domain is critic domain and the targeted domain is user domain in this paper. We concur that this specific area remains relatively untapped compared to traditional user-sharing cross-domain recommendation, thus underscoring the significance of our contribution. We will add more explanation in the paper for revision.\n\n2. In our experiments, we train and test the model on each dataset independently. There is no data sharing among the three datasets. MCIR can outperform all the baseline methods, demonstrating the effectiveness of our cross domain leaning approach.\n\nThe following is our responses to your questions:\n\nQuestion 1. Thank you. $ y_{lj} $ should be $ y_{lj}^c $ in the left up corner of Figure 2. We will correct this in the revised paper.\n\nQuestion 2. As stated in the paper, the user embedding network belongs to the encoder part of the VAE architecture. Hence we use $R_i $ to construct $ u_i $ but not using $ u_i $ to generate $R_i $. The latter is suitable for the decoder part of VAE. We will add more explanation in the revised paper.\n\nQuestion 3. Sorry for the confusion around the introduction of $L_j$ and $w_{0}^c=v_j$ in Equation 6. These elements are meant to simplify the mathematical expression. Without the help of $ L_j $ and $ w_{0}^c=v_j $, Equation 6 will look much more complex. According to your comment,  we will refine our explanation of the attentive integration mechanism, particularly focusing on the roles of key, query, and value vectors.\n\nQuestion 4.  As previously mentioned, our study defines 'cross-domain' as leveraging critic domain data to enhance user domain predictions. Critics, often from professional media institutions, and users, typically ordinary web contributors, represent distinct groups without overlap. Our study bridges these 'user' and 'critic' domains in a novel cross-domain approach.\n\nWe sincerely appreciate your time and effort in reviewing our work. We hope our responses have satisfactorily addressed your queries. Given the initial misunderstanding regarding the cross-domain definition, if you find our clarifications adequate, we kindly request you to consider revising the rating for our paper.\n\n[1] Zang T, Zhu Y, Liu H, et al. A survey on cross-domain recommendation: taxonomies, methods, and future directions[J]. ACM Transactions on Information Systems, 2022, 41(2): 1-39. \n\n[2] Zhu F, Wang Y, Chen C, et al. Cross-domain recommendation: challenges, progress, and prospects[J]. arXiv preprint arXiv:2103.01696, 2021.\n\n[3] Gao C, Li Y, Feng F, et al. Cross-domain recommendation with bridge-item embeddings[J]. ACM Transactions on Knowledge Discovery from Data (TKDD), 2021, 16(1): 1-23."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3010/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700088044366,
                "cdate": 1700088044366,
                "tmdate": 1700088044366,
                "mdate": 1700088044366,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sfCj1AVAKv",
                "forum": "Z7OWaSze0V",
                "replyto": "3kpzrSDvCu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3010/Reviewer_Pmes"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3010/Reviewer_Pmes"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the responses.\n\nto Answer 1: can you list a few concrete examples of \"cross-domain recommendations where different domains share items but not users\"? Asking because examples can help readers build an intuitive understanding of why this is an important problem to study and why it is challenging.\n\nto Answer 2:  did you mention you \"train and test the model on each dataset independently\"? If yes, can you point me to it? If not, it's necessary to add it.\n\nThanks!"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3010/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700437244680,
                "cdate": 1700437244680,
                "tmdate": 1700437244680,
                "mdate": 1700437244680,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5McBxGdXlo",
                "forum": "Z7OWaSze0V",
                "replyto": "PhQ5rJLUEJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3010/Reviewer_Pmes"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3010/Reviewer_Pmes"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the detailed response! I'd like to move up my rating. The authors did propose a very effective approach, however, the paper overall, especially its presentation, may not be good enough for ICLR yet."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3010/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700500337200,
                "cdate": 1700500337200,
                "tmdate": 1700500337200,
                "mdate": 1700500337200,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "WOy9PWP8ik",
            "forum": "Z7OWaSze0V",
            "replyto": "Z7OWaSze0V",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3010/Reviewer_6fW2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3010/Reviewer_6fW2"
            ],
            "content": {
                "summary": {
                    "value": "The paper builds a cross domain recommender system that leverages ratings and reviews from users belonging to different groups, and item descriptions. In particular, the different groups share no common users while makes the problem of information transfer across them more difficult. The paper builds an elaborate system with multiple components to overcome this challenge and obtains SOTA results."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The problem is well motivated \n2. The paper is written clearly\n3. The results beat SOTA by a good margin on the given datasets"
                },
                "weaknesses": {
                    "value": "The centra weakness is the lack of a detailed study of its individual components. For a system, that has as many components as this one, it is crucial to measure the relative importance of each. While the paper has some study ablation studies I do not think they are exhaustive (please see questions below). For instance,\n\n1. How useful is the attentive module? For instance what if all $v^a_j = 0$?\n2. How useful is the graph network $\\left(\\eta_3 = \\eta_4 = 0\\right)$  ?\n3. Why not also use a VAE in the critic embedding network for training $u_l^c$. Conversely why not use the (analogous) first term in equation of 5 in equation 3, and just not use the VAE at all? Could you please elaborate.\n\n\nIt is difficult to assess the impact of the proposed method (in terms of scope, generalizability, etc.) without understanding the value of its components."
                },
                "questions": {
                    "value": "1. What are $\\eta_n,\\eta_s, \\eta_c$? From the context I seem to gather that $\\eta_n = \\eta_4$?\n\n2. What does ablation study C1 mean? Does that mean neither critic comments or user comments or item summary text are used? \n\n3. Similarly, what does C2 mean?\n\n4. Does C3 mean making $\\mathcal L_{Multi} = 0, v^a_j = 0$ and excising all the critic-item edges from the graph?\n\n5. Does C4 mean, $\\eta_4 =0 $?\n\n6. How does the proposed method compare with the best prior methods (say BitGCF, EMCDR, SSCDR) in terms of training time, number of parameters, and inference cost?\n\n7. [Minor] In equation 7, one could catenate and then project? Do you think that could lead to substantial gains?  \n\n8. [Minor] Is there a reason the decoder network is chosen to be as simple as eq. 8? Needless to say, simple is good. But wondering if there are other motivations.\n\n9. [Broad] It seems there are existing datasets used by prior baselines (ML-NF dataset). Is there a reason for not choosing it over Metacritic (or for that matter, using both)?\n\nFor all the ablation questions, please answer in terms of what happens to equation 14, wherever possible."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3010/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699471880270,
            "cdate": 1699471880270,
            "tmdate": 1699636245313,
            "mdate": 1699636245313,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MnJOMQm1EM",
                "forum": "Z7OWaSze0V",
                "replyto": "WOy9PWP8ik",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3010/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3010/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 6fW2"
                    },
                    "comment": {
                        "value": "We greatly appreciate your insightful feedback and recognition of the strengths in our paper, particularly the well-motivated problem statement and our system's ability to surpass state-of-the-art results. Below, we have addressed your concerns in detail:\n\nWeakness 1: The attentive integration mechanism is essential in combining item-summary information with critics' commentary as it adaptively aggregates information, reflecting the varying influences of item summaries and critics\u2019 comments on item characteristics. We have included two case studies in Appendix Section D, demonstrating its effectiveness. In response to your suggestion, we introduce a new variant, MCIR-C6, employing simple average of item-summary vector $v_j^s$ and critic vectors $w_{l}^c$ instead of attentive integration. The comparative results on MC-Game are as follows:\n\nMethods R@5 P@5 MAP@5 NDCG@5\n\nMCIR-C6 0.1050 0.0845 0.0545 0.1172\n\nThese results clearly show the superior performance of MCIR over MCIR-C6, affirming the value of the attentive integration mechanism. Regarding the query \u201cwhat if all $v_j^a=0$?\u201d, in practice, $v_j^a$ will not be zero since the item-summary vector is always present. The variant MCIR-C2, which replaces $v_j^a$ with the item-summary vector $v_j$, underperforms compared to MCIR as shown in Figure 3(a). This further highlights the importance of the review text information alongside the attentive integration mechanism. We plan to include MCIR-C6 in our revised ablation study and provide an in-depth discussion of the attentive integration mechanism.\n\nWeakness 2: Actually, the variant MCIR-C4 is set as $\\eta_3=\\eta_4=0$. Note that the graph embeddings can only influence the final latent user and item representation $p_i $ and $q_j $ by the contrastive learning loss  $ \\mathcal{L}_{CL} $. \n\nSo when we set $\\eta_4=0$, the GCN loss $\\mathcal{L}_{Graph}$ is irrelevant to the predictions, which can also be viewed as $\\eta_3=0$. We will elaborate on this in the revised manuscript.\n\nWeakness 3: In our study, we focus on leveraging the auxiliary critic domain to enhance user domain predictions. To avoid overcomplicating the probabilistic derivation process, we did not use a VAE in the critic embedding network. Note that $v_j^a$ is involved in the loss function $\\mathcal{L}_{VAE}$, implicating $u_l^c $ in the VAE's ELBO for $u_i$. Employing two VAEs for $u_i$ and $ u_l^c $ would significantly complicate the VAE Loss due to their interdependence. Thus, we opted for a VAE solely in the user domain but not the auxiliary critic domain. \n\nAs for your concern \u201cwhy not use the (analogous) first term in equation of 5 in equation 3\u201d, this is because equation 5 is for concurrently learning the latent critic-rating and critic-comment vectors while equation 3 is only for learning the User-Comment vectors. The first term in equation of 5 is for learning critic-rating vectors. As discussed in the paper, given the diverse nature of user comments and their potential limited correlation with item property evaluations [1,2,3] and significant correlation exists between critics' scores and their explanatory comments [1,2], we opt for independent learning for users while concurrent learning for critics. According to your comments, we will expand on the rationale behind the loss design in our revised version.\n\nResponse to Questions:\n\nQuestion 1: We apologize for the typos. $\\eta_s$ should be $\\eta_1$, $\\eta_c$ should be $\\eta_2$, and $\\eta_n$ should be $\\eta_4$. These will be corrected in our revised paper.\n\nQuestion 2: Sorry for the confusion on the ablation study C1. It excludes review text information for both user and critic embedding networks. Specifically, we set the user-comment vector $w_i=0$, and the loss $\\mathcal{L}_{MSE}$ is not applied. \n\nAdditionally, the term $| y_{lj}^c-z_{lj}^c|  ^2$ is omitted in the loss $\\mathcal{L}_{Multi}$. We also replace $v_j^a$ with the item-summary vector $v_j$. More details will be provided in the revised version.\n\nQuestion 3: Ablation study C2 involves replacing $v_j^a$ with the item-summary vector $v_j$.\n\nQuestion 4: Ablation study C3 involves not applying the loss $ \\mathcal{L}_{Multi} $ and replacing $v_j^a$ with $v_j$. \n\nAdditionally, all critic-item edges are omitted from the graph for the loss $\\mathcal{L}_{Graph}$.\n\nQuestion 5: Yes. Ablation study C4 mean $\\eta_4=0$.\n\nOwing to the constraints of space, we will provide the remaining responses in our subsequent reply."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3010/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700088145416,
                "cdate": 1700088145416,
                "tmdate": 1700088145416,
                "mdate": 1700088145416,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "roSY1Bt8tE",
                "forum": "Z7OWaSze0V",
                "replyto": "KTuENvS0Qj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3010/Reviewer_6fW2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3010/Reviewer_6fW2"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarifications. Please include them (and more) in the main draft. There are several parts in the pipeline, and it is hard for the first time reader to appreciate the value, need and intuition for the individual parts. \n\nFor Question 2 above, do you also mean to set $w^c_l =0$ in $\\mathcal L_{multi}$? These changes do make me more optimistic about the paper.."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3010/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700604223707,
                "cdate": 1700604223707,
                "tmdate": 1700604223707,
                "mdate": 1700604223707,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]