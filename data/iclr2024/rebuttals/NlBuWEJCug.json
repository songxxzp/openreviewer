[
    {
        "title": "PcLast: Discovering Plannable Continuous Latent States"
    },
    {
        "review": {
            "id": "54rUxhrDnw",
            "forum": "NlBuWEJCug",
            "replyto": "NlBuWEJCug",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3799/Reviewer_wVZj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3799/Reviewer_wVZj"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new way to learn \"plannable\" representations. Multi-step inverse dynamics models have the desirable property that the learned representations are guaranteed to contain only the \"controllable\" parts of states. However, they do not necessarily maintain a metric structure, and this lack of distance metrics makes it difficult to use for planning. To resolve this issue, the authors train a contrastive representation on top of the multi-step inverse dynamics-based representations to impose a metric structure. The authors show that this PCLast representations are indeed aware of the inherent temporal structure of the MDP, and that it leads to better performance in several types of environments."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This work tackles the important problem of learning minimal representations that maintain sufficient information for control while having a metric structure. As far as I'm aware, this approach is the only such method (please correct me if not).\n- The imposed metric structure enables hierarchical planning based on L2 distances on the representation space, and the authors show that this planning is indeed helpful for performance.\n- The paper is well-written and easy to understand."
                },
                "weaknesses": {
                    "value": "- The proposed method is highly complicated, involving five moving components: a forward dynamics model (FDM), a multi-step inverse dynamics model (IDM), a contrastive representation learner (CL), a hierarchical graph-based planner, and a low-level MPC planner, with several newly introduced hyperparameters for each module. While I see the motivation behind this approach (i.e., we want to first eliminate all the uncontrollable parts, and then impose a metric on another latent representation space), I'm not fully convinced that all of these components are necessary in practice (see the next bullet points for more specific concerns).\n- In the Maze/Sawyer domains, the authors only compare PCLast with ACRO. Given the high complexity of the method, I think it is necessary to show that PCLast is at least better than all the \"basic\" representations that are used as building blocks for PCLast, i.e., IDM, CL, and FDM, to justify the added complexity.\n- The performance of ACRO (the best baseline considered in this work) on the exogenous noise MuJoCo environments seems to be worse than the original performance reported in Islam et al. (2023) (e.g., in `cheetah_run_expert`). Could the authors explain this performance gap? Moreover, given the complexity of PCLast, I believe it requires more thorough empirical comparisons to demonstrate the effectiveness of PCLast (e.g., comparisons on the same set of environments (12 datasets x n distractor configurations) used in ACRO).\n- Also, while the only \"non-toy\" benchmark considered in this work is MuJoCo in Section 4.5, it is unclear how planning helps on MuJoCo tasks (since hierarchical planners seem to be only used in the Maze environments). Given that the main benefit of PCLast is its ability to plan (as the title says), I believe it would be much more convincing if the authors could show this benefit in more practical environments.\n\n[Minor]\n- The paper is using the ICLR 2023 format.\n- Typo (small $\\\\\\|$) after \"we formulate the cost as\" in Appendix D.\n\nI believe this is a borderline paper. While I appreciate the motivation behind PCLast, the empirical results are not strong/extensive enough to justify the need for all five components of PCLast."
                },
                "questions": {
                    "value": "- What does LNS stand for in Appendix A?\n- In Section 3.4, why do the authors use $\\phi$ (the inverse dynamics model representation) instead of $\\psi \\circ \\phi$ (the PCLAST representation)? Perhaps it is just a typo?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3799/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698110624374,
            "cdate": 1698110624374,
            "tmdate": 1699636337403,
            "mdate": 1699636337403,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Bi6A8pa0gU",
                "forum": "NlBuWEJCug",
                "replyto": "54rUxhrDnw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3799/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3799/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "> \u201c... highly complicated, involving five moving components \u2026\u201d\n\nYes, it may be possible to eliminate some components under certain conditions. But, in principle, each component of our method plays its own critical role for real-world scenarios i.e. multi-step inverse dynamics helps in learning exogenous noise free representation, forward dynamics helps with planning during inference , temporal contrastive representation helps with retaining metric space, hierarchical planner reduces plan computation time and robustifies it, and low-level MPC planner helps in navigating to a goal state. Please note, hierarchical planner and low-level MPC are non-learning components of our approach. They are required as we are in a reward-free setting and don\u2019t learn any policy. \n \nIn the future, we can consider potential approaches of merging these components into a single module. Also, if there is no exogenous noise, one can probably ignore inverse-dynamics.\n \n>  \u201c\u2026 PCLast is at least better than all the basic representations\u2026 \u201d.\n\nIn ACRO, authors have shown that their method works better than IDM and FDM. This is the reason that we focus on simply comparing it with ACRO and show limitations of ACRO.\n \n> \u201c  The performance of ACRO (the best baseline considered in this work) on the exogenous noise MuJoCo environments seems to be worse than the original performance reported in Islam et al. (2023) (e.g., in cheetah_run_expert). Could the authors explain this performance gap? \u201c\n\nIn this paper, we evaluated on the hardest exogenous noise setting from the ACRO paper, which is called \u201cHARD-EXO-Background Agent\u201d, these are in Figure 20 of that paper\u2019s appendix.  Our ACRO baseline is very similar to the numbers reported in that paper.   \n      \n>   \u201c... how planning helps on MuJoCo tasks\u2026 \u201d\n\nWhen it comes to MuJoCo tasks, we simply focus on the method\u2019s ability to learning a better representation than baselines. This empirically shows improvement in policy learning. This is also an example, where not all the components of our method are required to be used since the considered mujoco-tasks are not goal-conditioned.\n \n>   \u201c...The paper is using the ICLR 2023 format\u2026\u201d\nWe have fixed this.\n \n>   What does LNS stand for in Appendix A?\n\nLNS refers to \u201cLocal Neighbourhood Structure\u201d which is enforced by the contrastive loss in Section 3.3. We have updated the text to be more clear about it.\n\n> \u201c...authors use  (the inverse dynamics model representation) instead of  (the PCLAST representation)...\u201d\n      \nYes, we use IDM representation in our work. Though, one can consider PcLast representation as well. The prime use of PcLast representation is to estimate distance between two states when planning."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3799/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700697106354,
                "cdate": 1700697106354,
                "tmdate": 1700697106354,
                "mdate": 1700697106354,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "htsoJTEMaF",
                "forum": "NlBuWEJCug",
                "replyto": "Bi6A8pa0gU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3799/Reviewer_wVZj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3799/Reviewer_wVZj"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the response. I appreciate the roles of the five components, and agree that all of them are potentially useful in theory. However, I\u2019m still not convinced that the newly added components, especially planning and contrastive learning (the main novelties of this work), play crucial roles _in practice_. I checked Figure 20 of the ACRO paper, but there still seems to be a significant gap between the original ACRO results and the results in this paper. Particularly, in `cheetah_run_medium_expert`, the original ACRO performance appears to be even better than that of PCLast. Moreover, even if PCLast outperforms ACRO in these settings, I still believe the empirical results are not comprehensive enough to justify the effectiveness of the new components given the small number (3) of \"non-toy\" tasks (in contrast, ACRO uses 84+). I maintain my rating this time."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3799/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700706443240,
                "cdate": 1700706443240,
                "tmdate": 1700706443240,
                "mdate": 1700706443240,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "BW4BpMpXgs",
            "forum": "NlBuWEJCug",
            "replyto": "NlBuWEJCug",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3799/Reviewer_uCK9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3799/Reviewer_uCK9"
            ],
            "content": {
                "summary": {
                    "value": "Latent representations of high-dimensional state spaces are a useful tool for\nreinforcement learning, but existing approaches do not model structural\ninformation about the environment. This paper proposes a new representation\nlearning approach, PCLaSt which ensures that states which are near each other in\nthe latent space have certain reachability properties. This is accomplished\nusing a secondary network to transform the latent space which is trained with a\ncontrastive loss. Enforcing reachability constraints on the state-space\nrepresentation is particularly useful in conjunction with hierarchical planning\nalgorithms, which rely on coherence between high- and low-level state-space\nabstractions. Experimental results show that PCLaSt in combination with\nhierarchical planning achieves much better performance than existing\nlatent-space learning approaches for goal-directed RL. PCLaSt also achieves\nhigher rewards in the presence of exogenous noise compared to baselines."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The algorithm is clean and well-presented, and the idea of using Brownian motion\nto generate samples to learn reachability constraints is interesting.\n\nThe fact that PCLaSt can be used for both deep RL and more traditional path\nplanning (Table 1) demonstrates a good level of flexibility and suggests broad\npotential impact.\n\nThe experiments which are presented show promising results, in particular\ndemonstrating better conformance between the latent space representation and the\ntrue dynamics of the environment (Figure 4)."
                },
                "weaknesses": {
                    "value": "There are a several experiments for which results are not presented which I think\nare necessary to clarify the benefits of this approach. In particular, the related\nwork lists HOMER and DRIML as methods which attempt to encode reachability\ninformation in the latent space. However, these techniques are only included in\nthe experiments on exogenous information, and not in the experiments on\ngoal-conditioned RL. Similarly, I'd be interested in the results you can obtain\nusing the hierarchical planner with alternative latent space learning techniques\nbesides PCLaSt.\n\nMore generally, I'm a bit confused by the relation of PCLaSt to HOMER and DRIML.\nThe related work section argues that these two approaches are different from\nPCLaSt because they don't deal with exogenous noise. However, in the technical\ndevelopment of the paper, it seems that the denoising effects are due primarily\nto ACRO, whereas the contribution of PCLaSt is primarily in enforcing\nstate-space geometry.\n\nOn a more minor notes, while the presentation is generally clear there is one\nomission that I found confusing at first. In Section 3.3, the process for\ngenerating samples for the contrastive loss omits a description of how $s_t$ and\n$s_{t+k}$ are generated based on $y$."
                },
                "questions": {
                    "value": "In general, reachability is not symmetrical (for example, it will not be\nsymmetrical in systems with momentum). However, the contrastive loss in Equation\n2 minimizes the (symmetrical) distance between states when one is reachable from\nthe other. Is there a theoretical or intuitive reason that this mismatch\nwouldn't hinder planning in systems with highly non-symmetrical reachability\nproperties?\n\nFrom my understanding of the paper, it seems that the noise filtering effects of\nPCLaSt are largely shared with ACRO. Is there some explanation of why PCLaSt\nseems to be so much more effective in Figure 6?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3799/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3799/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3799/Reviewer_uCK9"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3799/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698633837749,
            "cdate": 1698633837749,
            "tmdate": 1699636337328,
            "mdate": 1699636337328,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "uUp1iHNR9n",
                "forum": "NlBuWEJCug",
                "replyto": "BW4BpMpXgs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3799/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3799/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": ">  \u201c\u2026 HOMER and DRIML \u2026\u201d\nWe primarily compete and build upon ACRO as it showed that it does better than HOMER and DRIML to remove exogenous noise.  Note that HOMER uses a leveled structure which is unwieldy in practice (it\u2019s a theoretical algorithm) and DRIML uses rewards so it requires a different information access structure than PCLast to apply.\n \n> \u201c\u2026 Hierarchical Planner with other latent state spaces\u2026\u201d\nAs we investigated with other latent-state representations, we found that they lead to poor clustering of states for abstraction as shown for ACRO in Fig 1 (b) and Fig 4 ( third-row); making them unsuitable for further investigation.\n \n> In general, reachability is not symmetrical (for example, it will not be symmetrical in systems with momentum). However, the contrastive loss in Equation 2 minimizes the (symmetrical) distance between states when one is reachable from the other. Is there a theoretical or intuitive reason that this mismatch wouldn't hinder planning in systems with highly non-symmetrical reachability properties?\n      \nThis is an interesting aspect, and we can consider investigating it further in future work. One probable approach would be extend our current loss with weighted loss based on some reachability score of states in a trajectory.\n \n> \u201c\u2026PCLaSt seems to be so much more effective in Figure 6?\u201d\nPCLast helps in learning representation which maintains metric space between states. Intuitively, this eases the inter and extrapolation between states for policy, helping with better generalization."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3799/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700696974316,
                "cdate": 1700696974316,
                "tmdate": 1700696974316,
                "mdate": 1700696974316,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LMej4L5Ao4",
            "forum": "NlBuWEJCug",
            "replyto": "NlBuWEJCug",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3799/Reviewer_Gktz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3799/Reviewer_Gktz"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a method for learning a hybrid continuous-discrete representation that supports hierarchical planning. The first component of the method is an image encoder that learns a latent space using an inverse modeling loss. The second component is an additional encoder that re-projects the latent space so that it can be clustered using k-means; this additional encoder is trained using time-contrastive learning. The third component is a forward model learned in the latent space. Finally, a hierarchical planner finds the shortest path through state clusters and a low-level planner takes care of transitioning between clusters. The system is tested in various maze-like and continuous control environments. Experiments include varying the number of levels in the hierarchy."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "I reviewed a previous version of this paper.\n\n1. I appreciate the work that went into improving this paper since its last version. The paper now contains extensive experiments including a diverse set of domains and several different learning scenarios.\n\n2. The paper proposes a very interesting combination of multiple latent spaces and losses to support hierarchical planning. I find this to be an important problem in RL and robotics.\n\n3. The method is demonstrated in online and offline reinforcement learning in several different environments."
                },
                "weaknesses": {
                    "value": "1. The first main contribution is a new contrastive loss function. Although I like the justification of the loss function through the model of Brownian motion (Appendix B), there are several previously proposed loss functions that seem to solve the same problem. Specifically, the two time-contrastive loss functions I list below pull embeddings of frames nearby in time together and push embeddings of frames far away in time or from completely different videos apart. In the related work, the authors state that time-contrastive learning \u201cis not invariant to exogenous information\u201d, but neither is the proposed loss function. Invariance to exogenous information is achieved by first training the latent space using a prior method, ACRO.\n\nThe loss function proposed in this paper:\n$- \\log \\sigma ( \\beta - \\alpha D(s_t, s_{t+k}) ) - \\log (1 - \\sigma ( \\beta - \\alpha D(s_t, s_r) ) )$\n\nWang et al., 2015:\n$max(0, D(s_t, s_{t+k}) - D(s_t, s_r) + m)$\n\nNair et al., 2022:\n$- \\log \\frac{\\exp S(s_t, s_{t+k}) }{\\exp S(s_t, s_{t+k}) + \\exp S(s_t, s_{t+k+l}) + \\exp S (s_t, s_r)}$\n\nWhere $D$ is a distance function and $S$ is a similarity function between a pair of states.\n\n2. The second main contribution is the entire system of first learning an encoder $\\phi$ using an inverse dynamics loss function, followed by a contastively-learned encoder $\\psi$, followed by a forward model, followed by K-means clustering, followed by a hierarchical planner. I would like to see more justification of this approach. For example, the combination of $\\psi(\\phi(x))$, where $\\phi$, is trained first and frozen, is not fully justified. Could we train a single encoder with multiple losses? Further, the choice of the hierarchical clustering and planning methods could be compared to other hierarchical systems (e.g. Kurutach et al., 2018).\n\n3. (Relatively minor) From the introduction to the methods section, the paper does not flow very well. I think the reason is that the paper lacks focus on its key contribution. If the key contribution was a new and well-justified contrastive learning function, the paper could be written differently. If the key contribution was a system of learning a hierarchical latent space, the paper could also be written differently. This might be just a matter of personal taste, so feel free to disregard.\n\nMinor:\n\n* Should \u201c\u03c4 \u226b t \u226b t0\u201d be \u201c\u03c4 >= t >= t0\u201d?\n* As I stated in my previous review, the proof of Proposition 1 contains the term $P_k(z\u2032|z\u2032, y = 1)$, which I think is a typo since $z\u2019$ appears twice?\n\nReferences:\n\nWang et al., 2015: https://arxiv.org/abs/1505.00687\n\nNair et al., 2022: https://arxiv.org/abs/2203.12601\n\nKurutach et al., 2018: https://arxiv.org/abs/1807.09341\n\n**Post rebuttal:** Thank you for answering my questions! Unfortunately, I do not think this paper can be accepted without more comparisons to prior time-contrastive learning losses as well as prior hierarchical learning methods. I highlighted these in my review. Nevertheless, I believe the work addresses an important problem and is eventually going to be a strong submission."
                },
                "questions": {
                    "value": "1. How does your proposed loss function compare to the previously proposed time-contrastive learning losses?\n\n2. Is it possible to train a single state encoder using both the inverse dynamics and contrastive learning losses?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3799/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3799/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3799/Reviewer_Gktz"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3799/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698868725081,
            "cdate": 1698868725081,
            "tmdate": 1700877104025,
            "mdate": 1700877104025,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "019UGRuYQ5",
                "forum": "NlBuWEJCug",
                "replyto": "LMej4L5Ao4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3799/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3799/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "> How does your proposed loss function compare to the previously proposed time-contrastive learning losses?\n \nOn Wang et. al, the use of a margin is likely to be sufficient for using the representations downstream for classification, but isn't likely to work for capturing the precise numerical details in state position that are needed for control. On the Nair 2022 loss, likewise, a similarity won't necessarily yield a correct local neighborhood structure.\nNonetheless these are closely related and citations have been added, thanks for pointing these out.  \n \n> Is it possible to train a single state encoder using both the inverse dynamics and contrastive learning losses?\n \nThere are known counterexamples where mixing contrastive temporal and multi-step inverse leads to contamination of the latent state with exogenous noise.  Even a small weighting on contrastive temporal in a mixed loss create this contamination effect."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3799/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700696538237,
                "cdate": 1700696538237,
                "tmdate": 1700696538237,
                "mdate": 1700696538237,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "N3Zg9Dsinc",
            "forum": "NlBuWEJCug",
            "replyto": "NlBuWEJCug",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3799/Reviewer_AtR8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3799/Reviewer_AtR8"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a state representation learning approach, PCLaSt, which associates state reachability so that nearby and reachable states can be clustered together in the latent space. This learned representation can be directly used for online and offline RL, especially for goal-reaching tasks. Moreover, with this reachability-aware latent representation, we can efficiently find a path from one state to another by clustering the latent states, forming a graph of the clusters with their connectivity (reachability), and running Dijkstra's algorithm on the graph. The experiments on 2D maze navigation and 3D Sawyer reaching show that the proposed representations improve goal-reaching task performances in diverse RL settings."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The paper is very well written. The motivation and the proposed approach are easy to understand.\n\n* The idea of embedding reachability into state representations is intuitive and its implementation with contrastive learning is straightforward.\n\n* Visualization in Figure 1 and Figure 4 is very helpful in understanding how useful the latent states PCLaSt could learn."
                },
                "weaknesses": {
                    "value": "* Throughout the paper, there are several symbols used to denote different levels of latent states. However, each of the symbols $x$, $z$, and $s$ sometimes means different levels of abstraction. It might be easier to follow if each symbol is used to represent a single entity and a summary of these symbols is illustrated as a figure or list. If I didn't understand correctly, the paper writing could be improved to make it straightforward.\n\n* The proposed approach makes sense in 2D/3D navigation domains where reachability can be represented with a very low dimensional (2D/3D) latent space. However, it is unclear whether this also applies to more complicated environments with high-dimensional C-space, e.g., robotic manipulation with many objects. If the proposed method is not scalable but still useful for navigation tasks, the paper needs to explain which family of problems can be handled by the proposed approach and which family of problems cannot.\n\n* The proposed planner assumes that latent states in the same cluster are reachable from each other, which may not be true since the latent state representations are approximated and learned from random exploration trajectories. It might not be a problem in the experiments in this paper since the experiments are done in simple 2D navigation and 3D reaching tasks. However, this may fail when a higher-level plan cannot be achieved because an agent cannot reach a waypoint (the center of a cluster in the plan) from the current state. It is required to discuss this issue and how to resolve it. \n\n* The results in Sawyer-Reach do not demonstrate the advantage of the proposed approach as explained in Section 4.3. Extensive experiments with more challenging environments that can show the benefit of the proposed approach would strengthen the paper.\n\n* The experiments rely on exploratory data to pre-train the representations. This may not be scalable to more complex environments with many narrow passages in C-space. One alternative could be learning the representations using play data or offline data. This can be an interesting experiment to see."
                },
                "questions": {
                    "value": "Please address the weaknesses mentioned above.\n\n\n### Minor questions and suggestions\n\n* In Section 3, $x$ is often used for a variable in both $\\phi(x)$ and $\\psi(x)$. But, since $x$ is used to describe an observation in the section, it might be better denoted as $\\psi(s)$. Similarly in Section 3.2, $z$ is introduced for a latent state but it could be simply $s$?\n\n* In Section 3.2, $f_\\text{AC}$ is defined to take two latent states but the following sentence says it takes a concatenation of $\\tau + 1$ latent states, which is confusing.\n\n* In Section 3.3, it could be clearer if the latent state spaces induced by $\\phi$ and $\\psi$ are defined separately, like $\\mathcal{S}$ and $\\mathcal{Z}$? The definition of the second encoder $\\psi(x): \\mathcal{Z} \\rightarrow \\mathcal{Z}$ is kinda confusing as these two spaces are not shared (although they can have the same dimensionality).\n\n* Figure 2 is useful to understand the holistic view of the proposed method. However, it is a bit overwhelming with many symbols. It could be easier to understand this figure if it includes a few image observations for $x$s and uses different shapes or colors for different symbols."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3799/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699381264230,
            "cdate": 1699381264230,
            "tmdate": 1699636337120,
            "mdate": 1699636337120,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5d66O0Rl5w",
                "forum": "NlBuWEJCug",
                "replyto": "N3Zg9Dsinc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3799/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3799/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thanks for taking time to review our work. In the following, we address each of your concerns:\n\n> ...there are several symbols used to denote different levels of latent state\u2026\n \nWith \u201cx\u201d, we simply imply observations from the environment; \u201cz\u201d refers to the learnt latent state from the multi-step inverse-dynamics model, and \u201cs\u201d refers to the true-latent state. Though we attempted to be consistent in our usage of these symbols, we will revise our document to fix any inconsistencies and re-emphasize them in our \u201cSection 3.1 Notation and PRELIMINARIES\u201d  \n \n> ...more complicated environments with high-dimensional C-space\u2026\n\nIn principle, our work is not restricted to the dimensionality of the true state. We learn our latent state representation from high-dimensional image inputs and keep the dimensionality of the latent state in the order of 128 or 256 for our experiments. Our work rather emphasizes learning latent states for any high-dimensional environment which requires goal conditioned planning. Our experiments on half-cheetah and walker-2d suggest our learning method seems to be helping.\n \n> ... The proposed planner assumes that latent states in the same cluster are reachable from each other \u2026\n\nThanks for pointing out our assumption. Yes, we do make this assumption and it\u2019s based on learning formulation where latent states are learned in a manner such that state which are reachable to each other have similar latent-states. This helps in ensuring that any state which is clustered-together is navigable; irrespective of \u201ck\u201d used for k-means clustering. This is subject to learning latent state representation up to convergence.\n \n \n> ... One alternative could be learning the representations using play data or offline data \u2026\n\nThanks for the suggestion. In our current-experiments with half-cheetah and walker 2d, we make use of offline  \u201cmedium, medium-expert, and expert\u201d datasets.\n \n> ... it might be better denoted as \\psi(s)...\n\nWe have made the suggested change in the later half of section 3.1. For section 3.2, we continue to use \u201cz\u201d to maintain continuity with the rest of the document.\n \n> ... defined to take two latent states but the following sentence \u2026\n \nYes, it takes concatenation of the z_t, z_{t+k} and embedding of \u201ck\u201d. We have reworded this in section 3.2 to make it more clear. Thanks for pointing it out.\n \n>  ...the definition of second encoder...\n \nWe have updated the definition in section 3.3\n \n> ...However, it is a bit overwhelming with many symbols\u2026\n \nThanks for the suggestion, we will update the figure to have different symbols and colors for different modules."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3799/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700695363799,
                "cdate": 1700695363799,
                "tmdate": 1700695363799,
                "mdate": 1700695363799,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "i7ppioehor",
                "forum": "NlBuWEJCug",
                "replyto": "5d66O0Rl5w",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3799/Reviewer_AtR8"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3799/Reviewer_AtR8"
                ],
                "content": {
                    "comment": {
                        "value": "Thank for the author response. \n\nThe reachability assumption inside a cluster is not convincing to me, especially when the true state space becomes high-dimensional. Strong empirical results on tasks with high-dimensional state spaces would be required to claim the effectiveness of the proposed approach beyond simple 2D/3D navigation environments. Thus, I would keep my original rating of weak rejection."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3799/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700707862090,
                "cdate": 1700707862090,
                "tmdate": 1700707862090,
                "mdate": 1700707862090,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]