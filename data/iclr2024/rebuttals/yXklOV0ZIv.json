[
    {
        "title": "Learnable Counterfactual Attention for Singer Identification"
    },
    {
        "review": {
            "id": "T3hHG6upvJ",
            "forum": "yXklOV0ZIv",
            "replyto": "yXklOV0ZIv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1986/Reviewer_6GjB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1986/Reviewer_6GjB"
            ],
            "content": {
                "summary": {
                    "value": "This paper is out of my knowledge, and I tend to not submit any reviews for this paper. Thanks for the submission. Please ignore my ratings."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper is out of my knowledge, and I tend to not submit any reviews for this paper. Thanks for the submission."
                },
                "weaknesses": {
                    "value": "This paper is out of my knowledge, and I tend to not submit any reviews for this paper. Thanks for the submission."
                },
                "questions": {
                    "value": "This paper is out of my knowledge, and I tend to not submit any reviews for this paper. Thanks for the submission."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1986/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698636239702,
            "cdate": 1698636239702,
            "tmdate": 1699636130416,
            "mdate": 1699636130416,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YOdv5tJMUV",
                "forum": "yXklOV0ZIv",
                "replyto": "T3hHG6upvJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1986/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1986/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Reviewer 6GjB"
                    },
                    "comment": {
                        "value": "Thank you."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700388519105,
                "cdate": 1700388519105,
                "tmdate": 1700388519105,
                "mdate": 1700388519105,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "SxoLFDlmpD",
            "forum": "yXklOV0ZIv",
            "replyto": "yXklOV0ZIv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1986/Reviewer_i4Hf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1986/Reviewer_i4Hf"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes to extend counterfactual attention learning via a learnable counterfactual attention module to further improve the ability of counterfactual attention. To learn this learnable attention model, this paper designs a series of loss functions. Beyond the conventional cross-entropy and counterfactual losses, it adds three extra loss terms. First, a cross-entropy loss is applied to the counterfactual attention branch as the regularization term to make the counterfactual attention more meaningful. Second, a multiple classification loss for the counterfactual attention branch is designed to limit the performance of the counterfactual attention. Third, an L1 loss between the attention maps of factual and counterfactual branches encourages the difference.  This method is evaluated with the singer identification task which also requires the fine-grained identification ability.   Specifically, the benchmark artist20 dataset is employed for the comparison, including the comparison with other SOTA methods, and ablation studies."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1) This paper proposes a learnable counterfactual attention module to achieve better performance. \n2) This paper provides detailed explanations of each extra loss-term."
                },
                "weaknesses": {
                    "value": "Some concerns about this paper are summarized below:\n1) From the experiments in the original CAL method. It seems that the refinement of the counterfactual attention branch didn't improve the recognition performance. What is the motivation to refine the counterfactual attention branch? Did you find any insights from the preliminary experiments to support this enhancement path?\n2) As shown in Figure 2 and Section 3.2, CAL applies the counterfactual \"intervention\" to cut off the causal relations between image and attention.  The goal of this \"intervention\" is to obtain the independent effects and further benefit the calculation of the Total Direct Effect. Here, both the counterfactual and factual branches are learned from the image. From the perspective of causality, how can you guarantee the independence between counterfactual and factual attention for the causal inference? \n3) For the extra loss terms, there are two contradictory losses, one is to make the counterfactual attention meaningful and the other is to make it not too meaningful.  How can we balance these two losses?  Is it robust for different scenarios? Do the hyper-parameters of loss rates matter for the performance?\n4)  The motivation of this paper is to improve counterfactual attention learning. Given this goal, it is better to evaluate the proposed method and the key baseline (CAL) in the same settings, such as CUB, Cars, Aircraft, and so on.  \n5) As shown in Table 1, the improvement of the proposed LCA is very limited. Why these results can support the conclusion? Take the Best frame-level results as an example, the proposed method only improves 0.02 accuracy. \n6) Only one dataset is used.  The evaluation process seems to be not solid.  It is suggested to add more."
                },
                "questions": {
                    "value": "Beyond the questions in the weaknesses part, there are some questions for the details. \n\n1) As shown in Table 1, which counterfactual attention is used as a baseline, random, mean, or shuffle?\n2) What are the loss rates used in the experiments?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1986/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698708081665,
            "cdate": 1698708081665,
            "tmdate": 1699636130343,
            "mdate": 1699636130343,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FTiCNcjCaM",
                "forum": "yXklOV0ZIv",
                "replyto": "SxoLFDlmpD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1986/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1986/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Reviewer i4Hf"
                    },
                    "comment": {
                        "value": "For Weakness 1:\n\nThank you for your comment. Yes, experiments (Table 1) show that CAL's random attention maps are ineffective for SID task. This is due to the distinct nature of music tasks compared to vision tasks. For instance, in the SID task, singing voices are distributed in most frequency bands in the spectrogram, whereas in the image classification task, the target object usually occupies only a small portion of the image. This leads to the ineffectiveness of using random attention maps as counterfactual interventions in CAL for SID task. We addressed this by developing the LCA mechanism, which uses learnable attention maps to target specific biases instead of CAL's random attention maps. This approach improves SID and music genre classification performance (see Table 3 in original manuscript and Table A1 in appendix).\n\n For Weakness 2:\n\nOur study, as shown in Table 1, reveals that using random attention maps as counterfactual interventions to cut off the causal link between feature maps and attention is ineffective for the SID task. We believe that forcibly maintaining such independence in model training is not always advantageous. We suggest that a data-driven approach, where counterfactual attentions could automatically learn from data, identify biased regions, could be more advantageous. This approach was validated in SID experiments (Table1 and 3) and further supported by music genre classification experiments (Table A1 in the appendix), proving that our LCA mechanism's strategy of linking feature maps and attention (i.e., dependence assumption) outperforms the CAL mechanism in music tasks.\n\nFor Weakness 3:\n\nThank you. We balance the two loss functions in our counterfactual attention branch by adjusting the hyperparameters $\\lambda_{ce}^{cf}$ and $\\lambda_{ent}^{cf}$ (see formula 1). In fact, in the SID task, we did not extensively experiment with these hyperparameters, setting them based on the original audio files and vocal-only tracks, without considering duration (3, 5, or 10 seconds) (see Table 3). For the new music genre classification task (see Table A1 in appendix), we also employed the same hyperparameters used in the SID task for original audio files, and achieved excellent performance, demonstrating our method's robustness. We think designing ablation experiments for various tasks to optimize hyperparameters for loss functions can enhance performance. However, from our experience, satisfactory results are achievable in our design as long as $\\lambda_{ce}^{cf}$ is greater than $\\lambda_{ent}^{cf}$.\n\nFor Weakness 4:\n\nThis study focuses on evaluating the CAL mechanism's efficacy in music-related tasks. In our experiments (see Table 1), we have demonstrated the LCA mechanism's superior efficacy over CAL in the SID task (a fine-grained challenge (Kuo et al., 2021)) under identical experimental conditions. Additionally, we confirmed our LCA mechanism's superiority over CAL in music genre classification (see appendix).\n\nFor Weakness 5:\n\nThank you for your comment. Table 1 shows our LCA mechanism comprehensively outperforms both the original CRNN\\_FGNL and CRNN\\_FGNL (with CAL) at frame and song levels. Table 3 further indicates that LCA enhances CRNN\\_FGNL's performance in various settings, including 3, 5, and 10-second experiments with original and vocal-only audio. Additionally, the new music genre classification experiments in the appendix (see Table A1) reveal marked improvements with our LCA compared to CAL. Notably, our LCA is used only during training, thus not increasing the model's parameters or computational load in testing phase.\n\nFor Weakness 6:\n\nWe have included a music genre classification task in the appendix, which serves to further assess the performance of our method.\n\nFor Question 1:\n\nIn our original manuscript, we have clearly described in the results section (section 4.2) for Table 1 that we adopted random attention in the CAL mechanism. This approach of using random attention is also recommended by the original authors of the CAL mechanism (Rao et al., 2021).\n\nFor Question 2:\n\nIn the SID task, the weight of each loss function is as follows:\n\nOriginal audio file setting:\n$\\lambda_{ce}^{main}$=  1.0,\n$\\lambda_{ce}^{effect}$= 1.0, \n$\\lambda_{ce}^{cf}$= 0.3, \n$\\lambda_{ent}^{cf}$= 0.25, \n$\\lambda_{1}^{att}$= 1.0, \n$\\lambda_{ent}^{main}$= 0.2\n\nVocal only setting:\n$\\lambda_{ce}^{main}$=  1.0,\n$\\lambda_{ce}^{effect}$= 1.0, \n$\\lambda_{ce}^{cf}$= 0.8, \n$\\lambda_{ent}^{cf}$= 0.025, \n$\\lambda_{1}^{att}$= 1.0, \n$\\lambda_{ent}^{main}$= 0.02\n\nFor the newly implemented music genre classification task, we have set the weight of each loss function to be the same as those used in the original audio file setting of the SID task. We have added the hyperparameter setting (weight) of each loss function in the appendix. Thank you."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700388457576,
                "cdate": 1700388457576,
                "tmdate": 1700388457576,
                "mdate": 1700388457576,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UJgX0GGb8g",
                "forum": "yXklOV0ZIv",
                "replyto": "FTiCNcjCaM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1986/Reviewer_i4Hf"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1986/Reviewer_i4Hf"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your response."
                    },
                    "comment": {
                        "value": "Thank you for your response, and I apologize for my own delay in replying.\n\nAfter carefully reviewing the current revision, I still have significant concerns that need to be addressed:\n\nExperiments and Comparisons:\nThe paper lacks comparative experimental data between CAL and LCA in the context of fine-grained recognition tasks. Moreover, the reasons or motivations supporting this choice remain unconvincing. Given the introduction of more hyperparameters, the improvements demonstrated on SID tasks are not persuasive enough. A more rigorous experimental comparison and justification are needed to validate these claims.\n\nSoundness and Causal Inference:\nThe implementation of the study does not seem to align with standard causal inference methodologies. It's crucial to provide new guarantees or robust evidence regarding the learned counterfactual attentions. Currently, the limited scope of the experiments conducted does not suffice to convincingly demonstrate the effectiveness of your approach. A more comprehensive and theoretically sound exploration is required to substantiate your findings.\n\nI hope these points will be thoroughly considered and addressed in your next revision. I believe they will help the quality of this paper."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700688762497,
                "cdate": 1700688762497,
                "tmdate": 1700688762497,
                "mdate": 1700688762497,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "8HHZquGyfX",
            "forum": "yXklOV0ZIv",
            "replyto": "yXklOV0ZIv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1986/Reviewer_5eKQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1986/Reviewer_5eKQ"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a learnable counterfactual attention method to improve the recognition performance of the singer identification task. The method improves the existing counterfactual attention learning framework by replacing the random counterfactual attention with learnable ones. With some new and specifically designed loss functions, the method can better discover effective attention regions and show improvement on SID benchmarks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed learnable counterfactual attention is well-motivated and reasonable. Empirical results show the method is effective on the SID task.\n\n- The paper is well-written and easy to follow."
                },
                "weaknesses": {
                    "value": "- My main concern is the generality of the proposed method. The proposed method is motivated by the limitations of the existing CAL method. However, this paper only evaluates the method on the SID task, which is a less popular and competitive task compared to the tasks considered in CAL. According to the analysis provided in Section 3.2, LCA didn't add assumptions on the data or task types over CAL. So it is not clear why the proposed method is only evaluated on the SID task. Considering ICLR is a machine learning conference, I think showing the generality of the proposed method is also helpful to make the paper more suitable for publishing on ICLR and interest the audience of the conference. \n\n- The authors claim the method can \"guide the main branch to deviate from those regions, thereby focusing attention on discriminative\nregions to learn singer-specific features in fine-grained vocals\". I think it would be better to provide some quantitative evidence to support this claim."
                },
                "questions": {
                    "value": "Although I find the proposed method is well-motivated and reasonable, I still have some concerns about the experimental study and positioning of this paper. I think the paper can be further improved if the above problems can be solved."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1986/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698762285693,
            "cdate": 1698762285693,
            "tmdate": 1699636130212,
            "mdate": 1699636130212,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "j0GuYhuihW",
                "forum": "yXklOV0ZIv",
                "replyto": "8HHZquGyfX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1986/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1986/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Reviewer 5eKQ"
                    },
                    "comment": {
                        "value": "For Weakness 1:\n\nThank you for your comment. Our study primarily investigates the efficacy of the CAL mechanism in music-related tasks, particularly in the SID task. Through experiments (as shown in Table 1), we found that the CAL mechanism is ineffective for the SID task. This is due to the distinct nature of music-related tasks compared to vision tasks. For instance, in the SID task, singing voices are distributed in most frequency bands in the spectrogram, whereas in the image classification task, the target object usually occupies only a small portion of the image. This leads to the ineffectiveness of using random attention maps as counterfactual interventions in CAL for SID task. To overcome this limitation, we developed the LCA mechanism. It replaces the random attention maps used as counterfactual interventions in CAL with attention maps that automatically focus on biased regions, generated by a learnable counterfactual attention branch. This improvement has been proven effective in enhancing the SID task in experiments (see Table 3).\n\nOn the other hand, as you pointed out, the LCA mechanism does not add assumptions about data or task types compared to CAL. This is because our initial design intention of the LCA mechanism was to allow it to learn from data, thereby generating counterfactual attention maps that benefit the model. We expect this design to be more easily applicable to different tasks, thereby enhancing its universality.\n\nFinally, the SID task is a core topic in the field of Music Information Retrieval (MIR). However, following your valuable suggestion, we have added a task for music genre classification in the appendix to validate the universality and effectiveness of our proposed LCA mechanism in music-related tasks.\n\nFor Weakness 2:\n\nThank you for your comment. In Table 3 of our original manuscript, we have already demonstrated that integrating the LCA mechanism into the CRNN\\_FGNL model (i.e., CRNN\\_FGNL (w/ LCA)) leads to a comprehensive enhancement in performance. This is attributed to the counterfactual attention branch learned from the LCA mechanism, which effectively redirects the main branch from less discriminative regions (bias regions) to those with higher discriminative potential (singer-specific regions). Moreover, the t-SNE visualization in Figure 4 further bolsters our assertion that CRNN\\_FGNL (w/ LCA) demonstrates a significantly stronger discriminative ability in the learned features (i.e., can distinguish between different singers more effectively), as compared to the original CRNN\\_FGNL model. \n\nAdditionally, in the appendix, we have included an experiment to further confirm that the counterfactual branch can focus on common data biases (see Figure A1), thus encouraging the main branch to deviate from these biases and enhancing the discriminative nature of its features.\n\nFor Question:\n\nThank you for your valuable suggestion. Following your advice, we have added two additional experiments in the appendix to further validate the universality of our LCA mechanism and substantiate its claims."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700381540746,
                "cdate": 1700381540746,
                "tmdate": 1700381540746,
                "mdate": 1700381540746,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9G1RrtYTbi",
            "forum": "yXklOV0ZIv",
            "replyto": "yXklOV0ZIv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1986/Reviewer_hb43"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1986/Reviewer_hb43"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a learnable counterfactual attention mechanism, specifically tailored for the singer identification task, aiming to address the limitations of existing counterfactual attention learning. Unlike the traditional approach that depends on random attentions, the LCA mechanism enhances the ability of counterfactual attention to identify fine-grained vocals through direct learning. The implementation involves integrating a counterfactual attention branch into the existing model. This addition is meticulously guided by multiple loss functions, ensuring that the counterfactual attention branch focuses on regions that are meaningful yet not overly discriminative, avoiding potentially misleading results. Meanwhile, it directs the main branch towards discriminative regions to learn singer-specific features effectively. The performance improvement is demonstrated through evaluation on the benchmark artist20 dataset."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The authors provide a clear and intuitive analysis of the limitations present in the baseline method (CAL), proposing straightforward yet effective solutions to enhance its performance. Each proposed solution, addressing Characteristics 1, 2, and 3, demonstrates simplicity and efficacy. The experimental results solidify the effectiveness of the introduced loss functions, providing tangible evidence of improvement. Furthermore, the manuscript is well-structured and articulated, ensuring a smooth and comprehensible reading experience for the audience."
                },
                "weaknesses": {
                    "value": "1. Regarding the second Characteristic 2 (Targeting biased regions without outperforming the main branch), I can not see the logic between forcing the class distribution to be smooth and targeting biased regions without outperforming the main branch. Moreover, the assertion that a smoother output distribution directly correlates to effectively targeting biased regions without overshadowing the main branch is questionable. Since the output distributions of the two branches lead to disparate final classification results, this assumption appears to be unfounded and requires further clarification.\n\n2. Regarding Characteristic 3 (Regions of focus should differ from the main branch\u2019s attention), the manuscript appears to implicitly assume superior performance of the main branch. However, empirical observations suggest that the main branch\u2019s performance is not as exemplary as presumed. A straightforward deviation from the main branch's attention map might inadvertently introduce inaccuracies. This aspect of the methodology warrants a more cautious approach and a thorough examination to validate its effectiveness and mitigate potential risks of error introduction."
                },
                "questions": {
                    "value": "Please refer to the weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1986/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1986/Reviewer_hb43",
                        "ICLR.cc/2024/Conference/Submission1986/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1986/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698768965204,
            "cdate": 1698768965204,
            "tmdate": 1700550258280,
            "mdate": 1700550258280,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JfP76j7T2x",
                "forum": "yXklOV0ZIv",
                "replyto": "9G1RrtYTbi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1986/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1986/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Reviewer hb43"
                    },
                    "comment": {
                        "value": "For Weakness 1:\n\nThank you for your comment. In the design of neural network training, if entropy is used as the loss function, then when the probability distribution of the output layer becomes more smooth or uniform\u2014 that is, the probabilities of each category tend to be consistent \u2014 the entropy value will reach its maximum. Under this strategy of pursuing maximum entropy in Characteristic 2, the neural network is driven to focus on the common biases (data biases) in the training data across all categories, as focusing on common data biases will more easily lead the model's output layer to produce smooth or uniform probabilities across different categories. This approach of concentrating on biased regions means that the counterfactual branch is unlikely to surpass the main branch in terms of classification performance, as these bias regions typically lack strong discriminative power. Consequently, by further incorporating the loss function outlined in Characteristic 3, which is designed to maximize the differences between the counterfactual and main branch attention maps, our approach guides the main branch to shift its focus away from biased regions and instead concentrate on regions with greater discriminative power. \n\nTo validate that incorporating the loss functions of Characteristic 2 and 3 in the proposed learnable counterfactual attention (LCA) mechanism enables the counterfactual branch to focus on common data biases, thereby prompting the main branch to deviate from these biases, we expanded the experiment shown in Figure 1. Specifically, we introduced the same white noise in the 3k to 5k Hz range of the spectrogram for five different singers at varying proportions. Subsequently, we trained the CRNN\\_FGNL both with and without the LCA mechanism, visualizing the class activation maps (CAM) of the test data based on Grad-CAM. As can be seen in Figure A1 of the appendix, compared to Figure A1 (b) without the LCA mechanism, Figure A1 (c) clearly shows that after integrating the LCA mechanism, CRNN\\_FGNL significantly reduced its attention to the noise (bias) range. Such results confirm the effectiveness of our LCA mechanism in guiding the counterfactual attention branch to concentrate on common biased regions, subsequently prompting the main branch to divert its focus from these regions.\n\nFor Weakness 2:\n\nThank you for your comment. During our model training process, we intentionally designed the counterfactual attention branch to perform less effectively than the main branch. This is to ensure that the counterfactual attention branch focuses on learning the biases present in the data, specifically the regions with weaker discriminative power, thereby compelling the main branch to avoid concentrating on these biased regions. The experimental results presented in Table 4 of our manuscript confirm our design approach: the performance of the counterfactual branch is significantly lower than that of the main branch, indicating that the regions it focuses on have lower discriminative capabilities. Based on this, we further emphasize maximizing the differences in the attention maps between the counterfactual and main branches, aiming to direct the main branch's focus to regions distinct from those the counterfactual branch concentrates on. As demonstrated in Table 3, incorporating the loss function from Characteristic 3, our proposed LCA mechanism, namely CRNN\\_FGNL (w/LCA), outperforms the previous state-of-the-art CRNN\\_FGNL in all aspects, whether it be on original audio files or vocal-only tracks. However, we agree with your perspective that maximizing the differences in the attention maps between the counterfactual and main branches could inadvertently introduce inaccuracies. Therefore, our future research will focus on how to further discern the impact on classification from the regions that the counterfactual branch concentrates on."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700380549675,
                "cdate": 1700380549675,
                "tmdate": 1700380549675,
                "mdate": 1700380549675,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Oo36wBGO3g",
                "forum": "yXklOV0ZIv",
                "replyto": "JfP76j7T2x",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1986/Reviewer_hb43"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1986/Reviewer_hb43"
                ],
                "content": {
                    "title": {
                        "value": "Reply to the authors' rebuttal"
                    },
                    "comment": {
                        "value": "Many thanks for your reply. I think your response partially solves my concerns. I decided to raise the score."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700550221340,
                "cdate": 1700550221340,
                "tmdate": 1700550221340,
                "mdate": 1700550221340,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]