[
    {
        "title": "Rationality of Thought Improves Reasoning in Large Language Models"
    },
    {
        "review": {
            "id": "jeamltWAwj",
            "forum": "kaGA40pfFY",
            "replyto": "kaGA40pfFY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1926/Reviewer_58ny"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1926/Reviewer_58ny"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose Rationality of Thought as a new method to prompt LLMs into a rational thinking process. In addition, they propose a new benchmark inspired by problems that have been used to study cognitive biases in humans. Their methods improve the accuracy of LLMs on their new benchmark and on existing reasoning benchmarks (but to a lesser degree)."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The proposed method is interesting, clean, and well-motivated.\n\nThe paper is well-written and easy to follow.\n\nThe authors propose a new and interesting benchmark.\n\nThe obtained results are promising."
                },
                "weaknesses": {
                    "value": "The authors write that each type of bias has 16 questions in their data set. Were all of these problems taken from prior literature or does this also include novel problems created by the authors? My main concern about the current state of the paper is regarding this issue. Many of the original cognitive bias problems (e.g., the Linda problem) are presumably heavily featured in the training data. To ensure that we are probing the reasoning capabilities of LLMs, it would be important to include novel (i.e., rephrased) versions of the original problems. While the current set does not include any such problems, I am unlikely to increase my score further. Maybe this is already done but the information is just not provided. In this case, the authors should describe how the rephrasing was done.\n\nImportant references to prior work are missing. For example, Binz & Schulz (2023) already studied some of the biases included in the present benchmark. In addition, the present paper takes quite a one-sided view in claiming that LLMs are becoming increasingly similar to human reasoning. There are many examples where this is not the case, see for instance Ullman (2023) or Mitchell & Krakauer (2023).\n\nBinz, M., & Schulz, E. (2023). Using cognitive psychology to understand GPT-3. Proceedings of the National Academy of Sciences, 120(6), e2218523120.\n\nUllman, T. (2023). Large language models fail on trivial alterations to theory-of-mind tasks. arXiv preprint arXiv:2302.08399.\n\nMitchell, M., & Krakauer, D. C. (2023). The debate over understanding in AI\u2019s large language models. Proceedings of the National Academy of Sciences, 120(13), e2215907120.\n\nThe visual presentation could be improved in places. In particular, while Figure 1 gives a good intuitive understanding of the approach, the reader has to go to the SI to see the exact RoT prompt. This is unfortunate as this is the heart of the paper. Furthermore, Table 1 does not add any value in my opinion. A good solution would be to therefore replace Table 1 with Table 5 from the SI or similar.\n\nMinor:\n\nFormatting is a bit weird in places, especially spaces are often used wrongly/inconsistently.\n\nEquation on page 3:\n* is not numbered.\n* p_rot does not appear.\n* \\in \\mathcal{D} should be in the subscript (also for the equations later in the paper).\n* the equation implies that there is some optimization happening but that is not the case to my understanding (maybe I am missing something here).\n\nFigure 3: legend and text are way too small to be readable. To allow for larger font sizes, subplots a and c could be removed given that they display redundant information with b and d.\n\nThe conclusion is not a conclusion as it is followed by a related work section.\n\nPage 9: the authors say \u201cResearch by Alaina ...\u201d but then cite another author (maybe first and surnames are exchanged here)."
                },
                "questions": {
                    "value": "The authors use zero-shot CoT for the experiments in section 3 and few-shot CoT for the experiments in section 4. Why was this choice made? It would have been easy to also use zero-shot CoT for the experiments in section 4 (especially if the claim is that RoT is nice because it does not require example solutions). Related to that, the fact that zero-shot CoT actually decreases performance on the cognitive bias dataset is surprising. Any idea why this is the case?\n\nGiven that the improvements were not so great in GPT3.5, would you say that RoT prompting is an emergent ability?\n\nFinally, I was wondering whether all the steps in RoT prompting are needed or whether some of them could be removed without a loss of performance. I am not asking the authors to run additional ablations but I think this is still interesting to think about."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1926/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1926/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1926/Reviewer_58ny"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1926/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698401925882,
            "cdate": 1698401925882,
            "tmdate": 1700918421798,
            "mdate": 1700918421798,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vK1yHOSMKU",
                "forum": "kaGA40pfFY",
                "replyto": "jeamltWAwj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1926/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1926/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewers,\n\nFirst and foremost, we would like to express our sincere gratitude for the time and effort you have dedicated to reviewing our manuscript.Your reviews have been extremely helpful in improving our research work. This process has not only strengthened our current manuscript but also enriched our understanding of the subject matter.\nIn the past week, in reference to your reviews, we have supplemented the relevant experiments and clarified some of the previously unclear descriptions in our manuscript. Next, we will respond to your comments one by one.\n\nPlease kindly note, due to the extensive nature of my response and the limitation of 5000 characters per message, I will be submitting my response in multiple parts. I kindly ask for your patience and suggest that you review them collectively once all parts have been sent. Thank you very much for your understanding.\n\n\n| Comment | Response |\n| --- | --- |\n| The authors write that each type of bias has 16 questions in their data set. Were all of these problems taken from prior literature or does this also include novel problems created by the authors? My main concern about the current state of the paper is regarding this issue. Many of the original cognitive bias problems (e.g., the Linda problem) are presumably heavily featured in the training data. To ensure that we are probing the reasoning capabilities of LLMs, it would be important to include novel (i.e., rephrased) versions of the original problems. While the current set does not include any such problems, I am unlikely to increase my score further. Maybe this is already done but the information is just not provided. In this case, the authors should describe how the rephrasing was done. | In this study, during the construction of the bias dataset, we initially collected 116 seed questions, corresponding to four seed questions for each type of bias. Subsequently, utilizing these seed questions and associated construction rules, we employed the GPT-4 model to generate a broader set of questions. After manual review and selection, 348 questions were finalized, equating to 12 generalized questions per bias type. This implies that at least 75% of the questions in this dataset were not present in the training data of the models we used (GPT-4 and GPT-3.5), thus ensuring the quality of this bias dataset for validating the inferential capabilities of Large Language Models (LLMs). Detailed information regarding the dataset construction has been added to the latest version of the paper, specifically in Section 3.1, titled \"Cognitive Bias Task\". |\n| Important references to prior work are missing. For example, Binz & Schulz (2023) already studied some of the biases included in the present benchmark. | Yes, thank you very much for your reminder. We have carefully read the paper and have already incorporated its core content and references into Section 5.1 'Cognitive Biases' of the latest version of our manuscript. |"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1926/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700622378053,
                "cdate": 1700622378053,
                "tmdate": 1700622378053,
                "mdate": 1700622378053,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "j8wgkUcsag",
                "forum": "kaGA40pfFY",
                "replyto": "JSWWfcBB4i",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1926/Reviewer_58ny"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1926/Reviewer_58ny"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks to the authors for their reponse. I will not have the time to go through it today. I'll read it later this week and update here again if possible."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1926/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700655035576,
                "cdate": 1700655035576,
                "tmdate": 1700655035576,
                "mdate": 1700655035576,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "fLJ2F4bcrh",
            "forum": "kaGA40pfFY",
            "replyto": "kaGA40pfFY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1926/Reviewer_QJRm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1926/Reviewer_QJRm"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a prompt engineering technique, called RoT (Rationality of Thought), whose goal is to align with the underlying logic of human cognition. The paper claims that RoT can assist large language models (LLMs) to reduce cognitive biases. Compared with Chain-of-Thought and other reasoning-enhancement techniques, RoT does not need additional manual annotations. RoT integrates various methods to improve reasoning of LLMs (e.g. thought chains, self-reflection, and expert knowledge) into a unified theoretical framework rooted in cognitive psychology. As part of the study, the paper has created a cognitive bias dataset."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper proposes a new prompt engineering technique, RoT designed to avoid cognitive bias. RoT include steps: identification, decomposition, reflection, calculation, and evaluation, among other markers of rational thought. \n\n2. When applied RoT to GPT-3.5-turbo and GPT-4 on the cognitive bias test set, accuracy improvements are 1.5% and 18.7%, respectively. \n\n3. The paper collects a cognitive bias test dataset including 29 such biases."
                },
                "weaknesses": {
                    "value": "1. There does not seem to be convincing evidence that Rational of Thought method can improve arithmetic reasoning and common sense reasoning tasks. Specifically improvements on GSM8K (Cobbe et al., 2021), SVAMP (Patel et al., 2021),AQUA-RAT (Ling et al., 2017) , and ARC (Clark et al., 2018) over CoT are +0.4, -0.6, +4.8, -0.3, +0.7. Other than AQUA-RAT, the performance degradations and improvements are all very small. However, the paper does not dive deep into AQUA-RAT performance improvement.\n\nAs shown in the paper \"Large Language Models Cannot Self-Correct Reasoning Yet\", it is not clear RoT can improve reasoning when compared with CoT. \n\n2. Despite connecting RoT to human cognition, there is little insight on why RoT can improve cognitive biases."
                },
                "questions": {
                    "value": "Now there are a large number of prompt engineering techniques that decompose problems into sub-problems. The paper should comment and hopefully compare to some of the most notable ones, such as Least to most prompting, tree of thoughts, etc.\n\nBesides the GPT family models, the authors are encouraged to study Anthropic Claude and open source models such as LLaMA2. This would be very important to see whether the techniques can also apply to other LLMs.\n\nThe evaluation seems to focus on multiple choices. LLMs are known to have position bias. Does the result change if you change the ordering of the answer choices?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1926/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698537790205,
            "cdate": 1698537790205,
            "tmdate": 1699636123331,
            "mdate": 1699636123331,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "cZzLrmsSsN",
                "forum": "kaGA40pfFY",
                "replyto": "fLJ2F4bcrh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1926/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1926/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewers,\n\nFirst and foremost, we would like to express our sincere gratitude for the time and effort you have dedicated to reviewing our manuscript.Your reviews have been extremely helpful in improving our research work. This process has not only strengthened our current manuscript but also enriched our understanding of the subject matter.\nIn the past week, in reference to your reviews, we have supplemented the relevant experiments and clarified some of the previously unclear descriptions in our manuscript. Next, we will respond to your comments one by one.\n\nPlease kindly note, due to the extensive nature of my response and the limitation of 5000 characters per message, I will be submitting my response in multiple parts. I kindly ask for your patience and suggest that you review them collectively once all parts have been sent. Thank you very much for your understanding.\n| Comment | Response |\n| --- | --- |\n| There does not seem to be convincing evidence that Rational of Thought method can improve arithmetic reasoning and common sense reasoning tasks. Specifically improvements on GSM8K (Cobbe et al., 2021), SVAMP (Patel et al., 2021),AQUA-RAT (Ling et al., 2017) , and ARC (Clark et al., 2018) over CoT are +0.4, -0.6, +4.8, -0.3, +0.7. Other than AQUA-RAT, the performance degradations and improvements are all very small. However, the paper does not dive deep into AQUA-RAT performance improvement. | We have added COT zero-shot experiments, and the results show that, compared to CoT zero-shot, RoT zero-shot enables the GPT-4 model to achieve improved results on the following datasets: SVAMP (+1.8), AQUA-RAT (+6), ARC-e (+3.9), and ARC-c (+4.1). This improvement is quite significant, and based on these results, we believe that the Rational of Thought method can enhance performance in arithmetic reasoning and common sense reasoning tasks. However, in our experimental results, we also observed a puzzling phenomenon: on the GSM8K dataset, both GPT-3.5-turbo and GPT-4 models performed better using the CoT zero-shot strategy compared to the CoT few-shot strategy. The specific performances are as follows: GPT-3.5-turbo:CoT-zeroshot\uff0c79.2    GPT-3.5-turbo:CoT-fewshot\uff0c 76.6 GPT-4:CoT-zeroshot\uff0c95.7 GPT-4:CoT-fewshot\uff0c 94.1 We speculate that this may be because, under the zero-shot setting, the GPT-4 model's own reasoning process on the GSM8K dataset is superior to the reasoning provided by the few-shot examples of the CoT method. Thus, adding few-shot examples actually led to a decrease in performance. If this is true, it would represent another intriguing research topic. The AQUA-RAT dataset primarily focuses on algebra problems, often centering on computation and algebraic reasoning, requiring solving equations, handling ratios, and percentages, among others. Therefore, the thinking framework of the RoT method, compared to the CoT method, seems more suited for tackling these types of problems, which we also observed from the content of the output answers.For details, please refer to Appendix D of our paper due to space limitations in the main text. |\n| As shown in the paper \"Large Language Models Cannot Self-Correct Reasoning Yet\", it is not clear RoT can improve reasoning when compared with CoT. | We have added a COT zero-shot experiment, which demonstrates that the RoT zero-shot method leads to improvements in the GPT-4 model's performance on several datasets: SVAMP (+1.8), AQUA-RAT (+6), ARC-e (+3.9), and ARC-c (+4.1). This improvement is quite significant. Based on these results, we believe the Rational of Thought method can improve arithmetic reasoning and common sense reasoning tasks. Specifically, we conducted an ablation study on the RoT method, removing each step one at a time, and used the GPT-4 model to experiment on biased datasets. Observing the results (Table 2), it was evident that removing any step caused some detriment to the final outcomes. The most significant harm occurred with the removal of step 3, which led to a 9% decrease in model performance. This aligns with our hypothesis, as cognitive biases, from the perspectives of cognitive science and psychology, are primarily due to humans\u2019 tendency to rely on \"System 1\" for intuitive judgments, thereby lacking rigorous data analysis. Moreover, the entire RoT method is a holistic thinking framework, where each step contributes to and enhances the others. Therefore, the absence of any step inevitably leads to a decline in model performance. Overall, according to the experimental data, step 3 is particularly crucial for improving the model's cognitive reasoning abilities. For detailed experimental results, please refer to Table 2 on page 7 of the latest paper. |"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1926/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700621728452,
                "cdate": 1700621728452,
                "tmdate": 1700621728452,
                "mdate": 1700621728452,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "EXP5El547a",
            "forum": "kaGA40pfFY",
            "replyto": "kaGA40pfFY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1926/Reviewer_Zkyz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1926/Reviewer_Zkyz"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes Rationality of Thought, a prompting technique for reducing cognitive biases in LLMs. Based on a diverse collection of psychology papers, the authors compose a dataset of 464 questions reflecting 29 cognitive bias types. The RoT prompt improves performance of GPT-3.4 and -4 on this set of questions, and transfers effectively to other LLM benchmarks."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The approach is well grounded in studies of human psychology. \n- The authors expend significant effort on summarizing the cognitive bias types in prior psychology work.\n- The constructed dataset is valuable for assessing the cognitive biases of general-purpose AI agents.\n- The RoT prompt is simple and effective. It improves the performance of LLMs significantly, outperforming chain-of-thought."
                },
                "weaknesses": {
                    "value": "- The data collection process is insufficiently detailed. See questions. \n- The prompt search process is not transparent. See questions\n- Missing ablation studies. \n- The authors do not discuss the limitations of this approach (e.g., time/#tokens, generalizability)."
                },
                "questions": {
                    "value": "- Does the dataset have a train and a test set? If yes, are the results in figure 2 on the train or test set? If no, did you search for a prompt to overfit GPT-4 on the dataset?\n- The questions are collected from \"multiple authoritative psychological works\"? Are they the same as those from which you compose the list 93 common cognitive biases? If not, you must cite them explicitly. \n- What are the limitations of the dataset? Is it also biased in some way (e.g., representing only Western culture, focusing on a majority group)?\n- How did you come up with the prompt? Are these steps of solving a problem proposed prior psychology work?\n- For a fair comparison, can you also provide the results of CoT zeroshot in table 3? It is possible to put the average cost of each prompting technique as a column?\n- Can you conduct an ablation study to demonstrate the importance of each step in RoT? \n- Step 3 of the prompt encourages \"probability calculations, Bayesian methods, and other data analysis techniques\". It is a very specific request. Do you have evidence that the models actually follow this instruction? How do they behave when the solution of a problem does not require one of those techniques? \n- Do you use the same prompt for each evaluation domain? Are there any customizations?\n- Do you specify all the RoT steps all at once or input one step, wait for GPT to respond and then input the next step?\n- It would be more interesting to try this method on tasks on which the Direct-zeroshot performance is low (e.g., code generation?). Except GSM8K, performance of GPT-4 on other tasks is already strong."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1926/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1926/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1926/Reviewer_Zkyz"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1926/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698815027273,
            "cdate": 1698815027273,
            "tmdate": 1700636192954,
            "mdate": 1700636192954,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HwpplBx9hc",
                "forum": "kaGA40pfFY",
                "replyto": "EXP5El547a",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1926/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1926/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewers,\n\nFirst and foremost, we would like to express our sincere gratitude for the time and effort you have dedicated to reviewing our manuscript.Your reviews have been extremely helpful in improving our research work. This process has not only strengthened our current manuscript but also enriched our understanding of the subject matter.\nIn the past week, in reference to your reviews, we have supplemented the relevant experiments and clarified some of the previously unclear descriptions in our manuscript. Next, we will respond to your comments one by one.\n\nPlease kindly note, due to the extensive nature of my response and the limitation of 5000 characters per message, I will be submitting my response in multiple parts. I kindly ask for your patience and suggest that you review them collectively once all parts have been sent. Thank you very much for your understanding.\n\n| Comment | Response |\n| --- | --- |\n| Does the dataset have a train and a test set? If yes, are the results in figure 2 on the train or test set? If no, did you search for a prompt to overfit GPT-4 on the dataset? | Our bias dataset was not divided into training and testing sets. After constructing this dataset, we directly tested the models (GPT-4, GPT-3.5-turbo, LLAMA2-13B-chat) on it, using the RoT strategy. Therefore, the results in Figure 2 can be understood as the performance of these models on an unseen dataset.  Additionally, we did not search for a prompt to overfit GPT-4 on the dataset. Our RoT strategy is grounded in professional logic from cognitive science and psychology. Specifically, our approach references works such as \"Thinking, Fast and Slow\" by Daniel Kahneman, \"The Rationality Quotient: Toward a Test of Rational Thinking\" by Keith E. Stanovich et al., \"Beyond IQ: A Triarchic Theory of Human Intelligence\" by Robert J. Sternberg, and \"Intuition Pumps And Other Tools for Thinking\" by Daniel Dennett, among others. Drawing from these comprehensive theories in cognitive science and psychology, we decompose the process of rational thinking into six steps, which are the core of our proposed RoT method:   1. Identify a complex or novel task: Recognize the essence and key issues of the current task. 2. Mobilize cognitive and physical resources: Utilize the large model for accessing existing concepts, data, and solutions relevant to the task. 3. Formulate solutions: Establish objectives and select appropriate cognitive strategies (e.g., employing prior probabilities and Bayesian methods for inferential reasoning). 4. Analyze data, execute logical reasoning: Monitor and review each step in real-time during the task execution. 5. Generate solutions or decisions: Compute the likelihood of each potential answer and then provide the most probable one. 6. Evaluate output results and make corresponding adjustments: Assess from a rational standpoint and provide the final answer. These steps synthesize key concepts and theories from the aforementioned works on human rational thinking. For example:   - Identifying complex or novel tasks: This step relates to the concept of \"bounded rationality\" introduced by Herbert Simon in \"The Bounds of Reason.\" Simon emphasized the limitations and necessity of simplification strategies in human information processing, echoing the process of recognizing and understanding novel tasks. - Formulating solutions: Keith E. Stanovich's \"Rational Choice: The Psychology of Rational Thought\" offers an in-depth analysis of using different cognitive strategies for problem-solving, consistent with setting goals and choosing strategies in solution formulation. - Analyzing data, executing logical reasoning: The description of System 2 in Daniel Kahneman's \"Thinking, Fast and Slow\" fits this step well. System 2 involves slow, effortful logical thinking, closely associated with data analysis and logical reasoning execution, etc. Thus, we constructed the RoT method directly through these key concepts and theories, a method proven effective through empirical testing. |\n| The questions are collected from \"multiple authoritative psychological works\"? Are they the same as those from which you compose the list 93 common cognitive biases? If not, you must cite them explicitly. | Yes\uff0cThey are the same as those from which we compose the list 93 common cognitive biases.We have already made a clear reference list behind\"multiple authoritative psychological works\".  |"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1926/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700620555427,
                "cdate": 1700620555427,
                "tmdate": 1700620555427,
                "mdate": 1700620555427,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vhzle6EcFK",
                "forum": "kaGA40pfFY",
                "replyto": "ai441vEdBw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1926/Reviewer_Zkyz"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1926/Reviewer_Zkyz"
                ],
                "content": {
                    "title": {
                        "value": "Thanks"
                    },
                    "comment": {
                        "value": "I have raised the score to 8."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1926/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700636213475,
                "cdate": 1700636213475,
                "tmdate": 1700636213475,
                "mdate": 1700636213475,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "AZpYzC9KEa",
            "forum": "kaGA40pfFY",
            "replyto": "kaGA40pfFY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1926/Reviewer_BFjh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1926/Reviewer_BFjh"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a new prompt for LLM called \"Rationality of Thought\" especially designed to extract more rational answers from input queries. The prompt is evaluated on a proposed cognitive bias dataset as well as a number of reasoning datasets and is shown to outperform both direct prompting as well as the existing \"chain-of-thought\" prompting."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is easy to read and the overall presentation is clear.\n\nThe contribution of this work -- the RoT prompt, seems novel and works especially well for super large model like GPT-4."
                },
                "weaknesses": {
                    "value": "I think the only missing element is an ablation study. Given the rather wordy prompt, one wonders which part of it contributes the most to improving answer quality. \n\nAlthough it is in the appendix, I am not sure what role Table 4 plays in this work. Where is this algorithm used?"
                },
                "questions": {
                    "value": "See above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1926/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698849377521,
            "cdate": 1698849377521,
            "tmdate": 1699636123176,
            "mdate": 1699636123176,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fPz96YgMXz",
                "forum": "kaGA40pfFY",
                "replyto": "AZpYzC9KEa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1926/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1926/Authors"
                ],
                "content": {
                    "title": {
                        "value": "An ablation study on the RoT method using GPT-4 revealed that each step is crucial for performance, with step 3 being especially vital for enhancing the model's cognitive reasoning abilities, as evidenced by a significant performance drop when removed."
                    },
                    "comment": {
                        "value": "Dear Reviewers,\nFirst and foremost, we would like to express our sincere gratitude for the time and effort you have dedicated to reviewing our manuscript.Your reviews have been extremely helpful in improving our research work. This process has not only strengthened our current manuscript but also enriched our understanding of the subject matter.\nIn the past week, in reference to your reviews, we have supplemented the relevant experiments and clarified some of the previously unclear descriptions in our manuscript. Next, we will respond to your comments one by one.\n| Comment | Response |\n|---------|----------|\n| I think the only missing element is an ablation study. Given the rather wordy prompt, one wonders which part of it contributes the most to improving answer quality. | We have conducted an ablation study on the RoT method by \"removing one at a time\" each step and utilized the GPT-4 model to experiment on a biased dataset. Observing the results (Table 2), it was evident that removing any step caused some detriment to the final outcomes. The most significant harm occurred with the removal of step 3, which led to a 9% decrease in model performance. This aligns with our hypothesis, as cognitive biases, from the perspectives of cognitive science and psychology, are primarily due to humans\u2019 tendency to rely on \u201dSystem 1\u201d for intuitive judgments, thereby lacking rigorous data analysis. Moreover, the entire RoT method is a holistic thinking framework, where each step contributes to and enhances the others. Therefore, the absence of any step inevitably leads to a decline in model performance. Overall, according to the experimental data, the third step is particularly crucial in improving the model's cognitive reasoning abilities. For specific experimental results data, please refer to Table 2 on page 7 of the latest paper. |\n| Although it is in the appendix, I am not sure what role Table 4 plays in this work. Where is this algorithm used? | This code illustrates the decision-making and reasoning process of the ROT algorithm, including the prior probability estimation of options, the calculation process of Bayesian probability, and the probability calculation of each option. |\n\nAbove are all our responses, which have been updated in the latest version of our manuscript. For more detailed information, please refer to the newly submitted version of our paper. \nOnce again, we thank you for your time and effort."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1926/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700619700608,
                "cdate": 1700619700608,
                "tmdate": 1700619700608,
                "mdate": 1700619700608,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YA7f4mMTDN",
                "forum": "kaGA40pfFY",
                "replyto": "fPz96YgMXz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1926/Reviewer_BFjh"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1926/Reviewer_BFjh"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your effort in preparing the revisions, I maintain my rating."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1926/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700633495950,
                "cdate": 1700633495950,
                "tmdate": 1700633495950,
                "mdate": 1700633495950,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]