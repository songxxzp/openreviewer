[
    {
        "title": "Guiding Masked Representation Learning to Capture Spatio-Temporal Relationship of Electrocardiogram"
    },
    {
        "review": {
            "id": "RA0vZWl6LY",
            "forum": "WcOohbsF4H",
            "replyto": "WcOohbsF4H",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5394/Reviewer_mpnR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5394/Reviewer_mpnR"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a simple but effective ECG specific generative self-supervised learning framework utilizing both spatial and temporal characteristics of ECG. The project is straightforward, and well examined."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Althogh it's ECG specific, this work provides two important insights. 1) solution for data domain in which cost of labeling is quite high. 2) The electrocardiogram is an indirect observation of the electrical behavior of a single heart from multiple points on the body surface to begin with, and this approach has potential for application to similar data domains that exist not only in medicine."
                },
                "weaknesses": {
                    "value": "The problem setting is specialized to the ECG, and the scope might be too narrow for the general audiencs of ICLR."
                },
                "questions": {
                    "value": "To claim \"general ECG representation\", it is quite important what actual task was tested. Could you provide more details of classification of myocardial infarction as well as classification of cardiac arrhythmia, e.g., what are the diagnostic criteria of myocardial infarction? What type of arrhythmia are classified?\n\nThe authors tested Lead I for the single lead task. In a clinical setting, Lead II is the first choice in many situations. Did the author evaluate for Lead II as well?\n\nIt would be quite important for the general audience of ICLR that the authors discuss possible extension of this approach outside of ECG or the medical field.\n\nMinor point.\nIn Figure 2, the authors assigned the same color code to two different segmentations. Could you change one of them to the other color code such as grayscale?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5394/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698632985674,
            "cdate": 1698632985674,
            "tmdate": 1699636546271,
            "mdate": 1699636546271,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jdvfDneATS",
                "forum": "WcOohbsF4H",
                "replyto": "RA0vZWl6LY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5394/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5394/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "### __[Discussing possible extension of ST-MEM outside of ECGs]__\n \n\u3164\n\n|   Methods  |     _HAR_    |       |\n|:----------:|:------------:|:-----:|\n|            | __Accuracy__ | __F1__|\n|__Supervised__|        0.964 | 0.967 |\n|  __MTAE__  |        0.965 | 0.968 |\n| __ST-MEM (Ours)__ |      __0.983__|__0.984__|\n\n\u3164\n\n__Reply__: While our focus is introducing the general ECG representation, we believe that our approach holds the potential for conducting diverse time-series data. Conceptually, the lead can be regarded as a general feature in the time-series domain. To explore this applicability, we demonstrated experiments on human activity recognition [1] (_HAR_) time-series data (as presented in Table 21), comparing the performance of ST-MEM against the supervised model and the masked time autoencoder (MTAE) model. Additionally, we provided an extra section discussing future prospects in Section 8.\n\n\u3164\n\n__Change__: We included the future work in Section 8. Moreover, we provided the additional experiment on other time-series data, human activity recognition (_HAR_) data, and Appendix J.\n\n\u3164\n\n\u3164\n\n### __[Label information of this paper]__\n\n\u3164\n\n__Reply__: In Appendix A, we included explanations for all labels in each of the downstream datasets. Table 6, 7, and 8 provide details on the target labels assigned to our three downstream datasets. Multiple arrhythmia such as atrial fibrillation (AFIB), first degree atrioventricular block (1AVB), premature ventricular contraction (PVC) and ST-segment depression (STD) are included as labels. Taking the myocardial infarction (MI) label in _PTB-XL_ as an example, as explained in Table 6, MI is a merged label consisting of 14 individual labels interpreted by cardiologists using the corresponding ECG and the patient's medical record.\n\n\u3164\n\n__Change__: We updated Appendix A.\n\n\u3164\n\n\u3164\n\n### __[Experiments of different reduced lead settings]__\n\n\u3164\n \n|  Method  |    _PTB-XL_   |               |               |               |               |               |\n|:--------:|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|\n|          |   __Lead I__  |  __Lead II__  |  __Lead III__ |  __Lead aVR__ |  __Lead aVL__ |  __Lead aVF__ |\n|__MTAE+RLM__| 0.795 \u00b1 0.003 | 0.833 \u00b1 0.002 | 0.742 \u00b1 0.005 | 0.839 \u00b1 0.002 | 0.753 \u00b1 0.006 | 0.801 \u00b1 0.003 |\n| __MLAE__ | 0.797 \u00b1 0.001 | 0.826 \u00b1 0.003 | 0.743 \u00b1 0.006 | 0.830 \u00b1 0.003 | 0.753 \u00b1 0.004 | 0.793 \u00b1 0.002 |\n| __ST-MEM (Ours)__ |__0.804 \u00b1 0.005__|__0.856 \u00b1 0.002__|__0.788 \u00b1 0.019__|__0.840 \u00b1 0.003__|__0.805 \u00b1 0.003__|__0.819 \u00b1 0.022__|\n\n\u3164\n\n__Reply__: Thank you for the valuable comment. We only evaluated the lead I in that the lead I is easily accessible through the smartwatch. However, as you suggested, we provided additional single-lead experiments on the other five limb leads in Appendix H, Table 19.\n\n\u3164\n\n__Change__: We provided Appendix H and Table 19.\n\n\u3164\n\n\u3164\n\n### __[Modifying Figure 2]__\n\n\u3164\n \n__Reply__: There are some similar comments regarding Figure 2 from the other reviewer as well. Therefore, we decided to modify Figure 2. Hopefully, this illustration can provide you better understanding.\n \n\u3164\n\n__Change__: Modified Figure 2.\n\n\u3164\n\n\u3164\n\n\n---\n### __Reference__\n\n\u3164\n\n[1] Anguita, Davide, et al. \"A public domain dataset for human activity recognition using smartphones.\" Esann. Vol. 3. 2013."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5394/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700309902114,
                "cdate": 1700309902114,
                "tmdate": 1700549026200,
                "mdate": 1700549026200,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "S1ow2UxCOi",
                "forum": "WcOohbsF4H",
                "replyto": "jdvfDneATS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5394/Reviewer_mpnR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5394/Reviewer_mpnR"
                ],
                "content": {
                    "title": {
                        "value": "Reply to the responses"
                    },
                    "comment": {
                        "value": "Thanks for providing additional detals. I thinks these are quite important for the ICLR audiences. I stay \"8: accept, good paper\"."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5394/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700622647370,
                "cdate": 1700622647370,
                "tmdate": 1700622647370,
                "mdate": 1700622647370,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "pxTfveIQ2J",
            "forum": "WcOohbsF4H",
            "replyto": "WcOohbsF4H",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5394/Reviewer_QUx7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5394/Reviewer_QUx7"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes ST-MEM (Spatio-Temporal Masked Electrocardiogram Modeling) as an approach to learn a feature representation of ECGs which considered both spatial and temporal aspects of the signal. In particular the authors use a lead-specific decoder to guide the network to learn spatial representation. The author demonstrates the effectiveness of the proposed method on multiple datasets includes PTB-XL, CPSC2018 and Physionet 2017 by comparing to supervised learning baseline, as well as other self-supervised learning methods and get superior results on both general setting and low-resource/reduced lead setting. The author also performs quantitative and qualitative analysis of the captured spatial and temporal relationship, with clustering and attention map respectively."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is well-written with clear methodology and clarity in details. The presentation is readily comprehensible.\n2. The proposed method has superior performance on important public datasets compared to several other contrastive and generative self-supervised learning methods. The favorable performance of proposed method also extends to practical scenarios of reduced lead and low-resource setting."
                },
                "weaknesses": {
                    "value": "1. The idea of using MAE to learn representation for ECG signal has been explore previous work(Sawano et al., 2022[1] in the reference). The author should highlight the difference.\n2. The experiment session seems missing some previous works. For example, Temesgen et al., 2022[2] also report metrics on PTB-XL and seems to have higher AUROC score.\n\n\n[1] Shinnosuke Sawano, Satoshi Kodera, Hirotoshi Takeuchi, Issei Sukeda, Susumu Katsushika, and Is- sei Komuro. Masked autoencoder-based self-supervised learning for electrocardiograms to detect left ventricular systolic dysfunction. In NeurIPS 2022 Workshop on Learning from Time Series for Health, 2022.\n[2] Mehari, Temesgen, and Nils Strodthoff. \"Self-supervised representation learning from 12-lead ECG data.\" Computers in biology and medicine 141 (2022): 105114."
                },
                "questions": {
                    "value": "1. In the \"PERFORMANCE IN REDUCED LEAD SETTINGS\" section, 1-lead part was using lead I. How is the choice being made? Would it be valuable to also report 1-lead performance of other 5 leads?\n2. In the same section, all methods seem to have larger 6-lead vs 1-lead gap on PTB-XL than CPSC2018. Does the author have insight on why this is the case?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5394/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5394/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5394/Reviewer_QUx7"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5394/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698828792678,
            "cdate": 1698828792678,
            "tmdate": 1700732693477,
            "mdate": 1700732693477,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HU9IyNmtpR",
                "forum": "WcOohbsF4H",
                "replyto": "pxTfveIQ2J",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5394/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5394/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "### __[Highlighting distinctions from [1] in the methodology]__\n\u3164\n\n__Reply__: Although we discussed the methodology of this work in Section 6.1, we did not tagged the reference and adequately emphasize the differences from our paper. It solely applies the spatio-temporal patchifying mentioned in Figure 2(c), i.e., excluding the lead indicating modules and lead-wise decoder. \n\nOur comparison with this work is elaborated in Section 5.5. In first row of Table 5, the average AUROC of [1] in _PTB-XL_ and _CPSC2018_ is 0.805 and 0.861, respectively. In contrast, ST-MEM outperforms [1] with average AUROC values of 0.838 and 0.938 in _PTB-XL_ and _CPSC2018_, respectively. We updated Section 6.1 to reflect changes. \n\nMoreover, in Appendix B, by drawing t-SNE plots as Figure 6, we quantitatively analyzed how well the representation was learned. This analysis was conducted on both regular and irregular rhythms. [1], which utilizes only spatio-temporal patchifying, forms clusters effectively within the same lead for (b) and (d), but struggles to form clusters among spatially similar leads. On the contrary, ST-MEM for (a) and (c) not only forms clusters effectively within the same lead but also, limb leads (I, II, III, aVR, aVL, and aVF) cluster together, and precordial leads (V1, V2, V3, V4, V5, and V6) cluster together.\n\n\u3164\n\n__Change__: We modified Section 6.1.\n\n\u3164\n\n\u3164\n---\n### __Reference__\n\n[1] Shinnosuke Sawano, Satoshi Kodera, Hirotoshi Takeuchi, Issei Sukeda, Susumu Katsushika, and Is- sei Komuro. Masked autoencoder-based self-supervised learning for electrocardiograms to detect left ventricular systolic dysfunction. In NeurIPS 2022 Workshop on Learning from Time Series for Health, 2022."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5394/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700309229383,
                "cdate": 1700309229383,
                "tmdate": 1700463034367,
                "mdate": 1700463034367,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5Bqix76mQ4",
                "forum": "WcOohbsF4H",
                "replyto": "pxTfveIQ2J",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5394/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5394/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "### __[Comparison with other previous work]__\n\n\u3164\n\n#### __Table caption__: Experiments in low-resource settings. CPC indicates the original implementation of pre-trained model that utilizes pre-training datasets including _PTB-XL_ and _CPSC2018_. 250 Hz and 100 Hz represent the sampling rate for ECG preprocessing during the fine-tuning stage. Note that CPC was pre-trained in a sample rate of 100 Hz, yet our default sample rate experimental setting is 250 Hz. Furthermore, 1% and 5% indicate random sampling for training and validation data, while the test data remain constant for all results. Three different samplings were conducted, and the results were averaged. 12-lead ECG signals are used for each result, and the scores represent AUROC scores.\n|    Method    |    _PTB-XL_   |               |               |  _CPSC2018_  |               |               |\n|:------------:|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|\n|              |     __1%__    |     __5%__    |    __100%__   |     __1%__    |     __5%__    |    __100%__   |\n|__Supervised__| 0.676 \u00b1 0.011 |  0.736 \u00b1 0.020 | 0.905 \u00b1 0.004 |  0.600 \u00b1 0.095  | 0.609 \u00b1 0.111 | 0.958 \u00b1 0.002 |\n|  __MoCo v3__ | 0.797 \u00b1 0.006 | 0.826 \u00b1 0.015 | 0.913 \u00b1 0.002 | 0.791 \u00b1 0.045 | 0.903 \u00b1 0.019 | 0.967 \u00b1 0.003 |\n|   __CMSC__   | 0.648 \u00b1 0.064 | 0.773 \u00b1 0.023 | 0.877 \u00b1 0.003 | 0.625 \u00b1 0.013 | 0.732 \u00b1 0.038 | 0.938 \u00b1 0.006 |\n|   __MTAE__   | 0.707 \u00b1 0.024 | 0.713 \u00b1 0.001 |  0.910 \u00b1 0.001 |  0.670 \u00b1 0.032 | 0.756 \u00b1 0.013 | 0.961 \u00b1 0.001 |\n|__MTAE + RLM__|  0.730 \u00b1 0.030  |  0.730 \u00b1 0.003 | 0.911 \u00b1 0.004 |  0.708 \u00b1 0.020 | 0.726 \u00b1 0.011 |  0.960 \u00b1 0.002 |\n|   __MLAE__   | 0.793 \u00b1 0.007 | 0.838 \u00b1 0.018 | 0.915 \u00b1 0.001 |  0.860 \u00b1 0.013 | 0.922 \u00b1 0.007 | 0.973 \u00b1 0.002 |\n|__CPC (250Hz)__| 0.740 \u00b1 0.057 | 0.838 \u00b1 0.024 | 0.933 \u00b1 0.001 | 0.754 \u00b1 0.015 | 0.898 \u00b1 0.026 | 0.974 \u00b1 0.002 |\n|__CPC (100Hz)__| 0.773 \u00b1 0.014 | 0.842 \u00b1 0.043 | __0.934 \u00b1 0.002__ | 0.762 \u00b1 0.058 | 0.917 \u00b1 0.016 | 0.973 \u00b1 0.003 |\n|  __ST-MEM (Ours)__  | __0.815 \u00b1 0.012__ | __0.878 \u00b1 0.011__ | 0.933 \u00b1 0.003 | __0.897 \u00b1 0.025__ | __0.952 \u00b1 0.004__ |  __0.980 \u00b1 0.001__ |\n\n\u3164\n\n__Reply__: The paper [2] proposes Contrastive Predictive Coding (CPC) to ECG data. However, the experimental setting for [2] is different from ours which causes the discrepancy in the AUROC score in the _PTB-XL_ dataset. For instance, their problem setting is a multi-label classification for all 71 labels; however, we define the problem as multi-class classification using super-class labels provided from the original _PTB-XL_ paper. Our detailed experimental settings can be found in Appendix A.1. Sorry for the unclearness of the experimental setting.\n\nSince the experimental setting is different from [2], we utilized the pre-trained weights provided in the original paper. Then, we fine-tuned the CPC model on our settings. We could validate that ST-MEM still shows comparable performance and surpasses all the low-resource settings even though the CPC model utilized _PTB-XL_ and _CPSC2018_ to pre-train the model. We provided the additional experiments in Appendix K. \n\n\u3164\n\n__Change__: We added the new section as Appendix K.\n\n\u3164\n\n\u3164\n\n---\n### __Reference__\n\n[2] Mehari, Temesgen, and Nils Strodthoff. \"Self-supervised representation learning from 12-lead ECG data.\" Computers in biology and medicine 141 (2022): 105114."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5394/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700309361105,
                "cdate": 1700309361105,
                "tmdate": 1700463362659,
                "mdate": 1700463362659,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XKy4ivshin",
                "forum": "WcOohbsF4H",
                "replyto": "pxTfveIQ2J",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5394/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5394/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "### __[Experiments of different reduced lead settings]__\n\u3164\n\n|  Method  |    _PTB-XL_   |               |               |               |               |               |\n|:--------:|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|\n|          |   __Lead I__  |  __Lead II__  |  __Lead III__ |  __Lead aVR__ |  __Lead aVL__ |  __Lead aVF__ |\n|__MTAE+RLM__| 0.795 \u00b1 0.003 | 0.833 \u00b1 0.002 | 0.742 \u00b1 0.005 | 0.839 \u00b1 0.002 | 0.753 \u00b1 0.006 | 0.801 \u00b1 0.003 |\n| __MLAE__ | 0.797 \u00b1 0.001 | 0.826 \u00b1 0.003 | 0.743 \u00b1 0.006 | 0.830 \u00b1 0.003 | 0.753 \u00b1 0.004 | 0.793 \u00b1 0.002 |\n| __ST-MEM (Ours)__ | __0.804 \u00b1 0.005__ | __0.856 \u00b1 0.002__ | __0.788 \u00b1 0.019__| __0.840 \u00b1 0.003__ | __0.805 \u00b1 0.003__ | __0.819 \u00b1 0.022__ |\n\u3164\n \n__Reply__: Thank you for suggesting valuable experiments. Mobile devices such as smartwatches usually provide lead I; thus, we consider the practical scenario to choose lead I for the single lead reduced lead settings. However, as you suggested, we also provided additional single lead experiments in Appendix H. As shown in Table 19, we could validate that ST-MEM outperformed other baselines on other lead types.\n\n\u3164\n \n__Change__: We provided Appendix H and Table 19.\n\n\u3164\n\n\u3164\n\n### __[Different performance gaps between 6-lead vs 1-lead across dataset]__\n \u3164\n\n__Reply__: We think the performance gaps depend on the difficulty of the task. As one can see in Table 3, the overall performance metrics on _CPSC2018_ are higher than _PTB-XL_, which may indicate that the _CPSC2018_ tasks are easier than _PTB-XL_. Specifically, single lead alone may be sufficient to classify particular classes of _CPSC2018_, such as atrial fibrillation (AFIB), premature ventricular complex (PVC), but this may not be the case for certain classes of _PTB-XL_, such as myocardial infarction (MI).\n\n\u3164\n\n__Change__: None."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5394/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700309514117,
                "cdate": 1700309514117,
                "tmdate": 1700463509463,
                "mdate": 1700463509463,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ABYRbZiGjC",
                "forum": "WcOohbsF4H",
                "replyto": "pxTfveIQ2J",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5394/Reviewer_QUx7"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5394/Reviewer_QUx7"
                ],
                "content": {
                    "title": {
                        "value": "Response to the authors's comment"
                    },
                    "comment": {
                        "value": "Thanks the authors for taking the time to draft clear responses and make the change.\n\nDear area chairs and Reviewers,\n\nGiven the change and clarification from the authors, I am pleased to update the rating to: \n6: marginally above the acceptance threshold"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5394/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700732658965,
                "cdate": 1700732658965,
                "tmdate": 1700732724757,
                "mdate": 1700732724757,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "u0MZ8IxMFq",
                "forum": "WcOohbsF4H",
                "replyto": "pxTfveIQ2J",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5394/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5394/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for responding to our comments. We are glad that we could have addressed your concern of the comparison with other related works."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5394/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700734342927,
                "cdate": 1700734342927,
                "tmdate": 1700736565251,
                "mdate": 1700736565251,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "WCiq3OI1yU",
            "forum": "WcOohbsF4H",
            "replyto": "WcOohbsF4H",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5394/Reviewer_knNF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5394/Reviewer_knNF"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a self-supervised pre-training method for multi-lead ECG data that can be generalized to reduced lead sets. The method relies on spatio-temporal patch reconstruction, with led-wise shared decoders. The experiments were performed by pre-training on three ECG datasets and fine-tuning to two different down-stream ECG datasets/tasks. Results demonstrated the improvement in downstream tasks in comparison to supervised baselines and various unsupervised pre-training methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper was overall clearly written and easy to follow.\n\nThe experimentation was thorough, especially in the inclusion of relevant baselines, and the empirical results speak favorably to the contribution of the work.\n\nThe use in low-resource settings is interesting, and the gain brought by proposed pre-training more significant."
                },
                "weaknesses": {
                    "value": "Despite favorable empirical results, the intuition of the spatiotemporal patching based self-supervised learning is not very clear. It is not clear why such patching will help the learning of spatiotemporal representations. Furthermore, the relation with two baselines \u2014 MLAE that reconstructs spatial patches and MTAE that reconstructs temporal patches \u2014 need to be better clarified. \n\nThe assumption of the method, in particular to what type of ECG signals and tasks this will apply, needs to be better discussed. For instance, the use of temporal patching seems to rely on the assumption that the rhythm  within the input signal length (e.g., 10s) \u2014 whether it is normal or abnormal \u2014is regular and periodic.  Is that true? How would this work for rhythms that are irregular (e.g., atrial fibrillation), or rhythms where the abnormal rhythm only shows up in transient beats within a longer segment (which is typical for some PVCs and tachycardias). If the method is not designed for these scenarios, it should be clearly clarified.  \n\nRelated to the above comments, more details about the data and classification tasks needed to be given. What are the labels of rhythms being classified? Does each 10-s segment only has one label? The paper did a good job in highlighting the it\u2019s important to develop methodology to the application problem at hand \u2014 this should also be reflected when describing data and experimental settings, as different ECG tasks can mean that the features one are looking for is very different (e.g. is it a regular rhythm, is it an irregular rhythm, is it a transient rhythm, etc).\n\nOverall, while the performance gain is notable, they are also overall limited \u2014 at 2 decimal points compared to supervised baselines wen using 100% data. It is not clear what is the clinical significance of such performance gain. Perhaps it is because the supervised baselines are already quite good in the tasks considered (over 0.9 AUROC in both downstream datasets). It may be more convincing if the authors could find \u201charder\u201d base tasks in order to see if the proposed method will have clinical significance."
                },
                "questions": {
                    "value": "Please clarify the main questions listed in my above comments. \n\nIn addition, it\u2019d be interesting to see Fig 4, the embedding of the ECG signals, across different rhythm types as well, in order to appreciate the clustering across rhythm types versus spatial locations of the lead."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5394/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5394/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5394/Reviewer_knNF"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5394/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698869472633,
            "cdate": 1698869472633,
            "tmdate": 1700768569138,
            "mdate": 1700768569138,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9rT7wx1x36",
                "forum": "WcOohbsF4H",
                "replyto": "WCiq3OI1yU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5394/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5394/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "### __[Better explanation of the spatiotemporal patching]__\n \n\u3164\n\n__Reply__: The spatiotemporal patching allows the encoder to consider both temporal and spatial relationships concurrently. On the other hand, temporal patching leads the encoder to consider only the temporal relationship. The spatial patching (i.e., lead patching) discourages the encoder from capturing temporal relationships. For a better understanding of the patching approach, we modified Figure 2.\n\n\u3164\n \n__Change__: We modified Figure 2.\n\n\u3164\n\n\u3164\n\n\n### __[Clarifying the baselines, Masked Time Auto Encoder (MTAE) and Masked Lead Auto Encoder (MLAE)]__\n\n\u3164\n \n__Reply__: Since the MTAE and MLAE take different patching strategies (i.e., temporal or spatial patching), the encoder can only consider either temporal or spatial relationships. In other words, the encoder of MTAE utilizes temporal patching to capture the temporal relationship only, while the encoder of MLAE takes spatial patches to consider the spatial relationship only. Furthermore, MTAE and MLAE cannot explicitly distinguish the lead type information, whereas ST-MEM can encapsulate the lead type information through lead embedding and [SEP] patch embedding. We revised the manuscript to clarify the relation of baselines (MTAE and MLAE) with ST-MEM.\n \n\u3164\n\n__Change__: We clarified in Section 4.2 that MTAE and MLAE do not have lead indicating modules and differ in their approach to patchifying input ECGs with ST-MEM.\n\n\u3164\n\n\u3164\n\n\n### __[Applicability of the method to regular and irregular ECGs]__\n\n\u3164\n \n__Reply__: We used the ECGs of both regular and irregular rhythms during pre-training. We assume that the masked parts of the input signal can be reconstructed by utilizing the information extracted from the unmasked portions, regardless of the regularity of the rhythms. We did not mention the detailed characteristics of pre-training data, so we clarified in Section 4.1 that we used all ECGs of pre-training data without focusing on specific labels (e.g., normal rhythm).\n \nAdditionally, for more clarification, we demonstrated the self-attention maps of pre-trained ST-MEM for irregular rhythm ECGs in Appendix D. Notably, ST-MEM consistently assigned high attention weights to temporal patches that have similar shape to the query patch and neighboring spatial patches, regardless of the rhythm type of ECG. From this observation, we conjecture that pre-trained ST-MEM can effectively recognize the morphologies of ECG signals.\n \n\u3164\n\n__Change__: We clarified that we used ECGs of all rhythm types in Section 4.1, and demonstrated the self-attention maps of pre-trained ST-MEM for regular and irregular rhythm ECGs in Appendix D.\n\n\u3164\n\n\u3164\n\n\n### __[Explanation of dataset and classification task]__\n\n\u3164\n\n__Reply__: In appendix A, we added description for all labels of all 3 downstream datasets. In table 6, 7, and 8, we have outlined the target labels for our three downstream datasets. As apparent from the tables, we employed a variety of ECGs in both training and evaluation, encompassing regular rhythms such as Normal ECG and irregular rhythms like atrial fibrillation (AFIB), first degree atrioventricular block (1AVB) and premature ventricular contraction (PVC). Notably, during pretraining, we used all ECGs without focusing on specific labels. Typically, an ECG may have more than one label, but for our multiclass classification setting, we used only ECGs with a single label, discarding the rest. This processing step is also depicted in Section 4.1 and Appendix A. \n\n\u3164\n\n__Change__: We modified Section 4.1 and Appendix A."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5394/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700307929611,
                "cdate": 1700307929611,
                "tmdate": 1700307929611,
                "mdate": 1700307929611,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vb1ZdIOjgE",
                "forum": "WcOohbsF4H",
                "replyto": "WCiq3OI1yU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5394/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5394/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "### __[Clinical significance regarding the main result]__\n \u3164\n\n|           | Sensitivity | Specificity |\n|-----------|-------------|-------------|\n| __Supervised__| 77.3%       | 90.1%       |\n| __ST-MEM (Ours)__     | __88.2%__       | 90.1%       |\n\u3164\n\n__Reply__: The increase of AUROC by two decimal points may be interpreted as a slight performance gain. However, given that the AUROC measures the area under the curve representing the trade-off between the true positive rate (i.e., sensitivity) and false positive rate (i.e., 1-specificity), the noteworthy difference in sensitivity at the same specificity becomes quite significant. For instance, we computed the sensitivity and specificity of myocardial infarction (MI) classification results on the _PTB-XL_ dataset using the supervised and ST-MEM model. The supervised baseline provides sensitivity=0.773, whereas ST-MEM achieves 0.882 sensitivity. In other words, ST-MEM can classify 88.2% of MI on ECGs, while the supervised model can only classify 77.3%. We believe this difference is clinically significant since MI is known as a high-mortality disease.\n\u3164\n\n| _PTB-XL_     |               |               |               |               |               |               |\n|------------|---------------|---------------|---------------|---------------|---------------|---------------|\n| __Method__     | __Lead I__             | __Lead II__            | __Lead III__           | __Lead aVR__           | __Lead aVL__           | __Lead aVF__           |\n|            | __1%__            |               |               |               |               |               |\n| __Supervised__ | 0.638 \u00b1 0.035 | 0.657 \u00b1 0.025 | 0.538 \u00b1 0.050  | 0.668 \u00b1 0.021 | 0.562 \u00b1 0.015 | 0.603 \u00b1 0.030  |\n| __ST-MEM (Ours)__       | __0.673 \u00b1 0.012__ | __0.752 \u00b1 0.030__  | __0.640 \u00b1 0.008__  | __0.681 \u00b1 0.008__ | __0.667 \u00b1 0.006__ | __0.674 \u00b1 0.010__  |\n|            | __5%__            |               |               |               |               |               |\n| __Supervised__ | 0.655 \u00b1 0.018 | 0.682 \u00b1 0.006 | 0.577 \u00b1 0.041 | 0.654 \u00b1 0.053 | 0.593 \u00b1 0.003 | 0.652 \u00b1 0.012 |\n| __ST-MEM (Ours)__       | __0.694 \u00b1 0.017__ | __0.786 \u00b1 0.024__ | __0.700 \u00b1 0.016__   | __0.691 \u00b1 0.012__ | __0.718 \u00b1 0.026__ | __0.723 \u00b1 0.024__ |\n\u3164\n\nMoreover, considering the label scarcity and challenge of obtaining standard 12 lead ECGs, we provide the additional challenging experiment of single lead in the low-resource setting. As shown in the above table, ST-MEM outperforms the supervised baseline for all single lead types. Interestingly, we could achieve a 0.786 AUROC score with only 5% of lead II ECGs. With the emergence of mobile devices like smartwatches enabling access to single-lead ECG data, we believe this experiment demonstrates the importance of ECG representation learning.\n\u3164\n\n__Change__: We provided Appendix I and Table 20.\t\n\n\u3164\n\n\u3164\n\n\n### __[t-SNE plot for ECGs with different rhythm types]__\n \u3164\n\n__Reply__: We demonstrated the t-SNE plots only for ECGs with a regular rhythm. We added the t-SNE plots for ECGs with irregular rhythm as well on Appendix B. The appearance of t-SNE plots was similar across different rhythm types, showing that the representations of neighboring leads were gathered closely.\n \u3164\n\n__Change__: We added t-SNE plots of ECGs with irregular rhythm in Appendix B."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5394/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700308214190,
                "cdate": 1700308214190,
                "tmdate": 1700463581234,
                "mdate": 1700463581234,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "IswbzRG5Ee",
            "forum": "WcOohbsF4H",
            "replyto": "WcOohbsF4H",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5394/Reviewer_pLfJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5394/Reviewer_pLfJ"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes a method called ST-MEM (Spatio-Temporal Masked Electrocardiogram Modeling), \nto leverage self-supervised learning (SSL) in order to train a model that can be used for diagnosis of conditions detectable through Electrocardiograms (ECG). \n\nST-MEM is based on a Masked auto-encoder and it uses a vision transformers (ViT) architecture. The 12 leads ECG signal is divided into temporal patches. Some patches are masked and the task is to reconstruct the masked signal. Each encoded patch is then added to a LEAD-specific encoding (a way to identify from which lead the signal is coming from) and to the traditional positional encoding (a way to identify temporary where the patch belongs). Additionally, a special token is appended and postponed to each lead signal. Since some leads share a highly correlated signal the decoder is a Lead-wise shared decoder (i.e. it only attempts to decode the signal from 1 lead at the time, this is to ensure that the task is not trivially solved by copying the masked patched from a highly correlated lead).\n\nAfter training a labeled dataset can be sued to train a linear layer on top of the encoder, or to fully fine-tuned the model.\n\nThe proposed model is pre-trained using a total of 188,480 ECGs 12 leads signals coming from three datasets (Chapman, Ningbo, CODE-15), and if tested using two different datasets PTB-XL and CPSC2018 on the task of detecting cardiac arrhythmia and myocardial infarction. Results (in terms of accuracy, F1 and AUROC) show that with linear fine-tuning, the proposed method performs better than other SSL methods albeit it still underperforms the supervised baseline. When fine-tuning, however, the proposed method surpasses also the supervised baselined in all the metrics employed. \n\nThe current method is also resilient to lower amount of data compared to all alternatives tested as shown by achieving the best results in terms of AUROC using only 1% and 5% of the fine-tuning dataset. \n\nAdditionally, the authors perform experiments using only a sub set of the leads or using only 1 lead (as in the PhysioNet2017 dataset). The proposed technique remains the best  performer across all baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper tackles an important problem since high quality ECG labeled data are scarce but ECG data in general is much more available. \n\nThe proposed solution is simple yet very effective as shown in the results, also compared to other SSL alternatives."
                },
                "weaknesses": {
                    "value": "Some part of the manuscript could be improved. For example:\n\tFigure 2 (c) is not clear. \n\tWhat is \u201cseasonality\u201d?\n\tSee more clarification to add to the manuscript from my questions below\n\nSome experiments could be stronger. For example PTB XL dataset have 4 different conditions but it seems that only a couple were used in the tests."
                },
                "questions": {
                    "value": "Having both the SEP token and the leads embedding seems redundant. Have the authors considered an ablation where only the leads embedding are used but not the SEP? If SEP is needed why is it needed twice and not just at the beginning or just at the end?\n\nHave the author considered using only a subset of the 8 augmentations used for the contrastive SSL baselines shown in Appendix D? Some of them could really alter the signal and be counter productive. For example, the Flip, the shift perhaps also the Sine and partial Sine.\n\nThe initial statement \u201cdetecting various heart diseases\u201d seem to imply that the proposed technique could do so, however, the tests only show a couple of heart condition. For example in the PTB XL dataset there are 4 different conditions, why not show the results on all of them?\n\n\u201cThe patches undergo flattening\u201d why is flattening needed here? Isn\u2019t the signal already flat?\n\nThe pre-training dataset comes with different sampling rate (two at 500Hz and 1 at 400Hz). How was this taken care of? Was the 500 subsampled? This should be explained.\n\nSimilarly the physionet comes with 200Hz, how was it adapted to the pre-trained model?\n\nFor signals that are longer than 10 seconds, I assume the signal was split into 10 seconds but how was all the outcome computed? Average? Voting? This should be clarified."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5394/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699560548144,
            "cdate": 1699560548144,
            "tmdate": 1699636545953,
            "mdate": 1699636545953,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XesLg8uEk5",
                "forum": "WcOohbsF4H",
                "replyto": "IswbzRG5Ee",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5394/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5394/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "### __[Modifying Figure 2]__\n\n\u3164\n\n__Reply__: Sorry for the unclearness. We modified Figure 2 to illustrate the intuition of different patch strategies.\n\n\u3164\n \n__Change__: Modified Figure 2.  \n\n\u3164\n\n\u3164\n\n### __[Clarifying the word \u201cseasonality\u201d in Section 5.6]__\n\n\u3164\n \n__Reply__: Sorry for the confusion in Section 5.6. We misused the word \"seasonality\". We attempted to define the repeatability of QRS segments as the word seasonality since the query patch contains QRS segments. Note that we tried to avoid the use of clinical terms. We modified the sentence and removed the word \"seasonality\".\n\n\u3164\n \n__Change__: Revising the sentence in section 5.6.\n \n\u201cMoreover, from a temporal perspective, the ECG signal contains seasonality such that the patch with similar seasonality shows high attention scores.\u201d \n\n->\n \n\u201cMoreover, from a temporal perspective, the patches show high attention scores if the signal shape is similar to the query patch in that the ECG signal contains a periodic rhythm.\u201d\n\n\u3164\n\n\u3164\n\n### __[Ablation on SEP embedding]__\n\n\u3164\n\n|    Ablation    |               |_PTB-XL_|\n|:--------------:|:-------------:|:------:|\n| __SEP embedding__ | __Lead embedding__ |        |\n|        X       |       X       |  0.822 |\n|        X       |       O       |  0.830 |\n|        O       |       X       |  0.820 |\n|        O       |       O       |  __0.838__ |\n\n\u3164\n\n__Reply__: We assessed the effectiveness of the lead indicating modules (e.g., SEP embedding, and lead embedding) by removing them one by one. We added Table 13, the _PTB-XL_ linear evaluation performances of the model trained with or without each lead indicating module in Appendix C. The highest AUROC score is observed when both modules are employed simultaneously, indicating that they mutually contribute to enhancing the model's ability to learn spatio-temporal relationships.\n\n\u3164\n\n#### __Table caption__: Our proposed case\n|     Patch embedding    |     [SEP]       |     Patch (I)    |     [SEP]       |     [SEP]        |     Patch(II)    |     [SEP]        |\n|------------------------|---------------|------------------|---------------|----------------|------------------|----------------|\n|     __Lead embedding__     |     Lead I    |     Lead I       |     Lead I    |     Lead II    |     Lead II      |     Lead II    |\n\n\u3164\n\n#### __Table caption__: alternative case\n|     Patch embedding    |     [SEP]       |     Patch (I)    |     [SEP]        |     Patch(II)    |     [SEP]        |\n|------------------------|---------------|------------------|----------------|------------------|----------------|\n|     __Lead embedding__     |     Lead I    |     Lead I       |     Lead II    |     Lead II      |     Lead II    |\n\n\u3164\n\nMoreover, there is the reason that we appended the SEP embedding twice, i.e., at the beginning and at the end of each lead signal. The above table depicts two cases. Imagine that we do the single lead experiments for lead I ECGs and lead II ECGs. The discrepancy of input shape for lead I and II would discourage the model from distinguishing the lead type. On the other hand, the proposed method can provide a consistent input shape on each single lead experiment. Therefore, we appended SEP embeddings twice.\n\n\u3164\n\n__Change__: We added Table 13 in Appendix C."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5394/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700307264213,
                "cdate": 1700307264213,
                "tmdate": 1700463876881,
                "mdate": 1700463876881,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ioP5frrCkp",
                "forum": "WcOohbsF4H",
                "replyto": "IswbzRG5Ee",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5394/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5394/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "### __[Selecting augmentations for pre-training MoCo v3]__\n \u3164\n\u3164\n\n__Reply__: We appreciate your valuable feedback. Some augmentations may not preserve the semantics of the data and even have a negative impact. In that case, in contrastive learning with such augmentations, achieving high-quality representations might be challenging. We excluded four augmentations (flip, shift, sine, and partial sine) that could potentially affect the semantics of ECG data. We then pre-trained MoCo v3 using the remaining four augmentations (erase, drop, cutout, and partial noise) and compared the results with experiments using the original eight augmentations. After pre-training on the same 12-lead dataset, we fine-tuned the model on 12-lead ECGs from _PTB-XL_ and _CPSC2018_. The results are presented in the table below.\n\n\n|     Methods                     |     _PTB-XL_      |              |              |     _CPSC2018_    |              |              |\n|---------------------------------|-----------------|--------------|--------------|-----------------|--------------|--------------|\n|                                 |     __Accuracy__    |     __F1__       |     __AUROC__    |     __Accuracy__    |     __F1__       |     __AUROC__    |\n|     __Linear evaluation__           |                 |              |              |                 |              |              |\n|     __MoCo v3, 4 augmentations__    |   __0.552__     |   __0.142__  |     0.709    |     0.209       |     0.038    |     0.644    |\n|     __MoCo v3, 8 augmentations__    |   __0.552__     |   __0.142__  |   __0.739__  |   __0.268__     |   __0.080__  |   __0.712__  |\n|     __Fine-tuning__                 |                 |              |              |                 |              |              |\n|     __MoCo v3, 4 augmentations__    |     0.798       |     0.636    |     __0.915__    |     0.833       |     0.816    |   __0.967__  |\n|     __MoCo v3, 8 augmentations__    |     __0.799__       |     __0.644__    |     0.910    |     __0.852__       |     __0.838__    |     __0.967__    |\n\n\nAs shown in the table, using all eight augmentations performed better than using only four augmentations for all settings except for the fine-tuning the model on _PTB-XL_.\n\n\nSelecting proper augmentations is challenging when working with ECG signals. This complexity emphasizes the need of the generative learning (masking and reconstruction) against the contrastive learning which requires to consider the combination of proper augmentations.\n\n\u3164\n\n__Change__: We added new section as Appendix G.\n\n\u3164\n\n\u3164\n\n### __[Different problem settings of downstream dataset _PTB-XL_]__\n\n\u3164\n\n__Reply__: We focused solely on the task of distinguishing the 5 super-classes of diagnostic labels for _PTB-XL_. We conducted additional experiments for the other three settings: 23 diagnostic sub-class labels, 19 form labels, and 12 rhythm labels. In this multi-label classification experiment, our proposed method demonstrated superiority over other baselines (supervised learning and MTAE). Further details have been included in the Appendix F.\n\n\n|     Methods       |     Categories       |                      |                      |\n|-------------------|----------------------|----------------------|----------------------|\n|                   |     __Sub-class__         |     __Form__             |     __Rhythm__           |\n|     __Supervised__    |     0.914 \u00b1 0.002    |     0.829 \u00b1 0.021    |     0.934 \u00b1 0.003    |\n|     __MTAE__          |     0.911 \u00b1 0.001    |     0.793 \u00b1 0.014    |     0.920 \u00b1 0.005    |\n|     __ST-MEM (Ours)__      |     __0.929 \u00b1 0.001__    |     __0.895 \u00b1 0.008__    |     __0.966 \u00b1 0.004__    |\n\n\u3164\n\n__Change__: We added new section as Appendix F.\n\n\u3164\n\n\u3164\n\n\n### __[Use of word \u201cflattening\u201d in patchfying explanation]__\n\n__Reply__: We are sorry for confusing the audience by misusing the word \u201cflattening.\u201d In spatio-temporal patchifying, in contrast to the temporal patchifying scenario, there is no flatten operation as it is already flattened. We deleted the word \u201cflatten\u201d.\n \n__Change__: Revised the sentence.\n\n\u201cThe patches undergo flattening and linear projection to form patch embeddings of dimension D.\u201d\n\n-> \n\n\u201cThe patches undergo linear projection to form patch embeddings of dimension D.\u201d"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5394/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700307513090,
                "cdate": 1700307513090,
                "tmdate": 1700464052684,
                "mdate": 1700464052684,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YpR3TXxdTM",
                "forum": "WcOohbsF4H",
                "replyto": "fz0wjgCtQN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5394/Reviewer_pLfJ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5394/Reviewer_pLfJ"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks to these authors for the additional clarification and results."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5394/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700488453025,
                "cdate": 1700488453025,
                "tmdate": 1700488453025,
                "mdate": 1700488453025,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]