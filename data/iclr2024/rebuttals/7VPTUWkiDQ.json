[
    {
        "title": "Provable Compositional Generalization for Object-Centric Learning"
    },
    {
        "review": {
            "id": "jbfwEpmJNf",
            "forum": "7VPTUWkiDQ",
            "replyto": "7VPTUWkiDQ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8400/Reviewer_JA2G"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8400/Reviewer_JA2G"
            ],
            "content": {
                "summary": {
                    "value": "The authors theoretically and empirically show that compositional generalization can be achieved through:\n1. Structural constraints on the decoder (each data dimension is rendered as the sum of functions operating on slots separately), which ensures that the decoder compositionally generalizes.\n2. An encoder-decoder consistency loss (reconstruction loss for the representations) on slot-shuffled representations from the encoder output, which encourages the encoder to compositionally generalize with the additive decoder.\n\nThe paper provides a joint encoder-decoder framework for compositional generalization for autoencoders, where previous work has mostly focused on specific aspects of the setting."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is very well-written.\n- The theory is sound and significant for the community.\n- The joint encoder-decoder framework for compositional generalization in autoencoders is quite elegant.\n- The limitations of the framework and the additivity constraint on the decoder are adequately stated."
                },
                "weaknesses": {
                    "value": "Although they support the theory, the experiments are quite limited. For instance, these are all with only two slots with 16 dimensions each. See the questions section for additional information that would be interesting to see from experimentation."
                },
                "questions": {
                    "value": "- How does the effect of the consistency loss scale with the number of slots?\n- What is the impact of how slot-supported the training data is? i.e. in Figure 2 (1), what is the impact of the width of the blue band on empirical effectivity?\n- How does the method hold up on non-synthetic data, especially if you slightly relax some constraints? For instance, what if you have expressive slot-wise decoding, but allow for a low-expressivity non-linear combination at the end for rendering?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8400/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698612735636,
            "cdate": 1698612735636,
            "tmdate": 1699637046243,
            "mdate": 1699637046243,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MOMNSCACQg",
                "forum": "7VPTUWkiDQ",
                "replyto": "jbfwEpmJNf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8400/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8400/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nWe thank you for your positive review and your valuable feedback. We were delighted to see that you found our theory \u201csound and significant\u201d, that you found our proposed framework \u201celegant\u201d, and that you found our manuscript to be \u201cvery well written\u201d. \n\nWe address your comments below.\n\n___\n**Comment:** \u201dHow does the effect of the consistency loss scale with the number of slots?\u201d\n\n**Response**:\nThank you for asking this interesting question! In App. C.3, we now include an experiment that ablates the impact of the number of slots on the consistency loss. As the number of slots increases from 2 to 3 and 4, optimization of the consistency loss becomes more challenging, and its value grows. This is not unexpected as the number of possible latent slot combinations grows combinatorially with the number of slots, making sampling the space more challenging. Furthermore, as the consistency loss increases, we see worse performance on OOD metrics, as our theory suggests. We now include a discussion of potential solutions for scaling this loss to more complex settings in App. B.5.\n\n___\n**Comment:** \u201cWhat is the impact of how slot-supported the training data is? What is the impact of the width of the blue band on empirical effectivity?\"\n\n**Response**:\nThank you for raising this interesting point! We address this question by examining two questions empirically:\n\n1. What is the effect of the width of the diagonal band in latent space, i.e., the effect of the training data's size (and diversity)?\n2. What happens if slot-supportedness is not fulfilled?\n\nWe address the first point in App. C.1 and show that a model trained with the consistency loss yields high OOD performance across different widths. On the other hand, a model trained without consistency loss requires a much wider band to reach the same OOD performance.\n\nWe address the second point in App. C.2 by creating a dataset in which there is a gap in the latent space such that it is no longer a slot-supported subset. In this case, we see that OOD reconstruction increases sharply in the region around this gap. \n\n___\n**Comment:** \u201dHow does the method hold up on non-synthetic data?\u201d\n\n**Response**:\nWe agree with the reviewer that understanding our results on non-synthetic data is important; however, this is challenging for two main reasons. Firstly, for real-world data, one does not generally have access to the ground-truth latents making our evaluation schemes inapplicable. Secondly, even if access to ground-truth latent information is available, our experiments require being able to sample latents densely from a slot-supported subset. Specifically, our experiments rely on sampling from a diagonal strip in the latent space with a small width. If such a region were sub-sampled from an existing dataset, this would leave a tiny number of data points that are insufficient to train a model. To this end, our experiments require access to a dataset's ground-truth renderer so latents can be sampled densely. This is not available in most cases, however. We now discuss this in a paragraph in App. B.6.\n\n___\n**Comment:** \u201cWhat if you \u2026 allow for a low-expressivity non-linear combination at the end for rendering?\u201d\n\n**Response**:\nRegarding a \u201clow-expressivity non-linear combination at the end for rendering\u201d, we note that the softmax in the alpha-masking of Slot Attention in our experiments in Sec. 6.2 can be understood as just this. For these experiments, the model optimizes the consistency loss and includes a deterministic encoder, thus matching all theoretical assumptions except for _additivity_. In these cases, we found that the nonlinear combination leads to a steep increase in the isolated decoder OOD reconstruction error (See Fig. 5, left). Developing theory to allow for such nonlinear combinations is an important direction for modeling real-world data. We view our work as a crucial initial step in this direction."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8400/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700572939534,
                "cdate": 1700572939534,
                "tmdate": 1700572939534,
                "mdate": 1700572939534,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ntFIcPpOyn",
                "forum": "7VPTUWkiDQ",
                "replyto": "MOMNSCACQg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8400/Reviewer_JA2G"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8400/Reviewer_JA2G"
                ],
                "content": {
                    "title": {
                        "value": "Keeping my score"
                    },
                    "comment": {
                        "value": "Thank you for your response! I appreciate the additions to the appendix, and they resolve my questions. I think this is a theoretically important paper, even though it is limited by its currently demonstrated applicability. I am going to keep my score."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8400/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700585636459,
                "cdate": 1700585636459,
                "tmdate": 1700585636459,
                "mdate": 1700585636459,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ClvWuLVjqS",
            "forum": "7VPTUWkiDQ",
            "replyto": "7VPTUWkiDQ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8400/Reviewer_wPGp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8400/Reviewer_wPGp"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents conditions where compositional generalization is theoretically guaranteed for object-centric learning. \n\nSpecifically, they first extend the identifiability theory of object-centric representations to handle partial joint distribution supports, with an additional assumption/constraint on the decoder to be compositional. This ensures that slots are identifiable in the training distribution. They then ensure the generalizability of decoders (which, e.g., generate images given slot representations) with another assumption/constraint as the decoder being additive. The theoretical analysis is similar to those proving the compositional generalizability of any additive inference models.\n\nThe novel step is to enforce the compositional generalizability of encoders by learning with the synthesized data in new compositions of latent slots/symbols given the generalizable decoder. So, in order to learn an encoder that can generalize to unseen combinations of objects, they first build a dataset with new compositions of latent symbols/slots by permutating learned latent symbols/slots in the training distribution. They then generate the fake images using the \"supposedly generalizable\" decoders on new combinations. The encoder is trained to learn the inverse mapping of the decoder. This process is formulated as a compositional consistency regularization loss in practice.\n\nThe experimental results are aligned with the theories in a simple two-object synthetic image environment."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper discusses an important problem: learning compositionally generalizable object-centric representations. The paper is well-written and easy to read. The connections with related works are also interesting and inspiring. \n\nThe reviewer especially appreciates the theoretical guarantees and analysis. Even though the assumptions are strong on both the functions to be approximated as well as the parameterization of learned functions, they are still aligned with the image object-centric representation learning setting, and the methods can be relaxed and realized using modern object discovery methods such as slot attentions. \n\nThe proposed regularization loss to enforce the compositional generalizability of encoders is interesting and seems easy to use. \n\nThe ablation study on the additive decoder (softmax v.s. sigmoid in slot attentions) is interesting and inspiring."
                },
                "weaknesses": {
                    "value": "It would be great if the assumptions could be relaxed, e.g., to handle occluded objects or to handle general latent variable learning domains other than the image objects. \n\nThe \"contemporary\" work [1] discussed most parts of this paper except for the generalizable encoder. \n\nThe experimental environment is simple with two-object synthetic images. It would be more convincing to see results on multi-object real images. \n\n[1] S \u0301 ebastien Lachapelle, Divyat Mahajan, Ioannis Mitliagkas, and Simon Lacoste-Julien. Additive decoders for latent variables identification and cartesian-product extrapolation. arXiv preprint arXiv:2307.02598, 2023."
                },
                "questions": {
                    "value": "Are there results in more complex environments? \n\nCan the theories be generalized to more general settings with weaker assumptions?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8400/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698634403846,
            "cdate": 1698634403846,
            "tmdate": 1699637046123,
            "mdate": 1699637046123,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "P3UdnSpJNv",
                "forum": "7VPTUWkiDQ",
                "replyto": "ClvWuLVjqS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8400/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8400/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer, \n\nWe thank you for your positive review and your valuable feedback. We are happy to hear that you \u201cappreciated\u201d our theoretical analysis, that you found our work \u201cwell-written\u201d and \u201ceasy to read\u201d, and that you found multiple aspects of our work \u201cinteresting and inspiring\u201d. \n\nWe address your comments below:\n\n___\n**Comment:** \u201dIt would be great if the assumptions could be relaxed.\u201d\n\n**Response**:\nWe agree with the reviewer that relaxing our theoretical assumptions, namely _additivity_ and _compositionality_, is essential for modeling realistic data to allow for more complex interactions between slots. We aimed to highlight this in our discussion paragraph, \u201cExtensions of Theory\u201d.  While interactions between slots cannot be arbitrary, it is likely that further degrees of interaction may be allowed beyond additive interactions. We view this as an important direction for future work and believe that the current work constitutes a crucial step towards a more general result.\n\n___\n**Comment:** \"Are there results in more complex environments?\"\n\n**Response**:\nUnderstanding our theoretical results for more complex data is indeed important for better understanding its applicability. This is challenging for real-world datasets, however, as one does not generally have access to the ground-truth latents making our evaluation schemes inapplicable. Moreover, using more complex synthetic datasets typically used in object-centric learning is also not straightforward for our experiments due to the need to sample latents densely from a slot-supported subset. Specifically, our experiments rely on sampling from a diagonal strip in the latent space with a small width. If such a region were sub-sampled from an existing dataset, this would leave only a tiny number of data points that are insufficient to train a model. To this end, our experiments rely on access to the ground-truth renderer for a dataset such that latents can be sampled densely; however, this is not available in most cases. We now discuss this point in a paragraph in App. B.6."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8400/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700571268579,
                "cdate": 1700571268579,
                "tmdate": 1700571268579,
                "mdate": 1700571268579,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0e5VGdOhmn",
                "forum": "7VPTUWkiDQ",
                "replyto": "P3UdnSpJNv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8400/Reviewer_wPGp"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8400/Reviewer_wPGp"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the authors' reply and their honesty. I will then keep my rating as 8: accept, good paper."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8400/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700624285307,
                "cdate": 1700624285307,
                "tmdate": 1700624285307,
                "mdate": 1700624285307,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Cqyjwk0Hak",
            "forum": "7VPTUWkiDQ",
            "replyto": "7VPTUWkiDQ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8400/Reviewer_KGuC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8400/Reviewer_KGuC"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses the problem of compositional generalization in object-centric autoencoders.\nThe authors formalize this as requiring the model to identify the ground-truth object latents not just on the training distribution, but also on out-of-distribution combinations.\nThey make two key assumptions to achieve this: (1) The generative process satisfies compositionality, meaning each pixel depends on one object, and irreducibility, preventing objects from being decomposed.\n(2) The decoder is additive, decoding each object slot independently.\nUnder these assumptions, the authors prove autoencoders can identify objects in-distribution by minimizing reconstruction error.\nThe additive decoder then guarantees generalization out-of-distribution.\nHowever, the encoder may still fail to generalize.\nTo address this, the authors propose compositional consistency regularization.\nThis trains the encoder to invert the decoder on recombined object slots, enabling the full autoencoder to generalize.\nBy combining in-distribution identifiability and compositional consistency regularization, the authors prove autoencoders satisfying their assumptions will generalize compositionally.\nThrough synthetic experiments, they provide empirical evidence supporting their theoretical results.\nIn particular, they demonstrate the importance of additivity and compositional consistency for generalization."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper made contributions for \n- Formalizing compositional generalization as an identifiability problem\n- Theoretical guarantees for in-distribution identifiability\n- Showing an additive decoder enables out-of-distribution generalization\n- Introducing compositional consistency regularization\n- Providing overall theoretical guarantees for compositional generalization\n\nThe work makes theoretical progress on understanding compositional generalization in object-centric representation learning."
                },
                "weaknesses": {
                    "value": "- The assumptions of compositionality and irreducibility are quite restrictive. Most real-world datasets likely violate these. \n- The additive decoder limits modeling of complex object interactions and relations.\n- The consistency regularization implementation requires sampling implausible object combinations. More principled schemes could improve results in complex environments.\n- Experiments only validate the theory on simple synthetic datasets. Testing on more diverse and realistic data would better demonstrate applicability, though the evaluation would also be more challenging.\n- The proposed methods, especially when ensuring encoder-decoder consistency and handling latent slots, might pose scalability issues for very large datasets or more complex models. A discussion on the scalability, computational costs, and potential solutions would make the paper more robust."
                },
                "questions": {
                    "value": "Please see above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8400/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698730754058,
            "cdate": 1698730754058,
            "tmdate": 1699637046010,
            "mdate": 1699637046010,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "N0ABeERt0T",
                "forum": "7VPTUWkiDQ",
                "replyto": "Cqyjwk0Hak",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8400/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8400/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer, \n\nWe thank you for your review and your valuable feedback. We are happy that you found our work makes \u201ctheoretical progress on understanding compositional generalization in object-centric representation learning\u201c.\n\nWe address your comments below:\n\n**Comment:** \u201cCompositionality and irreducibility are quite restrictive.\u201d\n\n**Response**:\n\nRegarding compositionality, we agree with the reviewer about the restrictiveness of this assumption. Compositional decoders are special cases of additive decoders (see App. A.7) and thus share the same limitations: They cannot perfectly model objects with complex interactions such as occlusion or reflection. Irreducibility, on the other hand, roughly states that parts of the same object share information. We argue that this assumption is a more fundamental property of objects and will thus be valid more generally for multi-object scenes.\n\n**Comment:** \u201cAdditive decoder limits modeling of complex object interactions and relations.\u201d\n\n**Response**:\n\nAs noted in our \u201cExtensions of Theory\u201d paragraph in the Discussion section, we agree with the reviewer that additivity is indeed insufficient for modeling more complex object interactions. We believe, however, that this assumption can be relaxed to allow for more complex interactions and view this as an important direction for future work.\n\n**Comment:** \u201dConsistency regularization requires sampling implausible object combinations. More principled schemes could improve results.\u201d\n\n**Response**:\n\nAs noted in our \u201cExtensions of Experiments\u201d paragraph in the Discussion section, we agree regarding the limitations of our consistency loss implementation and approaches for improving it. One such approach could be to learn a prior over latent slots and sample slot combinations more rigorously according to their likelihood under the prior. This could avoid sampling implausible combinations; however, such a scheme is challenging as it relies on the likelihood of being valid for OOD combinations of slots. Another possibility would be to include heuristics to directly filter combinations based on prior knowledge of the data-generation process, e.g., to filter objects with similar coordinates that would intersect. We believe that further explorations in such directions are a promising and important direction for future work to make this method practical for more complex datasets. We now include this discussion in App. B.5.\n\n**Comment:** \u201cExperiments only validate the theory on simple synthetic datasets.\u201d\n\n**Response**:\n\nWe agree with the reviewer that understanding our theoretical results on more diverse and real-world data is important for better understanding its applicability. This is indeed challenging for real-world datasets, however, as one does not generally have access to the ground-truth latents making our evaluation schemes inapplicable. Moreover, using the synthetic datasets typically used in object-centric learning is also not straightforward for our experiments due to the need to sample latents densely from a slot-supported subset. Specifically, our experiments rely on sampling from a diagonal strip in the latent space with a small width. If such a region were sub-sampled from an existing dataset, this would leave only a tiny number of data points that are insufficient to train a model. To this end, our experiments rely on access to the ground-truth renderer for a dataset such that latents can be sampled densely; however, this is not available in most cases. We now discuss this paragraph in App. B.6.\n\n**Comment:** \u201cThe proposed methods might pose scalability issues for very large datasets or more complex models.\u201d\n\n**Response**:\n\nThank you for mentioning this. Methods based on latent slots have in fact been shown to scale to more complex settings (e.g., [1, 2]); however, we agree regarding the scalability of the consistency loss, which we aimed to highlight in our \u201climitations of experiments\u201d paragraph. We have included a figure in App. C.3 highlighting the challenges in scaling this loss as the number of objects increases. Regarding computational costs, the loss requires additional passes through the encoder and decoder as well as computation of the encoder\u2019s gradients wrt. the loss. We found this to increase training time by a maximum of 28% across runs. We have incorporated a discussion of this point in App. B.5.\n\nWe hope these clarifications and revisions are sufficient for the Reviewer to confidently increase their score. Furthermore, we noticed the Reviewer left a score of \u201c2\u201d regarding the soundness of our manuscript. We found this noteworthy as we are not aware of any inaccuracies in our theoretical or empirical contribution. Thus, if the soundness score was the result of one of the points raised by the reviewer above, we hope our comments were sufficient to resolve the reviewer's doubts.\n\n[1] https://arxiv.org/abs/2206.07764\n\n[2] https://arxiv.org/abs/2205.14065"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8400/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700517359634,
                "cdate": 1700517359634,
                "tmdate": 1700517359634,
                "mdate": 1700517359634,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]