[
    {
        "title": "Learning to design protein-protein interactions with enhanced generalization"
    },
    {
        "review": {
            "id": "bfXV4RNeg5",
            "forum": "xcMmebCT7s",
            "replyto": "xcMmebCT7s",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8349/Reviewer_Sjjh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8349/Reviewer_Sjjh"
            ],
            "content": {
                "summary": {
                    "value": "This work focuses on predicting binding affinity changes of protein complexes upon mutations, namely, it intends to solve $\\Delta\\Delta G$ prediction, which is critical in protein binder design. It has three major contributions: (1) They exhaustively mine PDB to build a large-scale non-redundant PPI dataset. (2) A novel transfer learning algorithm is introduced to bridge the conventional masked residue modeling and $\\Delta\\Delta G$ prediction. (3) A new state-of-the-art performance has been achieved at the standard Skempi2 dataset with a more reasonable data-splitting strategy. Overall speaking, I would recommend an acceptance to the ICLR committee but expect the author to elucidate more clearly about the new splitting mechanism."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "(1) The paper built the largest and non-redundant dataset named PPIRef for representation learning of PPI. \n\n(2) The study proposes a reasonable mechanism to transfer a masked language modeling (MLM)-pretrained PPI model to predict mutation effects. This abandons the traditional bidirectional forward scheme to enforce the antisymmetry. \n\n(3) The author points out the flaws of previous methods' data splitting strategies and formulated a new one, which should be a good contribution to the machine learning community (but there are also some parts in the new splitting strategy that puzzle me, see questions).\n\n(4) PPIFormer exhibits great potential in distinguishing the binding affinity change after mutations than existing algorithms such as RDE-Net and MSA-Transformer."
                },
                "weaknesses": {
                    "value": "(1) My major concern is that neither the code nor the data is publicly available. Are authors willing to release them? If possible, I would recommend authors upload the necessary part of the method to an anonymous GitHub (https://anonymous.4open.science/) during the review phase.\n\n(2) I value this study's effort in formulating a more comprehensive evaluation paradigm for mutation effect prediction, particularly in dataset splitting. However, the new splitting strategy is somehow unclear. For instance, the test set has only 5 samples, which are too small. And 3 cross-validation does not align with 5 test folds. \n\n(3) In the task of retrieving 5 human antibody mutations effect against SARS-CoV-2, the performance of PPIFormer is not good enough, it only outperforms RDE-Net in 3 of 5 samples and is worse in P@5% and P@10% than RDE-Net."
                },
                "questions": {
                    "value": "(1) I am a little confused about the evaluation of test folds. As mentioned in Appendix B.2, the author splits the dataset into 3 cross-validation folds based on the \"hold-out-proteins feature\" and then sets aside 5 random outlier PPIs to form 5 distinct test folds. Firstly, what is the \"hold-out-proteins feature\"? Please explain that term. Secondly, why are there 3 cross-validation folds but 5 test folds? Commonly, $k$ cross-validation would result in $k$ training sets as well as $k$ validation sets, and usually do not have a so-called test fold. In my understanding, these 5 extra outliers are excluded from both the training and validation sets and are used to evaluate models alone. So here comes the question: how does the author compute the $\\Delta\\Delta G$ for these 5 outliers? Notably, 3 cross-validation will lead to 3 sets of models that achieve the lowest losses in 3 different validation sets. Does the author just take an average of these 3 models' output to obtain the binding affinity change? If not, please specify the computational process. \n\nBesides, how does the author split the Skempi2 by 3 cross-validation? I want to know more details. Also, why do these 5 outlier PPIs are selected randomly? I am afraid that a test set of merely 5 samples is so small. Is there any possibility to increase the test size?    \n\n(2) I understand that the splitting strategy of RDE-Net introduces data leakage. However, its 3 cross-validation is implemented without any technical mistakes. Therefore, can the author please just examine PPIFormer in the same splitting way as RDE-PPI and report the performance to help me better understand the superiority of PPIFormer over RDE-PPI?\n\nBesides, can you report the performance of PPIFormer in the same way as RDE-Net? Namely, the Spearman and Pearson of PPIformer and different baselines in single-mutation and multiple-mutation cases. I hope to see that PPIFormer remains excellent in the multiple-mutation circumstance, which is more challenging and more likely to result in successful protein design. \n\n\n(3) In the ablation study, the author claims the benefit of 80% 10% 10% masking proposed by BERT. However, I remember that BERT masked 15% of input tokens and tried to recover them. What does 80%, 10%, 10% mean? \n\nWhat's more, in Figure (4), what is the difference between a3 and PPIFormer? It seems a3 is better than PPIFormer, but it is said PPIFormer is the best model. Please specify the difference between the upper and bottom subfigures. \n\n(4) During the phase of mutant effect prediction, the author adopts a simple summation of all log odds ratios. In other words, each substitution of residue is considered independently. I suppose it may be a better solution to calculate the joint probability as $\\log p (\\hat{M} = M | \\mathbf{c}_{\\backslash M})$. Does the author agree with my point?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8349/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8349/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8349/Reviewer_Sjjh"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8349/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697618682224,
            "cdate": 1697618682224,
            "tmdate": 1700708168991,
            "mdate": 1700708168991,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "V3fM90kv9W",
                "forum": "xcMmebCT7s",
                "replyto": "bfXV4RNeg5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8349/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8349/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors (Part 1)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the detailed analysis of our work and for providing us with highly valuable feedback.\n\n**Weaknesses**\n> (1) My major concern is that neither the code nor the data is publicly available. Are authors willing to release them? If possible, I would recommend authors upload the necessary part of the method to an anonymous GitHub (https://anonymous.4open.science/) during the review phase.\n\nThank you for raising this point. We definitely plan to release all the code, trained models and data once they are  finalized and incorporate all comments / input from the review process. \n\n> (2) I value this study's effort in formulating a more comprehensive evaluation paradigm for mutation effect prediction, particularly in dataset splitting. However, the new splitting strategy is somehow unclear. For instance, the test set has only 5 samples, which are too small. And 3 cross-validation does not align with 5 test folds.\n\nWe apologize for the confusion. Please see our response to question 1 for detailed clarification. The 5 test samples from SKEMPI v2.0 are difficult to expand due to the high redundancy of the dataset, and these samples are independent from the 3-fold cross-validation. We firstly set aside these 5 representative and independent PPIs for testing, and then split the remaining data into 3 folds.\n\n> (3) In the task of retrieving 5 human antibody mutations effect against SARS-CoV-2, the performance of PPIFormer is not good enough, it only outperforms RDE-Net in 3 of 5 samples and is worse in P@5% and P@10% than RDE-Net.\n\nPlease note that while the SARS-CoV-2 benchmark proposed by [4] and [5] is an invaluable contribution to the field, one needs to be a bit careful making strong conclusions based on comparison of exact values on the benchmark. In this benchmark, only 5 of 494 mutations are annotated as favorable, while the effects of the other 489 are unknown. For example, according to the benchmark, RDE-Net retrieves the LH104F mutation with lower rank (the predicted rank is 5.47, which is better than the 10.93 predicted by PPIformer). However, we don\u2019t know whether or not the hits predicted with better ranks by PPIformer are actually incorrect. Those mutations could also be favorable. The same holds true the other way around for high scoring mutations of RDE-Net. We will make a note about overinterpreting these results (both directions, in favour or against PPIFormer) in the paper. \n\nAdditionally, there is a chance that the performance of RDE-Net, as well as DDGPred, on this benchmark may be slightly overoptimistic. The pool of the experimentally-validated mutations, including the 5 benchmarked ones, was preselected according to DDGPred predictions, and RDE-Net was trained in a similar way as DDGPred (i.e. on a PDB-disjoint split of SKEMPI v2.0). This means that the performance of the methods may be overoptimistic due to the potential circular data leakage. In other words, the methods are tested on the data, that were preselected by the same or a similar method.\n\n**Questions**\n\n> (1) I am a little confused about the evaluation of test folds. As mentioned in Appendix B.2, the author splits the dataset into 3 cross-validation folds based on the \"hold-out-proteins feature\" and then sets aside 5 random outlier PPIs to form 5 distinct test folds. Firstly, what is the \"hold-out-proteins feature\"? Please explain that term. Secondly, why are there 3 cross-validation folds but 5 test folds? Commonly,  cross-validation would result in  training sets as well as  validation sets, and usually do not have a so-called test fold. In my understanding, these 5 extra outliers are excluded from both the training and validation sets and are used to evaluate models alone. So here comes the question: how does the author compute the  for these 5 outliers? Notably, 3 cross-validation will lead to 3 sets of models that achieve the lowest losses in 3 different validation sets. Does the author just take an average of these 3 models' output to obtain the binding affinity change? If not, please specify the computational process\n\nWe appreciate the detailed analysis of our data preparation and apologize for the confusion. We have now significantly expanded Appendix B.2 \u201cTest Datasets\u201d in the updated paper to address all the raised questions. The intuition of the reviewer about the parts that were unclear is correct, and we briefly answer the questions below.\n\nThe \u201cHold out proteins\u201d is [the column in the SKEMPI v2.0 dataset](https://life.bsc.es/pid/skempi2/database/browse), which specifies similar PPIs. We obtain our three folds by splitting the dataset by the values from this column. This ensures the PPIs are not leaked across folds. After 3-fold cross-validation, we, indeed, average three models for test predictions."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8349/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700579042352,
                "cdate": 1700579042352,
                "tmdate": 1700579042352,
                "mdate": 1700579042352,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "aQeUunUheH",
            "forum": "xcMmebCT7s",
            "replyto": "xcMmebCT7s",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8349/Reviewer_Kuay"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8349/Reviewer_Kuay"
            ],
            "content": {
                "summary": {
                    "value": "The manuscript presents a novel data splitting technique aimed at mitigating data leakage and generating a fresh dataset. Additionally, it introduces a new loss function for the equiformer, enhancing its ability to effectively undergo self-supervised training."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper is easy to read.\n\n2. The authors present a novel splitting method to prevent data leakage in the PPI dataset.\n\n3. They propose an innovative training scheme for EquiFormer, enabling self-supervised training.\n\n4. Additionally, the paper introduces a new feature generation technique to capture more information both within and outside the residue itself.\n\n5. Comprehensive experiments are conducted to evaluate the proposed method and the presented dataset."
                },
                "weaknesses": {
                    "value": "When considering the data, it's important to note that the DIPS dataset may not have broad applicability for Protein-Protein Interaction (PPI) tasks. This is because PPI tasks involve not only binding, as observed in DIPS, but also encompass other aspects such as reaction, Ptmod, and activation labels, as described in reference [1].\n\n[1] Learning Unknown from Correlations: Graph Neural Network for Inter-novel-protein Interaction Prediction"
                },
                "questions": {
                    "value": "1. In the optimization of a human antibody against SARS-CoV-2 and engineering staphylokinase for enhanced thrombolytic activity, how were the mutation pools obtained?\n\n2. Can you explain the process used to identify the five PPI outliers mentioned in Datasets?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8349/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698604860413,
            "cdate": 1698604860413,
            "tmdate": 1699637038511,
            "mdate": 1699637038511,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YwRPlrfaVE",
                "forum": "xcMmebCT7s",
                "replyto": "aQeUunUheH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8349/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8349/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer\u2019s valuable feedback and address the comments below.\n\n**Weaknesses**\n\n> When considering the data, it's important to note that the DIPS dataset may not have broad applicability for Protein-Protein Interaction (PPI) tasks. This is because PPI tasks involve not only binding, as observed in DIPS, but also encompass other aspects such as reaction, Ptmod, and activation labels, as described in reference [1].\n[1] Learning Unknown from Correlations: Graph Neural Network for Inter-novel-protein Interaction Prediction\n\nWe appreciate this important comment and agree that DIPS (as well as Protein Data Bank in general) does not extend beyond protein binding. Please, however, note that the focus of our paper is on designing protein-protein interactions for higher binding energy, and we do not study other, indirect ways of cooperation and mutual regulation between proteins. In this setup, the DIPS dataset (as well as our improved PPIRef) provides an important resource for self-supervised pre-training. Nevertheless, we believe that the reviewer\u2019s comment is very stimulating for potential future work. Extending PPIformer to also learn from PPI networks, where nodes are proteins and edges are interaction types, may lead to improved performance, inspired by [1, 2]. We will cite and discuss the suggested reference.\n\n**Questions**\n\n> 1. In the optimization of a human antibody against SARS-CoV-2 and engineering staphylokinase for enhanced thrombolytic activity, how were the mutation pools obtained?\n\nFor the SARS-CoV-2 test set, the authors of [3] selected a pool of all 494 possible single-point mutations on the heavy chain CDR region of the antibody. Out of these, five mutations were labeled as positive based on wet-lab experiments (please see [3] for the details on experimental setup). We obtained all the data from the official [RDE-PPI repository](https://github.com/luost26/RDE-PPI/tree/main).\n\nFor the staphylokinase test set, we used the results of [4]. The authors of [4] measured the effects of mutations of staphylokinase on its thrombolytic activity. 80 of these annotated mutations are located at its interface with microplasmin, where 28 mutations reportedly increased the protein's thrombolytic activity, while the remaining 52 decreased it. We use these mutations as an another independent test set. Please see Appendix B.2 \"Test datasets\" in the updated paper for more details.\n\n> 2. Can you explain the process used to identify the five PPI outliers mentioned in Datasets?\n\nWe select PPI outliers based on their similarity as defined by the authors of the SKEMPI v2.0 dataset [5]. Specifically, PPIs are considered similar if they share an interacting partner or a homologous binding site. Then, the outlier PPIs are defined as PPIs that do not have other similar PPIs. These outliers are depicted in Figure 2 of the original SKEMPI v2.0 publication [5] as connected components of two nodes (proteins), along with several other connected components mentioned in footnote 2 (on page 19) of our updated manuscript. \n\nWe identified five outlier PPIs by manually analyzing these examples from the figure, aiming to select those with both positive and negative ddG annotations. We succeded at selecting the five outliers only after examining the vast majority of candidates, which highlights the difficulty of choosing a reasonable test set from highly biased SKEMPI v2.0. Lastly, we confirmed that the selected PPIs do not have structural homologs among the other (training) PPIs by calculating interface similarities with iAlign. For more details, please see Appendix B.2 \"Test datasets\" in the updated paper.\n\n**References**\n\n[2] Gao, Ziqi, et al. \"Hierarchical graph learning for protein\u2013protein interaction.\" Nature Communications 14.1 (2023): 1093.\n\n[3] Shan, Sisi, et al. \"Deep learning guided optimization of human antibody against SARS-CoV-2 variants with broad neutralization.\" Proceedings of the National Academy of Sciences 119.11 (2022): e2122954119.\n\n[4] Laroche, Yves, et al. \"Recombinant staphylokinase variants with reduced antigenicity due to elimination of B-lymphocyte epitopes.\" Blood, The Journal of the American Society of Hematology 96.4 (2000): 1425-1432.\n\n[5] Jankauskait\u0117, Justina, et al. \"SKEMPI 2.0: an updated benchmark of changes in protein\u2013protein binding energy, kinetics and thermodynamics upon mutation.\" Bioinformatics 35.3 (2019): 462-469."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8349/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700581174246,
                "cdate": 1700581174246,
                "tmdate": 1700581174246,
                "mdate": 1700581174246,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "TA5ZNMbgu3",
            "forum": "xcMmebCT7s",
            "replyto": "xcMmebCT7s",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8349/Reviewer_brhp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8349/Reviewer_brhp"
            ],
            "content": {
                "summary": {
                    "value": "They first build an algorithm to approximate similarity between ppi interfaces and use it to assess the redundancy in existing datasets, like DIPS. Then they curate the available pdbs in protein data bank to create their dataset PPIREF, which reduces data leakage in train/test splits. The model architecture is comprised of Equiformer and it is first trained to predict masked residues with a regularised cross-entropy loss and then finetuned to predict the effects of mutations on binding affinity, using a thermodynamic-inspired loss."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper is well-written and organized in a logical manner. It is easy to follow and the visualizations are informative.\n- The authors put effort on choosing their metrics/loss functions/splits. Especially for the latter, they developed an algorithm to detect dataset redundancy and reduce data leakage in their splits. Overall, their design choices are well addressed. \n- The model shows good performance on the benchmarks. it is nicely compared to different state of the art methods (both force field and ml methods) and using many metrics."
                },
                "weaknesses": {
                    "value": "- IDIST could significantly improve the computation time needed to assess dataset redundancy, which can make redundancy tests a part of every dataset curation. However, I believe that establishing IDIST as part of dataset curation, requires more validation than comparing it against iAlign and for 100 pdbs. You should compare with more methods (eg Tm-align and US align) and repeat it for more pdbs (especially because you define the threshold of IDIST from the iAligh comparison)\n- The novelty is a bit limited, especially in the model architecture.\n- Appendix Figure 3/B: You mistakenly have the same pdb code in both subfigures."
                },
                "questions": {
                    "value": "- I am worried that the F1 features introduce a data leakage and I would like to clarify it a bit:\nDauparas et al. describe utilizing distances between N, C\u03b1, C, O, and a virtual C\u03b2 placed based on the other backbone atoms, but their down-streaming task is predicting protein sequences in an autoregressive manner from the N to C terminus.\nIn your case, you mask a few amino acids, so with high probability neighbors of a masked residue will not be corrupted. \nSo I am worried that the F1 features can provide information regarding the \"available space\" in a certain position, biasing the model towards specific amino acids that fit well the available space. Is that a concern of yours?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8349/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8349/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8349/Reviewer_brhp"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8349/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698686250985,
            "cdate": 1698686250985,
            "tmdate": 1699637038384,
            "mdate": 1699637038384,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CTkZvtCKz5",
                "forum": "xcMmebCT7s",
                "replyto": "TA5ZNMbgu3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8349/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8349/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors (Part 1)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for a detailed analysis of our work, and the valuable feedback! Below we address their comments.\n\n**Weaknesses**\n\n>IDIST could significantly improve the computation time needed to assess dataset redundancy, which can make redundancy tests a part of every dataset curation. However, I believe that establishing IDIST as part of dataset curation, requires more validation than comparing it against iAlign and for 100 pdbs. You should compare with more methods (eg Tm-align and US align) and repeat it for more pdbs (especially because you define the threshold of IDIST from the iAligh comparison)\n\nWe appreciate the reviewer\u2019s idea to establish iDist as a standard tool for dataset curation. We have performed a preliminary experiment according to the reviewer\u2019s suggestion and demonstrate that iDist accurately approximates USalign as well (details below, and illustrated in the new supplementary **Figure 7** in the updated version of the manuscript). We plan to extend the benchmark to more than 100 PDB entries (2,7M PPI pairs) and potentially other methods for the camera-ready version of the paper. It was hard to do a large-scale analysis in the limited time of the rebuttal. Please note that we have not benchmarked iDist against TM-align, as suggested, because iAlign is an adaptation of TM-align to the domain of PPIs developed by the authors of TM-align (i.e. the group of Jeffrey Skolnick). Hence, we expect iAlign is better suited for PPIs than TM-align. \n\nIn detail, iDist achieves high precision (99%) and recall (97%) with respect to near-duplicate PPI structures detected using USalign. Notably, this is a similar level of performance we achieved when benchmarking our iDist against iAlign. However, the iAlign and USalign methods modify TM-align differently, and with different constants, which introduces a shift in the marginal distributions of their alignment scores. We found that the threshold of 0.7 we used for the iAlign score corresponds approximately to a threshold of 0.8 on the USalign score (the threshold of iDist does not need to be adjusted for accurate approximation; see Figure 7 in the supplementary material). Regarding the computational time, we find that iDist is roughly 100 times faster than USalign, confirming the need for iDist for large-scale PPI analysis.\n\n>The novelty is a bit limited, especially in the model architecture.\n\nIn our work, we have developed a new ddG predictor along with a reliable evaluation protocol. The novelty of our predictor (PPIformer) primarily lies in a newly developed data representation (coarse-grain representation based on virtual beta-carbons), training objectives (structural masked modeling for pre-training combined with log odds ratio for fine-tuning), and high-quality training data (PPIRef) prepared with our new method (iDist). To establish a new evaluation protocol, we have rethought the data splits and evaluation metrics that have been used for more than a decade (please see Section 2, Related Work for the references). Our evaluation scheme enables benchmarking ddG predictors in a way that goes beyond overfitting to near duplicate PPIs and is a step towards a new class of ddG predictors that will generalize to new unseen protein-protein interactions. We believe this work has the potential to significantly push forward the research community in this area.\n\n>Appendix Figure 3/B: You mistakenly have the same pdb code in both subfigures.\n\nPlease note that this is not a mistake. Both PPI interfaces (E-M and N-D) come from the same PDB entry with the code [2V6A](https://www.rcsb.org/3d-view/2V6A). The complex is a 16-mer composed of two unique proteins. It is important to analyze the composition of interfaces within a single complex because symmetric complexes introduce a lot of redundancy (see also the caption under Figure 1 in the updated paper, which has been rewritten to be clearer)."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8349/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700580924356,
                "cdate": 1700580924356,
                "tmdate": 1700580924356,
                "mdate": 1700580924356,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "jfNTtLMy5P",
            "forum": "xcMmebCT7s",
            "replyto": "xcMmebCT7s",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8349/Reviewer_ZbAC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8349/Reviewer_ZbAC"
            ],
            "content": {
                "summary": {
                    "value": "The authors construct PPIRef, the largest, non-redundant PPI dataset, using a proposed fast interface align method iDist for deduplication. The proposed SE(3)-equivariant model, PPIformer, based on Equiformer, is pretrained in a thermodynamics-motivated way on PPIRef and fine-tuned on SKEMPI. Experiments show that the pretrained PPIformer achieves new SOTA on non-leaking SKEMPI splits."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1. Novelty: A novel structural pretraining loss is proposed for mutation effect prediction.\n2. Performance: New SOTA on SpearmanR on SKEMPI with non-leaking (harder) splits. Notably, this method does not rely on pre-computed mutant structures.\n3. Clarity: The contributions are clearly stated and the paper is well-written.\n4. Effort: The amount of work in this paper is quite comprehensive."
                },
                "weaknesses": {
                    "value": "Please see questions."
                },
                "questions": {
                    "value": "1. Would be nice if you could also compare your methods with baselines on the normal PDB-disjoint split, as this is also useful in real world cases. If PPIformer also performs best, the results would be more consistent and persuasive.\n2. What is the logic behind your architecture choice? What is the size (#params) of your model?\n3. In table 6, we can observe a high SpearmanR but the lower performance on precision and recall. What's your comment on this?\n4. For real-world case studies, I suggest you try your model on deep mutational scanning (DMS) data, where the enrichment ratios of all single-point mutations are measured (though with higher noise). Ranking mutations on a single protein where only a few mutations have been experimentally measured is less convincing IMHO."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8349/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8349/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8349/Reviewer_ZbAC"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8349/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698818316326,
            "cdate": 1698818316326,
            "tmdate": 1699637038272,
            "mdate": 1699637038272,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lD09csdBLC",
                "forum": "xcMmebCT7s",
                "replyto": "jfNTtLMy5P",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8349/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8349/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors (Part 1)"
                    },
                    "comment": {
                        "value": "We greatly appreciate the valuable feedback provided by the reviewer. Below, we answer the reviewer's questions.\n\n**Questions**\n> 1. Would be nice if you could also compare your methods with baselines on the normal PDB-disjoint split, as this is also useful in real world cases. If PPIformer also performs best, the results would be more consistent and persuasive.\n\nWe appreciate the reviewer's comment, but we would like to again emphasize that the PDB-disjoint splitting of SKEMPI v2.0 does not reflect the desired generalization in real-world scenarios. For instance, the first two PDB interaction codes present in the dataset, [1CSE_E_I](https://life.bsc.es/pid/skempi2/database/browse/mutations?keywords=mutations.pdb+contains+%221CSE_E_I%22+or+mutations.protein_1+contains+%221CSE_E_I%22+or+mutations.protein_2+contains+%221CSE_E_I%22&protein_search=1CSE_E_I) and [1ACB_E_I](https://life.bsc.es/pid/skempi2/database/browse/mutations?keywords=mutations.pdb+contains+%221ACB_E_I%22+or+mutations.protein_1+contains+%221ACB_E_I%22+or+mutations.protein_2+contains+%221ACB_E_I%22&protein_search=1ACB_E_I), come from different PDB entries ([1CSE](https://www.rcsb.org/structure/1CSE) and [1ACB](https://www.rcsb.org/structure/1ACB)) but have nearly identical 3D structures and sequences. Additionally, they are both labeled with the same six mutations, with slightly different ddG values. Despite this, they are divided into separate folds in the PDB-disjoint split by [5], exemplifying the data leakage problem. In SKEMPI v2.0, there are three times more unique PDB codes than PPIs, leading to most test PPIs having a near-duplicate PPI in the training set. Additionally, every third test mutation is located on a PPI present in the training set (please see Appendix B.2 \"Test Datasets\" for details).\n\nFollowing the request of the reviewer, we have now re-trained our identical PPIformer architecture in the RDE-Net setup and examine its performance below. We would like to emphasize that for our method we use the same hyperparameters (e.g. architecture, loss and data representation) and do not tune the hyperparameters for these leaked splits. We only adapt the batch size from 32 to 8 (we also experimented with different batch sizes when training RDE-Net on our splits). Overall, PPIformer has competitive performance. More specifically, PPIformer performs reasonably on the overall evaluation (although it is not the best method, it often is the second best). In addition, PPIformer is the best method according to some of the metrics on the challenging set-up of multi-point mutations, which may better reflect its generalization capabilities. Please also see the [review by Sjjh](https://openreview.net/forum?id=xcMmebCT7s&noteId=bfXV4RNeg5) highlighting the importance of multi-point mutations and our corresponding response for some other details.\n\nOverall performance:\n|          |                | Per-Structure |           | Overall |           |        |        |        |\n|----------|----------------|---------|----------|---------|----------|--------|--------|--------|\n| **Category** | **Method**         | **Pearson** | **Spearman** | **Pearson** | **Spearman** | **RMSE**   | **MAE**    | **AUROC**  |\n| Sequence Based | ESM-1v        | 0.0073  | -0.0118  | 0.1921  | 0.1572   | 1.9609 | 1.3683 | 0.5414 |\n|              | PSSM           | 0.0826  | 0.0822   | 0.0159  | 0.0666   | 1.9978 | 1.3895 | 0.5260 |\n|              | MSA Transf.    | 0.1031  | 0.0868   | 0.1173  | 0.1313   | 1.9835 | 1.3816 | 0.5768 |\n|              | Tranception    | 0.1348  | 0.1236   | 0.1141  | 0.1402   | 2.0382 | 1.3883 | 0.5885 |\n| Energy Function | Rosetta       | 0.3284  | 0.2988   | 0.3113  | 0.3468   | 1.6173 | 1.1311 | 0.6562 |\n|                | FoldX         | 0.3789  | 0.3693   | 0.3120  | 0.4071   | 1.9080 | 1.3089 | 0.6582 |\n| Supervised   | DDGPred        | 0.3750  | 0.3407   | **0.6580** | 0.4687   | **1.4998** | **1.0821** | 0.6992 |\n|              | End-to-End     | 0.3873  | 0.3587   | 0.6373  | 0.4882   | 1.6198 | 1.1761 | 0.7172 |\n| Unsup./Semisup. | B-factor    | 0.2042  | 0.1686   | 0.2390  | 0.2625   | 2.0411 | 1.4402 | 0.6044 |\n|                | ESM-IF        | 0.2241  | 0.2019   | 0.3194  | 0.2806   | 1.8860 | 1.2857 | 0.5899 |\n|                | MIF-Dlogit    | 0.1585  | 0.1166   | 0.2918  | 0.2192   | 1.9092 | 1.3301 | 0.5749 |\n|                | MIF-Net.      | 0.3965  | 0.3509   | 0.6523  | 0.5134   | 1.5932 | 1.1469 | 0.7329 |\n| RDE-PPI      | RDE-Linear     | 0.2903  | 0.2632   | 0.4185  | 0.3514   | 1.7832 | 1.2159 | 0.6059 |\n|              | RDE-Net.       | **0.4448** | **0.4010** | 0.6447  | **0.5584** | $\\underline{1.5799}$ | $\\underline{1.1123}$ | **0.7454** |\n| Ours         | PPIformer      | $\\underline{0.4281}$ | $\\underline{0.3995}$ | $\\underline{0.6450}$ | $\\underline{0.5304}$ | 1.6420 | 1.1186 | $\\underline{0.7380}$ |"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8349/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700580565404,
                "cdate": 1700580565404,
                "tmdate": 1700580565404,
                "mdate": 1700580565404,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ixdv5QzX4N",
                "forum": "xcMmebCT7s",
                "replyto": "Fb29oQ96vI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8349/Reviewer_ZbAC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8349/Reviewer_ZbAC"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Authors by Reviewer ZbAC"
                    },
                    "comment": {
                        "value": "Thank you for your detailed and insightful responses, especially those for questions 1 and 4.\nAfter reading your rebuttal and other reviewer's opinions, I have decided to maintain my score of 8. Though many points raised by reviewer Sjjh and others are valid and important (I also strongly suggest you open-source the code), I believe that the novelty and effort in this paper makes it qualified for an ICLR publication."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8349/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700633867128,
                "cdate": 1700633867128,
                "tmdate": 1700633867128,
                "mdate": 1700633867128,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "0tshmegDww",
            "forum": "xcMmebCT7s",
            "replyto": "xcMmebCT7s",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8349/Reviewer_hYdu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8349/Reviewer_hYdu"
            ],
            "content": {
                "summary": {
                    "value": "This article established a machine learning model to predict protein-protein interactions. The authors constructed a three-dimensional protein-protein interaction database and pre-trained the model based on it. They then made predictions on two existing examples and compared the performance with other baseline methods, yielding better performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Protein-protein interaction is important for protein design and engineering. The authors established a new machine learning model to predict the $\\Delta\\Delta G$. The paper is well-organized and easy to follow."
                },
                "weaknesses": {
                    "value": "1. Evaluations on a broader range of datasets are preferred in terms of PPI and mutational effect predictions. Currently, all the test samples are selected from a larger benchmark dataset, making it skeptical that the results might be cherry-picked. \n2. Comparison of baseline methods is limited. At least some other deep learning methods should be included. For instance, for mutational effect prediction, the authors might refer to https://github.com/OATML-Markslab/ProteinGym.\n3. The prediction results are not reported with standard deviation, which makes it hard to tell whether the performance is statistically significant."
                },
                "questions": {
                    "value": "1. Would it be possible to construct the message passing between interfaces with GVP, another MPNN model that aggregates with protein scalar and vector features? \n2. Why use log odds ratio for predicting $\\Delta\\Delta G$, instead of training a regressor to directly predicting the $\\Delta\\Delta G$ values?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8349/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8349/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8349/Reviewer_hYdu"
                    ]
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8349/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698845603225,
            "cdate": 1698845603225,
            "tmdate": 1700637402527,
            "mdate": 1700637402527,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "iOhywStUZb",
                "forum": "xcMmebCT7s",
                "replyto": "0tshmegDww",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8349/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8349/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors (Part 1)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their constructive and valuable feedback on our work. Below, we address the reviewer\u2019s comments.\n\n**Weaknesses**\n\n> 1. Evaluations on a broader range of datasets are preferred in terms of PPI and mutational effect predictions. Currently, all the test samples are selected from a larger benchmark dataset, making it skeptical that the results might be cherry-picked. \n\nThank you for this important comment. Please note that in our work we use three independent test datasets (see Section 5.1 Datasets). First, we select 5 outlier (i.e. not having a training homologue) test PPIs from the SKEMPI v2.0 dataset. SKEMPI v2.0 encompasses the vast majority of published experimental ddG studies. This dataset, indeed, represents a selection from a larger benchmark dataset. We selected the test samples once to evaluate the generalization of our model before seeing the results. We did not overfit our method to the test set by exploring any other subsets. Please see Appendix B.2 \u201cTest Datasets\u201d, which now describes in detail the construction of the SKEMPI v2.0 test set.\n\nMoreover, we evaluate our method on two additional (and separate) datasets, which are not part of SKEMPI v2.0 and come from independent studies. The \u201cOptimization of a human antibody against SARS-CoV-2\u201d provides an independent evaluation on the benchmark proposed by [1] and [2], the studies proposing DDGPred and RDE-Network (ICLR 2023). Finally, to compare generalization of different methods even more robustly, we curated a novel independent test set for the problem of  \u201cEngineering staphylokinase for enhanced thrombolytic activity\u201d. This dataset was mined from [12].\n\nWe hope that our test setup involving three mutually independent test sets provides enough evidence that the results are not cherry-picked. Please also see our comment on attempts to obtain more test data in the answer to the [ZbAC reviewer\u2019s Question 4](https://openreview.net/forum?id=xcMmebCT7s&noteId=jfNTtLMy5P). Overall, it is challenging to find additional independent and high-quality test data.\n\n> 2. Comparison of baseline methods is limited. At least some other deep learning methods should be included. For instance, for mutational effect prediction, the authors might refer to https://github.com/OATML-Markslab/ProteinGym.\n\nThank you for your important comment. Please note that, while the number of evaluated baselines is not excessive, we have initially selected methods among the most representative methods in four available categories:\n1. Physics-based simulators. Flex ddG is the most performant and elaborate force-field-based protocol for binding ddG prediction.\n2. Evolutionary methods. MSA-Transformer is a well-established method that might benefit from using multiple sequence alignment (MSA) compared to other baselines (MSA is crucial, for example, for AlphaFold2).\n3. Unsupervised models. ESM-IF is a state-of-the-art inverse folding method, trained on the extensive AlphaFold DB. It was shown to effectively score single-point mutations from SKEMPI v2.0.\n4. Supervised models. RDE-Network is a recent, high-quality, and state-of-the-art method fine-tuned on SKEMPI v2.0.\n\nWe value the suggestion to consider additional baselines from ProteinGym. Consequently, we have now added the evaluation of GEMME, the best publicly available model in [ProteinGym](https://www.proteingym.org/substitutions) (GEMME ranks second among 34 methods and is publicly available, unlike the top-ranked model, TranceptEVE). We find that GEMME performs worse on most metrics than our PPIformer (please refer to the table below). However, it is worth noting that GEMME, as well as other ProteinGym methods, was not trained for PPI design. Instead, it was trained to optimize the global fitness of a protein with respect to deep mutational scanning experiments."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8349/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700578559310,
                "cdate": 1700578559310,
                "tmdate": 1700578559310,
                "mdate": 1700578559310,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ZmO9dJiPSn",
                "forum": "xcMmebCT7s",
                "replyto": "0tshmegDww",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8349/Reviewer_hYdu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8349/Reviewer_hYdu"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for updating these extensive experimental results and detailed explanations in such a small time window. The majority of my concerns are well-addressed. While the proposed method does not always achieve top performance (which is usually expected for a conference paper to be accepted), I reckon many investigations and analyses are valuable. I have thus raised my score to 6.\n \nAlso, since the authors have made great efforts during the rebuttal, it would be nice if these investigations could be integrated into the final version (if it gets accepted).\n\nReminder: Please revise your paper to fit into 9 pages as required."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8349/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700637384239,
                "cdate": 1700637384239,
                "tmdate": 1700637861123,
                "mdate": 1700637861123,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "tGxapyvugK",
            "forum": "xcMmebCT7s",
            "replyto": "xcMmebCT7s",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8349/Reviewer_Sjjh"
            ],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8349/Reviewer_Sjjh"
            ],
            "content": {
                "title": {
                    "value": "A Kind Reminder to Authors"
                },
                "comment": {
                    "value": "Hi, authors of PPIFormer,\n\nSince the deadline of discussion period is approaching, I want to know whether you are going to reply to our reviewers' quesitons. I understand that most of us gave a relatively high score, but this does not mean that we have no doubt about the details of PPIformer. \n\nTo be specific, I sincerely hope you can answer the following questions:\n(1) Can you please upload the code to some anomynous repo? **I have reproduced the method described in your paper but the performance is far away from your reported one**. Therefore, I would be pleased to know how you implement this algorithm (e.g., the use of Equiformer, the masked amino acid modeling, fine-tuning the pretrained model)?\n\n(2) Can you please report the performance of PPIformer on the same split of RDE-Net in Skempi v2? As said by Reviewer hYdu, we may suspect that you evaluated models on a cherry-picked test set. The number of test set is so small, and we want to see more comprehensive evaluations. \n\nDue to this reason, I regretfully inform you that I adjusted my score from 6 to 3. But I would be happy to raise it if my concerns are addressed. \n\nThanks."
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8349/-/Official_Comment"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1700550074462,
            "cdate": 1700550074462,
            "tmdate": 1700555590468,
            "mdate": 1700555590468,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "diFxiepWQS",
                "forum": "xcMmebCT7s",
                "replyto": "tGxapyvugK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8349/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8349/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer very much for the high attention dedicated to the submission. We would like to sincerely apologize for the delay with answering the reviews, we are trying our best to run as many experiments as possible to address all the suggestions proposed by the 5 reviewers. We plan on submitting our official answer to all the reviews today."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8349/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700564417871,
                "cdate": 1700564417871,
                "tmdate": 1700564417871,
                "mdate": 1700564417871,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hHy72pYz15",
                "forum": "xcMmebCT7s",
                "replyto": "ft23bSgcz0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8349/Reviewer_Sjjh"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8349/Reviewer_Sjjh"
                ],
                "content": {
                    "title": {
                        "value": "Reply by Sjjh"
                    },
                    "comment": {
                        "value": "Thanks for your response and detailed explanation. I value your effort in trying to answering my questions. First of all, I want to emphasize my favor in your proposed PPIFormer, where a new iDist algorithm is invented to cluster interfaces and a transfer learning technique is introduced to align the pretrained model with ddG task. However, there are still several points that require further improvements and clarification. \n\n(1) I am glad that the author posted the performance of PPIFormer in the same split of RDE in Skempi. The results are not surprising. Because my team has reproduced nearly the same setting of yours (we created an interface dataset, used EquiFormer and adopted the same pretraining/fine-tuning techinque) but found it is impossible to outperform RDE. One of the key reason is that RDE is pretrained not solely on single-chains, but instead its crop of patches can also be located in interfaces (please see the code of RDE in \"rde/utils/transforms/patch.py''). Moreover, we found EquiFormer fairly hard to search the hyper-parameters and cannot stack too many layers. \n\nNotably, the reported performance in RDE is not the unreachable. In the contrast, we discovered many simple mechanims to improve it and our new RDE can reaech a Spearman of 0.43 and a Pearson of 0.46. Though I know it is not reasonble to compare PPIFormer with ours, since we have not published or released any kind of paper work. But my major concern is that even though there are a lot new things in your study (new dataset, new iDist, new transfer learning, etc.), but the accumulated improvement is not significant. A recent paper DiffAffinity [A] evaluated their method on the same split of RDE and claimed better capability. I understand that DiffAffinity is only released recently and it is too harsh if we require you to compare PPIFormer with it. But I hold the view that if PPIFormer is adequatly strong, it should easily outperform RDE by a large margin even if the data split is not perfect. \n\nTo summarize, I believe current results cannot fully convince me of the benefits of PPIFormer. There are many so-called innovations but its improvements are very limited over the baseline model RDE. \n\n[A] Predicting mutational effects on protein-protein binding via a side-chain diffusion probabilistic model. NIPS 2023 \n\n(2) How do you fine-tune your Equiformer. To be specific, are you directly fine-tuning the entire model, or freeze the pretrained weight and regard it as a feature extractor like RDE? \n\nIn addition, I have some suggestions for the authors. First, I think many of my questions do not need additional experiments, and just require clarificaiton. Since this year's discussion period is shorther than the last year, it is better to response as soon as possible rather than posting all answers at once. You replied at nearly the deadline of the discussion phase, and little time is left for our reviewers to exchange our point of views with you. Second, I do not agree with your idea that providing easily usable training code on such a short notice is challenging. Actually, we may not have enough time or computational resources to re-run your code (maybe some very interested reviewers will do). You do not need to upload the large interface data. What you have to do is to release the scripts of some of the key components of PPIFormer, so that we can directly go to your repo and see how you implemented it. Otherwise, we have to guess or ask in OpenReview how you designed and trained the model, which is not effecient. Experienced reviewers can immediately capture the innovations of your work via reviewing your code. \n\nBased on all these reasons, I would raise my score to 5 and wish PPIFormer good luck in the future."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8349/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700623770937,
                "cdate": 1700623770937,
                "tmdate": 1700623770937,
                "mdate": 1700623770937,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zh1UH8DqWy",
                "forum": "xcMmebCT7s",
                "replyto": "KVEA24d7Mb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8349/Reviewer_Sjjh"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8349/Reviewer_Sjjh"
                ],
                "content": {
                    "comment": {
                        "value": "There are so many issues that I disagreed, but I do not want to talk much considering your attitude towards my suggestions.\n\nFirst, we strictly ran several different seeds to ensure our \"simple techniques\" is robustly beneficial instead of merely on one split. Please do not question our rigor in implementing experiments. Besides, who told you that RDE-Linear, RDE-Net, as well as it seems DiffAffinity, are all evaluated on different 3-fold splits but compared together? DiffAffinity used a different split strategy but it re-examined RDE as well. Therefore, you can see RDE only achieved a Spearman of 0.37 in its paper. Please read the paper carefully rather than simply draw the conclusion. \n\nSecond, I still want to emphasize, I admit the existence of data leakage. But if your model is strong enough, you should outperform RDE-Net in whatever split. I have talked to RDE's authors before, and clearly know how they conducted the experiments. To be specific, RDE-Net used a relatively weak backbone (Graph Transformer), did not search the hyperparameters, and did not use complicated data like PPIRef. You brought up so many \"new\" things but still cannot beat it in standard split of RDE. But RDE performs so poorly in your \"new\" split with only 5 test samples. I have strong motivation to suspect that you reproduced RDE badly.\n\nThird, you mentioned a lot about the data leakage. But do you know that the Skempi v2 has many problems? Its value of ddG is not perfect? For instance, some complexes with the same mutations have different ddG (e.g., 3N01_A_B, 3NCB_A_B). Meanwhile,  some complex with different mutations have exactly the same ddGs (e.g., 2B2X_HL_A). There are, indeed, some errors or inaccuracy in the data. You can never train and test the data in a completely clean environment, especially for our AI for life science. A wonderful model should be competitive or the best in all circumstances. I really do not concur with the excuse that PPIFormer cannot outpass RDE due to the data leakage. You have already searched the hyperparameters, and you can use very small model to memorize the leakaged data, but why you still achieved low Spearman and Pearson? \n\nFourth, I have already listed the clue for the authors to investigate the strategy of RDE in cropping patches (\"rde/utils/transforms/patch.py'').  Can you please read the code first and ask for help? RDE randomly selects a chain and then found the closest 32 neighbors in this chain. After that, it choses the closest 96 residues to compose the final patch. These 96 residues can be located in any chains, and can be at the interface as well. \n\n| complex | mutstr | num_muts |  |\n| :--- | :--- | ---: | ---: |\n| 3NCB_A_B | AA167H | 1 | 0.686274 |\n| 3NCB_A_B | AA167H | 1 | -0.73409 |\n| 3NCB_A_B | AA167H | 1 | -1.66972 |\n| 3NCB_A_B | AA167H | 1 | -1.44501 |\n| 3NCB_A_B | AA167H | 1 | -1.48152 |\n| 3NCB_A_B | AA167H | 1 | -1.82152 |\n| 3NCB_A_B | AA167H | 1 | -1.63007 |\n| 3NCB_A_B | AA167H | 1 | -1.6149 |\n| 3NCB_A_B | AA167H | 1 | -1.53541 |\n| 3NCB_A_B | AA167H | 1 | -0.26778 |\n| 3NCB_A_B | AA167H | 1 | -0.77655 |\n| 3NCB_A_B | AA167H | 1 | -1.05533 |\n| 3NCB_A_B | AA167H | 1 | -1.71241 |\n| 3NCB_A_B | AA167H | 1 | -2.03769 |\n| 3NCB_A_B | AA167H | 1 | -2.20317 |\n| 3NCB_A_B | AA167H | 1 | -2.03356 |\n| 3NCB_A_B | AA167H | 1 | -2.45533 |\n| 3NCB_A_B | AA167H | 1 | -2.27295 |\n| 3NCB_A_B | AA167H | 1 | -2.21182 |\n\n| complex | mutstr | num_muts | ddG |\n| :--- | :--- | ---: | ---: |\n| 2B2X_HL_A | VH50T,EH64K,QL28S,YL52N | 4 | 1.043681 |\n| 2B2X_HL_A | VH50T,EH64K,QL28S,YL52N,FH99W | 5 | 1.043681 |\n| 2B2X_HL_A | VH50T,EH64K,QL28S,YL52N,GH54Y | 5 | 1.043681 |\n| 2B2X_HL_A | VH50T,EH64K,QL28S,YL52N,FH99W | 5 | 1.043681 |\n| 2B2X_HL_A | EH64K,QL28S,YL52N | 3 | 1.043681 |\n| 2B2X_HL_A | VH50T,EH64K,QL28S,YL52N,LH60D | 5 | 1.043681 |\n| 2B2X_HL_A | VH50T,QL28S,YL52N | 3 | 1.043681 |\n| 2B2X_HL_A | VH50T,EH64Q,QL28S,YL52N | 4 | 1.043681 |\n| 2B2X_HL_A | VH50T,EH64N,QL28S,YL52N | 4 | 1.043681 |\n| 2B2X_HL_A | VH50T,EH64K,QL28S | 3 | 1.043681 |\n| 2B2X_HL_A | VH50T,EH64K,QL28S,YL52E | 4 | 1.043681 |\n| 2B2X_HL_A | VH50T,EH64K,QL28S,YL52N,FH99W | 5 | 1.043681 |\n| 2B2X_HL_A | VH50T,EH64K,QL28S,YL52N,GH54Y | 5 | 1.043681 |\n| 2B2X_HL_A | VH50T,EH64K,QL28S,YL52N,FH99W | 5 | 1.043681 |\n| 2B2X_HL_A | QL28S,YL52N | 2 | 1.043681 |"
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8349/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700708126809,
                "cdate": 1700708126809,
                "tmdate": 1700708126809,
                "mdate": 1700708126809,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]