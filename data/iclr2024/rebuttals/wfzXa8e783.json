[
    {
        "title": "Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation"
    },
    {
        "review": {
            "id": "5Lb5rzzeE6",
            "forum": "wfzXa8e783",
            "replyto": "wfzXa8e783",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1940/Reviewer_EGJf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1940/Reviewer_EGJf"
            ],
            "content": {
                "summary": {
                    "value": "**Summary:** \nThis paper presents an open-source toolkit based on LoRa. I believe this work might be more appropriate for the \"benchmarking and datasets\" track. Positioned here, it's challenging for me to evaluate the innovation this paper offers."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "**Remarks:** \nWhile the improvements and variants on LoRa are relatively straightforward, the theoretical part of the paper seems sound."
                },
                "weaknesses": {
                    "value": "**Recommendation:** \nI would advise the authors to provide clear insights through experiments and offer some specific suggestions."
                },
                "questions": {
                    "value": "I cannot evaluate this paper because I believe it is proper for a benchmarking and dataset track, not the main track."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1940/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698648757307,
            "cdate": 1698648757307,
            "tmdate": 1699636125308,
            "mdate": 1699636125308,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "BvhALbwGIm",
                "forum": "wfzXa8e783",
                "replyto": "5Lb5rzzeE6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1940/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1940/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for taking the time to read and review our paper! We address your comments in detail below.\n\n> **I would advise the authors to provide clear insights through experiments and offer some specific suggestions.**\n\nIn response to your advice for clearer insights and specific suggestions through experiments, we have introduced a new table (Table 1) in the revised manuscript. This table is aimed at providing a straightforward guide for readers in choosing suitable algorithms for various fine-tuning scenarios. For instance, based on our comprehensive experiments, we suggest that LoHa may be more effective for fine-tuning multiple \"easier\" concepts, whereas LoKr with full dimension appears better suited for targeting single \"harder\" concepts. This insight is reflected in the revised conclusion of our paper to provide more specific guidance.\n\nIn the meantime, we want to emphasize that while our summarized findings and suggestions provide a useful overview, they should be considered with caution. The complexity of fine-tuning text-to-image models, as discussed in detail in appendix C, means that a simplified summary could hardly capture the full picture. In this regard, our detailed text discussion offers a more nuanced explanation of the various ways in which a hyperparameter can influence the results, and is indispensable for a more comprehensive understanding of the fine-tuning process.\n \n\n> **I cannot evaluate this paper because I believe it is proper for a benchmarking and dataset track, not the main track.**\n\nWe appreciate your perspective regarding the suitability of our paper for a benchmarking and dataset track. While our work does include benchmarking, it is important to highlight that these are not its only contributions. A major part of our research introduces and elaborates on new fine-tuning method such as LoHa and LoKr. Moreover, the introduction of the library should also be regarded as an independent contribution. Generally speaking, our work aims to identify the specific fine-tuning methods that are more appropriate for a task of interest. Many works in this line of research (discussed in detail in Appendix A) have been previously accepted by the main track of the conferences, such as\n\n- Zhiheng Liu et al. Cones: Concept neurons in diffusion models for customized generation. In ICML, 2023.\n-  Yuchao Gu et al. Mix-of-show: Decentralized low-rank adaptation for multi-concept customization of diffusion models. In NeurIPS, 2023.\n-  Zeju Qiu et al. Controlling text-to-image diffusion by orthogonal finetuning. In NeurIPS, 2023\n- Nupur Kumari et al. Multi-concept customization of text-to-image diffusion. In CVPR, 2023.\n- Nataniel Ruiz et al. Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation. In CVPR, 2023.\n\nFinally, we do not believe ICLR possesses a separate \"dataset and benchmark\" track. In fact, on the [call for paper page of ICLR 2024](https://iclr.cc/Conferences/2024/CallForPapers), datasets and benchmarks is clearly indicated as a valid subject area, even though in our case, as explained, benchmarking serves more to support and validate the novel contributions, rather than being the sole focus of our work."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1940/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700072612929,
                "cdate": 1700072612929,
                "tmdate": 1700072612929,
                "mdate": 1700072612929,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "8PYHA5RVKo",
            "forum": "wfzXa8e783",
            "replyto": "wfzXa8e783",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1940/Reviewer_DWom"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1940/Reviewer_DWom"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a comprehensive library for evaluating text-to-image finetuning methods, typically based on LoRA. In addition to different algorithms, it also provides comprehensive evaluation criteria. Finally, some experimental results provide some insight about different finetuning methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This is a good engineering paper that provides a library for text-to-image finetuning methods evaluation.\n2. It support different matrix factorization techniques such as LoRA, LoHa, LoKr, DyLoRA, GLoRA, GLoKr and so on.\n3. This paper also consider comprehensive evaluation metrics, including fieldity, controllability, diversity, base model preservation and image quality."
                },
                "weaknesses": {
                    "value": "1. This paper mainly focus on LoRA-based finetuing strategies, can it be expanded to other parameter-efficient finetuning methods such as [1] and [2]? It doesn't provide a clear explanation.\n2. The conclusion about the performance of different finetuning methods is not clearly presented in the experimental section. Maybe some tables can more straightforwardly represent your final conclusions. \n\n[1] Qiu, Zeju, et al. \"Controlling Text-to-Image Diffusion by Orthogonal Finetuning.\" arXiv preprint arXiv:2306.07280 (2023).\n[2] Xie, Enze, et al. \"DiffFit: Unlocking Transferability of Large Diffusion Models via Simple Parameter-Efficient Fine-Tuning.\" arXiv preprint arXiv:2304.06648 (2023)."
                },
                "questions": {
                    "value": "Please refer to the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1940/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1940/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1940/Reviewer_DWom"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1940/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698746208577,
            "cdate": 1698746208577,
            "tmdate": 1699636125239,
            "mdate": 1699636125239,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8gJxv8oKWn",
                "forum": "wfzXa8e783",
                "replyto": "8PYHA5RVKo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1940/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1940/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for your feedback and for raising important points regarding our paper. Please find below our responses to your questions.\n\n> **This paper mainly focus on LoRA-based finetuing strategies, can it be expanded to other parameter-efficient finetuning methods such as [1] and [2]?**\n\nWhile our paper is primarily focused on LoRA-type methods, it is completely possible to include other methods in our library and experiments.\n\nIn fact, IA3 that we mentioned in the paper provides a different strategy via fine-tuning a multiplicative term, which is later generalized by orthogonal fine-tuning (OFT) [1] that you mention. Although we only got aware of this work after submission of the paper, we have already included it in the latest version of LyCORIS. This is also indicated in the revised version of the paper.\n\nOn the other hand, as far as we understand, DiffFit [2] is tailored to class-conditional models and can otherwise be regarded as a more restrained case of IA3 with several additional components, notably the bias and normalization layers, being fine-tuned. We can thus readily configure the training to get something that is really close with earlier version of our library.\n\nFinally, the choice of the focus on LoRA, LoHa, LoKr, and native fine-tuning in the paper are due to their wider use in the community, but we are also considering conducting the same experiments for other methods, and notably OFT.\n\n\n\n> **The conclusion about the performance of different finetuning methods is not clearly presented in the experimental section. Maybe some tables can more straightforwardly represent your final conclusions.**\n\nFollowing your suggestion, we have added a new table (Table 1) in the revised version of our paper to demonstrate the influence of algorithm choice in the fine-tuning process. This addition should enhance clarity and accessibility for readers, providing a more direct understanding of our findings. Thank you for this valuable suggestion!\n\nIn addition to the table, the SHAP beeswarm charts readily included in our original paper serve as another effective tool for illustrating the influence of hyperparameters. However, it is crucial to note that many subtleties and context-specific insights discussed in our text cannot be fully captured by these visualizations alone. The readers should thus consider both the table and the charts in conjunction with the detailed textual explanations to gain a comprehensive understanding of the influence various factors on the fine-tuning process."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1940/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700072589480,
                "cdate": 1700072589480,
                "tmdate": 1700072589480,
                "mdate": 1700072589480,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ACE8ZLRX2R",
            "forum": "wfzXa8e783",
            "replyto": "wfzXa8e783",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1940/Reviewer_PnHf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1940/Reviewer_PnHf"
            ],
            "content": {
                "summary": {
                    "value": "This author introduces LyCORIS, an open source library dedicated to fine-tuning of Stable Diffusion, which integrates a comprehensive range of finetuning methods. For rigorous comparisons between the implemented methods, the author proposes a comprehensive evaluation framework that incorporates a wide range of metrics. Based on the evaluation framework, the author performs extensive experiments to compare different fine-tuning algorithms and to assess the impact of the hyperparameters (i.e, training epochs, learning rate, trained layers, et al). Overall, the experiments, comparisons, analyses, and results of the entire paper are very well-rounded and thorough."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Developing an open-source library is of great significance in fostering the advancement of a particular field. After comparing the existing open-source libraries available online, the LyCORIS library offers a relatively more comprehensive set of algorithms.\n\n2. The author has developed a comprehensive benchmark to evaluate various algorithms from multiple perspectives, addressing a significant gap in the text-to-image field. This thorough evaluation and comparison of existing finetuning methods have been lacking in the domain until now.\n\n3. The author conducted comprehensive experiments for different algorithms and parameters; in addition, the author also provided a detailed analysis of the current mainstream fine-tuning algorithms."
                },
                "weaknesses": {
                    "value": "1. HuggingFace has also released the PEFT library, which supports a wider range of pre-trained models and includes the methods mentioned in the paper. Therefore, what are the advantages of the LyCORIS library compared to PEFT?\n\n2. The paper conducted a multitude of experiments and comparisons on existing methods and various hyperparameters, leading to certain conclusions. Based on these findings, could there be a more optimal algorithm or design compared to previous ones?"
                },
                "questions": {
                    "value": "For this kind of paper that builds benchmarks based on a certain field, I would recommend the author to submit to a journal."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1940/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1940/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1940/Reviewer_PnHf"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1940/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698822869626,
            "cdate": 1698822869626,
            "tmdate": 1699636125143,
            "mdate": 1699636125143,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PAM0EGpoM3",
                "forum": "wfzXa8e783",
                "replyto": "ACE8ZLRX2R",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1940/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1940/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for your insightful comments and questions. Please find our responses to your comments below.\n\n> **HuggingFace has also released the PEFT library, which supports a wider range of pre-trained models and includes the methods mentioned in the paper. Therefore, what are the advantages of the LyCORIS library compared to PEFT?**\n\nWe appreciate your question about the advantages of the LyCORIS library compared to HuggingFace's PEFT. PEFT indeed provides a wide collection of parameter-efficient fine-tuning methods. However, there are two key distinctions that set LyCORIS apart.\n- LyCORIS is specifically designed to cater to users with less expertise in AI and Stable Diffusion, making it more accessible to a wider audience. In contrast, PEFT is tailored more towards expert users.\n- In terms of fine-tuning of text-to-image models, LyCORIS covers more methods than PEFT. In fact, while PEFT initially supported LoRA, our library has incorporated other methods, with some of them, notably LoHa and LoKr, later got implemented by PEFT.\n\n> **The paper conducted a multitude of experiments and comparisons on existing methods and various hyperparameters, leading to certain conclusions. Based on these findings, could there be a more optimal algorithm or design compared to previous ones?**\n \nWe conducted extensive experiments and comparisons on existing methods and various hyperparameters. While these studies have yielded important insights, we agree that asserting the existence of a universally \"optimal\" algorithm is challenging. The effectiveness of any given approach largely depends on specific datasets and tasks. For example, as we indicate in the conclusion of the revised paper, our experiments seem to suggest that LoHa would fit better the case of fine-tuning for multiple easy concepts while LoKr could be more suitable for the case of fine-tuning for a single difficult concept.\nBesides this, our findings offer guidance on hyperparameter choices, while acknowledging the dynamic and context-dependent nature of performance in this field.\n\n\n> **For this kind of paper that builds benchmarks based on a certain field, I would recommend the author to submit to a journal.**\n\nYour suggestion to submit our work to a journal is appreciated. While benchmarking is a significant contribution of our paper, it is not the sole one. Our work also introduces innovative approaches like LoHa and LoKr, which represent important advancements in the field. Therefore, while a journal submission is certainly a viable path, we believe our paper\u2019s diverse contributions warrant consideration in its current format and venue."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1940/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700072555108,
                "cdate": 1700072555108,
                "tmdate": 1700072555108,
                "mdate": 1700072555108,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "QBqp5H2DfK",
            "forum": "wfzXa8e783",
            "replyto": "wfzXa8e783",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1940/Reviewer_ekPo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1940/Reviewer_ekPo"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose LyCORIS, an open-source library that contains multiple fine-tuning techniques for Stable Diffusion. The authors also explore many improved fine-tuning techniques such as LoCon, LoHa and LoKr. This paper also presents evaluations for different fine-tuning techniques using multiple metrics and prompt types."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "(1) The theory and experiments are both solid. The paper has over 57 pages devoted to analyzing the fine-tuning techniques.\n(2) The details for experiments are very clear.\n(3) In addition to the framework, the authors also explore other fine-tuning techniques."
                },
                "weaknesses": {
                    "value": "(1) The results of this framework combined with ControlNet can be presented in this paper.\n(2) Efficiency (time and GPU memory cost) of different approaches are not provided and analyzed."
                },
                "questions": {
                    "value": "(1) Please refer to the main questions in the weakness section.\n(2) A minor question: It will be better if the authors provide the results on other versions of stable diffusion, such as SD2.0 and SDXL."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1940/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699260725548,
            "cdate": 1699260725548,
            "tmdate": 1699636125075,
            "mdate": 1699636125075,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3YtplHxdqt",
                "forum": "wfzXa8e783",
                "replyto": "QBqp5H2DfK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1940/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1940/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for your encouraging comments and valuable feedback. We have addressed each of the points raised in your review as follows.\n\n> **The results of this framework combined with ControlNet can be presented in this paper.**\n\nWe appreciate your suggestion in combining our framework with ControlNet. This is an interesting idea. StabilityAi indeed implemented LoRA for ControlNet during the writing of this paper [1]. However, their dimension is relative large (256 and 128) due to the heavy training workload and task drift. The introduction of other methods implemented in LyCORIS for ControlNet may then be helpful in this regard. While these have not yet been included in our library, we acknowledge their potential and are committed to exploring this integration in future work.\n\n\n[1] https://huggingface.co/stabilityai/control-lora \n\n\n> **Efficiency (time and GPU memory cost) of different approaches are not provided and analyzed.**\n\nTo address this point, we have included a summary of the time and GPU memory costs of different configurations in Table 5 of the revised version of our paper. It is worth noticing that both the actual VRAM usage and training efficiency can vary greatly depending on the implementation and the used hardware. For example, we have modified the implementation of native training in LyCORIS after the experiments, and this should lead to faster training compared to what we report in the table.\n \n> **It will be better if the authors provide the results on other versions of stable diffusion, such as SD2.0 and SDXL.**\n \nOur library has added the support for other versions of Stable Diffusion, such as SD2.0 and SDXL. In the paper, we choose to focus on SD 1.5 due to its wider use and larger user base in the community. Moreover, due to page limitations, we are constrained in the number of experiments we can include. Nevertheless, we believe the experiment based on SD 1.5 already provides a substantial assessment of our framework's capabilities."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1940/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700072522852,
                "cdate": 1700072522852,
                "tmdate": 1700072522852,
                "mdate": 1700072522852,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]