[
    {
        "title": "MAST: A Sparse Training Framework for Multi-agent Reinforcement Learning"
    },
    {
        "review": {
            "id": "H9zO65VLBl",
            "forum": "dtFN6T4aMU",
            "replyto": "dtFN6T4aMU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7594/Reviewer_ehLP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7594/Reviewer_ehLP"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces the Multi-Agent Sparse Training (MAST) framework, which aims to expedite training and enable model compression in MARL. MAST utilizes gradient-based topology evolution to train multiple agents using sparse networks, incorporating a hybrid TD-lambda schema and the Soft Mellowmax Operator to establish reliable learning targets in sparse scenarios. Experiments on the SMAC benchmarks demonstrate the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.\tThe proposed sparse training framework contributes to making MARL systems applicable to resource-limited devices.\n2.\tMAST can be applied to different methods with the CTDE training framework.\n3.\tExperiments on the SMAC benchmarks provide evidence of the effectiveness of the proposed"
                },
                "weaknesses": {
                    "value": "1.\tThe paper utilizes multiple technologies, such as RigL, hybrid TD targets, the Soft Mellowmax operator, and dual buffers, which may make it difficult to discern the specific kernel contribution and novelty.\n2.\tIf the motivation lies in the algorithm, the contribution may seem incremental. Additionally, if the paper aims to design an effective framework, it would be necessary to conduct experiments on other benchmarks, such as Google Research Football, to demonstrate its superiority."
                },
                "questions": {
                    "value": "1.\tI would like the authors to clarify their main contribution to help me better understand the paper.\n2.\tSome curves in the results do not appear to converge at the end. Could this be due to the figures being drawn with smooth weight?\n3.\tThe results were obtained with 4 random seeds. Could you provide information about the variance? Is the method stable?\n4.\tThe paper utilizes many technologies, such as hybrid TD-lambda, which introduces several hyperparameters. How do you decide on these hyperparameters in different scenarios, especially in real-world applications? Do you have any suggestions?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7594/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7594/Reviewer_ehLP",
                        "ICLR.cc/2024/Conference/Submission7594/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7594/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698330886771,
            "cdate": 1698330886771,
            "tmdate": 1700642734370,
            "mdate": 1700642734370,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Lapqaa5NGm",
                "forum": "dtFN6T4aMU",
                "replyto": "H9zO65VLBl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ehLP (Part 1 of 2)"
                    },
                    "comment": {
                        "value": "**Thank you sincerely for your invaluable feedback! Below, we provide a detailed response addressing your comments.**\n\n---\n### Weaknesses\n---\n\n> W1: The paper utilizes multiple technologies, such as RigL, hybrid TD targets, the Soft Mellowmax operator, and dual buffers, which may make it difficult to discern the specific kernel contribution and novelty.\n\nWe would like to highlight our contribution in three aspects.\n1. **Originality:**\n   - Addressing the costliness of training and inference in MARL algorithms, especially on resource-limited devices, our MAST framework stands as the *first* algorithm framework achieving 90% sparsity across multiple MARL algorithms. This marks pioneering research in sparse training for MARL.\n2. **Technical Contributions (Value Learning Enhancements):** Recognizing the inadequacies of sparse MARL models in value learning (indicated in Figure 1), we focused on improving the reliability of training data tagets and training data distributions.\n    - Notably, we introduced $TD(\\lambda)$ targets (Section 4.1) to mitigate sparsification errors and addressed overestimation issues in sparse models using the computationally efficient Soft Mellowmax operator (Section 4.2).\n    - In addition, we proposed a dual buffer mechanism to enhance training stability under sparse models by introducing an additional on-policy buffer.\n3. **Soundness:** Extensive experiments across popular MARL algorithms validate MAST's pioneering role in sparse training:\n    - MAST achieves model compression ratios ranging from 5\u00d7 to 20\u00d7 with minimal performance trade-offs (typically under 3%).\n    - Remarkably reduces FLOPs required for training and inference by up to 20\u00d7.\n\n\n> W2: If the motivation lies in the algorithm, the contribution may seem incremental. Additionally, if the paper aims to design an effective framework, it would be necessary to conduct experiments on other benchmarks, such as Google Research Football, to demonstrate its superiority.\n\n- **Innovative Framework Design:** Our MAST framework stands as a pioneering effort, marking the first algorithm framework to achieve 90% sparsity across multiple MARL algorithms. This represents groundbreaking research in sparse training for MARL.\n- **Experimental Scope:** Our current experiments predominantly focus on SMAC, given the suitability of our base algorithms (QMIX, WQIX, and RES) within this environment, as previously validated in their original papers (Rashid et al. 2020b; Rashid et al. 2020a; Pan et al 2021). Acknowledging the significance of expanding our experimental scope, we aim to include a broader range of algorithms and diverse environments, such as Google Research Football, in our future work."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700417605441,
                "cdate": 1700417605441,
                "tmdate": 1700475260808,
                "mdate": 1700475260808,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3XIYuGRAWm",
                "forum": "dtFN6T4aMU",
                "replyto": "H9zO65VLBl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ehLP (Part 2 of 2)"
                    },
                    "comment": {
                        "value": "### Questions\n---\n\n> Q1: I would like the authors to clarify their main contribution to help me better understand the paper.\n\nPlease refer to the answer for W1.\n\n> Q2: Some curves in the results do not appear to converge at the end. Could this be due to the figures being drawn with smooth weight?\n\nIn our comparative analysis of different algorithms, we ensure a fair assessment by evaluating their performances over a consistent period of interaction with the environment\u2014specifically, 2 million steps, as prior works such as QMIX (Rashid et al. 2020b), WQMIX (Rashid et al. 2020a), and RES (Pan et al. 2021). It's important to note that some curves in the results may not converge towards the end due to the figures being plotted with smoothed results. In some instances, divergent curves might be attributed to particular seeds leading to poorer outcomes. Additionally, certain experiments might not converge at the designated 2 million steps; these cases involve significantly longer training times, resulting in larger FLOPs, making them incomparable with our MAST framework.\n\n\n> Q3: The results were obtained with 4 random seeds. Could you provide information about the variance? Is the method stable?\n\nIn our revised experiments, we have expanded our seed set by incorporating an additional four seeds. Consequently, the reported results in Table 1 now reflect the average outcomes derived from a comprehensive set of eight seeds. Moreover, we've included detailed standard deviation information in Table 7 within Appendix B.6, focusing specifically on the win rate presented in Table 1. Besides, the standard deviation information is also depicted through the width of shaded areas within the training curves in Appendix B.5. These inclusive representations serve to underscore the stability and consistency of our MAST framework across various scenarios, showcasing its robust performance.\n\n\n> Q4: The paper utilizes many technologies, such as hybrid TD-lambda, which introduces several hyperparameters. How do you decide on these hyperparameters in different scenarios, especially in real-world applications? Do you have any suggestions?\n\nOur approach employs a consistent set of recommended hyperparameters (detailed in Table 4) across different algorithms and environments, consistently showcasing superior performance of our MAST framework compared to others.\n- For sensitive hyperparameters like $T_0$ and $\\lambda$ in hybrid TD($\\lambda$) targets and sample partition, we suggest the following values: $T_0=3/8T$, $\\lambda=0.6/0.8$, and a sample partition of $5:3$, where $T$ represents the maximum training step.\n- Regarding insensitive hyperparameters such as $\\alpha$ and $\\omega$ for the Soft Mellowmax operator, we recommend utilizing $\\alpha=1$ and $\\omega=10$. Our algorithm framework demonstrates insensitivity to these parameters, maintaining performances consistently over 85% compared to the original dense performance, as evidenced in our Section 5.2 ablation experiments.\n\n---\n**In conclusion, we extend our gratitude to the reviewer for their invaluable feedback. Should our response effectively address your concerns, we kindly hope that the reviewer could consider raising the score rating for our work. Furthermore, we remain available to address any additional queries or points for discussion.**"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700417630590,
                "cdate": 1700417630590,
                "tmdate": 1700417704576,
                "mdate": 1700417704576,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "la5xQe7Ab5",
                "forum": "dtFN6T4aMU",
                "replyto": "H9zO65VLBl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reminder to Reviewer ehLP"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nThank you for your effort in reviewing our paper!\n\nWe wonder whether our reply fully addresses your concerns. If so, could you please consider raising your score for our work? Please let us know if you have any further questions. We will be more than happy to discuss this with you and answer any remaining questions.\n\nThank you very much!"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700494844408,
                "cdate": 1700494844408,
                "tmdate": 1700494844408,
                "mdate": 1700494844408,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fFsN2MzpPw",
                "forum": "dtFN6T4aMU",
                "replyto": "GyoMY4jjS7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7594/Reviewer_ehLP"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7594/Reviewer_ehLP"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your response."
                    },
                    "comment": {
                        "value": "Thank you for your response. I appreciate that most of my concerns have been addressed. I have thoroughly reviewed all the opinions expressed in the other reviews. While the experiments conducted so far have shown promise, the main weakness still lies in the lack of novelty, and I believe further testing in diverse scenarios is necessary. Consequently, I will raise my score to a 6."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700642674244,
                "cdate": 1700642674244,
                "tmdate": 1700642674244,
                "mdate": 1700642674244,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rWvfYGVqko",
            "forum": "dtFN6T4aMU",
            "replyto": "dtFN6T4aMU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7594/Reviewer_JDXo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7594/Reviewer_JDXo"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces MAST, a novel sparse training framework for deep MARL, utilizing gradient\u0002based topology evolution to efficiently explore network configurations in sparse models. MARL faces significant challenges in ultra-sparse models, including value estimation errors and training instability. Their experiments show the contribution on FLOPs and performance."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.The problem that the authors focus on is very important and valuable to explore.\n2.A lot of experiments have been conducted to prove their contribution."
                },
                "weaknesses": {
                    "value": "1.The writing logic is bad, making readers hard to follow. For example, what is the relationship of the sparse model in SL, single-agent RL and multi-agent RL? Why does MASK apply to QMix series approaches and when MAST is applied to QMIX series algorithms and leverage the RigL method for topology evolution? The authors use too many words on the related work and basic knowledge of MARL, but not clarify the logic clearly.\n2.Some of the formulas are not numbered.\n3.Cannot the discount rate in RL be 1?\n4.The experiment is conducted only on 4 seeds, which is not enough and strong in RL scenarios.\n5.\u201cThese topology adjustments occur infrequently throughout the training process, happening every 200 episodes (about 10,000 steps) in our specific configuration.\u201d How about under other configurations?\n6.Algorithm 1 of the overall procedure is in supplementary, I suggest to contain it in the main text."
                },
                "questions": {
                    "value": "Please see the weakness above. Can the authors give a clear logic of the paper? And the innovative solutions in an easy-understood way?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7594/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698667658388,
            "cdate": 1698667658388,
            "tmdate": 1699636920103,
            "mdate": 1699636920103,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7ySmWyLTJv",
                "forum": "dtFN6T4aMU",
                "replyto": "rWvfYGVqko",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer JDXo (Part 1 of 2)"
                    },
                    "comment": {
                        "value": "**Thank you sincerely for your invaluable feedback! Below, we provide a detailed response addressing your comments.**\n\n---\n### Weaknesses\n---\n> W1. The writing logic is bad, making readers hard to follow. For example, what is the relationship of the sparse model in SL, single-agent RL and multi-agent RL? Why does MASK apply to QMix series approaches and when MAST is applied to QMIX series algorithms and leverage the RigL method for topology evolution? The authors use too many words on the related work and basic knowledge of MARL, but not clarify the logic clearly.\n\nWe've integrated the following bullet points in our revised manuscript and would greatly appreciate any specific areas that still require further clarification:\n\n1. **Relationship of Different Sparse Models**\n    - Sparse networks, initially proposed in **deep supervised learning**, alongside state-of-the-art sparse training frameworks such as SET (Mocanu et al., 2018) and RigL (Evci et al., 2020), can train a 90%-sparse network without performance degradation from scratch.\n    - In **DRL**, the learning target evolves in a bootstrap way (Tesauro et al., 1995), and the training data distribution can be non-stationary (Desai et al., 2019). Existing works (Sokar et al., 2021; Graesser et al., 2022) reveal that directly adopting a DST method in **single-agent RL** fails to uniformly achieve good compression across different environments. RLx2 (Tan et al. 2022) marks the first successful sparse training throughout, surpassing 90% sparsity.\n    - As depicted in Figure 1, neither DST nor RLx2 works in **multi-agent RL**. The complexities in **multi-agent RL**, such as inaccurate value estimation and training instability, are addressed by our MAST framework. MAST utilizes a novel hybrid TD(\u03bb) target mechanism, coupled with the Soft Mellowmax operator, which facilitates precise value estimation even in the face of extreme sparsity. Additionally, MAST unveils a dual buffer mechanism designed to bolster training stability in sparse environments.\n\n2. **Why QMIX?**\n    - Our focus lies on algorithms adhering to the Centralized Training with Decentralized Execution (CTDE) paradigm (Oliehoek et al., 2008; Kraemer & Banerjee, 2016). Within this paradigm, QMIX (Rashid et al., 2020b) stands as a representative algorithm.\n\n3. **Related Work and Basic Knowledge of MARL**\n    - We've condensed and restructured the related work and preliminary sections in our revision.\n\n*References:*\n(Tesauro et al., 1995) Gerald Tesauro et al. Temporal difference learning and td-gammon. Communications of the ACM, 38(3):58\u201368, 1995.\n(Desai et al., 2019) Shrey Desai, Hongyuan Zhan, and Ahmed Aly. Evaluating lottery tickets under distributional shifts. EMNLP-IJCNLP 2019, pp. 153, 2019.\n\n> W2: Some of the formulas are not numbered.\n\nWe have numbered all formulas in our revision.\n\n> W3: Cannot the discount rate in RL be 1?\n\nWe consider the case that discount rate is less than 1.\n* On the one hand, most Reinforcement Learning algorithms (such as SARSA or Q-learning) and Dynamic Programming algorithms converge solely towards the optimal policy under the discounted reward infinite horizon criteria.\n* On the other hand, when the discount rate is below 1, our $TD(\\lambda)$ targets play a significant role in mitigating the network fitting error resulting from network sparsification, as discussed in Section 4.1.\n\n> W4: The experiment is conducted only on 4 seeds, which is not enough and strong in RL scenarios.\n\nIn our revised experiments, we have expanded our seed set to include an additional four seeds. Consequently, the results reported in Table 1 now represent the average outcomes derived from a total of eight seeds.\n\n> W5: \u201cThese topology adjustments occur infrequently throughout the training process, happening every 200 episodes (about 10,000 steps) in our specific configuration.\u201d How about under other configurations?\n\nIn our revision, we've conducted an ablation study focusing on the mask update interval ($\\Delta_m$), detailed in Table 8 within Appendix B.7. Analysis from Table 8 reveals several key observations:\n\n- Findings indicate that a small $\\Delta_m$ negatively impacts performance, as frequent mask adjustments may prematurely drop critical connections before their weights are adequately updated by the optimizer.\n- Overall, A moderate $\\Delta_m=200$ episodes performs well in different algorithms.\n\n> W6: Algorithm 1 of the overall procedure is in supplementary, I suggest to contain it in the main text.\n\nIn our revised version, Algorithm 1 has been relocated to Section 4, accompanied by additional explanations detailing our topology evolution scheme."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700417283737,
                "cdate": 1700417283737,
                "tmdate": 1700624042930,
                "mdate": 1700624042930,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iYMrWYcqQ9",
                "forum": "dtFN6T4aMU",
                "replyto": "rWvfYGVqko",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer JDXo (Part 2 of 2)"
                    },
                    "comment": {
                        "value": "### Questions\n---\n> Q1: Can the authors give a clear logic of the paper? And the innovative solutions in an easy-understood way?\n\n**Summary of Paper Logic:**\n\n1. **Issues of Dynamic Sparse Training (DST) in MARL:** DST, stemming from supervised learning, holds potential for accelerating training and compressing models in MARL. However, direct adoption of DST methods in MARL fails to maintain performance at high sparsity levels, as indicated in Figure 1. This points to the challenge of sparse MARL models struggling with value learning, a crucial aspect for policy learning.\n\n2. **Improving Value Learning in Sparse MARL Models:** MAST introduces innovative solutions to address the accuracy of value learning in ultra-sparse models by concurrently refining training data targets and distributions.\n   - **Enhancing Learning Targets:** Recognizing larger network fitting errors in sparse models, we introduce $TD(\\lambda)$ targets (Section 4.1) to mitigate sparsification errors. Additionally, to address overestimation issues in sparse models, we employ the computationally efficient Soft Mellowmax operator (Section 4.2).\n   - **Stabilizing Training Data:** Observing training instability in MARL algorithms under sparse models with a single off-policy buffer, our proposed dual buffer mechanism (Section 4.3) improves stability by introducing an extra on-policy buffer.\n\n3. **An Innovative Solution (MAST) with Empirical Validation:**\n   - Integrating these enhancements, our innovative solution, MAST, achieves superior sparsity levels exceeding 90% without performance degradation in MARL, validated through our experiments. This work represents pioneering research in sparse training for MARL.\n\nWe have also updated our paper accordingly. Please see our revision.\n\n---\n**In conclusion, we extend our gratitude to the reviewer for their invaluable feedback. Should our response effectively address your concerns, we kindly hope that the reviewer could consider raising the score rating for our work. Furthermore, we remain available to address any additional queries or points for discussion.**"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700417306087,
                "cdate": 1700417306087,
                "tmdate": 1700417474052,
                "mdate": 1700417474052,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ICzAUakKDE",
                "forum": "dtFN6T4aMU",
                "replyto": "rWvfYGVqko",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reminder to Reviewer JDXo"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nThank you for your effort in reviewing our paper!\n\nWe wonder whether our reply fully addresses your concerns. If so, could you please consider raising your score for our work? Please let us know if you have any further questions. We will be more than happy to discuss this with you and answer any remaining questions.\n\nThank you very much!"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700494826031,
                "cdate": 1700494826031,
                "tmdate": 1700494826031,
                "mdate": 1700494826031,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yiYCxGe382",
                "forum": "dtFN6T4aMU",
                "replyto": "ddPzLIr3qz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7594/Reviewer_JDXo"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7594/Reviewer_JDXo"
                ],
                "content": {
                    "title": {
                        "value": "Reply to the authors"
                    },
                    "comment": {
                        "value": "Thanks for the authors' response. After reading other reviewers' concerns, I will remain my score. There are lots of meaningful points in the paper, but please revise the paper carefully and add some of the replies to the main paper. The current paper is below the acceptance."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700614257579,
                "cdate": 1700614257579,
                "tmdate": 1700614257579,
                "mdate": 1700614257579,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "eBu9jueMpf",
            "forum": "dtFN6T4aMU",
            "replyto": "dtFN6T4aMU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7594/Reviewer_LxMW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7594/Reviewer_LxMW"
            ],
            "content": {
                "summary": {
                    "value": "This paper involves sparse training for MARL to reduce the computation cost. Besides, to reduce the value estimation error, a hybrid TD($\\lambda$) and Soft Mellowmax operator are incorporated. Experiments on SMAC show the proposed method significantly reduces the training cost while maintains good performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Using sparse training in MARL is relatively new and an important direction that will inspire the community.\n\nExperiments are conducted on SMAC with extensive analysis."
                },
                "weaknesses": {
                    "value": "The clarity of this paper needs to be improved. For example, the proposed method uses RigL to sparse the network. However, the details of RigL are missing, which makes it confusing for readers who are not familiar with the sparse training area.\n\nThe limitation of this paper is not discussed. For example, there are too many key parameters that need to be fine-tuned, making it infeasible to apply to other complex domains.\n\nThe literature review lacks some closely related work, such as [1]. So the statement 'The only existing endeavor to train sparse MARL agents' is inaccurate. Also, dual buffers have some related work like [2].\n\nThe visualization does not look very informative to the reviewer, as there are no specific patterns for the latent space distribution. Perhaps projecting what connections are removed and what connections are remaining and analyzing why it is like that will be interesting.\n\n[1] Parameter Sharing with Network Pruning for Scalable Multi-Agent Deep Reinforcement Learning. AAMAS 2023.\n\n[2] PMIC: Improving Multi-Agent Reinforcement Learning with Progressive Mutual Information Collaboration. ICML 2022."
                },
                "questions": {
                    "value": "Please see the pros and cons part.\n\nCould you explain more about why 'larger values under a sparse model compared to a dense network' in Section 4.1? Do you mean overestimations?\n\nThe well-known method to deal with overestimation is double Q-learning, have you compared this with SM? Which one is better and why?\n\nHow do you select the value of $\\omega$ as 5 and 10? \n\nWhy does the value in Table 1 exceed 100%? How do you calculate it?\n\nThe common evaluation metric in SMAC is average success rate, why do you use average reward? Do you normalize all tasks' rewards to the same scale?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7594/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699071038816,
            "cdate": 1699071038816,
            "tmdate": 1699636920009,
            "mdate": 1699636920009,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "cZToNV3inu",
                "forum": "dtFN6T4aMU",
                "replyto": "eBu9jueMpf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer LxMW (Part 1 of 2)"
                    },
                    "comment": {
                        "value": "**Thank you sincerely for your invaluable feedback! Below, we provide a detailed response addressing your comments.**\n\n---\n### Weaknesses\n---\n> W1: The clarity of this paper needs to be improved. For example, the proposed method uses RigL to sparse the network. However, the details of RigL are missing, which makes it confusing for readers who are not familiar with the sparse training area.\n\nWe've incorporated additional details about RigL in Section 4 in our revision. We would greatly appreciate any specific areas that still require further clarification.\n\n> W2: The limitation of this paper is not discussed. For example, there are too many key parameters that need to be fine-tuned, making it infeasible to apply to other complex domains.\n\nIn our revision, we've discussed the limitations concerning implementation and hyperparameter tuning in Appendix A.4. Additionally, we also provide Table 4 in Appendix B.3 for practical recommendations for both sensitive and insensitive hyperparameters across different algorithms and environments:\n\n1. **For sensitive hyperparameters** (such as $T_0$ and $\\lambda$ for hybrid TD($\\lambda$) targets and sample partition), we recommend values of $T_0=3/8T$, $\\lambda=0.6/0.8$, and a ratio of $5:3$ for the sample partition, where $T$ represents the maximum training step.\n\n2. **For insensitive hyperparameters** (such as $\\alpha$ and $\\omega$ for the Soft Mellowmax operator), flexibility exists in their settings. However, we recommend following our suggestion of $\\alpha=1$ and $\\omega=10$. Our algorithm framework demonstrates insensitivity to these parameters, with performance consistently exceeding 85% compared to the original dense performance, as illustrated in Table 3.\n\n*Notably*, as depicted in Table 1, employing the recommended hyperparameter settings (as detailed above) across different algorithms and environments consistently positions our MAST as the top performer.\n\n\n> W3: The literature review lacks some closely related work, such as [1]. So the statement 'The only existing endeavor to train sparse MARL agents' is inaccurate. Also, dual buffers have some related work like [2].\n\nWe have included the related work mentioned in our revision.\n\n> W4: The visualization does not look very informative to the reviewer, as there are no specific patterns for the latent space distribution. Perhaps projecting what connections are removed and what connections are remaining and analyzing why it is like that will be interesting.\n\nIn our revision, we've provided connection counts for both input and output dimensions in Figure 10 of the main paper and Appendix B.8 for further insight into topology evolution. These new illustrations specifically highlight the non-zero connection counts in both input and output dimensions during the training, shedding light on pruned dimensions. Surprisingly, our findings reveal that a small portion of neurons in both input and output layers prove necessary, while others exhibit minimal or no connections after MAST training. This observation underscores the substantial redundancy present in the original dense network and the efficacy of our MAST framework in removing such redundancy. Notably, this observation aligns with the sparse model obtained in single-agent RL, as demonstrated in Appendix C.11 of (Tan et al., 2022)."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700417195052,
                "cdate": 1700417195052,
                "tmdate": 1700646003824,
                "mdate": 1700646003824,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NYLHV28P5U",
                "forum": "dtFN6T4aMU",
                "replyto": "eBu9jueMpf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer LxMW (Part 2 of 2)"
                    },
                    "comment": {
                        "value": "### Questions\n---\n> Q1: Could you explain more about why 'larger values under a sparse model compared to a dense network' in Section 4.1? Do you mean overestimations?\n\nThis sentence was amended in our revision as follows: *\"Denote the network fitting error as $\\epsilon(s,\\boldsymbol{u})=Q_\\text{tot}(s,\\boldsymbol{u};{\\theta})-Q_\\text{tot}^{\\pi_t}(s,\\boldsymbol{u})$, it will be larger under an improper sparsified model compared to a dense network, as evidenced in Figure 1 where improper sparsified models fail in learning good policy.\"* This statement highlights an empirical observation, implying that the network's performance might significantly deteriorate when trained with an improperly sparsified neural network.\n\nAs indicated in Figure 1, the use of static sparse networks or classical dynamic sparse training methods detrimentally affects network performance, leading to an increase in the network fitting error. This effect occurs when the network is only sparsified without other modifications in data distribution or data targets, causing a notable rise in the absolute value of the network fitting error.\n\n\n> Q2: The well-known method to deal with overestimation is double Q-learning, have you compared this with SM? Which one is better and why?\n\n\nIndeed, the algorithm we experimented with, such as QMIX, incorporates measures to mitigate overestimation issues, notably employing double Q-learning (utilizing $Q$ network and target $Q$ network for each agent's value esimation in QMIX). However, as demonstrated in Figure 4, relying solely on double Q-learning remains insufficient in resolving the overestimation challenges within sparse models. Our experimental findings indicate that despite the inclusion of double Q-learning in QMIX, the overestimation issue persists, and our SM operator significantly contributes to addressing this limitation within the framework.\n\n> Q3: How do you select the value of w as 5 and 10?\n\nWe adhere to the recommendations outlined in prior research on the Soft Mellowmax operator, specifically as detailed in Gan et al. (2021). On the other hand, we note that MAST's performances are insensitivity to these parameters ($\\alpha$ and $\\omega$), with performance consistently exceeding 85% compared to the original dense performance, as illustrated in Table 3.\n\n> Q4: Why does the value in Table 1 exceed 100%? How do you calculate it?\n\nAs highlighted in the caption of Table 1, all data is normalized with respect to the dense model. The performance attained by MAST surpasses that of the original dense model when the value exceeds 100%.\n\n> Q5: The common evaluation metric in SMAC is average success rate, why do you use average reward? Do you normalize all tasks' rewards to the same scale?\n\nThis was a typo, and we've corrected it in our revised version. Our primary evaluation metric is the average win rate. In Table 1 in the main paper, the performance, i.e. the win rate, of different algorithms is normalized with respect to the dense model. We provide a comprehensive report on the exact average win rate in Table 7 in the Appendix B.6 with standard deviation.\n\n---\n**In conclusion, we extend our gratitude to the reviewer for their invaluable feedback. Should our response effectively address your concerns, we kindly hope that the reviewer could consider raising the score rating for our work. Furthermore, we remain available to address any additional queries or points for discussion.**"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700417223418,
                "cdate": 1700417223418,
                "tmdate": 1700417499961,
                "mdate": 1700417499961,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SScurVJ08k",
                "forum": "dtFN6T4aMU",
                "replyto": "eBu9jueMpf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reminder to Reviewer LxMW"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nThank you for your effort in reviewing our paper!\n\nWe wonder whether our reply fully addresses your concerns. If so, could you please consider raising your score for our work? Please let us know if you have any further questions. We will be more than happy to discuss this with you and answer any remaining questions.\n\nThank you very much!"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700494795382,
                "cdate": 1700494795382,
                "tmdate": 1700494795382,
                "mdate": 1700494795382,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "R79fFK1qku",
                "forum": "dtFN6T4aMU",
                "replyto": "eBu9jueMpf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7594/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Another Reminder to Reviewer LxMW"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nYour thoughts on our revisions would be immensely valuable to us as we strive to address all concerns raised during the review process. We're eager to ensure that our paper meets the high standards set by your expertise and the conference's guidelines.\n\nWe greatly appreciate your time and consideration in reviewing our updated submission. Your prompt response would be sincerely appreciated."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700579302296,
                "cdate": 1700579302296,
                "tmdate": 1700579383686,
                "mdate": 1700579383686,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xT5f6k9eBa",
                "forum": "dtFN6T4aMU",
                "replyto": "R79fFK1qku",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7594/Reviewer_LxMW"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7594/Reviewer_LxMW"
                ],
                "content": {
                    "title": {
                        "value": "ACK"
                    },
                    "comment": {
                        "value": "Thanks for the response. I already have all the information I need for the discussion phase. Thanks."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700591272956,
                "cdate": 1700591272956,
                "tmdate": 1700591272956,
                "mdate": 1700591272956,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]