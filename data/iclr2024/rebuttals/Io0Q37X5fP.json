[
    {
        "title": "Counterfactual Generative Models for Time-Varying Treatments"
    },
    {
        "review": {
            "id": "FhxqZKlNzX",
            "forum": "Io0Q37X5fP",
            "replyto": "Io0Q37X5fP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6428/Reviewer_kkvR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6428/Reviewer_kkvR"
            ],
            "content": {
                "summary": {
                    "value": "This study addresses an important issue of causal inference (counterfactual outcome in time-varying situation) by generating a counterfactual distribution. They conducted various experiments as well as getting good results. I think this is a nice paper. However, there are many parts of this paper where the interpretation needs to be improved. As I have been busy lately, it is possible that there are some details that I have not checked sufficiently."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This study proposes a new approach that can be used for high-dimensional outcomes. Most existing studies consider low-dimensional outcomes.\n2. Addressing the issue of counterfactual outcomes by generating counterfactual distributions is interesting.\n3. They conducted experiments on various datasets. Importantly, they used real data.\n4. The experiment results provided by the authors are good."
                },
                "weaknesses": {
                    "value": "1. Many parts of the explanation need to be improved. For example, authors focus on describing what they did and used, but not why they did it. How do readers use this model to solve causal issues, such as ITE estimation? In addition, for the description of datasets, readers may wonder what is the treatment in these datasets (authors only said \"treatment variable\").\n2. Lack of comparison of technological innovations from previous approaches. It might be helpful to understand the contribution of this paper by adding a paragraph discussing this."
                },
                "questions": {
                    "value": "1. How should readers use your methods to estimate ITE?\n2. What do treatments represent in the datasets used in experiments?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6428/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6428/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6428/Reviewer_kkvR"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6428/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698373522714,
            "cdate": 1698373522714,
            "tmdate": 1699636717272,
            "mdate": 1699636717272,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "UBPgwAwqJB",
                "forum": "Io0Q37X5fP",
                "replyto": "FhxqZKlNzX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6428/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6428/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors"
                    },
                    "comment": {
                        "value": "Thanks much for your valuable and insightful comments. We express our gratitude to the reviewer for your positive comments regarding the importance of addressing high-dimension outcomes, the use of generative models, and the positive experimental results. We also thank the reviewer for emphasizing the potential extension of our framework, the comparison to current literature, and the meaning of the treatment variables. We have updated the manuscript according to your comments. Please see our point-by-point responses below.  \n\n\n > How do readers use this model to solve causal issues, such as ITE estimation?\n\nWe appreciate the reviewer's reference to Individual Treatment Effects (ITE). We would like to clarify that our approach to estimating the counterfactual distribution across a population, rather than individual-focused estimates (ITE), is driven by the practicality of our research's applications, such as in public health policy. Implementing policies on an individual basis can be costly and sometimes unfeasible. By focusing on the population level (or a sub-population), we capture individual differences, which is essential for effective policy-making. In contrast, the variation within individual counterfactuals often stems from observational noise and might need substantial data for precise estimation. Consider, for instance, the COVID-19 data: our objective is to analyze the counterfactual outcome of a state-wide policy (mask mandate) and provide policymakers with a range of possible counterfactual outcomes that reflect variability in county-level confirmed cases. In such contexts, policymakers might be less concerned with the estimation noise at the individual level and more focused on the broader variability across different individuals.\n\n In the meantime, a related extension of our work might be to infer conditional counterfactual outcomes (related to the conditional average treatment effect, CATE). This corresponds to looking at the distribution of the outcome under a specific subpopulation. Since our covariates are assumed to be time-varying, a common approach is to introduce a set of static baseline covariates, $V$ (Robins et al, 1999). The baseline covariate $V$ denotes the static feature (such as a patient's gender or age) that will influence both the time-varying covariates $X$ and the outcome $Y$. We can then draw counterfactual samples from a specific sub-population by conditioning on the values of the $V$. In this framework, we observe ($Y_t^i$, $\\overline{A}_t^i$, $\\overline{X}_t^i$, $V^i$), where $V \\in \\mathbb{R}^{\n    \\nu}$ is a static baseline variable that varies by individual.  Accordingly, the generator will have an additional input: \n$ g\\_{\\theta}(z, \\overline{a},v): \\mathbb{R}^r \\times \\mathcal{A}^d \\times \\mathbb{R}^{\\nu} \\rightarrow \\mathcal{Y}$ , and the IPTW weights will become $ w\\_\\phi(\\overline{a},\\overline{x},v) = \\frac{1}{\\prod\\_{\\tau=t-d+1}^{t} f\\_\\phi(a\\_{\\tau}|\\overline{a}\\_{\\tau-1},\\overline{x}\\_{\\tau},v)}$.   Correspondingly, the objective in Proposition 1 will become $\\mathbb{E}\\_{v} ~\\mathbb{E}\\_{\\overline{a}} ~\\left[\\mathbb{E}\\_{y \\sim f\\_{\\overline{a},v}} ~\\log f\\_\\theta(y|\\overline{a},v)\\right] \\approx \\frac{1}{N}\\sum\\_{(y,\\overline{a},\\overline{x},v) \\in \\mathcal{D}}w\\_\\phi(\\overline{a},\\overline{x},v) \\log f\\_\\theta(y|\\overline{a},v).$ \n\n We have conducted additional experiments using the fully synthetic dataset, where the baseline variable, $V$, was divided into two groups. The $V$ was uniformly drawn from $[-1,0]$ in the first group and from $[0,1]$ in the second group. We then looked at the performance of the generative samples corresponding to two sub-groups. We included the results in **Appendix I** (Table 4, Fig.11, and Fig.12) of the revised manuscript.  Our method (MSCVAE) still consistently outperforms other baseline methods in the simplified results below (Wasserstein distance, smaller the better):\n\n- $V\\in[-1,0]$\n\n|         | d=1  | d=3  |  d=5  |\n| ----------- | ----------- | ----------- |----------- |\n| MSM+NN      |   0.408    |  0.449   |  0.368 |\n| KDE               |      0.201 |  0.562 |  0.564  |\n| Plugin+KDE   |        0.117    |      0.134      |   0.196      |\n| G-Net             |        0.431        |      0.823       |   0.843    |\n| CVAE             |       0.240          |     0.571       |   0.585   |\n| MSCVAE        |        0.051         |      0.083      |    0.186   |\n\n- $V\\in[0,1]$\n\n|         | d=1  | d=3  |  d=5  |\n| ----------- | ----------- | ----------- |----------- |\n| MSM+NN      |   0.407    |  0.466  |  0.388 |\n| KDE               |      0.222 |  0.548 |  0.561  |\n| Plugin+KDE   |        0.121   |      0.109      |   0.182      |\n| G-Net             |        0.452       |      0.739       |   0.768    |\n| CVAE             |       0.258          |     0.565      |   0.591   |\n| MSCVAE        |        0.047         |      0.068      |    0.172   |"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700376918340,
                "cdate": 1700376918340,
                "tmdate": 1700376918340,
                "mdate": 1700376918340,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZQ4KWklBth",
            "forum": "Io0Q37X5fP",
            "replyto": "Io0Q37X5fP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6428/Reviewer_QN9X"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6428/Reviewer_QN9X"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors propose a method to estimate the high-dimensional counterfactual distributions for time-varying treatments. The method uses a generative model to do the task. The generative model allows for generating credible samples of the counterfactual outcomes given a time-varying treatment such that policymakers can assess a policy\u2019s efficacy by exploring a range of probable outcomes and deepening their understanding of its counterfactual result."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is technically sound. Generally, it is not hard for readers to follow. The ideas are presented well, but still, the clarity of the paper can be further improved."
                },
                "weaknesses": {
                    "value": "Although readers should be able to follow and understand the notions presented in the paper, the paper is not organized well. For instance, the authors defer the standard causal assumptions to the Appendix.  The authors may not give detailed explanations about the causal assumptions in the main paper, but at least mention the names of the causal assumptions in the paper. Please refer to questions for further weakness."
                },
                "questions": {
                    "value": "1. In Algorithm 1, the authors suggest that we should draw a sample epsilon from $N(0,I)$, where $I$ is the total number of individuals. What is the point of setting epsilon as a realization with large variance? Usually, $I$ can be very large. Indeed, if there are a large number of individuals, say $I=10000$, a realization can be very large. Further, why do you model epsilon as normally distributed?\n\n2. I have a question about the training process. The objective function is given in Eqn. (2) which is approximated by Eqn. (5). Nevertheless, the computation is given for each t only, where t lies in between 1, \u2026 , T according to the paper. We can obtain T approximations according to Eqn. (5). During training, the goal is to minimize one objective value, but we can calculate T approximations where each of the T approximations can be thought of as the objective value. What should be the objective value of training?\n\n3. In the paper, the authors state that t=1, \u2026, T in the section of PROBLEM SETUP. However, when the authors present Algorithm 1, t = d, \u2026, T. It is strange that t=d, \u2026, T in Algorithm 1. Is it a typo mistake? If not, from my realization about Algorithm 1, d should be determined. How to determine the value of d?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6428/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6428/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6428/Reviewer_QN9X"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6428/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698739941060,
            "cdate": 1698739941060,
            "tmdate": 1699636717133,
            "mdate": 1699636717133,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NeLRTGq0aw",
                "forum": "Io0Q37X5fP",
                "replyto": "ZQ4KWklBth",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6428/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6428/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors"
                    },
                    "comment": {
                        "value": "Thanks much for your valuable and insightful comments. We express our gratitude to the reviewer for your positive comments regarding the technical soundness of our method. We also thank the reviewer for the careful read and the mention of the confusion from the notations. We have updated the manuscript according to your comments. Please see our point-by-point responses below.\n\n> The authors may not give detailed explanations about the causal assumptions in the main paper, but at least mention the names of the causal assumptions in the paper. \n\nThanks for the suggestion. In the revised manuscript, we mentioned the three causal assumptions in the methodology section.\n\n>  In Algorithm 1, the authors suggest that we should draw a sample epsilon from $N(0,I), where $I$ is the total number of individuals. What is the point of setting epsilon as a realization with large variance?\n\nWe would like to clarify that $I$ should stand for the identity matrix, and $N$ represents the total number of samples. We have fixed it in the revised paper.\n\n>  Why do you model epsilon as normally distributed?\n\nThe Gaussian assumption for the VAE is a common assumption which enables a closed form expression for the ELBO  (Kingma and Welling, 2013). To elaborate, our generative framework essentially involves identifying a transformation that converts random noise into the desired target distribution, which in this case is the counterfactual distribution. It's a standard practice in the field of generative models to use the normal distribution as the basis for our source distribution (Kingma and Welling, 2013; Sohn et al, 2015; Higgins et al, 2016).\n\n>  What should be the objective value of training?\n\nWe would like to clarify that, the objective function in Proposition 1 is evaluated over the entire $N$ data samples, where $N$ represents the total number of samples across individuals and time (see below). Similarly, in the algorithm box, where batch optimization can be used, the objective is then evaluated over the mini-batch. \n\n In the revised manuscript, we have clarified how data were indexed. Consistent with much of the literature on longitudinal causal inference, such as (Lim et al, 2018; Bica et al, 2020; Li et al, 2021), our approach assumes that data is observed across individuals, with each individual having data for $T$ time points. Importantly, given its history $\\overline{X}$ and $\\overline{A}$, the outcome, $Y$, can be treated as conditionally independent samples. Therefore, for simplicity, we could 'chop' the time series of each individual, leading to a total of $N$ data tuples across individuals and time. For example, if there are $1000$ individuals each with $100$  time points and $d=3$, then $N = 1000\\times (100-3+1)=98,000$ (we truncate the first $d-1$ time points because they do not have a full history). Therefore, we denote the data tuples simply as ($y^i,\\overline{x}^i,\\overline{a}^i$), where $i$ denotes the index of the sample and ranges from $1$ to $N$. \n\n> It is strange that t=d, \u2026, T in Algorithm 1. Is it a typo mistake? \n\nFollowing the previous point, we ranged $t$ from $d$ instead of $1$ because the first $d-1$ time points do not have full-length ($=d$) history.\n\n> How to determine the value of d?\n\nAs a standard in longitudinal causal inference  (Robins et al, 1994; Lim et al, 2018; Bica et al, 2020; Li et al, 2021; Bica et al 2021), $d$ is pre-determined as prior knowledge of the data generating process.  This approach is validated by our numerical findings, proving to be an effective method. For instance, in our COVID-19 studies, we set $d=3$ following insights from epidemiological research, which indicates that a mask mandate typically requires two to three weeks to become effective in a population.\n\nIntuitively, $d$ can be considered as a causal structure that determines how many arrows should point to the current variable of interest from history. Therefore, if one is interested in estimating $d$ instead of pre-determining it, a potential method is causal discovery which automatically infer the DAG (Figure 8) from data."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700377928133,
                "cdate": 1700377928133,
                "tmdate": 1700377928133,
                "mdate": 1700377928133,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qhl7GxOZtX",
            "forum": "Io0Q37X5fP",
            "replyto": "Io0Q37X5fP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6428/Reviewer_9P43"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6428/Reviewer_9P43"
            ],
            "content": {
                "summary": {
                    "value": "The author delved into examining the counterfactual results of treatments in dynamic treatment scenarios. They introduced a novel generative framework designed to produce counterfactual outcomes without explicitly learning the counterfactual distribution. In their approach, they put forth a learning objective that relies on reweighted Evidence Lower Bound (ELBO) within a conditional Variational Autoencoder (VAE), utilizing inverse propensity weights."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Paper tackles the complex issue of estimating counterfactual outcomes in the face of time-varying treatment effects.\n-The proposed method adeptly handles high-dimensional outcomes.\n- Capable of generating counterfactual samples without imposing rigid assumptions on the distribution of the counterfactual outcome."
                },
                "weaknesses": {
                    "value": "IPTW values can be notably small and, as highlighted by the author, require precise definition. This circumstance can exacerbate in sequential treatment scenarios.\n\nGiven we're handling a treatment sequence, it's important to note that the counterfactual treatment is not unique. However, the notation used does not reflect this.\n\nI believe the following two papers could also serve as baseline references:\n1. \"Disentangled Counterfactual Recurrent Networks for Treatment Effect Inference Over Time\"\n2. \"Estimating Counterfactual Treatment Outcomes Over Time Through Adversarially Balanced Representations\""
                },
                "questions": {
                    "value": "If x isn't utilized in the generator, what's the rationale for calculating weights based on x? Why not solely estimate treatment probability based on the treatment sequence?\n\nCan you provide a proof for equation 2? What would be the difference in objective if we were to define the distance in terms of Maximum Mean Discrepancy (MMD) or Wasserstein distance?\n\nConsidering your framework, it appears straightforward to expand it to the individual outcome level. What led to the decision to overlook that possibility?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6428/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6428/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6428/Reviewer_9P43"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6428/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698814929889,
            "cdate": 1698814929889,
            "tmdate": 1699636717011,
            "mdate": 1699636717011,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Tr4X2qjePo",
                "forum": "Io0Q37X5fP",
                "replyto": "qhl7GxOZtX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6428/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6428/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors"
                    },
                    "comment": {
                        "value": "Thanks much for your valuable and insightful comments. Our sincere thanks to the reviewer for recognizing the underlying motivation and flexibility of our approach. Please see our point-by-point responses below. \n\n> IPTW values can be notably small and, as highlighted by the author, require precise definition.\n\nThank you for your comments regarding our use IPTW. We agree that IPTW can be unstable and might lead to less reliable results in certain contexts.  Nevertheless, it's important to highlight that integrating IPTW with our novel generative framework represents a significant and novel methodological advancement. This combination is particularly effective in capturing complex, high-dimensional patterns in counterfactual outcomes, an area our study uniquely addresses to the best of our knowledge.\n\nTo address the stability concerns in a practical context, our experiments incorporated established stabilization strategies, such as quantile truncation and standardization, as extensively discussed in the literature (Xiao et al, 2010; Chesnaye et al, 2022). The results from our experiments also show that incorporating these techniques into the design of our marginal structure model greatly results in promising and dependable numerical outcomes.\n\n> Given we're handling a treatment sequence, it's important to note that the counterfactual treatment is not unique.\n\nWe would like to clarify that our generator approximates the counterfactual distribution for any $\\overline{a}$, so there should be an expectation over $\\overline{a}$ for the objective function:\n    $$\\hat{\\theta} \n    = argmin_{\\theta \\in \\Theta}~\\mathbb{E}_{\\overline{a}} ~\\left[D_f(f\\_{\\overline{a}}, f\\_\\theta(\\cdot|\\overline{a})) \\right],$$\n\nwhere $D$ represents the distributional distance between $f\\_{\\overline{a}}$ (true counterfactual distribution) and $f\\_\\theta$ (the proxy conditional distribution represented by our proposed counterfactual generator $g\\_\\theta$), such as KL divergence. We genuinely appreciate the reviewer's careful read of these details, and have updated the manuscript (Equation 2, 3 and Proposition 1) to address this issue. \n\n>  I believe the following two papers could also serve as baseline references ... \n\n We thank the reviewer for mentioning these baseline methodologies. However, it's important to note that these methods are tailored for mean prediction, which differs from our objective of distribution estimation. Additionally, these methods primarily focus on predicting outcomes at the individual level, whereas our research is geared towards assessing the outcomes at the population level. These fundamental differences might make it challenging for a fair comparison between their methods and ours.  In this regard, we could incorporate these methods to compare with our method in terms of mean estimate, should the reviewer consider it necessary. \n\n> If x isn't utilized in the generator, what's the rationale for calculating weights based on x? Why not solely estimate treatment probability based on the treatment sequence?\n\n We would like to clarify that, estimating treatment probability based solely on the treatment sequence will introduce bias. This is because the propensity score, $f(A_t|\\overline{A}\\_{t-1},\\overline{X}\\_{t})$, depends the history of both treatments and covariates. Therefore, IPTW can vary for the same treatment sequence, $\\overline{a}$, owing to the variability in $X$. Importantly, the covariates $X$ play a crucial role in the standard approaches for IPTW estimation (Robins et al, 1999; Lim et al, 2018). As a result,  while we do not have to directly use  $X$ during training our conditional generative model, we still access them through the IPTW weights in Proposition 1."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700379564466,
                "cdate": 1700379564466,
                "tmdate": 1700379564466,
                "mdate": 1700379564466,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HGanRSIxkc",
                "forum": "Io0Q37X5fP",
                "replyto": "qhl7GxOZtX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6428/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6428/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Author"
                    },
                    "comment": {
                        "value": ">  Can you provide a proof for equation 2?\n\nWe have included a proof for Eq 2 (Eq 3 in the revised manuscript) in Appendix C (pasted below). The objective function for training the counterfactual generator minimizes the difference between $f\\_\\theta(\\cdot|\\overline{a})$ and the true counterfactual distribution $f\\_{\\overline{a}}$ with respect to a distributional difference $D_f(\\cdot,\\cdot)$ over all treatment combinations, $\\overline{a}$. When the distance measure is the KL-divergence, this  equals maximizing the log-likelihood of the conditional distribution when data is sampled from the counterfactual distribution:\n$$\\hat{\\theta} = argmin\\_{\\theta \\in \\Theta} \\mathbb{E}\\_{\\overline{a}} [{\\rm KL}(f\\_{\\overline{a}}(\\cdot) || f\\_\\theta(\\cdot|\\overline{a})) ]  $$\n$$= argmin\\_{\\theta \\in \\Theta} \\mathbb{E}\\_{\\overline{a}} [\\int \\log \\left(\\frac{f\\_{\\overline{a}}(y)}{f\\_\\theta(y|\\overline{a})}\\right)f\\_{\\overline{a}}(y) dy]$$\n$$= argmax\\_{\\theta \\in \\Theta} \\mathbb{E}\\_{\\overline{a}} [ \\int \\log \\left(f\\_\\theta(y|\\overline{a})\\right)f\\_{\\overline{a}}(y) dy ] $$\n$$= argmax\\_{\\theta \\in \\Theta} \\mathbb{E}\\_{\\overline{a}} [\\mathbb{E}_{y \\sim f\\_{\\overline{a}}} ~\\log f\\_\\theta(\\cdot|\\overline{a}) ]$$\n\n> What would be the difference in objective if we were to define the distance in terms of Maximum Mean Discrepancy (MMD) or Wasserstein distance?\n\nWe specifically study KL-divergence because it is well formulated for majority of generative models, including CVAE and many others, and has been focused in related work on counterfactual density estimation (Kennedy 2021, Melnychuk, 2023). Replacing KL with (kernel) MMD or Wasserstein-1 distance may lead to technical difficulties, due to the min-max formulation in MMD and Wasserstein distance. In particular, we have the following unified objective function for kernel MMD and Wasserstein-1 distance:\n$$\n    \\hat{\\theta} = argmin\\_{\\theta \\in \\Theta}~ \\mathbb{E}\\_{\\overline{a}} [\\sup\\_{\\phi \\in \\Phi} | \\mathbb{E}\\_{y \\sim f\\_\\theta(\\cdot | \\overline{a})}[\\phi(y)] -\\mathbb{E}\\_{y \\sim f\\_{\\overline{a}}(\\cdot)}[\\phi(y)] \\| \\].\n$$\nHere $\\Phi$ is a class of functions. For kernel MMD, $\\Phi$ is class of kernel mappings and for Wasserstein-1 distance, $\\Phi$ consists of all $1$-Lipschitz functions. As can be seen, the objective function now involves an inner maximization operation, which often leads to numerical instability. This phenomenon is well recognized in generative adversarial networks' training (Mescheder et al., 2018; Goodfellow et al., 2020). Therefore, we would like to emphasize the computational efficiency brought by Proposition 1 for the KL case. This proposition allows us to bypass the direct estimation of $f_{\\overline{a}}$, significantly enhancing computational scalability in high-dimensional cases.\n\n> Considering your framework, it appears straightforward to expand it to the individual outcome level. What led to the decision to overlook that possibility?\n\nWe appreciate the reviewer's reference to Individual Treatment Effects (ITE). We would like to clarify that our approach to estimating the counterfactual distribution across a population, rather than individual-focused estimates (ITE), is driven by the practicality of our research's applications, such as in public health policy. Implementing policies on an individual basis can be costly and sometimes unfeasible. By focusing on the population level (or a sub-population), we capture individual differences, which is essential for effective policy-making. In contrast, the variation within individual counterfactuals often stems from observational noise and might need substantial data for precise estimation. Consider, for instance, the COVID-19 data: our objective is to analyze the counterfactual outcome of a state-wide policy (mask mandate) and provide policymakers with a range of possible counterfactual outcomes that reflect variability in county-level confirmed cases. In such contexts, policymakers might be less concerned with the estimation noise at the individual level and more focused on the broader variability across different individuals."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700380223021,
                "cdate": 1700380223021,
                "tmdate": 1700380223021,
                "mdate": 1700380223021,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tN78yP0oc4",
                "forum": "Io0Q37X5fP",
                "replyto": "qhl7GxOZtX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6428/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6428/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Author"
                    },
                    "comment": {
                        "value": "(Continued from the last response)\n\n In the meantime, a related extension of our work might be to infer conditional counterfactual outcomes (related to the conditional average treatment effect, CATE). This corresponds to looking at the distribution of the outcome under a specific subpopulation. Since our covariates are assumed to be time-varying, a common approach is to introduce a set of static baseline covariates, $V$ (Robins et al, 1999). The baseline covariate $V$ denotes the static feature (such as a patient's gender or age) that will influence both the time-varying covariates $X$ and the outcome $Y$. We can then draw counterfactual samples from a specific sub-population by conditioning on the values of the $V$. In this framework, we observe ($Y_t^i$, $\\overline{A}_t^i$, $\\overline{X}_t^i$, $V^i$), where $V \\in \\mathbb{R}^{\n    \\nu}$ is a static baseline variable that varies by individual.  Accordingly, the generator will have an additional input: \n$ g\\_{\\theta}(z, \\overline{a},v): \\mathbb{R}^r \\times \\mathcal{A}^d \\times \\mathbb{R}^{\\nu} \\rightarrow \\mathcal{Y}$ , and the IPTW weights will become $ w\\_\\phi(\\overline{a},\\overline{x},v) = \\frac{1}{\\prod\\_{\\tau=t-d+1}^{t} f\\_\\phi(a\\_{\\tau}|\\overline{a}\\_{\\tau-1},\\overline{x}\\_{\\tau},v)}$.   Correspondingly, the objective in Proposition 1 will become $\\mathbb{E}\\_{v} ~\\mathbb{E}\\_{\\overline{a}} ~\\left[\\mathbb{E}\\_{y \\sim f\\_{\\overline{a},v}} ~\\log f\\_\\theta(y|\\overline{a},v)\\right] \\approx \\frac{1}{N}\\sum\\_{(y,\\overline{a},\\overline{x},v) \\in \\mathcal{D}}w\\_\\phi(\\overline{a},\\overline{x},v) \\log f\\_\\theta(y|\\overline{a},v).$ \n\n We have conducted additional experiments using the fully synthetic dataset, where the baseline variable, $V$, was divided into two groups. The $V$ was uniformly drawn from $[-1,0]$ in the first group and from $[0,1]$ in the second group. We then looked at the performance of the generative samples corresponding to two sub-groups. We included the results in **Appendix I** (Table 4, Fig.11, and Fig.12) of the revised manuscript.  Our method (MSCVAE) still consistently outperforms other baseline methods in the simplified results below (Wasserstein distance, smaller the better):\n\n- $V\\in[-1,0]$\n\n|         | d=1  | d=3  |  d=5  |\n| ----------- | ----------- | ----------- |----------- |\n| MSM+NN      |   0.408    |  0.449   |  0.368 |\n| KDE               |      0.201 |  0.562 |  0.564  |\n| Plugin+KDE   |        0.117    |      0.134      |   0.196      |\n| G-Net             |        0.431        |      0.823       |   0.843    |\n| CVAE             |       0.240          |     0.571       |   0.585   |\n| MSCVAE        |        0.051         |      0.083      |    0.186   |\n\n- $V\\in[0,1]$\n\n|         | d=1  | d=3  |  d=5  |\n| ----------- | ----------- | ----------- |----------- |\n| MSM+NN      |   0.407    |  0.466  |  0.388 |\n| KDE               |      0.222 |  0.548 |  0.561  |\n| Plugin+KDE   |        0.121   |      0.109      |   0.182      |\n| G-Net             |        0.452       |      0.739       |   0.768    |\n| CVAE             |       0.258          |     0.565      |   0.591   |\n| MSCVAE        |        0.047         |      0.068      |    0.172   |"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700380287942,
                "cdate": 1700380287942,
                "tmdate": 1700380287942,
                "mdate": 1700380287942,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "2ChkRQEJXJ",
            "forum": "Io0Q37X5fP",
            "replyto": "Io0Q37X5fP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6428/Reviewer_iR6m"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6428/Reviewer_iR6m"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a framework that can be used to simulate counterfactual outcomes in temporal experiments. The proposed method is a combination of conditional variational autoencoder and inverse probability weighting."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The proposed framework is simple, easy to use, and accessible. Judging from the experiments, the performance of the proposed method seems to be good."
                },
                "weaknesses": {
                    "value": "- Proposition 1 doesn\u2019t make sense. How could $\\bar{a}$, a fixed value, be drawn from $\\mathcal{D}$? Why is it a sum instead of an average? Wouldn\u2019t the RHS of (4) be the same for all $\\bar{a}$ while the LHS is supposed to be different? And why is the index in (5) from $t-d$ instead of from $t-d+1$? In proof of proposition 1, where does the expectation over $\\bar{a}$ come from? I would be concerned if the authors actually used this formula in their experiments.\n\n- I don\u2019t seem to understand the comment in Remark 1 that doubly robust methods are less robust to model misspecification than IPW methods, and I cannot find relevant discussions in Appendix D as claimed. I'm curious about why the authors would think so.\n\n- One pivotal assumption is that d, the length of history dependence, is finite and known, in which case the IPW methods in a temporal experiment are only a trivial extension to IPW methods in a static experiment. Also, as d gets large, the variance of those IPW-style methods can easily blow up.\n\n- The only theoretical guarantee provided in the paper is that the weighted log likelihood is unbiased. In that sense, this is closer to treatment effect estimations where the estimand of interest is a single value, and it is very different from density estimations. Kennedy et al. (2023) (and some of the other papers mentioned by the authors) require stronger conditions simply because their goals are a lot harder. Since this paper is purely applied, I don\u2019t see how they are comparable.  \n\n- Related to the last point, I fail to see how the absence of a unified theory for doubly robust density approximation in longitudinal settings serves as a reason for not using DR estimators, given that the authors never estimated the density. When the goal is not density estimation, there have been a plethora of studies on variations of IPW and AIPW estimators in longitudinal settings, especially from the dynamic treatment regimes and reinforcement learning literature.\n\n- I find the notations occasionally confusing, and the authors are somewhat vague regarding the assumptions."
                },
                "questions": {
                    "value": "See weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6428/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6428/Reviewer_iR6m",
                        "ICLR.cc/2024/Conference/Submission6428/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6428/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698820388680,
            "cdate": 1698820388680,
            "tmdate": 1700667599915,
            "mdate": 1700667599915,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ordwiQDyxT",
                "forum": "Io0Q37X5fP",
                "replyto": "2ChkRQEJXJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6428/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6428/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the comments. We appreciate your input and regret any confusion that may have arisen if our methodology wasn\u2019t adequately elucidated. We would like to clarify that our generative framework aims to draw high-quality counterfactual outcomes, which can be viewed as an implicit distribution estimator, bypassing the need for direct density estimation. We want to emphasize that this objective differs drastically from the majority of the existing literature, which only focus on estimating the mean of the counterfactual distribution. Please see our point-by-point responses below.\n\n> How could $\\overline{a}$, a fixed value, be drawn from $\\mathcal{D}$? Wouldn\u2019t the RHS of (4) be the same for all $\\overline{a}$\n while the LHS is supposed to be different?\n\nWe thank the reviewer for pointing it out.  Our generator approximates the underlying counterfactual for any $\\overline{a}$,, so there should be an expectation over $\\overline{a}$, for the objective function (Equation 2):\n    $$\\hat{\\theta} \n    = argmin_{\\theta \\in \\Theta}~\\mathbb{E}_{\\overline{a}} ~\\left[D_f(f\\_{\\overline{a}}, f\\_\\theta(\\cdot|\\overline{a})) \\right],$$\n\nwhere $D$ represents the distributional distance between $f\\_{\\overline{a}}$ (true counterfactual distribution) and $f\\_\\theta$ (the proxy conditional distribution represented by our proposed counterfactual generator $g\\_\\theta$), such as KL divergence. The resulting weighted loss function in Proposition 1 becomes:\n\n$$\n\\mathbb{E}\\_{\\overline{a}} [\\mathbb{E}\\_{y \\sim f\\_{\\overline{a}}} ~\\log f\\_\\theta(y|\\overline{a})] \\approx\n        \\frac{1}{N}\\sum\\_{(y,\\overline{a},\\overline{x}) \\in \\mathcal{D}}w\\_\\phi(\\overline{a},\\overline{x}) \\log f\\_\\theta(y|\\overline{a})\n$$\n\n> Why is it a sum instead of an average? \n\n We note that, in Proposition 1, we used the sum for simplicity, which is numerically equivalent to the average in practice as we fixed the batch size in our training.\n\n> And why is the index in (5) from $t-d$ instead of from $t-d-1$? \n\n  The index in (5) should be from $t-d+1$ instead of $t-d$, which is a typo.  We have fixed in the revised paper.\n\n>  Where does the expectation over $\\overline{a}$ come from? \n\nThe$\\overline{a}$in the proof for Proposition 1 is due to that we were taking an expectation over $\\overline{a}$  (as noted above). We have modified our notations in the revised manuscript. \n\n> I don\u2019t seem to understand the comment in Remark 1 ...\n\nWe would like to clarify that we did not suggest that the DR method lacks robustness under model misspecification than IPTW methods. In Remark 1, we intended to convey that it was challenging to extend our IPTW framework to a DR method. This is because in doing so, we need to augment the IPTW estimator with an outcome model for approximating the counterfactual distribution.  Such an extension would require accurately approximating the conditional outcome distribution $f(Y_t|\\overline{X}_t,\\overline{A}_t)$ and the conditional covariate distribution $f(X_t|\\overline{X}\\_{t-1},\\overline{A}\\_{t-1})$. This becomes particularly challenging when $Y$ is high-dimensional, a difficulty that is further exacerbated in the time-varying case with the need to accurately approximate $f(X_t|\\overline{X}\\_{t-1},\\overline{A}\\_{t-1})$. The G-Net is the only outcome-based method known to us that addresses such problem, and we have therefore included it as a baseline in our study. Our analysis revealed that G-Net's performance is suboptimal due to the aforementioned challenges, leading us to opt for the IPTW-only framework. We have clarified these points in the Appendix E of the revised paper.\n\nFurthermore, we would like to emphasize our main contribution is to use a generative model to draw high-quality counterfactual samples that follow the underlying counterfactual distribution. We opted for IPTW due to its seamless integration with our generative framework (the weighted loss in Proposition 1) and suitability for the high-d time-varying density approximation (it's easier to estimate the binary propensity model).  \n\n> One pivotal assumption is that d, the length of history dependence, is finite and known...\n\n\n   In line with established practices in longitudinal causal inference, as referenced in works like (Robins et al, 1994; Lim et al, 2018; Bica et al, 2020; Li et al, 2021; Bica et al 2021), we selected $d$ based on our pre-existing understanding of the data generation process. This approach is validated by our numerical findings, proving to be an effective method. For instance, in our COVID-19 studies, we set $d=3$ following insights from epidemiological research, which indicates that a mask mandate typically requires two to three weeks to become effective in a population."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700381258145,
                "cdate": 1700381258145,
                "tmdate": 1700381258145,
                "mdate": 1700381258145,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WOOuAkpBbo",
                "forum": "Io0Q37X5fP",
                "replyto": "hyZTTxem33",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6428/Reviewer_iR6m"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6428/Reviewer_iR6m"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for answering my questions and addressing some of my comments. A few things:\n\n- Proposition 1 now looks a lot better with all those typos fixed. Nevertheless, proof of proposition 1 still seems to be wrong. The authors somehow didn't condition on $\\bar a$ so there are steps where they took expectation over $\\bar a$ twice. Also, I found the proof incredibly hard to read as a conventional unbiasedness proof of an IPW estimator, for that the authors basically used $f(\\cdot)$ to denote everything.\n\n- I never said the authors didn't attempt to estimate the distribution. Although the authors aim to estimate the distribution, they only show that the log-likelihood objective, which appears to me to be a single value, is identifiable and can be estimated unbiasedly. Thus, if the authors do believe unbiased estimation of the log-likelihood suffices for estimating distribution, then the DR estimator, being unbiased as well, would also be applicable, and that is why I think the absence of a unified theory for doubly robust density approximation doesn't seem to be a valid reason. However, I'm not suggesting that the authors must use a DR estimator or provide theoretical guarantees. It is just my opinion that it might be easier to simply acknowledge limitations rather than make claims on methods that might not be fully understood."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700667573782,
                "cdate": 1700667573782,
                "tmdate": 1700667573782,
                "mdate": 1700667573782,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FpPhOwburh",
                "forum": "Io0Q37X5fP",
                "replyto": "y4KCDUEZfl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6428/Reviewer_iR6m"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6428/Reviewer_iR6m"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks. If the authors hope to use $\\bar{A}$ and $\\bar{a}$ to distinguish between a random variable and a constant, then how could you take expectation over a constant?"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6428/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700726817427,
                "cdate": 1700726817427,
                "tmdate": 1700726817427,
                "mdate": 1700726817427,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]