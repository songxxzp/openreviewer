[
    {
        "title": "A Probabilistic Framework for Modular Continual Learning"
    },
    {
        "review": {
            "id": "sRhh0qsglO",
            "forum": "MVe2dnWPCu",
            "replyto": "MVe2dnWPCu",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6487/Reviewer_REkX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6487/Reviewer_REkX"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose PICLE a probabilistic approach to spawn, compose and train a series of neural modules for solving continual and transfer learning tasks with compositionality. The proposed method considers two separate scenarios:  perceptual transfer, where the input space is the same for all tasks and the output function has to be adapted; and latent transfer, where the output functions have to be reused on new input spaces. For the first scenario, the authors approximate the input distribution of each module with the combination of a low-rank gaussian distribution and the accuracy as the prior. The final path is found by greedy search. For the second scenario, the authors use Bayesian optimization and a Gaussian process to approximate the accuracy of unseen module combinations. One of the main advantages of the proposed approach is that it scales with respect to the number of tasks sinc it evaluates a constant number of compositions and trains a network with a fixed size for each task. The proposed approach achieves state of the art perfomance on CTrL as well as on a new compositional version of CTrL named BELL by the authors."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Originality\n=======\n* The probabilistic modular framework proposed in this work is novel to the best of my knowledge.\n* The authors introduce BELL, a new compositional version of CTrL along with this work.\n\nQuality\n=====\n* The proposed approach is sound.\n* The low-rank approximation of the input as a proxy for the likelihood is simple yet effective.\n* The appendix contains details to ensure reproducibility and the authors promise to release the code.\n* The authors provide Algorithms.\n* The authors discuss the limitations of their approach.\n* Ablations can be found in the Appendix.\n\nClarity\n=====\n* The text is well-written.\n* I found Figure 3 and Table 4 very useful in order to understand the difference between PICLE and other algorithms.\n* The authors provide details about hyperparameters in the Appendix.\n\nSignificance\n=========\n* Continual learning is a challenging problem and I believe this work is an interesting step towards a modular solution\n* PICLE achieves a slight improvement on CTrL and greater improvement on some of the BELL tasks.\n* BELL complements CTrL with few-shot and compositional tasks."
                },
                "weaknesses": {
                    "value": "Originality\n=======\n* LMC also introduced a benchmark for compositional generalization based on colored-mnist that is not mentioned when introducing BELL.\n* Moreover the authors claim not to be able to obtain acceptable results with LMC on BELL despite their best efforts, while this is possible, they could have tried to run PICLE on compositional color MNIST task introduced in LMC.\n\nClarity\n=====\n* This work introduces a method and a benchmark, however most information about the benchmark is left in the appendix. I suggest providing simpler versions of the Algorithms in the main text, and to use the space to make the paper more self-contained (less dependent on the Appendix).\n\nSignificance\n=========\n* There exists a vast number of continual learning benchmarks. Although they enrich the field, they also dilute the efforts of the research community. Thus I suggest the authors to include some more motivation on why BELL is needed and why researchers should use it rather than other benchmarks or tasks.\n\nMinor\n====\n* Page 4: Accordignly\n* Appendix I: pre-traiend"
                },
                "questions": {
                    "value": "* Would it be possible to run PICLE on compositional color MNIST to be able to compare with LMC (see LMC paper)? (It is ok if you do not have enough time / compute resources to do it). \n* Could you include some more motivation on why BELL is needed and why researchers should use it rather than other benchmarks or tasks.\n* Why $\\{\\pi}^*$ is not used in Algorithm 2?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6487/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6487/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6487/Reviewer_REkX"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6487/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698005175005,
            "cdate": 1698005175005,
            "tmdate": 1700383365566,
            "mdate": 1700383365566,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "a91nnknLMA",
                "forum": "MVe2dnWPCu",
                "replyto": "sRhh0qsglO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6487/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6487/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their detailed feedback.\n\n**q2: Could you include some more motivation on why BELL is needed and why researchers should use it rather than other benchmarks or tasks.**\n\nOther CL benchmarks, such as split-CIFAR and CLEAR[2], can differ by the continual learning setup they assume (e.g. class-incremental, domain-incremental etc.). As a result, their sequences implicitly simultaneously evaluate a subset of CL properties, e.g. plasticity, stability and perceptual transfer, which are all summarized by a single number --- the final average accuracy. This makes it difficult to determine which of these properties is lacking from a CL algorithm.\n\nIt is important that the benchmarks which we use be able to measure whether algorithms have specific CL properties, like those we list in Table 4. This would guide future research in the field by making the desiderata explicit and facilitating the comparison of different CL algorithms against it.\n\nCTrL [1] is a step in this direction. However, it evaluates perceptual transfer between two problems by shuffling the original problem\u2019s labels, and it evaluates latent transfer between MNIST images with two different background colors. As such, CTrL cannot evaluate perceptual and latent transfer between disparate tasks and input domains. \\\nBELL is a further step in that direction, which addresses CTrL\u2019s shortcomings by creating sequences of compositional problems. The problems\u2019 compositionality allows us to create sequences which evaluate perceptual and latent transfer across disparate tasks and input domains. It also allows us to create more challenging sequences for evaluating perceptual transfer --- S^out* and S^out**. BELL also introduces new sequences which evaluate new CL properties --- S^few which evaluates few-shot transfer and S^sp which evaluates latent transfer across different input spaces.\n\nOverall, BELL should be used by researchers in order to diagnose the CL properties of a CL algorithm, which would improve our ability to compare different approaches.\n\n**wC, wS: Making the paper more self-contained, incorporating additional motivation for using BELL** \n\nThank you for the suggestion, we will add more information and motivation about the benchmark suite to the main text.\n\n**wO1: LMC also introduced a benchmark for compositional generalization based on colored-mnist that is not mentioned when introducing BELL.**\n\nThank you for pointing this out, we will change the text to mention the LMC sequence for compositional generalization.\n\nLMC introduced a sequence of tasks for evaluating compositional generalization. In it, each problem is derived from MNIST and is defined by one background-foreground color selection and one MNIST label pair. This leads to a limited variety between problems -- input domains are always somewhat similar as they all use MNIST digits, and tasks are restricted to be distinguishing between MNIST classes.\n\nThis sequence appears to be the most similar to BELL\u2019s S^few which evaluates a model\u2019s ability to achieve few-shot transfer by recomposing previous knowledge, with S^few involving disparate input domains and output tasks.\n\n**wO2, q1: Running PICLE on LMC's compositional color MNIST.**\n\nWe agree that these results would be nice to have. It's unlikely that we will have time to get these results by the end of the discussion period, but we will try and report back if we manage.\n\n**q3: Why is $\\mathbf{\\pi}^\\*$ not used in Algorithm 2**\n\nIn Algorithm 2, $\\mathbf{\\pi}^\\*$ is the given list of previous solutions. Our search through PT paths does not need it, which is reflected in it being unused in Algorithm 2. We currently have $\\mathbf{\\pi}^\\*$ as an input in order to keep the inputs to Algorithms 2 and 3 the same. However, we now appreciate that this can cause confusion and will remove $\\mathbf{\\pi}^\\*$ from the inputs of Algorithm 2.\n\nReferences:\\\n[1] Veniat, T., Denoyer, L. and Ranzato, M.A., 2020. Efficient continual learning with modular networks and task-driven priors. arXiv preprint arXiv:2012.12631.\\\n[2] Lin, Z., Shi, J., Pathak, D. and Ramanan, D., 2021, August. The clear benchmark: Continual learning on real-world imagery. In Thirty-fifth conference on neural information processing systems datasets and benchmarks track (round 2)."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6487/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700094444647,
                "cdate": 1700094444647,
                "tmdate": 1700094444647,
                "mdate": 1700094444647,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "q9iWx3nzET",
                "forum": "MVe2dnWPCu",
                "replyto": "sRhh0qsglO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6487/Reviewer_REkX"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6487/Reviewer_REkX"
                ],
                "content": {
                    "title": {
                        "value": "Response to rebuttal"
                    },
                    "comment": {
                        "value": "Thank you for your responses. After reading them and those to other reviewers I have decided to raise my score to 8."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6487/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700383329335,
                "cdate": 1700383329335,
                "tmdate": 1700383378648,
                "mdate": 1700383378648,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "o5XbRQa3Zp",
            "forum": "MVe2dnWPCu",
            "replyto": "MVe2dnWPCu",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6487/Reviewer_K341"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6487/Reviewer_K341"
            ],
            "content": {
                "summary": {
                    "value": "The work proposes a probabilistic modeling approach to efficiently search for the best-fit module composition out of the large discrete space of possible compositions of the modules in continual learning. Depending upon the similarity of the input distributions with that of a previous problem, two variants of the probabilistic model have been proposed: one for perceptual transfer where the prior uses the original accuracy of pre-trained modules to order these, and the other for latent transfer where the prior specifies that pre-trained modules in a path have been used together to solve a previous problem."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Good motivation, presentation, and writing. The equations have been explained well.\n- The idea of using the validation accuracy for a path as the proxy for its fitness is simple and elegant.\n- The limitations of the proposed method have been elaborated well.\n- The reported evaluation metrics are rigorous."
                },
                "weaknesses": {
                    "value": "Please see the questions."
                },
                "questions": {
                    "value": "- On page 3, the authors mention their strategy is based on a generative model of the input x. How is the generative quality of the proposed method quantitatively? Some further evaluation of the proposed method using metrics like ECE can thus be more insightful.\n\n- While I am not very familiar with the up-to-date modular continual learning literature, the baselines in Tables 1-2 look classic to me. Can the authors comment on comparing with more recent works?\n\n- Can the authors compare the computational overhead of their method against the baselines?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6487/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6487/Reviewer_K341",
                        "ICLR.cc/2024/Conference/Submission6487/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6487/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698648370840,
            "cdate": 1698648370840,
            "tmdate": 1700356597121,
            "mdate": 1700356597121,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oyuFxnxCc3",
                "forum": "MVe2dnWPCu",
                "replyto": "o5XbRQa3Zp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6487/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6487/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their feedback. \n\n**q1: Quantitative evaluation of the generative quality of the proposed method.**\n\nFor our purposes, the employed generative model needs to be useful for distinguishing between inputs sampled from different distributions. As a result, we have not explored the generative quality of the samples. Given our use of efficient Gaussian approximations, we expect that it is poor. Instead, in Appendix I, we have provided a quantitative evaluation of our method\u2019s ability to distinguish between different input domains. The results indicate that using random projections improves the discriminative capabilities of our generative model.\n\n**q2: Baselines in Tables 1-2  appear classic. Can the authors comment on comparing with more recent works?**\n\nOur work aims to improve modular CL methods. Therefore, we compare to the latest state-of-the-art modular CL algorithms, namely: MNTDP-D [1] (2020) and LMC [2] (2021). We also compare to an additional modular CL algorithm -- HOUDINI [3].\nFor completeness, as done in previous modular CL work [1, 2], we use O-EWC [4, 5] as a classic regularization-based CL algorithm, and ER [6] as a replay-based method, which was shown to have competitive performance despite its simplicity.\n\nTables 1-2 do not report the performance of LMC since it performed poorly, despite our efforts to adjust it to the BELL benchmark suite.\n\n**q3: Can the authors compare the computational overhead of their method against the baselines?**\n\nFigure 3a of our submission compares the computation demand of PICLE to those of the baselines, evaluated in FLOPs. It can be seen that since PICLE uses slightly more resources than MNTDP-D since it considers a larger search space. However, it can also be observed that PICLE\u2019s computational requirements scale well with the number of solve problems.\n\nReferences: \\\n[1] Veniat, T., Denoyer, L. and Ranzato, M.A., 2020. Efficient continual learning with modular networks and task-driven priors. arXiv preprint arXiv:2012.12631. \\\n[2] Ostapenko, O., Rodriguez, P., Caccia, M. and Charlin, L., 2021. Continual learning via local module composition. Advances in Neural Information Processing Systems, 34, pp.30298-30312. \\\n[3] Valkov, L., Chaudhari, D., Srivastava, A., Sutton, C. and Chaudhuri, S., 2018. Houdini: Lifelong learning as program synthesis. Advances in neural information processing systems, 31. \\\n[4] Schwarz, J., Czarnecki, W., Luketina, J., Grabska-Barwinska, A., Teh, Y.W., Pascanu, R. and Hadsell, R., 2018, July. Progress & compress: A scalable framework for continual learning. In International conference on machine learning (pp. 4528-4537). PMLR. \\\n[5] Chaudhry, A., Dokania, P.K., Ajanthan, T. and Torr, P.H., 2018. Riemannian walk for incremental learning: Understanding forgetting and intransigence. In Proceedings of the European conference on computer vision (ECCV) (pp. 532-547). \\\n[6] Chaudhry, A., Rohrbach, M., Elhoseiny, M., Ajanthan, T., Dokania, P.K., Torr, P.H. and Ranzato, M.A., 2019. On tiny episodic memories in continual learning. arXiv preprint arXiv:1902.10486."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6487/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700092676041,
                "cdate": 1700092676041,
                "tmdate": 1700092676041,
                "mdate": 1700092676041,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dJOpiW35bW",
                "forum": "MVe2dnWPCu",
                "replyto": "oyuFxnxCc3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6487/Reviewer_K341"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6487/Reviewer_K341"
                ],
                "content": {
                    "comment": {
                        "value": "The authors have addressed the majority of my concerns. I am thus raising my score. Good work. I have no further questions."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6487/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700356781831,
                "cdate": 1700356781831,
                "tmdate": 1700356781831,
                "mdate": 1700356781831,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "IKJUSZOqiu",
            "forum": "MVe2dnWPCu",
            "replyto": "MVe2dnWPCu",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6487/Reviewer_g7xb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6487/Reviewer_g7xb"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces PICLE, a scalable modular continual learning algorithm that addresses key challenges in the field. PICLE is task-aware and optimizes for different types of transfer learning, such as perceptual, few-shot, and latent transfer. Utilizing a probabilistic search method, it efficiently approximates the fitness of different module compositions, significantly reducing training requirements. The algorithm outperforms existing state-of-the-art solutions, demonstrating its efficacy on the popular CTrL benchmark suite and a new extension called BELL."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Modularity in continual learning is highly promising, offering a good balance between scalability and the ability to transfer knowledge across tasks without undue interference.\n  \n2. The key challenge in modular approaches is the exponentially increasing search space for module combinations, particularly as the number of layers grows. PICLE addresses this scalability issue effectively, allowing for both perceptual and latent transfer, which makes it a standout in the field.\n  \n3. The paper's empirical study is both comprehensive and well-executed, adding robustness to its claims."
                },
                "weaknesses": {
                    "value": "Minor weaknesses, if addressed during the rebuttal, I will keep my score at an 8:\n\n1. The table in the paper lacks uncertainty metrics such as standard deviation. This omission should be addressed to enhance the study's reliability. Additionally, for readability purposes, it would be better to show the percentages only up to three digits instead of four (e.g., XX.XX% should be changed to XX.X%).\n\n2. The paper should clearly state that the PICLE method is task-aware, which is an important limitation. Ideally, there would be a column in Table 4 that discusses task-agnosticism, a feature that another algorithm, LMC, is capable of.\n\n3. The concept of using a generative model to approximate latent activations and assume local independence from one layer to the next, as introduced in Section 4, was initially proposed in the LMC paper. The authors should give credit to this paper and clarify how their methods differ from those originally proposed in the LMC paper."
                },
                "questions": {
                    "value": "None"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6487/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698848329539,
            "cdate": 1698848329539,
            "tmdate": 1699636726486,
            "mdate": 1699636726486,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "sATUlsT9Mw",
                "forum": "MVe2dnWPCu",
                "replyto": "IKJUSZOqiu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6487/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6487/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their feedback. \n\n**w1a: Lack of uncertainty metrics in the table.**\n\nAs the performance of the different algorithms on the short sequences of the CTrL benchmark is similar, we added the standard deviations of the results shown in Table 3. This can be found in Table 6, Appendix K.1. Does this address your concern?\n\n**w1b: Show percentages for up to 1 decimal point.**\n\nWe agree that this would improve the paper\u2019s readability and will make the changes.\n\n**w2: The paper should clearly state that the PICLE method is task-aware**\n\nWe agree that this is an important property, which provides an interesting distinction between the algorithms. Therefore, we will mention it and add it as a row in Table 4.\n\n\n**w3: Credit to and better distinction from LMC.**\n\nWe have credited LMC with a similar approach for perceptual and few-shot transfer in the Related Work section, while also outlining the differences. However, we agree with the wording proposed by the reviewer, and will also add it to Section 4 for better visibility. Moreover, we acknowledge that the conceptual differences can be better presented and will amend the text accordingly.\n\nThe main conceptual difference is that while LMC also uses a module-specific generative model, PICLE unites the generative model for each layer using a single probabilistic model, which brings numerous advantages. First, our probabilistic model allows us to define a prior over the choice of modules. Second, by changing the probabilistic model, we can incorporate further assumptions in a principled way, for example, we can put a prior over the choice of pre-trained modules for multiple layers, rather than layer-specific priors.\nThird, the probabilistic model allows us to compute the posterior over the choice of pre-trained module for each layer collectively, rather than individually.\n\nThe main implementation difference is that PICLE utilizes a different approximation of a module\u2019s input distribution, using orders of magnitude fewer extra parameters per pre-trained module than LMC."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6487/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700092165273,
                "cdate": 1700092165273,
                "tmdate": 1700092165273,
                "mdate": 1700092165273,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "DEDRYTNzE5",
            "forum": "MVe2dnWPCu",
            "replyto": "MVe2dnWPCu",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6487/Reviewer_gkN4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6487/Reviewer_gkN4"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses the modular continual learning setting.  They introduce a probabilistic model to determine a distribution over paths for perceptual transfer.  This can be interpreted as selecting modules based on how similar the current features at that layer are to the modules' input distribution.  For latent transfer, they have a probabalistic model based on the idea that suffixes similar in L2 distance should have similar performance.  This modeling allows predicting the validation performance of a path without training.  Due to the modeling, they only need to evaluate a number of paths which grows linearly with the depth L.  Their method outperforms the other methods marginally on average, while in some cases demonstrating significant boosts, e.g. few-shot transfer."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The probabalistic models introduced are simple and make sense.  Using such modeling to avoid the expensive counterfactual of evaluating a path is a logical approach.\n* The paper is well written and I found the appendix helpful.\n* The evaluations seem consistent with prior works"
                },
                "weaknesses": {
                    "value": "* The quantitative advantage over MNTDP-D in accuracy is marginal on average ~1-3%\n* The method requires slightly more FLOPs than MNTDP-D (Figure 3 (a))\n\nOverall I am voting to accept this paper due to the conceptual contribution, however the quantitative results seem marginal to me, and thus I am not voting for a stronger accept."
                },
                "questions": {
                    "value": "**Table 1:** Why are the numbers for MNTDP-D and PICL forward transfer so similar?\n\nTypo: \u201cThe CL algorithm should be able to \u201dremember\u201d previous problems\u201c (backwards quotation) \n\n**Algorithm 3:** Bold lambda on right side of line 5\n\n\u201cThis search results in the most relevant previous solution $\\pi'$. Finally, in lines 11-14, we evaluate NT paths created by transferring a different number of the last $\\ell \\in \\\\{\\ell_{min} + 1, ..., L \u2212 1\\\\}$ layers of $\\pi'$, to see if re-using more layers leads to further improvement\u201d. (do you mean $\\ell \\in \\\\{2, \\ldots L - 1\\\\}$?  That's what the code appears to be searching over"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6487/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698906710354,
            "cdate": 1698906710354,
            "tmdate": 1699636726386,
            "mdate": 1699636726386,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9byudzdBR5",
                "forum": "MVe2dnWPCu",
                "replyto": "DEDRYTNzE5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6487/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6487/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their feedback. We will correct the reported typos.\n\n## Comparing MNTDP-D and PICLE:\n\nWe would argue that this is a case where looking at the average accuracy across tasks is misleading. Table 4 and Appendix H of our submission list a set of desirable properties for CL methods. Each sequence from our experiments evaluates a different CL property. Our argument is that MNTDP-D and PICLE share many desirable properties (see Table 4), so they will have similar accuracy on sequences that test those properties. But PICLE has a few desirable properties that MNTDP-D does not.\n\nAs a result, MNTDP-D and PICLE are expected to and do perform similarly on the sequences which evaluate: perceptual transfer (S^-, S^out, S^out*), plasticity (S^pl), Stability (S^+). We note that, PICLE is able to demonstrate perceptual transfer on S^out**, Table 1 while MNTDP-D fails to do so, leading to PICLE achieving **+10.3** higher transfer on the last problem.\n\nHowever, PICLE is expected to and does significantly outperform MNTDP-D on few-shot  transfer and latent transfer. Since the short sequences were designed to evaluate different transfer learning properties by an algorithm\u2019s performance on the last problem, we consider the amount of transfer to the last problem. For few-shot transfer, PICLE achieves **+34.65** higher transfer (S^few, Table 1) than MNTDP. For latent transfer, PICLE also demonstrates much higher transfer: **+12.58** (S^in, Table 2), **+23.65** (S^sp, Table 2), **+16.89** (S^in, Table 3).\n\nWe discuss this in Section 6, however, thanks to your comments, we will change the text to state this more clearly.\n\n**w1: The quantitative advantage over MNTDP-D in accuracy is marginal on average ~1-3% \\\nq1: \u201cWhy are the numbers for MNTDP-D and PICL forward transfer so similar?\u201d**\n\nSince PICLE and MNTDP-D share many CL properties, apart from few-shot transfer and latent transfer, their performance --- including accuracy and forward transfer --- on the short sequences is similar, apart from on S^few, S^in, S^sp.\n\nIn Table 1, the accuracy is averaged over mostly shared CL properties (apart from few-shot transfer). PICLE\u2019s advantage is only apparent by its superior performance on the last problem of S^few and S^out**. As a result, the average accuracy in Table 1 averages over 42 problems, while PICLE achieves significant improvement over MNTDP-D on 2 of them. This leads to the similar average accuracy which we observe. Similarly, the short sequences of CTrL mostly evaluate CL properties which are shared between MNTDP-D and PICLE, leading to PICLE outperforming MNTDP-D only on the last problem of S^in, and in turn leading similar average accuracies in Table 3.\n\nPICLE\u2019s advantage over MNTDP-D is that it can achieve few-shot and latent transfer. Overall, PICLE achieves much higher transfer on the last problem than MNTDP-D on: perceptual transfer (S^out**, Table 1, **+10.3**), few-shot transfer (S^few, Table 1, **+34.65**), latent transfer (S^in, Table 2, **+12.58**), (S^sp, Table2, **+23,65**), (S^in, Table 3, **+16,89**).\n\n**w2: The method requires slightly more FLOPs than MNTDP-D (Figure 3 (a))**\n\nThis is correct. Figure 3(a) shows that PICLE requires slightly more FLOPs, while considering a much bigger bigger search space. The figure also shows that the computational demands of both PICLE and MNTDP-D scale well with the number of problems.\n\n## Other questions:\n**q2: \u201cAlgorithm 3 - Do you mean $\\ell \\in \\{ 2, ..., L-1 \\} $?\u201d**\n\nThe $\\ell$ defined on line 11 of Algorithm 3 refers to the index of the first pre-trained module. On line 12 we use it to extract the pre-trained modules $\\pi\u2019[\\ell : L]$. For $\\ell = \\ell_{min}$ , the length of the pre-trained suffix $\\pi\u2019[\\ell_{min} : L]$ is $\\ell_{min} + 1$. And for $\\ell = 2$, the length of the pre-trained suffix $\\pi\u2019[2 : L]$ is $L-1$. Therefore, we indeed attempt to transfer ${\\ell_{min}+1, ..., L-1}$ pre-trained layers.\nHowever, thanks to your comment, we now see that it is confusing to use $\\ell$ inside the text to denote length while simultaneously using it in Algorithm 3 to denote an index. We will adjust the text accordingly."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6487/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700091168342,
                "cdate": 1700091168342,
                "tmdate": 1700091168342,
                "mdate": 1700091168342,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kvPY3KzQhV",
                "forum": "MVe2dnWPCu",
                "replyto": "9byudzdBR5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6487/Reviewer_gkN4"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6487/Reviewer_gkN4"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors part 1"
                    },
                    "comment": {
                        "value": "I thank the authors for their response and clarification.  I maintain my recommendation to accept this work."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6487/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700610556279,
                "cdate": 1700610556279,
                "tmdate": 1700610556279,
                "mdate": 1700610556279,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]