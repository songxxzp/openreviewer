[
    {
        "title": "Learning to Explore for Stochastic Gradient MCMC"
    },
    {
        "review": {
            "id": "Wc1QyRk1MB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8896/Reviewer_Stdr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8896/Reviewer_Stdr"
            ],
            "forum": "uhR7aYuf0i",
            "replyto": "uhR7aYuf0i",
            "content": {
                "summary": {
                    "value": "To encourage exploration, the authors proposed the \"learning to explore approach\" based on meta learning. The key idea is to learn the gradients of the kinetic energy  for SGMCMC update steps through two neural networks; the authors propose to train the networks on one tasks and then generalizes them to future tasks. This submission simplifies the work of meta-learning (Gong et al., 2018), which proposes to make D(z) and Q(z) as simple as possible."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The method starts from a practical viewpoint instead of physical intuitions to tackle the local trap problem suffered by the standard stochastic gradient MCMC methods. The idea of learning some key hyperparameters using parametrized networks based on meta learning may enjoy appealing implementation advantages.\n\nThe experimental evaluations, such as convergence analysis, loss surface demo, evaluation metrics (ACC, NLL, ECE), appear to be comprehensive in deep learning experiments."
                },
                "weaknesses": {
                    "value": "(a) Underdamped Langevin/ Hamiltonian Monte Carlo is a good method for accelerating the overdamped alternative in terms of mixing rates. However, I believe it is far from explorative enough compared to other baseline methods, such as the replica-exchange based approaches [1,2]. I am not fully convinced if optimizing the kinetic energy is sufficient enough to solve the exploration problem. Your model input is $(\\theta, r)$, I am not even sure it is really learning anything useful.\n\n[1] Non-convex Learning via Replica Exchange Stochastic Gradient MCMC. ICML'20\n[2] Non-reversible Parallel Tempering for Deep Posterior Approximation. AAAI'23.\n\n(b) Empirically, your baselines such as deep ensemble and cyclical SGMCMC are pretty weak in terms of multi-modal simulations (although their optimization performance is acceptable)."
                },
                "questions": {
                    "value": "I am interested to see how your algorithm is compared to [2] or [3].\n\n[2] Non-reversible Parallel Tempering for Deep Posterior Approximation. AAAI'23.\n\n[3] Interacting Contour Stochastic Gradient Langevin Dynamics. ICLR'22\n\n**************\n*After rebuttal, I slightly increased my ratings from 3 to 5.*"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8896/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8896/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8896/Reviewer_Stdr"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8896/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697139020009,
            "cdate": 1697139020009,
            "tmdate": 1700672193869,
            "mdate": 1700672193869,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "eiHBTj524Z",
                "forum": "uhR7aYuf0i",
                "replyto": "Wc1QyRk1MB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8896/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8896/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for constructive comments that can improve the quality of our paper. We would like to answer your comments.\n\n> Underdamped Langevin/ Hamiltonian Monte Carlo is a good method for accelerating the overdamped alternative in terms of mixing rates. However, I believe it is far from explorative enough compared to other baseline methods, such as the replica-exchange based approaches [1,2]. I am not fully convinced if optimizing the kinetic energy is sufficient enough to solve the exploration problem. Your model input is (\u03b8,r), I am not even sure it is really learning anything useful.\n\nFirstly, we develop our method to enhance the exploration of single-chain MCMC from the meta-training stage. Considering the scale of modern machine learning, improving the exploration of single-chain methods is advantageous due to the significant memory costs associated with parallel chain-based approaches. Therefore, directly comparing the exploration of replica-exchange based methods that use multiple independent chains with our method seems unfair for our method. However, following your suggestion, we are now implementing the method proposed in [3]. We will upload the comparison with [3] as soon as experiments are completed.\n\nWe have added the advantages of parameterizing kinetic energy term in overall response and Appendix A.1. Also, our learned sampler takes not only $(\\theta,r)$ as inputs but also takes the gradient and moving average of the gradient which encode the posterior information as inputs. We explained details for inputs of neural networks in section 3.1 and Appendix E.1.\n\n> Empirically, your baselines such as deep ensemble and cyclical SGMCMC are pretty weak in terms of multi-modal simulations (although their optimization performance is acceptable).\n\nDE is known as one of the most effective ensemble methods, including Bayesian methods, in capturing both weight diversity and functional diversity [4]. While it is difficult to say DE is good at simulating BNNs posterior as it is a non-Bayesian method, it is a powerful approach at least in capturing multi-modality in the function and weight space. Also, CSGMCMC are currently widely used by practitioners as a baseline for efficient simulation of BNNs posterior with a single chain which is deeply related to our method. But, comparing with other methods will also be interesting, we will upload the comparison with [3] as soon as experiments are completed.\n\n[1] Non-convex Learning via Replica Exchange Stochastic Gradient MCMC. ICML'20 \n\n[2] Non-reversible Parallel Tempering for Deep Posterior Approximation. AAAI'23.\n\n[3] Interacting Contour Stochastic Gradient Langevin Dynamics. ICLR'22\n\n[4] Ovadia, Yaniv, et al. \"Can you trust your model's uncertainty? evaluating predictive uncertainty under dataset shift.\" Advances in neural information processing systems 32 (2019)."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700192706885,
                "cdate": 1700192706885,
                "tmdate": 1700192706885,
                "mdate": 1700192706885,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "y7I5VCAhbJ",
                "forum": "uhR7aYuf0i",
                "replyto": "Wc1QyRk1MB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8896/Reviewer_Stdr"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8896/Reviewer_Stdr"
                ],
                "content": {
                    "title": {
                        "value": "Thank for discussing more exploration-related baselines"
                    },
                    "comment": {
                        "value": "**Deep Ensemble is a non-Bayesian method**\n\nI may respectfully disagree with this (although some debate exists) and I believe deep ensemble is also a Bayesian method. First, SGD is an approximate Bayesian method to capture one major mode [1]; second, deep ensemble uses different initialization to capture different modes, which is why I believe that the **exploration solely driven by different initialization may not be sufficient to tackle explorations**. Nevertheless, the straightforward advantage is that it is easy to implement, which is why it is so popular. But fundamentally it is not a principled method.\n\n[1] Stochastic Gradient Descent as Approximate Bayesian Inference. JMLR'17.\n\n**a single chain that is deeply related to our method**\n\nI understand why the authors didn't compare the multiple-chain baselines. However, in my experience, they are really crucial to address the exploration problem. In my limited experience in motivating explorations, how to appropriately set up different **learning rates** and **temperatures** is crucial (in theory and also well supported in practice) and more important than the rest of the factors, such as momentum, etc. So these references on simulated tempering (one chain version) and parallel tempering (multi-chain version) cannot be missing in any papers that aim to facilitate exploration.\n\n\n**Popularity is not the unique criterion as a baseline.**\n\nMany popular Github repos also work quite well, but they are not published as papers. **Popularity is not the first principle** to choose baselines in academic papers.\n\n**Summary**\n\nI will slightly increase my rating from 3 to 5 to thank the authors including one more baseline. \n\nI would suggest the authors include more relevant experiments to justify your work in your next revision. For example, instead of running so many large-scale experiments, I am actually more interested to see how your algorithm performs on the 25-mode 2D mixture distribution with unequal weights (figure 3 in [1]). If your algorithm can achieve similar performance without introducing too much cost, I will be more convinced if the algorithm is good or not. (I don't expect your algorithm to outperform replica-exchange.)\n\n[1] INTERACTING CONTOUR STOCHASTIC GRADIENT LANGEVIN DYNAMICS"
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700672116288,
                "cdate": 1700672116288,
                "tmdate": 1700672474366,
                "mdate": 1700672474366,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "k665haIQNp",
            "forum": "uhR7aYuf0i",
            "replyto": "uhR7aYuf0i",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8896/Reviewer_36ng"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8896/Reviewer_36ng"
            ],
            "content": {
                "summary": {
                    "value": "Unlike prior work, the authors propose a meta-learning strategy for SGHMC by learning the kinetic energy term. The authors show that the meta-learning the kinetic energy term is able to generalize as well as other competing methods, beyond the data distributions during meta-training. Such an approach leads to improved OOD detection, and the authors experimentally demonstrate the discovery of disconnected modes."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The authors take a different perspective to meta-learned SGMCMC where instead of the prior work which focused on meta-learning the dynamics matrix $D$ and curl matrix $Q$, they meta-learn the kinetic energy term.\n- The meta-learning procedure is designed to be operationally fairly simple, and can be relatively easily accommodated into existing SGMCMC pipelines."
                },
                "weaknesses": {
                    "value": "- I think the first and the biggest weakness of the work lies in the way it is framed. It seems that you are trying to compete with deep ensembles, and other SGMCMC variants. In fact, the message I get from the experimental results is that L2E is that it performs pretty much worse is most cases and at worse computational cost. But one could argue, the promise of the method is rather in the generalizability of the meta-learning procedure to unseen datasets. In a sense, it is pretraining for SGMCMC, which to me is the most interesting. Unfortunately, this is not how the authors position this paper.\n- The deliberate choice to not use data augmentations is a little concerning. I understand that it does not neatly fit into the Bayesian perspective, but when the same datasets perform significantly better with data augmentation (including with SGMCMC), it makes the comparisons incomplete. It would not be too hard to add data augmentations as is into the same training setup, and make the comparison on these datasets more fair to modern deep learning that achieves both better accuracy and better calibration properties.\n- The comparisons to DE and cSGMCMC looks to me a little unfair. L2E sees more variety of data by design, and one could then posit that the better OOD detection is not that surprising and simply a matter of having seen broader distributions are meta-train time. \n- It would be really helpful if we could have a toy illustration to build intuitions. For instance, meta-learning datasets sampled from 1-D sines and cosines. It would also reveal how the method behaves with \"in-between\" uncertainty, i.e. parts of the input space not in the training dataset. It would also help to see how the sampler behaves beyond the training dataset, when say you change to say a different function family of polynomials.\n\n### Minor\n\n- The choice of citation in the last paragraph on Page 1 \"Zhang et. al., 2020\" alone is odd. I would recommend citing all the other works.\n- The authors have made the choice of not having an explicit related work section. I think that is alright, but other work must be contextualized somewhere in the main text. Part of it is done in"
                },
                "questions": {
                    "value": "1. Could the authors clarify how L2E works at test time? Do you run the `InnerLoop` and take the samples after appropriate steps, thinning, and the compute the BMA?\n2. Equation 8 states that the loss is computed on validation data point. Is that true? Or during training this comes from the set of training distributions.\n3. The number of epochs as reported in Table 10 seem incredibly high for such a method to be scalable at all. Or is this supposed to be the number of gradient steps?\n4. How are the parameters initialized in the outer loop? Do you rely on default initializations for the family of architectures considered for meta-training? I wonder if such an approach would be unstable if the nature of networks considered is different.\n5. It seems like the choice to have different architectures for meta-training is challenging. What happens when the images have different number of channels? How is that currently handled? Are different sizes of images handled via resizing?\n6. I may have missed it, but I did not find the number of inner loop steps. Is it supposed to be the number of epochs?\n7. At test time, is the number of inner loop steps the same as train time? What happens when it is lesser? What happens when you keep it much larger?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8896/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698103669605,
            "cdate": 1698103669605,
            "tmdate": 1699637119481,
            "mdate": 1699637119481,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "sU4MmgeVtS",
                "forum": "uhR7aYuf0i",
                "replyto": "k665haIQNp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8896/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8896/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for constructive comments that can improve the quality of our paper. We would like to answer your comments.\n\n> I think the first and the biggest weakness of the work lies in the way it is framed. It seems that you are trying to compete with deep ensembles, and other SGMCMC variants. In fact, the message I get from the experimental results is that L2E is that it performs pretty much worse is most cases and at worse computational cost. But one could argue, the promise of the method is rather in the generalizability of the meta-learning procedure to unseen datasets. In a sense, it is pretraining for SGMCMC, which to me is the most interesting. Unfortunately, this is not how the authors position this paper.\n\nWould you elaborate why L2E performs pretty much worse than other methods? According to Table 1, we outperform other baselines in general. Only DE can match the predictive accuracy in some experiments and also L2E shows the best performance in OOD detection. Except for distribution-shift experiment where Bayesian methods can often fail [1], L2E shows competitive experiments with DE and outperforms CSGMCMC. From a computational cost perspective, we only meta-train once and L2E only takes about 1.2~1.5 times more wall clock time for one step update than CSGMCMC according to Table 18. Also, L2E is potentially much more efficient than other baselines since it is robust to the choice of thinning interval. In Figure 19, we plot the performance of the sampler with varying cycle length (thinning interval). Although L2E uses more computational cost for one step update, L2E can achieve comparable accuracy with other baselines with smaller total computational cost. We believe L2E excels in both aspects (performance and generalization), as it achieves better performance with reasonable computation costs even on unseen datasets compared to other methods. \n\n[1] Izmailov, Pavel, et al. \"Dangers of Bayesian model averaging under covariate shift.\" Advances in Neural Information Processing Systems 34 (2021): 3309-3322.\n."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700192406021,
                "cdate": 1700192406021,
                "tmdate": 1700192406021,
                "mdate": 1700192406021,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6wSY0K2Qcz",
                "forum": "uhR7aYuf0i",
                "replyto": "sU4MmgeVtS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8896/Reviewer_36ng"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8896/Reviewer_36ng"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "> According to Table 1, we outperform other baselines in general. \n\nPerhaps, you and I have different expectations from what Bayesian methods should contribute on top of deep learning. Let me present my point of view. Table 1, by the choice of not using data augmentations, already seems to perform below par what a single neural network can provide. Therefore, by having a weaker baseline to compare to, I think it is unfair to claim \"outperform\". Next, perhaps one place where I would expect Bayesian methods to really shine (other than accuracy which we now know that Bayesian methods can help) would be the quality of uncertainty. For a moment, the ECEs are still fairly far off from the best performing P-cSGMCMC. If as a user of the method, I am spending all the extra compute to construct posterior samples, I would ideally like to be at least very close other baselines even if not outperform. The gaps are fairly large, e.g. on Tiny ImageNet as large as 4% v/s 11% for ECE, and multiple percentage points on others.\n\nTable 3 for OOD detection tells me, that as the datasets get harder, the benefit of the method seems to become less remarkable. For a time, when scaling of models is important for performance, such a method seems not so amenable to scaling with the datasets.\n\nBut again, I don't want to force you into the narrative that L2E should be the absolute best. That is certainly the wrong goal to strive for. Nevertheless, outperforming would be a strong characterization of the results, and would require further work to really make that claim.\n\n> From a computational cost perspective, we only meta-train once and L2E only takes about 1.2~1.5 times more wall clock time for one step update than CSGMCMC according to Table 18\n\nI think that is completely reasonable. A large fraction of deep learning uses pre-trained models, so we can potentially even ignore this cost for the sake of our discussion. And as you say, with sufficient meta-training, it might even be effectively lower. I am indeed very happy to see that the meta-learned samplers are not bad at all, and this is not a big concern for me."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700253513979,
                "cdate": 1700253513979,
                "tmdate": 1700253513979,
                "mdate": 1700253513979,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HaqXrG4ZyR",
                "forum": "uhR7aYuf0i",
                "replyto": "6lGmQb4Oif",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8896/Reviewer_36ng"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8896/Reviewer_36ng"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "> Thus, in response to your request, we conduct experiments with data augmentation on CIFAR-10 and CIFAR-100. Please refer to Appendix C.2 for full details and results of the experiments\n\nI really appreciate you running these experiments. Here again, I want to point out that a performance less than 93% on CIFAR-10 seems like a model that is not up to par. It makes the comparisons look weak. But in any case, as you see, the difference in the methods become far less stark.\n\nWe as a community of Bayesian deep learning have been underselling these results for years. Without strong results that at least match simple baselines in deep learning, I am afraid BDL remains an intellectual curiosity with nothing exciting for the broader deep learning community to appreciate."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700253596589,
                "cdate": 1700253596589,
                "tmdate": 1700253596589,
                "mdate": 1700253596589,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zv0uCUp3vW",
                "forum": "uhR7aYuf0i",
                "replyto": "k665haIQNp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8896/Reviewer_36ng"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8896/Reviewer_36ng"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "> we confirm that seeing more datasets during the meta-training stage do not necessarily lead to better OOD detection performance.\n\nThank you for conducting this experiment. \n\nI have a different reading of the results here. On CIFAR-100, a broader dataset, large version seems to win always. Of course, it would be hard to extrapolate, but it would appear that a more diverse dataset leads to better sampler and better uncertainty estimation. Wouldn't that be the ideal scenario for L2E anyways - it improves its uncertainty estimation with more diverse meta-training?\n\nIn any case, what I was hinting at perhaps not a criticism of the approach, but more of trying to understand where the benefits come from - parametrizing the kinetic energy term or the choice of diverse datasets. In the current work, both these choices haven't quite been studied independently."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700253622814,
                "cdate": 1700253622814,
                "tmdate": 1700253642444,
                "mdate": 1700253642444,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6x79MRVH60",
                "forum": "uhR7aYuf0i",
                "replyto": "zv0uCUp3vW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8896/Reviewer_36ng"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8896/Reviewer_36ng"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "I appreciate the effort the authors have taken to add all the new experiments.\n\nI still think that there is a strong push to convey the method as an \"outperformer\" over existing methods, but I think the baselines are weak, and the attribution of method's benefits remain entangled between the choice of kinetic energy parametrization and the choice of using diverse meta-training. Further, the baselines used are below par for the deep learning community. We cannot rely on the intellectual merits of Bayesian inference alone, the benefits need to show up somewhere either in the accuracy or uncertainty properties, which I don't think is convincing when reading between the lines of what the results tables portray (as I have outlined in my comments above for additional experiments). Therefore, I will keep my score.\n\nThis perhaps could have been a different paper, were it not concerned with outperforming and introducing the idea that meta-training and kinetic energy parametrization is something that the community has largely ignored. But of course, it is the authors' right to decide, and I want to make sure the authors know that I do not hold it against them in my assessment."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700254162389,
                "cdate": 1700254162389,
                "tmdate": 1700254162389,
                "mdate": 1700254162389,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Zhp2xSdZsF",
            "forum": "uhR7aYuf0i",
            "replyto": "uhR7aYuf0i",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8896/Reviewer_LiEv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8896/Reviewer_LiEv"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a meta-learning method to learn the kinetic energy term in SGMCMC for multi-modal distributions. The proposed method uses two neural networks (NNs) to parameterize kinetic energy term and train these NNs based on a meta-objective function, which is the validation loss. The authors have conducted several experiments, including image classification and out-of-distribution detection to demonstrate the proposed method."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThe methodology of the proposed method is simple, which makes it a practical method for many tasks.\n2.\tThe experiments and ablation studies are comprehensive and cover many aspects of sampling, including predictive accuracy, uncertainty quantification, convergence diagnostic"
                },
                "weaknesses": {
                    "value": "1.\tThe paper did not mention at all at the beginning that, there already exist meta-learning methods for SGMCMC, such as Gong et al. Only in Section 3.1, the authors first briefly mention that paper. The presentation is misleading and may give the impression that this paper is the first to study meta-learning for SGMCMC.\n2.\tMore importantly, the proposed method is essentially very similar to Gong et al, which uses the same formulation for the SGMCMC class, but will slightly different parameterization. Gong et al learns the curl matrix Q and the diffusion matrix D whereas the proposed method learns the kinetic energy term. Given the similarity, it is important to clearly state the difference compared with Gong et al.\n3.\tThe motivation of the proposed method is weak. Since the main difference compared with Gong et al is the parameterization of the kinetic energy term, it is important to clearly motivate this choice. The authors did not mention at all in the paper why they choose to learn the kinetic energy term rather than the curl matrix and the diffusion matrix. The advantages of doing so are not discussed.\n4.\tGong et al has proposed several meta objectives. Again, the authors did not discuss their meta objective with existing ones.\n5.\tIn experiments, the authors did not compare with Gong et al, which is a very related method.\n6.\tAlthough the experimental results of the proposed method are promising, it is not clear why the proposed meta-learning method can lead to these empirical improvements. What kind of learning updates did the meta-learning algorithm learn in the end?  Why does the method show a better exploration-exploitation balance? how does it achieve that?\n7.\tThe meta-learning tasks are classification on MNIST, Fashion-MNIST, EMNIST and MedMNIST and the downstream tasks are classification on Fashion-MNIST, CIFAR and Tiny ImageNet.  Since Fashion-MNIST has appeared in meta-learning tasks, is it reasonable to use it as a test task? Are CIFAR and Tiny ImageNet similar to MNIST to be considered as test tasks?\n\nGong et al, Meta-Learning For Stochastic Gradient MCMC, ICLR 2019"
                },
                "questions": {
                    "value": "1.\tCan you explain T-SNE visualization of learning trajectories? Why does L2E\u2019s trajectory look very different from DE and CSGMCMC?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8896/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698605593195,
            "cdate": 1698605593195,
            "tmdate": 1699637119351,
            "mdate": 1699637119351,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qiI79O8cjb",
                "forum": "uhR7aYuf0i",
                "replyto": "Zhp2xSdZsF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8896/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8896/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for constructive comments that can improve the quality of our paper. We would like to answer your comments. Also, we revise our paper with comprehensive comparison with Gong et al., in Appendix A. Please refer to  Appendix A for more detailed information.\n\n> The paper did not mention at all at the beginning that, there already exist meta-learning methods for SGMCMC, such as Gong et al. Only in Section 3.1, the authors first briefly mention that paper. The presentation is misleading and may give the impression that this paper is the first to study meta-learning for SGMCMC.\n\nSorry for not faithfully discussing Gong et al., in our main paper, we did not intend to be misleading in acknowledging its contribution. We could not put enough discussion in the main paper due to the page limit. In the revised version, we added the discussion about Gong et al., and devoted an additional section in the appendix to compare ours to Gong et al., in various aspects.\n\n> More importantly, the proposed method is essentially very similar to Gong et al, which uses the same formulation for the SGMCMC class, but will slightly different parameterization. Gong et al learns the curl matrix Q and the diffusion matrix D whereas the proposed method learns the kinetic energy term. Given the similarity, it is important to clearly state the difference compared with Gong et al.\n\nWe have added Table 6 and Appendix A to state the difference between Gong et al. Please refer to Appendix A and Table 6 for more detailed explanation.\n\nFor what you have pointed out, especially the statement that ours is very similar to Gong et al., because they share the same formulation for the SGMCMC class and differ only in parameterization. We respectfully disagree with this. The SGMCMC class is a complete class, so any convergent SGMCMC algorithm must belong to this class, so whatever SGMCMC algorithm we try to learn we always have to be in the class both ours and Gong et al., are following. Moreover, as we have detailed in Appendix A, the fact that we are learning kinetic energy is a significant innovation, bringing noticeable gains both in terms of the exploration behaviour of the sampler and efficient training.\n\nMoreover, we have different goals with Gong et al. Their purpose was to learn the sampler that fastly converges to high density region with low bias. However, our approach is specifically designed with more concrete purpose of effectively simulating multi-modal BNNs posterior distribution and also generalizing to unseen problems for practicality. This goal was not achieved by Gong et al because Figure 3 in Gong et al showed that learned sampler fastly converges to low energy region, but learned friction term $D_f$ restricts the amount of update in low energy region to prevent divergence which harms the exploration of the sampler. Also, we aim to learn more generalizable and scalable sampler so we use different parameterization and meta-learning strategy with Gong et al. Therefore, although we share some similar features with Gong et al., it is difficult to say our method is essentially very similar to Gong et al since they could not achieve our goals."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700192081977,
                "cdate": 1700192081977,
                "tmdate": 1700192081977,
                "mdate": 1700192081977,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sT5X7KuutN",
                "forum": "uhR7aYuf0i",
                "replyto": "Zhp2xSdZsF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8896/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8896/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> The motivation of the proposed method is weak. Since the main difference compared with Gong et al is the parameterization of the kinetic energy term, it is important to clearly motivate this choice. The authors did not mention at all in the paper why they choose to learn the kinetic energy term rather than the curl matrix and the diffusion matrix. The advantages of doing so are not discussed.\n\nFirstly, we would like to say that we noted the advantages of the design of kinetic energy over the design of diffusion and curl matrices in Appendix F along with ablation study. Also, we have added the motivation to learn the kinetic energy term in Appendix A.1. Parameterization of diffusion matrix $D_f$ and curl matrix $Q_f$ suggested in Gong et al., has two limitations to achieve our goal, efficient exploration of multi-modal large scale BNNs posterior distribution. First, learning $D_f$ and $Q_f$ to be dependent on $z$ harms scalability of algorithm since it introduces a new correction term $\\Gamma_i(z)$ which forces to compute the gradient of $D_f$ and $Q_f$ with respect to $z$. This makes significant computational burden as the dimension of $z$ increases.\n\nAdditionally, since $Q_f$ which governs the acceleration of $\\theta$ is limited to operating as multipliers for the energy gradient and momentum, learning $D_f$ and $Q_f$ is not the best parameterization for learning sampler to effectively explore multi-modal distribution. In low energy regions where the norm of gradient and momentum are extremely small, it is difficult to make reasonable amount of update of $\\theta$ for exploration by multiplying $Q_f$ to momentum and gradient. By contrast, In the update rule of L2E, two parameterized gradients $\\alpha_\\phi, \\beta_\\phi$ are added to the energy gradient and $\\beta_\\phi$ directly updates the $\\theta$. This is more suitable for controlling the magnitude and direction of update to enhance exploration property in low energy regions.\n\n> Gong et al has proposed several meta objectives. Again, the authors did not discuss their meta objective with existing ones.\n\nTo the best of our knowledge, Gong et al did not propose meta-objectives other than the meta-objective they actually used. However, we have added a discussion on the meta-objective proposed by Gong et al and other related papers in Appendix A.3. Meta-objective of Gong et al aims to reduce the KL divergence between the target density $\\pi$ and the marginal distribution $q(\\theta|D)$ at time $t$. However, $q(\\theta|D)$ is intractable since it is an unknown density function, computing the gradient of $q(\\theta|D)$ requires a gradient estimator. They used stein-gradient estimator which requires multiple independent chains, but this undermines the scalability of the algorithm. Also, this objective does not lead the learned sampler to explore multi-modal distribution. Figure 3 in Gong et al showed that learned sampler fastly converges to low energy region, but learned curl matrix restricts the amount of update in low energy region to prevent divergence which harms the exploration in low energy region.\n\n\n> In experiments, the authors did not compare with Gong et al, which is a very related method.\n\nIn Appendix A.4 of revised version, we follow the experimental setup of Gong et al, and compare our method with Meta-SGMCMC (Gong et al). For experimental details and results, please refer to Appendix A.4. To summarize the experimental results, we have confirmed that L2E outperforms Meta-SGMCMC in various generalization experiments in terms of ACC and NLL. In CIFAR-10 experiment, despite L2E was not trained on the CIFAR-10 during the learning process, L2E significantly outperforms with a wide margin without being trained on CIFAR-10, indicating that our approach better generalizes to unseen datasets compared to Meta-SGMCMC. \n\n\n|Method|NT ACC|NT+AF ACC|NT+Data ACC|NT NLL/100|NT+AF NLL/100|NT+DATA NLL/100|\n|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n|Meta-SGMCMC|78.12\u00b10.04|74.41\u00b10.11|89.97\u00b10.04|68.88\u00b10.15|79.55\u00b10.06|15.66\u00b10.28|   \n|L2E|**79.21\u00b10.20**|**75.91\u00b10.20**|**92.49\u00b10.23**|**63.23\u00b10.46**|**72.11\u00b10.22**|**11.82\u00b10.81**|  \n\n|Method|NT ACC|NT+AF ACC|NT+Data ACC|NT NLL/100|NT+AF NLL/100|NT+DATA NLL/100|\n|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n|Meta-SGMCMC|98.36\u00b10.02|97.72\u00b10.02|98.62\u00b10.02|640\u00b16.25|875\u00b13.19|230\u00b13.23|   \n|L2E|**98.39\u00b10.05**|**98.07\u00b10.08**|-|**558\u00b13.19**|**679\u00b16.65**|-|"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700192196916,
                "cdate": 1700192196916,
                "tmdate": 1700192323405,
                "mdate": 1700192323405,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fLdQ7JAuyg",
                "forum": "uhR7aYuf0i",
                "replyto": "LDZnWnoAzj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8896/Reviewer_LiEv"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8896/Reviewer_LiEv"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the authors\u2019 response, especially the new experimental results. \n\n**The parameterization of the kinetic energy**\n\nThe benefits and motivation for parameterizing the kinetic energy are still unclear to me. I wonder if parameterizing the kinetic energy is theoretically sound. Since the kinetic energy depends on theta, my feeling is that the stationary distribution is no longer the target distribution. If so, what is the stationary distribution of the learned sampler? What are the requirements for the kinetic energy in order to ensure the Markov chain converges the target distribution? For parameterizing the diffusion and curl matrices, we know that the meta-learned sampler will still have the target distribution as the stationary distribution according to the complete recipe. \n\n**The meta-loss function**\n\nWhat is the reason that the proposed sampler can explore multi-modal distributions? It is not clear why meta-learning can help overcome the barrier between modes. The meta-loss does not seem to explicitly encourage this.\n\nOverall, I think the idea of a meta-learning sampler is very interesting and the experimental results seem promising. I would encourage the authors to continue revising the paper based on all reviews and submit this work to future venues."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700699003843,
                "cdate": 1700699003843,
                "tmdate": 1700699003843,
                "mdate": 1700699003843,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "pFZKphDAWA",
            "forum": "uhR7aYuf0i",
            "replyto": "uhR7aYuf0i",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8896/Reviewer_CsK6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8896/Reviewer_CsK6"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors present a general approach for SGMCMC using meta-learning. The meta-learning approach is explicitly trained to minimize the downstream log likelihood using Bayesian model averaging from the final model. This approach is motivated by the earlier successes of meta-learning approaches which show that rich feature representations can be learned and transferred to various tasks. The authors present experimental results looking at the convergence rate, the diversity of the samples, as well performance on downstream tasks of classification and uncertainty quantification."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The approach is well motivated by the previous successes in meta-learning. Knowledge-sharing between different SGMCMC chains across different multi-modal distributions across similar tasks should be explored in detail. \n\n- The authors have done a good job at experimentation overall. The empirical analysis spans understanding the diversity of MCMC chains as well as looking at the downstream tasks. \n\n- I really like the idea of parameterizing the gradients of kinetic energy function - it seems intuitive and to the best of my knowledge I haven't seen prior work do that. This building the SGMCMC algorithm from first principles is commendable."
                },
                "weaknesses": {
                    "value": "- While the experimental results are useful, I think the paper also needs an ablation study. We need to understand the impact of the parameterized gradients v/s transferability of the posterior information across the tasks. \n\n- Understanding the compute requirement at train time is equally important. We don't know how much training time is required per step and in total and how it compares with other baselines that the authors have compared with. It'll also be useful to know the additional # of parameters added through the gradient parameterization. \n\n- I think there will be some tradeoff between the number of samples we generate in the inner loop to compute $L$ and final convergence in terms of how quickly we converge and quality of the posterior samples. Running an ablation on the number of samples we generate in the inner loop would also be useful for practitioners who would be interested in using this approach."
                },
                "questions": {
                    "value": "I do like this paper overall and I think it has shown some interesting results. I have listed my comments that I'd like the authors to address in the weaknesses section.\n\nAlso, it'll be useful if the author can provide some insights on how to speed up their algorithm and make it more efficient. For e.g., would warm starting with an SGD estimate in the meta-learning framework help?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8896/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8896/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8896/Reviewer_CsK6"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8896/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698789923003,
            "cdate": 1698789923003,
            "tmdate": 1699637119235,
            "mdate": 1699637119235,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mh7xanAPQ0",
                "forum": "uhR7aYuf0i",
                "replyto": "pFZKphDAWA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8896/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8896/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your positive view supporting our method that enhances exploration of SGMCMC through learning kinetic energy terms. Our answer for your concern is as follows:\n\n> While the experimental results are useful, I think the paper also needs an ablation study. We need to understand the impact of the parameterized gradients v/s transferability of the posterior information across the tasks.\n\nWe understand your question as asking \u201cWhat is the common knowledge that parameterized gradients learn for the exploration of posterior distribution of different tasks\u201d. If this is your question, we have added an analysis of the parameterized gradient during the evaluation stage in Appendix B for answering this. We track the norm of parameterized gradient, $||\\beta||^2 = \\frac{||\\Delta\\theta||}{\\epsilon}^2$ we find that its magnitude is larger in local minima than in the early stages of training. This tendency is different from other gradient-based MCMC methods where the update amount decreases at minima. Additionally, we notice that L2E actively updates $\\theta$ at minima while maintaining loss as nearly constant. This trend is consistently observed in both CIFAR-10 and CIFAR-100, implying that L2E learns some common knowledge of posterior information across tasks for efficient exploration in low loss regions. \n\nIf this is not an appropriate answer to your question, could you please explain your question again in more detail?\n\n> Understanding the compute requirement at train time is equally important. We don't know how much training time is required per step and in total and how it compares with other baselines that the authors have compared with. It'll also be useful to know the additional # of parameters added through the gradient parameterization.\n\nFor meta-training, we use approximately 10 hours for 2000 updates of meta-parameters on a single NVIDIA RTX A6000 GPU. It is important to note that we meta-train only once for all experiments in the paper since we aimed to meta-train the sampler which is transferable to various tasks. Therefore, it is unfair for our method to compare the wall clock time including meta-training time with other baselines. \n\nOur meta-learner consists of 2 layer MLP with 32 hidden nodes. This neural network takes a 9-dimensional input and output 2-dimensional vector so the additional number of parameters is 1442. This neural network is applied to each dimension of the inner-parameter independently. L2E takes about 1.2~1.5 times more wall clock time than CSGMCMC for one step update according to Table 18.\n\n> I think there will be some tradeoff between the number of samples we generate in the inner loop to compute L and final convergence in terms of how quickly we converge and quality of the posterior samples. Running an ablation on the number of samples we generate in the inner loop would also be useful for practitioners who would be interested in using this approach.\n\nWe have added ablation experiments in Appendix C.3. for the number of samples in the inner loop. As you expected, we confirm that generating a smaller number of samples during inner-loop harms the convergence of the sampler in evaluation tasks. When the inner loop is too short, the sampler may not sufficiently learn information about the loss surface in low-loss regions during meta-training. Then, the sampler will fail to learn desirable properties such as exploration in minima or fast convergence.\n\n> I do like this paper overall and I think it has shown some interesting results. I have listed my comments that I'd like the authors to address in the weaknesses section. Also, it'll be useful if the author can provide some insights on how to speed up their algorithm and make it more efficient. For e.g., would warm starting with an SGD estimate in the meta-learning framework help?\n\nWe can speed up L2E by reducing the thinning interval. As shown in Figure 19, while CSGMCMC shows performance drop as the thinning interval decreases, L2E can maintain a similar level of accuracy and diversity with shorter thinning interval. Specifically, L2E maintains performance even when reducing the thinning interval from 50 epochs to 10 epochs for both CIFAR-10 and CIFAR-100. L2E outperforms CSGMCMC's 5100 epochs performance with just 1100 epochs.\n\nFurthermore, L2E may benefit from using burn-in epochs with SGD, as it allows for warm starting with SGD and immediate sample collection using L2E to traverse high density regions between different modes. Additionally, since our approach shares some similarities with other SGMCMC in parameterization, we can apply techniques such as LR warm-up or LR scheduling. In other words, existing techniques for accelerating training can be applied to L2E so L2E has great potential in terms of efficiency and scalability. In conclusion, based on these insights and results, L2E has numerous ways to achieve speed up and potentially efficiency."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700192089714,
                "cdate": 1700192089714,
                "tmdate": 1700193476794,
                "mdate": 1700193476794,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XWuD9dZ3ev",
                "forum": "uhR7aYuf0i",
                "replyto": "mh7xanAPQ0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8896/Reviewer_CsK6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8896/Reviewer_CsK6"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "I thank the authors for engaging in the discussion. \n\n- While talking about ablation study to understand the impact of parameterization v/s meta-learning, I meant what would be the performance impact if we didn't do parameterization and only used the meta-parameters as the starting point for sampling. \n- After reading your responses, I am a little confused. What are the 9 inputs to the meta-network here? \n- I guess 5100 epochs for cSGMCMC seems very high in general? Can you highlight what's the setup here? Also, the thinning interval of 50 or even 10 epochs seems pretty high. Especially, for cSGMCMC where you can potentially get away with very low thinning interval given that main benefits could come from running more cycles.\n\nI also read other reviews, and it seems like other reviewers also have concerns regarding the baseline. I also saw that the authors are not performing any data augmentation. For stronger baselines (such as deep ensembles), having data augmentations would be very important."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700551643468,
                "cdate": 1700551643468,
                "tmdate": 1700551643468,
                "mdate": 1700551643468,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fCE0QOsm3Y",
                "forum": "uhR7aYuf0i",
                "replyto": "aeCyO2Ls1s",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8896/Reviewer_CsK6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8896/Reviewer_CsK6"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "Thanks for your comments. \n\n> Our goal is completely different from other meta-learning methods that aim to learn good initial parameters which are adaptable for many tasks. We aim to meta-learn the sampler that can explore highly multimodal posterior distribution in large-scale BNNs tasks. We believe that we cannot achieve our goal solely by meta-learning good initial parameters.\n\nBut this would still be a good baseline, I believe. And this would help showcase why parameterized gradients are needed. I see that you also did another experiment looking at diversity of datasets, which is also helpful.\n\n> Basically, we use large thinning interval to collect diverse parameters from various parts of the posterior distribution. For cSGMCMC and L2E, we use 5100 epochs with 100 burn-in epochs and a thinning interval of 50 epochs to collect 100 parameters. For cSGMCMC, we also set cycle length to 50 epochs....\n\nSo L2E and cSGMCMC are run for identical number of epochs? If so, why is the training time different, exactly? Also, what I was alluding to previously was that you can reduce the thinning interval for cSGMCMC and I also believe that after a few # of cycles, the performance gain from additional parameter samples would be negligible. So we may not need very high # of parameter samples in the first place. \n\n> We do not use data augmentation in our experiments since including data augmentation violates i.i.d assumption of the dataset. \n\nI get that it's not a principled thing to do - however, as one other reviewer has pointed out, it significantly impacts the performance. One way to get around this is to say that after augmentation, you're generating samples from a different distribution (as long as the support for original samples under that distribution doesn't go down to zero). Agreed that this can still invite arguments against biases, but this would be one way to get around that assertion."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700639354037,
                "cdate": 1700639354037,
                "tmdate": 1700639354037,
                "mdate": 1700639354037,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]