[
    {
        "title": "Linear diffusion models meet contextual bandits with large action spaces"
    },
    {
        "review": {
            "id": "yd7sTFVyCt",
            "forum": "x2yFdUSJ4I",
            "replyto": "x2yFdUSJ4I",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission214/Reviewer_S8eU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission214/Reviewer_S8eU"
            ],
            "content": {
                "summary": {
                    "value": "The paper extends prior work on diffusion model-based TS with MAB to contextual bandits, and specifically, with a so-called linear diffusion model for linear contextual bandits. The corresponding TS algorithm is derived and analyzed, and numerical results are presented to show advantages over a few baselines."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper writing is clear and easy to follow"
                },
                "weaknesses": {
                    "value": "The main contribution of this paper (linear diffusion model for linear contextual bandits) is exactly equivalent to prior works, which makes the novelty and contribution very limited. See below."
                },
                "questions": {
                    "value": "It is important to clarify the distinction of linear diffusion models with the \"correct\" equivalent form of HierTS and (1). Indeed, in (4) or (9), with W'sand \\Sigma's as known, it is clear that the multiple layer of linear Gaussian transformation is just equivalent to one layer of linear Gaussian prior, and hence effectively equivalent to HierTS or (1). I notice the authors tried to clarify this point in (17), but in wrong way (which I hope is not on purpose) - instead of keeping the first layer and marginalizing the other latent layers, you should actually marginalizing all layers in the prior. The equivalent to linear bandits with linear Gaussian prior (and ignoring estimation error of the diffusion model) is exactly the reason why you can get a theoretical guarantee). \n\n\n[1] Aouali I, Kveton B, Katariya S. Mixed-effect thompson sampling[C]//International Conference on Artificial Intelligence and Statistics. PMLR, 2023: 2087-2115."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission214/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission214/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission214/Reviewer_S8eU"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission214/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698601266265,
            "cdate": 1698601266265,
            "tmdate": 1700599001108,
            "mdate": 1700599001108,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "uoyLOZGPbD",
                "forum": "x2yFdUSJ4I",
                "replyto": "yd7sTFVyCt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission214/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission214/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank you for your feedback and valuable time. We provide our response below. \n\n__dTS and Gaussianity__\n\nWhile our posterior derivations and Lemma 2 affirm the Gaussian nature of $\\theta_i|H_t$ , the structure of our proof is different from standard Gaussian Thompson Sampling (TS). In fact, using standard Gaussian TS results would lead to a Bayes regret bound that doesn't fully capture the structure of our problem (correct dependencies on $L$, $\\sigma_\\ell$, and more importantly sparsity dimensions $d_\\ell$). We acknowledged in the paper that the Gaussian form of the posterior leads to Lemma 1 which is borrowed from existing works. However, \n all the other elements, including Lemmas 2 and 3, Theorem 1, and Proposition 1, introduce novel concepts specifically designed for our model's unique framework, and are not standard. More details about the novelty of these results will be provided in the next part of our response. Now it is important to note that the primary objective of our study is to theoretically elucidate why diffusion models are effective priors for TS, complemented by experimental evidence supporting these theoretical insights. dTS was designed for general diffusion models, our current analysis focuses on the linear case. This analysis distinctly highlights the differences between dTS and standard TS, potentially motivating future explorations into analyzing the non-linear version of dTS.\n\n__Comparison to HierTS__\n\nOur approach to marginalizing latent parameters aligns with common practices (e.g., Tree-HierTS (Section 6 in [1])), to ensure a fair computational efficiency comparison. This is analogous to how two-level HierTS is typically compared to Independent-TS, which models each action parameter independently, rather than Joint-TS, which models the joint distribution but is computationally more intensive. For example, under specific choices of mixing matrices in dTS such that the coordinates of $\\psi_1$ independent given $\\psi_2, H_t$, our computational efficiency scales with $d_1$ rather than $d_1^3$ due to the feasibility of independent coordinate sampling. In contrast, two-level HierTS, with traditional marginalization, would scale with $d_1^3$ as conditional independence is lost after marginalizing $\\psi_2$.\n\nBeyond these comparisons, dTS is designed for more general cases (Section 3), where marginalization to two-level HierTS is not always possible. Additionally, direct application of the theory of two-level HierTS does not replicate our results, even in Gaussian cases. Our model deviates by using multiple levels, wherein a function $f_1(\\psi_1)$, or $W_1 \\psi_1$ in linear scenarios, is used as the mean for action parameters, unlike two-level HierTS's assumption of Gaussian distributions centered at a common latent parameter (which corresponds to $W_1=I_d$). In particular, the use of linear functions $W_1 \\psi_1$ allows the introduction of the sparsity assumption, which is a critical aspect not possible in standard HierTS. While Mixed-Effect TS also proposes a two-level hierarchy with Gaussian action parameters based on a linear mixture of latent parameters, our model extends beyond this, treating it as a special case with $L=1$ and specific mixing matrices. More technical novelties of our work are detailed subsequently.\n\n[1] Hong, Joey, et al. \"Deep Hierarchy in Bandits.\" arXiv preprint arXiv:2202.01454 (2022)."
                    },
                    "title": {
                        "value": "Part 1"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission214/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700233748509,
                "cdate": 1700233748509,
                "tmdate": 1700233780949,
                "mdate": 1700233780949,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XUQfF0P5pn",
                "forum": "x2yFdUSJ4I",
                "replyto": "05cscf4n9G",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission214/Reviewer_S8eU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission214/Reviewer_S8eU"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your reply. I agree considering sparsity in multi-layer prior has benefits in theory and computation), and non-linear case is different from Hier-TS. Though the former is actually a very strong assumption and the novelty in derivations is limited, and little efforts are actual spent on the latter. We may have different assessment but these are not what I want to focus on. \n\nConsider the linear-linear-Guassian case which is your main focus and where novelty mainly comes from.\n\nI think we agree both papers study how to model the prior of $\\theta_{\\*,i}$. \n\nYou claim in (17) that Hier-TS should be\n\n$\\psi_{*,L} \\sim N(0, \\Sigma_{L+1}) $   (meta-prior)\n\n$\\theta_{\\*, i} | \\psi_{\\*,L} \\sim N(\\psi_{\\*,L}, \\Omega) $ (prior) \n\nThis marginalization increases the prior variance. \n\nAnother marginalization is \n\n$\\psi_{*,1} \\sim N(0, \\Omega')$  (meta-prior)\n\n$\\theta_{\\*, i} | \\psi_{\\*,L} \\sim N(W_1 \\psi_{\\*,1}, \\Omega). $ (prior)\n\nI have a few questions. Put sparsity aside (consider all matrics are dense). \n\n1. Is there any theoretical difference between the two marginalization, when applying Hier-TS's result?\n2. What is the difference between your method/result with the second marginalization of Hier-TS in terms of either theory or computation (I understand you do computation hierarchically; but is there any gain without sparsity assumption)? You mentioned in your reply that Hier-TS assumes $W_1$ is an identity matrix, while it is quite unclear to me why that is a drawback. Indeed, your method/result looks **identical** with this formulation of Hier-TS. \n\nI am happy to consider increasing the score if the authors are willing to discuss these relationship, both here and also more openly in the paper."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission214/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700516115645,
                "cdate": 1700516115645,
                "tmdate": 1700516115645,
                "mdate": 1700516115645,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PmRdgIs3Kw",
                "forum": "x2yFdUSJ4I",
                "replyto": "yd7sTFVyCt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission214/Reviewer_S8eU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission214/Reviewer_S8eU"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the clarification to the question of mine and and Reviewer hKWS! \n\nMy take is the following: \n\n1. The **statistical property/performance** of HierTS-2 and dTS should be identical, for any models you study (recall HierTS was also defined in a general way as you are doing, though both without much analysis). This is because the two posterior distributions are just the same (though sampling is done in different ways). \n2. For **linear-linear-Gaussian without sparsity** (actually low-rank?) in prior: the theoretical performance is comparable (dTS is actually slightly worse with 2^l term), and the computation of dTS is also heavier. \n3. For **linear-linear-Gaussian with sparsity** (actually low-rank?) in prior: your paper provides a tighter regret bound under this more specific structure, and improves computation by hierarchical sampling\n\nI will raise my score to 3 given the connection with prior work is now discussed more openly, but I am still inclined to rejection given the statistical property/performance (if not algorithm, with the only difference in computation) is the same with HierTS-2. \n\nPlease let me know if I and/or Reviewer hKWS misunderstand any point. Thanks."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission214/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700598981297,
                "cdate": 1700598981297,
                "tmdate": 1700599044523,
                "mdate": 1700599044523,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "QU73bdOa5p",
            "forum": "x2yFdUSJ4I",
            "replyto": "x2yFdUSJ4I",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission214/Reviewer_zHzJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission214/Reviewer_zHzJ"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers the Bayesian bandit problem where the priors of underlying parameters are generated by a known linear diffusion model. The authors provide a closed-form posterior distribution formula and then apply the Thompson sampling algorithm based on this formula, establishing the corresponding Bayesian regret guarantee."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The motivation is compelling, given the practical success of the diffusion prior in bandit problems.\n2. The paper is well-written with both the problem setting and the results stated clearly.\n3. The results are sound, supported by detailed proofs and simulation results.\n4. The comparsion to previous algorithms TS and HierTS is insightful and reveals benefits on using the refined prior information instead of the marginalized prior."
                },
                "weaknesses": {
                    "value": "1. The adoption of the diffusion prior in bandits is interesting and powerful according to previous empirical studies. However, the paper's focus on the linear diffusion prior, essentially a linear Gaussian system, simplifies the problem considerably. Although deriving the exact formula for the posterior mean and covariance, as indicated in equations (5)-(8) of this paper, requires some calculations(see also weakness 2, 3, 4), once these results are established, I don't observe too much additional difficulty compared to prior Thompson sampling papers for linear Gaussian bandits.\n\n2. As pointed out in the first weakness, the linear diffusion considered in this paper is actually a linear Gaussian system (LGS). Several standard results from LGS theory could be directly applied to this paper to simplify the proof. For example:\n\n(2.1). Proposition 2 in Appendix B is straightforward from equations (13.89) and (13.90) in [1] when the parameters $\\Gamma = 0, A = I, z_1 = W_1 \\psi_{\\*,1}, V_0 = \\Sigma_1, \\Sigma = \\sigma^2 I,$ and $C_n = \\mathbf{1}(A_n = i) X_{n}^\\top$ are substituted into equations (13.78)-(13.83) of [1]. Here, $\\Gamma, A, z_1, V_0,C_n$ and $\\Sigma$ are notations from [1], while $W_1, \\psi_{\\*,1}, \\Sigma_1, \\sigma^2, A_n,$ and $X_n$ come from the paper. It's worth noting that although [1] let $C_n \\equiv C$ for the sake of simplicity, generalizing to allow varying $C_n$ is straightforward.\n\n(2.2). Proposition 3 in Appendix B can be directly derived by using equations (2.109) and (2.110) from [1] and making particular choices of prior covariance and design matrices. This also makes Lemma 4 redundant since it only acts as an intermediary result to prove Proposition 3.\n\n\n\n[1] Pattern Recognition and Machine Learning(2006), Christopher M. Bishop."
                },
                "questions": {
                    "value": "I have one quesition on the algorithm design: Given the knowledge of {$Q_{t,\\ell}$} and $P_{t,i}$, it appears that the posterior distribution of $\\( \\theta_i \\)$ given $H_{t}$ can be computed analytically using the properties of Gaussian distributions. Why do the authors tend to firstly sample {$\\psi_{t,\\ell}$} instead of directly sampling $\\theta_{t,i}$ from this distribution?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission214/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission214/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission214/Reviewer_zHzJ"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission214/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698657827197,
            "cdate": 1698657827197,
            "tmdate": 1699635946840,
            "mdate": 1699635946840,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qXPmERCrFu",
                "forum": "x2yFdUSJ4I",
                "replyto": "QU73bdOa5p",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission214/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission214/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for your positive feedback and valuable time. We address your comments and questions below. Please let us know if you have any additional questions.\n\n__I) Technical Contributions__\nWe have included a detailed discussion of the technical challenges and contributions in Appendix C.1. Below is a more succinct summary of these points.\n- __Lemma 2.__ In dTS, sampling is done hierarchically, and thus the marginal posterior distribution of $\\theta_i | H_t$ is not explicitly defined since we only use the conditional posterior distribution of $\\theta_i | H_t, \\psi_1$. Our first contribution was deriving the covariance of $\\theta_i | H_t$ using total covariance decomposition combined with an induction argument, as our posteriors in Section 3.1 were derived recursively. This differs from the standard Bayes regret, where the posterior distribution of $\\theta_i | H_t$ is predetermined due to the absence of latent parameters. Note that the total covariance decomposition was originally used in HierTS for multi-task linear bandits with a single latent parameter. Here, we extend it to contextual bandits with multiple, successive levels of latent parameters. Furthermore, our proof diverges from HierTS by incorporating linear functions ($W_\\ell\\psi_\\ell$), as opposed to HierTS's reliance on the more straightforward identity function $\\psi_\\ell$.\n- __Lemma 3.__ Standard Bayes regret analysis quantifies the posterior information gain from actions, particularly by examining the increase in posterior precision of the taken action $A_t$. Our proof, however, requires considering the information gain for each latent parameter, since they are also learned. Then, our contribution lies in using recursive formulas in Section 3.1 to propagate the posterior information gain of the taken action $A_t$ to all latent parameters within the range $\\ell \\in [L]$. This is not only novel but also technically challenging, as it combines recursive formulas, induction arguments, the Sherman\u2013Morrison formula, and properties of rank-1 matrices. This enables a nuanced quantification of how the information gain from a particular action can impact the learning of latent parameters.\n- __Proposition 1.__ Proposition 1 enhances Theorem 1's Bayes regret analysis through the sparsity assumption __(A3)__, which is grounded in the intuitive idea that sparsity leads to fewer parameters to learn, and hence smaller regret. This assumption refines regret to depend on the reduced dimensions $d_\\ell \\leq d$, instead of $d$. We adapt Theorem 1's proof by partitioning the covariance matrix of each latent parameter $\\psi_\\ell$ into two blocks: a $d_\\ell \\times d_\\ell$ block for learnable parameters and a $(d-d_\\ell) \\times (d-d_\\ell)$ block for non-learnable ones. This leads to the important finding that the final regret depends only on the learnable $d_\\ell$ parameter, leading to tighter regret and highlighting the impact of the sparsity assumption.\n\n__II) Posterior Derivations__ \n\nWe are grateful for the reviewer's insights regarding the use of results from linear Gaussian systems (LGS) to streamline our proof exposition. We plan to revise our paper to incorporate these suggestions into more simplified proofs, but we need to make sure that the direct application of these suggestions is possible due to our use of level-specific covariances and mixing matrices $\\Sigma_\\ell$ and $W_\\ell$ (they depend on $\\ell$). We will promptly update our paper with these revisions. Additionally, we'd like to note that our current proofs for posterior derivations in the Gaussian case were included for completeness, following the convention in prior research on hierarchical Bayesian bandits where detailed posterior derivations are typically provided.\n\nRegarding the reviewer's question on why we opt for hierarchical sampling over marginalizing the latent parameters, the primary reason is computational efficiency. Marginalization would require calculating the mean and covariance of the marginal $\\theta_i | H_t$, which entails several matrix multiplications, thereby increasing computational complexity. Additionally, marginalization becomes infeasible in the context of non-linear diffusions (Section 3), and empirical studies in prior works [1] have also demonstrated that hierarchical sampling offers more efficient approximations in non-linear diffusion models for multi-armed bandits, further justifying our choice in methodology.\n\n[1] Yu-Guan Hsieh, Shiva Prasad Kasiviswanathan, Branislav Kveton, and Patrick Blobaum. Thompson sampling with diffusion generative prior. arXiv preprint arXiv:2301.05182, 2023."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission214/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700230176185,
                "cdate": 1700230176185,
                "tmdate": 1700230176185,
                "mdate": 1700230176185,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "19KQUScnee",
            "forum": "x2yFdUSJ4I",
            "replyto": "x2yFdUSJ4I",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission214/Reviewer_6rz1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission214/Reviewer_6rz1"
            ],
            "content": {
                "summary": {
                    "value": "This work extends the previous study on informative prior in contextual bandits to having the prior in the form of a diffusion model, which targets to leverage the prior information to efficiently explore a large action space and make contextual bandit algorithms more practical. The classical Thompson sampling algorithm is extended with more detailed discussions performed in the case of linear diffusion models with (generalized) linear rewards. Theoretical analyses and experimental results are reported to demonstrate the effectiveness and superiority of the proposed design."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This work nicely follows the trends of broader ML developments and incorporates the modern diffusion models into the theoretical study of bandits, which is a valid and meaningful attempt.\n\n- The overall designs and analyses are sound based on my understanding although I have not checked all the proofs. The intuitions are also clear based on the existing works on parameterized priors in contextual bandits."
                },
                "weaknesses": {
                    "value": "- Novelty. It would be nice if the authors could better illustrate how this work differs from previous works studying contextual bandits with informative priors, especially the adopted techniques. I have come across some works, e.g., [1, 2]. It seems that the essence of this work is to leverage diffusion models are priors, while diffusion models are one particular kind of graphical model. As extending the design of Thompson sampling is rather straightforward in my view, I would love to hear the authors' comments on the technical challenges in dealing with transformers as priors.\n\n- Additionally, while the target is to handle large action space, the obtained regrets still contain $K$, i.e., the number of arms, unless $\\theta$'s are fixed given $\\psi_{*,1}$. I am wondering whether this meets the design goal of handling large action space.\n\n\n[1]  Aouali et. al 2023, \"Mixed-Effect Thompson Sampling\"\n\n[2] Wan et. al 2022 \"Towards scalable and robust structured bandits: a meta-learning framework\"."
                },
                "questions": {
                    "value": "It would be really helpful if the authors could provide additional comments on my unclear points listed in the weakness part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission214/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698676995934,
            "cdate": 1698676995934,
            "tmdate": 1699635946709,
            "mdate": 1699635946709,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dOS5a3vPdx",
                "forum": "x2yFdUSJ4I",
                "replyto": "19KQUScnee",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission214/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission214/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank you very much for your positive feedback and valuable time. We split our response into two parts. Please let us know if you have any additional questions or concerns.\n\n__I) Novetly__\n\n__Algorithmic novelty.__ Hierarchical Thompson sampling has been previously explored in simpler graphical models; our work expands this to diffusion models. While adapting hierarchical sampling to multi-level graphical models is conceptually straightforward, deriving posteriors can be complex. We offer general formulas for approximations applicable in general scenarios (Section 3). Then, specifically, for linear diffusions with linear rewards  (Section 3.1), we achieve closed-form Gaussian posteriors computed recursively in an efficient way. For linear diffusions with non-linear rewards (Section 3.2), we implement an efficient Laplace approximation, leveraging the recursive formulas from Section 3.1. Both approaches demonstrate excellent empirical performance. Notably, the recursive formulas from Section 3.1 also facilitated the development of a regret bound.\n\n__Theoretical novelty.__ We have included a detailed discussion of the technical challenges and contributions in Appendix C.1. Below is a more succinct summary of these points.\n\n- __Lemma 2.__ In dTS, sampling is done hierarchically, and thus the marginal posterior distribution of $\\theta_i | H_t$ is not explicitly defined since we only use the conditional posterior distribution of $\\theta_i | H_t, \\psi_1$. Our first contribution was deriving the covariance of $\\theta_i | H_t$ using total covariance decomposition combined with an induction argument, as our posteriors in Section 3.1 were derived recursively. This differs from the standard Bayes regret, where the posterior distribution of $\\theta_i | H_t$ is predetermined due to the absence of latent parameters. Note that the total covariance decomposition was originally used in HierTS for multi-task linear bandits with a single latent parameter. Here, we extend it to contextual bandits with multiple, successive levels of latent parameters. Furthermore, our proof diverges from HierTS by incorporating linear functions ($W_\\ell\\psi_\\ell$), as opposed to HierTS's reliance on the more straightforward identity function $\\psi_\\ell$.\n- __Lemma 3.__ Standard Bayes regret analysis quantifies the posterior information gain from actions, particularly by examining the increase in posterior precision of the taken action $A_t$. Our proof, however, requires considering the information gain for each latent parameter, since they are also learned. Then, our contribution lies in using recursive formulas in Section 3.1 to propagate the posterior information gain of the taken action $A_t$ to all latent parameters within the range $\\ell \\in [L]$. This is not only novel but also technically challenging, as it combines recursive formulas, induction arguments, the Sherman\u2013Morrison formula, and properties of rank-1 matrices. This enables a nuanced quantification of how the information gain from a particular action can impact the learning of latent parameters.\n- __Proposition 1.__ Proposition 1 enhances Theorem 1's Bayes regret analysis through the sparsity assumption __(A3)__, which is grounded in the intuitive idea that sparsity leads to fewer parameters to learn, and hence smaller regret. This assumption refines regret to depend on the reduced dimensions $d_\\ell \\leq d$, instead of $d$. We adapt Theorem 1's proof by partitioning the covariance matrix of each latent parameter $\\psi_\\ell$ into two blocks: a $d_\\ell \\times d_\\ell$ block for learnable parameters and a $(d-d_\\ell) \\times (d-d_\\ell)$ block for non-learnable ones. This leads to the important finding that the final regret depends only on the learnable $d_\\ell$ parameter, leading to tighter regret and highlighting the impact of the sparsity assumption."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission214/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700226560533,
                "cdate": 1700226560533,
                "tmdate": 1700226560533,
                "mdate": 1700226560533,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ltns599DHB",
                "forum": "x2yFdUSJ4I",
                "replyto": "19KQUScnee",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission214/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission214/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "__II) Large Action Spaces__\n\nWe explain next how dTS is efficient in large action spaces using both theory and practice.\n\n- __Theory.__ Roughly speaking, the regret bound of dTS scales with $K \\sigma_1^2$, contrasting with the standard $K \\sum_{\\ell}\\sigma_\\ell^2$ scaling, which proves advantageous especially when $\\sigma_1$ is small, as often seen in diffusion models. In particular, the regret becomes independent of $K$ when $\\sigma_1=0$. Moreover, analysis in Section 4.1 shows that the performance gap between dTS and LinTS is more pronounced in large action spaces, highlighting its suitability for such scenarios. There are some works [1,2,3] where the regret does not depend on $K$. However, our setting differs significantly from [1,2,3], and the dependency on $K$ is unavoidable in our setting when $\\sigma_1>0$. Precisely, while [1,2,3] use a reward function $r(x, i) = \\phi(x, i)^\\top \\theta_*$ with a common $\\theta_*$ and a known mapping $\\phi$, our model employs $r(x, i) = x^\\top \\theta_{*, i}$, necessitating the learning of $K$ distinct $d$-dimensional parameters. In the setting of [1,2,3] with an available mapping $\\phi$, dTS\u2019s regret would be independent of $K$. However, the practical challenge of obtaining such a mapping, which must capture complex context-action relations, makes our setting relevant. For example, in recommendation systems, a product is often associated with its separate embedding. To summarize, the dependency on $K$ is intrinsic to our specific setting rather than a limitation of dTS.\n\n- __Experiments.__ dTS enjoys notable computational and statistical efficiency, especially in large action spaces (Section 4.1). For instance, our empirical findings, showcased in Figure 2 with $K=10^4$, reveal that dTS substantially surpasses the baselines. More importantly, as $K$ increases, so does the performance gap between dTS and the baselines, underscoring dTS's enhanced scalability and effectiveness in large action spaces.\n\n[1] \"Adapting to Misspecification in Contextual Bandits\" by Foster et al. NeurIPS 2021\n\n[2] \"Upper Counterfactual Confidence Bounds: a New Optimism Principle for Contextual Bandits\" by Xu et al. 2021\n\n[3] \"Contextual Bandits with Large Action Spaces: Made Practical\" by Zhu et al. ICML 2022"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission214/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700226809790,
                "cdate": 1700226809790,
                "tmdate": 1700227418362,
                "mdate": 1700227418362,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "MxsPIa7bKm",
            "forum": "x2yFdUSJ4I",
            "replyto": "x2yFdUSJ4I",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission214/Reviewer_hKWS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission214/Reviewer_hKWS"
            ],
            "content": {
                "summary": {
                    "value": "To capture the correlations between arms, this paper incorporates diffusion models into contextual linear bandits. For this model, the authors propose the diffusion Thompson sampling (dTS) algorithm, utilizing diffusion models as priors. Notably, when the diffusion model is parameterized by linear functions, closed-form expressions can be obtained for the sampling procedure. Both theoretical analyses and empirical experiments confirm the superiority of dTS."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The use of diffusion models to capture correlations between arms in contextual linear bandits is impressive and highly intriguing. Personally, I think this contribution holds significant value for the bandit community.\n2. Theoretical guarantees on Bayes regret are provided.  Section 4.1 compares dTS to other methods, clearly demonstrating its statistical and computational advantages under different scenarios."
                },
                "weaknesses": {
                    "value": "1. While overall well-written and easy to follow, there are certain parts where I have specific questions. Please refer to my detailed queries below. \n2. Despite the excellence of the proposed model, the theoretical contribution may be considered somewhat limited. Both the derivation of closed-form posteriors and the analysis of Bayes regret seem somewhat straightforward, given the existing works."
                },
                "questions": {
                    "value": "1. Equation (2): At this point, as the specification to the linear regret model has not been made, the Bayes regret should be defined based on the mean of the reward distribution. Furthermore, in the definition of $A_{t, \\*}$, neither the function $r()$ nor $\\Theta_\\*$ has been defined.\n2. In the case that $\\sigma_1=0$ ($\\theta_{\\*, i}$ is deterministic given $\\psi_{*, 1}$), since all the arm vectors are the same, is it true that the regret is always zero?\n3. Section 4.1: The rationale behind LinTS being suboptimal is evident. That is, LinTS needs to learn $K$ independent $d$-dimensional parameters, each with a considerably higher initial covariance $\\Sigma$. However, the grounds for HierTS being suboptimal are not fully elucidated. A mere comparison of upper bounds of regrets is not equitable. More fundamental reasoning is imperative.\n4. In Equation (16), it is beneficial to explicitly state that while $\\theta_{*, i}$ for $i\\in[K]$ follow the same normal distribution $\\mathcal{N}(0, \\Sigma)$, they are not independent."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission214/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission214/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission214/Reviewer_hKWS"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission214/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699093284383,
            "cdate": 1699093284383,
            "tmdate": 1700741123446,
            "mdate": 1700741123446,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "W2gTRTy7ks",
                "forum": "x2yFdUSJ4I",
                "replyto": "MxsPIa7bKm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission214/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission214/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for your positive feedback and valuable time. We address your comments and questions below. Please let us know if you have any additional questions.\n\n__I) Theoretical Contributions__\n\nWe have included a detailed discussion of the technical challenges and contributions in Appendix C.1. Below is a more succinct summary of these points.\n\n- __Lemma 2.__ In dTS, sampling is done hierarchically, and thus the marginal posterior distribution of $\\theta_i | H_t$ is not explicitly defined since we only use the conditional posterior distribution of $\\theta_i | H_t, \\psi_1$. Our first contribution was deriving the covariance of $\\theta_i | H_t$ using total covariance decomposition combined with an induction argument, as our posteriors in Section 3.1 were derived recursively. This differs from the standard Bayes regret, where the posterior distribution of $\\theta_i | H_t$ is predetermined due to the absence of latent parameters. Note that the total covariance decomposition was originally used in HierTS for multi-task linear bandits with a single latent parameter. Here, we extend it to contextual bandits with multiple, successive levels of latent parameters. Furthermore, our proof diverges from HierTS by incorporating linear functions ($W_\\ell\\psi_\\ell$), as opposed to HierTS's reliance on the more straightforward identity function $\\psi_\\ell$.\n\n- __Lemma 3.__ Standard Bayes regret analysis quantifies the posterior information gain from actions, particularly by examining the increase in posterior precision of the taken action $A_t$. Our proof, however, requires considering the information gain for each latent parameter, since they are also learned. Then, our contribution lies in using recursive formulas in Section 3.1 to propagate the posterior information gain of the taken action $A_t$ to all latent parameters within the range $\\ell \\in [L]$. This is not only novel but also technically challenging, as it combines recursive formulas, induction arguments, the Sherman\u2013Morrison formula, and properties of rank-1 matrices. This enables a nuanced quantification of how the information gain from a particular action can impact the learning of latent parameters.\n\n- __Proposition 1.__ Proposition 1 enhances Theorem 1's Bayes regret analysis through the sparsity assumption __(A3)__, which is grounded in the intuitive idea that sparsity leads to fewer parameters to learn, and hence smaller regret. This assumption refines regret to depend on the reduced dimensions $d_\\ell \\leq d$, instead of $d$. We adapt Theorem 1's proof by partitioning the covariance matrix of each latent parameter $\\psi_\\ell$ into two blocks: a $d_\\ell \\times d_\\ell$ block for learnable parameters and a $(d-d_\\ell) \\times (d-d_\\ell)$ block for non-learnable ones. This leads to the important finding that the final regret depends only on the learnable $d_\\ell$ parameter, leading to tighter regret and highlighting the impact of the sparsity assumption. \n\n__II) Other Questions__\n\n- __Typos and suggestions.__ We appreciate the reviewer pointing out these typos, and we fixed them in the revised version. To clarify, $\\theta_*$ represents the concatenation of all $K$ action parameters. Moreover, $r(x, i; \\theta_*)$ denotes the expected reward for action $i$ in context $x$. Also, we added that $\\theta_{*, i}$ are not necessarily independent in Eq. (16).\n\n- __Regret when $\\sigma_1=0$.__ When $\\sigma_1=0$, the regret is not always zero as it is not gap dependent. Our Bayesian regret does not capture this similarly to frequentist problem-independent regret bounds.\n\n- __Additional Intuitions.__ The intuition behind the improved performance of dTS compared to HierTS is due to sparsity, especially when the sparsity dimensions $d_\\ell$ are in decreasing order, such as $d_1>d_2>...>d_L$. Roughly speaking, rather than learning $d_1$ parameters with a high initial (marginal) variance, dTS learns $d_1$ parameters with a smaller initial variance, as the remaining initial variances are already incorporated in the learning of the other latent parameters, each characterized by its own small initial variance. This is why the sparsity assumption was introduced and it is key in the comparison with HierTS."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission214/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700254009984,
                "cdate": 1700254009984,
                "tmdate": 1700254009984,
                "mdate": 1700254009984,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oTZEWI0qWF",
                "forum": "x2yFdUSJ4I",
                "replyto": "W2gTRTy7ks",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission214/Reviewer_hKWS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission214/Reviewer_hKWS"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the response. I would like to provide some feedback for your consideration:\n\n- Regarding the Bayes regret in Equation (2), could you provide additional details on why the regret is not zero when $\\sigma_1=0$? A more thorough explanation would enhance the understanding of this aspect.\n\n-  I find that my initial confusion regarding the suboptimality of HierTS has been partially addressed by Reviewer S8eU. In my perspective, the models of HierTS and dTS should inherently be equivalent. While I understand that the formulation in (17) may be influenced by computational considerations, it seems unfair to compare their theoretical performances based on this. Therefore, I recommend that the authors clarify the parts related to HierTS for a more accurate understanding. The current presentation is misleading.\n\nI am keenly interested in the issues raised by Reviewer S8eU and **strongly** encourage the authors to engage in a discussion with Reviewer S8eU to address these concerns."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission214/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700547573296,
                "cdate": 1700547573296,
                "tmdate": 1700547573296,
                "mdate": 1700547573296,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Jc2dead6UM",
                "forum": "x2yFdUSJ4I",
                "replyto": "KnLbB47xxd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission214/Reviewer_hKWS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission214/Reviewer_hKWS"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your prompt reply.\n\n- I appreciate the clarification. I consistently refer to Bayes regret rather than the regret bound. It would be beneficial for the authors to explicitly differentiate between **regret** and **regret bound** in the manuscript.\n\n  Given that the Bayes regrets of both methods are zero, investigating the case where $\\sigma_1 = 0$ seems to lack significance. Neither the bound of LTS nor the bound of dTS can effectively capture this scenario.\n\n  Additionally, in the manuscript, the authors state, \"If we were to assume deterministic linearity ($\\sigma_1 = 0$), our regret bound would scale with L only and we provide this example in Section 4.1. Consistently, our empirical results in Section 5 match **all** these findings.\" I suggest modifying the last sentence since this particular case is not explored in Section 5.\n\n-  Thank you for the discussion with Reviewer S8eU. The discussion and the take shared by Reviewer S8eU are very valuable for enhancing my understanding of the work!\n\nBased on the preceding discussion, I tend to disagree with accepting this work at this time. However, I believe that improvements can be made to enhance the clarity and presentation of the contributions."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission214/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700735578934,
                "cdate": 1700735578934,
                "tmdate": 1700735578934,
                "mdate": 1700735578934,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "32mXSqid5p",
            "forum": "x2yFdUSJ4I",
            "replyto": "x2yFdUSJ4I",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission214/Reviewer_sz3T"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission214/Reviewer_sz3T"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies contextual bandits with large action spaces. With prior specified by a diffusion model, the authors designed diffusion Thompson Sampling (dTS) algorithm. The authors theoretically analyze the performance of dTS, and empirically verify its efficacy.\n\nAfter rebuttal: I have read the rebuttal and I'd like to keep my scores."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The authors provide the first theoretically analysis of Thompson Sampling under linear diffusion models, under certain assumptions. The authors also discuss the benefits from both computational and statistical aspects."
                },
                "weaknesses": {
                    "value": "Since this paper is mainly theoretical, can the authors highlight the technical contribution of this paper? More specifically, can authors elaborate on the differences in analysis between the standard Thompson Sampling? It seems that the main difference comes from the sampling of the latent parameters \\psi; but under linear diffusion model, posteriors of \\psi can be easily calculated.\n\nHow does the authors address the problem with large action spaces? It seems that both statistical and computational complexities depends on poly(K), which can be exponentially large for linear bandits. Note that recent work [1, 2, 3] have removed the dependency in K, and thus work for large action spaces.\n\n[1] \"Adapting to Misspecification in Contextual Bandits\" by Foster et al. NeurIPS 2021\n\n[2] \"Upper Counterfactual Confidence Bounds: a New Optimism Principle for Contextual Bandits\" by Xu et al. 2021\n\n[3] \"Contextual Bandits with Large Action Spaces: Made Practical\" by Zhu et al. ICML 2022"
                },
                "questions": {
                    "value": "See comments above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission214/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission214/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission214/Reviewer_sz3T"
                    ]
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission214/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699177197048,
            "cdate": 1699177197048,
            "tmdate": 1700777106413,
            "mdate": 1700777106413,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1g2EUScBPK",
                "forum": "x2yFdUSJ4I",
                "replyto": "32mXSqid5p",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission214/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission214/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for your positive feedback and valuable time. We address your comments and questions below. Please let us know if you have any additional questions.\n\n__I) Technical Contributions__\n\nWe have included a detailed discussion of the technical challenges and contributions in Appendix C.1. Below is a more succinct summary of these points.\n\n- __Lemma 2.__ In dTS, sampling is done hierarchically, and thus the marginal posterior distribution of $\\theta_i | H_t$ is not explicitly defined since we only use the conditional posterior distribution of $\\theta_i | H_t, \\psi_1$. Our first contribution was deriving the covariance of $\\theta_i | H_t$ using total covariance decomposition combined with an induction argument, as our posteriors in Section 3.1 were derived recursively. This differs from the standard Bayes regret, where the posterior distribution of $\\theta_i | H_t$ is predetermined due to the absence of latent parameters. Note that the total covariance decomposition was originally used in HierTS for multi-task linear bandits with a single latent parameter. Here, we extend it to contextual bandits with multiple, successive levels of latent parameters. Furthermore, our proof diverges from HierTS by incorporating linear functions ($W_\\ell\\psi_\\ell$), as opposed to HierTS's reliance on the more straightforward identity function $\\psi_\\ell$.\n\n- __Lemma 3.__ Standard Bayes regret analysis quantifies the posterior information gain from actions, particularly by examining the increase in posterior precision of the taken action $A_t$. Our proof, however, requires considering the information gain for each latent parameter, since they are also learned. Then, our contribution lies in using recursive formulas in Section 3.1 to propagate the posterior information gain of the taken action $A_t$ to all latent parameters within the range $\\ell \\in [L]$. This is not only novel but also technically challenging, as it combines recursive formulas, induction arguments, the Sherman\u2013Morrison formula, and properties of rank-1 matrices. This enables a nuanced quantification of how the information gain from a particular action can impact the learning of latent parameters.\n\n- __Proposition 1.__ Proposition 1 enhances Theorem 1's Bayes regret analysis through the sparsity assumption __(A3)__, which is grounded in the intuitive idea that sparsity leads to fewer parameters to learn, and hence smaller regret. This assumption refines regret to depend on the reduced dimensions $d_\\ell \\leq d$, instead of $d$. We adapt Theorem 1's proof by partitioning the covariance matrix of each latent parameter $\\psi_\\ell$ into two blocks: a $d_\\ell \\times d_\\ell$ block for learnable parameters and a $(d-d_\\ell) \\times (d-d_\\ell)$ block for non-learnable ones. This leads to the important finding that the final regret depends only on the learnable $d_\\ell$ parameter, leading to tighter regret and highlighting the impact of the sparsity assumption. \n\n__II) Large Action Spaces__\n\nWe thank the reviewer for the references, they were added to Appendix A. We explain next how dTS is efficient in large action spaces using both theory and practice, but more details can be found in Appendix A.\n\n- __Theory.__ Roughly speaking, the regret bound of dTS scales with $K \\sigma_1^2$, contrasting with the standard $K \\sum_{\\ell}\\sigma_\\ell^2$ scaling, which proves advantageous especially when $\\sigma_1$ is small, as often seen in diffusion models. In particular, the regret becomes independent of $K$ when $\\sigma_1=0$. Moreover, analysis in Section 4.1 shows that the performance gap between dTS and LinTS is more pronounced in large action spaces, highlighting its suitability for such scenarios.  Furthermore, our setting differs significantly from [1,2,3], and the dependency on $K$ is unavoidable in our setting when $\\sigma_1>0$. Precisely, while [1,2,3] use a reward function $r(x, i) = \\phi(x, i)^\\top \\theta_*$ with a common $\\theta_*$ and a known mapping $\\phi$, our model employs $r(x, i) = x^\\top \\theta_{*, i}$, necessitating the learning of $K$ distinct $d$-dimensional parameters. In the setting of [1,2,3] with an available mapping $\\phi$, dTS\u2019s regret would be independent of $K$. However, the practical challenge of obtaining such a mapping, which must capture complex context-action relations, makes our setting relevant. For example, recommendation systems, each product is associated with its embedding. To summarize, the dependency on $K$ is intrinsic to our specific setting rather than a limitation of dTS.\n\n- __Experiments.__ dTS enjoys notable computational and statistical efficiency, especially in large action spaces (Section 4.1). For instance, our empirical findings, showcased in Figure 2 with $K=10^4$, reveal that dTS substantially surpasses the baselines. More importantly, as $K$ increases, so does the performance gap between dTS and the baselines, underscoring dTS's enhanced scalability and effectiveness in large action spaces."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission214/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700225986786,
                "cdate": 1700225986786,
                "tmdate": 1700226245953,
                "mdate": 1700226245953,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]