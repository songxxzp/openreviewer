[
    {
        "title": "T-Rep: Representation Learning for Time Series using Time-Embeddings"
    },
    {
        "review": {
            "id": "F1IjqZ1rlk",
            "forum": "3y2TfP966N",
            "replyto": "3y2TfP966N",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5683/Reviewer_9kuw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5683/Reviewer_9kuw"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a time embedding method in representation learning on unlabeled time series data. Following existing contrastive learning framework, it proposes two new regressive tasks to induce the learned time embeddings to play a good role in the final representation. Experiments on three different task categories  are performed to support the effectiveness of the proposed designs. An analysis on the robustness to missing data is also provided."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The presentation of the paper is smooth and easy to follow. The limitation of the existing methods and the novel part in the proposed method is quite clear.\n2. Comprehensive experiment results are provided to show the versatility of the learned representations."
                },
                "weaknesses": {
                    "value": "1. The biggest flaw of the paper is the lack of ablation study, in my opinion. While sufficient quantitative results are provided to showcase the advantage of the proposed T-Rep, there is no clear evidence that support the effectiveness of the time embedding module, the very core highlighted in the paper. While the evidence in the analysis of robustness to missing data claims that the use of time embedding is leveraged to improve the contextual awareness and to fill the gap of the missing interval, but it is not supported by any rigorous analyses and remains a conjecture. \nExtensive ablation studies should be provided to compare the T-Rep with the baseline of TS2Vec and versions with either of the regressive pretext task removed. \n2. Above the flaw in empirical study, the idea of using time embedding to improve contrastive learning is not well-motivated. It is not clear why time embedding would be the ideal way to improve the latent temporal structure. See details in questions."
                },
                "questions": {
                    "value": "1. While the authors claim that time embedding $\\tau$ are induced to learn such time-related features as trend, periodicity etc. , they are function of the time indices and are unaware of the time series values. How could the aforementioned features be captured from indices only?\n2. I understand that $\\tau$ is normalized so that their difference can be measured by JSD. But there are alternative ways to measure the divergence without confining the norm of time embeddings. \n3. The task in Sec 4.2.1 aims to regress difference in the representation to the time distance. As stated in point 1, again, various pattern difference might be contained in the representations from arbitrary pairs of time series, therefore it's very likely that they can not regress to the consistent time distance. Same concern applies to the other task\n4. The claim that the two proposed task complement each other needs to be elaborated."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5683/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5683/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5683/Reviewer_9kuw"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5683/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698795679982,
            "cdate": 1698795679982,
            "tmdate": 1700686648456,
            "mdate": 1700686648456,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XWQ8AACkBs",
                "forum": "3y2TfP966N",
                "replyto": "F1IjqZ1rlk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5683/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5683/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Rewiewer 9kuw - Part 1"
                    },
                    "comment": {
                        "value": "We sincerely appreciate the positive feedback regarding the presentation of our paper. It is gratifying to hear that the content is smooth and easy to follow. We are also pleased that the limitations of existing methods and the novelty of our proposed approach are clearly communicated. We totally agree that the biggest flaw of the paper is the lack of ablation study, as explained in the global answer we are working on it and we will update the submission with these results in a few days.\n\n**Q1. While the authors claim that time embedding tau are induced to learn such time-related features as trend, periodicity etc. , they are function of the time indices and are unaware of the time series values. How could the aforementioned features be captured from indices only?**  \n\n**A1.** T-Rep is a parameterised function we are learning, containing a sub-module for learning time-embeddings from time indices, an a module for feature extraction from the time series, with all modules interconnected. Because the loss function used to train T-Rep is a joint function of the produced representations and time-embeddings, the loss backpropagates through the feature extractor as well as the time-embedding module. This makes the time-embedding \u2018aware\u2019 of the time series values, through the loss function\u2019s gradient (the loss is a function of the time series and the time indices).  \n\nThe loss function is given by the pretext tasks, which have been designed to encourage the time-embeddings to contain meaningful information about the time-series (particularly the \u2018Time-embedding conditioned forecasting\u2019 task, see section 4.2.2 for more details). This consequently pushes the time-embedding to contain time-related features.  \n\nNow the nature of the features (e.g. trend, periodicity etc.) is, we believe, not only influenced by the pretext tasks but also by the choice of time-embedding architecture. For example, for forecasting and anomaly detection, we use Time2Vec (https://arxiv.org/abs/1907.05321). This architecture is quite interpretable: the first component of the time-embedding vector is a linear function, which Time2Vec authors claim learns the trend of the time-series. The other components are sinusoidal features with learned period and phase-shift, aiming to capture periodicity in the data at different scales.   \n\nWe hope this addresses your question. If you want more details, we encourage you to look at Time2Vec (https://arxiv.org/abs/1907.05321), which was the first paper to introduce this idea of learning a time-embedding module or function alongside the feature extractor/predictor.\n    \n**Q2. I understand that tau is normalized so that their difference can be measured by JSD. But there are alternative ways to measure the divergence without confining the norm of time embeddings.**  \n\n**A2.** Thank you for this very relevant question, which we thoroughly addressed during the model design process. Indeed, there are alternative ways to measure divergence without restricting the norm of time embeddings, but we haven't found any that provide as much satisfaction as the Jensen-Shannon Divergence (JSD). We explored the use of Kullback-Leibler Divergence, but it has some significant drawbacks: it is not symmetric, sensitive to zero values, and not defined on disjoint distributions. We also attempted to employ Wasserstein distance, but it proved computationally expensive, especially in high-dimensional spaces, leading us to quickly dismiss this option. The JSD appeared to be the best compromise, but we are open to suggestions if you believe that alternative approaches would be more relevant."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5683/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700151088802,
                "cdate": 1700151088802,
                "tmdate": 1700151088802,
                "mdate": 1700151088802,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "r7Oewp6wAw",
                "forum": "3y2TfP966N",
                "replyto": "lQmNc4SmIj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5683/Reviewer_9kuw"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5683/Reviewer_9kuw"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the detailed response."
                    },
                    "comment": {
                        "value": "I appreciate author's detailed response to my questions. Overall my concern is mostly about the ablation study, and as it has been provided, I am happy to adjust my rating. \n\nRegarding the answers to generalizability of time embedding (Q1 and Q3), I agree that periodicity of a specific task/dataset can be fitted with Time2Vec as it learns to project a periodical time series onto a set of Fourier bases. However, trend is not easy, if it's not impossible at all, to be fitted given the great variety by a single linear term. In fact, the original Time2Vec paper (arxiv: 1907.05321) did not articulate the ability of learning \"trends\". They only claim the linear term, i.e. the first dimension of the embedding, \"can model nonperiodic components and helps with extrapolation\". Therefore I believe \"capturing trends\" in this paper is somewhat over-claimed."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5683/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700686619148,
                "cdate": 1700686619148,
                "tmdate": 1700686619148,
                "mdate": 1700686619148,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "kfFZ8qbmDd",
            "forum": "3y2TfP966N",
            "replyto": "3y2TfP966N",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5683/Reviewer_5x3c"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5683/Reviewer_5x3c"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a sef-supervised representation learning method with a temporal, timestep granularity. The model is a linear projection layer and time embedding module that is fed into a dilated convolutional encoder. This representation is then used by four pretext tasks, two of which (time-embedding divergence prediction and time-embedding conditioned forecasting) are introduced in this paper. A linear combination of the pretext task losses is then used to compute a hierarchical loss. The paper evaluates the approach on different downstream tasks, including anomaly detection, forecasting, and classification. Additionally, the model authors show that the model is robust to missing data and qualitatively visualize the time evolution of the representation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "### Originality\nIntroducing the temporal structure into time series representations are an important problem. This paper attempts to capture the time evolution with two additional pretext tasks and a time embedding module. These components are well reasoned and appear to result into a representation that can be successfully leveraged in tasks that require timestep granularity (forecasting, anomaly detection) and tasks that might not necessarily need it (classification).  \n\n### Quality\nThe discussion of the related work covers related articles well and summarizes the gap in learning temporal resolution in representation learning for time series. The experimental section covers standard benchmarks for anomaly detection, forecasting, and classification. I think the experimental evaluation has some weaknesses, which I will elaborate in the Weaknesses section. \n\n### Clarity\nThe paper is well written. The introduction and related work clearly introduces the challenges and previous work in this space and points out the specific challenge that the paper aims to address (learning timestep granular representations that work for several downstream tasks). The experimental section is also well written and easy to follow. \n\n### Significance\nTime series representation learning is an important problem. Previous work focused on classification or other tasks that don't require timestep granularity of the embeddings, while some applications (like forecasting) would require this. This paper represents a significant step into this direction of universal time series embeddings that are useful for several different applications."
                },
                "weaknesses": {
                    "value": "The paper has two weaknesses in the experimental evaluation: Missing ablation experiments and choice of baselines. \n\n### Ablation study \n\nThe method presented in this work shares several components with TS2Vec (linear projection layer, dilated convolution encoder, instance-wise/temporal contrasting, and the hierarchical loss). It would be beneficial for the readers to point out the common components of T-Rep and TS2Vec. It would also be interesting for the reader to understand, which of the additional components introduced in this work actually improved the performance, but an ablation study to investigate this is missing. My understanding is that the additional pretext tasks require the time embedding (TE) module, so factoring that out for ablation is probably difficult. However, testing the impact of the pretext tasks setting the weights of the linear combination loss for the TE-conditioned forecasting and/or TE-divergence prediction should be straightforward. I would kindly ask the authors to add these ablation results. I would consider raising my score if the ablation study is added. \n\n\n### Choice of baselines \n\nFor the forecasting experiments, the authors use the benchmark introduced by Zhou et al., AAAI 2021 is a common benchmark in forecasting. However, several iterations on transformer architectures have been published since this work, some of which are even outperformed by linear baselines (Zeng et al., AAAI 2022). Given that the forecasting task introduced here is a linear regression layer using the time series embeddings, it would be good to understand the gain in performance relative to the linear methods (N-Linear and D-Linear) that are introduced in Zeng et al., AAAI 2022. I would kindly ask the authors to consider these baselines. \n\nFor classification, Minirocket (Dempster at al., KDD 2021) is a simple and fast baseline for practical applications and it would be interesting to understand the gain in accuracy from T-Rep over Minirocket."
                },
                "questions": {
                    "value": "Appendix A.2 mentions that each models are run 10 times but also notes \"Also, we do not use any random seed, (...)\". I'm unsure what this means. Are all experiments started from the same seed or are ten (fixed) seeds used here? I would kindly ask the authors to clarify that."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5683/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5683/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5683/Reviewer_5x3c"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5683/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698930382191,
            "cdate": 1698930382191,
            "tmdate": 1700671449752,
            "mdate": 1700671449752,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CVV7BjK11t",
                "forum": "3y2TfP966N",
                "replyto": "kfFZ8qbmDd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5683/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5683/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 5x3c"
                    },
                    "comment": {
                        "value": "We appreciate your very detailed review and the attention given to our submission. We are pleased that you found our presentation excellent and the paper easy to read. Regarding the ablation study, as mentioned in the overall response, we are in the process of finalizing it to add these results to the article because we completely agree that it is a crucial experiment to include in our submission. \nIn the same manner, we are in the process of adding the baselines you suggest.  \n\nHaving started the ablation study, we can already provide you with results of the ablation study on the forecasting task. We observe that the two pretext tasks complement each other well: if only one of them is used, the performance is lower than using none, and significantly lower than using both. Additionally, we can see that the time-embedding (TE) module effectively enhances performance, and it is the combination of these elements (TE + 2 proposed pretext tasks) that allows us to outperform the state-of-the-art TS2Vec.\n\n|                                   | Forecasting |\n|-----------------------------------|-------------|\n|                                   | Avg. MSE    |\n|-----------------------------------|-------------|\n| **T-Rep**                          | **0.986**   |\n|-----------------------------------|-------------|\n| *Pretext tasks*                    |             |\n| w/o TE-conditioned forecasting    | 1.022 (+3.7%) |\n| w/o TE divergence prediction       | 1.003 (+1.7%) |\n| w/o New pretext tasks               | 0.999 (+1.3%) |\n|-----------------------------------|-------------|\n| *Architecture*                     |             |\n| w/o TE module (=TS2Vec)            | 1.004 (+1.8%) |\n\n*Ablation results on ETT forecasting dataset. The percentage changes are calculated as the relative difference between the modified model's performance and T-Rep's performance.*\n\n\n\n**Q1. Appendix A.2 mentions that each models are run 10 times but also notes \"Also, we do not use any random seed, (...)\". I'm unsure what this means. Are all experiments started from the same seed or are ten (fixed) seeds used here? I would kindly ask the authors to clarify that.**\n\n**A1.** Thank you for raising this point, which seems to lack clarity in our article and was also highlighted by reviewer rWLt. Instead of fixing a seed, which has the disadvantage of not accounting for the variance that may exist between two seeds, we chose to run each experiment between 10 and 20 times to address variance and obtain reliable results. The reported results represent the average of these runs. This approach maximizes the reliability and robustness of our results, avoiding the selection of a specific seed that might produce the best results. During our 10 or 20 runs, the seed is set to \"None.\" When the seed is set to None, PyTorch utilizes the system time or another unpredictable source to initialize the random number generator. Consequently, each time you run the program, you are likely to get different random numbers.\n\n*If our responses and revisions meet your expectations, we would greatly appreciate it if you could consider revising your evaluation accordingly. Thank you for your time and thorough review.*"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5683/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700150877287,
                "cdate": 1700150877287,
                "tmdate": 1700150877287,
                "mdate": 1700150877287,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RZ8AnyEpni",
                "forum": "3y2TfP966N",
                "replyto": "9D1N7xzON8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5683/Reviewer_5x3c"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5683/Reviewer_5x3c"
                ],
                "content": {
                    "title": {
                        "value": "Response to Rebuttal"
                    },
                    "comment": {
                        "value": "I would like to thank the authors for adding additional experiments and analysis for their paper. My points have been addressed and I will increase my score. \n\nHowever, I think with the additional baselines for forecasting and classification, it appears that the proposed model only performs slightly better (forecasting) and sometimes worse or better in classification (depending on the metric). In essence, the performance is close to baselines. The paper still has its merits in being a representation method that appears to work across tasks when compared to task-specific models. \n\nGiven that the standard error/confidence interval is not accounted for in this paper to test whether the performance differences are statistically significant, I would suggest that the authors make sure the language chosen does not suggest that. For example: \"Table 2 shows that T-Rep beats TS2Vec by 2.1% and Minirocket by `4.8% on average, a significant margin.\" suggests that some sort of significant testing is performed (which is not as far as I can tell). I think the paper still has its merits and the method is on-par with task-specific baselines, which I think is sufficient for publication."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5683/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700671430424,
                "cdate": 1700671430424,
                "tmdate": 1700671430424,
                "mdate": 1700671430424,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "BbypRcymac",
            "forum": "3y2TfP966N",
            "replyto": "3y2TfP966N",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5683/Reviewer_znEu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5683/Reviewer_znEu"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes T-Rep, a self-supervised method for learning time series representations at the timestep level. The key innovation of T-Rep is the use of learnable time embeddings in pretext tasks to learn detailed temporal dependencies and robustness in time series representations. Experiments demonstrate improved performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper proposes T-Rep, a self-supervised method for learning representations of time series at the timestep level.\n\nT-Rep learns vector embeddings of time called \"time-embeddings\" alongside its feature extractor encoder. The time-embeddings help capture temporal features like trend, periodicity, distribution shifts.\n\nThe time-embeddings are incorporated into pretext tasks to learn fine-grained temporal dependencies and make the model robust to missing data. Two new pretext tasks are proposed: time-embedding divergence prediction and time-embedding-conditioned forecasting.\n\nT-Rep is evaluated on downstream tasks of classification, forecasting, and anomaly detection. It outperforms previous self-supervised methods like TS2Vec, showing the benefit of time-embeddings.\n\nT-Rep is more robust to missing data than methods like TS2Vec. Visualizations show T-Rep can produce smooth representations even with missing timesteps."
                },
                "weaknesses": {
                    "value": "The choice of time-embedding architecture is not well motivated or analyzed. Different architectures are used for different tasks, but it is unclear why they perform best in each case. More ablation studies on the time-embedding design could strengthen this key component.\n\nThe pretext tasks using time-embeddings seem somewhat ad-hoc. While they demonstrate the utility of time-embeddings, developing more principled pretext tasks derived from intrinsic properties of time series could be beneficial.\n\nThe comparison to previous methods like TS2Vec is not entirely fair, as T-Rep uses a larger encoder architecture. Comparisons with a TS2Vec model of comparable complexity could better isolate the benefits of the time-embeddings. Besides, the composition on TimeNet and PatchTST on SOTA ETT dataset is necessary.\n\nThe treatment of missing data is a major claimed contribution, but the missing data experiments are limited. More systematic tests on real-world messy data with different missing data types could better showcase these abilities.\n\nThe interpretability of representations is claimed but only briefly demonstrated with some visualizations. More analysis connecting latent dimensions to meaningful time series properties could better support the interpretability claims.\n\nThe classification task does not standalone evaluate the quality of the learned representations. Adding unsupervised evaluations like clustering could help assess representation quality."
                },
                "questions": {
                    "value": "See the weekness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "-"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5683/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5683/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5683/Reviewer_znEu"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5683/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698977685791,
            "cdate": 1698977685791,
            "tmdate": 1699636593619,
            "mdate": 1699636593619,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Azn56VLw8K",
                "forum": "3y2TfP966N",
                "replyto": "BbypRcymac",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5683/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5683/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer znEu - Part 1"
                    },
                    "comment": {
                        "value": "Thank you very much for all your highly relevant suggestions, motivating experiments that significantly enhance the quality of the article. We appreciate your considerations regarding interpretability and the quality of representations, which align with those of reviewers 99iS and rWLt.   \nCurrently, we are conducting experiments to demonstrate the meaningful time series properties of latent dimensions, and we will send you the results in the next few days.   \nSimilarly, we are incorporating comparisons with the baselines you suggest, and we are working on highlighting the robustness of our model to missing data, with a new real-world anomaly detection dataset.\n\n**Q1. The choice of time-embedding architecture is not well motivated or analyzed. Different architectures are used for different tasks, but it is unclear why they perform best in each case. More ablation studies on the time-embedding design could strengthen this key component.**  \n\n    \n**A1.** Thank you for pointing out this issue. The field of time-embeddings is very recent and little literature exists. The most famous time-embedding architecture is Time2Vec (https://arxiv.org/abs/1907.05321), which we use in forecasting and anomaly detection tasks. This architecture is actually relatively interpretable: the first component of the time-embedding vector is a linear function, which Time2Vec authors claim learns the trend of the time-series. The other components are sinusoidal features with learned period and phase-shift, aiming to capture periodicity in the data at different scales. This focus on learning a dataset\u2019s inherent trend and periodicity explains why it helps the T-Rep outperform its counterparts in the forecasting and anomaly detection tasks.  \nGenerally speaking, constrained time-embedding architectures (i.e. sinusoidal form, linear, RBF features) will tend to be more interpretable than their very expressive but more \u2018black-box\u2019 MLP-based counterparts.   \nWe believe MLP-based time-embeddings outperform sinusoidal ones in classification (and other instance-wide tasks) because they can capture more \u2018global\u2019 and coarse features of a time-series instance\u2019s temporal structure, allowing T-Rep differentiate different instances of a dataset more easily in downstream tasks. This is a result of the expressivity of MLPs and the lack of constraint on the features they can extract, compared to sinusoidal or RBF-based time-embedding architectures. It is very hard to give more rigorous explanations, as the learned features are not human-interpretable.  \nOverall, we agree that there is limited understanding of why time-embeddings behave differently depending on the task. This is because it is a new niche of machine learning which has not been studied in great depth, and few people have experimented with thus far (we haven\u2019t come across any papers using them in classification).  \n    \n**Q2. The pretext tasks using time-embeddings seem somewhat ad-hoc. While they demonstrate the utility of time-embeddings, developing more principled pretext tasks derived from intrinsic properties of time series could be beneficial.**  \n\n**A2.** Thank you for your highly relevant question, which happens to be one of the main avenues of our future work. We completely agree that these pretext tasks are ad-hoc, and our intention was to experimentally verify their relevance before delving into the theoretical foundation of these pretext tasks using time embeddings. We are particularly interested in this aspect, which will be the focus of our upcoming work.\n\n**Q3. The comparison to previous methods like TS2Vec is not entirely fair, as T-Rep uses a larger encoder architecture. Comparisons with a TS2Vec model of comparable complexity could better isolate the benefits of the time-embeddings. Besides, the composition on TimeNet and PatchTST on SOTA ETT dataset is necessary.**  \n\n**A3.** That is absolutely true, thank you for noting this point. We use a layer of 128 instead of 64 to facilitate the concatenation of the time embedding to the time series (an issue TS2Vec does not have to deal with). We considered that these dimensions, while larger, are still \"small\" (we are not in the range of 2048, for instance), making it acceptable.   \n\nWe have begun implementing the pipeline to compare PatchTST on the state-of-the-art ETT forecasting dataset. This will be included in the final version of the article, and we hope to present the results to you by the end of the discussion period. Based on our understanding, TimeNet cannot be included in this comparison as it has been developed for classification, and not for tasks requiring timestep granularity, such as forecasting. Do you think this comparison is really necessary despite this aspect?"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5683/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700150523568,
                "cdate": 1700150523568,
                "tmdate": 1700150523568,
                "mdate": 1700150523568,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zyLqPgG6vM",
                "forum": "3y2TfP966N",
                "replyto": "9wkb9fiFzG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5683/Reviewer_znEu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5683/Reviewer_znEu"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "Dear Authors,\n\nThanks for your efforts on replying my comments. While most of the concerns are addressed, I cannot see any of the updates of my Q3. Note that the comparison with state-of-the-art works is important which will help to position this paper. I would like to hear all the potential helpful updates or discussions on this issue.\n\nTherefore, I tend to stick my score at current stage.\n\nBest"
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5683/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700707635643,
                "cdate": 1700707635643,
                "tmdate": 1700707635643,
                "mdate": 1700707635643,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Nbe84tnJEQ",
            "forum": "3y2TfP966N",
            "replyto": "3y2TfP966N",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5683/Reviewer_rWLt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5683/Reviewer_rWLt"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a time series representation learning methodology based on self-supervision. The paper identifies two key issues with current time-series embedding using contrastive learning which -- a) aims to embed entire trajectories based on a binary notion of similarity vs. dissimilarity, ignoring temporal structure, and b) incompatibility with systems which switch between states, where notions of similarity vs. dissimilarity are based on states. They propose two pretext tasks to address these issues. \n\n\nOverall, I think the paper is very well written and motivated, except a few things that can really improve the quality. I hope authors can address these in the discussion."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper is very well motivated, I congratulate the authors on explaining the issues with contrastive learning in the context of time-series. \n2. The paper is overall well-written and easy to follow. \n3. Experiments are set-up well except that monte-carlo simulations are missing."
                },
                "weaknesses": {
                    "value": "1. The results are not repeated across random seeds, which significantly impacts the confidence in the method. \n2. Visualizations: since the paper centers around time series representation learning, it would have been extremely valuable to see t-SNE plots of the learned embeddings to see how T-Rep performs over SOTA (TS2VEC) and others. \n3. There are a number of moving parts, and some level of ablations are expected, but missing. For instance, impact of overlap in contexual consistency etc."
                },
                "questions": {
                    "value": "1. How may dataset are used for anomaly detection (sec 5.1)?\n2. How does the issues of similarity/dissimilarity play out in multivariate settings? What if the switching behaviour is only present in a few of the channels?\n3. Why does T-Rep perform better in some cases and not it others? For instance, in Table 5 in ETTh_2 T-Rep performs better at larger horizons, while being significantly worse at lower ones. This is counter-intuitive, since in section 4.2.2. the paper mentions that the pretext forecasting task specifically aims to predict shorter horizons.\n4. It seems that the methods requires supervision in pretest task 4.2.1 and not in 4.2.2 for the pretext task, can the authors comment on potential use of T-Rep in completely unsupervised pretraining?\n5. How much overlap do we need for contextual consistency? How is this parameter decided? \n6. In section 3, the terms such as contextual consistency and heirarchical loss are only defined intuitively. These need to be defined in terms of their mathematical formulation(s). Currently, these are difficult to understand. Furthermore, it is also unclear how this plays out mathematically in linear projection layer. \n7. What is the mathematical action of TCN layer, and what is its role?\n\n\nMinor: \n1. Fig. 1 uses yellow against a whote background is difficult to read."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5683/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699142102810,
            "cdate": 1699142102810,
            "tmdate": 1699636593526,
            "mdate": 1699636593526,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1rf3MlYQP7",
                "forum": "3y2TfP966N",
                "replyto": "Nbe84tnJEQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5683/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5683/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer rWLt - Part 1"
                    },
                    "comment": {
                        "value": "Thank you for taking the time to review our article, and we sincerely appreciate your thoughtful comments. Your positive remarks on the motivation and clarity of our paper are encouraging, and we are pleased that you found the overall presentation to be well-written and easy to follow. We are currently working on the final experiments for visualizations and the ablation study, as you recommended and as explained in the common answer. In the meantime, here are the answers to your various questions:\n\n**Q1. How many datasets are used for anomaly detection (sec 5.1)?**  \n**A1.** The Yahoo Dataset, consisting of 367 synthetic and real univariate time series featuring outlier and change point anomalies, was used for the anomaly detection task. To address the comments from the reviewers, especially reviewers 99iS and znEu, we are currently replicating our experiments on the 'Sepsis' dataset from The PhysioNet/Computing in Cardiology Challenge 2019, which contains multivariate data sourced from 40 000 Intensive Care Unit patients in three separate hospital systems. We chose this dataset because it contains real-life data, includes missing data, and anomalie appear by segment. Link of the dataset can be found here: https://journals.lww.com/ccmjournal/fulltext/2020/02000/early_prediction_of_sepsis_from_clinical_data__the.10.aspx.  \n We will have the results shortly, providing us with a second dataset for anomaly detection.  \n\n**Q2. How does the issues of similarity/dissimilarity play out in multivariate settings? What if the switching behaviour is only present in a few of the channels?**\n    \n**A2.** This issue of similarity and dissimilarity in contrastive learning is treated the same way for univariate and multivariate settings. The semantic choice of which instances should be similar/dissimilar is entirely dependent on the method developed and the problem at hand. For example, in time-series it is common to want to represent two samples from nearby timesteps similarly. However, the way in which the similarity/dissimalirity of representations is evaluated is the same for univariate/multivariate: a dot product is computed between two representation vectors as a measure of similarity.  \n    \nWith regards to the state switching issue, this happens regardless of the number of affected channels. The issue with contrastive learning and finite-state systems is the pair selection process: in the introduction of our paper, we explain that contrastive learning tasks \u201cdefine positive pairs by proximity in time, and negative pairs by points that are distant in time (Banville et al., 2021; Franceschi et al., 2019), which can incur sampling bias issues. Points of a negative pair might be far in time but close to a period apart (i.e. very similar) and points of a positive pair might be close but very different (think of a pulsatile signal for example).\u201d Whether the switching state behaviour is present in a few or all channels, this information will be lost during training because of the pair selection process.\n    \n**Q3. Why does T-Rep perform better in some cases and not it others? For instance, in Table 5 in ETTh_2 T-Rep performs better at larger horizons, while being significantly worse at lower ones. This is counter-intuitive, since in section 4.2.2. the paper mentions that the pretext forecasting task specifically aims to predict shorter horizons.**\n\n**A3.** We appreciate this question, which we also considered during our experiments. We lack both theoretical and experimental evidence for why T-Rep performs better on longer horizons. However, our intuition leads us to believe that on a short horizon, we are still within a Markovian process, with the major dependence on the preceding moment. On a longer horizon, periodic processes come into play, and the model excels through its handling of time embeddings. This, however, remains speculative, and extensive experiments will need to be conducted in future work to confirm this.\n\n**Q4. It seems that the methods requires supervision in pretest task 4.2.1 and not in 4.2.2 for the pretext task, can the authors comment on potential use of T-Rep in completely unsupervised pretraining?**\n\n**A4.** It may not be expressed clearly enough in the article, but we confirm that both pretext task (4.2.1 and 4.2.2) are supervised. T-Rep as a whole is trained on datasets without labels (there is an \u2018X\u2019, but no \u2018y\u2019), so the training of this model can be regarded as unsupervised. However, it relies on the creation of artificial supervisory signals constructed from the given \u2018X\u2019. These artificial supervisory signals are what we call \u2018pretext tasks\u2019, and do not require any data or information beyond the given dataset \u2018X\u2019. This duality between not using any labels for the dataset but creating artificial supervised signals (=pretext tasks) to train the model resulted in the field\u2019s name, \u201cSelf-supervised learning\u201d: the supervision in pretext tasks originates from the input data."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5683/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700149495189,
                "cdate": 1700149495189,
                "tmdate": 1700149495189,
                "mdate": 1700149495189,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "TV2DeFfwA2",
            "forum": "3y2TfP966N",
            "replyto": "3y2TfP966N",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5683/Reviewer_99iS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5683/Reviewer_99iS"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a self-supervised way of learning latent representations of variable length time series data that are useful for various downstream tasks like time series anomaly detection, forecasting and classification. The authors propose two surrogate loss functions in form of 'pretext tasks' that influence the learned representation/embedding to persist temporal consistency in latent space along with information to forecast, and thus be robust to missing data. The results are demonstrated on three downstream tasks where T-Rep outperforms the SOTA time series representation learning methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Below are the strengths of this proposed work: \n1. The problem is highly relevant to the time series research community and well motivated by the authors. They also do a good job at covering the related work and highlighting the necessity of temporal robustness in the representations that's usually overlooked when learning time series representation. \n2. The authors introduce surrogate loss functions to train the representation model in a self supervised manner which they refer to as 'pretext tasks'. The two loss functions (although not novel) are practically reasonable given the need of temporal consistency and predictability in the learned representations. \n3. Authors do a good job of testing T-Rep across three key downstream tasks which helps in validating the usefulness of learned representation as task-agnostic."
                },
                "weaknesses": {
                    "value": "Following are weaknesses of this work: \n1. The effectiveness of the proposed method relies on the evaluation done mainly on UCR/UEA and Yahoo Datasets which are infamous for their incorrectness, and triviality in labels. Refer: https://arxiv.org/pdf/2009.13807.pdf. This questions the effectiveness of the proposed method and how well would it work in real-world scenarios?\n2. Similar to Pt.1, I feel the downstream benchmarks are bit too trivial to test the true effectiveness/usefulness of a representation learning method. For e.g., in the task of anomaly detection, the authors propose to use a simple point-based evaluation method which is not realistic, as real world anomalies are usually segment based and need more rigorous evalution to demonstrate usefulness. Refer: https://arxiv.org/pdf/2109.05257.pdf. \n3. In Sec 5.5, I get that one can manually look at the heatmaps to infer similarities between the patterns in raw time series signal and the learned representation but I didn't fully understand the usefulness of that? Can I just look at the heatmap and use that information? if so, how? Manually matching pattern is pleasing but I don't see any usability, and hence don't see any true interpretability coming out of it."
                },
                "questions": {
                    "value": "My questions can be found in Weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5683/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699516726452,
            "cdate": 1699516726452,
            "tmdate": 1699636593410,
            "mdate": 1699636593410,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "BLZp5UhxTE",
                "forum": "3y2TfP966N",
                "replyto": "TV2DeFfwA2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5683/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5683/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 99iS"
                    },
                    "comment": {
                        "value": "We appreciate your insightful review of our paper. We have diligently addressed each of your comments point by point, aiming to enhance the overall quality of our work in response to your valuable feedback.\n\n**Q1. The effectiveness of the proposed method relies on the evaluation done mainly on UCR/UEA and Yahoo Datasets which are infamous for their incorrectness, and triviality in labels. Refer:\u00a0https://arxiv.org/pdf/2009.13807.pdf. This questions the effectiveness of the proposed method and how well would it work in real-world scenarios?\nQ2. Similar to Pt.1, I feel the downstream benchmarks are bit too trivial to test the true effectiveness/usefulness of a representation learning method. For e.g., in the task of anomaly detection, the authors propose to use a simple point-based evaluation method which is not realistic, as real world anomalies are usually segment based and need more rigorous evalution to demonstrate usefulness. Refer: https://arxiv.org/pdf/2109.05257.pdf.**\n\n**A1 and A2.** We acknowledge the concerns you raised regarding the datasets used for anomaly detection evaluation and the behavior of the model in real-world scenarios. We are aware of the limitations of these datasets, and we have recently become acquainted with them.  We completely agree with the necessity of working with less trivial datasets.\n\nTo address those 2 questions, we are currently testing our model on the 'Sepsis' dataset from The PhysioNet/Computing in Cardiology Challenge 2019, which contains multivariate data sourced from ICU patients in three separate hospital systems. We chose this dataset because it contains real-life data, includes missing data, and anomalies appear by segment. We are, in fact, implementing the PA%K protocol presented in the article you suggested (Towards a Rigorous Evaluation of Time-series Anomaly Detection, Kim et al., https://arxiv.org/pdf/2109.05257.pdf.), which helps alleviate the overestimation effect of point-based evaluation methods.  \nThis allows us to address both your concerns regarding the Yahoo Dataset while demonstrating that our T-Rep model is effective in real-world scenarios with messy data. \nLink of the dataset can be found here: https://journals.lww.com/ccmjournal/fulltext/2020/02000/early_prediction_of_sepsis_from_clinical_data__the.10.aspx  \nWe will communicate our results to you as soon as possible and include them in the article\n\n**Q3. In Sec 5.5, I get that one can manually look at the heatmaps to infer similarities between the patterns in raw time series signal and the learned representation but I didn't fully understand the usefulness of that? Can I just look at the heatmap and use that information? if so, how? Manually matching pattern is pleasing but I don't see any usability, and hence don't see any true interpretability coming out of it.**\n\n**A3.** What this heatmap shows is two-fold. \n\nFirstly, it serves as a valuable sanity check by offering a qualitative means of verifying the preservation of information and properties from the original signal in the representations. To give an example, this can be used by a data scientist working on a change point detection model to see if there's an abrupt change in the probability distribution of the signal.  \n\nSecondly, it shows that the features extracted by the model are interpretable: we can visually see that variations in the representation vectors correspond to human-interpretable features such as periodicity, variance, anomalies, distribution shifts etc. One could imagine that the model learns features which aren\u2019t human interpretable. For instance, in a CNN, the first few layers tend to capture high-level features like edges or textures, but the last few layers learn more abstract and complex features, which we can\u2019t visually make sense of. It is very positive to us to see that this is not the case with T-Rep and that the extracted features can be visually interpreted and matched with properties of the original signal. Whilst we agree one shouldn\u2019t rely on visual pattern matching, this provides advantages by providing visual support. We agree this visual aid is not sufficient for downstream tasks, where we rely on comparing representations quantitatively rather than qualitatively.\n  \n\n\n*If our responses and revisions meet your expectations, we would greatly appreciate it if you could consider revising your evaluation accordingly. Thank you for your time and thorough review.*"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5683/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700149267742,
                "cdate": 1700149267742,
                "tmdate": 1700149267742,
                "mdate": 1700149267742,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kpxlviGv6A",
                "forum": "3y2TfP966N",
                "replyto": "TV2DeFfwA2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5683/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5683/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 99iS - Experiments"
                    },
                    "comment": {
                        "value": "We have now conducted the experiment you requested, which you can find in section 5.1 of the paper in blue.   \nThe results on the Sepsis dataset confirm that T-Rep performs better than TS2Vec and a linear baseline on a dataset different from UCR/UEA and Yahoo Datasets. The proposed method has a great effectiveness in a real-world scenario and on non-trivial downstream benchmarks, even when using an evaluation method that is not point-based. \nWe have also added the two references you suggested. \n\nThank you for proposing this improvement.\n\n*If our adjustments meet your expectations, we would greatly appreciate it if you could consider revising your evaluation accordingly. Thank you for your time and thorough review.*"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5683/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700653718752,
                "cdate": 1700653718752,
                "tmdate": 1700654331989,
                "mdate": 1700654331989,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]