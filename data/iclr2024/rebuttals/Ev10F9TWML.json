[
    {
        "title": "Dissecting Neural Network Robustness Proofs"
    },
    {
        "review": {
            "id": "S3osBQH70R",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3862/Reviewer_UvmS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3862/Reviewer_UvmS"
            ],
            "forum": "Ev10F9TWML",
            "replyto": "Ev10F9TWML",
            "content": {
                "summary": {
                    "value": "This paper proposes the method ProFIt to extract a set of proof features by retaining only the more important parts of the proof that preserves the property and then conducts experiments to explore the selected features for standard trained / adversarial trained / certifiable trained neural networks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed method is novel and theoretically guaranteed.\n- The experiments validate the sufficiency of the proposed method."
                },
                "weaknesses": {
                    "value": "- The proposed algorithm seems only valid for the linear property, how can we deal with the nonlinear properties?\n- My main concern is the meaning of this task.\n  - The selected features are the most relevant to the predefined linear property. However, there are many other properties of a neural network, different properties lead to different sufficient proof features. So, the features selected by one property may only reflect one perspective of the neural network. Such a \"local\" interpretation may be misleading.\n  - Can sufficient proof features provide intuitions on how to design a training method to train a model with such a property? I think this need to be discussed."
                },
                "questions": {
                    "value": "See the weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3862/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3862/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3862/Reviewer_UvmS"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3862/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697427730822,
            "cdate": 1697427730822,
            "tmdate": 1699636344646,
            "mdate": 1699636344646,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7YExI0TLox",
                "forum": "Ev10F9TWML",
                "replyto": "S3osBQH70R",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3862/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3862/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1. how can we deal with the nonlinear properties?**\n\n**R1:** Existing works [1, 2] that handle non-linear properties typically compute a linear approximation of these properties and utilize existing DNN verifiers designed for linear specifications. For instance, in [1], when verifying robustness against geometric perturbations like rotation, an overapproximated convex input region is computed, specified by a set of linear inequalities encompassing all rotated images. Subsequently, existing DNN verifiers are applied. A similar approach is employed in [2] for non-linear output specifications. \nBoth these cases with linear approximations of non-linear input and output specification can be handled with ProFIt. In general, for DNN verification, nonlinear specifications are rare, and most of the common norm-based local robustness properties can be specified as a conjunction of linear inequalities, and the corresponding proofs can be analyzed with ProFIt.\n\n[1] \"Certifying Geometric Robustness of Neural Networks\", M. Balunovic, NeurIPS, 2019. \\\n[2] \"Verification of Non-Linear Specifications for Neural Networks\", C. Qin, ICLR, 2019.\n\n**Q2. Different properties lead to different sufficient proof features. So, the features selected by one property may only reflect one perspective of the neural network.**\n\n**R2:** ProFIt analyzes and generates a human-understandable explanation of the proof of a specific property. Different properties capture different behaviors of the DNN and therefore, the proof and subsequently human-understandable explanation generated by ProFIt will reflect these differences. To elaborate, for robustness we want the DNN output to remain correct when input changes. In contrast, for monotonicity we want the output of DNN to change in a certain manner with respect to the change in input. So, it is natural that the proof of different properties on the same DNN will rely on different proof features. In this paper, we focus on proof dissection of the common local robustness properties and leave the dissection of proofs of other properties such as monotonicity to future work.\n\n**Q3. Can sufficient proof features provide intuitions on how to design a training method to train a model with such a property?**\n\n**R3:** Please refer to the response to Q2 in the common response."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3862/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700112441252,
                "cdate": 1700112441252,
                "tmdate": 1700112441252,
                "mdate": 1700112441252,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gAI1TBbBaK",
                "forum": "Ev10F9TWML",
                "replyto": "7YExI0TLox",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3862/Reviewer_UvmS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3862/Reviewer_UvmS"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your reply. I have no further questions."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3862/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700140179168,
                "cdate": 1700140179168,
                "tmdate": 1700140179168,
                "mdate": 1700140179168,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Ng3R6B4lZN",
            "forum": "Ev10F9TWML",
            "replyto": "Ev10F9TWML",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3862/Reviewer_YfNd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3862/Reviewer_YfNd"
            ],
            "content": {
                "summary": {
                    "value": "The authors consider the problem of making proofs of neural network robustness more human understandable. In particular, the authors consider recent verification methods developed for computing neural networks robustness and extract proof features from these methods by analysing the ranges of the outputs of each neuron at the penultimate layer. Then, they proceed by finding a small subset of these features that are sufficient to explain the verification result. The authors show the effectiveness of their results on experiments on the MNIST and CIFAR datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper is well written\n\n- The problem of analysing and explain the decisions of the various methods developed to verify neural networks is of interest to the ICLR community and to the best of my knowledge novel\n\n- The algorithm is sound and experimental results seem to show improvement compared to state of the art"
                },
                "weaknesses": {
                    "value": "- The experimental setting is not totally clear to me: \n\n1) how is the original feature count in Table 1 computed? Should not this be just the size of the penultimate layer? Also why is this 10 times larger for PGD trained networks on MNIST compared to PGD trained networks on CIFAR? \n\n2) As ProFIt has a  subroutine that needs to check for sufficiency of a feature set, It would be good to perform experiment to analyse the scalability of the proposed method on various architectures for the various robustness methods considered in the paper (and to report computation times).\n\n- The computational complexity of ProFIt should be discussed more clearly."
                },
                "questions": {
                    "value": "- Can the method also be applied to other certification methods such as randomised smoothing [Cohen, Jeremy, Elan Rosenfeld, and Zico Kolter. \"Certified adversarial robustness via randomized smoothing.\" international conference on machine learning. PMLR, 2019.]?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3862/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698165098266,
            "cdate": 1698165098266,
            "tmdate": 1699636344555,
            "mdate": 1699636344555,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NMLWze6TGm",
                "forum": "Ev10F9TWML",
                "replyto": "Ng3R6B4lZN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3862/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3862/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1. how is the original feature count in Table 1 computed? Why the size of the penultimate is different for MNIST and CIFAR10 PGD-trained networks?**\n\n**R1:** As pointed out, the original feature count is the same as the size of the penultimate layer. In Table 1, we opted for publicly available state-of-the-art pre-trained networks from official repositories [1, 2, 3] to prevent training networks ourselves and introducing unintended bias in the process. Therefore, the networks in Table 1 do not always share the same architecture and may have different sizes at the penultimate layer. The experiments on networks with the **same architecture** are in Appendix C.9. \\\n[1] ERAN - https://github.com/eth-sri/eran \\\n[2] CROWN-IBP - https://github.com/huanzhang12/CROWN-IBP \\\n[3] COLT - https://github.com/eth-sri/colt \\\n\n**Q2. Scalability analysis of ProFIt**\n\n**R2:** Please refer to the response to Q1 in common response.\n\n**Q3. The computational complexity of ProFIt**\n\n**R2:** Please refer to the response to Q1 in common response.\n\n**Q4. Can the method also be applied to probabilistic certification methods such as randomised smoothing?**\n\n**R4:** ProFIt is designed for deterministic DNN verifiers and currently cannot handle probabilistic verifiers like randomized smoothing. To extend ProFIt to accommodate probabilistic verifiers, we would first need to define the priority ordering of the proof features w.r.t the proof generated by probabilistic verifiers. Additionally, determining how to generate visualizations of the proof features poses a challenge since, unlike common incomplete verifiers, the computation of randomized smoothing cannot be represented as differentiable programs. Both of these aspects require further investigation, and we leave them as subjects for future work. We will update Section 4.5 of the paper to include this limitation."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3862/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700112362135,
                "cdate": 1700112362135,
                "tmdate": 1700112362135,
                "mdate": 1700112362135,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "6Nb0wtuwnJ",
            "forum": "Ev10F9TWML",
            "replyto": "Ev10F9TWML",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3862/Reviewer_zRr5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3862/Reviewer_zRr5"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes to verify the robustness of neural classifiers by finding the \"robust features\" via pruning the penultimate layer features based on their \"priority\". The resulting \"ProFIt\" algorithm guarantees sufficiency and reduces the number of proof features required to certify an area around the input, reducing the complexity of the certificate. The authors also show that high-priority robust features can visualize the neural classifier attention and use such a property to compare various robust models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper proposes a theoretically-inspired heuristic algorithm that seems to work as expected. The algorithm provides improved interpretability to the robust verification problem. Furthermore, the qualitative comparisons are constructive. The paper is generally well-structured, the notations are mostly well-defined, and the experiment results are clearly presented. The proposed algorithm is general and is compatible with existing certification methods."
                },
                "weaknesses": {
                    "value": "- I find the motivation of this work to be a little ambiguous. Specifically, the author argues that the challenge this work aims to address here is \"investigating the entire set $\\mathcal{F}$ is always a valid but expensive option considering the size of $\\mathcal{F}$\". However, Algorithm 1 needs to iteratively query the verifier on subsets of $\\mathcal{F}$, with the subset in the first couple of iterations potentially quite large. Particularly, at the first iteration, the cardinality of $F_{S_0} \\cup F_{S_1}$ seems to be half of $\\mathcal{F}$. Therefore, it is not immediately clear to me how the proposed algorithm reduces the overall computational complexity, and some additional explanation would be preferred.\n- While the visualizations in Figure 3 are nice, it would be helpful and more meaningful if they could be generated from commonly used model architectures, as ConvNets and vision transformers may attend to different parts of the input image compared with the feed-forward networks used in this paper. Are there any challenges for applying the proposed methods to these more sophisticated networks, since these models usually also have a linear layer as the final layer? I believe that this paper will benefit from a more diverse empirical evaluation.\n- Some typos: \"uppper\" on page 5; \"both the baselines\" on page 8."
                },
                "questions": {
                    "value": "- Is the certificate issued by ProFIt related to the robust accuracy in any way? My impression after reading the paper is that since $\\it{F}_{S_0}$ returned by Algorithm 1 is always sufficient, the percentage of data that can be certified will be the same as the verifier $\\mathcal{V}$. Is this correct?\n- I see that the experiments and calculations are performed using a CPU. Is the proposed algorithm also compatible with GPU acceleration?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3862/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3862/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3862/Reviewer_zRr5"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3862/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698792995870,
            "cdate": 1698792995870,
            "tmdate": 1699636344482,
            "mdate": 1699636344482,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "BPzsIHnsDj",
                "forum": "Ev10F9TWML",
                "replyto": "6Nb0wtuwnJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3862/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3862/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1. It is not immediately clear to me how the proposed algorithm reduces the overall computational complexity, and some additional explanation would be preferred.**\n\n**R1:** First, let us clarify the statement: \"Investigating the entire set $\\mathcal{F}$ is always a valid but expensive option, considering the size of $\\mathcal{F}$.\" For DNNs, the proof feature set $\\mathcal{F}$ may comprise thousands of proof features, making it impractical to manually investigate each one (e.g., by examining the gradient maps) individually. For this reason, one of our objectives is to automatically extract a proof feature set that is small (the first of three expectations outlined in Section 4.1) and, consequently, easy to manually investigate.\nIn Table 1 of the paper, we demonstrate that ProFIt successfully extracts a small yet sufficient and important proof feature set, containing fewer than 10 proof features. This significantly reduces the effort required for the manual investigation of all constituent proof features. We will provide further clarification in the revised version of the paper.\n\n**Q2.  Can ProFIt be used for ConvNets and vision transformers?**\n\n**R2:** All the networks used in the experiments in Table 1 of the paper, are convolutional. We have provided detailed information about the architecture of the DNNs, handled by ProFIt, in the response to Q1 in the common response. For even larger networks like vision transformers, the state-of-the-art deterministic DNN verifiers do not scale. As the scalability of ProFIt is ultimately constrained by the limitations of existing DNN verifiers, it currently does not scale to vision transformers. However, it's crucial to note that ProFIt is a general tool compatible with any deterministic DNN verification algorithm. Therefore, ProFIt will benefit from any future advances to enable the deterministic DNN verifiers to scale to vision transformers. We have discussed this limitation in Section 4.5 of the paper.\n\n**Q3. Is the certificate issued by ProFIt related to the robust accuracy in any way?**\n\n**R3:** ProFIt analyzes the proof only if the underlying verifier $\\mathcal{V}$ can prove the property. So, the percentage of cases ProFIt generates proof dissection is the same as the robust accuracy of the DNN with verifier $\\mathcal{V}$. \n\n**Q4. Is the proposed algorithm also compatible with GPU acceleration?**\n\n**R4:** Yes, ProFIt is compatible with GPU acceleration. We provide the runtime analysis of ProFIt with GPUs in the response to Q1 in the common response. We will add these runtimes in the revised version of the paper.\n\n**Q5. Typographical errors in page 5 and page 8.**\n\n**R5:** Thanks for pointing out we will fix this in the revised version of the paper."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3862/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700112270905,
                "cdate": 1700112270905,
                "tmdate": 1700112270905,
                "mdate": 1700112270905,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "imSMcnPcvU",
                "forum": "Ev10F9TWML",
                "replyto": "6Nb0wtuwnJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3862/Reviewer_zRr5"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3862/Reviewer_zRr5"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the response."
                    },
                    "comment": {
                        "value": "Thank you for the response, which clarified most of my questions. Overall, I think this paper presents a coherent story but the motivation is less clear and prominent. Therefore, I stand on the fence about this manuscript and keep my rating of 6."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3862/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700357738291,
                "cdate": 1700357738291,
                "tmdate": 1700357938763,
                "mdate": 1700357938763,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "UvJ1C0VZPf",
            "forum": "Ev10F9TWML",
            "replyto": "Ev10F9TWML",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3862/Reviewer_rPr5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3862/Reviewer_rPr5"
            ],
            "content": {
                "summary": {
                    "value": "This paper aims to analyze the robustness proof generated by a DNN verifier. Given a neural network and a DNN verifier (deterministic, sound, and incomplete verifiers, such as DeepZ and CROWN), the paper presents an algorithm ProFlt to extract a set of proof features (defined as the reachable interval of neurons in the penultimate layer) that is small, sufficient, and retains important proof features. Based on the top-proof feature extracted using the proposed algorithm, the paper then visualizes the gradient maps for different neural networks and DNN verifiers and explains why they differ."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is well-structured and technically solid. To the best of my knowledge, most existing works focus on debugging neural networks and explaining how they make predictions. In contrast, this paper proposes to identify the most influential proof features for a DNN verifier, which is different and new. I also like how the paper presents the problem formulation for proof dissection, where the three expectations are discussed in great detail. The proposed ProFit algorithm and how it approximates the priority of proof features are well-explained."
                },
                "weaknesses": {
                    "value": "While I most enjoyed reading the paper, the significance of generating human-understandable proof features and the user case of the extracted proof features need to be explained more clearly. A DNN verifier is supposed to provide a mathematically sound robustness certificate, so by design, it gives a result that can be trusted. However, this paper aims to identify important/human-understandable proof features that can explain how the DNN verifier works, so I wonder why we need a DNN verifier to be explainable in the first place. The following question is: after we obtain the top proof feature (e.g., the one returned by your algorithm), how can we use the extracted insight to assist the DNN verification procedure or the development of adversarially robust models? \n\nWithin the proposed problem formulation, the paper did quite a good job explaining the relevant concepts of proof features and developing a well-motivated algorithm to prioritize the proof features. I hope that the authors can better explain the underlying motivation of the considered problem."
                },
                "questions": {
                    "value": "1. What is the computational complexity of the proposed _ProFit_ algorithm and the reliance on the dependent factors? \n\n2. The gradient map visualizations shown in Figure 3 seem interesting. Still, I do not understand the corresponding explanations: \"CROWN-IBP filters out most of the spurious features, but it also misses out on some meaningful features.\" What do you mean by \"spurious\" and \"meaningful\" features in the context of gradient maps? Does the provably robust training method CROWN-IBP have a much lower standard accuracy because it overly filters the meaningful features?\n\n3. How can the extracted top proof features benefit the development of better DNN verifiers or robust training methods?\n\n\n============== Post Rebuttal Comments ==============\n\nI appreciate the authors' feedback and additional experimental results. I would be interested to see how ProFIt analysis can contribute to building more robust DNNs."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3862/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3862/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3862/Reviewer_rPr5"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3862/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699129314273,
            "cdate": 1699129314273,
            "tmdate": 1700806031199,
            "mdate": 1700806031199,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XPun99I8hf",
                "forum": "Ev10F9TWML",
                "replyto": "UvJ1C0VZPf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3862/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3862/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1. Since the DNN verifier is supposed to provide a mathematically sound robustness certificate, explain the motivation for dissecting DNN proofs.**\n\n**R1:** The primary objective of ProFIt is to explain why the verifier successfully proves a property on the given DNN. This motivation aligns with traditional DNN interpretation techniques, where, given a DNN correctly computes the output, the goal is to comprehend the decision-making process of the DNN. In contrast to existing DNN verifiers that often act as black boxes, traditional program verifiers do offer insights into why certain properties are proven for the given program.\nFor instance, in programs featuring loops, loop invariants characterize the expected behavior of the program after each iteration, making the proof human understandable (discussed in Section 1 of the paper). We want to check whether the proofs generated by DNN verifiers provide similar insights or not. As shown in Section 5.3, even if a DNN is robust for some $L_{\\infty}$ region, the input features, the proof relies on can be different. Moreover, dissection results obtained by ProFIt can serve as a qualitative metric to compare different DNNs achieving similar levels of robustness. For example, proofs generated on standard DNNs highlight spurious input features that are part of the background rather than those associated with the actual object. In contrast, the proof generated on COLT networks relies on input pixels that are part of the actual object.  These applications emphasize the importance of delving into proof dissection techniques. \n\n**Q2.  What is the computational complexity of the proposed  ProFit algorithm and the reliance on the dependent factors?** \n\n**R2:** Please refer to response to Q1 in the common response.\n\n**Q3. What do you mean by \"spurious\" and \"meaningful\" features in the context of gradient maps? Does the provably robust training method CROWN-IBP have a much lower standard accuracy because it overly filters the meaningful features?**\n\n**R3:** As defined in Section 5.3 in the paper, for gradient maps generated on MNIST and CIFAR10 images, spurious input features are the pixels coming from the image background, whereas meaningful input features are the pixels that are a part of the actual object being identified by the DNN. \nRobustly trained networks generally report lower standard accuracy than commonly trained networks [1]. Additionally, certifiably robust DNNs (CROWN-IBP) generally report smaller standard accuracy when compared to empirically robust DNNs (PGD-trained) [2]. It appears that the loss in standard accuracy is due to the fact that the certifiably robust networks overly filters the meaningful input features.\n\n[1] \"Robustness May Be at Odds with Accuracy\", D. Tsipras. ICLR, 2019.\n\n[2] \"Certified Training: Small Boxes are All You Need \", M. Mueller, ICLR, 2023.\n\n**Q4 How can the extracted top proof features benefit the development of better DNN verifiers or robust training methods?**\n\n**R4:** Please refer to the response to Q2 in the common response."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3862/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700112159355,
                "cdate": 1700112159355,
                "tmdate": 1700112159355,
                "mdate": 1700112159355,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]