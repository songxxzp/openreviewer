[
    {
        "title": "Fine-grained Local Sensitivity Analysis of Standard Dot-Product Self-Attention"
    },
    {
        "review": {
            "id": "zb4c79bpiT",
            "forum": "IWpLQfZ8Xg",
            "replyto": "IWpLQfZ8Xg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8242/Reviewer_BhUy"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8242/Reviewer_BhUy"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the local sensitivity of dot-product self-attention in Transformers. Though the outputs of all heads is not globally Lipchitz, a weaker condition, i.e., the local sensitivity can be theoretically analyzed by providing a upper bound. Besides, the upper bound is empirically verified and certification on practical models is also given."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Upper bound of local sensitivity analyse is derived\n- Numerical validations are also provided to support the fact that, the upper bound is tight and reasonable"
                },
                "weaknesses": {
                    "value": "- The dimension of some matrices are undefined, e.g., $W^O \\in R^{d \\times d}$ and $H \\in R^{n \\times n}$?\n- Solving Eq. (10) requires SVD for the n-by-d matrix. How to ensure the computational efficiency? \n- To bound the second term in Eq. (14), the author uses the triangle inequality to obtain the upper bound at first. However, this can be also obtained with a closed-form solution? This is because the objective function and constraint are both linear."
                },
                "questions": {
                    "value": "- Before Proposition 1, the authors mention the robustness under l_2 perturbation. How about using l_\\inf perturbations for robustness when compared to the adversarially chosen l_2 perturbations? In this case, Eq. (5) will be changed to the l_\\inf norm but I\u2019m not sure the used techniques are still valid."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8242/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698580904699,
            "cdate": 1698580904699,
            "tmdate": 1699637024549,
            "mdate": 1699637024549,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "h2YAQiUxi0",
                "forum": "IWpLQfZ8Xg",
                "replyto": "zb4c79bpiT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8242/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8242/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer BhUy"
                    },
                    "comment": {
                        "value": "Thanks for your comments. We believe that the significance of our contribution has been underestimated. We share Reviewer d9ub's opinion that our paper has made significant contributions in achieving **the first non-zero certified robustness result of standard dot-product self-attention networks on CIFAR**. We further address all your individual comments as below.\n\n\n> The dimension of some matrices are undefined, e.g., $W^O$ and $H$?\n\nWe consider a standard setting with $W^O\\in \\mathbb{R}^{(d/h) \\times d}$ and $H\\in \\mathbb{R}^{n\\times n}$. We have now made the dimensions of these matrices clear in the revised paper\n\n\n>Solving Eq. (10) requires SVD for the n-by-d matrix. How to ensure the computational efficiency?\n\nTo be clear, our approach only requires computing the spectral norm, and SVD is not needed for solving the spectral norm. In our paper, we just use the power iteration method which is known to be very efficient in computing the spectral norm and has been used many times in deep learning (e.g. Tsuzuku'18,  Miyato'18, Meunier'22).  \n\n\n\n> To bound the second term in Eq. (14), the author uses the triangle inequality to obtain the upper bound at first. However, this can be also obtained with a closed-form solution? This is because the objective function and constraint are both linear.\n\nUnfortunately, there is no closed-form solution for the second term of Eq. (14), since this is a problem maximizing the spectral norm under a quadratic constraint. The objective function $||X' W^V W^O||$ is not a linear function of $X'$ due to the appearance of the spectral norm. The constraint $||X'-X||_F \\leq \\epsilon$ is also not linear in $X'$ due to the appearance of the Frobenius norm. It is actually quadratic. \nFor problems minimizing the spectral norm under a quadratic constraint, it is possible to reformulate them as semidefinite programs (SDPs). However, the second term of Eq. (14) requires maximizing the spectral norm, and hence it is difficult to obtain a bound tighter than our current bound based on triangle inequality.\n\n\n> Before Proposition 1, the authors mention the robustness under $\\ell_2$ perturbation. How about using $\\ell_\\infty$ perturbations for robustness when compared to the adversarially chosen $\\ell_2$ perturbations? In this case, Eq. (5) will be changed to the $\\ell_\\infty$ norm but I\u2019m not sure the used techniques are still valid.\n\nExtending our fine-grained $\\ell_2$ analysis to the $\\ell_\\infty$ case is definitely non-trivial and would require some major changes, since we are using the fact that softmax is $1$-Lipschitz with respect to the $\\ell_2$ norm. We want to emphasize that it is totally reasonable for our current paper to focus on the $\\ell_2$ perturbation cases, and there are many papers published in top machine learning venues (e.g Singla'21, Trockman'21, Meunier'22, Singla'22, Prach'22, Araujo'23, Wang'23,Hu'23) that only focus on robustness and sensitivity of neural networks under the $\\ell_2$ setting. Our paper is the first obtaining a non-vacuous certified robustness result of standard dot-product self-attention networks on CIFAR.\n\n\n[Singla'21]. Sahil Singla and Soheil Feizi. Skew orthogonal convolutions. ICML\n\n[Trockman'21] Asher Trockman and J Zico Kolter. Orthogonalizing convolutional layers with the Cayley transform. ICLR\n\n[Meunier'22] Laurent Meunier, Blaise J Delattre, Alexandre Araujo, and Alexandre Allauzen. A dynamical system\nperspective for lipschitz neural networks. ICML\n\n[Singla'22] Sahil Singla, Surbhi Singla, and Soheil Feizi. Improved deterministic l2 robustness on CIFAR-10 and CIFAR-100. ICLR\n\n[Prach'22] Bernd Prach and Christoph H Lampert. Almost-orthogonal layers for efficient general-purpose lipschitz networks. ECCV\n\n[Araujo'23] Alexandre Araujo, Aaron J Havens, Blaise Delattre, Alexandre Allauzen, and Bin Hu. A unified algebraic perspective on lipschitz neural networks. ICLR\n\n[Wang'23] Ruigang Wang and Ian Manchester. Direct parameterization of lipschitz-bounded deep networks. ICML\n\n[Hu'23] Kai Hu, Andy Zou, Zifan Wang, Klas Leino, and Matt Fredrikson. Unlocking deterministic robustness certification on imagenet. NeurIPS"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8242/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700369927621,
                "cdate": 1700369927621,
                "tmdate": 1700369927621,
                "mdate": 1700369927621,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GSbq5phXHz",
                "forum": "IWpLQfZ8Xg",
                "replyto": "h2YAQiUxi0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8242/Reviewer_BhUy"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8242/Reviewer_BhUy"
                ],
                "content": {
                    "comment": {
                        "value": "thanks for the authors' response.\n\nIf the author(s) would like to focus on **the first non-zero certified robustness result of standard dot-product self-attention networks on CIFAR**, there are some references that are missing:\n\nhttps://openreview.net/forum?id=BJxwPJHFwS\n\nShi, Z., Zhang, H., Chang, K.W., Huang, M. and Hsieh, C.J., 2020. Robustness verification for transformers. ICLR 2020.\n\nBonaert, G., Dimitrov, D.I., Baader, M. and Vechev, M., 2021, June. Fast and precise certification of transformers. In Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation (pp. 466-481).\n\n---\n\nSorry for the late reply but my score will remain unchanged."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8242/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700734950324,
                "cdate": 1700734950324,
                "tmdate": 1700734950324,
                "mdate": 1700734950324,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "PHEu6amj0P",
            "forum": "IWpLQfZ8Xg",
            "replyto": "IWpLQfZ8Xg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8242/Reviewer_VymQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8242/Reviewer_VymQ"
            ],
            "content": {
                "summary": {
                    "value": "This paper aim to theoretically analyze the sensitivity of the self attention mechanism. Local perturbations are imposed on the weights, and authors quantify the relationship between the sensitivity between the input, weight matrices, etc. Experiments are done to validate the theory, and insights are provided to achieve more stable self attention structure."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This paper captures a common problem of the popular Transformer model: self attention mechanism can be sensitive. The work quantifies the sensitivity and provides insight into how to make the self attention structure stable. This topic is important in the performance of Transformer model, which is widely applied in NLP, CV tasks.\n2. I do not have doubt on the theoretical results, as they are clearly derived.\n3. The experiments are closely related with the theory."
                },
                "weaknesses": {
                    "value": "1. My main concern is that this work does not provide enough contribution. In Section 4, the gap caused by perturbation is derived. However, these results are not novel, in fact, they are easy to derive. The main idea of Section 4 is just finding a Lipschitz constant to bound the gap when perturbation is added to input. This can be easily done if we take derivative over input X and find an upper bound for the Frobenius norm of the gradient over X. In some other works, the closed form gradients (maybe over $W^Q,W^K$, but similar to gradient over X) are easily derived, e.g, Tian, Yuandong, et al. \"Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer.\" arXiv preprint arXiv:2305.16380 (2023). Thus, I do not think the theory has much contribution.\n2. The theory in Section 4 implies that weight matrices and data with small magnitude is better. However, 'small magnitude' does not mean a self attention mechanism is a good model. Consider an extreme case where all weight matrices are close to 0, then the attention mechanism has poor representation ability. We usually require a model with both expressivity and stability, while in this work, the expressivity is ignored."
                },
                "questions": {
                    "value": "1. How to theoretically guarantee that a model can both have good expressivity and stability?\n2. When weights $W^Q,W^K,W^V$ follows some specific distribution, can the sensitivity bound be improved? Or the bound is only related to the magnitude of weights?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8242/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8242/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8242/Reviewer_VymQ"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8242/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698734954955,
            "cdate": 1698734954955,
            "tmdate": 1700708346615,
            "mdate": 1700708346615,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AfV5j8TyqD",
                "forum": "IWpLQfZ8Xg",
                "replyto": "PHEu6amj0P",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8242/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8242/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer VymQ"
                    },
                    "comment": {
                        "value": "Thanks for your comments. We believe that our contribution has been misunderstood. We share Reviewer d9ub's opinion that our paper has made significant contributions in achieving **non-vacuous certified robustness result of standard dot-product self-attention networks on CIFAR**. We further address all your individual comments as below.\n\n> However, these results are not novel, in fact, they are easy to derive. This can be easily done if we take derivative over input X and find an upper bound for the Frobenius norm of the gradient over X. \n\nWe think our results are novel for the following reason. Our local sensitivity analysis is not a local Lipschitz bound result (see the explanation in Appendix A of our paper), and **our analysis is really needed to achieve our main goal that is to produce tight local bounds which can lead to non-vacuous certified robustness of standard dot-product self-attention networks on realistic data sets such as CIFAR.** We emphasize that getting **non-vacuous** certified robust accuracy is an important topic that is being studied in the deep learning field (e.g. see Singla'21, Trockman'21, Meunier'22, Singla'22, Prach'22, Araujo'23, Wang'23,Hu'23), and this is very different from the cases when one studies generalization bounds which are typically used to provide design guidelines and hence not required to be non-vacuous. If one follows the suggestions in this comment (e.g. finding upper bound for the Frobenius norm of the gradient), then the resultant bounds (e.g. the local Lipschitz bound in a concurrent submission available at https://openreview.net/forum?id=mivL0akE5E is exactly derived using this gradient norm idea) is too loose and can only produce 0 certified robust accuracy for self-attention networks on CIFAR.  Now we elaborate as follows.\n\n- Non-vacuous certified robustness: Given a data point $X$, a classifier $F$ is said to be certifiably robust at radius $\\epsilon > 0$ at this data point with label $y$ if for all $\\tau$ such that $||\\tau|| \\leq \\epsilon$, we have $arg max_j [F (X+\\delta)]_j = y$. Given a perturbation level $\\epsilon$, the certified robust accuracy is defined to be the percentage of the data points (in the testing test) where the classifier $F$ is certifiably robust at radius $\\epsilon$, and this notion of certified robustness has been adopted in many recent works (e.g. Singla'21, Trockman'21, Meunier'22, Singla'22, Prach'22, Araujo'23, Wang'23,Hu'23). Based on our Proposition 1, our local sensitivity bound can be combined with the prediction margin to calculate the certified robust accuracy. As commented by Reviewer d9ub, achieving non-vacuous certified accuracy for dot-product self-attention on CIFAR10 task is one of our main contributions.  If ones tries to develop a local Lipschitz bound and uses it for certified robustness, the bound is usually too loose and the robust accuracy will be 0. For example, the local Lipschitz bound in a concurrent submission (Specformer) available at https://openreview.net/forum?id=mivL0akE5E is exactly derived using this gradient norm idea (see Theorem 4.3 of that paper). If we compare Theorem 4.3 of the SpecFormer paper with our bound (see table below), we can see our bounds are better by magnitude. The consequence is that Theorem 4.3 of the SpecFormer paper can only achieve 0 certified accuracy on CIFAR. **Our key sensitivity metric (Lemma 1 in our paper) is novel and crucial for obtaining a non-vacuous certified accuracy result.**\n\n| $\\ell_2$ perturbation bound $\\epsilon$ | .01| .02|.03|.04|.05|.06| .07 |.08 | .09 | .10 |\n|----|---|--------|--------|--------|--------|---------|---------|---------|---------|---------|\n| PGD Lower Bound | 0.0286 | 0.0573 | 0.0860 | 0.1147 | 0.1427 | 0.1719  | 0.2008  | 0.2295  | 0.2582  | 0.2865  |\n| Local Bound Theorem 1. (ours) | 0.0291 | 0.0582 | 0.0875 | 0.1168 | 0.1462 | 0.1757  | 0.2052  | 0.2348  | 0.2646| 0.2943|\n| SpecFormer Local Lipschitz Bound (Gradient-based)| 16.901 | 34.403 | 52.515 | 71.245 | 90.600 | 110.589 | 131.219 | 152.499 | 174.436 | 197.036 |\n\n[Figure Comparing to the Gradient-based Bound](https://drive.google.com/file/d/1riLDjkjXMbf0bmi3Ux6t0puZ_z60mSFq/view?usp=sharing)\n\n\n- Our analysis is not a local Lipschitz constant analysis: To reduce conservatism, the local bounds derived in our paper are actually quite different from a local Lipschitz constant bound. Our local bound $||X-X'||\\leq \\epsilon \\implies ||F(X)-F(X')|| \\leq \\delta(X, \\epsilon)$ fixes $X$ and only allows $X'$ to vary. This is sufficient for calculating certified robust accuracy. The Lipschitz constant bound you describe $||F(X'')-F(X')||\\leq L(X, \\epsilon)||X''-X'||$ actually holds for any two points $(X',X'')$ in the $\\epsilon$-ball around $X$.  This introduces unnecessary conservatism when applied to compute the certified robustness."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8242/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700369637784,
                "cdate": 1700369637784,
                "tmdate": 1700369637784,
                "mdate": 1700369637784,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Reqwmltt7o",
                "forum": "IWpLQfZ8Xg",
                "replyto": "PHEu6amj0P",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8242/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8242/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer VymQ"
                    },
                    "comment": {
                        "value": "> The theory in Section 4 implies that weight matrices and data with small magnitude is better. In this work, the expressivity is ignored.\n\nOur theory should not imply that weight matrices and data with small magnitude are necessarily better for network design. Previous study on certifiably robust networks (e.g Singla'21, Trockman'21, Meunier'22, Prach'22, Araujo'23, Wang'23) has revealed that there is a trade-off between deterministic $\\ell_2$ certified robustness and the clean performance for standard feed-forward networks or residual networks (dot-product self-attention has not been covered in these previous works). The right interpretation is that our bound can be used to quantify such a robustness/performance trade-off for dot-product self-attention (based on our bound, one can sacrifice the clean performance to achieve non-vacuous certified robust accuracy for standard dot-product self-attention). Importantly, as constraining the weight/data norm can improve the certified robustness, there is a price to pay, i.e.  the clean accuracy will drop.  So we never claim that one should always maximize the robustness. Instead, our theory offers the tool to quantify the robustness/performance trade-off for dot-product self-attention such that one can explore this trade-off for various tasks at hand (different tasks require different levels of robustness). We have also revised our paper accordingly to better reflect the above point.\n\n> How to theoretically guarantee that a model can both have good expressivity and stability?\n\nAs mentioned before, our focus is more on certified robustness rather than stability (which is typically used for generalization). Now we address the above comment via emphasizing the trade-off between certified robustness and clean performance. Our results and other papers on certifiably robust networks (e.g Singla'21, Trockman'21, Meunier'22, Prach'22, Araujo'23, Wang'23) all demonstrate that there is a trade-off between deterministic $\\ell_2$ certified robustness and the clean performance (expressivity). Currently, improving certified robustness typically leads to degraded performance. One just navigates the optimal Pareto trade-off between robustness and expressivity depending on the possible level of perturbations for the tasks at hand.  Continuing to boost the clean performance of certifiably robust models is an ongoing research effort in the robust learning community. Our main contribution is on characterizing the robustness/performance trade-off for dot-product self-attention, which is a very reasonable self-contained topic. How to improve the structures of transformers to obtain better Pareto trade-off curves for robustness/robustness is beyond the scope of our paper, and should be investigated in the future. Our work serves as a foundation for such future study. \n\n> When weights follows some specific distribution, can the sensitivity bound be improved? \n\nWe follow the standard setup in the certified robustness literature  and consider the certified robustness of a trained model with deterministic weight (Singla'21, Trockman'21, Meunier'22, Prach'22, Araujo'23, Wang'23). Evaluating the robust accuracy for a fixed trained model makes sense, since robustness certification is typically applied to a trained model. To the best of our knowledge, certified robustness under distributions of the network weight has not been extensively studied in the robust learning field. It is unclear how to extend our analysis or any other existing deterministic $\\ell_2$ certified robustness analysis to such a setting considering a weight distribution. \n\n>Or the bound is only related to the magnitude of weights?\n\nOur bound in Theorem 1 not only depends on the spectral norm of the weights, but is highly dependent on the actual matrix elements and how they interact with the input and other attention heads. This is especially true in the \"key sensitivity metric\" of eq. (12) since we are looking at the spectral norm after summing many attention weights together, making our bound more fine-grained and less conservative.\nHere's a simple example: Suppose we have an attention layer with two attention heads. We set $H=0$, $W^Q_1 = W^Q_2$, $W^K_1=W^K_2$ ($P(X)_1=P(X)_2$), and $W^V_1 = W^V_2$. Then if $W^O_2 = -1/2*W^O_1$, the sensitivity metric of Eq (12) is: $||\\sum_i P(X)_i \\otimes (W^V_i W^O_i)^T|| = 1/2 ||P(X)_1 \\otimes (W^V_1W^O_1)^T||$. However, if $W^O_2= 1/2 W^O_1$, then we have $ 3/2 ||P(X)_1 \\otimes (W^V_1W^O_1)^T||$ which is a bound 3 times larger. In this case, we have not changed the spectral norm of any weight matrix, only the sign direction. But our key sensitivity metric changes significantly. To summarize, our bound is mainly related to our key sensitivity metric (Lemma 1).  Decreasing the spectral norms of $(W^Q, W^K, W^V, W^O)$ can eventually lead to a decreased value of the key sensitivity metric. However, that is not the only way to decrease the key sensitivity metric."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8242/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700369831031,
                "cdate": 1700369831031,
                "tmdate": 1700369831031,
                "mdate": 1700369831031,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ikKZvODHkM",
                "forum": "IWpLQfZ8Xg",
                "replyto": "PHEu6amj0P",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8242/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8242/Authors"
                ],
                "content": {
                    "title": {
                        "value": "The list of the references mentioned in our response"
                    },
                    "comment": {
                        "value": "For your convenience, here we list the detailed information of the references mentioned in our above response. Hopefully this makes reading our response easier. We are also willing to address any follow-up questions.\n\n[Singla'21]. Sahil Singla and Soheil Feizi. Skew orthogonal convolutions. ICML\n\n[Trockman'21] Asher Trockman and J Zico Kolter. Orthogonalizing convolutional layers with the Cayley transform. ICLR\n\n[Meunier'22] Laurent Meunier, Blaise J Delattre, Alexandre Araujo, and Alexandre Allauzen. A dynamical system perspective for lipschitz neural networks. ICML\n\n[Singla'22] Sahil Singla, Surbhi Singla, and Soheil Feizi. Improved deterministic l2 robustness on CIFAR-10 and CIFAR-100. ICLR\n\n[Prach'22] Bernd Prach and Christoph H Lampert. Almost-orthogonal layers for efficient general-purpose lipschitz networks. ECCV\n\n[Araujo'23] Alexandre Araujo, Aaron J Havens, Blaise Delattre, Alexandre Allauzen, and Bin Hu. A unified algebraic perspective on lipschitz neural networks. ICLR\n\n[Wang'23] Ruigang Wang and Ian Manchester. Direct parameterization of lipschitz-bounded deep networks. ICML\n\n[Hu'23] Kai Hu, Andy Zou, Zifan Wang, Klas Leino, and Matt Fredrikson. Unlocking deterministic robustness certification on imagenet. NeurIPS"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8242/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700403846606,
                "cdate": 1700403846606,
                "tmdate": 1700403846606,
                "mdate": 1700403846606,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "P4FlZkCvG6",
                "forum": "IWpLQfZ8Xg",
                "replyto": "PHEu6amj0P",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8242/Reviewer_VymQ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8242/Reviewer_VymQ"
                ],
                "content": {
                    "title": {
                        "value": "Reply to authors"
                    },
                    "comment": {
                        "value": "Thanks for clarification. I have changed the score. But I still think the work is a little below the margin considering the theoretical contribution is not sufficient."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8242/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700708886470,
                "cdate": 1700708886470,
                "tmdate": 1700708886470,
                "mdate": 1700708886470,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vRnc5Fn47t",
            "forum": "IWpLQfZ8Xg",
            "replyto": "IWpLQfZ8Xg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8242/Reviewer_d9ub"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8242/Reviewer_d9ub"
            ],
            "content": {
                "summary": {
                    "value": "This paper provides a fine-grained theoretical analysis on the local sensitivity of self-attention. The primary constrained optimization for this local sensitivity is $\\max_{X': ||X' - X||_F \\leq \\epsilon} || F(X') - F(X) ||_F$ where $F(X)$ is the residual self attention. The authors divide $|| F(X') - F(X) ||_F$ into $\\Delta_1$ and $\\Delta_2$ (equation 7 & 8). For $\\Delta_1$, the authors provide an analytical upper bound (**first contribution** of this paper) as \n\n$$\\xi(x) = || H \\bigotimes I_n + \\sum_{l = 1}^h (P_l(X) \\bigotimes (W_l^V W_l^O)^\\top) ||$$ \n\nFor $\\Delta_2$, the authors first apply triangle inequality to divide equation 13 into the perturbation on self-attention score matrix (equation 17) and $|| X' W_l^V W_l^O||$ (equation 15). **The second contribution** of this paper is on bounding equation 17 as Lemma 2 and equation 19. Putting them all together, we obtain an upper bound for $|| F(X') - F(X) ||_F$.\n\nIn the experiments, the authors first study the $\\Delta_1$ and $\\Delta_2$ values versus the PGD low bound across epsilon values in single and multi (8) head cases. The authors also analyze ViT's certified robust accuracy on CIFAR10 task, and provide a nonzero robustness $\\epsilon \\sim 36/255$ (**third contribution**)."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The proof organization of this paper is pretty clear and easy to follow in section 4. The authors meticulously described the looseness of each naive bound and strategies to further tighten the bound.\n\nThis local sensitivity analysis would be insightful for both adversarial and general machine learning community.\n\nThe experiments are also conducted on real-world tasks (ViT on CIFAR10), which makes this theoretical analysis practical on understanding the robustness of self-attention."
                },
                "weaknesses": {
                    "value": "There are multiple naive bounds described in theory but not evaluated in practice. For example, equation 9 for bounding $\\Delta_1$ and $||W_l^V W_l^O||(||X|| + \\epsilon)$ for bounding $||X' W_l^V W_l^O||$ should also be evaluated in Figure 1 to make the conservatism argument strong.\n\n\nMinor:\n\ntypo in equation 5: $||F(X') - F(x)||$ should be $||F(X') - F(X)||$"
                },
                "questions": {
                    "value": "Is it possible to perform another trial of robustness experiments on NLP tasks (text classification, entailment, etc.)? The analysis of this paper is applied to general self-attention and it is definitely great to see a practical evaluation on vision tasks. But it would be even better to see if the same robustness argument is applicable across domains. \n\nIn the network design section, it is mentioned that Theorem 1 would shed light on constraining weight norms for self-attention. It would be nice to see a concrete use case. For example, given a particular quadruple $(W_Q, W_K, W_V, W_O)$ and an input $X$, could we ablate on each weight individually and use the Theorem 1 to predict the local sensitivity?\n\nOverall, this is a good paper, but I believe the evaluation section could be further improved. I would give a weak accept score at this moment, but I am willing to raise my score if my above concerns / questions are addressed."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8242/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8242/Reviewer_d9ub",
                        "ICLR.cc/2024/Conference/Submission8242/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8242/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699608212794,
            "cdate": 1699608212794,
            "tmdate": 1700725865153,
            "mdate": 1700725865153,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "N7xXCEY22o",
                "forum": "IWpLQfZ8Xg",
                "replyto": "vRnc5Fn47t",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8242/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8242/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer d9ub"
                    },
                    "comment": {
                        "value": "Thank you for your valuable feedback. We have addressed your comments below.\n\n> There are multiple naive bounds described in theory but not evaluated in practice... they\nshould also be evaluated in Figure 1 to make the conservatism argument strong.\n\nWe agree that evaluating these naive bounds, especially the naive estimate of eq (9), would make the conservatism argument strong.  We have revised the experimental section (Section 5) and Figure 1 with the additional naive bounds. The results further show that our choice of the key-sensitivity metric is crucial for getting tight local sensitivity bounds of dot-product self-attention. We have also included an additional study on the tightness of our bound similar to Figure 1 for several input norm values found in Appendix C.2, Figure 4. We hope this provides a more complete picture of how our bound and architecture deal with conservatism.\n\n>Is it possible to perform another trial of robustness experiments on NLP tasks (text classification, entailment, etc.)? The analysis of this paper is applied to general self-attention and it is definitely great to see a practical evaluation on vision tasks. But it would be even better to see if the same robustness argument is applicable across domains.\n\nThanks for this comment. We followed your instruction and produced a robustness study of dot-product self-attention on the Stanford Sentiment Tree-bank (SST) dataset. We also revised our paper to include these new results in Appendix C.3 and Figure 5. We follow the setup in Xu\u201923, Wang\u201920, Zhu\u201920, and Li\u201921, and consider the deterministic $\\ell_2$ certified robustness on the word embedding space (we use the BERT embedding from Devlin'19). Our analysis here only serves as a proof of concept for using our bounds to NLP tasks, and we acknowledge that considering perturbations on the word embedding space (instead of the tokens directly) is a common limitation of applying sensitivity analysis to NLP benchmarks, as shared in many other papers (Hou\u201923). The certified robustness radii that we obtained is measured using $\\ell_2$ norm, and this is similar to those in prior work *without* using dot-product attention (Xu\u201923). Our results demonstrate that our sensitivity analysis bounds lead to non-vacuous robustness results on SST. For more details, see Appendix C of our revised paper. If the reviewer further wants us to work on other specific tasks, please let us know and we are willing to provide more results.\n\n[Xu\u201923] Xu et al. Certifiably Robust Transformers with 1-Lipschitz Self-Attention. \n[Hou\u201923] Hou et al. TextGrad: Advancing Robustness Evaluation in NLP by Gradient-Driven Optimization. ICLR  \n[Wang\u201920] Wang et al. InfoBERT: Improving Robustness of Language Models from An Information Theoretic Perspective. ICLR  \n[Zhu\u201920] Zhu et al. FreeLB: Enhanced Adversarial Training for Natural Language Understanding. ICLR  \n[Li\u201921] Li et al. TAVAT: Token-Aware Virtual Adversarial Training for Language Understanding. AAAI  \n[Devlin\u201919] Devlin et al. Bert: Pre-training of deep bidirectional transformers for language understanding. NAACL-HLT\n\n\n\n> In the network design section, it is mentioned that Theorem 1 would shed light on constraining weight norms for self-attention. It would be nice to see a concrete use case. For example, given a particular quadruple $(W^K, W^Q, W^V, W^O)$ and an input $X$, could we ablate on each weight individually and use the Theorem 1 to predict the local sensitivity?\n\nWe can certainly use Theorem 1 to predict local sensitivity, and agree that ablating the weight as suggested by the reviewer could give useful insight. These new experiments are presented in Appendix C.1, Figure 3. The ablation was already partially carried out in our CIFAR10 experiments of Figure 2, where we display the results for different spectral norm constraints on $(W^V, W^O)$.  In this additional experiment, we consider an experiment very similar to your suggestion. We take a  tuple $(W^Q, W^K, W^V, W^O, X)$ from the first layer of a trained ViT on CIFAR10 and a normalized input. We then sample perturbations of each element while keeping the others fixed, observing how our local upper-bound is affected with increasing parameter perturbation size. In addition we have also included an extended study on the tightness of our bound similar to Figure 1, but we vary the input norms found in Appendix C, Figure 4. In practice, it is possible to choose the norms of $(W^K, W^Q, W^V, W^O)$ to control expansion of the of each term in our local bound throughout each layer, and we can directly examine these values in the design process (This is how we designed our networks and determined the appropriate pre-attention layer projections)."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8242/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700369256840,
                "cdate": 1700369256840,
                "tmdate": 1700369306731,
                "mdate": 1700369306731,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1nU2xu7kWK",
                "forum": "IWpLQfZ8Xg",
                "replyto": "N7xXCEY22o",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8242/Reviewer_d9ub"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8242/Reviewer_d9ub"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your detailed response and changes!"
                    },
                    "comment": {
                        "value": "**A1**\nThank you for adding the Figure 4! This figure looks great and makes the conservatism argument stronger in practice.\n\n**A2** \nThank you for adding the BERT on the SST experiment! This experiment looks great and it strengthens the applicability of the derived bounds across domains. \n\n**A3**\nThank you for adding the Figure 3! This is a really practical ablation study but it would be even better to include a value derived from Theorem 1 as an upper bound shown in the figure. It would be informative to see these curves are quite close to their Theorem 1 upper bound.\n\nOverall, I believe that this is a good paper and I have bumped my score to accept."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8242/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700725839540,
                "cdate": 1700725839540,
                "tmdate": 1700725839540,
                "mdate": 1700725839540,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]