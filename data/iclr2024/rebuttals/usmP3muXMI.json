[
    {
        "title": "Minimizing Chebyshev Risk Magically Mitigates the Perils of Overfitting"
    },
    {
        "review": {
            "id": "3wAWUDZyBn",
            "forum": "usmP3muXMI",
            "replyto": "usmP3muXMI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6766/Reviewer_wkG8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6766/Reviewer_wkG8"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a novel regularization for deep neural networks (DNNs) based on Chebyshev's inequality, where Chebyshev's inequality is used to derive the upper bound of the probability of an embedding feature for an example deviating from class-wise prototypes.\nLosses for estimating prototypes as the class-wise embedding average, reducing intra-class feature covariances, and making prototypes orthogonal to each other are proposed.\nExperiments are conducted to compare the proposed regularization with existing methods that try to minimize covariances between activations or weights."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The use of Chebyshev's inequality to derive the regularization for DNNs is novel."
                },
                "weaknesses": {
                    "value": "- I could not figure out the theoretical justification for using DS in Lemma 3.1 or Corollary 3.1.1.\n    - If I understand correctly, the DS part in Eq.(6) can be any positive variable. Then what is the reason for using DS here?\n    - Moreover, the authors claim to regularize DNN training by increasing DS (which is established by decreasing $\\mathcal{L}_{CS}$), because it leads to a smaller value of the right part of Eq.(6). However, the larger DS value leads to the looser condition from the point of view of the left part of Eq.(6).\n- Discussion and empirical comparison with related work is insufficient.\n    - There are several other existing papers that discuss the orthogonality of weights, such as [1].\n    - It is also preferable to qualitatively or qualitatively compare the proposed method with other methods using class-wise prototypes, such as [2].\n    - Formatting in references is incomplete. For example, some papers do not have a place of publication.\n- Experiments are performed with CIFAR-100 and STL-10 only.\n\n[1] L. Huang et al., Orthogonal Weight Normalization: Solution to Optimization over Multiple Dependent Stiefel Manifolds in Deep Neural Networks, AAAI 2018.\n\n[2] J. Deng et al., ArcFace: Additive Angular Margin Loss for Deep Face Recognition, CVPR 2019."
                },
                "questions": {
                    "value": "- In Lemma 3.1, is there an assumption that the class label of $v$ is $k$?\n\n- In Section 5.4, I could not understand how the hyperparameters are determined in the proposed method.\n\n- In Section 4.3, Eq.11 -> Eq.9?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6766/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698053396279,
            "cdate": 1698053396279,
            "tmdate": 1699636780074,
            "mdate": 1699636780074,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "M1bquoGg0U",
                "forum": "usmP3muXMI",
                "replyto": "3wAWUDZyBn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6766/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6766/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Hello Reviewer wkG8,\n\nThank you for reviewing our paper in-depth.  Your questions and comments are very detailed and helpful.  We will try to answer them one-by-one as best we can.\n\nIn Lemma 3.1, is there an assumption that the class label of v is k?\nYes.  We propose to change the wording of lemma 3.1 to read:\n\u201cLemma 4.3.1 Given a sufficiently trained classifier \u2026 , [a feature vector v for a class k input example],\u2026\u201d\n\nIn Section 5.4, I could not understand how the hyperparameters are determined in the proposed method.\nWe can be more clear here.  We propose to change the wording in section 4.5.4:\n\n\u201cFor our algorithm, we could not conduct a large hyperparameter study on (beta,gamma,zeta) for computational reasons, so we instead performed cross-entropy loss training on the first training subset for 10 epochs and adjusted the values of (beta,gamma,zeta) until the other 3 loss components Lcov, Lcs, and Lproto had similar magnitude to Lce at epoch 10.  Our goal was to ensure that after the 10 epoch warmup period the relative scales of the different losses were similar and that the full training could optimize the Chebyshev Prototype Risk (CPR) while still fitting the data.  Our results indicate that our hyperparameter choices indeed allowed the model to fit the data to 100\\% training accuracy while still reducing the CPR.\u201d\n\nIn Section 4.3, Eq.11 -> Eq.9?\nYes, thank you this is a typo.  We will update this.\n\nWe have also overhauled the references to make sure they are complete.\n\nIf I understand correctly, the DS part in Eq.(6) can be any positive variable. Then what is the reason for using DS here?\nMoreover, the authors claim to regularize DNN training by increasing DS (which is established by decreasing DS), because it leads to a smaller value of the right part of Eq.(6). However, the larger DS value leads to the looser condition from the point of view of the left part of Eq.(6).\n\nWe can put any value for 'a' into the proof of the probability bound in eqn 22, but because the left hand side | CS(v,p) - E[CS(v,p)] | only exists on the interval [0,1], any 'a' value above 1 is not useful since the probability distribution goes to zero."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6766/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251415963,
                "cdate": 1700251415963,
                "tmdate": 1700251415963,
                "mdate": 1700251415963,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CEUbsaPr8o",
                "forum": "usmP3muXMI",
                "replyto": "M1bquoGg0U",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6766/Reviewer_wkG8"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6766/Reviewer_wkG8"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your responses"
                    },
                    "comment": {
                        "value": "Thanks for your responses.\n\nI agree that it makes no sense to use $a > 1$ in Eq.(22). But it is still not clear why DS is used as $a$.\n\nI would like to keep my score."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6766/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700473182710,
                "cdate": 1700473182710,
                "tmdate": 1700473182710,
                "mdate": 1700473182710,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7cI0LHM5qI",
                "forum": "usmP3muXMI",
                "replyto": "q45Wegzd6V",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6766/Reviewer_wkG8"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6766/Reviewer_wkG8"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your responses"
                    },
                    "comment": {
                        "value": "Thank you for your responses.\n\nIf I understand correctly, your loss $\\mathcal{L}_{CS}$ is introduced to increase DS, and the justification for this comes from Lemma 3.1.\nHowever, the inequality in Lemma 3.1 holds for any value of DS. Therefore, there is no reason why it is better to increase DS."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6766/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700625732961,
                "cdate": 1700625732961,
                "tmdate": 1700625732961,
                "mdate": 1700625732961,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Q6qGEEzn60",
                "forum": "usmP3muXMI",
                "replyto": "caRj5gDloB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6766/Reviewer_wkG8"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6766/Reviewer_wkG8"
                ],
                "content": {
                    "comment": {
                        "value": "I agree that decreasing the cov (the numerator of the right hand side) decreases the probability of the left hand side.\nHowever, regarding the DS, I still disagree with your comment.\nIt is true that the right hand side decreases as the DS increases, but at the same time the condition in the left hand side becomes looser.\n\nThank you for your kind replies."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6766/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700718922449,
                "cdate": 1700718922449,
                "tmdate": 1700718922449,
                "mdate": 1700718922449,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "52o12rV7SS",
            "forum": "usmP3muXMI",
            "replyto": "usmP3muXMI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6766/Reviewer_nGbq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6766/Reviewer_nGbq"
            ],
            "content": {
                "summary": {
                    "value": "This work subscribes itself within methods for improving generalization such as Cogswell et al.'15, Rodriguez et al. '16 and Haresh et al. '18, that seek to limit the hypothesis space by reducing the variance in either covariates or among members of a class. They agree to use an idea borrowed from the group that produced a distance-based classification and nearest-class means to use as anchors, and much in the same manner as anchors in a siamese setup. Thereby global loss components that enforce distance among these class prototypes, and locals ones that enforce class-cluster compactness, are derived. As an extension almost, the authors derive bounds on the variances around class prototypes."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper makes clear and persuasive arguments and the motivation leads naturally to the presented solution. It provides theoretic grounds for tailoring the loss for exploiting the two classicalideas of intra- and inter- class-cluster (for the lack of better terminology). The presented theorems and proofs check out for correctness. Benchmarks are sufficiently provided."
                },
                "weaknesses": {
                    "value": "I would have liked to see a theoretical understanding of why prefer your method over the competition, beyond the simple benchmark over two usual datasets."
                },
                "questions": {
                    "value": "None."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6766/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698653331251,
            "cdate": 1698653331251,
            "tmdate": 1699636779907,
            "mdate": 1699636779907,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hdwZ4lFfiQ",
                "forum": "usmP3muXMI",
                "replyto": "52o12rV7SS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6766/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6766/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Hello Reviewer nGbq,\n\nThank you for your helpful comments.  We have tried to address our weakness and included a new paragraph stating the reasons we prefer our method over previous methods.  Please find the new discussion paragraph in the global response or in the revised version of paper.\n\nThank you again."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6766/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251215035,
                "cdate": 1700251215035,
                "tmdate": 1700251215035,
                "mdate": 1700251215035,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "RfPq7DcNXN",
            "forum": "usmP3muXMI",
            "replyto": "usmP3muXMI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6766/Reviewer_tQCr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6766/Reviewer_tQCr"
            ],
            "content": {
                "summary": {
                    "value": "This work presents an approach to reduce overfitting and improve the test performance of DNNs. It considers the existence of an optimal prototype (featurizer) and uses Chebyshev's inequality to bound the misclassification probability, which depends on (low) intra-class variance and (high) inter-class distances in the prototype. Based on this, the authors present a new loss function and showcase its effectiveness in reducing overfitting on some image classification benchmarks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The idea to use Chebyshev prototype risk is novel, interesting and theoretically grounded. The authors also present a way to make their approach scalable with number of classes and it seems effective across several settings.\n\n1. Overall, the paper is well-written and easy to follow."
                },
                "weaknesses": {
                    "value": "1. ****Discussion on a set of related works seems missing.****\n- The concept of minimizing intra-class variance while encouraging larger inter-class distances seems very similar to the well-observed phenomenon of neural collapse [1]. In [1], it was observed that after training for a sufficiently long time, the final layer feature embeddings collapse to class means and form a simplex ETF structure. The classifier of top also coincides with these. It was also shown to improve test performance. How does the proposed approach relate to this? I suggest including some discussion on the connection/comparisons with this.\n- It seems that the section on related work on methods aimed to reduce overfitting only contains relatively older papers. For instance, [2] is a recent work that is not discussed.\n\n2. ****Limited evaluation.****\n- The proposed approach seems promising but it would be helpful to see more evidence that it is effective, e.g. by evaluating this approach on other datasets such as ImageNet.\n- I would also suggest comparing with some other methods. For instance, the recently proposed squentropy loss [3] is shown to improve test performance.\n\n****References:****\n\n[1] V. Papyan et al., Prevalence of neural collapse during the terminal phase of training, PNAS, 2020. https://www.pnas.org/doi/10.1073/pnas.2015509117\n\n[2] B. O. Ayinde et al., Regularizing Deep Neural Networks by Enhancing Diversity in Feature Extraction, TNNLS, 2019. https://ieeexplore.ieee.org/abstract/document/8603826?casa_token=94lYsTy6k-kAAAAA:ciG1-MsnzN_6BQRrLMz3V5PGAVLi4JB_j-EwRfsFRT-D_K9H82Cm08VspCUnM-SFvid176-wzw\n\n[3] L. Hui et al., Cut your losses with squentropy, ICML 2023. https://proceedings.mlr.press/v202/hui23a.html"
                },
                "questions": {
                    "value": "(See weaknesses above)\n\nCan the authors verify whether the baseline numbers used for comparison are computed in the terminal phase of training where neural collapse happens (please refer to [1])? Since the proposed approach seems to have a similar motivation as this phenomenon, it would be interesting to see how much incorporating the loss helps compared to just training for a large enough time."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6766/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698913961968,
            "cdate": 1698913961968,
            "tmdate": 1699636779780,
            "mdate": 1699636779780,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KilNBqoWvC",
                "forum": "usmP3muXMI",
                "replyto": "RfPq7DcNXN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6766/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6766/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Hello Reviewer tQCr, \n\nThank you for taking the time to read our paper in-depth and provide constructive comments.  We have taken your feedback and have developed some additional paragraphs to add to the paper the address your comments.\n\nThank you for pointing us towards the line of research on neural collapse phenomena, after reviewing papers in this area, it is certainly worth a paragraph discussion in our paper because we believe our basic idea behind the Chebyshev bound development contributes a different, probabilistic mathematical model to this discussion.\n\nThe main question regards whether our baseline models are in the terminal phase of training, implying that 100% of the training data has been fit and Tr(SwSb), a measure of intra-class feature covariance as a noise-to-signal ratio, has collapsed during the natural course of training (the phenomenon).  The short answer is that our baseline models have not reached the terminal phase yet and our algorithm is able to significantly reduce intra-class feature covariance compared to the baselines.\n\nWe do have data on the intra-class feature covariance (numerator of CPR) for our models at epoch 100 showing that our algorithm reduced the class average numerator by 50% compared to baselines in both weight decay settings and both datasets.  Being able to reduce these numbers implies that the intra-class feature covariance had not collapsed yet to the point we could no longer effectively reduce them.  There are two limitations to comparing directly to Papyan et. al [1].  First, we use standard flipping/cropping while they did not include data augmentation, which introduces more variation in the input space, greatly benefits test accuracy, and is more standard practice in visual tasks.  Second, our intra-class feature covariance is prototype weighted because our mathematical model required it \u2013 note how our numerator is E[pi(vi \u2212 pi)pj (vj \u2212 pj )], not the typical covariance E[(vi \u2212 pi)(vj \u2212 pj )].  Having said this, we have added the following paragraph to the paper after the CPR definition:\n\n\u2022\tOur probabilistic model for CPR has parallels to Neural Collapse property (NC1), which is the collapse of within-class feature covariance when a neural network has been trained for a sufficient number of epochs beyond 100\\% training accuracy (see \\citep{Papyan_2020} for details).  Through this lens, our work shares two connections to Neural Collapse.  First, our results show that our algorithm significantly reduces intra-class feature covariance compared to baseline models within a typical duration (100 epochs) of training, which is not in the terminal phase of training \u2013 in this way our loss components accelerate the covariance effects of neural collapse, which has been shown to improve generalization in many settings and lends credence to our Chebyshev model that reducing CPR reduces overfitting \\citep{Papyan_2020}.  The second connection is that we introduce a new probabilistic modeling of the similarity between an example\u2019s features to its class mean feature vector (Lemma \\ref{lem:2}), which to our knowledge has not been mathematically derived in the existing Neural Collapse discussion.  Future work could look to integrate theoretical arguments like ours into modeling Neural Collapse phenomena.\n\n[1] V. Papyan et al., Prevalence of neural collapse during the terminal phase of training, PNAS, 2020. https://www.pnas.org/doi/10.1073/pnas.2015509117"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6766/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251070527,
                "cdate": 1700251070527,
                "tmdate": 1700251070527,
                "mdate": 1700251070527,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Wl3ttXc6Yy",
                "forum": "usmP3muXMI",
                "replyto": "KilNBqoWvC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6766/Reviewer_tQCr"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6766/Reviewer_tQCr"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for the detailed response and appreciate the discussion on related works added in the paper. Overall, if the authors can include some additional experimental results for comparisons with other methods in the final version, then I am not opposed to accepting the paper."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6766/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700724801583,
                "cdate": 1700724801583,
                "tmdate": 1700724801583,
                "mdate": 1700724801583,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]