[
    {
        "title": "MedJourney: Counterfactual Medical Image Generation by Instruction-Learning from Multimodal Patient Journeys"
    },
    {
        "review": {
            "id": "MQZZCNEBVE",
            "forum": "ELlBpc0tfb",
            "replyto": "ELlBpc0tfb",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9035/Reviewer_egz5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9035/Reviewer_egz5"
            ],
            "content": {
                "summary": {
                    "value": "This article proposes a counterfactual medical image generation method that can generate high-quality counterfactual images guided by natural language. To achieve this, the authors use multimodal medical imaging information such as sequential images and medical reports to generate progress descriptions of image sequences using GPT-4. Based on the sequential images, reports, and these progress descriptions, a two-stage training diffusion model is used for image generation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. A method is proposed to generate counterfactual medical images based on natural language descriptions.\n2. Curriculum learning is introduced to make full use of the ability of non-sequential images to enhance the base model.\n3. GPT-4 is used to process textual information about disease progression in the training set and generate intermediate progress descriptions. Detailed and feasible descriptions are provided for constructing the training set.\n4. The ability of generating counterfactual medical images is evaluated on multiple test sets including pathology, race, age, spatial alignment, etc."
                },
                "weaknesses": {
                    "value": "1. The corresponding reference image in the training set should be included in Figure 4.\n2. The accuracy of descriptions generated by GPT-4 lacks evaluation, which directly affects whether the generated images are correct or not."
                },
                "questions": {
                    "value": "1. Why use the word `counterfactual` instead of direct `image editing`? The latter is more intuitive and understandable. Since reference images already exist in this case, such image generation does not appear counterfactual.\n2. In Table 4, MedJourney has more accurate segmentation results than Reference Image; does this mean that segmentation results are difficult to evaluate the quality of generated images?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9035/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9035/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9035/Reviewer_egz5"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9035/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698727942560,
            "cdate": 1698727942560,
            "tmdate": 1699637138267,
            "mdate": 1699637138267,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "frRuIHVGxu",
                "forum": "ELlBpc0tfb",
                "replyto": "MQZZCNEBVE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9035/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9035/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your insightful comments and suggestions. Below we will address all the questions and concerns. \n\n# Re adding reference image in Figure 4: \n\nThanks for the suggestion. We have the reference image in Figure 5, second from left on top row. We will add it to Figure 4 in the final version.\n\n# Re GPT-4 evaluation:\n\nAlthough GPT-4 has no specialized training in biomedicine, many prior studies have demonstrated its impressive capabilities in understanding and processing biomedical text. E.g., book by Peter Lee et al. on: \u201cThe AI Revolution in Medicine: GPT-4 and Beyond.\u201d offers insights into this aspect.\n\nAdditionally, one of the coauthors, a board-certified practicing radiologist at a top US medical school, has played a crucial role in assessing the utility of GPT-4 in our context. The progression description generated by GPT-4 appears reasonable upon preliminary examination. We will add more systematic assessments in the final version. \n\nTo illustrate, here are some examples reviewed by the radiologist, comparing GPT-4 vs orginal text: \n|Impression| GPT-4 |\n|-----| -----|\n\u201cResolving right middle lobe pneumonia. A followup chest radiograph in 4 weeks is recommended. If the right middle lobe opacity fails to completely resolve by that time, a chest CT should be performed at that time to exclude an endobronchial lesion. New small right pleural effusion.\u201d |\u201dResolving right middle lobe pneumonia. New small right pleural effusion.\u201d|\n\u201cSubtle right lower lobe opacity may represent early pneumonia. These findings were discussed with Dr. _ by Dr. _ at 2:30 p.m.\u201d |\"Subtle right lower lobe opacity may represent early pneumonia.\"\n\nThese examples demonstrate GPT-4's ability to succinctly summarize key radiological findings, which aligns well with clinical needs and workflow efficiency. This aspect will be further elaborated in the final version of our manuscript.\n\nLikewise, in addition to the quantitative evaluation, we have conducted several review sessions with the aforementioned radiologist co-author, who expressed satisfaction with the image generation quality. We will mention this in the final version. Thanks much for your suggestion.\n\n\n# Re counterfactual vs image editing:\n\nWe agree that the underlying technique might share a lot of similarity, but the real-world semantics are quite different. In biomedicine, a clinician won\u2019t be thinking about this generation problem as editing an image. Instead, their interest lies in counterfactual reasoning,  i.e., projecting what if the patient\u2019s condition has progressed in certain ways. Many prior works have studied the \u201cCounterfactual\u201d factor for medical images, e.g. Cohen et, al. \u201cGifsplanation via Latent Shift: A Simple Autoencoder Approach to Counterfactual Generation for Chest X-rays\u201d; Sumedha Singla, et, al. \u201cExplaining the Black-box Smoothly- A Counterfactual Approach\u201d. In this context, counterfactual just means answering what if questions, which could be with or without the prior image. However, in the case of progression modeling, the patient already has some prior image taken. So it is natural to condition on the prior image, rather than generating a newmage from scratch without any constraints. This distinction is pivotal in our research, as it aligns with the clinical workflow and decision-making processes, emphasizing the practical applicability in real-world medical settings. We will mention this in the final version. \n\n\n# Re Table 4:\n\nThanks for the insightful comment. Here, we are comparing the similarity of a generated image with the prior image. The reference image may have lower DICE score due to variations in the creation process for the consecutive images, which are taken at different times, potentially by different clinicians with different machines. This variation is a typical characteristic in clinical imaging and does not imply inferiority of the reference image.\n\nBy contrast, the extremely low scores for baseline systems indicate that they are completely off base with respect to the prior image. \n\nWe will clarify this in the final version."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9035/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700702562214,
                "cdate": 1700702562214,
                "tmdate": 1700702562214,
                "mdate": 1700702562214,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "GuciZO5m4z",
            "forum": "ELlBpc0tfb",
            "replyto": "ELlBpc0tfb",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9035/Reviewer_jLph"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9035/Reviewer_jLph"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a method for counterfactual medical image generation leveraging instruction-learning from multimodal patient journeys. Amidst rapid advancements in image editing using natural-language instruction, as seen with \"InstructPix2Pix,\" there remains a significant gap in biomedicine. Current models, though effective in generic contexts, fall short in the biomedical domain. MedJourney addresses this by generating counterfactual medical images based on instruction-learning from patient data. The method involves processing two medical images taken at different time points, using GPT-4 to generate a natural language description of disease progression based on associated reports. This information is used to train a latent diffusion model for image generation. Due to the limited availability of image time-series data, the authors employ a two-stage curriculum: first pretraining with abundant single image-report pairs, followed by training with counterfactual triples. Experiments on the MIMIC-CXR dataset reveal MedJourney's superior performance over existing methods like InstructPix2Pix and RoentGen."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Strengths:\n1. **First paper to develop models for counterfactual image generation in the medical domain**:\nThe paper emphasizes the largely unexplored domain of unconstrained counterfactual medical image generation. While there have been attempts in the biomedical imaging field to answer \"what if\" questions, existing methods primarily focus on simple image class changes, akin to predefined class edits. MedJourney stands out as it closely follows arbitrary natural-language descriptions of disease progression to generate counterfactual images, making it a pioneering method in the field.\n\n2. **The innovative use of GPT-4 to extract the progression description**:\nMedJourney uniquely leverages the GPT-4 model to generate a natural language description of disease progression. When given two medical images from different time points of a patient, manually synthesizing image-editing instructions from their reports can be both expensive and time-consuming. Instead of manual synthesis, the authors utilize GPT-4 to generate these descriptions automatically from the imaging reports, offering a scalable solution.\n\n3. **Benchmarked against general domain method: InstructPix2Pix**:\nIn the rapidly evolving field of image editing with natural language instruction, InstructPix2Pix has been a benchmark. However, models like InstructPix2Pix, trained on generic images and text, might not be optimally suited for the nuanced biomedical domain. MedJourney, in its extensive tests on the MIMIC-CXR dataset, not only compared its performance with methods tailored for the medical domain like RoentGen but also with general domain methods like InstructPix2Pix. The results showed that MedJourney substantially outperforms these state-of-the-art methods in both instruction image editing and medical image generation.\n\n4. **Authors gave an honest attempt at establishing quantitative evaluation metrics**:\nRecognizing the complexity and challenges associated with evaluating counterfactual medical image generation, the authors introduced an extensive suite of tests. These tests include evaluations based on various factors such as pathology, race, age, and spatial alignment. This can be certainly improved upon but it is at least a step in the right direction."
                },
                "weaknesses": {
                    "value": "Areas for improvement:\n\n1. **Comparison to more recent works that closely follow the instruction and reference image**:\nWhile MedJourney has shown promise in counterfactual medical image generation, it lacks a direct comparison with more recent works, such as \"Imagic: Text-Based Real Image Editing with Diffusion Models.\" Imagic, designed to closely follow instructions and reference images, is potentially better suited for the tasks that MedJourney addresses with medical images. A side-by-side comparison or integration of insights from Imagic could potentially strengthen the robustness and applicability of MedJourney.\n\n2. **Need for reader study in addition to quantitative metrics for qualitative evaluation of different methods**:\nWhile the authors have introduced a comprehensive suite of quantitative tests, the paper could benefit from a reader study that provides qualitative insights. Direct feedback from radiologists or medical experts on the interpretability, authenticity, and clinical utility of the counterfactual images would enhance the evaluation depth and offer a more holistic understanding of MedJourney's real-world applicability.\n\n3. **Ethical considerations and limitations are not discussed**:\nThe application of AI in the medical domain has inherent ethical implications. Given that counterfactual medical images could influence clinical decisions, the absence of a discussion on the ethical considerations and potential risks associated with MedJourney is a significant oversight. Addressing these concerns would not only ensure the safe deployment of such methods but also enhance trust among medical practitioners and patients.\n\n4. **How well does it apply to other medical image datasets?**\nWhile MedJourney's performance on the MIMIC-CXR dataset is commendable, its generalizability across diverse medical imaging modalities remains uncertain. Demonstrating its efficacy on a broader range of datasets, such as MRI, CT scans, or ultrasounds, would substantiate its versatility. Furthermore, insights into how the method adapts and performs across different diseases, anatomical regions, or imaging techniques would solidify its position as a universally applicable counterfactual medical image generation tool.\n\n5. **Minor edits**: All citations should be in parenthesis. In many place, the parenthesis are missing which messes up the main text. Please correct those.\n\n6. **Demographic diversity is crucial for medical datasets**: \nMedical datasets must accurately represent the diverse patient populations they serve to ensure that AI models generalize well across varied demographic groups. The authors acknowledge in the appendix that the dataset has an overrepresentation of the white elderly population. Such biases can inadvertently lead to models that perform sub-optimally or even erroneously for underrepresented groups, which can have significant clinical implications. Highlighting this limitation in the main body of the paper, especially in sections like 'Limitations' or 'Discussion,' would underscore the importance of demographic diversity. It would also serve as a call to action for researchers to actively pursue more balanced datasets, ensuring equitable healthcare outcomes for all patients regardless of their background.\n\n7. **Add FID as an additional metric**: Please add FID as an additional qualitative metric to evaluate different methods. See UnixGen and RoentGen paper for details on the FID metric."
                },
                "questions": {
                    "value": "If authors address the areas of improvement, I would be open to update my score."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Discrimination / bias / fairness concerns",
                        "Yes, Privacy, security and safety"
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "1. **Demographic diversity is crucial for medical datasets**: \nMedical datasets must accurately represent the diverse patient populations they serve to ensure that AI models generalize well across varied demographic groups. The authors acknowledge in the appendix that the dataset has an overrepresentation of the white elderly population. Such biases can inadvertently lead to models that perform sub-optimally or even erroneously for underrepresented groups, which can have significant clinical implications. Highlighting this limitation in the main body of the paper, especially in sections like 'Limitations' or 'Discussion,' would underscore the importance of demographic diversity. It would also serve as a call to action for researchers to actively pursue more balanced datasets, ensuring equitable healthcare outcomes for all patients regardless of their background.\n\n2. **Ethical considerations and limitations are not discussed**:\nThe application of AI in the medical domain has inherent ethical implications. Given that counterfactual medical images could influence clinical decisions, the absence of a discussion on the ethical considerations and potential risks associated with MedJourney is a significant oversight. Addressing these concerns would not only ensure the safe deployment of such methods but also enhance trust among medical practitioners and patients."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9035/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698810693628,
            "cdate": 1698810693628,
            "tmdate": 1699637138136,
            "mdate": 1699637138136,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dxikQHQPFW",
                "forum": "ELlBpc0tfb",
                "replyto": "GuciZO5m4z",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9035/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9035/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your insightful comments and suggestions. Below we will address all the questions and concerns.\n\n# Re comparison to Imagic:\n\nThanks for this suggestion. Imagic requires per-example inversion and fine-tuning. Namely, for each input image and target description, it requires a fine-tuning process to obtain an optimal text embedding close to the target description, fine-tune the diffusion model conditioned on the optimal text embedding (rather than noise in the original diffusion model), and then apply the newly fine-tuned diffusion model to an interpolation of original & target text embeddings to generate the new image. This is very cumbersome and not very generalizable. \n\nBy contrast, our method builds on the more recent InstructPix2Pix method, which learns a single model that can generate new image in a single forward pass, without requiring elaborate text embedding and diffusion learning for each test example as in Imagic.\n\nWe will add discussion to explain why our method is superior to the Imagic approach.\n\n\n# Re reader study by radiologist: \n\nOne of the coauthors is a board-certified practicing radiology at a top US medical school. In addition to the quantitative evaluation, we have conducted several review sessions with this radiologist co-author, who expressed satisfaction with the generation quality. We will mention this in the final version. Thanks much for your suggestion.\n\n\n# Re ethical considerations and limitations:\n\nThanks much for this insightful suggestion. We have discussed limitations in the Appendix. But as you suggested, this is such an important aspect that we will move our existing discussion on limitations to the main body and add additional considerations for ethical implications.\n\n\n# Re generalization to other medical image datasets:\n\nThanks much for this suggestion. While we tried to break new ground in counterfactual medical image generation, this is just the first baby step towards a universally applicable tool. We plan to explore exactly along the directions you have outlined in future work.\n\n# Re citation: \n\nThanks for the good catch! We will fix them.\n\n# Re demographic diversity:\n\nThanks much for this insightful suggestions. We will move our discussion about demographic diversity to the main body. \nFurther, we have conducted additional evaluations focusing specifically on racial diversity. Our analysis compared image generations for the dominant demographic group (white) and an underrepresented group (black). Despite the training data itself being skewed in terms of racial representation (**17%** black vs **78%** white), our results are promising. MedJourney successfully retained the racial features of the prior image with high fidelity, scoring **0.92** for the underrepresented group and **0.98** for the dominant group (we used the SOTA image race classifier, as mentioned in sec 4.3, as evaluator and AUC as metric). This indicates our MedJourney has a decent property of preserving demographic diversity,  and further suggests that it may contribute to mitigating racial representation disparities through data augmentation for underrepresented groups. \nWhile our results are promising, they also emphasize the crucial need for balanced datasets in medical research. We will include this insight in the final version.\n\n# Re adding FID metric: \n\nThanks for the suggestion. We have incorporated this metric into our analysis and will present it in the final version. The FID results are as follows: \n| Method| FID|\n|-|-| \n| Stable Diffusion| 291.13\n|InstructPix2Pix| 180.72\n|RoentGen| 42.61\n|MedJourney| **29.68**\n\nWe believe these results further demonstrate the effectiveness of MedJouney."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9035/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700704839314,
                "cdate": 1700704839314,
                "tmdate": 1700710905461,
                "mdate": 1700710905461,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "nEQXRC38QP",
            "forum": "ELlBpc0tfb",
            "replyto": "ELlBpc0tfb",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9035/Reviewer_A6Mk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9035/Reviewer_A6Mk"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses the challenge of generating counterfactual medical images. It involves a two-step process: initially, it utilizes GPT-4 to create a natural language narrative describing the progression of a disease based on two medical reports corresponding to images taken at different times. Subsequently, the paper employs a latent diffusion model to produce the counterfactual medical images. The experimental evaluation using MIMIC-CXR demonstrates a significant improvement over previous methods, particularly in aligning pathology, race, and age in the generated counterfactual images."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper investigates the unique problem of counterfactual image generation, generating counterfactual images from description of disease progression. It introduces a curriculum learning technique for generating counterfactual images using these progression descriptions. This approach is novel and would interest the machine learning and medical imaging community.\n\n- The paper is well-structured, making it straightforward and easy to follow.\n\n- The methodology used for evaluating pathology, race, and age classification, along with the CMIG score that measures both accuracy and feature retention, provides a practical and insightful perspective on the issue."
                },
                "weaknesses": {
                    "value": "The paper's enhancement primarily hinges on text processing and image registration, both of which raise concerns:\n\n- **Concerns with Text Processing using GPT-4**:\n    - **Validity of Disease Progression**: he paper does not indicate whether the disease progression generated by GPT-4 has been compared or verified against radiologists' opinions. Such a comparison is crucial for establishing the reliability of the generated progression description.\n    - **Lack of Sanity Checks**: There seems to be no mention of sanity checks for the progression generated between two images. Considering GPT-4's capability to generate progression even for unrelated images of different patients, it's vital to understand how the paper ensures the accuracy and relevance of these progressions.\n    - **Comparison between Impression Section and GPT-4 Usage**: The advantages of using GPT-4 over the impression section in reports are minimal (as evident in Table 2). Clarification on how the impression section was used and whether GPT-4 is actually essential for this study would be beneficial, given the marginal gains across metrics.\n\n- **Image Registration Contribution**:\n    - The substantial improvements seem to stem from image registration, primarily leveraging the SimpleITK toolkit (Beare et al. 2018). This raises concerns about the originality of the MedJourney method's contributions. An expanded discussion on how image registration was adapted for the proposed method would provide a clearer understanding of its impact.\n\nAdditional Question:\n\n- Concerning the pathology classifier, it's unclear which report's reference pathology labels are used. Are these labels compared with those generated in Cohen et al. 2021, which are used for assessing the counterfactual image model? Clarification on this process would be helpful.\n\n- **Prompt Requirement**: The necessity of the prompt \u201ca photo of chest x-ray\u201d is not justified. Including results without this prompt might offer more insight into its impact.\n\nMinor Issues:\n- There's a missing citation for GPT-4 in the related work section on page 3.\n- Figure 3 could be better placed in the experiments section, as it is not referenced beforehand.\n- Figure 1 is not referenced in the text.\n- Paper uses Figure and Fig. interchangeably."
                },
                "questions": {
                    "value": "Kindly refer to the concerns raised in the above section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9035/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698873850684,
            "cdate": 1698873850684,
            "tmdate": 1699637137956,
            "mdate": 1699637137956,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "k5DmQaVGAr",
                "forum": "ELlBpc0tfb",
                "replyto": "nEQXRC38QP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9035/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9035/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your insight comments and suggestions. Below we will address all the questions and concerns.\n\n# Re concerns with text processing:\n\n**Validity of disease progression**: Thanks for the suggestion. One of the coauthors is a board-certified practicing radiology at a top US medical school. The progression description generated by GPT-4 appears reasonable upon preliminary examination. We will add more systematic assessments in the final version. In general, although GPT-4 has no specialized training in biomedicine, many prior studies have demonstrated its amazing capabilities in understanding and processing biomedical text. E.g., see the book by Peter Lee et al. on: \u201cThe AI Revolution in Medicine: GPT-4 and Beyond.\u201d\n\n**Lack of sanity check**: In addition to the quantitative evaluation, we have conducted several review sessions with the aforementioned radiologist co-author, who expressed satisfaction with the generation quality. We will mention this in the final version. Thanks much for your suggestion.\n\n**Comparison between Impression and GPT-4**: The impression section is taken from the gold report describing the target image. The small difference between using impression vs GPT-4 generated progression may stem from the characteristics of this dataset, where in many cases the first image is normal, and thus the pathological description of the follow-up image essentially describes progression. Additionally, some impression would include comparison against the prior image, also similar to what GPT-4 would generate as progression. As in 5.3 \u201cimpression v.s. GPT-4 generation\u201d, GPT-4 generated is usually more succinct (averaging 146 characters v.s. 179) and more naturally phrased. For example,\n|Impression| GPT-4 |\n|-----| -----|\n\u201cResolving right middle lobe pneumonia. A followup chest radiograph in 4 weeks is recommended. If the right middle lobe opacity fails to completely resolve by that time, a chest CT should be performed at that time to exclude an endobronchial lesion. New small right pleural effusion.\u201d |\u201dResolving right middle lobe pneumonia. New small right pleural effusion.\u201d|\n\u201cSubtle right lower lobe opacity may represent early pneumonia. These findings were discussed with Dr. _ by Dr. _ at 2:30 p.m.\u201d |\"Subtle right lower lobe opacity may represent early pneumonia.\"\n\n# Re image registration contribution:\n\nNote that image registration is only a preprocessing step that helps align the two consecutive images for a given patient in the training data. This is a standard technique to reduce immaterial variations of images taken at different times by different technicians, e.g., translational shift or rotation. Image registration alone can\u2019t perform counterfactual image generation and is thus irrelevant with respect to the novelty of MedJourney. We will clarify this in the final version.\n\nA significant challenge in our research was the limited dataset size (approximately 10,000 triplets), posing the risk of learning spurious correlations due to minor, non-essential variations in images. By implementing image registration, we effectively minimized these immaterial variations, enabling the model to focus on material changes indicative of disease progression.\n\nThis image registration procedure is used merely for preprocessing training data. This procedure is illustrated in Appendix Figure 8, and to enhance understanding, we will move it to the main part in the final version.  \n\nThis innovative use of image registration in our specific learning pipeline is, to our knowledge, unprecedented in both generic and medical image generation research. We want to reiterate that, image registration cannot generate counterfactual image on its own, its use in MedJourney represents an inventive adaptation of existing techniques, augmenting rather than diminishing the method's originality."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9035/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700708849577,
                "cdate": 1700708849577,
                "tmdate": 1700721363221,
                "mdate": 1700721363221,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]