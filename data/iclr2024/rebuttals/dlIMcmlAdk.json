[
    {
        "title": "Noise-free Score Distillation"
    },
    {
        "review": {
            "id": "SZsgqBnBTH",
            "forum": "dlIMcmlAdk",
            "replyto": "dlIMcmlAdk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5101/Reviewer_EnYB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5101/Reviewer_EnYB"
            ],
            "content": {
                "summary": {
                    "value": "This work tackles the blurry results from Score Distillation Sampling (SDS) for text-to-3D generation. The score is decomposed into the condition, domain, and noise residual terms; the proposed method is designed to reduce the effect of the undesired noise component, by heuristically estimating the domain term with a negative prompt."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Text-guided 3D generation by leveraging pretrained text-to-image models is a hot, timely topic. The authors propose to improve the famous SDS-based framework with a small modification.\n- The proposed decomposition can be also used to understand existing works (DDS and VSD), which seems like a valuable contribution.\n- The paper is well-written; the terms and derivations are clearly presented."
                },
                "weaknesses": {
                    "value": "- Although a key value of this work seems to be the decomposition of the SDS loss, I have a few questions on designing the proposed ~NFSW~ NFSD method (<- apologize for this big typo at the initial review):\n  - How did the authors separate the small and large timestep values based on t=200? Why not t=100, 300, or 400?\n  - Is it valid to assume \u03b4_{C=p_neg} \u2248 \u2212\u03b4_{D}? Did the choice of the negative prompt affect the performance?\n  - How about changing (6) into just using the second part of (6) for all the time steps (i.e., unconditional term - negative-prompt-induced term, for all the time steps)?\n- I appreciate the effort for many visual results; however, the lack of any quantitative results concerns me a lot. Is it possible to include the comparison using CLIP R-Precision of Table 1 in the DreamFusion paper? Furthermore, leveraging the MS-COCO text-to-image benchmark with FID/IS/CLIP score metrics may be worth trying to justify the results of 2D image generation in Figure 7."
                },
                "questions": {
                    "value": "Please refer to the Weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No ethics review needed."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5101/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5101/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5101/Reviewer_EnYB"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5101/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698584807101,
            "cdate": 1698584807101,
            "tmdate": 1700623991426,
            "mdate": 1700623991426,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "g1YAq20hFj",
                "forum": "dlIMcmlAdk",
                "replyto": "SZsgqBnBTH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5101/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5101/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to reviewer EnYB"
                    },
                    "comment": {
                        "value": "Thank you for your time and constructive questions. We address them below:\n\n\n**How did the authors separate the small and large timestep values based on $t=200$? Why not $t=100, 300$, or $400$?**\n\nWe added ablation studies in Appendix A.5, including an ablation on this threshold. As can be seen in the results presented in Figure 12, $t\\_s=200$ provides the best tradeoff between fine details and artifacts.\n\n**Is it valid to assume $\\delta\\_{C=p\\_\\text{neg}} \u2248 \u2212\\delta\\_\\text{D}$? Did the choice of the negative prompt affect the performance?**\n\nWe added a discussion that motivates this choice in Appendix A.4. As explained there, there is a close relation between this assumption and the common technique of using negative prompts in ancestral sampling to improve image quality.\nThe negative prompt was kept fixed during all experiments (both images and NeRFs). Our method is not sensitive to the exact choice of words in the negative prompt, and other combinations of negative words do not have much impact.\n\n\n**How about changing (6) into just using the second part of (6) for all the time steps (i.e., unconditional term - negative-prompt-induced term, for all the time steps)?**\n\nWe added ablation studies in Appendix A.5. In the time threshold ablation presented in Figure 12 we included results for $t\\_s=0$, in which the negative prompt term is applied for all timesteps.\n\n**Lack of any quantitative results concerns me a lot. Is it possible to include the comparison using CLIP R-Precision of Table 1 in the DreamFusion paper? Furthermore, leveraging the MS-COCO text-to-image benchmark with FID/IS/CLIP score metrics may be worth trying to justify the results of 2D image generation in Figure**\n\n\nAs mentioned in our conclusion section, quantitatively comparing NeRFs generated from text prompt remains a challenge due to the absence of suitable metrics and benchmarks. Additionally, most works do not provide an official implementation which makes the quantitative evaluation even more tricky. Therefore, we chose to provide a large gallery of results (with prompts *taken* from the baseline works) to allow the reader to get an impression and to directly assess the quality of our results compared to other works.\nYet, we add quantitative evaluation in Appendix A.6, measuring FID on generated images with NFSD and SDS-100, and presenting user study results, following Magic3D and ProlificDreamer.\nAs can be seen in Table 1, our method achieves lower (better) FID compared to SDS-100, confirming the better quality achieved by our method.\nAs can be seen in Table 2, our method also achieved the best results in both prompt alignment and image quality in the user study. We suspect that in the prompt alignment question responders were biased by the superior image quality of our results. Note that our results are aligned with the results shown in the user study in ProlificDreamer, in the sense that in both studies ProlificDreamer got better results than Fantasia3D, which, in turn, got better results than Magic3D."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5101/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700253093273,
                "cdate": 1700253093273,
                "tmdate": 1700253093273,
                "mdate": 1700253093273,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zl7lqpZJEP",
                "forum": "dlIMcmlAdk",
                "replyto": "g1YAq20hFj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5101/Reviewer_EnYB"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5101/Reviewer_EnYB"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your effort and time on this rebuttal. I\u2019ve reread the revised paper and other reviewers\u2019 comments. I am generally satisfied with the rebuttal and appreciate the additional ablation studies and strengthened quantitative evaluation. I think I assigned my highest score in the initial review phase, and the following things would be good to address.\n\n- I appreciate the proposed score decomposition and the further discussion on the relationship to using negative prompts in Sect. A.4. It would be beneficial to add SDS-100+NP and NFSD+NP in Figure 7 and/or Table 1, since the effect of NP seems significant.\n\n- I appreciate Q1 raised by Reviewer eQLa and the subsequent discussion regarding diversity. I am looking forward to seeing the revision in the last paragraph of Sect. 3 (the issue of less diverse results).\n\n- This does not affect the score, but it would be great to see if the hyperparameters found for SD-2.1-base can be applicable to other SD versions with the same latent dimensions (e.g., SD-1.x using 64x64) or with enlarged dimensions (e.g., SD-2.1 using 96x96)."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5101/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700496848542,
                "cdate": 1700496848542,
                "tmdate": 1700496848542,
                "mdate": 1700496848542,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "MoWY0RH56d",
            "forum": "dlIMcmlAdk",
            "replyto": "dlIMcmlAdk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5101/Reviewer_wypJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5101/Reviewer_wypJ"
            ],
            "content": {
                "summary": {
                    "value": "This paper reexamined the Score Distillation Sampling and proposed Noise-Free Score Distillation. The details of the images generated using SDS are more blurred, due to the slightly different distribution between the images generated by the generator(x(\\theta)) and the original image x. This paper found a decomposition to counteract this effect and the authors use this decomposition to explain why previous methods have improved SDS. Adequate experimental results also demonstrate the effectiveness of the methodology."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper proposed a decomposition method to solve the problem of ambiguous results caused by the different distribution of the images generated by the generator and the original images; and uses this decomposition method to explain why previous methods have improved SDS. The experimental results are intuitive."
                },
                "weaknesses": {
                    "value": "I'm concerned about whether p_{neg} = \u201cunrealistic, blurry, low quality, out of focus, ugly, low contrast, dull, dark, low-resolution, gloomy\u201d is generalizable across situations and able to cancel out \\delta_{N}. Would a better generator g(\\theta) be able to achieve the same effect, or train a model to estimate the bias \\delta_{N}?"
                },
                "questions": {
                    "value": "Please see the weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5101/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698825745701,
            "cdate": 1698825745701,
            "tmdate": 1699636501649,
            "mdate": 1699636501649,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "OA39HpO5Ki",
                "forum": "dlIMcmlAdk",
                "replyto": "MoWY0RH56d",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5101/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5101/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to reviewer wypJ"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their time and the concern they raised.  We have addressed it below.\n\n**I'm concerned about whether $p\\_\\text{neg}$ = \u201cunrealistic, blurry, low quality, out of focus, ugly, low contrast, dull, dark, low-resolution, gloomy\u201d is generalizable across situations and able to cancel out $\\delta\\_\\text{N}$. Would a better generator $g(\\theta)$ be able to achieve the same effect, or train a model to estimate the bias $\\delta\\_\\text{N}$?**\n\nWe evaluated our approach with two generators $g(\\theta)$, one that renders NeRFs, and the other is defined by $g(\\theta) = \\theta$. We used the same $p\\_\\text{neg}$ in both cases and observed that it generalizes across them.\nIt is worth mentioning that we observed that incorporating $\\delta\\_\\text{D}$ for the directly optimized image was more significant compared with adding it to the optimized NeRF. This is related to the NeRF representation which naturally provides regularization on the rendered images. Therefore, it is true that our implementation for $\\delta\\_\\text{D}$ affects differently on different generators $g$.\nAs mentioned in Section 5, training a model that estimates $\\delta\\_\\text{N}$ is exactly the method introduced in ProlificDreamer. We believe that presenting ProlificDreamer with this formulation helps to gain more intuition over their method, and see this as one of our contributions."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5101/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700253087490,
                "cdate": 1700253087490,
                "tmdate": 1700253087490,
                "mdate": 1700253087490,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "SEUdcpZHpw",
            "forum": "dlIMcmlAdk",
            "replyto": "dlIMcmlAdk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5101/Reviewer_opTp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5101/Reviewer_opTp"
            ],
            "content": {
                "summary": {
                    "value": "This paper first revisits Score Distillation Sampling (SDS) and proposes to decompose the updates generated by SDS into three components: domain correction, noise estimation, and condition direction. Through this approach, the authors provide an explanation for why SDS accommodates a high Classifier-Free Guidance (CFG) coefficient and introduce Noise-Free Score Distillation (NFSD). NFSD re-estimates the unconditional score using the negative prompt trick. As a result, NFSD can employ a standard CFG weight to alleviate the over-smoothing/saturation problem and enhance the quality of text-guided image editing and 3D asset generation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ The paper is well structured and organized. The method introduced in this paper is intuitive and straightforward to implement. The motivations behind the approach are vividly conveyed through clear formulations and effective visualizations.\n\n+ The decomposition of SDS is both novel and intriguing. It not only offers a compelling interpretation of the large CFG weight selection in DreamFusion but also offers valuable insights into DDS [1] and VSD [2].\n\n+ The empirical results clearly demonstrate a significant enhancement in 3D generation through the simple modifications initiated by NFSD.\n\n[1] Hertz et al., Delta Denoising Score, 2023\n\n[2] Wang et al., ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation, 2023"
                },
                "weaknesses": {
                    "value": "- While the explanation is intuitively presented, it remains somewhat challenging to discern the fundamental distinction from the negative prompt trick.\n\n- In Sec. 5, the paper asserts that NFSD is notably more efficient than VSD, despite sharing a similar working mechanism. Although this claim appears obvious, I would recommend providing quantitative evidence to substantiate this advantage when compared to other baseline methods. It is conceivable that dropping the noise term could even speed up the convergence of ancestral sampling by using fewer optimization steps.\n\n- Further ablation studies are needed to validate the assertions put forth in this paper. In comparison to SDS, two terms have been omitted according to Eqs. 5 and 7: the noise prediction $\\delta_N$ and the noise ground truth $\\epsilon$. However, it remains unclear which of these terms plays the most pivotal role in improving the final results."
                },
                "questions": {
                    "value": "1. Furthermore, it is not evident how steering the update of SDS could alter the optimization objective. Providing a more rigorous and formal argument would deepen the contribution of this work.\n\n2. The authors introduce Eq. 6 to estimate $\\delta_D$. Can the authors offer a rationale or justification for this approximation? Additionally, including visualizations that align with Fig. 3 would enhance the clarity and understanding of this proposal."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5101/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5101/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5101/Reviewer_opTp"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5101/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698901761307,
            "cdate": 1698901761307,
            "tmdate": 1699636501548,
            "mdate": 1699636501548,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "d0GwdpmjTC",
                "forum": "dlIMcmlAdk",
                "replyto": "SEUdcpZHpw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5101/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5101/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to reviewer opTp"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their detailed comments and questions. We address them below:\n\n**It remains somewhat challenging to discern the fundamental distinction from the negative prompt trick.**\n\nStemming from the presented score decomposition, our fundamental distinction is that $\\delta\\_\\text{C}$ and $\\delta\\_\\text{D}$ should be used to optimize the parameters $\\theta$. While it is clear how to calculate $\\delta\\_\\text{C}$, separating $\\delta\\_\\text{D}$ from $\\delta\\_\\text{N}$ remains a challenge.\nWe added a discussion about negative prompts in Appendix A.4, motivating our definition of $\\delta\\_\\text{D}$ by relating it to the common practice of negative prompts.\nPlease note that we see the exact definition of $\\delta\\_\\text{D}$ as an implementation detail for applying our main observation.\n\n\n**In Sec. 5, the paper asserts that NFSD is notably more efficient than VSD, despite sharing a similar working mechanism... I would recommend providing quantitative evidence. It is conceivable that dropping the noise term could even speed up the convergence of ancestral sampling by using fewer optimization steps.**\n\nFor 2D-image generation, trained on a single RTX2080 for 1K iterations, on average:\n\nSDS - 2.9 [min]  NFSD - 4.3 [min] and Prolific - 8 [min]\n\nFor NeRF generation, trained on a single A100 for 25K iterations, on average:\n\nSDS - 3.1 [hr], NFSD - 3.5 [hr] and Prolific - 4.5 [hr]\n\nPlease note that we did not optimize our implementation.\nThe noise term is undesirable for score distillation sampling. In contrast, for ancestral sampling, the score (comprising the noise term) is inherent to the step-by-step stochastic progression.\n\n**Further ablation studies are needed to validate the assertions put forth in this paper. In comparison to SDS, two terms have been omitted according to Eqs. 5 and 7: the noise prediction $\\delta\\_\\text{N}$ and the noise ground truth  $\\epsilon$. However, it remains unclear which of these terms plays the most pivotal role in improving the final results.**\n\nIn practice, the difference between SDS and our NFSD is that for $t < t\\_s$ we do not subtract the added noise $\\epsilon$, where $t\\_s=200$, and for $t >= t\\_s$ we subtract $\\epsilon(z\\_t, p\\_\\text{neg}, t)$ (instead of subtracting $\\epsilon$). We added ablation studies in Appendix A.5, where we ablate the following:\n* Subtracting $\\epsilon(\\mathbf{z}\\_t, p\\_\\text{neg}, t)$ in all timesteps (instead of subtracting $\\epsilon$ in SDS) ($t\\_s=0$ in Figure 12)\n* Not subtracting $\\epsilon$ from SDS loss in all timesteps ($t\\_s=1000$ in Figure 12)\n* Change the threshold $t\\_s$ (Figure 12)\n* Using only $\\delta\\_\\text{C}$ as the loss (leftmost column in Figure 13)\n\n\n**It is not evident how steering the update of SDS could alter the optimization objective. Providing a more rigorous and formal argument would deepen the contribution of this work.**\n\nWe developed NFSD with the perspective of score function distillation, aiming to distill the score of a diffusion model for optimizing the parameters of rendered images. We observed that the score distilled in SDS includes a noise component, resulting in an averaging effect, leading to a local optimum that is overly smooth and lacks detail. NFSD attempts to avoid this noise component, allowing the optimization process to converge to a better local optimum.\nThe optimization objective for diffusion time $t < t_s$ is similar to SDS, while for $ t \\geq t\\_s$ it can be shown that $\\nabla\\_\\theta \\mathcal{L}\\_{\\textrm{NFSD}} =\\nabla\\_\\theta \\mathbb{E}\\_{t}\\left[w(t)\\frac{\\sigma\\_t}{\\alpha\\_t}\\textrm{KL}\\left(q(\\mathbf{z}\\_t|g(\\theta);y,t)\\parallel \\frac{1}{Z}\\frac{p\\_\\phi(\\mathbf{z}\\_t;y,t)}{p\\_\\phi(\\mathbf{z}\\_t;y\\_{neg},t)}\\right)\\right]$, where $Z$ is a normliazation factor. \nHowever, we find the optimized objective to lack intuitiveness and offer only little additional insight into NFSD. Therefore, we choose to focus on the score decomposition formulation.\n\n\n**The authors introduce Eq. 6 to estimate  $\\delta\\_\\text{D}$ Can the authors offer a rationale or justification for this approximation? Additionally, including visualizations that align with Fig. 3 would enhance the clarity and understanding of this proposal.**\n\nSeparating $\\delta\\_\\text{D}$ from $\\delta\\_\\text{N}$ is challenging. We found that for small enough timesteps (e.g., $t<200$) $\\delta\\_\\text{N}$ is negligible and therefore $\\epsilon(\\mathbf{z}\\_t, \\varnothing, t) = \\delta\\_\\text{N} + \\delta\\_\\text{D}$ provides a good enough approximation for $\\delta\\_\\text{D}$.\nFor other timesteps, we approximate $\\delta\\_\\text{D}$ by $-\\delta\\_{C=p\\_\\text{neg}}$. The discussion we added in Appendix A.4 motivates the use of a negative prompt to define $\\delta\\_\\text{D}$.\nAdditionally, to show the effect of our defined $\\delta\\_\\text{D}$ in a similar manner to Figure 3, we added Figure 10  where we extract $\\delta\\_\\text{D}$ from the definition in Eq. (6) (two rightmost images on the bottom row)."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5101/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700253082918,
                "cdate": 1700253082918,
                "tmdate": 1700253082918,
                "mdate": 1700253082918,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "dDx0OjKT6j",
            "forum": "dlIMcmlAdk",
            "replyto": "dlIMcmlAdk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5101/Reviewer_eQLa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5101/Reviewer_eQLa"
            ],
            "content": {
                "summary": {
                    "value": "This study proposes a simple yet effective method, Noise-Free Score Distillation (NFSD), to improve the conventional score distillation using a minimal modification. This study decomposes the score with classifier-free guidance (CFG)  into three terms, the condition, the domain, and the denoising components. Then, they remove the prediction error on unconditional samples between the estimated scores and and injected noises, since the score prediction error on unconditional samples is noisy. The domain score is estimated by a text prompt for a text-to-image model. The experimental results show that extremely high scale of CFG in score distillation is unnecessary, and NFSD can improve fine-grained details of generated images or neural fields."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "S1. The proposed method, NFSD, is simple yet effective. In addition, the qualitative results support and demonstrate the effectiveness of NFSD.\n\nS2. The paper is well-organized and easy to understand.\n\nS3. The analogical decomposition of scores into three terms is interesting and makes sense."
                },
                "weaknesses": {
                    "value": "W1. Despite the interestingness of score decomposition, the proposed method stems from numerous assumptions based on empirical findings without a principal approach.\n\nW2. Thorough experiments to validate the effectiveness of NFSD are absent. Although the qualitative results show improved quality of text-to-NeRF than conventional SDS-based approaches, there is no ablation study and quantitative result. \n\nW3. Some technical parts lack enough rationales. For example, estimating the domain score by negative text prompts lacks the rationales."
                },
                "questions": {
                    "value": "Q1. Although the authors discuss the low diversity of NFSD, I wonder the detailed reason why the reduced CFG scale cannot produce diverse visual contents. In addition, can the authors provide the samples with different seeds and the same text prompts to show the diversity of generated contents?\n\nQ2. In Figure 3, what is the diffusion timestep? In addition, I think that the authors should show the results of \n$x_{\\text{OOD}} + \\delta_D + \\delta_N^{\\text{OOD}}$\n, where $\\delta_N^{\\text{OOD}}$ is the denoising score of $x_\\text{OOD}$, not $x_\\text{ID}$. I also suggest clarifying the notation of $\\delta_N$ and $\\delta_D$ in Figure 3, since the two scores are from different samples. \n\nQ3. Why do the prediction errors in Figure 4 (the second row) show a less-noisy map at t=1000? I think that the results are unintuitive, since they indicate that the score prediction at t=1 is difficult, while the score prediction at t=1000 is conducted almost perfectly except for the central region. \n\nQ4. In Section 4, the authors claim that the magnitude of the noise to be removed is monotonically decreased in the backward process. I wonder how we can assume that the scale of the domain score is preserved? Is there any rationale that only $\\delta_N$ decreases over the backward process, while $\\delta_D$ preserves its scale?\n\nQ5. How about the results of SDS, where its CFG adopts the same negative prompts as NFSD, described in Section 4?\n\nQ6. The authors have discussed that ProlificDreamer\u2019s LoRA adaptation has a similar role with NFSD to exclude the prediction error of the denoising term $\\delta_N$. Then, can the LoRA of ProlificDreamer be replaced with NFSD, while variational particle optimization is used? It would be interesting to show the compatibility of NFSD with ProlificDreamer.\n\nQ7. Since NFSD requires additional inference at each training iteration due to negative prompting, I think that comparing the results of NFSD with those of SDS in terms of the number of function evaluations (NFEs) of diffusion models. \n\nQ8. In Section 4, how can we assume that the score prediction on text conditions is also composed of $\\delta_D + \\delta_N + \\delta_C$, where $\\delta_D + \\delta_N$ is equal to the unconditional prediction? I think that it is a technical flaw, since Eq.(3) just implies $\\epsilon_\\phi (z_t ; t) - \\epsilon_\\phi (z_t  ; y=p_\\text{neg}, t) = \\delta_{C=p_\\text{neg}}$. That is, $\\delta_C$ is defined with both conditional and unconditional scores, not solely on the conditional score term. \n\nQ9. How is the negative prompt to estimate the domain term defined? I wonder whether the negative prompt is universal regardless of the image renderer. In addition, it assumes that the domain score can be estimated by the text prompts. However, how can we say that the image is from out-of-distribution, when the image can be estimated by text prompts of text-to-image models?\n\nQ10. Can be simply using $s \\delta_C$ for the score distillation possible without $\\delta_D$? That is, using $\\delta_D$ is necessary?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5101/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5101/Reviewer_eQLa",
                        "ICLR.cc/2024/Conference/Submission5101/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5101/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699234329324,
            "cdate": 1699234329324,
            "tmdate": 1700452341567,
            "mdate": 1700452341567,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "g2Bp9a0c8C",
                "forum": "dlIMcmlAdk",
                "replyto": "dDx0OjKT6j",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5101/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5101/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to reviewer eQLa"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their detailed comments and questions. We address them below:\n\n**W2. Thorough experiments to validate the effectiveness of NFSD are absent\u2026There is no ablation study and quantitative result.**\n\nWe added ablation studies in Appendix A.5 and quantitative evaluation in Appendix A.6.\n\n**Q1.Why the reduced CFG scale cannot produce diverse visual contents. In addition, can the authors provide the samples with different seeds and the same text prompts to show the diversity of generated contents?**\n\nOur approach actually sheds some light on the lack of diversity - it is not due to the high CFG. We hypothesize that the reason for the low diversity is rooted deeply in the process of score distillation. Unlike ancestral sampling, at each SDS iteration we add random noise to a rendered image, and we update the rendered image (or the generator parameters) independently of previous noises . Therefore, for a specific noised rendered image we follow some direction to optimize $p\\_t(\\mathbf{x}\\_t)$. At the next step we again add (different) random noise and optimize $p\\_t\u2019(\\mathbf{x}\\_t\u2019)$, which can yield a completely different direction. This results in an averaging effect (unlike ancestral sampling where each step corrects the previous as it is conditioned on it).\nMoreover, in our work, as in most score sampling methods, even the same diffusion time (i.e. similar noise level) can be used with different noises during the optimization process, yielding a different direction each time. \nWe added a discussion alongside results obtained from different seeds in Appendix A.3.\n\n\n**Q2. In Figure 3, what is the diffusion timestep? ... show the results of $x\\_{OOD}+\\delta\\_D + \\delta\\_N^{OOD}$ where $\u05bf\\delta\\_\\text{N}^{\\text{OOD}}$  is the denoising score of $x\\_{\\text{OOD}}$ not $x\\_{\\text{ID}}$. I also suggest clarifying the notation of $\\delta\\_\\text{D}$ and $\\delta\\_\\text{N}$  in Figure 3, since the two scores are from different samples**\n\nThe diffusion timestep used is $t=400$. Indeed, this should be specified in the paper.\nIn Figure 3 we propose to visualize $\\delta\\_\\text{N}$ and $\\delta\\_\\text{D}$ by an engineered pair of $\\mathbf{x}\\_\\text{ID}$ and $\\mathbf{x}\\_\\text{OOD}$ images. We set $\\delta\\_\\text{N}$ to be the denoising score of $\\mathbf{x}\\_\\text{ID}$ as the image is in-domain and the prediction mostly just removes noise. We assume that $\u05bf\\delta\\_\\text{N}$ is shared between the in-domain and out-of-domain predictions, thus $\\delta\\_\\text{D}$ is obtained as the difference between predictions of $\\mathbf{x}\\_\\text{OOD}$ and $\\mathbf{x}\\_\\text{ID}$. We explain this more clearly in the revised version. \nRegarding the term $\\mathbf{x}\\_\\text{OOD}+\\delta\\_\\text{D} + \\delta\\_\\text{N}$, please note that this includes a noise direction term, thus the resulting image is noisy, as we show in Figure 10 in our revision.\n\n\n**Q3. Why do the prediction errors in Figure 4 (the second row) show a less-noisy map at t=1000?**\n\nAlthough the initial impression may appear counterintuitive, it's important to bear in mind that these are unnormalized disparities between the noise $\\epsilon$ and the network's prediction $\\epsilon\\_{\\phi}$\u2014meaning, they haven't been adjusted in relation to the diffusion noise scheduler. Predicting the precise added noise to the image becomes notably more challenging when a small amount of noise is introduced. In contrast, at $t=1000$, the noised image predominantly consists of noise ($\\epsilon \\approx \\mathbf{x}\\_t$), simplifying the prediction process. as the image is heavily influenced by the noise itself.\n\n\n**Q4. How can we assume that the scale of the domain score is preserved? Is there any rationale that only  $\\delta\\_N$ decreases over the backward process, while $\\delta\\_\\text{D}$ preserves its scale?**\n\nYou are correct that there is no guarantee that $\\delta\\_\\text{D}$ will preserve its scale. Nonetheless, our main point is that since the noise to be removed is monotonically decreasing in the backward process (according to the noise-scheduler), the noise prediction $\\delta\\_\\text{N}$ part of the score (corresponding to $\\epsilon\\_{\\phi}$) is becoming increasingly negligible as diffusion time becomes smaller. In contrast, the magnitude of the $\\delta\\_D$ component depends both on the diffusion time and the current stage of the optimization process. Thank you for this important comment, and we have revised our paper accordingly.\n\n\n**Q5. How about the results of SDS, where its CFG adopts the same negative prompts as NFSD, described in Section 4?** \n\nWe added a discussion about negative prompts in Appendix A.4. As we explain there, using a negative prompt in the CFG term mimics the effect of $\\delta\\_\\text{D}$.\nAdditionally, in Figure 13 we perform an experiment where we add a negative prompt to the CFG term of both SDS-100 and NFSD losses. As can be seen, the negative prompt improves the results of both SDS and NFSD.\n\n**(Continued in next reply)**"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5101/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700253077964,
                "cdate": 1700253077964,
                "tmdate": 1700253077964,
                "mdate": 1700253077964,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8VJ7fUlZqx",
                "forum": "dlIMcmlAdk",
                "replyto": "dDx0OjKT6j",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5101/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5101/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to reviewer eQLa - cont."
                    },
                    "comment": {
                        "value": "**Q6. Can the LoRA of ProlificDreamer be replaced with NFSD, while variational particle optimization is used?** \n\nThe variational particle optimization proposed in ProlificDreamer is entangled with the LoRA variational model, as it is designed to model possible 3D representations (rather than one). \nHence, applying NFSD for multiple particles can not be directly transferred from ProlificDreamer to our method.\nA possible approach for multiple particles was proposed by [Kim et al](https://arxiv.org/abs/2307.04787). This is a general multi-particle approach for SDS-based methods, which can be combined with NFSD, but is out-of-the scope of our work.\n\n\n**Q7. Comparing the results of NFSD with those of SDS in terms of the number of function evaluations (NFEs) of diffusion models.**\n\nTo the best of our knowledge, there isn't a method available for automatically determining the optimal number of iterations for SDS-based methods.\nIn all our experiments, we use the same fixed number of iterations both for SDS and NFSD, resulting in an equal count of parameter updates for both methodologies.\nThe term \"NFEs\" of diffusion models might be misleading here, given that the outcome of the diffusion model functions merely as a guiding factor without involving subsequent backpropagation through it. Theoretically, NFSD necessitates an additional evaluation of the negative prompt (in the worst-case scenario, as the negative prompt isn't utilized for diffusion times below $t\\_s = 200$). Consequently, NFEs(NFSD) equate to 1.5 times NFEs(SDS). \nIncreasing the iteration count did not yield improvements in the SDS results; On the contrary, it tended to introduce artifacts.\n\n\n**Q8. In Section 4, how can we assume that the score prediction on text conditions is also composed of  $\\delta\\_\\text{D} + \\delta\\_\\text{N} + \\delta\\_\\text{C}$, where $\\delta\\_\\text{D} + \\delta\\_\\text{N}$ is equal to the unconditional prediction?** \n\nThank you for the clarification. Indeed, $\\delta\\_\\text{C}$ is defined as $\\epsilon\\_\\phi(\\mathbf{z}\\_t;y,t) - \\epsilon\\_\\phi(\\mathbf{z}\\_t;\\varnothing,t)$. Plugging $y=p\\_{\\text{neg}}$ into the definition directly gives $\\epsilon\\_\\phi(\\mathbf{z}\\_t;\\varnothing,t) - \\epsilon\\_\\phi(\\mathbf{z}\\_t;y=p\\_\\text{neg},t) = -\\delta\\_{c=p\\_\\text{neg}}$. Therefore, applying the score decomposition on the terms before Equation (6) is unnecessary and we fixed it in the revision.\n\n\n**Q9. How is the negative prompt to estimate the domain term defined? \nHow can we say that the image is from out-of-distribution, when the image can be estimated by text prompts of text-to-image models?**\n\nWe use the same prompt for all experiments (3D and 2D). The prompt is simply a collection of synonym words for \u201clow quality\u201d image.\nGiven a specific prompt, e.g. \u201ca photo of a panda\u201d, the score of the diffusion model will be in the direction that maximizes the likelihood of the sample given the prompt, i.e. it will point to a dense region of the conditioned distribution. The term out-of-distribution refers to this conditioned distribution. While low quality images with noticeable artifacts can be generated by a diffusion model (simply input the negative prompt), under a \u201cnormal\u201d condition e.g. \u201ca photo of a panda\u201d, this is highly unlikely and thus we term it as out-of-distribution.\n\n\n**Q10. Can be simply using $s\\delta\\_\\text{C}$   for the score distillation possible without $\\delta\\_\\text{D}$? That is, is using  $\\delta\\_\\text{D}$  is necessary?**\n\nWe added ablation studies in Appendix A.5, including an experiment for using $s\\delta\\_\\text{C}$ only for 2D-latent in Figure 13. While the generated image is consistent with the prompt it contains artifacts, indicating that $\\delta\\_\\text{D}$ term is necessary for obtaining high-quality results.\nWe do stress that the effect of $\\delta\\_\\text{D}$ can be achieved by other means of regularization, not only the diffusion model. For example, using additional losses for smoothness regularization can be used. Specifically in NeRF optimization, the parameter space and other losses (e.g. sprasity and opacity losses) can be used to regularize the results, serving as $\\delta\\_\\text{D}$."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5101/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700253188643,
                "cdate": 1700253188643,
                "tmdate": 1700253188643,
                "mdate": 1700253188643,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "K2rmfTTIsT",
                "forum": "dlIMcmlAdk",
                "replyto": "dDx0OjKT6j",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5101/Reviewer_eQLa"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5101/Reviewer_eQLa"
                ],
                "content": {
                    "comment": {
                        "value": "I carefully read the authors' responses and the revised version of the paper including the Appendix.\n\nRegarding to Q1, I encourage the authors to further revise the paper. In the last paragraph in Section 3, \u201cHowever, high CFG coefficients are known to yield less realistic and less diverse results, as demonstrated in Figure 5, typically leading to over-saturated images and NeRFs.\u201d can lead to misunderstanding of authors, high CFG coefficients are the root cause of low diversity even in SDS. \n\nI have recognized the contributions of this paper, but the major concerns to reject this paper were some unclear explanations under assumptions and the lack of ablation study.\nHowever, the authors' responses clearly resolve most of my concerns, so I readily revise my final score to give an opinion to accept this paper."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5101/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700452872831,
                "cdate": 1700452872831,
                "tmdate": 1700492308964,
                "mdate": 1700492308964,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]