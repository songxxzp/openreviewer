[
    {
        "title": "Towards Deep Viticultural Representations: Joint Region and Grape Variety Embeddings"
    },
    {
        "review": {
            "id": "MmCoYLfzxl",
            "forum": "q4cfN6PGY7",
            "replyto": "q4cfN6PGY7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8247/Reviewer_p5Cm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8247/Reviewer_p5Cm"
            ],
            "content": {
                "summary": {
                    "value": "In the paper \"Towards deep viticultural representations: joint region and grape variety embeddings\", the authors develop a VAE-based approach for learning representations of wine varieties and wine-growing regions. They use data on ~600 wine-growing regions with information on which of the ~1500 wine varieties they grow. The authors train two coupled multinomial VAEs, one encoding wine variety and another encoding wine-growing region. Then the authors argue that the resulting latent representations are meaningful and outperform existing alternatives in terms of representation quality."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "I am a big fan of both, representation learning and wine, so I was very excited to read this paper. I am not familiar with prior literature on wine representation learning, but the authors say it is scarce, i.e. this paper is exploring a novel application area."
                },
                "weaknesses": {
                    "value": "That said, I found the paper disappointing and not really publication ready. In particular, it seems to me to fall far below the threshold of importance, novelty, and rigour expected by ICLR. The main issues are: (1) lack of clarity in writing and presentation; (2) unclear motivation for a coupled region-variety representation; (3) insufficient and unconvincing evaluation; (4) insufficient benchmark comparisons, in particular using simpler non-deep-learning baseline models."
                },
                "questions": {
                    "value": "MAJOR ISSUES\n\n1. I found the presentation very confusing. After reading the first THREE PAGES (\"Introduction\"), I still did not know what the authors want to achieve. I would recommend to have a clear 1-page introduction that explains what the paper wants to do (what exactly is the input data, what is the output, what are the performance metrics). The rest can go into the \"Related work\".\n\n   The whole sampling approach and sampling-based evaluation are not very clear either... Does each variety (and each region) in the end get one embedding vector? Or does it get a whole distribution? Can this distribution be multimodal? All figures that I see in the Appendix contain multiple points per variety/region, but all very unimodal. Is this expected/desired?\n \n   Many technical details are unclear as well. E.g. what K is used for K-means clustering, and why? What are the A/B/C classes used for classification? Etc. \n\n2. The premise of the paper is that they use *coupled* VAEs for joint representations of varieties and regions. This was not motivated clearly enough. Imagine there is one wine region that grows two very different varieties. What is the perfect joint representation of this data? The \"coupling\" only ensures that the entire latent spaces overlap, if I understand it correctly. What would make them overlap meaningfully? I don't understand the setup or the goals here.\n\n3. Regarding evaluation. Tables 1 and 2 assess how clustered the representations are but tell us nothing about how meaningful they are. Table 3 shows that VAEs outperform an extremely simple model based only on 2 features (latitude + longitude). And they don't outperform it very strongly. Table 4 only uses dummy baseline, Table 5 shows that all wine/region parirings are not statistically significant. So the ONLY result that actually shows that the emebddings are meaningful is Table 3; and that result is reather weak.\n\n   I understand that quantitative evalutions may be difficult. But qualitative evaluations are lacking altogether. I would expect to see some visualisations of the latent space, but they are only shown in the Appendix and only using PCA. Moreover, they seem to make no sense! For example, in Fiture 1 in the Appendix, Alvarinho (white grape) is located close to Tempranillo (red grape), and similarly Riesling (white) is located close to Pinot Noir (red). How is this meaningful? Maybe PCA is misleading here, so why not use something like t-SNE? I feel like qualitative evaluation has not even started here.\n \n4. Lack of proper baselines is a big problem. In Table 3, the comparison is to lon/lat model with 2 features. Why not using something that actually uses the A_ij matrix, but without deep learning? Some simple regression/classification models or maybe SVD/NNMF models applied to A_ij matrix? Same for Table 4. The authors use a relatively complex setup (coupled VAEs) for a relatively simple dataset (co-occurence matrix A_ij), so I would expect them to choose some reasonable baselines."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8247/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8247/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8247/Reviewer_p5Cm"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8247/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698333234718,
            "cdate": 1698333234718,
            "tmdate": 1700732971044,
            "mdate": 1700732971044,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "l8xwwjtRpK",
                "forum": "q4cfN6PGY7",
                "replyto": "MmCoYLfzxl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8247/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8247/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to review"
                    },
                    "comment": {
                        "value": "Thank you for your review! We are responding to each of your comments below:\n\n1.   \tI found the presentation very confusing. After reading the first THREE PAGES (\"Introduction\"), I still did not know what the authors want to achieve. I would recommend to have a clear 1-page introduction that explains what the paper wants to do (what exactly is the input data, what is the output, what are the performance metrics). The rest can go into the \"Related work\".\na.    *Thank you for pointing this out; we have clarified the aim of this paper and reduced and reworked the abstract and introduction sections to make them much more focused and clear.*\n\n2.   \tThe whole sampling approach and sampling-based evaluation are not very clear either... Does each variety (and each region) in the end get one embedding vector? Or does it get a whole distribution? Can this distribution be multimodal? All figures that I see in the Appendix contain multiple points per variety/region, but all very unimodal. Is this expected/desired?\n\n*Each variety and region gets a multi-normal distribution that represents it. Varieties and regions share the space in which they are projected, regions and varieties that frequently occur together are pushed together by the joining losses so their distribution should overlap in the latent space. We do expect the distributions to be quite uni-modal in the dimensionality-reduced latent space, particularly when comparing \u201cfar apart\u201d varieties or regions.*\n\n3.   \tMany technical details are unclear as well. E.g. what K is used for K-means clustering, and why? What are the A/B/C classes used for classification? Etc.\n*The A/B/C classes used for classification come from the EU legislation that determines which practices are lawful in certain regions and which aren\u2019t. They use primarily climate data to assess this and therefore we make the claim that they implicitly contain terroir information (both through legislation and since they are based on climate and elevation features). We have clarified and expanded the explanation as to why we use this as the test set in the paper. Please see the discussion section 3.1, paragraph 1. For the K we set it to the number of labels, such that it corresponds to the number of countries, the number of varieties or the number of regions, whichever we are clustering to. We have clarified this in the figure labels and as a footnote (this section is now in the appendix, we explain more below).*\n\n4.   \tThe premise of the paper is that they use coupled VAEs for joint representations of varieties and regions. This was not motivated clearly enough. Imagine there is one wine region that grows two very different varieties. What is the perfect joint representation of this data? The \"coupling\" only ensures that the entire latent spaces overlap, if I understand it correctly. What would make them overlap meaningfully? I don't understand the setup or the goals here.\n\n*We have gone throughout the paper to clarify the motivation, as this was pointed out by other reviewers as well. A good representation is one that relates the conditions in which grapes are grown, or the conditions under which a variety thrives to the variety itself. This way we can then use it to recommend varieties for certain growing conditions, or to more meaningfully classify varieties. Overlap is expected between varieties as we assume that in most regions multiple varieties will thrive; we do not know about all of the possible varieties that could thrive but the varieties currently grown there we assume to indicate the kind-of-varieties that do. By our definition of similarity one region would not grow two very different varieties, as the fact that they are grown near each other indicates that they thrive in a similar environment. Here for us the wine-style is not the most important indicator but the environmental conditions that a grape variety may like. This also allows clustering or classification of regions not by their historic wine style but by the environmental conditions they offer, now shown in Table 1. We also want the embeddings to be variational as this accounts for the range of environments that a grape may be found or that a region may provide. The joining of latent spaces is important as it allows imputation, or recommendations to be produced.*"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8247/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700727695237,
                "cdate": 1700727695237,
                "tmdate": 1700727695237,
                "mdate": 1700727695237,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8L6Gre3vM3",
                "forum": "q4cfN6PGY7",
                "replyto": "brC7VgxeUM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8247/Reviewer_p5Cm"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8247/Reviewer_p5Cm"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the responses. I don't have time right now to go over everything carefully (and the discussion period ends in a few hours), and I can raise my score from 1 to 3, but there seemed to be a consensus among reviewers that the paper falls short of the ICLR expectations (all four scores <=3). Hopefully the feedback was useful for future revisions and resubmissions."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8247/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700732958102,
                "cdate": 1700732958102,
                "tmdate": 1700732958102,
                "mdate": 1700732958102,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "xjmDfH4V2G",
            "forum": "q4cfN6PGY7",
            "replyto": "q4cfN6PGY7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8247/Reviewer_VuWc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8247/Reviewer_VuWc"
            ],
            "content": {
                "summary": {
                    "value": "The paper conducts a study on producing representations for viticulture (the cultivation of grapevines). It uses a VAE approach with self-supervision. Specifically, it focuses on the creation of deep embeddings for viticultural regions and grape varieties. It created tons of features for grapes."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- Interesting application to viticulture"
                },
                "weaknesses": {
                    "value": "- Novelty is limited on the methodological side since it aims to apply an existing method to tackle an application problem. \n- No alternative baseline is used; it focuses on feature ablations of the proposed method"
                },
                "questions": {
                    "value": "- Can the authors formulate a machine learning challenge of this problem that is specialized for viticulture?\n- Can the authors compare with other models? \n- Can the authors describe novel insights about viticulture that can be gained?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8247/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698633329034,
            "cdate": 1698633329034,
            "tmdate": 1699637025515,
            "mdate": 1699637025515,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4TN4hCMyB2",
                "forum": "q4cfN6PGY7",
                "replyto": "xjmDfH4V2G",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8247/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8247/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to review"
                    },
                    "comment": {
                        "value": "Thank you for your review! Please see our answers to your questions below:\n\n1.   \tCan the authors formulate a machine learning challenge of this problem that is specialized for viticulture?\na.       *In the revision of this paper we have clarified the challenges that we aimed to overcome and gave a more concise and clear explanation of the state of this problem in viticulture currently. See this in the Introduction section 1.1, and the Abstract.*\n2.   \tCan the authors compare with other models?\na.       *Yes, we now compare with a baseline using roughly the same inputs as our model that uses an SVD approach as suggested by reviewer 4, and a global region classification based on climate data and PCA analysis from the only comparable study to our knowledge. We outperform both significantly on region classification and 6/9 models outperform SVD for variety classification. Please see section 3.1 and 3.2 for this and Tables 1 and 2 for the results.*\n3.   \tCan the authors describe novel insights about viticulture that can be gained?\na.     *In our paper, though we do not necessarily uncover surprising new results as this is a bit outside of the current scope, however, we show some latent space exploration and that it aligns closely with the reality of grape-growing. In this way our results indicate that the latent-space has a \u201creal foundation\u201d making it useful to find novel insights. See the Qualitative analysis section 3.3.*"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8247/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700727511656,
                "cdate": 1700727511656,
                "tmdate": 1700727582829,
                "mdate": 1700727582829,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "AcRslXmTpj",
            "forum": "q4cfN6PGY7",
            "replyto": "q4cfN6PGY7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8247/Reviewer_VBQe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8247/Reviewer_VBQe"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a self-supervised approach to learning joint regional and varietal embeddings using joint variational autoencoder (VAE) networks, and examines the embeddings, their usability for downstream tasks as well as whether the joint autoencoder network may be used as a varietal suitability ranking system. The results demonstrate that the embeddings to outperform \u2019raw\u2019 features on downstream tasks and results indicating potential of the autoencoder networks as data-based recommender systems."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper applies joint variational autoencoder (VAE) networks to the study of viticultural regions and grape variety, demonstrating that the embeddings in the paper outperform the \"raw\" features on downstream tasks. This paper examine whether the joint autoencoder network may be used as a varietal suitability ranking system."
                },
                "weaknesses": {
                    "value": "1. The English of the manuscript must be improved. There are problems with context transition and logical cohesion, and there are errors in the use of proper nouns. The methods and framework employed in the paper exhibit limited originality and innovation.\n2. Section 1.1 extensively discusses the current research status in the field of viticulture, which is less relevant to the research of this paper.\n3. Section 1.2 introduces the development process of embedding in detail, lacking an introduction to related technologies and methods.\n4. The section 1.3 on \"REGION AND VARIETY EMBEDDING REQUIREMENTS\" is excessively lengthy and lacks emphasis on key points. It occupies an entire page, which is excessive.\n5. There are also some unclear and unreasonable statements in the article:\n1) The formulas used in this paper are not numbered.\n2) There are errors in the description of variable v_i.\n3) The description of the variables in the formulas is unclear.\n4) Confusing organization of content in the part of the paper that tests the model on downstream tasks.\n6. The description of specific parameter settings in section 2.3 is excessively lengthy. It is recommended to provide these details in APPENDIX.\n7. The authors should compare their methodology with existing approaches, both qualitatively and quantitatively, to demonstrate its advantages or innovations in the field.\n8. The contribution, the authors claim, to overcome the lack of detailed data. But, quantitative comparison of the above argument is hard to find in the discussion about the effectiveness in the experiments. The authors are strongly suggested to show the strength of the article in overcoming the lack of detailed data. In addition, time complexity or computation overhead analyses need be discussed properly."
                },
                "questions": {
                    "value": "Please refer to the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8247/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698732426904,
            "cdate": 1698732426904,
            "tmdate": 1699637025393,
            "mdate": 1699637025393,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wCtXqQTzSu",
                "forum": "q4cfN6PGY7",
                "replyto": "AcRslXmTpj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8247/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8247/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to review"
                    },
                    "comment": {
                        "value": "Thank you for your comments! We are replying to each in detail below:\n\n1.   \tThe English of the manuscript must be improved. There are problems with context transition and logical cohesion, and there are errors in the use of proper nouns.\na.       *We have, during the current revision, worked to improve this and are going over the spelling and grammar until the final \u201cprinter-ready\u201d submission deadline as well. Thank you for pointing this out.*\n2.   \tThe methods and framework employed in the paper exhibit limited originality and innovation.\na.       *In a way these methods are not strictly novel, however, applying joint variational autoencoders for purely categorical data is novel and requires adaptations to this domain that we describe, such as balancing the reconstruction and the KL-divergence loss terms. Furthermore, we utilize tree-structured Parzen estimator optimization for balancing the joining loss terms whereas the current literature uses purely hand-picked values to balance losses. See for example these papers: https://doi.org/10.1038/s41467-023-38125-0 and https://doi.org/10.1038/s41467-023-39895-3 . These innovations have previously not been well highlighted in our paper but we have adjusted that and emphasized this throughout, especially in the loss section of the methodology.*\n3.   \tSection 1.1 extensively discusses the current research status in the field of viticulture, which is less relevant to the research of this paper.\na.    *We have largely removed this information and replaced it with more relevant information regarding the problem we are seeking to address. We further combined Section 1.1 and Section 1.3 into a new section called \u201cMotivation\u201d. It is shorter and contains only the essential points of the previously too lengthy and unspecific sections.*\n4.   \tSection 1.2 introduces the development process of embedding in detail, lacking an introduction to related technologies and methods.\na.       *We have adjusted this section accordingly and now focus more on the methodology rather than \u201cgeneral concept\u201d of the approaches we mention.*\n5.   \tThe section 1.3 on \"REGION AND VARIETY EMBEDDING REQUIREMENTS\" is excessively lengthy and lacks emphasis on key points. It occupies an entire page, which is excessive.\na.       *This section has been removed and key points have been instead mentioned in the \u201cMotivation\u201d section.*\n6.   \tThe formulas used in this paper are not numbered.\na.       *Formulas are now numbered. Thank you for pointing this out.*\n7.   \tThere are errors in the description of variable v_i. The description of the variables in the formulas is unclear.\na.       *We are a bit unsure what you mean regarding the variable descriptions, we have gone over them. Please let us know whether it is still unclear.*\n8.   \tConfusing organization of content in the part of the paper that tests the model on downstream tasks.\na.       *We have done a major rewrite of the results and discussion section as we have received multiple comments about this. We focused particularly on clarifying and justifying the criteria and choice of tasks as well as organizing them more clearly and removing tests that are not very valuable while including a new Qualitative Analysis section.*\n9.   \tThe description of specific parameter settings in section 2.3 is excessively lengthy. It is recommended to provide these details in APPENDIX.\na.       *Other reviewers asked for more information on how these parameters are found so we have provided that in this revision, but we moved the re-formatted table listing the values to the appendix to not take up too much space.*"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8247/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700727395520,
                "cdate": 1700727395520,
                "tmdate": 1700727395520,
                "mdate": 1700727395520,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "K9vtD5Cm7s",
            "forum": "q4cfN6PGY7",
            "replyto": "q4cfN6PGY7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8247/Reviewer_U2kf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8247/Reviewer_U2kf"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes to jointly learn continuous representations for viticultural regions and grape varieties, which can potentially be leveraged in downstream tasks for enhanced performance. Specifically, the paper first constructs a grape variety and region co-occurrence dataset, and then uses a variational auto-encoder (VAE) model to learn the low-dimensional representations. The model is trained using the VAE loss and a joining loss."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The idea of learning low-dimensional representations for viticultural regions and grape varieties to improve the performance of downstream tasks seems novel and interesting. \n2. The paper also conducted experiments to investigate the property of the latent representation space."
                },
                "weaknesses": {
                    "value": "1. The writing of the paper could be improved as it is sometimes difficult to follow the paper. \n2. The paper is incremental since it simply applies VAE to learn the latent representations of grape varieties and viticultural regions. \n3. I think the joining loss is quite important in aligning the representations of regions and varieties. The paper introduces three different joining losses. However, the details of these losses are missing from the paper. \n4. The paper lists the weights of different losses in the paper. However, it is unclear how these weights are chosen. \n5. I find the Results & Discussion section difficult to follow. There is no explicit introduction to the datasets, baselines, experimental setups and research questions."
                },
                "questions": {
                    "value": "Please see the questions in the Weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8247/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8247/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8247/Reviewer_U2kf"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8247/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698845122359,
            "cdate": 1698845122359,
            "tmdate": 1699637025280,
            "mdate": 1699637025280,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "O94Aj8U7oK",
                "forum": "q4cfN6PGY7",
                "replyto": "K9vtD5Cm7s",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8247/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8247/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to review"
                    },
                    "comment": {
                        "value": "Thank you for your review. Please see our responses to your comments below:\n\n1.   \tThe writing of the paper could be improved as it is sometimes difficult to follow the paper.\na.       *Thank you for pointing this out, we are revising the grammar of the paper and have also re-written the abstract to be clearer. We are double checking throughout while implementing the other changes.*\n\n2.   \tThe paper is incremental since it simply applies VAE to learn the latent representations of grape varieties and viticultural regions.\na.       *We introduce a joint VAE approach for both learning latent representations to assist with classification of viticultural regions (where the only precedent was PCA decomposition) and of grape varieties for which, to our knowledge, no such classification that is based on utilization of the grapes (rather than the origin of them) exists. Lastly, we present a methodology that shows promise of making data-based recommendations to inform varietal choice for vineyard developers under climate uncertainty, this is completely novel. We have clarified aims and innovations in the revised abstract, and in the rest of the paper as well (see motivation and conclusion for example). Additionally, we show the application of joint VAEs to purely categorical data which, to our knowledge, has also not been done before; this required us to re-balance the VAE loss prior to being able to determine the joining loss weights. The joining weights we find by Bayesian optimization rather than hand-picking as is the norm in the current literature such as: https://doi.org/10.1038/s41467-023-38125-0  and https://doi.org/10.1038/s41467-023-39895-3 . This we have highlighted as well (see section 2.3, last paragraph).*\n\n3.   \tI think the joining loss is quite important in aligning the representations of regions and varieties. The paper introduces three different joining losses. However, the details of these losses are missing from the paper.\na.     *We have gone over the loss-section of the methodology and provide some additional details about the similarity and correlation losses. Please let us know whether this is now more appropriate.*\n\n4.   \tThe paper lists the weights of different losses in the paper. However, it is unclear how these weights are chosen.\na.       *We find the joining loss weights by tree-structured Parzen estimator optimization. We have made this more clear and explicit in the paper, and included our optimization criterion. Please see section 2.3*\n\n5.   \tI find the Results & Discussion section difficult to follow. There is no explicit introduction to the datasets, baselines, experimental setups and research questions.\na.      *The discussion and results were revised according to your and other reviewer comments. See section 3.1, 3.2 and 3.4 for the experiments and baselines.*"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8247/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700727104342,
                "cdate": 1700727104342,
                "tmdate": 1700727104342,
                "mdate": 1700727104342,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]