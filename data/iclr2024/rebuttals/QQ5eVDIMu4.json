[
    {
        "title": "Distribution Shift Resilient GNN via Mixture of Aligned Experts"
    },
    {
        "review": {
            "id": "8aHY4kybDv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1560/Reviewer_FURX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1560/Reviewer_FURX"
            ],
            "forum": "QQ5eVDIMu4",
            "replyto": "QQ5eVDIMu4",
            "content": {
                "summary": {
                    "value": "This paper presents GraphMETRO, a graph neural network with mixture-of-experts architecture for domain generalized graph learning. The idea of GraphMETRO is a two-level design. It first aims to identify the form of graph distribution change with a gating module, and then directs the graph to the corresponding experts that are responsible for the forms of graph distribution change. In addition, the experts should generate invariant features w.r.t to its graph distribution change. The authors design objective functions for each of the goals above. Experiments over real-world and synthetic datasets with distribution shift show the effectiveness of the proposed GraphMETRO."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The problem of graph OOD generalization is important in real-world applications. Indeed, in real-world deployment of graph neural networks, we have to deal with shifting data (e.g. caused by temporal dynamics or cross-domain data). I also appreciate that the authors do not view distribution shifts as a whole, but try to decompose a distribution shift into different types of shifts. This brings extra insights to the problem of graph OOD generalization. \n\n2. The paper is well-presented, well-organized, and very easy to follow. \n\n3. The solution with mixture-of-experts is simple but sound and provides some interpretability to the distribution change. Indeed, mixture-of-experts is an established technique, but the authors made extra efforts to adapt MoE to the case of OOD generalization. The design that each expert is in charge of one type of distribution shift makes good use of MoE architecture, and a gating module that identifies the type of distribution changes adds interpretability to the whole method. In addition, adequate designs are made to ensure that the gating model recovers the right shift types, and the experts output invariant features."
                },
                "weaknesses": {
                    "value": "1. It is not clear how well the 5 designed distribution shifts can well cover real-world graph distribution shifts. The authors listed 5 distribution shifts in the paper (add edge, drop edge, feature noise, subgraph, drop nodes), but in fact there may be more graph distribution shifts than that. For example, there may be a systematic change in link preference (i.e. nodes tend to link with a different type of neighbors), adding malicious nodes (e.g. malicious users in a trading system). Maybe the authors can justify how well the 5 designed shifts can cover real-world distribution shifts.  \n\n2. It is not clear how the proposed GraphMETRO can handle imbalanced distribution shifts within the same graph. For example, it may happen that some subgraphs in the graph gets denser, while other subgraphs get sparser (e.g. some topics gain interest, while others lose).  How will GraphMETRO respond to this kind of shifts? \n\n3. It is not clear how graph pre-training can address the OOD generalization issue. Pre-training trains the model to observe a wide range of graphs and should be helpful in improving generalization. \n\n4. It may be good to discuss some previous works in graph transfer learning. Graph transfer learning addresses the problem that the source graph has a different distribution with the target graph, but the target graph should be given beforehand and is thus less difficult than the problem in this paper. Nevertheless, it may be good to discuss them and clarify the differences, e.g. (Zhang et al. 2019), (Wu et al. 2020). \n\nUnsupervised Domain Adaptive Graph Convolutional Networks. Wu et al. WWW 2020\n\nDANE: Domain adaptive network embedding. Zhang et al. IJCAI 2019."
                },
                "questions": {
                    "value": "1 and 2 in weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1560/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697132709868,
            "cdate": 1697132709868,
            "tmdate": 1699636084394,
            "mdate": 1699636084394,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CHCcPZ7hve",
                "forum": "QQ5eVDIMu4",
                "replyto": "8aHY4kybDv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response #1"
                    },
                    "comment": {
                        "value": "We are grateful for your positive feedback and detailed suggestions! We provide responses below to address your remaining concerns. \n\n---\n\n### **Comment & Question 1: Generality of the distribution shifts covered by the transform functions.**\n\nGood question! We provide the response from two angles:\n\n\n**(a) For general domain**: In our experiments, we mainly use the five stochastic transform functions, which are universal graph augmentations as listed in Zhao et al., (2021) [3]. In our code implementation, we have also included additional transform functions as shown in Appendix B. We believe these transform functions, while not exhaustive, still cover a wide range of distribution shifts observing from our experimental results.\n\nNevertheless, we agree that the real graph distribution shifts can go beyond any possible combinations of the predefined transform functions. In that case, the assumption may not hold, meaning that GraphMETRO may not capture and precisely mitigate the unknown distribution shift. This scenario could always possibly exist due to the lack of information about the testing distribution or its domain knowledge. We include it as a limitation in Appendix 5, while we further discuss how we could alleviate the problem with additional information.\n\n**(b) For specific domains where additional knowledge is available**: In fact, knowing the tendency of the distribution shifts, such as increasing malicious users in a trading system, would be very helpful in constructing the transform functions that can cover the target distribution shifts well. We believe that such knowledge can come from two sources: \n- **Domain knowledge**, e.g., on molecular datasets, the transform function could be adding additional carbon structure to a molecule (while preserving its functional groups). Or, in a particular social network, transform functions can be defined from known user behaviors. \n- **Leveraging a few samples from target distribution**. This is in fact in line with the reviewer\u2019s Comment #4 regarding graph transfer learning. Specifically, with the guide from a few target samples, we can select more relevant transform functions by, e.g., measuring the distance of the extrapolated datasets under a certain transform function with the target samples in the embedding space.\n\n We hope this response can alleviate your concern about our applicability.\n\n---\n\n### **Comment & Question 2: The mechanism of GaphMETRO in handling heterogeneous shifts within one graph.**\n\nGood question! For simplicity, suppose we have two transform functions, i.e., adding edges and dropping edges. Given a node classification task and the objective in Eq. (3), the model is trained on the extrapolated datasets based on the transform functions. After that, given an unseen graph with imbalanced distribution shifts, the gating model outputs scores to identify nodes likely to experience increasing or decreasing degrees, while others might adhere to the original distribution. Then, for each node, each expert takes its multihop subgraph, and outputs its referential invariant representation w.r.t. the correposing transform function. These expert outputs and gating model results are then aggregated to form the final representation. Assuming accurate predictions by the gating function, nodes in denser/sparser subgraphs are represented by expert models corresponding to adding/dropping edges. As each expert is trained to create invariant representations, the final node representations remain unaffected by their individual distribution shifts.\n\n---\n\n### **Comment 3: How to leverage graph pretraining.**\n\nIf we understand correctly, the reviewer was asking how to leverage a pretrained model to further aid the training of GraphMETRO. Please let us know if otherwise. \n\nThis is in fact an interesting point! We believe a model pretrained on a wide variety of data can be very helpful to initialize the gating model, which is required to output the mixture of a node or graph (after it is finetuned on the extrapolated dataset). By enhancing the gating model's predictive capability regarding mixtures, GraphMETRO's final representation should become more resilient. This becomes particularly advantageous when dealing with graphs not previously encountered in the extrapolated dataset. Moreover, it is possible that the pretrained model will also benefit the expert models, while one minor concern would be that the expert model may tend to be similar instead of dedicating to generating invariant representation w.r.t. their corresponding transform function. We added the above discussion to Appendix F as a future work. Thanks again for this comment!"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700273182862,
                "cdate": 1700273182862,
                "tmdate": 1700273182862,
                "mdate": 1700273182862,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Lko4GvxskR",
                "forum": "QQ5eVDIMu4",
                "replyto": "8aHY4kybDv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1560/Reviewer_FURX"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1560/Reviewer_FURX"
                ],
                "content": {
                    "title": {
                        "value": "Response acknowledged."
                    },
                    "comment": {
                        "value": "I appreciate the authors for providing a detailed response. Below are my response. \n\n1. I agree that the pre-defined transformations can cover a good range of graph OOD. However, it is indeed a slight limitation that the whole set of methods relies on the set. \n\n2. The response on heterogeneous shifts somewhat answers my question. Indeed, node-level OOD can always be transformed to graph-level OOD by considering a k-hop subgraph of the node. However, I suppose that at least some node-level OOD training objectives should be modified in Eqn. 3 (e.g. modifying the BCE part to some node-level ones) rather than its present form. \n\n3. I apologize for my unclear comments. What I am actually curious about is how GraphMETRO performs compared to some pre-trained models (e,g, GPT-GNN, GCC). Nonetheless, it may be out of the scope of this paper, and I think the authors have given some good analysis. \n\nTherefore, I would like to maintain a weak accept at this point. However, I do like the overall idea and presentation of this work and would be glad to see future revisions of this work being accepted, if not this time."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700451923565,
                "cdate": 1700451923565,
                "tmdate": 1700460874534,
                "mdate": 1700460874534,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1km0ax1a5b",
                "forum": "QQ5eVDIMu4",
                "replyto": "8aHY4kybDv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you!"
                    },
                    "comment": {
                        "value": "We deeply appreciate your approval. Your suggestions definitely inspired us a lot and have greatly improved our work.\n\nA few additional notes for the further comments:\n\n- Regarding **point #2**: In node classification tasks, the BCE objective already considers node embeddings other than the graph embedding of the k-hop subgraph. What we described previously refers to the computational graph (i.e., k-hop message passing), which generates node embeddings. We apologize for any confusion.\n\n- Regarding **point #3**: Yes it would be quite interesting to see how graph pretraining methods perform on the current OOD benchmarks. Graph pretraining methods like GCC and GPT-GNN also consider graph extrapolation to some extent, e.g., through subgraph extraction and masked attributes/structures. The key difference between graph pretraining and generalization may lie in their different focuses on **expressiveness** and **invariance**. While these two aspects do not always conflict, ensuring invariance w.r.t. a certain type of extrapolation might affect expressiveness (if the change is relevant to labels), and vice versa. To seek a balance in between, one might need prior knowledge in which types of transformations may or may not be sensitive to the labels (and perhaps build experts with different goals to make ensure invariance or expressivess). We believe there is still a lot to explore in this domain.\n\nOverall, we are grateful for your positive stand on this work. We believe that our [current version](https://openreview.net/pdf?id=QQ5eVDIMu4), incorporating opinions from you and other reviewers, is sound and well-refined. We are also committed to further improving it. We would appreciate your support based on our current version! \n\nThank you!"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700460773122,
                "cdate": 1700460773122,
                "tmdate": 1700460813195,
                "mdate": 1700460813195,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "mwtc9UylhG",
            "forum": "QQ5eVDIMu4",
            "replyto": "QQ5eVDIMu4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1560/Reviewer_C9mM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1560/Reviewer_C9mM"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the distribution shift of graphs caused by a set of stochastic transformations. To obtain an invariant representation under distribution shift, the paper proposes a mixture of experts where each mixture is designed to capture a corresponding transformation. Through the gating mechanism, the model automatically captures the transformation that causes the distribution shift. Experimental results with synthetic and real datasets show the superior performances of the proposed algorithm."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The experimental result on the WebKB dataset is outstanding."
                },
                "weaknesses": {
                    "value": "- The proposed approach assumes that the distribution shift on a graph dataset happens due to some underlying transformations. While this assumption looks plausible at first, it seems quite difficult to identify all distribution shifts with the assumption since the transformations are treated independently when combined together.\n- In other words, the entire framework requires a set of predefined transformation classes to learn the model, and all necessary transformations need to be identified beforehand. However, it is unclear whether the set of transformations used in the experiments is enough to cover complex distributions causing the distribution shift.\n- Moreover, most of the transformation requires a set of hyperparameters, e.g., dropout probability. However, each mixture only models a single instance of the transformation but not the entire class of transformations. Given that the hyperparameters are selected via the validation set, there is no evidence that the same configurations can work for the test set since it may caused by the different hyperparameters of the same transformation type.\n- This work only considers the distribution shift in the graph structure but not in the labels."
                },
                "questions": {
                    "value": "- Which of the results are statistically significant in Table 1? For graph classification tasks, the proposed model seems marginally better than the others.\n- Can we say we use ERM for the node classification even if nodes and their labels are not i.i.d.?\n- Figure 2 is not easy to digest since there is only a single label along the radial axis. Could you provide the exact numbers?\n- The test accuracy for the synthetic dataset for some transformations is relatively lower than the other transformations. Why some transformations is harder to identify than others for some datasets?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1560/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1560/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1560/Reviewer_C9mM"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1560/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698289168259,
            "cdate": 1698289168259,
            "tmdate": 1700624904879,
            "mdate": 1700624904879,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Kgncno2hbj",
                "forum": "QQ5eVDIMu4",
                "replyto": "mwtc9UylhG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response #1"
                    },
                    "comment": {
                        "value": "We appreciate your comments! To address your concerns, below we prudently justify the assumption of our method, the predefined transformation functions, as well as their complexity, and clarify our presented results.\n\n---\n\n### **Comment 1-3: Applicability and our assumptions**\n\nThanks for these great comments! Here we provide response in three folds:\n\n**(1) How does GraphMETRO identify all distribution shifts from transform functions if they are treated independently when combined together?** \n\nIf we understand correctly, by \u201ctreated independently\u201d, the reviewer is referring to the first term in our objective $\\text{BCE}(\\phi(\\tau^{(k)}(\\mathcal{G})), Y (\\tau^{(k)}))$, where we formulate predicting the distribution shifts types of a jointly transformed graph as a binary multiclass classification problem. We believe the difficulty of this task comes from both the property of transform functions and the expressiveness of the gating model. \n\n- Firstly, some transform functions are **inherently disentangled**, e.g., adding nodes feature noise and random subgraph extraction. In this case, there will be certain distinction between any pair from these three data distributions, i.e., (graphs with node noise, random subgraph graphs, random subgraphs with node noise), which the gating model can easily tell. \n- While some transform functions can be **essentially similar**, e.g., drop path and drop edges, this won\u2019t affect the performance of our method as long as each expert outputs the corresponding invariant representation. \n- Lastly, indeed, there could be more **complex combinations of the transform functions**, which poses challenges to the gating model\u2019s expressiveness in identifying the combinations. However, this challenge may be minor in the practice. Specifically, we observe fairly high accuracy performances of the gating model, which are above 85% and 73% averagely on extrapolated datasets with one transformation and multiple transformations, respectively.\n\nWe added the above discussion to Appendix F to enable a more comprehensive view towards our methodology. We hope this can alleviate your concern on our gating model\u2019s performance in identifying the distribution shift types.\n\n**(2) How does the predefined transform functions cover complex distributions causing the distribution shift?**\n\nThis is also a great question! We believe there are two angles for this question. \n\n**(a) For general domain**: In our experiments, we mainly use the five stochastic transform functions, which are universal graph augmentations as listed in Zhao et al., (2021) [3]. In our code implementation, we have also included additional transform functions as shown in Appendix B. We believe these transform functions, while not exhaustive, still cover a wide range of distribution shifts observing from our experimental results.\n\nNevertheless, we agree that the real graph distribution shifts can go beyond any possible combinations of the predefined transform functions. In that case, the assumption may not hold, meaning that GraphMETRO may not capture and precisely mitigate the unknown distribution shift. This scenario could always possibly exist due to the lack of information about the testing distribution or its domain knowledge. We include it as a limitation in Appendix 5, while we further discuss how we could alleviate the problem with additional information.\n\n**(b) For specific domains where additional knowledge is available**: In fact, knowing the tendency of the distribution shifts, such as increasing malicious users in a trading system, would be very helpful in constructing the transform functions that can cover the target distribution shifts well. We believe that such knowledge can come from two sources: \n- **Domain knowledge**, e.g., on molecular datasets, the transform function could be adding additional carbon structure to a molecule (while preserving its functional groups). Or, in a particular social network, transform functions can be defined from known user behaviors. \n- **Leveraging a few samples from target distribution**. Specifically, with the guide from a few target samples, we can select more relevant transform functions by, e.g., measuring the distance of the extrapolated datasets under a certain transform function with the target samples in the embedding space."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700272260737,
                "cdate": 1700272260737,
                "tmdate": 1700637541287,
                "mdate": 1700637541287,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CvjWzOMpTI",
                "forum": "QQ5eVDIMu4",
                "replyto": "mwtc9UylhG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response #2"
                    },
                    "comment": {
                        "value": "**(3) What is the complexity of the transform functions and how does it affect generalization?** \n\nInteresting question! In fact, our implementation and framework could easily avoid selecting hyperparameters on the transform functions. Specifically, we can make multiple transform functions of the same type with different ranges of hyperparameters. Specifically, GraphMETRO allows three edge dropping transform functions, $\\tau_1^{\\alpha_1}, \\tau_2^{\\alpha_2}, \\tau_3^{\\alpha_3}$, where $\\alpha_i$ (i=1, 2, 3) are three different ranges of edge dropping probabilities, e.g., [0.1,0.3], [0.3, 0.6], [0.6,0.9], representing different transform extents. Thus, given an input from the validation dataset, the gating model will highlight the transform function which simultaneously selects the corresponding hyperparameter that matches the distribution of the validation set. Interestingly, this idea is in the same spirit as how DARTS [3]  proposes to perform architecture search by formulating the task in a differentiable manner. \n\nIn our previous experiments, we did try this scheme where we replaced a single edge dropping transform function with the ratio range [0.3, 0.5] to three transform functions as mentioned above. While we didn\u2019t see a significantly different performance in that case, we believe this would be a flexible solution which avoids the need to conduct hyperparameter selection. \n\nWe include the above discussion in our open discussion and future works (Appendix F). We hope this response can alleviate your concern about the applicability of our method. \n\n---\n\n### **Comment 4: Limitations of our work**\n\nGreat point! We think the issue of label distributional shift, while important, is orthogonal and complementary to the focus of our current study. To elaborate, label distributional shifts exert analogous impacts across various modalities, such as graphs or images. Moreover, existing methods [1,2] designed to tackle label distributional shifts can be seamlessly integrated into our proposed framework. Such integration would necessitate minimal adjustments, potentially involving modifications to the loss function or the training pipeline. We added this as a future work in Appendix F.\n\n---\n\n### **Question 1: Statistical significance of the results on Table 1**\n\nThanks for the question! We compute the p-value of our method against the best baselines method as follows:\n\n| | WebKB | Twitch | Twitter | SST2 | \n|:--|:--|:--|:--|:--|\n|p-value|< 0.001| 0.023 | 0.042| 0.081|\n\nGiven the cut-off threshold as 0.05, we believe the performances of GraphMETRO are statistically significant on WekGB, Twitch, and Twitter datasets, while on the SST2, we see relatively weak evidence. We added the p-value results to our revision and hope our response can alleviate your concern on our improvements.\n\n---\n\n###  **Question 2: Can we say we use ERM for the node classification even if nodes and their labels are not i.i.d.?** \n\nIf we understand correctly, the reviewer is asking for clarification on the 2nd term of our objective. Please let us know if otherwise. Here, our thinking is that the cross-entropy loss for node classification already assumes node labels are conditionally independent given the model (the negative log-likelihood is a sum over the labeled nodes in training). Then, we use the same assumption of cross-entropy on Empirical Risk Minimization (ERM). That is, for a given model we must also minimize the error variance across nodes. The task is then to find the model with the best performance and small variance.\n\n---\n\n### **Question 3: Numerical results on Figure 2**\n\nThanks for pointing it out! We included all of the numerical results of Figure 2 in Appendix E, while showing the results on DBLP below.\n\n| |i.i.d. (0)|noisy feature (1)|add edge (2)|drop edge (3)|drop node (4)|random subgraph (5)|\n|:--|:--|:--|:--|:--|:--|:--|\n|ERM | 85.71 | 84.48 | 71.08 | 79.69 | 83.41 | 76.9|\n|ERM-Aug | 85.66 | 85.29 | 74.85 | 82.34 | 84.44 | 72.81|\n|GraphMETRO | 85.92 | 85.78 | 76.61 | 82.95 | 84.98 | 81.32|\n\n| |(4, 5)|(3, 5)|(2, 5)|(1, 5)|(2, 4)|(1, 4)|     (2, 3)|(1, 3)|\n|:--|:--|:--|:--|:--|:--|:--|:--|:--|\n|ERM | 70.4 | 77.63 | 81.99 | 79.69 | 70.55 | 71.52 | 77.73 | 79.59|\n|ERM-Aug | 74.16 | 81.04 | 83.65 | 68.62 | 74.01 | 68.27 | 81.13 | 84.49|\n|GraphMETRO | 76.18 | 81.71 | 84.26 | 80.31 | 75.1 | 71.05 | 81.85 | 87.14|\n\nAcross all of the synthetic environments, GraphMETRO averagely outperforms ERM and ERM-Aug by 3.20% and 2.45%, respectively."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700272568655,
                "cdate": 1700272568655,
                "tmdate": 1700274448113,
                "mdate": 1700274448113,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GepQUdS3FE",
                "forum": "QQ5eVDIMu4",
                "replyto": "mwtc9UylhG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response #3"
                    },
                    "comment": {
                        "value": "### **Question 4: Why does the test accuracy vary across different transformations?**\n\nGreat question! Here we summarize three possible reasons:\n\n- **Information Preservation in Transformations:** Certain transformations retain more informative features than others. For instance, in the REDDIT-BINARY (graph classification task), the random subgraph transformation may retain more graph label-related information compared to dropping edges, as the latter tends to lose more global information. This discrepancy in testing performance, where dropping edges outperforms random subgraph extraction, could be due to the preservation of crucial information. However, conclusions may vary across datasets or tasks depending on how information influences final predictions. For CiteSeer (a node classification task), a random subgraph might preserve more local node information, potentially explaining why its testing performance surpasses dropping edges in this specific task.\n\n- **Complexity of transformation:** Certain transformations inherently generate more diverse graphs than others. If the model lacks the expressive capacity to capture such diversity, it may lead to a decline in testing performance.\n\n- **Model Sensitivity:** Certain transformations may be easier for a model to learn due to compatibility with specific model architectures. This extends beyond transformation complexity and emphasizes how different model architectures may prefer learning particular distributions from one of the extrapolated datasets, which can also contribute to the difference in the testing performance.\n\nWe included the above discussion to Appendix F: Open Discussions. We hope this response can answer your question and improve the soundness of our work.\n\n---\n\n# Summary \n\nWe are grateful for your time and insightful suggestions! \n\nWe would like to highlight that our main contribution is framing the graph generalization problem on top of an equivalent mixture, a simple yet novel and tractable \"middle ground\", as well as proposing the training framework which effectively guarantees the generalization. While our method relies on a set of predefined transform functions, we believe they cover a wide range of distribution shifts based on our empirical results. Also, we agree that there could be some scenarios where the transform functions may not cover complex distributions, and we discuss two future directions and include them into our future works. Moreover, while selecting the hyperparameters for the transform functions introduce extra complexity, the issue could be minor in practice and we also conduct more experiments to justify the applicability better. Finally, we address several questions about clarification and presentation, as well as including more future works. \n\nLastly, we prudently ask you to reevaluate our work given the clarification in our responses, which we also updated our paper correspondingly. Overall, we believe our work makes good contributions to the field of graph distribution learning by proposing a novel and effective solution, and we would appreciate your reconsideration on this point. Thank you for your efforts again!\n\n---\n\n### **Reference**\n\n[1] Menon, Aditya Krishna, et al. \"Long-tail learning via logit adjustment.\" International Conference on Learning Representations. 2020.\n\n[2] Cao, Kaidi, et al. \"Learning imbalanced datasets with label-distribution-aware margin loss.\" Advances in neural information processing systems 32 (2019).\n\n[3] DARTS: Differentiable Architecture Search. Hanxiao Liu, Karen Simonyan, Yiming Yang. 2018."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700272796326,
                "cdate": 1700272796326,
                "tmdate": 1700274465626,
                "mdate": 1700274465626,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hyAammlWFs",
                "forum": "QQ5eVDIMu4",
                "replyto": "GepQUdS3FE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1560/Reviewer_C9mM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1560/Reviewer_C9mM"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response."
                    },
                    "comment": {
                        "value": "I appreciate the detailed responses from the authors. I must admit that I have enjoyed reading the paper.\nThe responses did not fully address my concerns (especially w.r.t. the limitations of the proposed method). Having said that, based on the other reviews and responses, I decided to increase my score."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700624888873,
                "cdate": 1700624888873,
                "tmdate": 1700624888873,
                "mdate": 1700624888873,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tmezUZnXSu",
                "forum": "QQ5eVDIMu4",
                "replyto": "mwtc9UylhG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We appreciate your approval!"
                    },
                    "comment": {
                        "value": "We thank the reviewer once again! We also enjoyed the process of making our work more sound from your suggestions. And your approval surely means a lot to us.\n\nWe do apologize for not making our solutions towards the limitations clear enough. We summarize them into a short table, hopefully could alleviate your concerns a bit more.\n\n| Limitation| Potential solutions | Location of discussion/action |\n|:---|:---|:---|\n|**Coverage of the transformations** | 1) Extend the coverage by adding representative transform functions. 2) Or include tranform functions based on domain knowledge or a few samples from target distribution | Appendix F, paragraph #3|\n|**Complexity of the transformations** | Make experts dedicated to different hyperparameters for the same type of transformation | Argument options are available in our codebase. Will make it more detailed in the experimental settings. |\n|**Label distributional shift**|Integrate the objective of the existing methods studying labe distributional shifts into our framework. |Appendix F, paragraph #4 |\n\n----\n\nWe completely agree on the existence of these limitations and we will move some limitations (esp #1) to the main paper in our final version. While they could be important in the practice, they are, in our perspective, fair \"side effects\" considering the benefits (i.e., mitigating multiple and nuanced distribution shifts and better interpretability), and may not be the central part of our novelty and main contribution (i.e., the proposal of an equivalent mixture, the concept of referential invariant representations, as well as the training framework). We are also eager to further improve other aspects.\n\nOnce again thank you so much for your support!!"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700640631798,
                "cdate": 1700640631798,
                "tmdate": 1700641145433,
                "mdate": 1700641145433,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ppMpJyIYRZ",
            "forum": "QQ5eVDIMu4",
            "replyto": "QQ5eVDIMu4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1560/Reviewer_m8JS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1560/Reviewer_m8JS"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a method to enhance the out-of-distribution performance of graph neural networks (GNN) by learning to understand distribution shifts instead of addressing the assumed ones. To achieve this, the Mixture of Experts architecture is integrated into the GNN, supplemented by an alignment procedure to recognize the shift. Empirical experiments are conducted to validate the theoretical assertion.\n\nOn the whole, I believe the proposed method lacks the necessary motivation and its novelty isn't substantial enough to meet the standard."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper aptly addresses OOD as a crucial issue for GNNs, pinpointing graph shift heterogeneity as the core challenge.\n- Real-world datasets back the claims through experiments.\n- Thorough ablation studies validate the learned graph shifts, a commendable effort."
                },
                "weaknesses": {
                    "value": "- The motivation behind the proposed method is not adequately substantiated. The primary basis given is that \"previous research has concentrated on addressing specific types of distribution shifts.\" However, this overlooks a plethora of prior works in the field. Contrary to the suggestion that graph shift heterogeneity is under-explored, numerous studies have delved into learning the \"environment generators\" for GNNs to detect graph shifts, as exemplified by [https://arxiv.org/abs/2202.02466]. Other works have focused on learning shift-specific transformations, such as [https://arxiv.org/abs/2211.02843]. Consequently, there exists a wide spectrum of approaches to tackle graph shift heterogeneity. The choice of approach in this paper, especially the emphasis on MOE, requires a more detailed and robust justification to elucidate its relevance and significance.\n\n- The presented assumption seems overly broad and lacks specificity. Additionally, the architectural design appears to be somewhat arbitrary. Consequently, it's challenging to discern the functionality, its underlying mechanism, and its improvements over existing methods.\n\n- The proposal is insufficient in its details, particularly concerning the implementation of specific model architectures, stochastic transformation, and the optimization process. Given the inclusion of shift learning midway and data augmentation initially, one would expect a more intricate optimization strategy than standard routines."
                },
                "questions": {
                    "value": "Please check Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1560/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698613696053,
            "cdate": 1698613696053,
            "tmdate": 1699636084227,
            "mdate": 1699636084227,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MrQ7X2xZ9P",
                "forum": "QQ5eVDIMu4",
                "replyto": "ppMpJyIYRZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response #1"
                    },
                    "comment": {
                        "value": "We appreciate your comments! To address your concerns, below we prudently justify the motivation of our proposed method, clarify our assumptions, and provide details regarding our experiment implementation.\n\n---------------------\n\n### **Comment 1: Motivation of this work**\n\nThank you for this comment! We believe there might be a bit of misunderstanding due to our different definitions of *\u201cgraph shift heterogeneity\u201d*. We firstly discuss the related works mentioned and then justify our statement:\n\n**(1) Related works**\n\nPlease see Section 2 where we discussed the paper mentioned by the reviewer, i.e., EERM (Wu et al., 2022a). We repeat part of it here for you convenience:\n\n```The prevailing invariant learning approaches assume that there exist an underlying graph structure (i.e., subgraph) (Wu et al., 2022c; Li et al., 2022b;a) or representation (Arjovsky et al., 2019; Wu et al., 2022a; Chen et al., 2022; Bevilacqua et al., 2021; Zhang et al., 2022) that is invariant to different environments and / or causally related to the label of a given instance. However, these approaches focus on group patterns without explicitly considering nuanced (instance-wise) distribution shifts, making their applicability limited.```\n\nMoreover, we apologize for missing the recent interesting work by **Sui et al. [1]** which officially came out two days before the ICLR abstract deadline. We added it to our revision, thank you! \n\nSpecifically, Sui et al. [1] proposed a graph data augmentation strategy that alleviates covariate shift by generating diverse and invariant causal features. However, the trainable augmenter they used may not distill diverse augmentations or construct unseen perturbations. Moreover, Sui et al. [1] test its method only on graph classification tasks, while GraphMETRO can be applied to both node and graph classification tasks. Besides, we have discussed graph augmentation and attention-based methods in our related works, and we added more recent works on graph OOD [2,3,4], and we hope our response clears your concern on the related work discussion.\n\n\n**(2) The definition of graph shift heterogeneity**\n\nIn this work, we refer to **\u201cheterogeneous shifts\u201d** as multiple and different levels of shifts which vary across different instances (nodes or graphs), as illustrated in the example in the abstract. While we agree that the existing invariant learning approches can accommodate multiple distribution shifts, it could be hard for them to tackle nuanced distribution shifts for individual instances (nodes or graphs) since the distribution shifts are inferred from variance across multiple data environments. If GraphMETRO's approach were described via environments, we would have a combinatorial number of such environments in training (the product of all different subsets of nodes and all their possible distinct shifts). Thankfully, GraphMETRO avoids this combinatorial explosion by considering **a mixture of transformations as a proxy** for the target distribution shifts rather than invariance to whole-graph environment shifts. This is the type of heterogeneity we are interested in our paper. \n\n**(3) Regarding our original motivation statement**\n\nWhile the statement pointed out by the reviewer serves as our primary motivation, we would like to note that we did not claim all of the previous works fall into this category. And we have provided detailed discussion about three lines of research in the related work section.\n\nHowever, we agree that we could make this statement border to cover the previous invariant learning methods. To improve the clarity, we change the statement from \"previous works mostly focus on addressing specific types of distribution shifts\" to \"**previous works mostly focus on addressing specific types of distribution shifts or inferring distribution shifts from data environments\u2026**\u201d. We also modified our introduction correspondingly, we hope this will better position our work.\n\n**(4) The choice of our MoE design**\n\n- The choice of our approach comes as a consequence of our motivation to model the graph/instance shift heterogeneity. As mentioned, mitigating multiple and nuanced distribution shifts simply goes beyond certain distribution shift types or environment construction as seen in the previous methods. \n- Thus, GraphMETRO takes a different path, i.e., predicting a mixture of transformations as the proxy of the target distribution shifts. This enables the prediction of multiple different distribution shifts and the flexibility to model fine-grained heterogeneity since the mixture can be varied across different instances. We then tackled the proxy to mitigate the target distribution shifts. Intuitively, this solution provides a **\u201cmiddle ground\u201d** to deem graph generalization as an equivalent mixture, which, we believe, is a more tractable solution.\n\nWe updated our paper to make the above point more clear. We genuinely hope our answer can justify the motivation and solve your concern."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700270979150,
                "cdate": 1700270979150,
                "tmdate": 1700273849016,
                "mdate": 1700273849016,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "K3hNyGE62r",
                "forum": "QQ5eVDIMu4",
                "replyto": "zM7PdgjPF0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1560/Reviewer_m8JS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1560/Reviewer_m8JS"
                ],
                "content": {
                    "title": {
                        "value": "Replying to Rebuttal"
                    },
                    "comment": {
                        "value": "I appreciate the authors' response which has clarified some of my concerns, particularly regarding the first motivation point. However, I still have reservations about both the concept and methodology.\n\nRegarding the concept, the paper describes 'heterogeneous shifts as multiple and different levels of shifts varying across instances (nodes or graphs).' This definition appears unclear since distribution shifts are typically defined at a population level rather than at the instantiation of individual variables. This leaves me uncertain about the specific conceptual gap this paper addresses.\n\nAs for the methodology, while it's noted that NOT all previous works fall short in addressing 'shift-per-instance', the reasons why the MOE approach outperforms others remain vague. The numerical results are presented, but the underlying rationale is not adequately explained.\n\nConsequently, I am inclined to maintain my initial rating and would encourage the authors to delve deeper into these intriguing yet complex aspects of their research."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700665713385,
                "cdate": 1700665713385,
                "tmdate": 1700665713385,
                "mdate": 1700665713385,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "m2MlhNQ5X5",
                "forum": "QQ5eVDIMu4",
                "replyto": "ppMpJyIYRZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for reading our response! We would also appreciate your patience for reading the two points below \n\n---\n\n**Regarding point #1:**\n\nYes, we agree that the concept of heterogeneous shifts is relatively new for the current studies on distribution shifts, however, this is not new for studies on network patterns (Newman, 2003; Leskovec et al., 2005; 2007; Peel et al., 2017). In fact, the ignorance of such nuanced heterogeneous shifts in the previous studies instead emphasises our motivation and the potential impact of this work. \n\nFrom a causality perspective, distribution shifts can naturally happen in the instance level when (1) additional causal variables, beyond environmental factors and randomized noise, influence these shifts, or (2) multiple causal variables simultaneously affect the shifts with different strengths. Without modeling these explicitly, the mitigation of distribution shifts can easily fail. \n\nIn terms of our presentation, we have illustrated these cases of interest in abstract and introduction, we made further explanations in Section 3.1, we also present the specific results of distribution types in Figure 3 (b). \n\n\n**Regarding point #2:**\n\nWe think we can all agree that, if the ground truth of the instance shifts is available on the real-world datasets, it would be crystal clear to see where the improvement comes from since we can conduct case study to compare our method and the baselines on instances with nuanced distribution shifts, to see the influence of the modeling these heterogeneous shifts. \n\nHowever, with such ground truth not available, we had to seek other seemingly less intuitive but also in-depth way to illustrate the insights (esp Section 4.3) as mentioned above in our previous response. This is also why we designed the synthetic experiments at the first place. We think we did try hard to explain the underlying rationale with the ground truth being absent.\n\n----\n\n**Refinement**: We can of course add a causal graph in the our assumption section to make the concept more clear. And we can illustrate more if you could let us know the specific obstable to understand our mechanism, which will be extremely helpful.\n\n----\n\n### **Summary/TL;DR**\nWe understand the reviewer's clarification concerns, however, we don't agree that they, based on our justificaton, are the cause of rejection. We believe nuanced heterogeneous shifts are common, important, yet being typically ignored in the research domain of distribution shifts, we made these argument clear and also promise to refine. While explaining the underlying rationale is hindered by the lack of ground truth, we did try hard to dissection it from the gating model, the invariant representations generated, and more ablations in the appendix. We respect the reviewer's current opinion. Still, reconsideration will be greatly appreciated."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700688106892,
                "cdate": 1700688106892,
                "tmdate": 1700701377967,
                "mdate": 1700701377967,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KZ3PAMhk1Y",
            "forum": "QQ5eVDIMu4",
            "replyto": "QQ5eVDIMu4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1560/Reviewer_NLg1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1560/Reviewer_NLg1"
            ],
            "content": {
                "summary": {
                    "value": "This paper studied learning with distribution shifts on graphs, which is an under-explored open challenge in GNN community. The authors propose a mixure-of-expert-based model to learn the invariant representation learning of graph data for out-of-distribution generalization. By theoretical analysis, the authors show that the proposed model can provably capture the invariant patterns. Experiments showcase the efficacy of the model for tackling both node-level and graph-level distribution shifts against several state-of-the-art methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The problem this paper targets is a significant problem and the paper is well motivated\n\n2. The proposed model seems reasonable and interesting to my knowledge\n\n3. The experiment results are promising and the improvements are solid"
                },
                "weaknesses": {
                    "value": "1. The novelty is not well justified and comparison with recent methosd is not sufficient\n\n2. Some of recent papers on out-of-distribution learning on graphs are not discussed [3-5]\n\n3. The authors argued that \"previous works mostly focus on addressing specific types of distribution shifts\", which seems inproper and incorrect. E.g., the typical works for graph OOD learning EERM [1] and DIR [2] do not assume the type of distribution shifts in their problem formulation.\n\n[1] Qitian Wu, et al. Handling distribution shifts on graphs: An invariance perspective. In ICLR, 2022\n\n[2] Ying-Xin Wu, et al. Discovering invariant rationales for graph neural networks. In ICLR, 2022\n\n[3] Nianzu Yang et al. Learning substructure invariance for out-of-distribution molecular representations, NeurIPS 2022\n\n[4] Yongduo Sui et al. Causal Attention for Interpretable and Generalizable Graph Classification, KDD 2022.\n\n[5] Jiaqi Ma et al. Subgroup Generalization and Fairness of Graph Neural Networks, NeurIPS 2022."
                },
                "questions": {
                    "value": "1. How does the model compare with existing invariant learning-based models for graph OOD generalization, e.g., EERM [1] and DIR [2]? What is the key technical originality of this work?\n\n2. What is the computation cost of this model compared against other peer models?\n\n3. Can the proposed model handle multiple different types of distribution shifts that simultanenously exist in data?\n\n4. Can the proposed model tackle distribution shifts and out-of-distribution generalization on molecular graphs?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1560/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698741974670,
            "cdate": 1698741974670,
            "tmdate": 1699636084123,
            "mdate": 1699636084123,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "D1e98yje3o",
                "forum": "QQ5eVDIMu4",
                "replyto": "KZ3PAMhk1Y",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response #1"
                    },
                    "comment": {
                        "value": "We appreciate your efforts and insightful comments! To address your concerns, we provide point-to-point responses below.\n\n---------------------\n\n### **Comment 1: Regarding the novelty of GraphMETRO.**\n\nThanks for the comment! We believe our novelty comes from the proposal of an equivalent mixture for graph OOD and the construction of our training framework, as detailed below:\n\n- **An equivalent mixture for graph OOD**: The key challenge we faced to mitigate multiple and nuanced distribution shifts is the intrinsic complexity and heterogeneity of graph distribution shifts, which simply goes beyond certain distribution shift types [6,7,8,9] or environment construction as seen in the previous methods [1,2,3]. GraphMETRO takes a different path, i.e., predicting a mixture of transformations as the proxy of the target distribution shifts, where the mixture can be varied across different instances, and then tackled the proxy to mitigate the target distribution shifts. We believe the high-level idea is succinct, nevertheless, novel, in the sense that it provides a \u201cmiddle ground\u201d to deem graph generalization as an equivalent mixture that is more tractable.\n\n- **Training framework**: With the guide of our formulation, the training framework is still non-trivial due to two problems, i.e., \u201chow to provide supervision for predicting the mixture\u201d and \u201chow to ensure the experts corresponding to mixture components are compatible when working as a whole\u201d. Specifically, GraphMETRO solves the first problem by conducting graph extrapolation. This is somewhat similar to the spirit of graph pretraining in the sense that we inject heterogeneity to promote the expressiveness of the gating model in recognizing the mixture components. For the second problem, we introduce the concept of Referential Invariant Representation, along with the novel objective in Eq. (3) to enforce the invariance and compatibility. It is worth mentioning that the model performance is much worse than the reported numbers (e.g., 2.7\\% lower on Twitch dataset) without the compatibility constraint, indicating the proposed referential invariance concept is indispensable. \n\nWe added more justification in the introduction (updated in the revision). We genuinely hope our responses can solve your concerns about the novelty of our work.\n\n------------------------------\n\n### **Comment 2: Comparison with recent methods [3,4,5].**\n\nIn compacting the paper to fit in the page limit we mistakenly did not include these relevant references, we apologize. We added discussion in the revised version. Here we summarize these works and point out their key differences with our method: \n\n- In particular, **Yang et al. [3]** explore molecule representation learning in out-of-distribution (OOD) scenarios. They achieve this by directing the molecule encoder to utilize stable and environment-invariant substructures relevant to the labels without the need for environmental labels. \n- Similarly, **Sui et al. [4]** introduces causal attention modules to identify key invariant subgraph features that can be described as causing the graph label. The type of OOD task that Sui et al. [4] considers assumes the graph label is caused by a subgraph, which is quite different from ours. Moreover, both Yang et al. [3] and Sui et al. [4] consider tasks where the graph label is caused by a subgraph. \n- **Ma et al.[5]** is an interesting theoretical work which studies GNN generalization and examines their fairness, showing that the test subgroup's distance from the training set impacts GNN performance. Ma et al.[5], as far as we could assess, does not propose any specific architecture to solve the type of OOD tasks we consider in our work.\n\nOverall, the goal of GraphMETRO is to be invariant to a mixture of selected stochastic transform functions (and the mixture can vary across different instances), which is a more flexible and general solution. \nWe added a discussion of these works to our revision, hopefully providing a more comprehensive comparison and literature overview. We hope our responses can solve your concerns about the related work."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700269189275,
                "cdate": 1700269189275,
                "tmdate": 1700270064211,
                "mdate": 1700270064211,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "thNaK2YN9t",
                "forum": "QQ5eVDIMu4",
                "replyto": "KZ3PAMhk1Y",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response #2"
                    },
                    "comment": {
                        "value": "### **Comment 3 & Question 1: Related works on invariant learning and clarification on our statement.**\n\nThanks for pointing it out! Below we clarify the statement and clear potential misunderstanding:\n\n**(1) How does GraphMETRO compare with invariant learning methods like DIR and EERM?** \n\nPlease see our related work section where we discussed these two papers, i.e., DIR (Wu et al., 2022c) and EERM (Wu et al., 2022a). We repeat part of it here for you convenience:\n\n```The prevailing invariant learning approaches assume that there exist an underlying graph structure (i.e., subgraph) (Wu et al., 2022c; Li et al., 2022b;a) or representation (Arjovsky et al., 2019; Wu et al., 2022a; Chen et al., 2022; Bevilacqua et al., 2021; Zhang et al., 2022) that is invariant to different environments and / or causally related to the label of a given instance. However, these approaches focus on environmental patterns without explicitly considering nuanced (instance-wise) distribution shifts, making their applicability limited.```\n\nBesides, we also provide a more in-depth comparison in our point (3) below to highlight our key technical originality.\n\n**(2) Regarding our statement about previous works:** \n\nWhile the statement serves as our primary motivation, we would like to note that we did not claim all of the previous works fall into this category, and we have provided detailed discussion about three lines of research in the related work section.\n\nTo improve the clarity, we change the statement from \"previous works mostly focus on addressing specific types of distribution shifts\" to **\"previous works mostly focus on addressing specific types of distribution shifts or inferring distribution shifts from data environments** (which is highly limited when confronted with nuanced distribution shifts)\u201d. We also modified our introduction correspondingly. Thanks for letting us know our statement could be misinterpreted.\n\n**(3) Why do we say our method could be more broad than the existing invariant learning approaches?** \n\n- Invariant subgraph learning approaches, e.g., [1,2], consider variance of constructed data environments, which are designed very differently compared to our work. \nWhile they can accommodate multiple distribution shifts (as in multiple environments), these focus on patterns within each environment and ignore the variety across instances (e.g., shifts at the resolution of nodes), which may not be well-captured by the environment assignments. \n- GraphMETRO considers that specific parts of the test graph may have different shifts. Particularly, our goal is to make the generalization to unknown testing distribution more adaptive and broad, as opposed to limiting the distribution shifts to being invariant to specific types of subgraphs. \n\nIn other words, if GraphMETRO's approach were described via environments, we would have a combinatorial number of such environments in training (the product of all different subsets of nodes and all their possible distinct shifts). Thankfully, GraphMETRO avoids this combinatorial explosion by considering a mixture of transformations as a proxy for the target distribution shifts rather than invariance to environment shifts.\n\n**(4) Key technical originality compared to invariance learning (going more deeply)**\n\nAnother interesting view to see the innovation of GraphMETRO is that it breaks the typical invariant learning formulation, which assumes the data is manipulated by the environment variables (and then can be \u201cdecoded\u201d into multiple environments). Instead, GraphMETRO sees the distribution shifts on an instance as a mixture, which is represented by the score vector output by the gating function over the basis of the transform functions. In other words, GraphMETRO can produce infinite environments as the elements in the score vector are continuous. One can see that once we limit the output domain of the gating function into, e.g., binary {0, 1}, GraphMETRO can also produce a limited number of environments (if we categorize the instances based on the score vector), which covers the environment construction in invariant learning. Moreover, as mentioned, we propose the concept of referential invariant representation with a base model $\\xi_0$, which is also different from previous works on invariant learning. We added the above discussion to Appendix F to improve the depth of our analysis."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700269948983,
                "cdate": 1700269948983,
                "tmdate": 1700512573674,
                "mdate": 1700512573674,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YnhSSw37xf",
                "forum": "QQ5eVDIMu4",
                "replyto": "KZ3PAMhk1Y",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1560/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response #3"
                    },
                    "comment": {
                        "value": "### **Question 2: How does the computational cost of GraphMETRO compare to other methods?**\n\nPlease see the last paragraph of Section 3.4, where we analyze the computation complexity of GraphMETRO. We repeat part of it here for your convenience:\n\n```Consider the scenario where we use an individual encoder for each expert. The forward process of $f$ involves $O(K)$ forward times using the weighted sum aggregation (or $O(1)$ if using the maximum selection). Since we extend the dataset to $(K + 1)$ times larger than the original data, the computation complexity is $O(K^2 |D_s|)$, where |Ds| is the size of the source dataset.```\n\nThus, the computation cost is about $K^2$ or $K$ times (if using the maximum selection) than an ERM model, where $K=5$ in our experiments. Compared to DIR, as they extract $B$ spurious subgraphs from each batch to conduct the intervention, their computation cost is $B$ times compared to ERM, where $B$ could be 32. Thus, we believe the computation cost of GraphMETRO is fair for the gains we get, considering $K$ is usually small.\n\n----------------------\n\n### **Question 3: Can GraphMETRO handle multiple different types of distribution shifts that simultaneously exist in data?**\n\nYes! The distribution shift types corresponding to the gating outputs with high scores will be tackled during training. That is, if the gating output highlights multiple mixture components, their corresponding distribution shift types will be handled jointly.\n\n----------------------\n\n### **Question 4: Can GraphMETRO  tackle distribution shifts on molecular graphs?**\n\nThat is a great idea! Yes, GraphMETRO can be applied to molecular datasets if one designs transform functions to cover typical molecular variants. For instance, a transform function may add carbon structures to the molecules. These domain-specific transform functions are outside the scope of our work, however, we believe these would be interesting future work directions!\n\n----------------------\n\n# Summary \n\nWe thank the reviewer for the time and insightful suggestions! We hope our answers can address your concerns well.\n\nWe also prudently ask you to reconsider our work if the concerns are addressed. To highlight, our novelty comes from the formulation of an equivalent mixture for graph OOD and the training framework to effectively realize generalization. We also provide an in-depth analysis on our originality compared to some previous invariant learning methods. While we discussed and compared with previous works, we added more related works and modified our statement to position our work better. Finally, our method achieves great improvements on both node and graph classification tasks, and is a more general solution to mitigate multiple and nuanced distribution shifts. \n\nOverall, we believe our work proposes a new paradigm and novel training framework and makes good contributions in the fields of graph generalization, and we would appreciate your reconsideration on this point. Thank you for your efforts again!\n\n----------------------\n\n**Reference**\n\n\n[1-5] The same as listed by the reviewer\n\n\n[6] Beatrice Bevilacqua, Yangze Zhou, and Bruno Ribeiro. Size-invariant graph representations for graph classification extrapolations. In ICML, 2021.\n\n[7] Davide Buffelli, Pietro Li\u00b4o, and Fabio Vandin. Sizeshiftreg: a regularization method for improving size-generalization in graph neural networks. In NeurIPS, 2022.\n\n[8] Boris Knyazev, Graham W. Taylor, and Mohamed R. Amer. Understanding attention and generalization in graph neural networks. In NeurIPS, 2019.\n\n[9] Mucong Ding, Kezhi Kong, Jiuhai Chen, John Kirchenbauer, Micah Goldblum, David Wipf, Furong Huang, and Tom Goldstein. A closer look at distribution shifts and out-of-distribution generalization on graphs. In NeurIPS DistShift, 2021."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700270315779,
                "cdate": 1700270315779,
                "tmdate": 1700273786339,
                "mdate": 1700273786339,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]