[
    {
        "title": "A Cognitive Model for Learning Abstract Relational Structures from Memory-based Decision-Making Tasks"
    },
    {
        "review": {
            "id": "DI0QT6hLrX",
            "forum": "KC58bVmxyN",
            "replyto": "KC58bVmxyN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1539/Reviewer_NM51"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1539/Reviewer_NM51"
            ],
            "content": {
                "summary": {
                    "value": "This work builds a model that learns generalizable abstract relational structure on a decision making task where one has to answer the relation between pairs of stimuli for a reward. The stimuli can have \"many to many\" relations in that each stimuli can have up to 4 relations with other stimuli. The model builds on works like TEM and NTM where an explicit external memory module is written to/read from. The authors tried a one-dimensional version of the task where stimuli only had two relations and a two-dimensional version of the task where there can be more relations. The authors then saw that the model reproduced some neural phenomenon on such relational tasks such as distance coding, hexagonal modulation, and distance coding."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* Very comprehensive review of past work. \n\n* Experiments are rigorous (multiple seeds, etc) and well-done. Showing the reproduction of the neural phenomenon is pretty nice. \n\n* Model is written clearly."
                },
                "weaknesses": {
                    "value": "* There is extensive discussion of previous work, but I was left wondering what exact contributions this model makes over other models in this space like TEM. The paper discusses numerous differences, but I would like to see explicit discussion of what this model brings to the table, what specific phenomenon that this model produces that other models don't, etc. There are maybe some signs of this throughout the paper, but I didn't see any explicit discussion on it. \n\n* There's no limitations section/paragraph, which is an important part of any iclr paper."
                },
                "questions": {
                    "value": "* Would it be possible for the model to learn these relations implicitly without specifically being rewarded for them? Sometimes for humans, abstract relational structure can often be learned in service of doing a specific task, rather than being trained specifically on finding the correct relations."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1539/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1539/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1539/Reviewer_NM51"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1539/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698780354662,
            "cdate": 1698780354662,
            "tmdate": 1699636082505,
            "mdate": 1699636082505,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AcV8toK87y",
                "forum": "KC58bVmxyN",
                "replyto": "DI0QT6hLrX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1539/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1539/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer NM51"
                    },
                    "comment": {
                        "value": "Thanks for the positive review.  \n\nWe think the exact contribution in TEM space as follows.  In TEM, they proposed the learning principle of abstract relational structure as hypothesis for hippocampal computation and a particular model to perform a random-walking task in this principle that can reproduce rodent data.  Our exact contribution is to consider another model in this principle that performs a decision making and reproduce human data, thus strengthening the hypothesis.   The paper explains that this is actually a substantial undertaking requiring a number of technical developments and experimental efforts.\n\nWe miss the limitation section and will have it in the revision.  Right now, we think of limitation in the scalability of the relational structure.  The model finds difficulty structure larger than ~15 entities in 1D or ~5x5 entities in 2D.  Also, the long training time is a big issue.  \n\nThe question on the implicit learning is extreme interesting.  We have not thought about this possibility, and our current model would not be capable without substantial extension.  Probably, the task is a lot more difficult (note that the current task is quite difficult)."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1539/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700551613271,
                "cdate": 1700551613271,
                "tmdate": 1700551613271,
                "mdate": 1700551613271,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WoJliS2T5r",
                "forum": "KC58bVmxyN",
                "replyto": "AcV8toK87y",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1539/Reviewer_NM51"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1539/Reviewer_NM51"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the response. I will keep my score as is."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1539/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700591262666,
                "cdate": 1700591262666,
                "tmdate": 1700591262666,
                "mdate": 1700591262666,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "86xBcUtm3u",
            "forum": "KC58bVmxyN",
            "replyto": "KC58bVmxyN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1539/Reviewer_k38n"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1539/Reviewer_k38n"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a computational model for learning continuous spaces.  The primitives of the model include relationships, a, as well as entities x (just vectors in R^N).  To learn a one-dimensional space, the model is given two relations (analogous to greater than and lesser than); to learn a 2-dimensional space the model is given four relations (analogous to left vs right and above vs below).  The model's given a set of training data using near neighbors and then asked to generalize to pairs that were not observed (transitive inference).  And after learning a set of relationships, the model can generalize in that after learning a 1-D relationship among one set of stimuli, the model can more rapidly learn the analogous relationship among a second set of stimuli.  Notably, other approaches that are widely used in computational neuroscience (Tolman Eichenbaum machine, neural Turing machine, LSTM etc) not only fail to show these properties but can't learn the problem in the first place."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "As far as I'm aware this is a completely novel approach.   \n\nThe construction of ``internal spaces'' is an absolutely fundamental in computational cognitive neuroscience. \n\nThe idea of separating entities from relationships could be on the right track."
                },
                "weaknesses": {
                    "value": "I wonder if it's possible to get TEM/transformer/NTM/etc to do something like this task if it's presented differently.  \n\nI found the connection to neuroscience very indirect, notwithstanding the observation that the similarity of internal states exhibits a distance effect and there's evidence for 60 degree symmetry.  This model is very abstract."
                },
                "questions": {
                    "value": "The observation that transformers (for instance) don't learn these tasks is interesting.  Presumably, though this model is ill-suited for, say, language modeling.  What other problems can this computational approach solve (preferably in the general field of AI/ML)?   \n\nHow does this approach scale?  As the number of continuous dimensions goes up how does it behave?  Suppose you chose a different way to tile the plane.  Rather than placing items at grid coordinates, suppose each item had N near neighbors (or that the exemplars were irregularly scattered).  This would mean that the number of relations a has to grow.  How sensitive is this model to the number of relations (controlling for the dimension of the space)?  Does it depend on a regular tiling of the space with entities?\n\nAn alternative approach is to simply assume that the brain is organized to represent low dimensional spaces and the learning problem is to determine how to map those internal spaces onto the external world. E.g.,\nhttps://doi.org/10.1109/IJCNN54540.2023.10190998\nhttps://doi.org/10.1109/IJCNN54540.2023.10191578"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1539/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698814635864,
            "cdate": 1698814635864,
            "tmdate": 1699636082428,
            "mdate": 1699636082428,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JHXatIqpGd",
                "forum": "KC58bVmxyN",
                "replyto": "86xBcUtm3u",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1539/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1539/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer k38n"
                    },
                    "comment": {
                        "value": "Thanks for the positive and useful comments.\n\nRegarding what other problems our model can solve, we consider that it can learn general tree or cyclic structures beyond the presented 1D/2D structures.  However, since our model focuses on the particular type of tasks of discovering abstract relation structure, it would need a substantial extension to solve a more general problem as in AI/ML.  We believe that this situation is not so unreasonable as this seems the usual tension between AI models and cognitive (or computational neuroscience) models.  AI models are usually designed to be general enough for solving various, interesting tasks with high performance, while they often have components unrelated to the task in question, thus can sometimes obscure how the models solve the task or fail.  On the other hand, cognitive models are often designed to understand certain cognitive or neural data at the abstract level and thus specialized to a particular setting and drop unnecessary components for the task in question, which often allow us to focus on, explain, and clarify the computational essence (Occam\u2019s razor).  Neither approach is better than the other in general.  However, in our study, since our goal is to understand the novel kind of task (abstract relational learning in decision-making setting) and the related neural properties, we chose to design a cognitive model.  \n\nRegarding scalability, in our experience, our model works for a range of state dimensions, 10 to 100 (in 1D case).  Interestingly, we observed that it stopped working for a larger dimension possibly because it could not find an optimal solution which allows for generalization over domains.  We will provide a plot in the revision.  As for the suggested different approach of tiling, which we believe is about general graph structure, we have not yet studied this direction and probably this would be the next step; thus, we do not have a clear answer to the question at this moment.  However, we are quite confident that the hexagonal modulation property is specific to the regular 2D tiling.\n\nFinally, thanks for the suggested references.  We will include and discuss these in the revision."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1539/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700540333016,
                "cdate": 1700540333016,
                "tmdate": 1700614236052,
                "mdate": 1700614236052,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kJKQ7kp4y7",
                "forum": "KC58bVmxyN",
                "replyto": "JHXatIqpGd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1539/Reviewer_k38n"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1539/Reviewer_k38n"
                ],
                "content": {
                    "title": {
                        "value": "response"
                    },
                    "comment": {
                        "value": "I have read the author's response.\n\nThese are interesting questions for future work."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1539/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700713881963,
                "cdate": 1700713881963,
                "tmdate": 1700713881963,
                "mdate": 1700713881963,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vVchYyza6T",
            "forum": "KC58bVmxyN",
            "replyto": "KC58bVmxyN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1539/Reviewer_rY1U"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1539/Reviewer_rY1U"
            ],
            "content": {
                "summary": {
                    "value": "This paper describes a new neural model that learns abstract relations for one-dimensional and two-dimensional set orderings. The model is trained and tested on sets from different domains, such that  the testing phase is identical to human experiments on learning transitive relations. \nThe model is demonstrated to generalize to unseen domains, while several stat-of-the art methods are not able to solve their task. This generalization is made possible by the model's architecture with two components - (1) a set matrixes for learning abstract relations (one per relation), and set of  memory matrixes for binding concrete tokens from a specific domain to the abstract relations. The model is cognitively plausible, as its performance during the test phase appears to be similar to human performance in relation learning experiments, while other state-of-the-art models fail to complete the task."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This paper makes a novel contribution, significantly improving on existing models.  \n\n2. Model testing based on simulating previous human studies strongly supports cognitive plausibility of the model."
                },
                "weaknesses": {
                    "value": "I found the presentation to be poorly readable in places - this is not a big deal, but I would suggest editing for clarity."
                },
                "questions": {
                    "value": "The section analyzing hexagonal modulation within the model was not entirely clear to me -- it wasn't clear why the authors used the specific method of averaging state vectors.  Is there a citation, or maybe some explanation rationalizing this method? This can be included in the supplement. What is the significance of this hexagonal modulation emerging, given that the model's architecture is fundamentaly different from biological brains? Why would the authors expect hexagonal modulation to emerge?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1539/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698970731847,
            "cdate": 1698970731847,
            "tmdate": 1699636082354,
            "mdate": 1699636082354,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gpfYJ2X1rl",
                "forum": "KC58bVmxyN",
                "replyto": "vVchYyza6T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1539/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1539/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer rY1U"
                    },
                    "comment": {
                        "value": "Thanks for the positive review.  We will certainly make the best efforts to improve the clarity especially in Section 4.2.\n\nOur approach of averaging state vectors comes from the analysis method used in Park et al. (2021).  In their experiment, they measured the BOLD activities while they consecutively presented two stimuli (corresponding to two positions in the map), and they took the average over all the activities at each voxel.  We simulated this by averaging the hidden variables corresponding to the two inputs.  This may sound a bit crude, but we believe this is the best we could do.  We have more details about this part in Sec C.1.\n\nOn the significance of the emerging hexagonal modulation, this result suggests that the hippocampal formation may use the learning principle of abstract relational structure.  The model is certainly abstract and structurally different from the biological brain.  The question as to how these can correspond to each other is left open.  There could a neural implementation of our algorithm, or there could be some other model of the same principle for which a neural implementation could be found.  In any case, it is important to understand, from theoretical neuroscience point of view, why brain might have the hexagonal modulation property.  Pursing the principle is one such approach.\n\nThe reason why we expected the emergence of hexagonal modulation is as follows.  Since the previous work by Whittington et al. (2018,2020) showed that hexagonal grid-cell property emerges from the abstract relation structure principle in a 2D random-walking task and since hexagonal modulation is supposed to arise as aggregate responses from grid-cells, we expected this property to emerge from the same principle in a different, decision-making task.  This is actually not so straightforward since there is a subtlety in the difference of the tasks.  In the random-walking task, the relations are all one-to-one and have no ambiguity, while in the decision-making task, the relations are many-to-many (Sec 2).  Nonetheless, the hexagonal representation appears to be optimal for 2D structure."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1539/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700534706881,
                "cdate": 1700534706881,
                "tmdate": 1700613968518,
                "mdate": 1700613968518,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LweKBM1yLv",
            "forum": "KC58bVmxyN",
            "replyto": "KC58bVmxyN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1539/Reviewer_RHcS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1539/Reviewer_RHcS"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new cognitive model for performing memory-based decision-making tasks. The main contribution is a learning algorithm that allows the model to learn abstract relationships from reward-guided relational inference tasks, while maintaining dynamic binding between these abstract relations and concrete entities in a given task using a memory mechanism. The experiments demonstrate the model's ability to capture relational structures in one-dimensional and two-dimensional hierarchies. The authors also show that the model exhibits both performance and internal representations that bear resemblance to human behavioral and fMRI experimental data."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper introduces an interesting cognitive model for acquiring abstract relationships through reward-guided relational inference tasks. The experiments showcase the model's ability in learning relational structures that exhibit generalization across novel domains, featuring previously unseen entities. Notably, it significantly outperforms baseline models, such as LSTMs and standard Transformers. Further, the authors reveal an intriguing alignment between the model's behavior and fMRI data from humans performing the same tasks."
                },
                "weaknesses": {
                    "value": "While the overall presentation of the paper is good, there are a couple of sections that are not easy to follow. The results on the two-dimensional hierarchy (section 4.2) can be challenging to understand for someone not very familiar with the findings in Park et al. (2021). Additionally, the notation in the section on transitive inference (3.4) can be a bit confusing (please see questions below).\n\nThe paper also misses references to related works on models for cognitive maps [1, 2]. Notably, [2] provides a unifying explanation for multiple hippocampal observations, while [3] presents an interesting approach for the reuse of learned abstractions in the form of graph schemas. It would be helpful to discuss the relationship between the approach in this work and these previous works.\n\nMinor: There are several grammatical errors and a few typos (e.g., 'Maharanobis' on page 15) scattered throughout the paper.\n\n\n[1] George, D., et al., 2021. Clone-structured graph representations enable flexible learning and vicarious evaluation of cognitive maps. Nature communications, 12(1), p.2392.\n\n[2] Raju, R.V., et al.., 2022. Space is a latent sequence: Structured sequence learning as a unified theory of representation in the hippocampus.\n\n[3] Guntupalli, J.S., et al., 2023. Graph schemas as abstractions for transfer learning, inference, and planning. arXiv preprint arXiv:2302.07350."
                },
                "questions": {
                    "value": "- What properties does the relation matrix possess, could you offer insights into them?\n- Is there a separate MLP for each $g_a$? If yes, how do you ensure the probabilities sum to 1?\n- In equation 10, does $m$ in $\\psi_a^{m-1}$ correspond to the $m^{\\rm th}$ power? Or is it the $m^{\\rm th}$ iteration? If the latter, how is  $\\psi_a^{m-1}$ updated? \n- In the formula for the inference score in section 4.1, what is $c^{ti}$?\n- How was the value $\\alpha=0.7$ chosen?\n- In the caption of Figure 4, you mention that the for NTM and DNC the horizontal axis is 50-times reduced for readability. Does this mean that they used 50-times more epochs?\n- How were the hyperparameters selected for the baseline methods in Figure 4a? \n- In Figure 4b, why is the performance, after approximately 150 steps, slightly worse after 8000 epochs compared to the performance after 1000 epochs?\n- What is the effect of S (the length of the state vector) on the results?\n- In section 4.2, you discuss the learned intermediate representation $h$. I'd like to clarify the definition, since there appear to be two distinct uses of $h$ in equations 3 and 4.\n- Could you please clarify how the state values are computed in section 4.2? \n- Are there any thoughts about how this approach can be extended to more general relational graphs or to scenarios with sparse rewards?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1539/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698999184208,
            "cdate": 1698999184208,
            "tmdate": 1699636082225,
            "mdate": 1699636082225,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "yo3HRQbzH0",
                "forum": "KC58bVmxyN",
                "replyto": "LweKBM1yLv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1539/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1539/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer RHcS"
                    },
                    "comment": {
                        "value": "Thanks very much for the useful comments.  Especially, we will certainly incorporate and discuss the suggested references, which provide a different approach to explanation of hippocampal cognitive maps with abstraction and generalization.\n\nAnswers to questions:\n\n* Regarding the relation matrix, we generally interpret it as a kind of rotation in the state space since 2D visualization after dimension reduction often indicates so, although it is often not very precisely so.\n* The MLP ends with a softmax function (Sec B.2.1)\n* $\\phi_a^m(s)$ means m-th iteration, namely, $\\phi_a(\\phi_a(...(s)..))$, where $\\phi_a$ is recursively applied m-times.  There is no update in this computation since $\\phi_a(s)$ is defined as $\\kappa(\\rho(R_a s))$ where all the parameters used there $(M, W, R_a)$ are fixed when it is performed.  Note that we perform transitive inference task for testing a learned model (the model does not learn the transitive inference task).\n* c^ti is the confidence value for the relation chosen by the model: $\\max_a p^+(a|s,s')$ (Sec 3.4).\n* In our experience, the model behaves equally well when alpha is large, say, $\\alpha \\geq 0.5$ but badly when it is small otherwise.  We chose $\\alpha=0.7$ arbitrarily.  We will provide a plot in the revision.\n* On the number of steps in NTM and DNC, these indeed spent 50 times more epochs than the other models, taking about 40 days for the task (Fig 4).  Since the plot (Fig 4a) is in retrospect a bit confusing, in the revision, we will show a log plot (in x-axis).\n* We set the hyperparameters of the base line methods as follows.  For LSTM, we chose its state dimension as the state dimension plus the memory dimension of our model.  We also played with other settings but the result was pretty much the same.  For NTM and DNC, we used the default parameters of the package.  Since these take huge amount of time for training, we did not try other settings.  For Transformer, we chose the state dimension as the state dimension plus the memory dimension of our model.  We extensively searched other hyperparameters so that at least training works, as described in Sec B.2.2.  For FW, we set the same hyperparameters as our model except for $\\alpha=0.5$ (similar to TEM).  Sec B.2.2 gives more on this topic.\n* As for the slight performance decrease in Fig 4b, we do not know exactly the reason but it is likely some kind of overfitting.\n* On the effect of $S$, we observed that the training works for a range of it from 10 to 100.  We will provide a plot in the revision.\n* The intermediate representation $h$ mentioned in Sec 4.2 refers to the $h$ in eq (4). \n* The state $s$ metioned in Sec 4.2 for given stimulus x is computed by $s=infer_{M,W}(x)$ using eq (4).  Note that we first run the model in the test domain (Sec 4.2, par 3)\n* For extension, we think that the current framework can be used for general relational graphs like trees and cycles.  For sparse rewards, the current design assumes immediate rewards: the reward is associated with the choice made in the same step.  Therefore we would likely need a nontrivial extension possibly with value functions.  We have not studied either topic much so far."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1539/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700526830433,
                "cdate": 1700526830433,
                "tmdate": 1700526830433,
                "mdate": 1700526830433,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]