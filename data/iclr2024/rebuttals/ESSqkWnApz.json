[
    {
        "title": "Fast and Reliable Generation of EHR Time Series via Diffusion Models"
    },
    {
        "review": {
            "id": "lfHVBcjRQX",
            "forum": "ESSqkWnApz",
            "replyto": "ESSqkWnApz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6531/Reviewer_5r5j"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6531/Reviewer_5r5j"
            ],
            "content": {
                "summary": {
                    "value": "This paper developed a diffusion model, TimeDiff to generate synthetic EHR time-series data. Authors consider the generation of both numerical\n(real-valued) and discrete time-series by combining both multinomial and Gaussian diffusions. Experiments on 6 datasets show the proposed method achieves better discriminative and predictive scores."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper studies an important problem, mixed-type EHR generation."
                },
                "weaknesses": {
                    "value": "1. The authors claim that TIMEDIFF is the first to generate mixed type EHR. However, other works like [1,2,3,4] have done the same or similar things. The authors did not compare or discuss these works. And comparing one or two of them is important. \n2. Further, the proposed method might not be as new or unique as the authors suggest. It\u2019s important to note that TIMEDIFF is a diffusion model by replacing the U-Net architecture. The change of loss function and nosing step is straightforward by incorporating previous works (multinomial diffusion). \n3. The authors say that TIMEDIFF is faster because it takes less time to train than GAN-based methods. However, when we look at how fast generative models work, we usually look at how quickly they can create samples (**sampling procedure**), not how quickly they can be trained. Diffusion models, which TIMEDIFF is based on, usually create high-quality samples but take a long time to do so. So, saying that TIMEDIFF is more efficient than GANs in the introduction is misleading. The authors should instead focus on comparing the speed of creating samples. \n4 Privacy evaluation is necessary as existing works do, like membership inference attack. \n\n## Reference \n1. Li et.al., 2023. Generating synthetic mixed-type longitudinal electronic health records for artificial intelligent applications\n2. Ceritli et.al. 2022.  Synthesizing Mixed-type Electronic Health Records using Diffusion Models\n3. Naseer1 et.al., 2023. ScoEHR: Generating Synthetic Electronic Health Records using Continuous-time Diffusion Models\n4. Theodorou et.al., 2023. Synthesize high-dimensional longitudinal electronic health records via hierarchical autoregressive language model"
                },
                "questions": {
                    "value": "See weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6531/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698744012249,
            "cdate": 1698744012249,
            "tmdate": 1699636735202,
            "mdate": 1699636735202,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Pn88fRSfnS",
                "forum": "ESSqkWnApz",
                "replyto": "lfHVBcjRQX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6531/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6531/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 5r5j"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the comments. We address each of the questions and weaknesses below.\n\n> The authors claim that TIMEDIFF is the first to generate mixed type EHR. However, other works like [1,2,3,4] have done the same or similar things. The authors did not compare or discuss these works. And comparing one or two of them is important.\n\nFirst, we would like to kindly note that our work states that TimeDiff is the first to generate **mix-type time series via diffusion models. We did not claim our work is the first to generate mixed-type EHR**, which is already being studied by others. Our contribution comes from the use of mixed diffusion to generate mixed-type time series, which has not been done before.\n\nSecondly, we acknowledge the importance of comparing our work with the method in [1], EHR-M-GAN. In response, we have conducted an evaluation and included these results in our revised manuscript. This comparison clearly demonstrates TimeDiff's superiority over all other eleven baseline methods considered in our study. We hope our comparison is convincing.\n\nThirdly, we cannot compare with [2,3,4] for the reasons below:\n* For [2]: this method is for **tabular** data generation, which is very different from **time series** data generation.\n* [3,4] became publicly available in August, 2023, while our submission deadline is in September, 2023. We are not required to compare with these works per ICLR policy.\n\n> Further, the proposed method might not be as new or unique as the authors suggest. It\u2019s important to note that TIMEDIFF is a diffusion model by replacing the U-Net architecture. The change of loss function and nosing step is straightforward by incorporating previous works (multinomial diffusion).\n\nWe appreciate your comments regarding the novelty of our method. While diffusion models or generative models for EHR are an established concept, their application to mixed-type time series data, especially in time-dependent Electronic Health Records (EHR), is a significant innovation in our work. This is not just a matter of substituting the U-Net architecture or altering the loss function. We have specifically tailored the noise model and loss function to address the complexities inherent in mixed-type EHR data, a challenge that existing models have not adequately tackled. This adaptation is crucial for accurately capturing the diverse data characteristics in EHR, as detailed in our paper. Ultimately, we believe our method enhances the accuracy and training efficiency of generative modeling in healthcare, presenting a noteworthy advancement.\n\n> The authors say that TIMEDIFF is faster because it takes less time to train than GAN-based methods. However, when we look at how fast generative models work, we usually look at how quickly they can create samples (sampling procedure), not how quickly they can be trained. Diffusion models, which TIMEDIFF is based on, usually create high-quality samples but take a long time to do so. So, saying that TIMEDIFF is more efficient than GANs in the introduction is misleading. The authors should instead focus on comparing the speed of creating samples.\n\nOur original intention for saying \"Fast and Reliable Generation of EHR Time Series via Diffusion Models\" was to indicate the ease in training. We have noticed that this can cause confusion for the readers. Thus, in our revision, we have removed \"fast generation\" in our title. We have also removed mentioning that our model is \"more computationally efficient\" in our introduction. Instead, we only mention that our method is easier to train than GAN-based methods. We hope these edits make our paper clearer to the readers.\n\n\n> Privacy evaluation is necessary as existing works do, like membership inference attack.\n \nWe agree that this privacy risk should be evaluated. We have included membership inference risk in our revision. The results are shown in Table 4, and the full results are contained in Appendix B.4. Our method is able to achieve low risks across four EHR datasets.\n\n## References\n[1] Li et.al., 2023. Generating synthetic mixed-type longitudinal electronic health records for artificial intelligent applications\n\n[2] Ceritli et.al. 2022. Synthesizing Mixed-type Electronic Health Records using Diffusion Models\n\n[3] Naseer1 et.al., 2023. ScoEHR: Generating Synthetic Electronic Health Records using Continuous-time Diffusion Models\n\n[4] Theodorou et.al., 2023. Synthesize high-dimensional longitudinal electronic health records via hierarchical autoregressive language model"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6531/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700209802162,
                "cdate": 1700209802162,
                "tmdate": 1700423073750,
                "mdate": 1700423073750,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "cJn6xlsJjf",
            "forum": "ESSqkWnApz",
            "replyto": "ESSqkWnApz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6531/Reviewer_27MX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6531/Reviewer_27MX"
            ],
            "content": {
                "summary": {
                    "value": "The authors present an approach to generate synthetic EHR samples using denoting diffusion probabilistic models (DDPM). To admit both numerical and categorical data, they proposed a novel 2-stage method to generate samples using the diffusion model. Furthermore they compared against several baseline models for a number of tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "There are several key contributions in the paper as follows\n- Synthetic samples for EHR is an immensely important topic that can potentially impact many aspects of AI for Health, including data availability and privacy preserving learning. The current SOTA method for synthetic EHR data is based of GAN. Seeing the promise of diffusion models for other domains, both in terms of performance and optimized training, it is thus quite exciting to see a working solution that can adapt to the nuances of EHR. The authors have explicitly considered several nuances such as mixture of numerical/categorical data and missing values. \n- The performances on several benchmark datasets are quite promising, especially in terms of being able to mimic the real world datasets\n- The authors have tried to justify the importance of several sub components using ablation studies"
                },
                "weaknesses": {
                    "value": "There are several aspects which if addressed can improve the exposition of the paper. \n- The main aspect is that while the authors have performed various high level experimental evaluation, the paper is a bit under-analyzed, especially when considering the domain of healthcare. For example, it may be interesting to conduct sub-group analysis to understand reliability zones of the algorithm\n- Another aspect that could be analyzed is some form of explainability analysis to understand the key driver of the learning. While the authors have presented results at a meta-level of categorical (multinomial) and numerical (gaussian) data modalities - it would be interesting to understand the modalities around health data dimensions such as diagnosis, drugs, and lab results.\n\nSome other minor comments are as follows\n- the presentation of the method can be substantially improved. While noting the page limit, the description of diffusion processes and the key contribution could be improved upon\n- Some choices have not been explained in details. For example for the backbone network, the authors chose BiRNN. Were attention based models considered? \n- Also, the baselines, while many, should include a few of the more recent architectures (e.g. based on diffusion processes that granted may not address the categorical data well) and some classical ones e.g MedGaN"
                },
                "questions": {
                    "value": "There are few aspects which may need some clarification from the authors\n- the Diffusion process presented assumes no interaction between numerical and categorical features. Is this choice justified? Have the authors considered investigating individual trajectories for validity of the samples? \n- The performance of in-hospital mortality task is rather low. Have the authors considered more advanced methods such as RNN/Attention models as modelers? In the same note, how was the data cohorted and the features selected for this task?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6531/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698762798757,
            "cdate": 1698762798757,
            "tmdate": 1699636735060,
            "mdate": 1699636735060,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "iBH9SZsFfk",
                "forum": "ESSqkWnApz",
                "replyto": "cJn6xlsJjf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6531/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6531/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 27MX (first half)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the thorough comments and thoughts. We provide our response for each of the points raised below.\n\n> The main aspect is that while the authors have performed various high level experimental evaluation, the paper is a bit under-analyzed, especially when considering the domain of healthcare. For example, it may be interesting to conduct sub-group analysis to understand reliability zones of the algorithm\n\nWe agree with the reviewer and believe that sub-group analysis is very meaningful for a complete understanding of the proposed method. Unfortunately, due to time constraints in the rebuttal period, we cannot conduct a thorough sub-group and reliability zone analysis. We believe this is an interesting direction to explore nonetheless. We have noted this in Section 6 in our revision.\n\n> Another aspect that could be analyzed is some form of explainability analysis to understand the key driver of the learning. While the authors have presented results at a meta-level of categorical (multinomial) and numerical (gaussian) data modalities - it would be interesting to understand the modalities around health data dimensions such as diagnosis, drugs, and lab results.\n\nWe agree that it would be interesting to evaluate the impact of different modalities of healthcare data on our model's performance. Although the current TimeDiff framework allows for the generation of categorical and numerical data modalities, our current work mainly focuses on generating non-sparse time series. For other modalities mentioned by the reviewer, they are often sparser than the data modalities we considered in this study. We hypothesize that a different modeling approach is needed since: (1) records like drugs and lab tests may not occur often and could be highly irregular; (2) the value for those results may be highly dependent on other conditions (such as initial diagnoses and past medical history). Thus, the complex nature of modeling such data modalities would require the design of a new approach, which is a good direction for future work. We have noted this and the need for explainability analysis in Section 6 as well.\n\n\n> the presentation of the method can be substantially improved. While noting the page limit, the description of diffusion processes and the key contribution could be improved upon\n\nWe thank the reviewer for pointing out a potential improvement of our paper. We have edited the method and key contribution sections to make the presentation clearer in our new revision.\n\n> Some choices have not been explained in details. For example for the backbone network, the authors chose BiRNN. Were attention based models considered?\n\nWe have previously considered and experimented with attention based models and found that they do not bring performance boosts. We have edited the texts to make this clearer in our revision.\n\n> Also, the baselines, while many, should include a few of the more recent architectures (e.g. based on diffusion processes that granted may not address the categorical data well) and some classical ones e.g MedGaN\n\nWe agree with the reviewer that more recent architectures (especially EHR-focused ones) should be included. Our primary reason for the lack of EHR time series generation frameworks are three fold: (1) code for some recent works (Yoon at al., 2023; Kuobet al., 2023) are unavailable. (2) most of the other works are very recent, within four months away from ICLR submission date. Per ICLR policy, authors do not need to compare such very recent works. (3) Most of the classical works on EHR synthesis are not focused on time series generation, which is one of the primary motivations for our study.\n\nFor the classical methods like MedGAN, they are designed for tabular or ICD code generation tasks, which is quite different from the time series generation task we are interested in our study. Thus, we believe direct comparison with MedGAN is unsuitable. Nevertheless, we totally agree that a EHR-based generative model should be added among the baselines. Thus, we have added EHR-M-GAN (Li et al., 2023). The results are contained in the revision of our paper."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6531/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700209090661,
                "cdate": 1700209090661,
                "tmdate": 1700216615409,
                "mdate": 1700216615409,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Buy71qUsHY",
                "forum": "ESSqkWnApz",
                "replyto": "cJn6xlsJjf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6531/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6531/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 27MX (second half)"
                    },
                    "comment": {
                        "value": "> the Diffusion process presented assumes no interaction between numerical and categorical features. Is this choice justified? Have the authors considered investigating individual trajectories for validity of the samples\n\nFor the forward processes (either multinomial or Gaussian diffusion), there is no interaction between numerical and categorical features. This is because the noises are added independently. This choice has been widely adopted in the diffusion model paradigm. The DSPD/CSPD baselines in our study proposed to modify this noise by using stochastic processes to model a distribution over continuous functions. However, as our results demonstrate, such modeling approach may be unsuitable for EHR time series measurements.\n\nWhile the forward processes in TimeDiff does not assume interactions between features, the reverse process does. This is achieved by the mixed loss. The neural network $s_{\\theta}$ is trained for the reverse process, learning to generate new synthetic samples by gradually denoising the latent noise. This reverse process is performed in parallel for categorical and numerical features, which are both fed into $s_{\\theta}$. Thus, the reverse process does capture interaction between numerical and categorical features, since the network must learn to approximate the reverse process via the mixed loss.\n\nWe have investigated the individual trajectories from a statistical perspective, some examples are added to Appendix B.5 in our revision. For a medical-knowledge-oriented perspective, a thorough analysis should involve medical practitioners' judgements. Given the time constraint in the rebuttal period, we believe this is a great direction for future work instead.\n\n\n> The performance of in-hospital mortality task is rather low.\n\nIndeed, the performance for in-hospital mortality prediction task is low. We believe the major cause is the number of feature types used for training of the modelers. Since our approach solely focuses on time series features, the modelers cannot make use of static variables. These static variables can be very important for in-hospital mortality prediction tasks (an example is age and commorbidities). Without those static variables, it is difficult for the modelers to predict mortality alone by solely using time series.\n\nHowever, we would like to note that this is more of an issue with the prediction modelers rather than TimeDiff. The TSTR and TSRTR evaluations still demonstrate that the synthetic samples from TimeDiff can support modelers\u2019 performances. This reflects the synthetic data's high utility, which is also supported by the discriminative and predictive scores in Table 1.\n\n> Have the authors considered more advanced methods such as RNN/Attention models as modelers?\n\nWe have added the results for RNN modelers for in-hospital mortality prediction task in Appendix B.4. \n\n> In the same note, how was the data cohorted and the features selected for this task?\n\nOur feature selection and cohort selection methods for the real data are discussed in Appendix A.1. We have also made edits to Appendix A.1 to make the presentation clearer. To train the modelers, we first obtained synthetic samples from TimeDiff. We then used these synthetic samples as the training data for the modelers. We did not manually select the synthetic data samples."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6531/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700209507958,
                "cdate": 1700209507958,
                "tmdate": 1700215741857,
                "mdate": 1700215741857,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "k8WcHwDwHL",
                "forum": "ESSqkWnApz",
                "replyto": "iBH9SZsFfk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6531/Reviewer_27MX"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6531/Reviewer_27MX"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "Thanks for the detailed response. Based on the response, I am happy with my original rating of the paper"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6531/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700684059076,
                "cdate": 1700684059076,
                "tmdate": 1700684059076,
                "mdate": 1700684059076,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "kHlXInGXPo",
            "forum": "ESSqkWnApz",
            "replyto": "ESSqkWnApz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6531/Reviewer_WAfz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6531/Reviewer_WAfz"
            ],
            "content": {
                "summary": {
                    "value": "The authors adopt DDPM (Gaussian transition together with multinomial transition) for EHR generation. They adopt Time-conditional BRNN as the backbone together with Diffusion Step Embedding. They evaluate their methods on six datasets against seven baseline methods."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The experimental results are good. The authors adopt six criteria rather than only TSTR and similarity criteria by previous methods."
                },
                "weaknesses": {
                    "value": "The contribution of this paper is more heuristic, i.e., Time-conditional BRNN with time embedding can achieve better performance for generating EHR data while with no theoretical guarantees."
                },
                "questions": {
                    "value": "The author adopts the sample mean as the imputation methods for dealing with missing data. More advance techniques can be adopted, which might further improve the performance."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6531/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6531/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6531/Reviewer_WAfz"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6531/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698835024388,
            "cdate": 1698835024388,
            "tmdate": 1699636734768,
            "mdate": 1699636734768,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "IPRsha0uyc",
                "forum": "ESSqkWnApz",
                "replyto": "kHlXInGXPo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6531/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6531/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer WAfz"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the comments. We address the weakness and question raise by the reviewer below.\n\n> The contribution of this paper is more heuristic, i.e., Time-conditional BRNN with time embedding can achieve better performance for generating EHR data while with no theoretical guarantees.\n\nWe believe theoretical understanding of diffusion or score-based models are very important to the ML community. However, **as indicated by our Primary Area of submission (applications to physical sciences), the focus of our paper is on *application* of diffusion models on EHR time series**. Most application-oriented studies in deep learning community are based on empirical analysis and experimentation, which we have conducted in our paper.\n\nWe firmly believe theoretical explanations of the existing complex generative models are a crucial direction for future research. However, for this paper, our focus is on application rather than theory. We have added theoretical analysis as a future direction in Section 6.\n\n> The author adopts the sample mean as the imputation methods for dealing with missing data. More advance techniques can be adopted, which might further improve the performance.\n\nWe thank the reviewer for pointing out this idea. \n\nFirstly, we have explored using spline interpolation to replace missing values, which is a more advanced technique than using the sample mean. We found it yields similar performances. \n\nSecondly, we adopt sample mean since it is straightforward to implement, allowing for easier comparisons between baseline methods. This allows our evaluation to focus on the generative models themselves rather than missing value imputations. Given our paper's focus on generative modeling, optimizing missing value imputations is relatively out of the scope of this work."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6531/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700208978954,
                "cdate": 1700208978954,
                "tmdate": 1700210300335,
                "mdate": 1700210300335,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "USVqDRgmyQ",
                "forum": "ESSqkWnApz",
                "replyto": "IPRsha0uyc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6531/Reviewer_WAfz"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6531/Reviewer_WAfz"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for the detailed responses. My overall rating remains."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6531/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700733581465,
                "cdate": 1700733581465,
                "tmdate": 1700733581465,
                "mdate": 1700733581465,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "A5tECFWVxm",
            "forum": "ESSqkWnApz",
            "replyto": "ESSqkWnApz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6531/Reviewer_UTQr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6531/Reviewer_UTQr"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposed a diffusion probabilistic model for the generation of EHR time-series data, leveraging a combination of multinomial and Gaussian diffusion. By introducing this mixed diffusion approach specific to EHR time-series data, they have empirically demonstrated enhanced performance in comparison to other time-series generation methodologies, especially in terms of data utility."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This is the first work to apply this mixed diffusion approach to EHR time-series data.\n- The authors have demonstrated the model's performance not only on EHR data but also on non-EHR data, showcasing its applicability across diverse domains."
                },
                "weaknesses": {
                    "value": "- The time series EHR synthesis studies from Kuo et al. (2023) and Yoon et al. (2023) were mentioned in the related works, but not included in the baseline section. It would be an imperative first step to improve the soundess of the paper to integrate these studies into the baseline to ensure a thorough comparative analysis, especially given the absence of synthetic models specifically designed for EHR synthesis in the current baseline candidates.\n- The title suggests \"Fast and reliable generation\", yet the evaluation on this aspect seems somewhat limited. Merely measuring training time and claiming \"fast generation\" may be an overclaim, without addressing the sampling time."
                },
                "questions": {
                    "value": "Please see the weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6531/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698841963674,
            "cdate": 1698841963674,
            "tmdate": 1699636734464,
            "mdate": 1699636734464,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JKUwrHJI6e",
                "forum": "ESSqkWnApz",
                "replyto": "A5tECFWVxm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6531/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6531/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer UTQr"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the critique on our paper. We address each of the weaknesses below:\n\n> The time series EHR synthesis studies from Kuo et al. (2023) and Yoon et al. (2023) were mentioned in the related works, but not included in the baseline section. It would be an imperative first step to improve the soundess of the paper to integrate these studies into the baseline to ensure a thorough comparative analysis, especially given the absence of synthetic models specifically designed for EHR synthesis in the current baseline candidates.\n\nThe reviewer raised a great question about the soundness of our work. Our reasons for not including these two works in our paper are as follows:\n1. We have considered to include these two baselines in our studies since the very beginning. **However, their code implementations are not avaialble. We also reached out to the authors for those two papers but received either no response or inability to share the code**. This is the main reason for not comparing TimeDiff with the works by Kuo et al. (2023) and Yoon et al. (2023). \n2. In addition, the work by Yoon et al. is published in npj Digital Medicine on 11 August 2023 (which is after May 28, 2023). **This work falls under the ICLR policy where our submission can be excused from not comparing the results to it** (*see the last question in FAQ for Reviewers: https://iclr.cc/Conferences/2024/ReviewerGuide*):\n\nWhile we cannot obtain code implementation for the method proposed by Kuo et al., we would like to note that the alternative approach in our ablation study is very close to it. To summarize, the method used by Kuo et al. bascially applies Gaussian diffusion with a U-Net backbone, and discrete-valued time series is generated with argmax of softmax of the generated real-valued time series.\n\nWe agree with the reviewer that most of our baseline candidates are not specifically designed for EHR time series generation (except for RCGAN). Thus, we have added EHR-M-GAN (Li et.al., 2023) as one of our baselines. We have included its results in the revision. Please see Table 1, Figure 1, Table 2, and Table 4 for the results. Due to page limits, we have to include some results in the appendix, and those can be found at Appendix B.1, B.2, and B.4.\n\n> The title suggests \"Fast and reliable generation\", yet the evaluation on this aspect seems somewhat limited. Merely measuring training time and claiming \"fast generation\" may be an overclaim, without addressing the sampling time\n\nWe sincerely thank the reviewer for pointing out the confusion in our paper. Indeed, our original intention is to state that the training time is faster. As stated in our abstract, our work mainly focuses on demonstrating the superior performance of the diffusion model paradigm compared with generative adversarial networks in terms of ease of training and sample quality. We agree that this title can cause confusion for the readers. In our revision, we have adjusted the title and texts accordingly to clarify that we do not have speed up in sampling. We apologize for causing this confusion to the reviewer."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6531/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700208720048,
                "cdate": 1700208720048,
                "tmdate": 1700208720048,
                "mdate": 1700208720048,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]