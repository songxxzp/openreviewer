[
    {
        "title": "A Convergent Federated Clustering  Algorithm without Initial Condition"
    },
    {
        "review": {
            "id": "teNdKsBIOP",
            "forum": "gaAvQ4ogUX",
            "replyto": "gaAvQ4ogUX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9076/Reviewer_Vidh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9076/Reviewer_Vidh"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a federated clustering framework to address the dichotomy between heterogeneous models and simultaneous training in FL. This work proposes an algorithm, named SR-FCA, that treats each client as a singleton cluster as an initialization, and then successively refine the cluster estimation via exploiting similarity with other clients. The experimental results show that the proposed SR-FCA achieves a smaller clustering error and outperforms existing methods."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper introduces a clustering framework tailored for the Federated Learning environment, which aims to address the dichotomy between heterogeneous models and simultaneous training in FL.\n\n2. The paper provides theoretical guarantees for the proposed method.\n\n3. The experimental results appear to demonstrate that the proposed method (SR-FAC) achieves good performance in image classification tasks."
                },
                "weaknesses": {
                    "value": "1. This paper could be improved in terms of clarity, such as simplifying the usage of symbols.\n \n2. This paper aims to address the issue of collaborative training between clients in the case of model heterogeneity. However, there are some well-known solutions that have not been discussed yet, such as \n\n[1] Tan, Yue, et al. \"Fedproto: Federated prototype learning across heterogeneous clients.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 36. No. 8. 2022. \n[2] Fang, Xiuwen, and Mang Ye. \"Robust federated learning with noisy and heterogeneous clients.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.\n[3] Alam, Samiul, et al. \"Fedrolex: Model-heterogeneous federated learning with rolling sub-model extraction.\" Advances in Neural Information Processing Systems 35 (2022): 29677-29690.\n\n3. The method might not be suitable for all FL scenarios, especially when there's a vast number of clients or highly dispersed data.\n\n4. While this study provides some theoretical analysis, it contains numerous assumptions which limit its applicability in the real world.\n\n5. This study utilized only some small datasets for experiments. Incorporating commonly-used datasets like Tiny-Imagenet and CIFAR-100 in the experimental evaluation would be beneficial.\n\n6. This study compares only a few methods in the performance comparison section and misses the most advanced ones from 2023. Consequently, it doesn't adequately illustrate the superiority of the proposed SR-FAC.\n\n7. While this study discusses some works in the Introduction Section, it lacks a dedicated Related Work Section in its structure, failing to reflect a comprehensive review of the relevant literature."
                },
                "questions": {
                    "value": "1. Why did the authors emphasize in Section 2 that the data size $n_i$ for each client $i$ is greater than $n$? Does $n$ have any special significance?\n\n2. How does SR-FAC perform in terms of efficiency and scalability in large-scale data or node environments?\n\n3. How does this work measure the distance between different architectural models?\n\n4. How to determine the number of clusters? Is there any adaptive methods, which are particularly important for large-scale datasets?\n\n5.This paper claims that the proposed method SR-FAC can overcome the issue of model heterogeneity, but this is not reflected in the experimental section.\n\n6. How were some parameters in the experimental section selected, such as the optimizer and its associated parameters, training epochs, etc.?\""
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9076/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9076/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9076/Reviewer_Vidh"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9076/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698728948868,
            "cdate": 1698728948868,
            "tmdate": 1699637143229,
            "mdate": 1699637143229,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "GZBeTT7buD",
            "forum": "gaAvQ4ogUX",
            "replyto": "gaAvQ4ogUX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9076/Reviewer_41D8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9076/Reviewer_41D8"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a new clustering algorithm in federated learning named as SR-FCA. SR-FCA resolves several drawbacks existing in baseline IFCA. Most importantly, SR-FCA does not require any specific initialization, does not restrict all users in the same cluster to be exactly identical, and does not require knowledge of the cluster number apriori. Furthermore, this paper provides theoretical guarantees for the proposed SR-FCA."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper has a strong motivation, e.g., provides a well-justified improvement over baseline in terms of arbitrary initialization, as well as no prior knowledge of cluster number and no restriction of the identical inner-cluster client models, which are all legitimate practical concerns.\n\n- Experimental results seem to demonstrate that SR-FCA achieves convincing results compared to many baselines."
                },
                "weaknesses": {
                    "value": "- The algorithmic novelty: the ingredients e.g., ONE_SHOT, MERGE, are techniques in many existing clustering approaches. Admittedly, they may be applied to centralized scenarios instead of federated settings as in this paper. \n\nNevertheless, the difference and unique challenges from centralized to federated settings may be more explicitly illustrated.\n\n- The theoretical analysis: I generally find the theoretical analysis part is not difficult to follow compared to some exsiting literature like IFCA paper, and thus it is difficult to evaluate the actual theoretical contribution:\n\nThe assumptions used in this paper are relatively stronger, and thus less well justified, than IFCA. e.g., (1) the per-sample convexity and smoothness assumption, instead of the assumptions of population loss function as in IFCA, wondering whether assumption on individual loss function is necessary; (2) no characterization of stochasticity of the gradient, while existing literature like IFCA works with stochastic gradient, which is more realistic in deployment. wondering whether the stochastic gradient assumption poses extra complexity; (3) the coordinate-wise Lipschitz assumption is very restrictive, though the authors mention it is unavoidable when encountering trimmed mean procedure. Nonetheless, it is a very strong and unrealistic assumption in real world setting.\n\nThese assumptions need clearer justification for readers to evaluate the technical contribution of this part."
                },
                "questions": {
                    "value": "Please see the questions raised in weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9076/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698781000320,
            "cdate": 1698781000320,
            "tmdate": 1699637143126,
            "mdate": 1699637143126,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "8UGtJV0x6B",
            "forum": "gaAvQ4ogUX",
            "replyto": "gaAvQ4ogUX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9076/Reviewer_rp3L"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9076/Reviewer_rp3L"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new clustering framework for federated learning that allows for high heterogeneity level between clients while still enabling clients with similar data to train a shared model. The proposed algorithm, SR-FCA, does not require any good initialization and uses an error-tolerant federated learning algorithm within each cluster to exploit simultaneous training and correct clustering errors."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper proposes a novel federated clustering algorithm that addresses the challenges of heterogeneous models and simultaneous training in federated learning. The proposed algorithm introduces a clustering structure among the clients, which allows for high heterogeneity levels between clients while still enabling clients with similar data to train a shared model. The proposed algorithm incurs arbitrarily small clustering errors with proper choice of learning rate. The authors also demonstrate the convergence of the algorithm through experiments on simulated and real-world datasets."
                },
                "weaknesses": {
                    "value": "1.\tWhat if C0 is bad in initialization? How often will it happen?\n2.\tThe author should provide more experiments and illustrations on several hyperparameters, especially for those thresholds (e.g., lambda, beta)\n3.\tWhat is the difference between a client and a node? Are they the same? It confused me during the reading.\n4.\tIs trimmedmean algorithm training anything? Does it produce an averaged model based on the local model within the cluster?"
                },
                "questions": {
                    "value": "Please refer to Strengths and Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9076/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9076/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9076/Reviewer_rp3L"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9076/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698891953144,
            "cdate": 1698891953144,
            "tmdate": 1699637143017,
            "mdate": 1699637143017,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "46j5vHHU1y",
            "forum": "gaAvQ4ogUX",
            "replyto": "gaAvQ4ogUX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9076/Reviewer_TZiD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9076/Reviewer_TZiD"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a clustered FL method to tackle non-IID issues. Specifically, the proposed clustering method does not rely on selecting a good initialization."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The targeting problem is a practical issue of clustered FL."
                },
                "weaknesses": {
                    "value": "1. The proposed algorithm is overly complicated. There are many simple ways to solve the initialization issue of clustering. \n\n2. The selecting threshold of lambda is infeasible in calculating the distance between two high-dimensional vectors.\n\n3. The paper's writing is confusing."
                },
                "questions": {
                    "value": "Please refer to weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9076/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699448424385,
            "cdate": 1699448424385,
            "tmdate": 1699637142924,
            "mdate": 1699637142924,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]