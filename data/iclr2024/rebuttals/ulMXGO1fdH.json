[
    {
        "title": "Estimating Post-Synaptic Effects for Online Training of Feed-Forward SNNs"
    },
    {
        "review": {
            "id": "AwVrkLDkfX",
            "forum": "ulMXGO1fdH",
            "replyto": "ulMXGO1fdH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5696/Reviewer_Rp8L"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5696/Reviewer_Rp8L"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new online training method OTPE for spiking neural networks. It incorporates temporal dynamics not captured by existing online methods such as OSTL and OTTT while maintaining similar time and space complexity. Experiments on synthetic datasets and SHD with feedforward networks demonstrate improved performance and better alignment of gradient angles with BPTT."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This paper considers facilitating online learning in SNNs, which is important for biological plausibility and neuromorphic hardware.\n\n2. Experiments demonstrate large improvements on gradient angle alignment and better performance than existing methods."
                },
                "weaknesses": {
                    "value": "1. The presentation can be improved. It is not quite clear what is the major component in the methodology that leads to the large improvement over existing methods. From Section 3, OTPE is very similar to OSTL and there is no explicit description of the key difference. From Section 3.1, AOTPE differs from OTTT only in that AOTPE uses a running weighted average of surrogate derivatives. Why this small change can almost double the cosine similarity given the similar time and space complexity? Is there more formal theoretical justification? From the derivation, OTPE also makes many approximations, why these approximations have less effect than OSTL/OTTT? Besides, what does the term \u201cpostsynaptic estimates\u201d mean?\n\n2. Scalability is mentioned multiple times in the paper. Are there more large-scale (datasets, network, etc.) results?\n\n3. In the abstract, \u201crate-based and time-based encoding\u201d is mentioned. However, there is no corresponding part in the paper."
                },
                "questions": {
                    "value": "See weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5696/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698648699572,
            "cdate": 1698648699572,
            "tmdate": 1699636595829,
            "mdate": 1699636595829,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2ej13F3U2X",
                "forum": "ulMXGO1fdH",
                "replyto": "AwVrkLDkfX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5696/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5696/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear reviewer,\n\nThank you for your comments and questions. Our responses are below.\n\n> The presentation can be improved. It is not quite clear what is the major component in the methodology that leads to the large improvement over existing methods. From Section 3, OTPE is very similar to OSTL and there is no explicit description of the key difference. From Section 3.1, AOTPE differs from OTTT only in that AOTPE uses a running weighted average of surrogate derivatives. Why this small change can almost double the cosine similarity given the similar time and space complexity? Is there more formal theoretical justification? From the derivation, OTPE also makes many approximations, why these approximations have less effect than OSTL/OTTT? Besides, what does the term \u201cpostsynaptic estimates\u201d mean?\n\nThe major component is including the effect of previous spikes, captured by $\\hat{R}$. For approx. OTPE, it is the combination of both $\\bar{g}$ and $\\hat{z}$. The formal justification can be seen in what OSTL misses ($\\sum\\_{t=1}^T \\frac{\\partial \\mathcal{L}\\_t}{\\partial s^l\\_t} \\frac{\\partial s^l\\_t}{\\partial U^l\\_t} \\left(\\frac{\\partial U^l\\_t}{\\partial \\theta^{l-1}\\_t}+\\xcancel{\\frac{\\partial U^l\\_t}{\\partial U^l\\_{t-1}} \\frac{\\partial U^l\\_{t-1}}{\\partial \\theta^{l-1}}}\\right)$) and how OTPE approximately captures that ($\\xcancel{\\frac{\\partial U^l\\_t}{\\partial U^l\\_{t-1}} \\frac{\\partial U^l\\_{t-1}}{\\partial \\theta^{l-1}}} \\approx \\lambda \\cdot {\\theta^{l}}^\\intercal \\hat{R}^{l-1}$). Intuitively, hidden layers early in the pipeline of a very long network will affect many membrane potentials, which influences the network outputs in subsequent time-steps. Gradients from this path are ignored by OTTT and OSTL, and as seen by layer-wise gradient cosine similarity, those effects can be the primary driver of gradient direction in early hidden layers.\n\nOSTL\u2019s approximation of gradients is the assumption that the spiking activity at the most recent time-step is solely responsible for the network output at said time-step. OTPE\u2019s approximation directly addresses an area of gradient calculation where OSTL is almost guaranteed to be wrong. As long as OTPE\u2019s approximation is more accurate than assuming this part of the gradient is zero, OTPE\u2019s gradients will be more accurate than OSTL.\n\n\u201cPost-synaptic estimates\u201d refers to $\\hat{R}$, which estimates how a layer\u2019s parameters influenced the following layer\u2019s (post-synaptic neurons) membrane potentials.\n\n> Scalability is mentioned multiple times in the paper. Are there more large-scale (datasets, network, etc.) results?\n\nWe consider our algorithm scalable because its storage is $O(n^2)$ (i.e. the number of parameters in the network) compared to RTRL with $O(n^3)$ storage (number of parameters x number of state variables), with a similar decrease in computational complexity. We do not provide an empirical comparison because evaluating RTRL is impractical for the multilayer models we are testing.\n\n> In the abstract, \u201crate-based and time-based encoding\u201d is mentioned. However, there is no corresponding part in the paper.\n\nWe introduce R-Randman which is a variant of the Randman dataset that depends only on rate-based encoding in spiking neurons. We then evaluate the performance difference of different algorithms on R-Randman and T-Randman (the time-encoded version of Randman). The rate-based and time-based encoding in the abstract reference these evaluations. The loss landscapes we presented (see Fig 5 ) are for the different learning methods on R-Randman and T-Randman. Figures 2-6 all have subplots for R-Randman and T-Randman for comparison."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5696/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700732099833,
                "cdate": 1700732099833,
                "tmdate": 1700732099833,
                "mdate": 1700732099833,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "oyfAQIu8r3",
            "forum": "ulMXGO1fdH",
            "replyto": "ulMXGO1fdH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5696/Reviewer_Q7D9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5696/Reviewer_Q7D9"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the author presents an Online Training algorithm with postsynaptic estimates (OTPE). OTPE leverages the preservation of multiple temporal spike outputs to achieve a more precise gradient. Their experiments demonstrate that, compared to similar algorithms, OTPE achieves better alignment with gradients by BPTT."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The authors introduce a new approximation RTRL algorithm called OTPE that captures richer temporal effects compared to previous online training methods. OTPE algorithm achieve  gradients highly aligned between BPTT method and effectively reduce the time and space complexity."
                },
                "weaknesses": {
                    "value": "1. The OTTT algorithm was experimented on several datasets such as CIFAR10 and CIFAR100. In comparison, the paper only presented comparative experiments on SHD, which may lead to insufficient persuasive power of the experiments. Therefore, it may be necessary to conduct experiments on a more diverse range of datasets to fully validate the effectiveness of OTPE.\n2. The presentation of the Approximate OTPE section in the paper seems unclear as it does not clearly demonstrate the mathematical approximation made by OTPE and Approximate OTPE.\n3. The paper claims in the abstract that \"This approximation incurs minimal overhead in the time and space complexity compared to similar algorithms.\" However, the theoretical analysis does not demonstrate the advantages, and there is a lack of corresponding experimental comparisons to support this claim.\n4. The LIF neurons of the article seem to be missing $ s_t^{l-1}\\cdot \\theta $, so the membrane potential stays the state of decay. If the membrane potential update formula is modified to $s_t^l=H(U_{t}^l-V_{th}), U_t^l=\\lambda U_{t-1}^l+ s_t^{l-1}\\cdot \\theta -V_{th}\\cdot s_t^l$, then the OTPE's $ \\frac{\\partial U_t^l}{\\partial \\theta^{l-1}}=\\frac{\\partial U_t^l}{\\partial s_t^{l-1}}\\frac{\\partial s_t^{l-1}}{\\partial \\theta^{l-1}} $ of the second term on the right-hand side What does it mean? Does this also mean that it is possible to compute the expression of the left form directly, without the need to use the chain rule, as in the article?\n5. In the second paragraph of section 3, the expression $$\\frac{\\partial s(t)_i^l}{w_{ij}^l} $$, does the subscript \"i\" in the numerator refer to the current time step? Could you explain the meanings of the variables and improve the wording accordingly? Moreover, should the parameter \"w\" be denoted as $\\theta$ based on the preceding text?"
                },
                "questions": {
                    "value": "See the weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5696/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698726272877,
            "cdate": 1698726272877,
            "tmdate": 1699636595726,
            "mdate": 1699636595726,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7tskJYpHSL",
                "forum": "ulMXGO1fdH",
                "replyto": "oyfAQIu8r3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5696/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5696/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Questions"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nThank you for your comments and questions. Our responses are below.\n\n> W1\n\nWe appreciate the reviewer's concerns. However, as we show in Figure 2a, we do not see any advantage to using our method in datasets with limited temporal dependency (e.g., rate-based encoding or the use of datasets like DVS-CIFAR or DVS-Gesture, etc.). We see performance advantages for temporal dependencies in Figure 2b, so we focus on benchmarks for this purpose (e.g. Spiking Heidelberg Digits). We have also added results for Spiking Speech Commands. The relative performance of the online algorithms on SSC is consistent with our other results in online learning.\n\n> W2 and W3\n\nOTPE differs from OSTL by approximating the term OSTL ignores ($\\sum\\_{t=1}^T \\frac{\\partial \\mathcal{L}\\_t}{\\partial s^l\\_t} \\frac{\\partial s^l\\_t}{\\partial U^l\\_t} \\left(\\frac{\\partial U^l\\_t}{\\partial \\theta^{l-1}\\_t}+\\xcancel{\\frac{\\partial U^l\\_t}{\\partial U^l\\_{t-1}} \\frac{\\partial U^l\\_{t-1}}{\\partial \\theta^{l-1}}}\\right)$), which is the temporal gradient from post-synaptic neurons. Because $ \\hat{R}\\_{t=0} = \\frac{\\partial U^l_{t=0}}{\\partial \\theta^{l-1}_{t=0}} $ and updates as $\\hat{R}\\_t = \\frac{\\partial U^l\\_t}{\\partial \\theta^{l-1}\\_t}+ \\lambda \\cdot \\hat{R}\\_{t-1}$, $\\hat{R}$ is the same shape as $\\frac{\\partial U^l_t}{\\partial \\theta^{l-1}_t}$, which is $n^2$ due to OSTL's sparse assumption. \n\n$\\xcancel{\\frac{\\partial U^l_t}{\\partial U^l_{t-1}} \\frac{\\partial U^l_{t-1}}{\\partial \\theta^{l-1}}} \\approx \\lambda \\cdot {\\theta^{l}}^\\intercal \\hat{R}^{l-1}$\n\nApproximate OTPE relies on two assumptions on top of OTPE: 1) We decouple the components of $\\hat{R}$, $\\frac{\\partial s^l_t}{\\partial U^l_t}$ and $\\frac{\\partial U^l_t}{\\partial \\theta^l}$, through time by assuming $\\sum_{t=1}^T \\lambda^{T-t} \\frac{\\partial s^l_t}{\\partial U^l_t}\\frac{\\partial U^l_t}{\\partial \\theta^l} \\approx \\left(\\frac{1}{T} \\sum_{t=1}^T \\lambda^{T-t} \\frac{\\partial s^l_t}{\\partial U^l_t} \\right) \\cdot \\left(\\sum_{t=1}^T \\frac{\\partial U^l_t}{\\partial \\theta^l} \\right)$. We maintain a size $n$ running weighted average of the surrogate gradients through time, which we refer to as $\\bar{g} = \\frac{1}{T}\\sum_{t=1}^T \\lambda^{T-t} \\frac{\\partial s^l_t}{\\partial U^l_t}$. 2) We approximate our layer-local temporal calculation in OTPE to only store vectors of size n by assuming the same temporal dynamics as OTTT for a single layer, $\\frac{\\partial U^l_{t}}{\\partial \\theta^{l}_t} \\approx \\hat{a}$ , such that $\\frac{\\partial U^l}{\\partial \\theta^{l-1}} \\approx {\\theta^{l}}^\\intercal \\cdot \\bar{g} \\left(\\hat{a}^{l-1}\\_t + \\lambda \\cdot \\hat{z}^{l-1}\\_{t-1} \\right)$, where $\\hat{z}$ is a weighted sum of OTTT's weighted sum ($\\hat{z}^{l-1}_t = \\hat{a}^{l-1}\\_t + \\lambda \\cdot \\hat{z}^{l-1}\\_{t-1}$).\n\n> W4\n\nWe appreciate the reviewer\u2019s concern. The equations in question specifically address the reset mechanism. We have restructured the equations and text to clarify this. \n\nYes, updating $\\hat{R}$ still does not require the chain rule. Because we assume the weights do not change throughout time when calculating gradients, matrix multiplication with the kernel at each time-step is linear throughout time (i.e. $\\sum\\_{t=1}^T \\theta^{l} s^{l-1}\\_t = \\theta^{l} \\sum\\_{t=1}^T s^{l-1}\\_t$). Therefore, the involvement of $\\theta^l$ in gradient calculation is handled outside of the time loop. If we assume the output layer never spikes, which produces the same gradients as ignoring gradients originating from the reset mechanism, then $U = \\theta^{l} \\sum\\_{t=1}^T \\lambda^{T-t}  s^{l-1}\\_t$. It follows that $\\frac{\\partial U^l\\_{t}}{\\partial \\theta^{l-1}} = \\theta^{l} \\sum_{t=1}^T \\lambda^{T-t}  \\frac{\\partial s^{l-1}\\_t}{\\theta^{l-1}}$. Since only items within the summation must be calculated through time, we only need the global leak, $\\lambda$, and $\\frac{\\partial s^{l-1}t}{\\theta^{l-1}}$ for updating. This avoids the chain rule because both $\\lambda$ and $\\frac{\\partial s^{l-1}t}{\\theta^{l-1}}$ are available at layer l-1.\n\n> W5\n\nThank you for catching this typo. We have changed the notation to match the other equations"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5696/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700731700295,
                "cdate": 1700731700295,
                "tmdate": 1700731700295,
                "mdate": 1700731700295,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "mmWkjuWCwr",
            "forum": "ulMXGO1fdH",
            "replyto": "ulMXGO1fdH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5696/Reviewer_hRpc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5696/Reviewer_hRpc"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a novel method for the online training of feed-forward Spiking Neural Networks (SNNs) that incorporates temporal information from the previous and current spikes into a postsynaptic estimate of the Real-Time Recurrent Learning (RTRL). Previous implementations of online SNN learning (such as Online Training Through Time (OTTT) or Online Spatio-Temporal Learning (OSTL)) fails to account for the temporal information of previous spikes leading to reduced accuracy of the SNN. Using Online Training with Postsynaptic Estimates (OTPE) or its approximation, gradient estimates exhibited more alignment to the exact gradients generated from Backpropagation through time (BPTT) compared to previous approaches."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "-\tGood background explanation, especially with explaining the mathematics of previous methods in comparison to OTPE.\n-\tTable 2 clearly demonstrates how OTPE performs at a closer online accuracy level to BPTT offline accuracy for SNNs at different depths and widths compared to other approximation training methods.\n-\tAnalysis was clear and transparent. Analysis was able to differentiate between actual results and faulty results due to the methodology. In the last paragraph before Section 5, the author says \u201cThe performance difference across OTPE, its approximations, OSTL, and OTTT is more apparent for T-Randman and SHD. Although we observed higher test accuracy for online learning on SHD than for offline learning, we attribute this to our hyperparameter search (see Appendix A.2).\u201d Author also acknowledges intermediate/incomplete results in this paragraph when it\u2019s said \u201cOTPE does not appear to have reached peak validation accuracy even after training on 10,000 mini-batches.\u201d"
                },
                "weaknesses": {
                    "value": "-\tThe F-OTPE method should\u2019ve been tested in multiple application-specific SNN datasets such as Auditory N-MNIST, DVS-Speech, or Spiking MNIST Audio Dataset. It\u2019s hard to tell whether the results presented for F-OTPE are valid and can be reproducible since the method was only tested on one dataset. \n-\tOnline training of OTPE only occurred on one dataset throughout the paper. If this is supposed to be a preferred method for online training, there should be more tests demonstrating the improved performance of OTPE in online SNN training using a variety of datasets such as Auditory N-MNIST, DVS-Speech, or Spiking MNIST Audio Dataset. The author can also try testing using image classification data (instead of audio) by using N-CARS, DvsGesture, or N-MNIST."
                },
                "questions": {
                    "value": "-\t[Introduction, 1st paragraph] The authors say that \u201cHowever, BPTT is unsuitable for online learning (Kaiser et al., 2020; Bohnstingl et al., 2022)\u201d. Throughout the paper, I see them using gradients from BPTT as the ground truth for their approach. Can you explain this discrepancy?\n-\tIn Figure 2, I observe that the proposed approach is as good as BPTT, then why won\u2019t I just use BPTT? What advantage is the OTPE giving?\n-\t[Introduction, 2nd paragraph] \u201cTo address these limitations ...\u201d All the references are bunched up so it is hard to understand which technique points to which reference.\n-\tMany of the figures were unclear or hard to read, e.g., all the line plots in Fig 2a are bunched up, for Figure 5 the markers are obfuscating the color of the line.\n-\tPlease explain F-OTPE more thoroughly in the Section 3.2. Elaborate on the line \u201cthe loss can be calcualted similarly to how cross-entropy loss is calculated in offline training.\u201d Also include the equations involved for F-OTPE and how it relates to normal OTPE. While the explanation in the paper was fine, it will be better explained through a visual of the mathematics.\n-\tWhy wasn\u2019t F-OTPE tested along with OTPE and approx OTPE in the offline training scenarios presented in Figures 2, 3, 4, 5? \n-\tHow will OTPE, approx OTPE, F-OTPE perform in a different application-specific dataset? You can stick to audio datasets by using Auditory N-MNIST, DVS-Speech, Spiking MNIST Audio Dataset, etc. Or you can expand to image classification datasets by using N-CARS, DvsGesture, N-MNIST, etc."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5696/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698785681954,
            "cdate": 1698785681954,
            "tmdate": 1699636595631,
            "mdate": 1699636595631,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LFbkb97Ywz",
                "forum": "ulMXGO1fdH",
                "replyto": "mmWkjuWCwr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5696/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5696/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Questions"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nThank you for your comments and questions. Our responses are below.\n\n> [Introduction, 1st paragraph] The authors say that \u201cHowever, BPTT is unsuitable for online learning (Kaiser et al., 2020; Bohnstingl et al., 2022)\u201d. Throughout the paper, I see them using gradients from BPTT as the ground truth for their approach. Can you explain this discrepancy?\n\nWe only compare against BPTT for offline learning scenarios, for online learning we compare against OTTT and OSTL. Like us, they compare with offline learning to evaluate the performance cost of the approximation. This is because online learning with exact gradients (via RTRL) does not facilitate practical evaluation for multi-layer networks and is too costly to use for comparison.\n\n> In Figure 2, I observe that the proposed approach is as good as BPTT, then why won\u2019t I just use BPTT? What advantage is the OTPE giving?\n\nWhile BPTT can deliver high performance in the offline learning scenario, it is not suitable for online learning (Rostami et al., 2022). In order to contextualize OTPE\u2019s online learning performance, we also compare its offline learning capabilities to BPTT. However, we primarily focus on online learning.\n\n> [Introduction, 2nd paragraph] \u201cTo address these limitations ...\u201d All the references are bunched up so it is hard to understand which technique points to which reference.\n\nWe have addressed this by placing the citations with their corresponding concept.\n\n> Many of the figures were unclear or hard to read, e.g., all the line plots in Fig 2a are bunched up, for Figure 5 the markers are obfuscating the color of the line.\n\nWe addressed this by reducing clutter in Fig 2a and subsampling our points on Figure 5. Unfortunately, space limitations prevent larger figures.\n\n> Please explain F-OTPE more thoroughly in the Section 3.2. Elaborate on the line \u201cthe loss can be calcualted similarly to how cross-entropy loss is calculated in offline training.\u201d Also include the equations involved for F-OTPE and how it relates to normal OTPE. While the explanation in the paper was fine, it will be better explained through a visual of the mathematics.\n\nOTPE calculates gradients under the assumption that output spikes of a hidden layer at previous time-steps are accumulated with membrane leak in the following layer ($\\hat{R}^{l} = \\frac{\\partial \\sum^{T}\\_{t=1} \\lambda^{T-t} s^{l}\\_t}{\\partial \\theta^l}$). In the output layer, this can apply to the leaked accumulation of spikes through time. Suppose we calculate loss using the accumulated spikes instead of solely relying on the spiking behavior at the current time-step. In this case, we can use $\\hat{R}$ to exactly calculate the derivative of the loss with respect to the output layer\u2019s parameters ($\\frac{\\partial \\mathcal{L}}{\\partial \\sum^{T}\\_{t=1} \\lambda^{T-t} s^{l}\\_t} \\frac{\\partial \\sum^{T}_{t=1} \\lambda^{T-t} s^{l}\\_t}{\\partial \\theta^l} = \\frac{\\partial \\mathcal{L}}{\\partial \\sum^{T}\\_{t=1} \\lambda^{T-t} s^{l}\\_t} \\hat{R}^l = \\frac{\\partial \\mathcal{L}}{\\partial \\theta^l}$). We have added this text and the mathematics for F-OTPE to the paper.\n\n\n> Why wasn\u2019t F-OTPE tested along with OTPE and approx OTPE in the offline training scenarios presented in Figures 2, 3, 4, 5?\n\nF-OTPE uses a different scoring mechanism than OTTT and OSTL, which prevents a fair comparison of gradient approximation quality and training trajectory. Both OTTT and OSTL are derived under the assumption that the loss only applies to the output of the latest time-step. If you were to use OSTL and score an aggregation of previous model outputs, then the output layer of OSTL would not match exact gradients. The primary purpose of our offline results is to make relative comparisons concerning approximation quality and optimization. We have added text to the manuscript to clarify the exclusion of F-OTPE.\n\n\n> How will OTPE, approx OTPE, F-OTPE perform in a different application-specific dataset? You can stick to audio datasets by using Auditory N-MNIST, DVS-Speech, Spiking MNIST Audio Dataset, etc. Or you can expand to image classification datasets by using N-CARS, DvsGesture, N-MNIST, etc.\n\nWe have examined test accuracy after online training on an additional dataset, Spiking Speech Commands. Our results are consistent with our previous results in online learning. F-OTPE, in particular, outperforms all other online algorithms by at least 10%."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5696/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700730375166,
                "cdate": 1700730375166,
                "tmdate": 1700730375166,
                "mdate": 1700730375166,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]