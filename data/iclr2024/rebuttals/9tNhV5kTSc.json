[
    {
        "title": "How do agents invest strategically under persistent improvement?"
    },
    {
        "review": {
            "id": "LyFbB7Fxvv",
            "forum": "9tNhV5kTSc",
            "replyto": "9tNhV5kTSc",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1108/Reviewer_6GuR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1108/Reviewer_6GuR"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigates an interesting problem of agents' learning to better satisfy the requirements for being accepted (for completing a task, etc.)  Though the paper emphasises that the objects are human agents, I think the whole paper considers only hypothetical/ artificial agents as the authors do not base the settings/ hypotheses on any verified human data.  They are just reasonable and plausible assumptions and there are no evidence that humans behave exactly in the way as depicted by the hypotheses.\n\nThe paper first gives a basic model for agent qualification dynamics (equation 1).  The relation between similarity and time is then given by equation 2.  Utility of an agent is hypothesised in equation 3, from which equation 5 is derived.  Equation 5 is the central equation of the paper as it defines utility U in terms of acceptance threshold theta.  Based on equation 5, Table 1 presents the condition U > 0 in terms x0 and theta. Corollary 4.2 shows that there is an optimal theta that maximises U_d defined in equation 7.  Section 5 changes the setting so that an agent can change its similarity in consideration of manipulation cost and detection probability.  Section 6 changes allows forgetting to happen.  Experimental studies are done in Section 7."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper is original in some aspect, in particular it captures the delayed and persistent impacts of agents' improvement, as the authors claim.  The quality of writing is good and clear.\n\nThe paper's significance is hindered by a possible technical flaw, which I shall elaborate in the weaknesses section below."
                },
                "weaknesses": {
                    "value": "The major question that I have about the paper is the one-time effort k.  The authors emphasise repeatedly that the effort is a one-time effort, which the agent pays at time t=t_i, say.  Such an effort paid changes the agent's qualification from q_{t_i} at time {t_i} to q_{t_{i+1}} at time t_{i+1}, as depicted in equation 1.  From equation 1 the authors derive equation 2.  Now my question is, for equation 2 to hold for any time t, is it not true that the agent needs to pay effort k again at time t_{i+1}, so that its qualifications will be changed from q_{t_{i+1}} to q_{t_{i+2}} according to equation 1?  If what I understand is correct, then equation 3 will need to be revised, so will virtually all subsequent equations and conclusions.\n\nAnother issue is that the definition of function C (equation 6) looks arbitrary.  It is unclear to me what C is and why we need this function.  In fact, the definitions of U (equation 3) and U_d (equation 7) are equally arbitrary, but at least the authors explain what thehy are and why they are defined in that way.  I have to point out that though equations 3 and 7 give reasonable definitions for U and U_d, there are no evidence that these *are* the utility functions real people use.\n\nSuch an issue is related to another issue (more serious in my view) in section 7.  Basically section 7 only presents a numerical simulation of the relevant equations, instead of proving their correctness in any way.  As a matter of fact, it does not really matter what dataset the authors use--even an artificially created dataset would have served this purpose very well, because only the initial conditions are obtained from the dataset.  Therefore, I do not see the use of this section.  By the way, I do not have the assess to the Exam dataset.\n\nOne last point is that the authors use superscript 'T' sometimes to denote 'to the power of T' and sometimes to denote 'transpose'.  This is confusing."
                },
                "questions": {
                    "value": "(1) Is it true that an agent needs to pay effort k in every time step in order for equation 2 to hold?\n\n(2) What is function C and why (and how) is it useful?\n\n(3) Does section 7 only present a numerical simulation of the relevant equations?  What is its significance?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1108/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1108/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1108/Reviewer_6GuR"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1108/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698720447651,
            "cdate": 1698720447651,
            "tmdate": 1699636036997,
            "mdate": 1699636036997,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "MNAkkKngyR",
            "forum": "9tNhV5kTSc",
            "replyto": "9tNhV5kTSc",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1108/Reviewer_m2xs"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1108/Reviewer_m2xs"
            ],
            "content": {
                "summary": {
                    "value": "The paper investigated a Stackelberg game between agents and a decision-maker where agents choose the effort to improve their profile to get accepted and the agents maximize the social welfare, which is the total amount of agents' improvements. The authors consider a specific scenario where the effect of agents' action is delayed and has persistent effects. Also, they consider the dishonest behavior of the agents and a forgetting mechanism that captures the case when efforts don't transform to improvements."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper presents the idea and formulation clearly. The organization of the paper is structured in an order that facilitates easy readability and understadability.\n\n2. The study of a Stackelberg game with delayed and persistent impacts of agents' action is important. The problem has not been investigated thoroughly in the context of the specific model presented in this paper.\n\n3. The proof of the theorems and lemmas are well presented and sound."
                },
                "weaknesses": {
                    "value": "1. My major concern is whether the paper fits the scope of the conference or not. It seems to the reviewer that this paper is more suited for a economic journal/conference based on the topic, the way it is presented, and the results. I did not see any discussion in the paper that are related to learning. This is concern drives my rating for this paper.\n\n2. The model formulation is not a generic stackelberg game. The utility function, the dynamics of the model, and the action profile of the agents are defined to study a very specific game. The suggest the authors give a name to the specific game instead of calling it \"a novel two-stage Stackelberg model\". I was having an impression that the paper studies a generic stackelberg game with delayed and persistent effects when reading the introduction section. \n\n3. The contributions of the results are not significant. For example, the two takeaways from the two theorems in section 6 are 1. the dynamics under forgetting still converges, and 2. the improvement an agent can make under the forgetting mechanism is limited. The two takeaways seem intuitive give the setup of the forgetting mechanism. There are other examples in the previous sections too."
                },
                "questions": {
                    "value": "1. Have the authors considered using dynamic stackelberg game framework to study the scenario, in which agents can change their actions at each time step?\n\n2. Can the authors summarize the most interesting results at the beginning/end of the paper? In section 1, the contributions the authors listed are all about \"we formulate\", \"we study\", \"we propose\". The readers would like to see more insights that we derived from the model and how these results or insights can make an impact in the community."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1108/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699054179158,
            "cdate": 1699054179158,
            "tmdate": 1699636036939,
            "mdate": 1699636036939,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "fkZZbqUG5I",
            "forum": "9tNhV5kTSc",
            "replyto": "9tNhV5kTSc",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1108/Reviewer_gzfu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1108/Reviewer_gzfu"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers a problem where an agent has the power to improve or manipulate its feature with delayed effect. The problem is modeled as a Stackelberg game, and the paper studied the optimal strategy in several different settings such as from the agent or the designer, whether manipulation, forgetting is involved."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The model proposed by this paper is indeed novel and interesting to me.\n- The paper is overall easy to follow and the figures are helpful to understand the model and experiments.\n- The paper used real world data to showcase the use of its model."
                },
                "weaknesses": {
                    "value": "While the model is interesting and could form a reasonable game, I have a major concern about this paper. That is, it is unclear to me how the model is a good reflection of any real world problem. The assumption on the agent qualification dynamics, manipulation/forgetting, and the designer's threshold policy seem to be very strong and artificial. The experiment on real world data also does not reflect whether the modeling is realistic. Hence, I am not sure whether the results derived from this model are particularly useful or insightful for the ICLR audience."
                },
                "questions": {
                    "value": "Can you explain how realistic this model is, and how any of the results derived from this model could be useful for the ICLR community?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1108/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699416294134,
            "cdate": 1699416294134,
            "tmdate": 1699636036850,
            "mdate": 1699636036850,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]