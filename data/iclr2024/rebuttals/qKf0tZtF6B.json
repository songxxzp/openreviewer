[
    {
        "title": "Learning Dynamical Systems with Helmholtz-Hodge Decomposition and Gaussian Processes"
    },
    {
        "review": {
            "id": "tGLRRoIUDe",
            "forum": "qKf0tZtF6B",
            "replyto": "qKf0tZtF6B",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8944/Reviewer_e4ns"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8944/Reviewer_e4ns"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose to learn from dynamical data by considering the Helmholtz-Hodge decomposition and modeling separate GPs to the divergence-free and the curl-free components of the system. To enable identifiability for the resulting additive model, Euclidean symmetries are imposed to the components. The obtained experimental results are promising when compared to a neural network model and other GP-based methods."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "Learning dynamical systems is a fundamental problem that has been covered by the machine learning community from many angles. By considering the Helmholtz-Hodge decomposition and directly including symmetry constraints in the kernel function, the authors present a very interesting and relevant contribution.\n\nThe overall presentation is laid very carefully and the text is well written. The authors take their time to explain all the important concepts and related work in the main text, which greatly aids the reader. Despite tackling several concepts of dynamical systems and vector calculus, I found the manuscript to be very didactic and easy to follow.\n\nTheoretical and implementation details are presented in the the very comprehensive appendix, which also includes additional plots from the experiments."
                },
                "weaknesses": {
                    "value": "I believe it would be of interest to include at least one scenario where the number of training observations is larger to verify if the SPHHD-GP maintains its high gains compared to the baselines. I think a larger Gaussian noise could also be tested, since a standard deviation of 0.01 (0.0001 variance) seems a bit too low.\n\nThe authors consider only the RMSE and VPT metrics in the experiments. The predicted variances provided by the GP models should also be included in the evaluation, e.g., by computing the log predictive density."
                },
                "questions": {
                    "value": "It is difficult to visually differentiate the colors of the curves in Figs. 5, 6, 7. Is it possible to consider distinct line styles, similar to Fig. 2?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8944/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698440664174,
            "cdate": 1698440664174,
            "tmdate": 1699637126035,
            "mdate": 1699637126035,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "OAPeJJ4Pv4",
                "forum": "qKf0tZtF6B",
                "replyto": "tGLRRoIUDe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8944/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8944/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer e4ns"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the constructive comments. We are glad that you believe that this work can bring a valuable contribution to the community. We have carefully gone through your comments, so we have done additional experiments and revised our paper accordingly. We believe addressing these points in the manuscript would indeed make the paper better.\n\n---\n\n> **1.Comment**: I believe it would be of interest to include at least one scenario where the number of training observations is larger to verify if the SPHHD-GP maintains its high gains compared to the baselines. I think a larger Gaussian noise could also be tested, since a standard deviation of 0.01 (0.0001 variance) seems a bit too low.\n\n\n**Response**: Thanks to the reviewer for this suggestion. We agree that a more thorough validation will strengthen our paper. So we added experiments of evaluating the models performance under various noise and number of training data in the Appendix A.8.3 of the updated draft (colored by blue). Specifically, the first part of additional experiments were perfomed on a damped pendulum with increasing standard deviation (0.01, 0.05, 0.10 and 0.20) of Gaussian noise in training data. The results in Fig.8 and Table 3 shows that our model (SPHHD-GP) performs best at every noise level relative to the baseline models, meaning that our model is more robust to data noise. And the second part of experiments investigated the effect of the number of training data (20, 100, 260, 420) on the model performance. The results are shown in Fig.9 and Table 4, where we can observe that the performance of the models are closer as the training data increases, but our model still shows the best performance on any number of training data. Furthermore, an important observation from Fig.8(c) and Fig.9(c) is that both HHD-GP and D-HNN consistently generate significant errors in predicting energy evolution, and the errors are almost unaffected by the noise and quantity of training data, meaning these two models cannot learn the correct decomposition under any training data conditions. In contrast, the energy errors generated by SPHHD-GP exhibit a increasing trend with increasing noise and an decreasing trend with increasing number of training data. This observation further proves the importance and effectiveness of addressing model identifiability through symmetry constraints.\n\n---\n\n> **2.Comment**: The authors consider only the RMSE and VPT metrics in the experiments. The predicted variances provided by the GP models should also be included in the evaluation, e.g., by computing the log predictive density.\n\n**Response**: Providing uncertainty estimates about predictions is one of the unique advantages of the GP model, so we fully agree with the reviewer's suggestion to add evaluation metrics in this aspect, so we added the mean negative log likelihood (MNLL) as one of our measures when evaluating the models performance under different noise and number of training data. The definition of MNLL and the corresponding experimental results can be found in Appendix A.8.3 of the updated draft (colored by blue). The lower the MNLL, the more effectively the forecast uncertainty reflects the prediction error. As expected, MNLLs of the GP models exhibit a increasing trend with increasing noise and an decreasing trend with increasing number. An exception is Div-GP (divergence-free GP, a GP model that can only learn conservative dynamics), which produces MNLL with a different trend compared to other GP models. This is because it uses incorrect prior knowledge as an inductive bias, so the uncertainty estimates it produces cannot serve as a reference for prediction errors. And our model (SPHHD-GP) has the lowest MNLL for every noise and number of training data, meaning that the uncertainty estimates produced by our model can better reflect the prediction error.\n\n---\n\n> **3.Comment**: It is difficult to visually differentiate the colors of the curves in Figs. 5, 6, 7. Is it possible to consider distinct line styles, similar to Fig. 2?\n\n**Response**: We thank the reviewer for pointing this out. We now used distinct line styles to represent trajectories generated by different models.\n\n---\nThank you again for the constructive comments. We hope these explanations resolve the concerns. Any further questions or suggestions would be greatly appreciated."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8944/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700658396570,
                "cdate": 1700658396570,
                "tmdate": 1700658396570,
                "mdate": 1700658396570,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1kit7YAV8J",
                "forum": "qKf0tZtF6B",
                "replyto": "OAPeJJ4Pv4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8944/Reviewer_e4ns"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8944/Reviewer_e4ns"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the update"
                    },
                    "comment": {
                        "value": "I would like to thank the authors for the responses and the several updates to the manuscript. I will maintain my original rating."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8944/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700665398857,
                "cdate": 1700665398857,
                "tmdate": 1700665398857,
                "mdate": 1700665398857,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "zzJ2thzRBm",
            "forum": "qKf0tZtF6B",
            "replyto": "qKf0tZtF6B",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8944/Reviewer_oXvz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8944/Reviewer_oXvz"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a dynamical system based on the Helmholtz\u2013Hodge decomposition (HHD) and Gaussian processes (GPs). The authors demonstrate how to learn the dynamic systems in the HHD form where each component is modeled as a GP."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The authors propose to decompose the dynamical system as curl-free and divergence-free components and learn the decomposition using GPs. The formulation is interesting and has physically-meaningful interpretation.\n2. To address identifiability, the authors incorporate symmetry constraints on the HHD components, and provide theoretical characterizations of the resulting kernels.\n3. Empirical results demonstrate that the proposed method achieves improved accuracy in modeling ODEs as well as energy evolution of the systems."
                },
                "weaknesses": {
                    "value": "1. Computational complexity for the method could be prohibitive for high-dimensional problems where the partial derivatives wrt. the input need to be computed. Low-rank structures are typically used in standard dynamical systems, but it is not leveraged in the proposed approach.\n2.  As suggested by the authors, the decomposition is not unique due to the unidentifiability of the harmony component. The authors address this issue by imposing symmetry constraints; however, the uniqueness and characteristics of the resulting decomposition are not investigated.\n3. Another concern is the novelty of the approach compared to the multiple kernel learning literature. The proposed method appears to be an instance of learning a combination of two pre-defined kernels."
                },
                "questions": {
                    "value": "1. What is the computational complexity of the method in terms of the sample size and input dimension?\n2. How does the method differ from multiple kernel learning with two given kernels?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8944/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698798104082,
            "cdate": 1698798104082,
            "tmdate": 1699637125914,
            "mdate": 1699637125914,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "d3yYKMekiS",
                "forum": "qKf0tZtF6B",
                "replyto": "zzJ2thzRBm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8944/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8944/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer oXvz (Part-1 out of 2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the constructive comments and for taking the time to thoroughly read this paper. We have carefully gone through your comments and addressed each of them point-by-point. Sorry for the late response.\n\n---\n\n> **1.Comment (W1&Q1)**: Computational complexity for the method could be prohibitive for high-dimensional problems where the partial derivatives wrt. the input need to be computed. Low-rank structures are typically used in standard dynamical systems, but it is not leveraged in the proposed approach. What is the computational complexity of the method in terms of the sample size and input dimension?\n\n\n**Response**: Thanks to the reviewer for raising this concern. Computational complexity is indeed one of the main drawbacks of GPs. Define $m$ as the sample size and $n$ as the number of the input dimension, then the time complexity of our method is dominated by the Cholesky decomposition to invert the $mn \\times mn$ covariance matrix, which takes $\\left ( m n \\right )^3/6$ operations, and all other operations are at most quadratic in $m$ and $n$. So the time complexity of our model is $\\mathcal{O} \\left ( m^3 n^3 \\right )$. We understand the reviewer's concern about computational complexity, but at the expense of this computational cost, our model achieves high data efficiency and inherent regularization. We thank the reviewer for your inspiration in leveraging low-rank structures in dynamical systems to approximate the covariance matrix, and we are very intrigued about extensions of our work in reducing the computational complexity in future work. And we now discussed this limitation of computational complexity in the section of Conlusion in the updated draft (colored by blue).\n\n---\n\n> **2.Comment (W2)**:  As suggested by the authors, the decomposition is not unique due to the unidentifiability of the harmony component. The authors address this issue by imposing symmetry constraints; however, the uniqueness and characteristics of the resulting decomposition are not investigated.\n\n**Response**: \n\nWe thank the reviewer for giving us the opportunity to clarify the the uniqueness of the resulting decomposition. A unique decomposition makes our model identifiable. To show the identifiability of our model, an additional experiment on the damped pendulum system was perfomed to demonstrate the ***consistency*** of our model. Consistency is a key property of identifiable models [C1, C2]. If the model is identifiable, then the parameter estimates should converge to the true values as the amount of data increases. Therefore, we added experiments of evaluating the models performance with increasing number of training data (n=20, 100, 260, 420) in the Appendix A.8.3 of the updated draft (colored by blue). We invite the reviewer to review Fig.9(c) and Table 4, which shows that models without symmetry constraints (HHD-GP and D-HNN) consistently generate significant errors in predicting energy evolution, and the errors are almost unaffected by the number of training data, meaning that the model parameters cannot converge as the amount of data increases. In contrast, the energy errors of SPHHD-GP (Symmetry-preserving HHD-GP) exhibit a decreasing trend with increasing number of training data. The experimental results proves the consistency of our model, but since consistency is only a necessary condition for identifiability, we can only conclude that symmetry constraints improves the model identifiability, i.e. reducing the space of harmonic components. To prove that the existence of harmonic components are completely eliminated by the symmetry constraints, we added a theoretical verification that for the three dynamical systems in our experiments, the non-uniqueness of HHD has been solved through forced symmetries. We invite the reviewer to review this analysis in Appendix A.6 (colored by blue) of the updated draft.\n\nWe would like to further clarify that although we currently do not have a theoretical result to characterize the conditions for symmetry to effectively eliminate harmonic components in HHD, we have demonstrated the potential of symmetry in enhancing model identifiability, an area that has been relatively unexplored before. Current research mainly focuses on using symmetry to improve the predictive power of models. Therefore, we believe that studying the effect of symmetry on model identifiability is a very valuable future direction, which is important for model interpretability.\n\n---"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8944/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700678002915,
                "cdate": 1700678002915,
                "tmdate": 1700726782816,
                "mdate": 1700726782816,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "q8ME5Am60C",
            "forum": "qKf0tZtF6B",
            "replyto": "qKf0tZtF6B",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8944/Reviewer_JNyE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8944/Reviewer_JNyE"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a method to learning complex systems. The method has three components: using Helmholtz-Hodge decomposition on the phase plane of the dynamic systems, as influenced by Greydanus et al 2019 (Hamiltonian NN), to decompose system dynamics into curl-free and div-free components; using Gaussian Process as prior to capture those two components separately from the training data; and use Euclidean group to further enforce the symmetries of GP models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper addresses an important problem in dynamics prediction. Inspired by D-HNN (2022), the method is novel, in particular the usage of Euclidean Group to further enforce the symmetries. There is sufficient amount of empirical evidence to back up the claims. The paper contains extensive amount of theoretical work, and is written reasonably well."
                },
                "weaknesses": {
                    "value": "The experimental results section needs some more clarification, see the questions in the next sections.\n\nThe non-uniqueness of HHD is well-known. The authors use it as in section 3.3 to introduce the enforcement of the symmetries of the GP model. However it's unclear that the enforcement of the symmetries can completely eliminate the non-uniqueness of HHD. (My understanding is negative). Although the preservation of symmetries is usually a desirable property to model dynamics systems, either a theoretical guarantee or empirical validation that the non-uniqueness can be addressed or mitigated is highly desirable. \n\nReal data are never clean. The authors added noise into the training data. But my concern is that the noise magnitude is too small (0.01, only 1% of the data range. I would like to see how well the method behaves when larger magnitude of noise is added, for instance, with std. dev. of 0.01, 0.05, 0.10 and 0.20."
                },
                "questions": {
                    "value": "1. In Table 1, what are the std. dev. values collected from? My understanding is that random initial values are used in the GP model. Are the randomness of the initial values cause the derivations?\n\n2. I am trying to understand the reported RMSE and VPT in Table 1. For each system, 20 pairs of data are generated for training, where are the testing data generated? In the temporal sense, are the testing data lie in the future of the training data, or the training and testing data pairs are intermingled with respect of time?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8944/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8944/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8944/Reviewer_JNyE"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8944/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698800361391,
            "cdate": 1698800361391,
            "tmdate": 1699637125793,
            "mdate": 1699637125793,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Q4shdtyNLF",
                "forum": "qKf0tZtF6B",
                "replyto": "q8ME5Am60C",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8944/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8944/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer JNyE (Part-1 out of 2)"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for the thoughtful comments and suggestions, which have helped to improve the quality of our manuscript.\n\n---\n\n> **1. Comment**: The non-uniqueness of HHD is well-known. The authors use it as in section 3.3 to introduce the enforcement of the symmetries of the GP model. However it's unclear that the enforcement of the symmetries can completely eliminate the non-uniqueness of HHD. (My understanding is negative). Although the preservation of symmetries is usually a desirable property to model dynamics systems, either a theoretical guarantee or empirical validation that the non-uniqueness can be addressed or mitigated is highly desirable. \n\n**Response**: We thank the reviewer for giving us the opportunity to present a theoretical analysis that for the three dynamical systems in our experiments the non-uniqueness of HHD is solved through forced symmetries. The non-uniqueness of HHD is caused by the presence of harmonic components (vector fields that are both curl-free and divergence-free). To make HHD unique, we propose to imposing symmetry constraints to the space of divergence-free vector fields and the space of curl-free vector fields respectively, with the corresponding symmetry groups defined as $G_{div}$ and $G_{curl}$. So the HHD will be unique if there are no harmonic vector fields respecting the union of $G_{div}$ and $G_{curl}$. \n\nA harmonic vector field on $\\mathbb{R}^n$ can be represented by the gradient field of a harmonic function $h$, which is a scalar function satisfying $\\nabla \\cdot \\nabla h = 0$ (Laplace's equation). For the three dynamical systems used in our experiments, it can be easily verified that the existence of $h$ can be eliminated through forced symmetries. The symmetry group union of a damped mass-spring system consists of a rotation group $G_{div} = SO \\left ( 2 \\right )$ and a translation group $G_{curl} = \\left \\\\{ \\left ( g, 0 \\right ) \\mid g \\in \\mathbb{R} \\right \\\\}$. A harmonic vector field $\\mathbf{f} = \\nabla h$ that satisfies this translation symmetry implies that its harmonic function $h \\left ( q, p \\right )$ is independent of the variable $q$, so the harmonic vector field is given by $\\mathbf{f} = \\left (0, \\partial_p h \\right )$ and $\\partial_p h$ should be a constant to satisfy the Laplace\u2019s equation, but the harmonic vector field in the form of constant clearly contradicts rotation symmetry $G_{div}$. Therefore, there is no harmonic vector field that respects both the symmetry groups $G_{div}$ and $G_{curl}$. Similar conclusions can be drawn for the damped pendulum and the Chua circuit. The Laplace's equation and translation symmetry imply that harmonic vector fields can only exist in the form of constant vector fields. However, constant vector fields obviously contradict odd symmetry or mirror symmetry. We added this theoretical analysis to the Section A.6 in the appendix of the updated draft.\n\nAlthough we currently do not have a theoretical result to characterize the conditions for symmetry to effectively eliminate harmonic components in HHD, we have demonstrated the potential of symmetry in enhancing model identifiability, an area that has been relatively unexplored before. Current research mainly focuses on using symmetry to improve the predictive power of models. Therefore, we believe that studying the effect of symmetry on model identifiability is a very valuable future direction, which is important for model interpretability.\n\n---\n\n> **2. Comment**: Real data are never clean. The authors added noise into the training data. But my concern is that the noise magnitude is too small (0.01, only 1\\% of the data range. I would like to see how well the method behaves when larger magnitude of noise is added, for instance, with std. dev. of 0.01, 0.05, 0.10 and 0.20.\n\n**Response**: Thank the reviewer for this valuable suggestions. We added the experiments of evaluating the models performance with increasing standard deviation (0.01, 0.05, 0.10 and 0.20) of Gaussian noise in training data. We find that our model (SPHHD-GP) performs best at every noise level relative to the baseline models, meaning that our model is more robust to data noise. We invite the reviewer to Fig.8 and Table 3 in the updated draft to check the experimental results. In addition, according to the suggestion of Reviewer e4ns, we added the experiments of investigating the effect of the number of training data on the model performance. The results are shown in Fig.9 and Table 4, where we can observe that our model also shows the best performance on any number of training data. \n\n---"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8944/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700648181797,
                "cdate": 1700648181797,
                "tmdate": 1700726676032,
                "mdate": 1700726676032,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "MwnxOwXnnV",
            "forum": "qKf0tZtF6B",
            "replyto": "qKf0tZtF6B",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8944/Reviewer_uHv2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8944/Reviewer_uHv2"
            ],
            "content": {
                "summary": {
                    "value": "In this work, authors present a Gaussian process model that decomposes the dynamics of a dissipative system into the curl-free and divergence-free terms. Further, these terms are learned from the noisy ground truth data. The framework is claimed to have the additional advantage of being interpretable due to the separate learning of the two terms in the dynamics. Empirical studies on damped mass-spring system, damped pendulum, and Chua circuit shows superior performance over the baselines."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The main strengths of the paper are as follows.\n\nS1. Presents a GP-based framework that can inherently handle noisy data. This is in contrast to most of the works in the literature that employs neural-based approaches.\n\nS2. Decomposes the dynamics into curl-free and div-free terms. This allows learning the non-conservative and conservative components of the dynamics separately.\n\nS3. Empirically demonstrates that the presented framework is superior to the baselines on damped spring systems, damped pendulum and Chua circuit."
                },
                "weaknesses": {
                    "value": "There are several weaknesses for the paper. \n\nW1. There are several works in the literature which demonstrates how the Lagrangian, (port-)Hamiltonian, and neural ODE based NN frameworks can be used to model dissipative dynamical systems. Authors have not given any mention of such frameworks in the introduction, which provides a feeling that there is no prior work in this area. The reference comes much later when discussing the baselines. This should be clearly included in the introduction. Some relevant works are as follows.\n* Desai, S.A., Mattheakis, M., Sondak, D., Protopapas, P. and Roberts, S.J., 2021. Port-Hamiltonian neural networks for learning explicit time-dependent dynamical systems. Physical Review E, 104(3), p.034312.\n* Sosanya, A. and Greydanus, S., 2022. Dissipative hamiltonian neural networks: Learning dissipative and conservative dynamics separately. arXiv preprint arXiv:2201.10085.\n* Drgo\u0148a, J., Tuor, A., Vasisht, S. and Vrabie, D., 2022. Dissipative deep neural dynamical systems. IEEE Open Journal of Control Systems, 1, pp.100-112.\n* Gruver, N., Finzi, M., Stanton, S. and Wilson, A.G., 2022. Deconstructing the inductive biases of hamiltonian neural networks. arXiv preprint arXiv:2202.04836.\n* Bhattoo, R., Ranu, S. and Krishnan, N.A., 2023. Learning the dynamics of particle-based systems with Lagrangian graph neural networks. Machine Learning: Science and Technology, 4(1), p.015003.\n\nW2. The claim on the interpretability presented in the abstract is not substantiated later on in the empirical experiments or results. It is not clear how the framework is interpretable especially for a system with larger number of degrees of freedom. \n\nW3. The experiments performed are on very (very) simple systems such as a damped spring and damped pendulum. The community has moved forward from these experiments. Please see the experiments in the references mentioned against W1. Especially, the experiments on simple one-degree of freedom toy examples are not enough to show the applicability of the approach to any realistic problems. For this some demonstration on larger systems with more degrees of freedom (~50-100) should be conducted. Note that realistic systems can have much higher degrees of freedom.\n\nW4. Baselines are not appropriately chosen. Again, references provided in W1 should be used for baselines. Some of the baselines that can be included are graph neural ODE, Lagrangian and Hamiltonian NN with dissipative terms, Lagrangian and Hamiltonian graph NNs with the dissipative terms to name a few."
                },
                "questions": {
                    "value": "In continuation to the weaknesses, the following questions/comments need to be addressed.\n\nQ1. The evaluation metrics are important. This should be preferably included in the main manuscript and not the appendix. Moreover, why are other metrics such as energy error, momentum error etc. not included? This allows meaningful interpretation of the error in the learned dynamics. \n\nQ2. It is not clear what the authors mean by the claim that the framework is interpretable. Do they mean that the dissipative and non-dissipative terms are learned separately? This is not necessarily interpretable. There are interesting works on interpretability. For instance, see:\n* Cranmer, M., Sanchez Gonzalez, A., Battaglia, P., Xu, R., Cranmer, K., Spergel, D. and Ho, S., 2020. Discovering symbolic models from deep learning with inductive biases. Advances in Neural Information Processing Systems, 33, pp.17429-17442.\n* Cranmer, M.D., Xu, R., Battaglia, P. and Ho, S., 2019. Learning symbolic physics with graph networks. arXiv preprint arXiv:1909.05862.\n\nQ3. How does the system perform on more complex systems such as 50-mass spring systems or 5-pendulum systems. GPs are known to have issues with larger input features. Can the present approach be extended to such realistic systems?\n\nQ4. It is not clear how the input features will be employed for the present approach in a multi-degree of freedom system. Specifically, whether the approach is permutation invariant or not is not clear. That is, does the order in which the degrees of freedom are provided as the input matter or not? Authors should clarify."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8944/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699164580356,
            "cdate": 1699164580356,
            "tmdate": 1699637125676,
            "mdate": 1699637125676,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hjpcWkFyqc",
                "forum": "qKf0tZtF6B",
                "replyto": "MwnxOwXnnV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8944/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8944/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer uHv2 (Part-1 out of 3)"
                    },
                    "comment": {
                        "value": "We thank the reviewer\u2019s detailed and constructive comments. We have carefully gone through the comments and below are our responses point-by-point. Sorry for our late response.\n\n---\n\n> **1. Comment (W1)**: There are several works in the literature used to model dissipative dynamical systems, which should be clearly included in the introduction [1-5].\n\n**Response**: We thank the reviewer for the suggestion and for providing these reference methods. We now include these works in the Introduction of the updated draft (colored by blue). We illustrate the essential differences between our approach and these methods. We emphasize that our focus is on designing an additive GP model whose each component satisfies certain differential invariants (either free of divergence or of curl), rather than constructing ML models according to some physically governing equations (e.g. Hamiltonian or Lagrangian equations). Therefore, our model has a wider scope of applicability. For example, in our experiments, the methods mentioned by the reviewer are difficult to apply to the Chua circuit system, which is a 3D chaotic system that is hard to describe using Hamiltonian or Lagrangian equations.\n\n---\n\n> **2. Comment (W2 & Q2)**: The claim on the interpretability presented in the abstract is not substantiated later on in the empirical experiments or results. It is not clear what the authors mean by the claim that the framework is interpretable. Do they mean that the dissipative and non-dissipative terms are learned separately? This is not necessarily interpretable. There are interesting works on interpretability [5,6].\n\n**Response**: Thanks to the reviewer for recommending two such interesting works. Indeed, these deep symbolic regression methods are known to have high interpretability, because they can recover symbolic expressions of dynamical systems from learned models. Your comment prompt us to further clarify and demonstrate interpretability of our model. While our model cannot extract explicit analytical forms, it instead provides a unique and valuable interpretation by decomposing the underlying system into a divergence-free component and a curl-free component, which represent the distinct physical phenomena at play within the system. The current work emphasizes the connection between HHD and the generalized Hamiltonian formalism. As described in Appendix A, our model can learn a generalized Hamiltonian function for any dimensional system, as long as the correct form of HHD is learned. To demonstrate this interpretability, the experiments detailed in Section 6.2 shows that the div-free features learned by the model with symmetry constraints (SPHHD-GP) can be used to accurately predict the energy evolution of dynamical systems. In contrast, models without symmetry constraints (HHD-GP and D-HNN) cannot learn the correct HHD decomposition due to model identifiability issues, so the features they learn are not physically interpretable. To further show the interpretability of our model, we add experiments of generalizing the learned models to predict dynamics with unseen friction coefficients, which demonstrate the interpretability of learned curl-free features. We invite the reviewer to view the experimental results in the Appendix A.8.4 (colored by blue) of the updated draft. We state that the interpretability of our model is guaranteed by the identifiability of the model achieved by symmetry constraints. Therefore, in addition to these experimental results, we have now added theoretical verification (Appendix A.6 in the updated draft) for the three demonstration examples that the non-identifiability of our model (i.e. non-uniqueness of the HHD) is solved through forced symmetries."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8944/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700649341590,
                "cdate": 1700649341590,
                "tmdate": 1700649341590,
                "mdate": 1700649341590,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "gcDIfC8smg",
            "forum": "qKf0tZtF6B",
            "replyto": "qKf0tZtF6B",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8944/Reviewer_Vrr3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8944/Reviewer_Vrr3"
            ],
            "content": {
                "summary": {
                    "value": "This manuscript proposes a Gaussian process regression model that incorporates the Helmholtz-Hodge decomposition and a method for eliminating indeterminacy by incorporating knowledge of symmetry into it as a constraint on the model. Compared to the baseline models, the proposed method has not only improved the predictive performance but also allows for the construction of interpretable models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The strength of this manuscript lies in the fact that the interpretability of the nonparametric model, Gaussian process regression, was ensured by basing it on the Helmholtz Hodge decomposition, and that compensation was made for the identifiability of the estimated model in order to achieve a physical valid interpretation."
                },
                "weaknesses": {
                    "value": "A weakness of this manuscript is the lack of discussion of interpretability in the demonstration experiments, despite the authors' claim that the proposed method has a high interpretability.\nIn addition, when the proposed method is applied to complex phenomena that often require interpretation, the symmetries of the system are often considered to be unknown, and in this case, it is considered to be difficult to achieve identifiability by the proposed method.\nThis point is also considered to pose difficulties in terms of improving the prediction performance by the proposed method."
                },
                "questions": {
                    "value": "It would be better to add a demonstration for more complex systems with larger degrees of freedom.\nIt would be better to describe the concept of applying the proposed method to cases where the symmetry of the system is unknown."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8944/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699499471911,
            "cdate": 1699499471911,
            "tmdate": 1699637125573,
            "mdate": 1699637125573,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "B6pOH3xCBq",
                "forum": "qKf0tZtF6B",
                "replyto": "gcDIfC8smg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8944/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8944/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Vrr3"
                    },
                    "comment": {
                        "value": "We are very grateful for your valuable comments and acknowledging our main contributions. We greatly appreciate the time and effort you put into reviewing our paper. Below are our responses to your concerns and the changes we have made to address them.\n\n---\n\n> **1. Comment**: A weakness of this manuscript is the lack of discussion of interpretability in the demonstration experiments, despite the authors' claim that the proposed method has a high interpretability. \n\n**Response**: We thank the reviewer for the opportunity to further clarify and demonstrate the interpretability of our model. We stated that our model is an interpretable way to learn a dynamical system because it allows one to learn the curl-free and div-free dynamics of a system separately, which are the two most ubiquitous differential invariants of vector fields in nature and are always physically meaningful. Therefore, our model can not only recover the dynamics of the full system, but also learn physically interpretable features that can provide new insights into the dynamical system. This interpretability is guaranteed by the identifiability of the model through symmetry constraints. To demonstrate this interpretability, the experiments detailed in Section 6.2 shows that the div-free features learned by the model with symmetry constraints (SPHHD-GP) can be used to accurately predict the energy evolution of dynamical systems. In contrast, models without symmetry constraints (HHD-GP and D-HNN) cannot learn the correct HHD decomposition due to model identifiability issues, so the features they learn are not physically interpretable. To further show the interpretability of our model, we add experiments of generalizing the learned models to predict dynamics with unseen friction coefficients, which demonstrate the interpretability of learned curl-free features. We invite the reviewer to view the experimental results in the Appendix A.8.4 (colored by blue) of the updated draft. We state that the interpretability of our model is guaranteed by the identifiability of the model achieved by symmetry constraints. Therefore, in addition to these experimental results, we have now added theoretical verification (Appendix A.6 in the updated draft) for the three demonstration examples that the non-identifiability of our model (i.e. non-uniqueness of the HHD) is solved through forced symmetries.\n\n---\n\n> **2. Comment**: When the proposed method is applied to complex phenomena that often require interpretation, the symmetries of the system are often considered to be unknown, and in this case, it is considered to be difficult to achieve identifiability by the proposed method. This point is also considered to pose difficulties in terms of improving the prediction performance by the proposed method. It would be better to add a demonstration for more complex systems with larger degrees of freedom and describe the concept of applying the proposed method to cases where the symmetry of the system is unknown.\n\n**Response**: Comparative experiments between HHD-GP and SPHHD-GP (Symmetry-preserving HHD-GP) show that the interpretability of our model is difficult to guarantee when the symmetry is unknown. We understand the reviewer's concern about the availability of symmetry. Although physical systems always adhere to symmetries, the symmetries of many complex phenomena are often considered to be partially known or unknown. Considering the importance and ubiquitous of symmetry, there are a few recent works addressing this issue by learning hidden symmetries of unknown systems from data [A1, A2, A3]. This is an interesting direction but goes in a different direction from our main point, which is in finding ways to incorporate symmetries we already have into div-free and curl-free GPs and in demonstrating that symmetries are effective in improving the predictability and interpretability of GPs. Now that our model has been demonstrated to perform well when system symmetry is available, we look forward to enhancing our model with the capabilities of automatedly learning symmetries for the model in future work. \n\n---\n\nThank you again for the constructive comments. We hope these explanations resolve the concerns. Any further questions or suggestions would be greatly appreciated.\n\n## References\n\n[A1] Liu, Ziming, et al. *Machine learning hidden symmetries*. Physical Review Letters 128.18 (2022): 180201.\n\n[A2] Desai, Krish, et al. *Symmetry discovery with deep learning*. Physical Review D 105.9 (2022): 096031.\n\n[A3] Forestano, Roy T., et al. *Deep learning symmetries and their Lie groups, algebras, and subalgebras from first principles*. Machine Learning: Science and Technology (2023)."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8944/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700645228761,
                "cdate": 1700645228761,
                "tmdate": 1700645228761,
                "mdate": 1700645228761,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]