[
    {
        "title": "Constrained Bayesian Optimization with Adaptive Active Learning of Unknown Constraints"
    },
    {
        "review": {
            "id": "LHfJYusV8b",
            "forum": "WKALcMvCdm",
            "replyto": "WKALcMvCdm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5950/Reviewer_E2Xp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5950/Reviewer_E2Xp"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposed a novel approach for combining active learning of unknown constraints with Bayesian optimization (CBO). The active learning criterion identifies regions of interest (ROI) based on confidence bounds on the output of the constraint function, and subsequently performs BO (UCB specifically) within the ROI. Theoretical analysis of the proposed algorithm is presented. Lastly, CBO is compared to other relevant algorithms, showing favorable results on synthetic and realistic tasks."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- __The methods section__ is clearly presented piece by piece, which makes it simple to digest.\n- __Related works__ appear thorough, and cover relevant works from both the constrained BO and active learning litterature.\n- __Results__ span from highly synthetic (aimed at showing traits of the algorithm rather than pure performance) to more realistic tasks."
                },
                "weaknesses": {
                    "value": "To summarize, I believe this paper has substantial flaws both in terms of the novelty of the method, the theoretical analysis, and overall presentation. Unfortunately, this results in a paper that is far from publishable in its current state. Specifically:\n\n- __The active learning component__ (the difference between the confidence bounds) is oddly presented and is not novel. The authors recognize this, but fail to recognize that the active learning method harks back to at least MacKay (1992) and has been widely applied since. Global variance reduction should not, in my opinion, be presented as a novel aspect of any algorithm. Moreover, it should be presented as Global variance reduction, or ALM (Active Learning MacKay), or otherwise, but _not_ as a difference between confidence bounds. This simply disguises the method as something seemingly more complex than it is. \n\n- __Theoretical analysis__ contains substantial flaws, starting with Assumption 3:\n\n  ___Assumption 3__ Given a proper choice of $\\beta_t$ that is non-increasing, the confidence interval shrinks monotonically. (...)_.\nThis is flawed for two reasons:\n\n  1. It appears trivial (beta is non-increasing, so the confidence interval will naturally be smaller as beta shrinks). _If there is a nuance to this assumption that I am missing, I encourage the authors to enlighten me._\n  2. Assuming a non-increasing $\\beta_t$ goes against a decade of BO convention, set by Srinivas et. al. (2009) that beta should scale as $\\mathcal{O}(\\log t)$.\nMoreover, the subsequent Lemma 1 and Theorem have numerous un-introduced quantities ($K, \\pi_t$, and appears to run contrary to Assumption 3. In Theorem 1,\n\n $\\beta_t =2 \\log( 2K+1)|D_{X_t}|$ \nwhere $D_{X_t}$ should be increasing in the data, making $\\beta_t$ increase over time - thus not non-increasing. Admittedly, $D_{X_t}$ is the _intersection_ between a discretization of the search space and the data, which clearly contains only the data, at most. The non-increasing property of $\\beta$ is re-stated in the Appendix, suggesting it is not a mistake.\n\nThe theoretical results are difficult to properly assess due to these apparent issues and ambiguities, so I will refrain from commenting on the correctness of the proofs in the appendix until these issues are clarified. \n\n- __The algorithm__ _\"Maximize the acquisition values from different aspects:\"_ is informal, and line 11 is not well-defined. What does the $\\text{argmax}$ over $\\mathcal{G}$ (but not $x$) mean? Moreover, $x_{g, t}$ in line 12 has not been obtained from any prior step. Should the $g_t$ in line 11 really be $x_{g,t }$? As such, it is still not clear to me what the resulting acquisition function is, (but I believe it is the $\\text{argmax}_{g, x}$ over all constraint and BO acquisitions, jointly.\n\n- __The figures__ are difficult to parse due to the odd color choices (bright grey and dark orange on orange in Fig. 1, tiny legends everywhere).\n\n- __Competing methods__ do not seem to be properly implemented. SCBO (Eriksson and Poloczek, 2019) builds on TuRBO, one of the more robust BO methods around. Seeing it fail on most tasks is a warning sign, and suggests to me that there are implementation flaws. If the authors believe it has been correctly implemented and used, I would suggest they motivate its poor performance in their specific setting.\n\n__Minor__: \n- Enumeration of contributions is generally a nice-to-have, and adds clarity.\n- Hyperlinks are missing completely. Consider adding these.\n- I would argue that the CBO acronym is occupied by Gardner et. al. (2014). While I don't believe there is a rule governing acronyms, I would strongly suggest for the authors to change it.\n \n\n__Additional References__:\n\nDavid MacKay. Information-based objective functions for active data selection. _Neural Computation_, 1992."
                },
                "questions": {
                    "value": "In addition to the weaknesses (which certainly poses a few questions), I am curious about the following:\n\n- The constraint functions $g$ are assumed to be continous-valued. Is this conventional, and is the method ammenable to non- continous (i.e. binary output) constraints?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None."
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5950/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5950/Reviewer_E2Xp",
                        "ICLR.cc/2024/Conference/Submission5950/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5950/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698505227044,
            "cdate": 1698505227044,
            "tmdate": 1700055987029,
            "mdate": 1700055987029,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VOAjn7zTXA",
                "forum": "WKALcMvCdm",
                "replyto": "LHfJYusV8b",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response by Authors (1/3)"
                    },
                    "comment": {
                        "value": "We sincerely appreciate the detailed comments by the reviewer and would like to respond in the following.\n\n***Weakness***\n\n```\nThe active learning component is oddly presented and is not novel.\n\n```\nWe sincerely appreciate the reference pointed out by the reviewer, where the active data selection on the region of interest is thoroughly discussed. We acknowledge the similarities between our approach and the global variance reduction methods or ALM, as well as their roots in previous work. In the revision, we will clarify this connection and refrain from describing the active learning aspect of COBALT as entirely novel. However, we would like to highlight the difference between the active learning methods referred by the reviewer and the proposed algorithm for constrained BO tasks. \n\nWe aim to propose a principled tradeoff of **active learning of multiple unknown constraints and the optimization of the objective in the feasible region**. To achieve this, we choose to unify the two different aspects---namely variance reduction and UCB, by framing them under the same mathematical framework as elaborated in Eq (5) and Eq (6). This framing ensures the comparability of the acquisition function of the unknown objective and the acquisition function of the unknown constraints. Further, it serves as the foundation for defining our acquisition function tailored to both needs. The other reason we use the interval between UCB and LCB is to follow the convention in previous works (AL-LSE[5] and BALLET[6]).\n\nAnother significant difference between the proposed method and the global variance reduction is that we are doing **combined variance reduction** on adaptively identified **intersected ROI**, which leverages the UCB or LCB as the threshold.  The **shrinkage of the intersected ROI** guarantees the exploitation perspective of the acquisition and avoids budget waste, as discussed with reviewer AopU. The **variance reduction on ROI (as in eq (6)) and standardized GP-UCB** on ROI (as in eq (6)) achieve the exploration for both active learning and optimization. With the combination of ROI intersection and variance reduction on both the objective and the constraints, the proposed method achieves an **efficient and principled tradeoff** between exploration and exploitation. This serves the purpose of constrained BO and resonates with the well-known tradeoff in conventional BO. \n\nAs pointed out by other reviewers, given the **specific constrained BO reward** discussed in this paper, this is the **first theoretical result of the convergence of the constrained BO** algorithm we are aware of.\n\n```\nTheoretical analysis constraints substantial flaws: assumption 3 seems trivial.\n```\nWe\u2019d like to point out that there is a subtle difference between a monotonically shrinking $2\\beta_t^{1/2}(x)\\sigma_{t-1}(x)$ and the consistency of confidence interval at different iterations, as discussed in assumption 3. The former is trivial given the monotonicity of $\\\\sigma_{t-1}(x)$, while the latter could possibly be violated even when $\\beta_t$ is non-increasing. For example, if the observed $y_t$ actually lies on the confidence interval, the resulting posterior confidence interval at $x_t$ could disagree with the confidence interval of the prior. Assumption 3 actually assumes a consistency of prior and posterior confidence intervals, and it helps with the analysis by guaranteeing a consistently shrinking ROI.\n\nIf we only resort to the monotonicity of the pointwise $ \\sigma_{t-1}(x)$ when having a constant $\\beta$ for $\\forall 1 \\geq t \\geq T$ where T is the known total budget, we could revise the $\\beta$ to be dependent only on $\\tilde{D}$ rather than  $\\tilde{D}_{\\hat{X}_t}$. In that case, the theoretical results still hold. We refer to the detailed discussion in Appendix A of the revised paper.\n\n```\nNon-increasing beta_t\n```\n\nWe appreciate the detailed question here. The reason $\\beta_t=2\\log(2(K+1)\\vert \\tilde{D}\\vert \\pi_t/ \\delta)$ needs to grow is the need to guarantee the convergence of the series, which allows an asymptotical sublinear regret. Specifically, the requirement is $\\sum_t{\\pi_t} = 1$. Yet, in our problem setup, since cumulative regret could not be bounded as instantaneous regret could be infinite when the evaluated candidate $x_t$ violates any of the constraints (cf. Equation (3)), we aim to guarantee that after a certain horizon T, the *simple regret* could be bounded. Therefore, there is no need to have a convergence series $\\sum_t{\\pi_t} = 1$. As shown in the proof, we only need $\\sum_{t=1}^T{\\pi_t} = 1$ for a given budget/horizon T, and setting $\\pi_t = 1/T$ satisfies it. We made revisions in the analysis section and the proof part to highlight this."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700472665065,
                "cdate": 1700472665065,
                "tmdate": 1700472665065,
                "mdate": 1700472665065,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "q9Am9wAkl0",
                "forum": "WKALcMvCdm",
                "replyto": "VOAjn7zTXA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5950/Reviewer_E2Xp"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5950/Reviewer_E2Xp"
                ],
                "content": {
                    "title": {
                        "value": "Follow-up"
                    },
                    "comment": {
                        "value": "__The active learning component is oddly presented and is not novel.__\n\n_We acknowledge the similarities between our approach and the global variance reduction methods or ALM, as well as their roots in previous work._\n\nI am not saying that there are similarities - I am saying that ALM/global variance reduction is clearly _equivalent_ to the proposed method (this is also shown in the paper's appendix). As such, I do not think the statement by the authors is fair. \n\nIn the paper (Paragraph _Acquisition function for learning the constraints_) it is still not acknowledged that an ALM-equvialent strategy is used, despite it being proven in the appendix. This, to me, is the biggest issue with the paper, as I do not think it properly acknowledges previous work within the field. To this end, I think the formulation (i.e. as the difference between confidence bounds) disguises the fact that the method _already exists_. The two work cited for convention is published within the last year (and does not cite McKay, either) and the other does not seem to _evaluate the difference between bounds_ as the acquisition function. As such, I would not call this the convention.\n\nAs I have several concerns regarding the theory of the paper, I will refrain from commenting further here.\n\n__Theoretical analysis constraints substantial flaws: assumption 3 seems trivial.__\n\nI do not see consistency mentioned in relation to that Assumption. Can the authors clarify further?\n\n__Non-increasing beta_t__\n\nLooking at the paper, it is still difficult to assess if $\\beta_t$ is increasing or decreasing. Lemma 1 has  $\\beta_t$ be a function of $\\pi_t$  and Theorem 1 has  $\\beta_t$ not be a function of $t$ at all, but of $T$."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700580670242,
                "cdate": 1700580670242,
                "tmdate": 1700580670242,
                "mdate": 1700580670242,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "d9U3A5AiCJ",
                "forum": "WKALcMvCdm",
                "replyto": "q9Am9wAkl0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5950/Reviewer_E2Xp"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5950/Reviewer_E2Xp"
                ],
                "content": {
                    "title": {
                        "value": "Follow-up, p2"
                    },
                    "comment": {
                        "value": "__The algorithm \"Maximize the acquisition values from different aspects:\" is informal, and line 11 is not well-defined.__ \n\nI would still encourage the authors to be more precise. _Maximize the acquisition values from different aspects_ is not precise enough to include in an algorithm, as the uninformed reader cannot devise what the algorithm does. Moreover, I think the authors need to expand on this specific line in the text.\n\nLastly, my question regarding the intersection between the data and the discretization has yet to be addressed."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700581312250,
                "cdate": 1700581312250,
                "tmdate": 1700581312250,
                "mdate": 1700581312250,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "k55yy7ZYvx",
                "forum": "WKALcMvCdm",
                "replyto": "LHfJYusV8b",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response by Authors"
                    },
                    "comment": {
                        "value": "Thank you for the swift response! We\u2019d like to clarify the novelty further and answer the remaining question by the reviewer.\n```\nI am saying that ALM/global variance reduction is clearly equivalent to the proposed method. \n```\nThank you for your constructive comments! We want to add the following clarification.\n\nWe agree with the reviewer that the variance maximization defined in equation (6) exactly matches the discussion about maximum information gain in the ALM paper.  In fact, equation (6) itself is an AL-LSE [1] acquisition function, and equation (5) is a slightly modified UCB acquisition function. And we don\u2019t intend to claim novelty on either the UCB or the variance reduction part. Please note that in the previous revision, we admitted the root of the active learning part in ALM in paragraph 3 of section 2. **We additionally clearly stated this inheritance in the latest revision in section 4.3.** However, the domain the acquisition function is maximized on is adaptively identified in a way that is not the same as the ALM discussion.\n\nWe still want to reiterate our contribution here. The adaptive tradeoff of AL-LSE and GP-UCB to achieve an efficient constrained BO method that comes with theoretical justification on its convergence rate, given the specific reward form we discussed in equation (3), is non-trivial. As far as we are aware, the ALM paper and recent advances in CBO do not offer efficient, principled adaptive trade-offs between multiple acquisitions through the ROI intersection and acquisition function combination, as proposed in our work. We are not aware of the existing convergence guarantee to the reward corresponding to equation (3). Therefore, the proposed intersected ROI ($\\hat{X}_t$ as defined in equation (4))-based method on top of the ALM differentiates it from the original ALM method, though the ALM paper uses ROI for different notions.\n\nIn addition, please note the acquisition function for AL-LSE[1] is defined as the intersection of confidence intervals: $\\vert\\cap_{i=1}^t Q_i \\vert = \\vert \\max_{i=1,..,t} LCB_i, \\min_{i=1,...,t}UCB_i\\vert$ and is maximized on an adaptively identified set.\n\n```\nI do not see consistency mentioned in relation to that Assumption. Can the authors clarify further?\n```\n\nSure! The notion of consistency is stated in assumption 3, $UCB_{t_1}(x) \\geq UCB_{t_2}(x)$ and $LCB_{t_1}(x) \\leq LCB_{t_2}(x)$. While the monotonical shrinking that naturally holds due to the monotonicity of $\\sigma_t$ only guarantees that $UCB_{t_2}(x)-LCB_{t_2}(x) \\leq UCB_{t_1}(x)-LCB_{t_1}(x)$, when $t_1 \\leq t_2$. We wanted to highlight that the consistency doesn\u2019t naturally hold, in contrast to the shrinkage of the pointwise confidence interval.\n\n\n```\nLooking at the paper, it is still difficult to assess if $\\beta_t$ is increasing or decreasing. Lemma 1 has $\\beta_t$ be a function of $\\pi_t$, and Theorem 1 has $\\beta_t$ not be a function of $t$ at all, but of $T$.\n```\n\nPlease note that in addition to the previous clarification where we justify that, in $\\beta_t = 2log(2(K+1)\\vert \\tilde{D} \\vert \\pi_t / \\delta)$ could be non-increasing as long as we don\u2019t want a convergent series $\\sum_t\\pi_t^{-1} = 1$ but instead we only need $\\sum_{t=1}^T\\pi_t ^{-1}= 1$, we set $\\pi_t = T$ as $T$ is the preset constant horizon meeting requirement in theorem 1. Then $\\beta=2log(\\frac{2(K+1)\\vert \\tilde{D} \\vert T}{  \\delta})$. Here the number of constraints $K$, the size of the discretization $\\vert \\tilde{D} \\vert$, the horizon $T$, and $\\delta$ are all given numbers. Then, $\\beta$ is a constant.\n\n\n```\nI would still encourage the authors to be more precise. Maximizing the acquisition values from different aspects is not precise enough to include in an algorithm, as the uninformed reader cannot devise what the algorithm does. Moreover, I think the authors need to expand on this specific line in the text.\n```\nWe sincerely appreciate these constructive comments. We added additional discussion to clarify it in the revision.\n\n```\nLastly, my question regarding the intersection between the data and the discretization has yet to be addressed.\n```\nWe apologize for missing it in the previous response. In fact, we believe $\\tilde{D}$ as defined in Lemma 1 is a preset discretization in contrast to the $D_t$, which is the growing collection of historical observations. And $\\hat{X}_t$ is the subset of the search space $\\mathbf{X}$. Therefore, we do not intend to describe $\\tilde{D}\\_{\\hat{X}_t}$ as the intersection of discretization and data but the discretization of the subset of search space. And as described in the previous response, we make $\\beta=2log(\\frac{2(K+1)\\vert \\tilde{D} \\vert}{ T \\delta})$ instead of relying on $\\tilde{D}\\_{\\hat{X}_t}$ now.\n\n***reference***\n\n[1] Gotovos, Alkis. \"Active learning for level set estimation.\" Master's thesis, Eidgen\u00f6ssische Technische Hochschule Z\u00fcrich, Department of Computer Science,, 2013."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700667151083,
                "cdate": 1700667151083,
                "tmdate": 1700727656033,
                "mdate": 1700727656033,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "k0dIImkwk6",
            "forum": "WKALcMvCdm",
            "replyto": "WKALcMvCdm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5950/Reviewer_AopU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5950/Reviewer_AopU"
            ],
            "content": {
                "summary": {
                    "value": "This study presents a solution to the constrained Bayesian optimization problem with theoretical analysis. The method involves defining high-confidence regions of interest (ROIs) for both the objective and constraints. Following this, an acquisition function is constructed to simultaneously optimize the objective and identify feasible regions. The effectiveness of the proposed algorithm is showcased through numerous experiments."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "It is uncommon to find a paper on constrained Bayesian Optimization that includes theoretical analysis. This paper explores both coupled and decoupled settings, with the decoupled setting detailed in the appendix."
                },
                "weaknesses": {
                    "value": "Unfortunately, the paper lacks clarity and precision, with several confusing and potentially erroneous arguments.\n\n1. The high-level approach is inefficient for the following reasons:\n\n   a. $x_t$ can be picked as $x\\_{\\\\mathcal{C}\\_k,t} = \\\\text{arg}\\\\!\\\\max\\_{x \\\\in U\\_{\\\\mathcal{C}\\_k,t}} \\\\alpha\\_{\\\\mathcal{C}\\_k,t}(x)$, so it may belong to $L_{\\mathcal{C}_{k'},t}$ for some $k' \\neq k$. In this case, it raises the question of why the objective and constraints are evaluated at an infeasible input.\n\n   b. In equation (5), when $\\text{LCB}_{f,t,\\max} = \\infty$, we basically pick the most uncertain $f(x)$. However, there may existing uncertain $f(x)$ with a very low evaluation. Then, why do we need to pick this input if we are interested in large $f(x)$? \n\n2. Here are some arguments that might be incorrect:\n\n   a. The paper asserts that existing constrained Bayesian optimization lacks theoretical analysis. However, the work titled \"No-Regret Bayesian Optimization with Unknown Equality and Inequality Constraints using Exact Penalty Functions\" by Lu and Paulson (2022) provides theoretical analysis.\n\n   b. The value of $\\beta_t$ is defined based on $\\hat{X}_t$ but $\\hat{X}_t$ is defined based on $\\beta_t$. Therefore, $\\beta_t$ cannot be defined in Theorem 1. \n\n   c. In the proof of Theorem 1 (proof of Lemma A.1): Lemma 5.4 of Srinivas et al. (2009) is not applied correctly. Lemma 5.4 is intended for *points selected* in Srinivas et al. (2009). However, in this paper, it is applied to the sequence of $x_{g,t}$ for all $g \\in \\mathcal{G}$ and $t$. It is important to note that not all $x_{g,t}$ are *selected points*: At each iteration only 1 input $x_{g,t}$ of a function $g \\in \\mathcal{G}$ is picked as the candidate to evaluate.\n   \n3. There are several unclear points: \n\n   a. The paper may need more arguments to explain why the approach of Takeno et al. (2022) \"violates the theoretical soundness\".\n\n   b. Theorem 1 does not address feasibility. Furthermore, Srinivas et al. (2009) analyze the regret of *some input* (for example $x_t$). While this paper introduces a definition of regret (or reward) of inputs, it does not use this definition in the theoretical analysis. This raises questions about the significance of Theorem 1 in terms of the algorithm's achieved reward (or regret).\n\n   c. The abstract highlights a setting where \"the objective and constraints can be independently evaluated\", yet the paper primarily focuses on the coupled setting where they are evaluated together. The decoupled setting is briefly explained in the appendix without any supporting experiments.\n\n   d. The paper introduces $\\epsilon_C$ for theoretical analysis but does not utilize it in the algorithm. If the algorithm is used with $\\epsilon_C = 0$, the theoretical analysis loses its significance as $T \\ge \\infty$.\n\n   e. The abstract mentions a discussion on \"the fundamental challenge of deriving practical regret bounds for CBO algorithms\", but this discussion cannot be located in the paper.\"\n\n\n4. There are other issues such as\n\n   a. The chosen performance metric is simple regret. However, in practical applications, identifying the input with minimum regret is unknown. Thus, the paper does not address what input Bayesian Optimization recommends as the optimal solution.\n\n   b. The experiment section is quite short. Surprisingly, in the Rastrigin-1D-1C, the discrete search space consists of $1000$ points but the proposed algorithm reaches the optimum with $2000$ iterations. Furthermore the noise is small $\\mathcal{N}(0,0.1)$ compared to the function range $[-40,0]$. This efficiency is questionable.\n\n   c. Assumption 2 does not hold for equality constraints.\n\n5. There are some typos in the paper:\n\n   a. In equation (5), $\\infty$ should be replaced with $-\\infty$.\n\n   b. Before equation (1), GP\\supscript(()\n\n   c. In the appendix, there are several typos: thoeretical, defination, Cauchy-Schwar.\n\n   d. Both $\\epsilon_k$ and $\\epsilon_C$ refer to the same thing.\n   \n   e. The label of the proposed algorithm in Figures 3 and 4 should be COBALT instead of CBO.\n\n   f. It's worth noting that the name COBALT coincides with an existing Bayesian Optimization work titled 'COBALT: COnstrained Bayesian optimizAtion of computationaLly expensive grey-box models exploiting derivaTive information' by Paulson and Lu (2021)."
                },
                "questions": {
                    "value": "Please answer to the aforementioned weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5950/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698636474122,
            "cdate": 1698636474122,
            "tmdate": 1699636634457,
            "mdate": 1699636634457,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JZqyH8gvsE",
                "forum": "WKALcMvCdm",
                "replyto": "k0dIImkwk6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response by Authors (1/2)"
                    },
                    "comment": {
                        "value": "We appreciate the detailed and constructive comments by the reviewer. We\u2019d love to clarify the following.\n\n***Weakness***\n\n***1. The high-level approach is inefficient for the following reasons:***\n\n```\na. Querying $L_{C_{k\u2019}}$ for some $k\u2019 \\neq k$.\n```\n\nYes, this motivates the design of the intersection of ROIs and different ROIs for objectives and constraints. We want to avoid inefficient queries. This is a very good point. Actually, the reviewer might refer to the code we provided (src/opt/constrained.py line 523-524); we are actually intersecting $U_{C_k,t}$ with $\\hat{X_t} $ instead of maximizing on the full $U_{C_k,t}$ on line 7 in algorithm 1. This is actually a typo, and we apologize for the confusion. Also, please note that in the proof of theorem 1, we\u2019ve been using the correct domain.\n\n```\nb. In equation (5), pick the most uncertain f(x).\n```\n\nPlease note that we are picking the most uncertain $f(x)$ on ROI, where the $UCB_{f} (x)$ is guaranteed to be above a certain threshold. Intuitively, we are narrowing the confidence interval of $f(x^*)$. This serves as an efficient global optimization acquisition as the uncertainty maximization guarantees the exploration while the ROI shrinking guarantees the exploitation. When $LCB_{f,t,max}$ is infinity, it means there is no super level-set identified, and taking the maximum of UCB could be optimizing the objective function out of the feasible region, which doesn\u2019t always contribute to the performance.\n\n\n***2. The arguments that might be incorrect.***\n\n```\na. With respect to the claim that Constrained Bayesian optimization lacks theoretical analysis, the work by Lu and Paulson provides theoretical analysis.\n```\n\nWe\u2019re grateful for the reference provided by the reviewer and would like to add additional discussion to the related work.  We would like to highlight that regret is different, and we provide theoretical justification in the task following the constrained BO problem setup where the infeasible candidate doesn\u2019t incur a reward. \n\n```\nb. $\\beta_t$ cannot be defined in theorem 1. \n```\nWe appreciate the reviewer pointing out the typo here. Actually, the reason we introduce assumption is to guarantee a monotonically shrinking $\\hat{X_t}$, meaning we could use $\\hat{X}\\_{t-1}$ as the conservative surrogate for $\\hat{X_{t}}$. In the revision, we will avoid confusion by using $\\tilde{D}$ instead.\n\n```\nc. In the proof of theorem 1 (proof Lemma A.1), Lemma 5.4 of Srinivas is not applied correctly applied.\n```\nWe appreciate the reviewer pointing out the typo here. We correct the proof in the revision by replacing $x_{g,t}$ with $x_t$. Please note that the ultimate acquisition function is defined as the maximum of the multiple acquisition functions. Roughly speaking, though only one of the $x_{g, t}$  is picked as $x_t$, the upper bound holds for the other points that have not been picked, as is shown in the revised proof in section A.2.\n\n***3. There are several unclear points.***\n```\nThe paper may need more arguments to explain why the approach of Takeno et al. (2022) \"violates the theoretical soundness.\"\n```\nWe acknowledge that the criticism could be overstated. Yet, as admitted in Takeno et al. (2022), there is no regret guarantee for the entropy-based method. It proves that the link to the UCB method in previous work could be an error. \n\n```\nb. Theorem 1 does not address the feasibility. Furthermore, Srinivas et al. (2009) analyze the regret of some input. While this paper introduces a definition of regret (or reward) of inputs, it does not use this definition in the theoretical analysis. This raises questions about the significance of Theorem 1 in terms of the algorithm's achieved reward (or regret).\n```\n(1) In assumption 2, we assume the feasibility. Theorem 1 shows that if there are feasible points, we can identify them after sufficient query with a certain confidence. Otherwise, the empty super level-set would suggest that with a certain confidence, assumption 2 is violated. That is, there is no feasible area.\n\n(2) With regards to actual reward, if the identified Superlevel set is non-empty, the acquisition function $acq_{f,t}$ on that would actually be $UCB_f(x)$, which shares the regret guarantee with Srinivas et al. (2009). If the user wants to guarantee a query on the argmax of $UCB_f(x)$, the user can enforce that at any time or afterward. Otherwise, the algorithm is likely to query at least the argmax of $UCB_f(x)$ once within a large interval. We also add an additional corollary of theorem 1 in the revision to show the guarantee of a simple regret."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700471322380,
                "cdate": 1700471322380,
                "tmdate": 1700555180126,
                "mdate": 1700555180126,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cqUHXmEJLm",
                "forum": "WKALcMvCdm",
                "replyto": "8rIHYM66XJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5950/Reviewer_AopU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5950/Reviewer_AopU"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for Your Reply and Clarification Needed on Certain Aspects"
                    },
                    "comment": {
                        "value": "Thank you for the response, which gives me a clearer understanding of 1a, 1b, 2a, 3a, 4b, 4c. However, I am still facing difficulties in understanding some aspects of the responses. Furthermore, a review of the notations in the paper may be necessary to ensure consistency (this notation revision is for future revision following the rebuttal, not an immediate request).\n\n(2b) Could the authors provide a concise explanation for the need to ensure a monotonically shrinking $\\hat{X}_t$ and elaborate on how defining $\\beta_t$ using $\\tilde{D}$ still ensures this property.\n\n(2c) My understanding of the application of Lemma 5.4 remains unclear. Suppose $x_{g,t}$ is not selected as $x_t$ for iterations from 1 to 5 for a function $g$; how can we demonstrate that $\\sum_{t=1}^5 (2 \\beta^{1/2} \\sigma_{g,t-1}(x_t))^2 \\le C_1 \\beta \\gamma_{g,5}$?\n\n(3b) I kind of understand (1) but I find (2) difficult to understand. Why \"if the superlevel set is non-empty, ..., which shares the regret guarantee with Srinivas et al. (2009)\"? Could you clarify what is meant by the superlevel set in this context? If it is either a strict superset or a strict subset of the feasible region, then could you provide the reasons why the regret is comparable with Srinivas et al. (2009) where the feasible region is X?\n\n(4a) Is the authors referring to Corollary 2 in the Appendix? This section lacks clarity, as it appears that $R_T$ is defined as $f^* - f(x_T)$ in this proof, which is not the same as the simple regret defined at the end of section 3. The use of both $t$ and $T$ in the same term within this proof seems to be typos and causes confusions.\n\nConcerning item 3c, leaving the comprehensive study of decoupled settings for future research could potentially lessen the impact of the paper. This is due to the fact that Lu and Paulson have previously conducted theoretical work on CBO, specifically addressing equality constraints which is not addressed in this paper.\n\nIn the proof of Theorem 2, where does $g$ come from? This proof needs to be proofread and elaborated carefully.\n\n\nMinor points:\n\n(3d) There might be a misunderstanding of my question. I am specifically asking about \"The paper introduces $\\epsilon_C$ for theoretical analysis but does not utilize it in the algorithm.\" It means why $\\epsilon_C$ is absent from the algorithmic description and only surfaces in the theoretical analysis (with no prior mention before section 5). If the algorithm sets $\\epsilon_C = 0$, it implies that the analysis loses its significance for the proposed algorithm. \nThis observation suggests ensuring consistency between the algorithmic description and the theoretical analysis with respect to $\\epsilon_C$.\n\n(3e) I am expecting the paper would discuss a fundamental challenge of deriving practical regret bounds for CBO algorithms, which prevents existing works from deriving a theoretical analysis. Then, the paper will propose an algorithm to resolve it. However, from the response, it seems to be a limitation that is not resolved in this work.\n\nIn lines 12 and 13 of Algorithm 2, the subscripts should be $g_t$ instead of $g,t$."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700581646152,
                "cdate": 1700581646152,
                "tmdate": 1700581646152,
                "mdate": 1700581646152,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aeT37pgZXK",
                "forum": "WKALcMvCdm",
                "replyto": "k0dIImkwk6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Clarification by Authors (1/3)"
                    },
                    "comment": {
                        "value": "We are glad that we have addressed some of the reviewer\u2019s concerns and would like to clarify the following further.\n\n```\n(2b) Could the authors provide a concise explanation for the need to ensure a monotonically shrinking $\\hat{X}_t$ and elaborate on how defining $\\beta_t$ using $\\tilde{D}$ still ensures this property?\n```\nSure! As noted by the reviewer in the original 2.b comments, at $t$, we can not actually estimate $\\beta_t =2\\log(\\frac{2(K+1)\\vert \\tilde{D} \\cap \\hat{X}\\_t \\vert T}{\\delta})$ because $\\hat{X}\\_t$ relies on the $\\beta_t$. However, if $\\hat{X}\\_t$ is monotonically shrinking, meaning $\\vert \\tilde{D} \\cap \\hat{X}\\_t \\vert \\leq  \\vert\\tilde{D} \\cap \\hat{X}\\_{t-1}\\vert $, we could define $\\beta_t =2\\log(\\frac{2(K+1)\\vert \\tilde{D} \\cap \\hat{X}\\_{t-1} \\vert T}{\\delta}) \\geq 2\\log(\\frac{2(K+1)\\vert \\tilde{D} \\cap \\hat{X}\\_t \\vert T}{\\delta})$, then the union bound taken in the proof of lemma 1 still hold. \n\nNow, we avoid the confusion by simply letting $\\beta_t =2\\log(\\frac{2(K+1)\\vert \\tilde{D} \\_t \\vert T}{\\delta}) \\geq 2\\log(\\frac{2(K+1)\\vert \\tilde{D} \\cap \\hat{X}\\_{t-1} \\vert T}{\\delta})$ as in the revised theorem 1. Then $\\beta_t$ is essentially a constant. Though it does not guarantee that $\\hat{X}\\_t$ is monotonically shrinking, the desired union bound in lemma 1 still holds. The loss here is that $\\beta_t$ could have been smaller if being defined upon $\\vert\\tilde{D} \\cap \\hat{X}\\_{t-1}\\vert$ instead. \n\n```\n(2c) My understanding of the application of Lemma 5.4 remains unclear. Suppose $x_{g,t}$ is not selected as $x_t$ for iterations from 1 to 5 for a function $g$; how can we demonstrate that $\\sum_{t=1}^5 (2 \\beta^{1/2} \\sigma_{g,t-1}(x_t))^2 \\le C_1 \\beta \\gamma_{g,5}$?\n```\n\nWe\u2019d like to address the reviewer\u2019s concern but are not sure if we fully understand the question here. In the original 2.c comments, the reviewer pointed out that Lemma 5.4 only applies to the actually selected sequence of $x_t$. We believe here $\\sum_{t=1}^5 (2 \\beta^{1/2} \\sigma_{g,t-1}(x_t))^2 \\le C_1 \\beta \\gamma_{g,5}$ exactly match Lemma 5.4. Please note that in the proof of lemma 5.4, the sum of the square of simple regret $\\sum_t r^2_t$ is first transformed into $\\sum_{t=1} (2 \\beta^{1/2} \\sigma_{t-1}(x_t))^2$ by lemma 5.1 and 5.2 of Srinivas et al. (2009). \n\nIn addition, we want to highlight that the bridge between $2 \\beta^{1/2} \\sigma_{g,t-1}(x_{g,t})$ and the usage of lemma 5.4  is $\\sum_{t=1}^{T} \\alpha_t^2 \\leq \\sum_{t=1}^{T} \\sum_{g \\in \\{C_k\\}\\_{k\\in\\mathcal{K}} } (\\alpha_{g,t}(x_{t}))^2$, which is currently in the proof of our lemma A.1. For the left-hand side we have $2 \\beta^{1/2} \\sigma_{g,t-1}(x_{g,t}) \\leq \\alpha_t$ in the scenarios we\u2019ve discussed in formula (8)-(12) in the proof of lemma A.1. And for the right-hand side we have $\\alpha_{g,t}(x_{t}) \\leq 2 \\beta^{1/2} \\sigma_{g,t-1}(x_t)$ by definition of the acquisition functions $\\alpha_{g,t}$.\n\n```\n(3b) I kind of understand (1) but I find (2) difficult to understand. Why \"if the superlevel set is non-empty, ..., which shares the regret guarantee with Srinivas et al. (2009)\"? Could you clarify what is meant by the superlevel set in this context? If it is either a strict superset or a strict subset of the feasible region, then could you provide the reasons why the regret is comparable with Srinivas et al. (2009) where the feasible region is X?\n```\nWe apologize for the confusion here. First, the superlevel set we refer to in this context is $S_{C,t}$, which is defined in section 4.2. In practice, since we are working on the discretization, it should be $\\tilde{D} \\cap S_{C,t}$ in the implementation. As illustrated in equation (5) in section 4.3, when $S_{C,t}\\neq \\emptyset$, $\\alpha_{f,t}$ is essentially $UCB_{f,t}$. Yet we find out that the originally claimed connection to the regret guarantee with Srinivas et al. (2009) might be indirect, as the results by Srinivas et al. (2009) are on cumulative regret when using UCB as an acquisition function, while we are aiming at a simple regret guarantee. \n\nWe would like to refer to the updated Corollary 2, where we now show that when picking the point maximizing $UCB_{f,t}$ on $\\tilde{D} \\cap S_{C,t}$, we could translate the theorem 1 into a simple regret bound."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700660533206,
                "cdate": 1700660533206,
                "tmdate": 1700727195602,
                "mdate": 1700727195602,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "x2Lm5AipZg",
                "forum": "WKALcMvCdm",
                "replyto": "k0dIImkwk6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Clarification by Authors (3/3)"
                    },
                    "comment": {
                        "value": "***Minor points:***\n```\n(3d) There might be a misunderstanding of my question. I am specifically asking about \"The paper introduces $\\epsilon_C$ for theoretical analysis but does not utilize it in the algorithm.\" It means why $\\epsilon_C$ is absent from the algorithmic description and only surfaces in the theoretical analysis (with no prior mention before section 5). If the algorithm sets $\\epsilon_C = 0$, it implies that the analysis loses its significance for the proposed algorithm.\nThis observation suggests ensuring consistency between the algorithmic description and the theoretical analysis with respect to $\\epsilon_C$.\n```\nWe appreciate the clarification by the reviewer, and we would address this inconsistency by explicitly including the estimation of $\\epsilon_C$ as an input of the algorithm. \n\n```\n(3e) I am expecting the paper to discuss a fundamental challenge of deriving practical regret bounds for CBO algorithms, which prevents existing works from deriving a theoretical analysis. Then, the paper will propose an algorithm to resolve it. However, from the response, it seems to be a limitation that is not resolved in this work.\n```\nWe believe it is fundamental because we regard the limitation that the active learning component can not identify the full boundary of a dense search space with confidence within the limited number of queries as fundamental. Yet, we agree with the reviewer that there is no proof that the problem of active learning is a necessity, even considering our definition of reward.\n\n```\nIn lines 12 and 13 of Algorithm 2, the subscripts should be $g_t$ instead of $g,t$.\n```\nWe are grateful for the correction and have revised it accordingly. We found it actually should be corrected to be $g_{t}, t$ instead of $g_t$. Here, $g_t$ denotes the function to be evaluated at $t$, while the other $t$ is needed to ensure the alignment with subscript $C_k, t$ in line 7 and  $f, t$ in line 9.\n\n\n***Reference***\n\n[1] Lu, Congwen, and Joel A. Paulson. \"No-regret Bayesian optimization with unknown equality and inequality constraints using exact penalty functions.\" IFAC-PapersOnLine 55, no. 7 (2022): 895-902.\n\n[2] Lu, Congwen, and Joel A. Paulson. \"No-regret constrained Bayesian optimization of noisy and expensive hybrid models using differentiable quantile function approximations.\" arXiv preprint arXiv:2305.03824 (2023)."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700660930053,
                "cdate": 1700660930053,
                "tmdate": 1700661528485,
                "mdate": 1700661528485,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WeKlaj82Et",
                "forum": "WKALcMvCdm",
                "replyto": "x2Lm5AipZg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5950/Reviewer_AopU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5950/Reviewer_AopU"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for providing the updated paper and addressing my questions. After reviewing the response, there is a remaining issue related to (3b) and (4a). The proof of the simple regret in Corollary 2 is \"after attaining 13\". But the definition $\\beta = 1/T$ is established based on the iteration T when 13 is attained. Consequently, \"after attaining 13\", the upper confidence bound and lower confidence bound (depending on $\\beta$) may no longer be applicable. So, this is potentially an error in the proof of the simple regret.\n\nThe following are just some comments and clarifications.\n\n(3c) The comparison with existing works may be improved by including a discussion on the difference in the assumptions. \n\n(2c) My question is from the previous response \n```\nRoughly speaking, though only one of the $x_{g,t}$ is picked as $x_t$, the upper bound holds for the other points that have not been picked, as is shown in the revised proof in section A.2.\n```\nMy question is that assuming $x_{g',t}$ is not selected as $x_t$ (for a function $g'$), how do we show that the upper bound holds for these \"other points that have not been picked\".\n\n```\nIn the proof of Theorem 2, we are not sure which one the reviewer is pointing to, but we believe should be taken according to algorithm 2.\n```\nIn the proof of Theorem 2 in the last revision, the first line of the equation is  $\\sum_{t=1}^T \\alpha_t^2 = \\sum_{t=1}^T \\alpha_{g,t}^2(x_{g,t})$. Hence, my question is about $g$ on the RHS. Anyways, this is corrected in the latest revision as $g_t$. So this issue is resolved."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687342030,
                "cdate": 1700687342030,
                "tmdate": 1700687342030,
                "mdate": 1700687342030,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gJtJqNPJve",
                "forum": "WKALcMvCdm",
                "replyto": "k0dIImkwk6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Further Clarification about Corollary 2 by Authors"
                    },
                    "comment": {
                        "value": "We appreciate the further clarification of the previous discussion and constructive comments that help enhance the presentation of our paper. We\u2019d like to add a tentative discussion over the difference from the existing no-regret CBO method in the appendix. In the following, we want to address the reviewer\u2019s remaining concerns.\n\n```\nThe proof of the simple regret in Corollary 2 is \"after attaining 13\". But the definition $\\beta = 1/T$ is established based on the iteration T when 13 is attained. Consequently, \"after attaining 13\", the upper confidence bound and lower confidence bound (depending on $\\beta$) may no longer be applicable. So, this is potentially an error in the proof of the simple regret.\n```\n\nWe understand the concern raised by the reviewer here. Though we leverage the bounds and the acquisition function holds at $ T $ for the $ T+1 $ query, the discrepancy on $\\beta$ could be confusing and even erroneous. \n\nWe made the following revisions to the corollary 2.  \n\n(1) By enlarging $\\beta$ from $\\beta =2\\log(\\frac{2(K+1)\\vert \\tilde{D}\\vert T}{\\delta})$ to $\\beta =2\\log(\\frac{2(K+1)\\vert \\tilde{D} \\vert (T+1)}{\\delta})$, we guarantee that the union bound used in the proof of theorem 1 before attaining 13 would still hold; \n\n(2) we change the acquisition back to $LCB_{f,t}$, since we figured out $UCB_{f,t}$ actually incur an additional term we do not see a straightforward proof to guarantee that it can be bounded by $\\alpha_T \\leq \\epsilon$. \n\nThough we make the changes, the intended interpretation of Corollary 2 remains the same as the following. As long as $T$ is sufficiently large for a fixed $\\epsilon$ so that it meets $T \\geq \\frac{\\beta \\widehat{\\gamma_T} C_1}{\\epsilon^2}$, and the algorithm picks the $arg\\max_{x \\in \\tilde{D}\\_{\\hat{X}\\_T} \\cap S_{C, T}}LCB_{f,T}(x) $, the algorithm would translate the analysis in theorem 1 into a high probability bound by the simple regret."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700730420081,
                "cdate": 1700730420081,
                "tmdate": 1700730721302,
                "mdate": 1700730721302,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "dKpOJVptWB",
            "forum": "WKALcMvCdm",
            "replyto": "WKALcMvCdm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5950/Reviewer_vk7s"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5950/Reviewer_vk7s"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new algorithm for constrained Bayesian optimization. The acquisition function for the objective is a modified UCB, and the acquisition function for the constraints are marginal variance. In each iteration, the algorithm selects a query point by maximizing the maximum over the objective's and constraints' acquisition functions. The authors have proved an upper bound on the number of samples to find an $\\epsilon$ confidence interval containing the global maximum. Empirically, they have shown that the proposed method achieves superior convergence speed compared with other constrained Bayesian optimization baselines."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The theoretical result seems to be the first non-asymptotic sample complexity guarantee for constrained Bayesian optimization.\n- According to the plots in Figure 3 and Figure 4, it looks like the method is often much better than the baselines when the constraint is more challenging (where the feasible set is a small fraction of the domain)."
                },
                "weaknesses": {
                    "value": "- Some important experimental details are missing.\n    - It is not clear how to numerically check if $LCB_{f, t, \\max}$ is finite or not. To do this, one needs to check if the intersection of $S_{C, t}$ is nonempty, where each super level set $S_{C, t}$ is a non-convex set. It is unclear from the paper how the intersection is computed.\n    - It is unclear how the hyperparameter $\\beta_t$ is set in the experiments. The constant $\\beta_t$ balances the exploration and exploitation and has huge impact on the practical performance.\n- The exact condition on the discretization $\\tilde D$ is unclear in the statements of Lemma 1 and Theorem 1. According to Lemma 1, $\\tilde D$ can be an arbitrary discretization of the domain as long as it contains the global optimum. However, I don't quite think this can be true. For example, the discretization of Srinivas et al. (2009) has to be large enough (exponential) to roughly cover the entire domain. Otherwise, the concentration inequality only holds inside the discretization $\\tilde D$ and cannot be generalized to the entire domain.\n- The proof relies on an additional assumption that the confidence interval has to shrinks monotonically, which is somewhat non-standard in the analysis of BO algorithms. Though, the author claims they can apply a proof technique by Gotovos et al. (2013) even if this assumption is violated."
                },
                "questions": {
                    "value": "- The Assumption 3 needs $\\beta_t$ to be non-increasing. However, subsequently $\\beta_t = 2 \\log (2 (K + 1) |\\tilde D| \\pi_t / \\delta)$ which is increasing in $t$, given that $\\pi_t$ has to grow superlinearly (typically quadratically). Can you comment on this discrepancy?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5950/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5950/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5950/Reviewer_vk7s"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5950/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698741483528,
            "cdate": 1698741483528,
            "tmdate": 1699636634305,
            "mdate": 1699636634305,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oUFUdrv1Cl",
                "forum": "WKALcMvCdm",
                "replyto": "dKpOJVptWB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response by Authors (1/2)"
                    },
                    "comment": {
                        "value": "We appreciate the detailed comments made by the reviewer. We would like to clarify the confusion raised by the reviewer in the following.\n\n***Weakness***\n\n```\nThe exact conditions of the discretization are unclear in the statement of lemma 1 and theorem 1.\n```\n\nWe'd like first to clarify the discretization as it is related to the other concern raised by the reviewer. Throughout the design of the algorithm, we focus on dealing with the **finite discretization $\\tilde{D}$ of the original search space**, which aligns with many engineering tasks where only the discretization is feasible or a known smoothness on locality alleviates the needs to scan the whole continuous space. \n\nAs noted by the reviewer, Srinivas et al. (2009) start by studying a search space of finite discretization and then introducing the smoothness assumption to extend the results to a multi-dimensional continuous search space where the regret bound relies on the search space. We do not further extend the discussion to a continuous search space for two reasons. (1) The motivating application for us does not deal with a continuous search space; (2) There are recent advancements introducing **various treatments** of continuous search space given different assumptions on the structure of the problem. For example, with regard to the high-dimensional BO task as concerned by the reviewer, except directly creating discretization, which incurs the curse of dimensionality, various principled treatments [3,4,5] have been studied. They could be incorporated into our constrained BO framework to address the concern that the construction of a finite search space could be troubled by high dimensionality. A comprehensive discussion of the construction of a finite search space might go beyond the scope of this work.\n\n```\nIt is not clear how to numerically check if $LCB_{f, t, max}$ is finite or not. It is unclear from the paper how the intersection is computed.\n```\n\nRelated to the previous question, we are focusing on a finite discrete search space $\\tilde{D}$, where a simple strategy would be checking the membership to different sets using the point-wise LCB and UCB values.\n\n```\nThe constant balances the exploration and exploitation and has a huge impact on the practical performance. It is unclear how it is set in practice.\n```\n\nWe appreciate the constructive comment. We added additional results and corresponding scripts in the revision to demonstrate the robustness against different choices of $\\beta$. In summary, among the choices of the theoretical results or constant values, including 0.1, 2, 4, and 8, we observe that only .1 could trap the algorithm in the sub-optimal area due to its lack of exploration.\n\n```\nThe proof relies on an additional assumption that the confidence interval has to shrink monotonically, which is somewhat non-standard in the analysis of BO algorithms. However, the author claims they can apply a proof technique by Gotovos et al. (2013) even if this assumption is violated.\n```\n\nYou are correct that our proof relies on the assumption, and as the reviewer pointed out, we can apply a proof technique by Gotovos et al. (2013) even if this assumption is violated. We can construct a new confidence interval by taking the maximum (minimum) of historical pointwise LCB (UCB). Then, the new confidence interval monotonically and consistently shrinks. Since we are aiming at a guarantee within a finite known $T$ iteration, the construction of this new confidence interval (taking union bound) would only incur a constant cost on the confidence level of the ultimate bound in theorem 1. Please note that such modification implies a slight change in the algorithm. However, we find in our empirical study that, even without these additional steps, our algorithm already exhibits compelling performance consistently across a variety of BO benchmarks."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700469527945,
                "cdate": 1700469527945,
                "tmdate": 1700469527945,
                "mdate": 1700469527945,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7ofvfRqwTX",
                "forum": "WKALcMvCdm",
                "replyto": "dKpOJVptWB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response by Authors (2/2)"
                    },
                    "comment": {
                        "value": "***Question***\n\n```\nThe assumption 2 needs \\beta_t to be non-increasing. \n```\n\nWe appreciate the detailed question here. The reason $\\pi_t$ needs to grow is the need to guarantee the convergence of the series, which allows an asymptotical sublinear regret. Specifically, the requirement is $\\sum_t{\\pi_t}^{-1} = 1$. Yet, in our problem setup, since cumulative regret could not be bounded as instantaneous regret could be infinite when the evaluated candidate $x_t$ violates any of the constraints (cf. Equation (3)), we aim to guarantee that after a certain horizon T, the *simple regret* could be bounded. Therefore, there is no need to have a convergence series $\\sum_t{\\pi_t}^{-1} = 1$. As shown in the proof, we only need $\\sum_{t=1}^T{\\pi_t}^{-1} = 1$ for a given budget/horizon T, and setting $\\pi_t = T$ satisfies it. We made revisions in the analysis section and the proof part to highlight this.\n\nThe setting in which $\\sum_{t=1}^T{\\pi_t}^{-1} = 1$ is used instead of $\\sum_t{\\pi_t}^{-1} = 1$ can be found in [1] as they also aim at a simple regret after a sufficiently large $T$. Similarly, in a multi-fidelity BO setting [2], the total budget is assumed to be given to attain a theoretical guarantee on the cumulative regret.\n\n***Reference***\n\n[1] Wang, Zi, and Stefanie Jegelka. \"Max-value entropy search for efficient Bayesian optimization.\" In International Conference on Machine Learning, pp. 3627-3635. PMLR, 2017.\n\n[2] Song, Jialin, Yuxin Chen, and Yisong Yue. \"A general framework for multi-fidelity bayesian optimization with gaussian processes.\" In The 22nd International Conference on Artificial Intelligence and Statistics, pp. 3158-3167. PMLR, 2019.\n\n[3] Maus, Natalie, Haydn Jones, Juston Moore, Matt J. Kusner, John Bradshaw, and Jacob Gardner. \"Local latent space Bayesian optimization over structured inputs.\" Advances in Neural Information Processing Systems 35 (2022): 34505-34518.\n\n[4] Gardner, Jacob, Chuan Guo, Kilian Weinberger, Roman Garnett, and Roger Grosse. \"Discovering and exploiting additive structure for Bayesian optimization.\" In Artificial Intelligence and Statistics, pp. 1311-1319. PMLR, 2017.\n\n[5] Nayebi, Amin, Alexander Munteanu, and Matthias Poloczek. \"A framework for Bayesian optimization in embedded subspaces.\" In International Conference on Machine Learning, pp. 4752-4761. PMLR, 2019."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700469686700,
                "cdate": 1700469686700,
                "tmdate": 1700727068573,
                "mdate": 1700727068573,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "h0lU3EDW9P",
                "forum": "WKALcMvCdm",
                "replyto": "dKpOJVptWB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5950/Reviewer_vk7s"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5950/Reviewer_vk7s"
                ],
                "content": {
                    "comment": {
                        "value": "Hi authors,\n\nI appreciate the effort of clarification. However, I still disagree the argument on discretization.\n\nFirst of all, the search domain $\\mathbf{X}$ is never assumed to be discrete in the paper. Second, the objective functions used in the experiments have continuous domain (e.g. Rastrigin). If the experiments are conducted on a discretized search space $\\tilde D$, the authors are required to provide the detail of the discretization $\\tilde D$ (which unfortunately is not available).\n\nThis is also related to my original concern: the explicit expression of the discretization $\\tilde D$ is missing in Lemma 1. Based on Lemma 1, any discretization works. If I pick a singleton $\\tilde D = \\\\{\\mathbf{x}^*\\\\}$, does the high probability bound still work? It does not quite make sense as the region of interest $\\hat{X}_t$ does not make use of the discretization at all.."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700522557698,
                "cdate": 1700522557698,
                "tmdate": 1700522644393,
                "mdate": 1700522644393,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GjOQIIYpsf",
                "forum": "WKALcMvCdm",
                "replyto": "dKpOJVptWB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Concerns about Discretization"
                    },
                    "comment": {
                        "value": "Dear Reviewer vk7s, \n\nThank you for the swift reply and for clarifying the concerns about the discretization!\n\n```\nFirst of all, the search domain $\\mathbf{X}$ is never assumed to be discrete in the paper. \n```\nBefore reaching algorithm 1, we do not discuss the discretization $\\tilde D$. We define the region of interest $\\hat{\\mathbf{X}}$ in equation (4) to be a subset of $\\mathbf{X}$, which is not assumed to be discrete. \n\nYet in practice, since we need to check the membership pointwise on the discretization $\\tilde D$, we actually rely on the discrete set $\\tilde{D}\\_{\\hat{X_t}}= \\tilde D \\cap \\hat{X_t}$. As illustrated in lines 7-8 of the algorithm 1, we use $arg\\max_{x\\in \\tilde{D}\\_{\\hat{X_t}} \\cap U_{C_k, t}} \\alpha_{C_k, t} (x)$ and $arg\\max_{x\\in \\tilde{D}\\_{\\hat{X_t}}} \\alpha_{f, t} (x)$ in contrast to the conceptual discussion in section 4.3 where we use $arg\\max_{x\\in \\hat{X_t} \\cap U_{C_k, t}} \\alpha_{C_k, t} (x)$ and $arg\\max_{x\\in \\hat{X_t}} \\alpha_{f, t} (x)$. We just added additional clarification at the end of section 4.3 to clarify the implementation.\n\n\n```\nSecond, the objective functions used in the experiments have a continuous domain (e.g., Rastrigin). If the experiments are conducted on a discretized search space $\\tilde D$, the authors are required to provide the detail of the discretization $\\tilde D$ (which, unfortunately, is not available).\n```\nWe just added additional information about the construction of discrete space we used in the low-dimensional synthetic datasets. We fix the $\\tilde D$ throughout the experiment on both Ratrigin and Ackley to reduce randomness and guarantee reproducibility. Please note that, as illustrated in the first row of Figure 3, we make the discretization dense to capture the geometry of the continuous functions.\n\n\n```\nThis is also related to my original concern: the explicit expression of the discretization $\\tilde D$ is missing in Lemma 1.\n```\nYes, you are right! The result of Lemma 1 should actually be the probability bound for $x \\in \\tilde{D}\\_{\\hat{X_t}}$ instead of $x \\in \\hat{X_t}$. We just corrected it in both the lemma and proof in Appendix A.1. We apologize for the confusion. At some point, we decoupled the concepts of search space and ROI from the discretization, which is now separately denoted as $\\tilde {D}$, and the notation is mistakenly left over.\n\n-----\nThank you again for the constructive comments, which we find helpful in enhancing the clarity of the paper! We hope our clarification and updated revision addresses your concern."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700552173534,
                "cdate": 1700552173534,
                "tmdate": 1700555606307,
                "mdate": 1700555606307,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ysqBF7jbAw",
            "forum": "WKALcMvCdm",
            "replyto": "WKALcMvCdm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5950/Reviewer_uw1z"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5950/Reviewer_uw1z"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes COBALT, a constrained Bayesian optimization algorithm. It models the unknown objective and constraints with Gaussian processes. Regions of interest (ROIs) are defined for the objective and each constraint based on confidence intervals. Acquisition functions are defined on the ROIs. The next point maximizes the combined acquisition functions over the ROI intersection, enabling an adaptive tradeoff between learning constraints and optimization. Theoretical analysis shows the confidence interval around the global optimum shrinks below a threshold after enough iterations. Experiments demonstrate COBALT efficiently finds the global optimum compared to existing methods, benefitting from active constraint learning. In summary, COBALT introduces a principled constrained Bayesian optimization framework, leveraging ideas from active learning and Bayesian optimization via acquisition functions and ROIs for the adaptive constraint-objective tradeoff."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper presents an original contribution to the field of constrained Bayesian optimization. The key strength is the principled integration of ideas from both Bayesian optimization and active learning of constraints to develop the novel COBALT algorithm. Defining separate acquisition functions on regions of interest for the objective and constraints enables explicit, adaptive tradeoff between exploring constraints vs exploiting the objective. This combination of existing methods with new problem formulations results in an algorithm with theoretical guarantees on optimizing unknown black box functions subject to unknown constraints. Experiments demonstrate superiority over current state-of-the-art techniques on challenging synthetic and real-world optimization tasks."
                },
                "weaknesses": {
                    "value": "While the COBALT algorithm represents a significant advance, there are a few areas where the work could be strengthened:\n* Empirical evaluation is limited to 6 relatively low-dimensional tasks. Testing on more high-dimensional real-world problems would better showcase scalability.\n* The theoretical analysis relies on several assumptions that may not always hold in practice, such as the independence of the GPs and the existence of a feasible solution."
                },
                "questions": {
                    "value": "* The theoretical analysis relies on assumptions like GP independence and feasible solutions. Could these be relaxed? What are the barriers to deriving more general guarantees?\n* What is the computational complexity of COBALT? How does it scale with dimensionality and constraints?\n* Have you tested on any high-dimensional (D>10) or large-scale real-world problems? This could better showcase scalability.\n* Is there a principled way to set the \u03b2 tradeoff parameter? Sensitivity analysis could elucidate its impact.\n* How does performance depend on the quality of the GP model of the constraints?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5950/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5950/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5950/Reviewer_uw1z"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5950/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698843415858,
            "cdate": 1698843415858,
            "tmdate": 1699636634208,
            "mdate": 1699636634208,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FEVJH4K46N",
                "forum": "WKALcMvCdm",
                "replyto": "ysqBF7jbAw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5950/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response by Authors (1/2)"
                    },
                    "comment": {
                        "value": "We are glad the reviewer appreciates our contribution to the BO with unknown constraints, and we sincerely appreciate the constructive comments by the reviewer.\n\n***Weakness***\n```\nEmpirical evaluation is limited to 6 relatively low-dimensional tasks. Testing on more high-dimensional real-world problems would better showcase scalability.\n```\n\n1. Thank you for raising this in the comments. Please note that the water converter is a 36-dimensional task, which is reasonably high-dimensional (i.e., d>10).\n\n2. As the reviewer noted in the questions, the performance actually depends on the quality of the GP models. We found tuning a large number of GPs in high-dimensional, large-scale tasks to be more challenging. Especially when the prior or kernel learning is not properly tuned, the **misspecification of every single model accumulates in the ROI intersection**. Then, it is possible to result in an empty intersected ROI, which is not expected when models offer satisfying uncertainty quantification.\n\n3. We do see the potential of further integrating additional ROI-based HDBO treatments, such as BALLET[1], into the COBALT framework to further enhance the scalability through (deep) kernel learning [6]. We want to highlight that, as noted by the reviewer, this submission **focused** on the principled tradeoff between learning and optimization in the constrained BO setting within the limited pages. Advancements in modeling and efficiency for large-scale constrained BO tasks would definitely be of interest in the future.\n\n```\nThe theoretical analysis relies on several assumptions that may not always hold in practice, such as the independence of the GPs and the existence of a feasible solution.\n```\n\n1. This is a good point (question). Thank you for raising this concern. For the dependency assumption, we follow the convention in the constrained Bayesian optimization literature [2, 3]. As discussed in section F.3 in the appendix, we acknowledge the limitation of the current assumption and believe it is an interesting future direction to explore different dependency assumptions, which could lead to potentially novel modeling and acquisition function choices. \n\n2. We also appreciate the reviewer's concern about our assumption of the existence of a feasible solution, although it wasn't a primary consideration in our motivating applications. If this assumption does not hold, it implies two significant implications: (1) the task or application in question may encounter fundamental challenges; (2) as our analysis indicates, the algorithm is designed to identify a subset of the feasible region, should it exist. In the absence of such a region, the active learning component of our algorithm would converge to an empty intersected Region of Interest (ROI).\n\n3. To provide further clarity on this aspect, we have extended our analysis in the appendix of the revised version. Our additional result further highlights the algorithm's capability to detect infeasibility and is presented as a corollary of our existing results."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700469034409,
                "cdate": 1700469034409,
                "tmdate": 1700469034409,
                "mdate": 1700469034409,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]