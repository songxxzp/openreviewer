[
    {
        "title": "Subject-specific Deep Neural Networks for Count Data with High-cardinality Categorical Features"
    },
    {
        "review": {
            "id": "RMHQg1wNrh",
            "forum": "0xLWPdObG1",
            "replyto": "0xLWPdObG1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9157/Reviewer_HXxH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9157/Reviewer_HXxH"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a way to learn a deep neural network (DNN) with Poisson outcome distribution and Gamma-distributed random effects in one joint optimization approach using the h-likelihood framework. Apart from the derivation of a constant to obtain both maximum likelihood estimates for the fixed effects model part and best unbiased predictions for the random effects, the authors also using a method-of-moments approach to circumvent non-identifiability."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Significance: Including random effects in neural networks is an important research topic that has not been fully explored\n- Originality: The paper seems to be the first to tackle Poisson DNNs with random effects in this way"
                },
                "weaknesses": {
                    "value": "- Significance: \n    + It's not clear how much better the given idea works compared to other approaches\n    + Figure 4 shows that there is no true sparsity achieved, and separability between relevant and irrelavant features might depend on the size of the gap; using an actual l1-penalty via [overparametrization](https://arxiv.org/abs/2307.03571) could help in this case.\n    + Statements in 4.2\n        * Theorem 1: Maybe I have missed something, but AFAIU it's trivial that the likelihood will improve once you shift fixed information from random to fixed effects as both the likelihood and \"prior\" will increase (this is also common knowledge in mixed models). I would thus see this as part of Section 2.2. \n        * Online or post-hoc corrections like the one in (7) probably work, but why not directly encode the constraint by encoding the information in z (i.e., using the design matrix $\\tilde{Z} = Z - 1_n 1_n^\\top Z / n$ instead of Z where Z is the matrix stacking all observations $z_{ij}$)? \n    + Section 3: It's unclear to me why it is important to align $\\ell_e(\\theta,v)$ and $\\ell_e(\\theta, u)$ as both are simply two different model assumptions. The reason this might not be clear is that the same $f_\\theta$ is used, yet not explicitly defined. More specifically, if $u_i$ follows a Gamma distribution, then $f_\\theta$ should be the density of a Gamma distribution. But using **the same** Gamma density to evaluate the likelihood of a transformed random variable $v(u_i)$ does not make sense. If $v$ is $log(\\cdot)$, then $v_i$ yields values that can be negative while the Gamma distribution is only defined for positive values. If 2) the authors mean that one transforms $v_i$ and then plugs in $u_i$ into a Gamma density (or the other way around), then there should not be any additional Jacobian term as the log-Gamma distribution is exactly defined in a way such that $exp(v_i) \\sim Gamma$. \n- Clarity: The math is not always clear, e.g., \n    + $f_\\theta$ in (3) is never explicitly defined if I am not mistaken \n    + bold/non-bold symbols are not used in a consistent manner (e.g. $\\boldsymbol{\\mu}^m$ and $\\boldsymbol{\\mu}^c$ in Section 2)\n    + I assume $f_\\theta(y|u)$ does not actually depend on $\\theta$ directly? (in all fairness, this is also not very clear in many papers by Lee and authors which are cited for this)\n    + in Section 4.4 the typical sparsemax notation is adopted but not aligned with the previous notation (it does not get clear what $\\textbf{z}$ and $\\textbf{p}$ are in the context of the paper -- in particular as z is already used by the \"random slope features\", but the lines below suggest that the section talks about selection of fixed effects) and also contains typos (e.g., it should say \"genuine features $(K < 10)$\" I assume, not $k < 10$).\n- Limited empirical evidence: The simulation study is rather limited with\n    + fixed n, number of features, etc.\n    + no comparison against other hglm approaches (e.g. hglm package in R)\n    + no comparison with REML approaches (?)\n\n  and sometimes not very clear\n    +  why simulate $v_i \\sim N(0, \\lambda)$ if it's clear that $log (u_i)$ won't follow a Gamma distribution?\n    +  why does Table 1 say \"Distribution of random effects\" if the content is RMSPE values? Actually measuring the distribution quality would give more insights into the estimation performance.\n- Quality: the phrasing is a bit akward at several places (e.g. \"However, it could not yield MLE for the variance component $\\lambda$\")"
                },
                "questions": {
                    "value": "1. Can you comment on my comment on Theorem 1?\n2. Can you clarify the idea behind Section 3 and the two different likelihoods?\n3. The authors talk about obtaining \"MLEs\" and \"BUPs\". How is the unbiasedness for random effects defined (as there are multiple ways to do this) and can the authors prove that unbiasedness is something that can be achieved, even in the case of a \"highly non-convex\" neural network likelihood (that influences the random effects at least indirectly)?\n4. Can z also contain information from x and if yes, how is identifiability ensured in this case (cf. [Ruegamer, 2023](https://proceedings.mlr.press/v202/rugamer23a.html))?\n5. How do REML approaches fit into the picture?  \n6. Would an EM-based approach for NNs like in [Xiong et al., 2019](https://openaccess.thecvf.com/content_CVPR_2019/papers/Xiong_Mixed_Effects_Neural_Networks_MeNets_With_Applications_to_Gaze_Estimation_CVPR_2019_paper.pdf) be a meaningful alternative?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9157/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698534588997,
            "cdate": 1698534588997,
            "tmdate": 1699637152177,
            "mdate": 1699637152177,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gNGMBiDAGh",
                "forum": "0xLWPdObG1",
                "replyto": "RMHQg1wNrh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9157/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9157/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer HXxH"
                    },
                    "comment": {
                        "value": "We greatly appreciate you for your insightful and interesting comments, which provided diverse perspectives on this paper. We have prepared responses for your questions and revised the manuscript.\nWe supplemented our experimental studies with increasing sample size in Section 5 and permutation importance in Section 4.4 and Appendix A.5. We provided p-values from Wilcoxon signed-rank test for comparing RMSPEs in experimental studies and real data analyses. We have supplemented the explanation on the notation and corrected some typos. In Section 7, we added remarks on future research. We are delighted to have enhanced our paper and hope that it will meet your expectations as well.\n\n### **Question 1**\n\n(1) It could be a part of theoretical section, as you mentioned, but this could be a practical issue, because Theorem 1 justifies the adjustment process. If we can achieve the global optimum, as in linear models, then this kind of adjustment would not be necessary. However, since the global optimum may not be guaranteed in DNNs, there could be room for improving the fixed effects and random effects. Theorem 1 shows that our adjustment always reduce the loss function.\n\n(2) Due to the limited support for matrix representation in the OpenReview system, we are attaching a link for the screenshot of our response.\n\n* [Answer to Question 1-(2)](https://i.imgur.com/uwSwFxv.png)\n\n### **Question 2 and clarity of notation**\n\n* Bold face stands for vectors and matrices and non-bold face stands for scalars.\n\n* $\\boldsymbol{\\theta}$ is the vector of all the fixed parameters, including all the weights $\\mathbf{w}$ in neural network NN$(\\cdot)$, fixed effects $\\boldsymbol{\\beta}$ from the last hidden layer to the output layer, and variance component $\\lambda$ for the distribution of random effects. For the briefness of equation, we write the subscript $\\boldsymbol{\\theta}$ for dependency on any fixed parameters in $\\boldsymbol{\\theta}$, rather than describe a specific parameter for each function. \n\n* For notational convenience, $f_{\\boldsymbol{\\theta}}(\\cdot)$ stands for a density function of the random variable in the parentheses, depending on some parameters in $\\boldsymbol{\\theta}$. For example, $f_{\\boldsymbol{\\theta}}(u) = f_{U}(u; \\boldsymbol{\\theta})$ denotes the probability density function of $u$, $f_{\\boldsymbol{\\theta}}(v) = f_{V}(v; \\boldsymbol{\\theta})$ denotes the probability density function of $v$, $f_{\\boldsymbol{\\theta}}(y,v) = f_{Y,V}(y,v; \\boldsymbol{\\theta})$ denotes the joint probability density function of $(y, v)$. As far as we know, this is conventional notation in statistics. \n\n* In Section 4.4, we changed $\\mathbf{z}$ and $\\mathbf{p}$ to $\\mathbf{a}$ and $\\mathbf{b}$, respectively. $K$ is corrected to $p$, which denotes the number of features. $k$ denotes the index of each feature. Thus, there are $p=100$ features including 10 genuine features $(k=1,...,10)$ and 90 irrelevant features $(k=11,...,100)$. We corrected our explanation in Section 4.4.\n\n### **Question 3**\n\nWe intended to say that theoretically the joint maximizer of h-likelihood is equivalent to the MLEs and BUPs of fixed and random parameters, respectively. However, as you mentioned, there is no guarantee to achieve the global maxima in practice. That is the reason why we proposed the use of an adjustment process in Theorem 1.\n\n\n### **Question 4**\n\nMany thanks for introducing an interesting paper by R\u00fcgamer [1], which consider the identifiability problem in semi-structured networks (SSNs). R\u00fcgamer [1] considered SSNs with a late fusion of the structured and unstructured model,\n$$\nE(\\mathbf{y}|\\mathbf{X}, \\mathbf{X}^*) \n= \\boldsymbol{\\eta}\n= \\mathbf{X} \\boldsymbol{\\beta} + \\mathbf{U} \\boldsymbol{\\gamma},\n$$\nwhere $\\mathbf{X}$ is tabular features and $\\mathbf{X}^*$ is additional features. Here, $\\mathbf{U}$ are latent features learned in the penultimate layer of the neural network (i.e., $\\mathbf{U}$ are latent features learned from $\\mathbf{X}^*$), and $\\boldsymbol{\\gamma}$ are the weights from the connection between the last hidden and the output layer. The predictor $\\boldsymbol{\\eta}$ is combined with structured predictor $(\\boldsymbol{\\eta}^{\\text{str}} = \\mathbf{X}\\boldsymbol{\\beta})$ and non-structured predictor $(\\boldsymbol{\\eta}^{\\text{unstr}} = \\mathbf{X}\\boldsymbol{\\beta})$. In SSNs where both $\\boldsymbol{\\beta}$ and $\\boldsymbol{\\gamma}$ are fixed effects, R\u00fcgamer [1] studied identifiability of $\\boldsymbol{\\eta}^{\\text{str}}$.\n\nIn this paper, we are handling the identifiability between fixed and random effects (Section 2.2), which are quite different from that between two fixed effects $\\boldsymbol{\\beta}$ and $\\boldsymbol{\\gamma}$. We believe that, if $\\boldsymbol{\\gamma}$ were treated as random effects, it would satisfy the orthogonality properties for identifiability, which is very interesting topic, requesting a separate paper for extensive future research. We added a remark in Section 6 for your suggestion."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9157/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700496832643,
                "cdate": 1700496832643,
                "tmdate": 1700496832643,
                "mdate": 1700496832643,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0WjxkieVxz",
                "forum": "0xLWPdObG1",
                "replyto": "RMHQg1wNrh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9157/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9157/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer HXxH (continued)"
                    },
                    "comment": {
                        "value": "### **Question 5**\n\nREML approaches for linear mixed models (LMMs) can be implemented into DNNs by regarding the last hidden layer as the covariates of LMMs [2, 3].\n\n### **Question 6**\n\nThe variational EM approach [4] is another way for handling the random effects in DNNs. EM algorithm is composed of the E-step and M-step. It computes random effect predictors after estimating the fixed effects, including the variance components. On the other hand, the h-likelihood approach jointly optimizes the loss function, hence it only maximize the h-likelihood without an E-step. It can give more efficient and stable procedure. Lee and Lee [3] showed the advantage of joint optimization in their experimental studies.\n\n### **Advantage of the given idea and limited empirical evidence**\n\nDuring the rebuttal period, we presented some additional experiments to clarify the advantage of the proposed method. First, we performed the Wilcoxon signed rank test for the RMSPEs, which is widely-used for comparing the prediction errors [4-6].\n\n* In experimental studies, PG-NN outperforms the other models with p-value$<$0.001 in all scenarios except for G(0), with the absence of random effects. In this case, P-NN performs the best.\n* Following Tran et al. [7, Section 6.2.4], we did not consider the cross-validation for longitudinal data (Epilepsy, CD4, Bolus), because the last observations (test data) were predicted by training the past data for each subject. For clustered data (Owls, Fruits), we present the average of RMSPEs from 10-fold cross-validation with the p-values from Wilcoxon signed rank test. The following table (Table 3 in Appendix A.6) shows the mean RMSPEs and p-values for testing whether the RMSPE of PG-NN is less than that of other methods. (Hence the p-value for PG-NN itself is not included in this table.) In Owls data, though the p-values are marginal (0.05$\\sim$0.1) in some cases, the proposed PG-NN significantly (p-value$<$0.05) outperforms the other methods. In Fruits data, the PG-NN has the smallest RMSPEs but the difference is not significant except for N-NN and NN-NN. Note here that the P-GLM was the best in Fruits data without cross-validation, but the cross-validation clarifies that the PG-NN has better overall RMSPE.\n\n|Model|Owls/RMSPE|Owls/p-value|Fruits/RMSPE|Fruits/p-value|\n|---|---|---|---|---|\n|P-GLM |2.493|0.032|6.203|0.065|\n|PN-GLM|6.695|0.001|5.953|0.138|\n|PG-GLM|6.689|0.001|5.954|0.138|\n|N-NN  |2.492|0.065|7.128|0.001|\n|NF-NN |2.602|0.080|6.159|0.042|\n|NN-NN |2.473|0.032|6.566|0.003|\n|P-NN  |2.463|0.042|6.234|0.053|\n|PF-NN |2.496|0.007|5.906|0.161|\n|PG-NN |2.427|     |5.901|     |\n\nFurthermore, for handling extremely high-cardinality categorical features, it has been acknowledged that the random effect models have less degrees of freedom (less model complexity) than the fixed effect models [8, Chapter 6.5]. We presented an experiment with $q_{train}$ varying from 1 to 20 $(N=1,000 \\sim 20,000)$. Figure 4 in Section 5 shows the average RMSPEs and computing times of standard PF-NN and the proposed PG-NN from 100 repetitions. The proposed PG-NN requires less computation time, while maintaining smaller RMSPE than standard PF-NN.\n\n* [Figure 4 (Link)](https://i.imgur.com/7YNF1xi.png)\n\n\n### **Feature selection and L1-penalty**\n\nDue to page limitations, Figure 4 in the initial submission was moved to Figure 6 in Appendix A.5. This figure illustrates the average of the feature importance for 100 repetitions to summarize all the results. Figure 5 in Appendix A.5 shows the attention scores from one repetition, and we can recognize this attention-based feature selection can achieve the sparsity. \n\nSince the L1-penalty promotes sparsity by pushing the less important weights of a neural network towards zero, it induces sparsity in the solution of weights rather than in features. Therefore, the L1-penalty could be helpful for achieving the sparsity of individual weight, but in different context from the sparsity of an input feature itself, i.e., exclusion of all the weights from that feature. \n\nAdditionally, we implemented the permutation importance for feature selection and added the result in Appendix A.5.\n\n### **Comparison with \\texttt{hglm} package in R**\n\nActually, we tried hglm package in R for fitting PG-GLM, but we did not present it because it encountered the singularity problems. Furthermore, the hglm package cannot provide the MLE, because it uses Laplace approximation [3], whereas the new h-likelihood can provide the MLE without using any approximation.\n\n### **Scenario with N$(\\lambda)$**\nSince the random effect is unobserved, the distributional assumption for random effects is often hard to check in practice. Thus, it is important to show that our PG-modeling is robust against misspecification of random effect distribution. We considered the case where $v_i \\sim N(0,\\lambda)$ is the true distribution, which is one of the commonly used assumptions for random effects."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9157/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700497131816,
                "cdate": 1700497131816,
                "tmdate": 1700664113740,
                "mdate": 1700664113740,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "AANLzMRhY9",
                "forum": "0xLWPdObG1",
                "replyto": "y1Bwe87R22",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9157/Reviewer_HXxH"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9157/Reviewer_HXxH"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors' Response"
                    },
                    "comment": {
                        "value": "I thank the authors for their response, the additional materials provided as well as clarifying various aspects of their work. A couple of follow-up questions (if time still allows to answer):\n\n- Q1:\n    1. Does it really make a difference if it is a linear model or an NN? The two parts are additive (on the predictor level) and one (the random effect part) assumes a simple structure with mean of zero / of one. This identifiability problem is always present as long as you don't orthogonalize the two parts. Imho, it is the same problem as in generalized additive models, where the intercept is not identifiable without constraints. And then, per definition, anything that deviates from the mean assumption will decrease the \"prior probability\". \n    2. Correct. My proposed approach is different from the authors' approach, but it will ensure that the second term on the RHS of (2) in the paper is zero mean in sum and hence the NN part will capture the intercept If I am not mistaken. (Just as a side note)\n- Q2: \n    > Bold face stands for vectors and matrices and non-bold face stands for scalars.\n\n    Right. I was just mentioning this as a friendly pointer on areas where things can be improved -- because you actually did not use it consistently throughout the paper IIRC.\n\n    > [...]  As far as we know, this is conventional notation in statistics.\n\n    Again, just a friendly pointer. I would consider myself a statistician and I found it confusing / usually read papers that make it (more) explicit.\n\n\n    It also seems that the authors have missed or misunderstood my question to explain the idea of the different likelihoods in Section 3 (\"why to align the two log-likelihoods\"). \n\n- Other comments:\n\n    > With the new h-likelihood, our procedure is better than hglm package in R.\"\n\n    That seems like a bold claim without any empirical evidence. Does this have theoretical justificiation?"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9157/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700597756155,
                "cdate": 1700597756155,
                "tmdate": 1700597756155,
                "mdate": 1700597756155,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "AY6sqdx6Bx",
                "forum": "0xLWPdObG1",
                "replyto": "RMHQg1wNrh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9157/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9157/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your prompt feedback. Regarding your additional questions, we have prepared the following responses.\n\n### **Question 1**\n\n#### **On the adjustment**\n\n(1) In linear models under the assumption $\\text{E}(u_i)=1$, the random effect predictors automatically satisfy $\\bar{u} = \\sum_{i=1}^{n} \\widehat{u}_i/n = 1$, since we achieve the global optimum. Thus, the adjustment and Theorem 1 would not be necessary for linear models. However, since we may not achieve the global optimum in DNNs, we introduced the adjustment to give $\\bar{u}=1$.\n\nAs you mentioned, the adjustment does not change $\\widehat{\\mu}_{ij}^c$, but it changes the loss function (negative h-likelihood). During training, it influences the estimate of the variance component $\\lambda$, which in turn affects the predictions of random effects.\n\n(2) We believe that your idea, using \n$\\tilde{\\mathbf{Z}}=\\mathbf{Z}-\\mathbf{1}_n\\mathbf{1}_n^T/n,$\nwould be useful under the assumption $\\text{E}(v_i)=0$, \nwhich is commonly assumed for normal random effects. \nHowever, for gamma random effects, we assume $\\text{E}(u_i)=\\text{E}(e^{v_i})=1$ in our PG modeling. \n\n* When $\\text{E}(u_i)=1$, the fixed part can give the marginal mean,\n$$\n\\text{E}(y_{ij}) = \\mu_{ij}^m = \\exp [ \\text{NN}(\\mathbf{x}_{ij}; \\mathbf{w}, \\boldsymbol{\\beta}) ],\n$$\nas derived in Section 2.2. \n\n* On the other hand, when $\\text{E}(v_i)=0$, the distribution of $u_i$ becomes\n$$\nu_i \\sim \\text{Gamma}\\left(\\alpha, e^{\\psi(\\alpha)}\\right),\n$$ \nwith $\\text{E}(u_i)=\\alpha e^{-\\psi(\\alpha)}$ and $\\text{var}(u_i)=\\lambda=\\alpha e^{-2\\psi(\\alpha)}$,\nwhere $\\psi(\\cdot)$ is the digamma function and $\\alpha>0$, so that the marginal mean becomes\n$$\n\\text{E}(y_{ij}) = \\mu_{ij}^m = \\exp [ \\text{NN}(\\mathbf{x}_{ij}; \\mathbf{w}, \\boldsymbol{\\beta})] \\cdot \\alpha e^{-\\psi(\\alpha)},\n$$\nwhich depends on $\\alpha$.\n\n#### **On the identifiability**\n\nFor the identifiability problem, we regarded the last hidden layer of NN as given covariates, hence we simply adapted the results in HGLMs (Lee et al., 2017). It is worth noting that the identifiability of random effects has quite different nature from that of fixed effects. For example, consider a linear model,\n$$\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{X}\\boldsymbol{\\gamma} + \\mathbf{e},\n$$\nwhere $\\mathbf{y}=(y_1, ..., y_N)^T$ is the response variable, $\\mathbf{X}=(\\mathbf{x}_1,...,\\mathbf{x}_N)^T$ is the model matrix, $\\mathbf{e} \\sim N(\\mathbf{0}, \\sigma^2 \\mathbf{I})$ is the random noise, $\\boldsymbol{\\beta}$ and $\\boldsymbol{\\gamma}$ are two different fixed effects. Then, the fixed effects $\\boldsymbol{\\beta}$ and $\\boldsymbol{\\gamma}$ are not identifiable, so the orthogonality condition is required for the identifiability of $\\boldsymbol{\\beta}$. On the other hand, if we consider the following model,\n$$\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{X}\\mathbf{v} + \\mathbf{e},\n$$\nwhere $\\mathbf{v}\\sim N(\\mathbf{0}, \\lambda \\mathbf{I})$ is normal random effects, then the fixed effect $\\boldsymbol{\\beta}$ is identifiable since $\\widehat{\\mathbf{v}} = \\mathbf{0}$. Therefore, for the identifiability of random effects and related orthogonalization methods, a more thorough discussion in future research would be beneficial. We greatly appreciate your introduction of this interesting topic."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9157/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700663853879,
                "cdate": 1700663853879,
                "tmdate": 1700664082509,
                "mdate": 1700664082509,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IBznluHHjN",
                "forum": "0xLWPdObG1",
                "replyto": "7B9inHy71m",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9157/Reviewer_HXxH"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9157/Reviewer_HXxH"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for the quick reply and clarifications! I understand now (I think) what the purpose of your way of adjustment $u$ and $\\beta_0$ is. I will rethink all my points of criticism once again and take a look at the new results with a bit more time during the reviewer discussion phase."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9157/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700683496749,
                "cdate": 1700683496749,
                "tmdate": 1700683496749,
                "mdate": 1700683496749,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "F05flpNYQs",
            "forum": "0xLWPdObG1",
            "replyto": "0xLWPdObG1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9157/Reviewer_ZRFo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9157/Reviewer_ZRFo"
            ],
            "content": {
                "summary": {
                    "value": "This paper essentially extends subject-specific predictions to Poisson DNNs. It introduces Gamma random effects into Poisson DNNs and proposes a novel learning framework that can be applied when high-cardinality categorical features are present.  The experimental results across synthetic and real-world data suggest that in certain scenarios, employing this framework can yield advantageous results."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1) The theory checks out and the introduction of a method that simultaneously yields maximum likelihood estimators for fixed parameters and best unbiased predictors for random effects for Poisson DNNs is a valuable contribution.\n2) The feature selection process for high cardinality categorical features is interesting and has valuable practical implications."
                },
                "weaknesses": {
                    "value": "1) The synthetic experiments are rather limited. I would like to see how certain hyperparameters affect the experiments. For example, for any $x_{ij}$ only 5 features are chosen from an AR(1) process, is this choice standard? Why is the AR(1) process considered?\n2) The improvements are marginal across both synthetic and real-world experiments."
                },
                "questions": {
                    "value": "1) Could you please provide more examples of why Poisson DNN modelling might be advantageous compared to previous methods, especially in real-world experiments that you have considered?\n2) At some point, after running a set of synthetic experiments, it is claimed that \u201cTherefore, the proposed method enhances subject-specific predictions as the cardinality of categorical features becomes high.\u201d However, this claim seems rather premature especially since only $q_{train} = 3$ and $q_{train} = 1$ have been considered. Could you please provide the RMSPE of PF-NN and PG-NN on a line chart where different values of $q_{train}$ are considered? This is needed to fully validate such a claim."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9157/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698813291254,
            "cdate": 1698813291254,
            "tmdate": 1699637152045,
            "mdate": 1699637152045,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4zMPZS3Y7F",
                "forum": "0xLWPdObG1",
                "replyto": "F05flpNYQs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9157/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9157/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ZRFo"
                    },
                    "comment": {
                        "value": "Thank you for your valuable feedback on our paper. We greatly appreciate your advice, which have contributed to enriching the content of our work. We have prepared responses for your questions and revised our manuscript. We supplemented our experimental studies with increasing sample size in Section 5 and permutation importance in Section 4.4 and Appendix A.5. We provided p-values from Wilcoxon signed-rank test for comparing RMSPEs in experimental studies and real data analyses. It has been our pleasure to improve our manuscript, and we hope it also meets with your approval.\n\n### **Weakness 1**\n\nIt is common in statistical literature to generate input features from AR(1) to exhibit the multicollinearity among them [1-3]. Though we could not investigate the impact for each hyperparameter, we tried to present various scenarios as possible, including the model misspecification, such as N(0.5) and N(1). \n\n\n### **Weakness 2**\n\nMany thanks for a nice comment. For a statistical test, we performed the Wilcoxon signed-rank test for the RMSPEs, which is widely-used for comparing the prediction errors [4-6].\n* In experimental studies, PG-NN outperforms the other models with p-value$<$0.001 in all scenarios except for G(0), with the absence of random effects. In this case, P-NN performs the best.\n* Following Tran et al. [3, Section 6.2.4], we did not consider the cross-validation for longitudinal data (Epilepsy, CD4, Bolus), because the last observations (test data) were predicted by training the past data for each subject. For clustered data (Owls, Fruits), we present the average of RMSPEs from 10-fold cross-validation with the p-values from Wilcoxon signed rank test. The following table (Table 3 in Appendix A.6) shows the mean RMSPEs and p-values for testing whether the RMSPE of PG-NN is less than that of other methods. (Hence the p-value for PG-NN itself is not included in this table.) In Owls data, though the p-values are marginal (0.05$\\sim$0.1) in some cases, the proposed PG-NN significantly (p-value$<$0.05) outperforms the other methods. In Fruits data, the PG-NN has the smallest RMSPEs but the difference is not significant except for N-NN and NN-NN. Note here that the P-GLM was the best in Fruits data without cross-validation, but the cross-validation clarifies that the PG-NN has better overall RMSPE.\n\n|Model|Owls/RMSPE|Owls/p-value|Fruits/RMSPE|Fruits/p-value|\n|---|---|---|---|---|\n|P-GLM |2.493|0.032|6.203|0.065|\n|PN-GLM|6.695|0.001|5.953|0.138|\n|PG-GLM|6.689|0.001|5.954|0.138|\n|N-NN  |2.492|0.065|7.128|0.001|\n|NF-NN |2.602|0.080|6.159|0.042|\n|NN-NN |2.473|0.032|6.566|0.003|\n|P-NN  |2.463|0.042|6.234|0.053|\n|PF-NN |2.496|0.007|5.906|0.161|\n|PG-NN |2.427|     |5.901|     |\n\n### **Question 1**\n\nPoisson DNN is an extension of Poisson GLM (a standard regression model for count data) to highly non-linear model structures. The use of OLS for log-transformed count data is not satisfactory for analysis [7]. Though it was challenging to acquire large-sized datasets due to their confidential nature, count data are common in many domains since they reflect the number of occurrences of an outcome variable measured in unit period, area or volume. Here are some examples of application data: microbiome count data, CD4 count data, pandemic mortality data, insurance data, etc [8-12].\n\n### **Question 2**\n\nThank you for valuable comments. We presented an experiment with $q_{train}$ varying from 1 to 20 $(N=1,000 \\sim 20,000)$. Figure 4 in Section 5 shows the average RMSPEs and computing times of standard PF-NN and the proposed PG-NN from 100 repetitions. The proposed PG-NN requires less computation time, while maintaining smaller RMSPE than standard PF-NN.\n\n* [Figure 4 (Link)](https://i.imgur.com/7YNF1xi.png)"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9157/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700495781013,
                "cdate": 1700495781013,
                "tmdate": 1700495948216,
                "mdate": 1700495948216,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bj1lRXSzNG",
                "forum": "0xLWPdObG1",
                "replyto": "F05flpNYQs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9157/Reviewer_ZRFo"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9157/Reviewer_ZRFo"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the reply"
                    },
                    "comment": {
                        "value": "Thank you for your detailed reply and for conducting the additional experiments using a real-world example. These efforts have significantly enhanced my understanding and appreciation of your work. With these new insights, I am now more convinced of the value that your paper contributes to the field."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9157/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700675410958,
                "cdate": 1700675410958,
                "tmdate": 1700675410958,
                "mdate": 1700675410958,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "mAACpDtX6p",
            "forum": "0xLWPdObG1",
            "replyto": "0xLWPdObG1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9157/Reviewer_z2gb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9157/Reviewer_z2gb"
            ],
            "content": {
                "summary": {
                    "value": "Here the authors presents a novel framework that merges hierarchical likelihood learning with Poisson-gamma Deep Neural Networks. This approach aims to better handle clustered count data by incorporating both fixed and random effects into the model. A proposed two-phase training algorithm is aimed at improving model performance. The proposed method is evaluated on both simulated data and real data where it is compared to existing methods, various types of DNNs and GLMs."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper introduces a novel Poisson-gamma Deep Neural Network (DNN) and supports it with a robust mathematical foundation. This includes deriving h-likelihood functions and addressing identifiability issues, which demonstrates a high level of theoretical rigour.\n- Incorporation of Random Effects: The model incorporates both fixed and random effects into a deep learning framework, aiming to capture both marginal and subject-specific variations in count data. This is particularly useful for applications where understanding both population and subject-specific trends is crucial such as in healthcare or social sciences.\n- Two-Phase Training: The paper proposes a comprehensive two-phase training algorithm that focuses on both pretraining and fine-tuning of the model parameters. This adds to the model's could potentially improve its generalisation to unseen data.\n- The motivation is well founded and I believe it would be of relevance to the ICLR community."
                },
                "weaknesses": {
                    "value": "- The largest weakness is the unconvincing experimental result. They do not confirm fully confirm the advantages of the method (as claimed in the abstract). The distribution of the multiple runs on simulated data does not show obviously outperformance of this method compared to the others. It would have been interesting to see a statistical test of difference performed here.\n- Related to the previous point, results on real datasets are presented without any replications or multiple runs. No errors are shown in table  2 making it very hard to judge the importance of the values. It should not be terrible expensive to perform multiple runs on these relatively small datasets. It would also have been very interesting to see this method applied to much larger datasets.\n- The feature importance experiment (Figure 4) is valuable but I feel that it lacks context when not presented with more standard feature importance methods (e.g. permutation importance). I understand these are simulations with a pre-determined ground truth but contrasting this new method with a well-understood method would be a welcome addition to help better showcase the relative properties of this method.\n- Although the two-phase training can bring benefits, as set out in the paper, it is also important to understand the cost that comes with it. A clear comment from the authors on the absolute and relative efficiency (or better, computational cost per training compared with other methods) would be a very useful addition from practical standpoint. Without one, the reader is left wondering if this truly is practical."
                },
                "questions": {
                    "value": "- Spelling: e.g. in 4.2 \"In contrast to HGLM and DNN\" should be HGLMs and DNNs\n- What is the early stopping method used for the experiments? Is it the same for pre-training and training?\n- The method does not perform as well as PG-GLM on the fruits dataset but better on the others. Do the authors have any hypotheses as to why that is the case? What is different about these datasets?\n- How do the authors envision the scalability of the proposed framework when dealing with extremely large datasets, particularly in medical and health applications?\n- Could this method be extended to a larger framework to include other types of random effects distributions beyond the gamma distribution?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9157/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698832419154,
            "cdate": 1698832419154,
            "tmdate": 1699637151941,
            "mdate": 1699637151941,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "89QpCzswXi",
                "forum": "0xLWPdObG1",
                "replyto": "mAACpDtX6p",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9157/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9157/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer z2gb"
                    },
                    "comment": {
                        "value": "We greatly appreciate your nice comments on our paper. We have prepared responses for your questions and revised our manuscript. We supplemented our experimental studies with increasing sample size in Section 5 and permutation importance in Section 4.4 and Appendix A.5. We provided p-values from Wilcoxon signed-rank test for comparing RMSPEs in experimental studies and real data analyses. We are pleased to strengthen our paper, and we hope it is satisfactory for you too.\n\n### **Weakness 1 and 2**\n\nFor a statistical test, we performed the Wilcoxon signed-rank test for the RMSPEs, which is widely-used for comparing the prediction errors [1-3].\n\n* In experimental studies, PG-NN outperforms the other models with p-value$<$0.001 in all scenarios except for G(0), with the absence of random effects. In this case, P-NN performs the best.\n* Following Tran et al. [4, Section 6.2.4], we did not consider the cross-validation for longitudinal data (Epilepsy, CD4, Bolus), because the last observations (test data) were predicted by training the past data for each subject. For clustered data (Owls, Fruits), we present the average of RMSPEs from 10-fold cross-validation with the p-values from Wilcoxon signed rank test. The following table (Table 3 in Appendix A.6) shows the mean RMSPEs and p-values for testing whether the RMSPE of PG-NN is less than that of other methods. (Hence the p-value for PG-NN itself is not included in this table.) In Owls data, though the p-values are marginal (0.05$\\sim$0.1) in some cases, the proposed PG-NN significantly (p-value$<$0.05) outperforms the other methods. In Fruits data, the PG-NN has the smallest RMSPEs but the difference is not significant except for N-NN and NN-NN. Note here that the P-GLM was the best in Fruits data without cross-validation, but the cross-validation clarifies that the PG-NN has better overall RMSPE.\n\n|Model|Owls/RMSPE|Owls/p-value|Fruits/RMSPE|Fruits/p-value|\n|---|---|---|---|---|\n|P-GLM |2.493|0.032|6.203|0.065|\n|PN-GLM|6.695|0.001|5.953|0.138|\n|PG-GLM|6.689|0.001|5.954|0.138|\n|N-NN  |2.492|0.065|7.128|0.001|\n|NF-NN |2.602|0.080|6.159|0.042|\n|NN-NN |2.473|0.032|6.566|0.003|\n|P-NN  |2.463|0.042|6.234|0.053|\n|PF-NN |2.496|0.007|5.906|0.161|\n|PG-NN |2.427|     |5.901|     |\n\nWe are willing to try with much larger real datasets, such as microbiome data and pandemic mortality data [5-9], but they were not open in public. Thus, in Section 4.4, we presented an experiment with $N=200,000$ and $p=100$. Average computing time for this experiment was about 30 minutes, which implies that the model can be applied to much larger datasets.\n\n### **Weakness 3**\n\nWe used the attention-based feature selection method to show that the proposed method can be adapted for various state-of-the-art neural network architectures. More standard feature importance methods can also be implemented to the proposed framework. Following your advice, we implemented the permutation importance method to our experiment in Section 4.4. Both the attention-based feature selection and permutation importance can identify the genuine features from the irrelevant features. The main difference between them is that the attention-based feature selection can achieve sparsity during training by using the sparsemax transformation, whereas the permutation importance is a post-hoc procedure which is calculated after the model has been fitted. Figures 7 and 8 in Appendix A.5 show the attention scores and permutation scores from one repetition, respectively. (Due to page limitations, Figure 4 in the initial submission was moved to Figure 6 in Appendix A.5, which shows the average of 100 repetitions to summarize all the results.)\n\n* [Figure 7 (Link)](https://i.imgur.com/Bya8aXy.png)\n\n* [Figure 8 (Link)](https://i.imgur.com/aAZASSR.png)\n\n### **Weakness 4 and question 3**\n\nWe presented an experiment with $q_{train}$ varying from 1 to 20 $(N=1,000 \\sim 20,000)$. Figure 4 in Section 5 shows the average RMSPEs and computing times of standard PF-NN and the proposed PG-NN from 100 repetitions. The proposed PG-NN requires less computation time, while maintaining smaller RMSPE than standard PF-NN.\n\n* [Figure 4 (Link)](https://i.imgur.com/7YNF1xi.png)\n\nThe experiment in Section 4.4 with N=200,000 and p=100 shows that the proposed method takes average 30min for each repetition. Furthermore, for handling extremely high-cardinality categorical features, it has been acknowledged that the random effect models have less degrees of freedom (less model complexity) than the fixed effect models [10, Chapter 6.5]. Thus, though we did not analyze such extremely large datasets, we expect that our framework is suitable to such large datasets."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9157/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700495228900,
                "cdate": 1700495228900,
                "tmdate": 1700496056872,
                "mdate": 1700496056872,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3UTLQ2FBxg",
                "forum": "0xLWPdObG1",
                "replyto": "89QpCzswXi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9157/Reviewer_z2gb"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9157/Reviewer_z2gb"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for responding to my points. In particular, the statistical tests provide much stronger evidence of the claims made. Including these results in the appendix is a positive addition to the paper."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9157/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700734870334,
                "cdate": 1700734870334,
                "tmdate": 1700734870334,
                "mdate": 1700734870334,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]