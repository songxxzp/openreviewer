[
    {
        "title": "Causal Influence-Aware Counterfactual Data Augmentation"
    },
    {
        "review": {
            "id": "5Gai7iBPRt",
            "forum": "AMCaG2TAeg",
            "replyto": "AMCaG2TAeg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7407/Reviewer_LtoA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7407/Reviewer_LtoA"
            ],
            "content": {
                "summary": {
                    "value": "This paper emphasizes the importance of allowing learning agents to generalize to various situations, rather than being constrained by limited demonstrations. In real-world scenarios, the combinatorial complexity necessitates a significant amount of data to prevent neural network policies from relying on non-causal factors. Therefore, the authors propose CAIAC, a data augmentation method that generates synthetic samples from a fixed dataset without requiring new interactions with the environment. This method is inspired by the idea that an agent can only change its environment through actions. Hence, parts of the state space that are unaffected by actions are swapped from different trajectories in the dataset. The paper utilizes Causal Action Influence\" (CAI) to identify action-independent entities and then swap states of these entities from other observations in the dataset. The introduction highlights the potential of teaching robots using demonstrations and datasets, which is a promising approach for developing competent robotic assistants."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The idea of using local independence to do counterfactual data augmentation is neat and interesting. As there could exist many spurious correlations during the offline data collection process, counterfactual data augmentation is important for breaking the spurious correlation.\n\n2. The paper is well-written and easy to follow. The formulation of the problem and the proposed method is clear."
                },
                "weaknesses": {
                    "value": "1. If I understand correctly, a strong underlying assumption of the proposed method is that the swapped states are irrelevant to the goal state. In the experiment part, the authors mention that \u201cwe initialize all non-target entities (with p = 0.5) to a random state\u201d, which is why I think there exists such an assumption. This assumption is required since local independence does not imply the dependency between the current state and the goal state. This assumption is fine if the task is simple and the horizon is short. However, if the task is long-horizon and the later sub-tasks require some pre-conditioned to be satisfied, the local independence may not always be true. \n\n2. Another assumption of the method is the fixed factorization of the state space, which may not be available in most real-world tasks. Determining which variable to be abstract from raw sensors may limit the usage of this method. \n\n3. Missing related literature on causal reinforcement learning [1-11].\n\n4. Using counterfactual data augmentation to improve RL algorithms has been investigated a lot in previous work. CoDA is an important work but cannot cover all existing baselines. The authors may need to add more baselines to show fair comparison, for example [1, 2, 4, 7, 9].\n\n\n---\n[1] Pitis, S., Creager, E., Mandlekar, A., & Garg, A. (2022). Mocoda: Model-based counterfactual data augmentation. NeurIPS 2022\n\n[2] Lu, C., Huang, B., Wang, K., Hern\u00e1ndez-Lobato, J. M., Zhang, K., & Sch\u00f6lkopf, B. (2020). Sample-efficient reinforcement learning via counterfactual-based data augmentation. arXiv preprint arXiv:2012.09092.\n\n[3] Ding, W., Lin, H., Li, B., & Zhao, D. (2022). Generalizing goal-conditioned reinforcement learning with variational causal reasoning. NeurIPS 2022\n\n[4] Ding, W., Shi, L., Chi, Y., & Zhao, D. (2023). Seeing is not believing: Robust reinforcement learning against spurious correlation. NeurIPS 2023\n\n[5] Wang, Z., Xiao, X., Xu, Z., Zhu, Y., & Stone, P. (2022). Causal dynamics learning for task-independent state abstraction. ICML 2022\n\n[6] Ke, N. R., Didolkar, A., Mittal, S., Goyal, A., Lajoie, G., Bauer, S., ... & Pal, C. (2021). Systematic evaluation of causal discovery in visual model-based reinforcement learning. arXiv preprint arXiv:2107.00848.\n\n[7] Lyle, C., Zhang, A., Jiang, M., Pineau, J., & Gal, Y. (2021). Resolving causal confusion in reinforcement learning via robust exploration. In Self-Supervision for Reinforcement Learning Workshop-ICLR (Vol. 2021).\n\n[8] Zhang, A., Lyle, C., Sodhani, S., Filos, A., Kwiatkowska, M., Pineau, J., ... & Precup, D. (2020, November). Invariant causal prediction for block MDPs. ICML 2020\n\n[9] Zhang, A., McAllister, R., Calandra, R., Gal, Y., & Levine, S. (2020). Learning invariant representations for reinforcement learning without reconstruction. ICLR 2021\n\n[10] Gasse, M., Grasset, D., Gaudron, G., & Oudeyer, P. Y. (2021). Causal reinforcement learning using observational and interventional data. arXiv preprint arXiv:2106.14421.\n\n[11] Buesing, L., Weber, T., Zwols, Y., Racaniere, S., Guez, A., Lespiau, J. B., & Heess, N. (2018). Woulda, coulda, shoulda: Counterfactually-guided policy search. ICLR 2019"
                },
                "questions": {
                    "value": "1. The analysis of the failure cases in Table 1 is missing. The proposed method does not have an improvement in the last three tasks (i.e., Slide cabinet, Light switch, Hinge cabinet). I also observe such a performance drop in Figure 5. According to the design of the spurious correlation, I expect that the proposed method should generally work for all tasks. Could the authors explain the reasons for the failure?\n\n2. In Section 5.2, the authors explore a goal-conditioned task. One question about the results is the statement \u201cAll methods perform similarly, given that there is enough coverage of the state space in the original dataset.\u201d. It looks like the proposed method is the worst among all four methods. I don\u2019t think the gap between CAIAC and No Aug. is caused by randomness. Usually, using data augmentation will not harm the performance. Could the authors provide some explanations? Is this related to the first point of the weakness part of my review?\n\n3. Still in Section 5.2, the statement \u201cthe transformer model is able to discover the causal graph and creates realistic counterfactuals\u201d is not supported by any evidence. \n\n4. Could the authors provide a detailed comparison between CAIAC and CoDA? I think these two methods have very similar ideas but with different implementations. CoDA may suffer the problem of data scarcity for training a good transformer, but generally, what is the main advantage of using CAI to identify local independence?\n\n5. \u201cFor Fetch-Push we set \u03b8 = 0.1, and \u03b8 = 0.3 for Franka-Kitchen.\u201d How do you select the parameter \u03b8?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7407/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698619158506,
            "cdate": 1698619158506,
            "tmdate": 1699636888076,
            "mdate": 1699636888076,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1KPFl7q5vm",
                "forum": "AMCaG2TAeg",
                "replyto": "5Gai7iBPRt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7407/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7407/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer LtoA (Part 1)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their valuable feedback. We first address the points under weaknesses and then answer the reviewer\u2019s questions. We address weaknesses with W# and questions with Q#. \n\n\n**W1: Assumption about independence swapped states and goal states:** \n\nWe thank the reviewer for spotting a lack of detail in the manuscript. We would like to further elaborate on this point.\n\nWe agree that in cases where demonstrations were provided to achieve desired goals, augmentations to a given state should be irrelevant to the goal that the trajectory achieves. In the Franka-Kitchen environment, we use the intersection of the uncontrollable sets along extended time windows, which excludes intermediate and final entities under influence that are potentially relevant for the demonstration. This is described in Equation 5) of the manuscript. We added a reference to section 3.3 as well.\n\nIn addition, all three experiments (Franka-Kitchen, Fetch-Push and Fetch-Pick&Lift) rely on self-supervised goals: the training data does not provide an explicit goal space, nor desired goals per trajectory. For each experiment, goals for counterfactual states are relabeled by either sampling the final state of the skill (Franka-Kitchen), a random state from any trajectory (Fetch-Push), or a future state within the trajectory (Fetch-Pick&Lift). In any of these cases, as long as all trajectories are augmented before goal sampling, no assumption on independence between desired goals and states is necessary. We added clarifications on goal sampling in the updated manuscript (see Section 5.2,  A.1.1 and A.2.1).\n\nMoreover, to the best of our knowledge, the issue of dependence between states and goals is also less of a concern when performing offline reinforcement learning with goal relabeling (as done in Fetch experiments). In this case, a reward function can be used to evaluate success (as done in HER [F1]). Thus, a given trajectory does not need to successfully achieve its goal (in other words, the dependency between states and goals does not need to hold).\n\nTherefore, in Fetch experiments, the joint distribution over states and goals at training time only needs to assign a significant probability mass to state-goal pairs observed at test time. As goals are relabeled from augmented states, improved coverage over the joint state space at training time also results in improved coverage over the joint goal space. Finally, coverage over the space of state-goal pairs can be controlled through the relabeling strategy.\n\n[F1] Andrychowicz, Marcin, et al. \"Hindsight experience replay.\" Advances in neural information processing systems 30 (2017)."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7407/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700685910377,
                "cdate": 1700685910377,
                "tmdate": 1700686141347,
                "mdate": 1700686141347,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "16RxdgW3aL",
            "forum": "AMCaG2TAeg",
            "replyto": "AMCaG2TAeg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7407/Reviewer_1iyX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7407/Reviewer_1iyX"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes CAIAC, a novel counterfactual data augmentation technique that generates additional data by swapping causally \u201caction-unaffected\u201d state dimensions of different transitions. CAIAC identifies action unaffected state dimensions using a Causal Action Influence (CAI) metric. Empirically, CAIAC outperforms other counterfactual data augmentation techniques (CoDA and CoDA-ACTION, sort of interpolation between CAIAC and CoDA) on offline Franka Kitchen tasks and a two-block FetchPush task."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. The topic of counterfactual data augmentation is of general interest to the RL community, as many real-world tasks have local causal structures (as noted in the paper).\n2. The paper is well-motivated, and I found the description of local causal models easy to follow."
                },
                "weaknesses": {
                    "value": "1. There seems to be a fine distinction between CAIAC, CoDA, and CoDA-ACTION that that isn\u2019t quite clear to me. My understanding is as follows:\n* CoDA uses a learn local causal model (or a hard-coded heuristic) to identify locally independent state dimensions and then generates augmented transitions by swapping the locally independent state dimensions of observed transitions. The resulting augmented transitions.\n* CAIAC is identical to CoDA but uses a CAI metric to identify locally independent state dimensions.\n* I could not understand the difference between CoDA and CoDA-ACTION.\n\n\n  I hope the authors can clear up my confusion on this matter. If my current understanding of CAIAC vs CoDA is correct, then algorithmic contribution of this work is limited. In any case, a figure that clearly illustrates the difference between CoDA, CODA-ACTION, and CAIAC would be immensely helpful towards understanding (1) the CAIAC algorithm and (2) the novelty of this work. It would also be helpful if the authors evaluated these algorithms on a simple, didactic toy task like the SpriteWorld task used CoDA.\n    \n2. Empirical results seem weak. In Table 1, CAIAC outperforms baselines with obvious significance in 3/6 tasks (Kettle, Microwave, Bottom-burner), and struggles in the remaining 3 tasks (Slide Cabinet, Light Switch, Hinge Cabinet). Since the algorithmic contribution seems limited, I would like to see CAIAC evaluated on additional tasks -- tasks that show some learning progress with CAIAC and in an online learning setting. Some possible tasks: FetchSlide, FetchPickAndPlace, FetchStack, or the analogous PandaGym tasks. \n\n3. The paper states that CoDA and CODA-ACTION are (1) unable to recover the correct causal graph and (2) create dynamically infeasible data which harms performance, but there is no empirical evidence to support this claim. Given a dataset of augmented transitions {(s, a, r, s')}, the authors might consider validating claim (2) by initializing simulation to s, taking action a, and then checking if s' equals the simulators true next state. Then we could compute the probability that each algorithm generates feasible data and see if CoDA and CoDA-ACTION are more likely to generate such data than CAIAC. Claim (1) would then follow immediately -- if an algorithm generates a relatively large amount of infeasible data, then it surely has the wrong causal model. \n\n1. It\u2019s not immediately clear what CAIAC is doing from Figure 1. I suggest explicitly stating in caption or the figure itself what is being swapped and what augmented data is generated.\n\nOther comments:\n\n1. I found Figure 6 to be quite helpful in understanding the CAI scores. If possible, this figure would be a nice addition to the main paper.\n\n2. When describing the local causal structure in the chosen benchmark tasks, it may be beneficial to concretely describe the structure. In particular, the agent's actions only affect an object if the agent is in contact with the object.\n\n3. The authors may find the following references particularly relevant to this work:\n* MoCoDA [1] is an extension of CoDA that enables a user to control the distribution of augmented data.\n* GuDA [2] is a framework for generating expert-quality augmented data.\n\n[1] MoCoDA: Model-based Counterfactual Data Augmentation. Pitis et. al, NeurIPS 2022.\n\n[2] Corrado & Hanna. Guided Data Augmentation for Offline Reinforcement Learning and Imitation Learning. arXiv:2310.18247"
                },
                "questions": {
                    "value": "1. In the weaknesses section, I suggested additional online RL experiments. CAIAC, like CoDA, can be used in online learning too, correct?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7407/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7407/Reviewer_1iyX",
                        "ICLR.cc/2024/Conference/Submission7407/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7407/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698774106028,
            "cdate": 1698774106028,
            "tmdate": 1699642739407,
            "mdate": 1699642739407,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "EEGTZf7MfB",
                "forum": "AMCaG2TAeg",
                "replyto": "16RxdgW3aL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7407/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7407/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1iyX (Part 1)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their valuable feedback. We first address the points under weaknesses and then answer the reviewer\u2019s questions. We address weaknesses with W# and questions with Q#. \n\n\n**W1: Distinction between CAIAC, CoDA, and CoDA-ACTION.** \n\nThe algorithms differ on two aspects: (1) the extent of causal discovery and (2) the methodology used for causal discovery.\n\nCoDA performs (1) full causal discovery, i.e., it tries to detect influence between all the entities in the causal graph, and (2) uses the attention weights of a trained transformer to infer causation. CoDA-action is a baseline we introduce. It performs (1) partial causal discovery,i.e. it only tries to detect the agent\u2019s action-influence on the entities, and (2) uses the attention weights of a trained transformer to infer causation. Finally, CAIAC performs (1) partial causal discovery and (2) uses state-conditioned mutual information (namely CAI)  to infer causation. The novelty of the method is therefore not limited to the mechanism used to infer causation, but should also include the assumption of sparsity in the causal graph outlined in Section 3.1 of the paper, which motivates partial causal discovery.\n\nWe further demonstrate these differences in the updated version of the paper. In Section A.5 (Figure 7 and 8) we visualize the computed influences for the Fetch-Push task for all the methods: CAIAC influence scores (namely CAI) , CoDA influence scores (namely the transformer\u2019s attention matrix) and the CoDA-action scores (namely the values of the attention matrix that correspond to the row \u201caction\u201d and columns {\u201cobject1, object2 or agent\u201d}). This didactic example displays  how using such an implicit measure to detect influence can lead to misestimation (as in CoDA and CoDA-action), whereas CAIAC is better suited for detecting influence in this setting. \n\nWe updated the text in the updated version of the paper referring the reader to the appendix sections of interest to clarify the points above. \n\n**W2 + W3:  A figure that clearly illustrates the difference between CoDA, CODA-ACTION, and CAIAC [...]  + Simple, didactic toy task like the SpriteWorld task used CoDA**\n\nWe hope that the explanations above helped clarify the distinctions between the different algorithms. We updated the text in the updated version of the paper referring the reader to the appendix where we include the computed influence scores mentioned in the point above. We hope that this scenario with only 3 entities (agent, object 1 and object 2) is already a good didactic example.\n\n**W4: Empirical results seem weak. In Table 1 [...] struggles in the remaining 3 tasks (Slide Cabinet, Light Switch, Hinge Cabinet).** \n\nWe thank the reviewer for suggesting to further elaborate on empirical results. We provide this discussion below, and integrate it in the updated version of the manuscript (Section 5.1.2 and Appendix A.2.1).\n\nAs stated in the paper, \u201cThe results, shown in Table 1, are consistent with the challenging nature of this benchmark, as the evaluated tasks involve OOD settings in terms of states and actions\u201d. More specifically, we found that only a subset of tasks is shown to be performed directly from the initial configuration in the training data. \nIn particular, the training data does not contain state and action trajectories that show how to solve each of the 3 mentioned tasks from the initial robot joint configuration. Instead, these 3 tasks are only demonstrated after solving other tasks, and hence starting from other robot configurations. For this reason, even with perfect counterfactual data augmentation, these tasks remain challenging. \n\nSpecifically, out of the 1200 demonstrations in the dataset, containing different task sequences, only 3 objects are shown to be manipulated from the initial robot configuration: 60% of the trajectories solve the microwave task first, 30% show the kettle task first and 10% show the bottom right burner first. This aligns with the relative performance achieved for those tasks. For the 3 remaining tasks, namely the slide cabinet, the light and the hinge cabinet, there is no demonstration shown directly from the initial configuration, and hence the low performance.\n\n Moreover, we remark that this issue adds up to the OOD nature of states and goals at test time, thus defining a fundamentally challenging benchmark."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7407/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687870441,
                "cdate": 1700687870441,
                "tmdate": 1700687870441,
                "mdate": 1700687870441,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "884aFuSCQY",
                "forum": "AMCaG2TAeg",
                "replyto": "16RxdgW3aL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7407/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7407/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1iyX (Part 2)"
                    },
                    "comment": {
                        "value": "**W5: [...]  would like to see CAIAC evaluated on additional tasks -- tasks that show some learning progress with CAIAC and in an online learning setting [...]** \n\nFollowing reviewer\u2019s suggestions, we added an additional experiment: Fetch-Pick&Lift  with 4 blocks (see Figure 4 right), where there is a mismatch between the empirical joint state distribution in the training data and the joint state distribution at test time. \nOn this task, CAIAC can create useful counterfactual samples and allows  generalization beyond the joint state distribution in the training data, thus outperforming other methods by 60%. The rest of the baselines cannot create the needed counterfactuals and have significantly lower performance.\n\nCAIAC is mainly aimed at settings in which the distribution and quantity of training data cannot be controlled, and distribution mismatch is thus a fundamental issue. While applying CAIAC to the online setting remains possible, the continual collection of on-policy data can already alleviate issues such as spurious correlation in the replay buffer or insufficient coverage of the joint state space. While data augmentation can also be helpful in online learning, we believe that centering our experiments on the offline setting can better isolate the issues the method is tackling, and constitutes a more meaningful benchmark.\n\n**W6: Empirical evidence on quality of counterfactuals** \n\nWe appreciate the reviewer\u2019s nice suggestion since we believe it provides additional empirical support to this work.\nFirst of all, we want to refer the reader to the Section A.4  of the updated version of the paper, where we show the attention weights of the trained transformer (see Figures 7 and 8) to provide evidence of incorrect causal estimation by CoDA and CoDA action. The weights are even unable to recover influence along the diagonal, i.e., that an entity state at time $t+1$ depends on the entity state at time $t$. These visual results give evidence for claim 1).\n\n**Comment 1: I found Figure 6 to be quite helpful in understanding the CAI scores.**\n\nWe appreciate the comment. We added a reference to the figure in the main paper (Section 5.1.2) as well to an additional analogous figure for the Fetch-Push task (see Figure 7 in the Appendix) which also has an added reference in the main paper (see Section 5.2).\n\n**Comment 2: When describing the local causal structure in the chosen benchmark tasks, it may be beneficial to concretely describe the structure. In particular, the agent's actions only affect an object if the agent is in contact with the object.**\n\nWe would like to clarify that through our work we adopt a unified definition of influence: the agent has influence over an entity in a specific state configuration if it can modify the state of the entity at next time step through its actions (see equation 3  for a formal definition). Concretely, in the case of robotic manipulation environments physical contact is not necessary as long as the agent can change the object pose, even if indirectly,  in a single simulation step. We clarified this in the updated version of the manuscript (see Appendix A4).\n\n**Comment 3: Related literature**\n\nWe thank the reviewer for pointing us out to these papers. We will add and discuss the 2 mentioned papers in an extended related work section.\nAfter checking these papers, we would like to mention that [2] was not published yet by the time we submitted our manuscript and will be cited as concurrent work. Furthermore [1] is an interesting follow-up of CoDA but assumes access to the true causal graph, and hence does not address the problem we are tackling.\n\n**Q1: Additional online RL experiment**\n\nPlease see answer to weakness W5 above."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7407/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700688134195,
                "cdate": 1700688134195,
                "tmdate": 1700688187438,
                "mdate": 1700688187438,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2byocuWQ8K",
                "forum": "AMCaG2TAeg",
                "replyto": "16RxdgW3aL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7407/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7407/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1iyX (Part 3)"
                    },
                    "comment": {
                        "value": "**W6: Empirical evidence on quality of counterfactuals (Part 2)**\n\nWe provide an analysis on the created counterfactuals using CAIAC.\nWe visually show how the created augmented samples have an increased support of the joint state space distribution in the kitchen dataset, compared to the No-Augmented baseline.\nIn Figure 12 of the updated manuscript,  we show 1000 randomly selected samples from the Franka-Kitchen dataset together with one counterfactual for each. The visualization employs t-SNE for a 2D representation of the high-dimensional state space. \nWe observe how the augmented samples using CAIAC cover a much larger space than the observed data, suggesting that we are able to provide states with a richer amount of configurations.\nHowever, this does not tell us whether these counterfactuals are actually valid. \nTo quantify whether an augmented datapoint is valid, we do the following:\nWe consider time-windows  $(s_t, \\dots, s_{t+\\tau})$ sampled from the Franka-Kitchen dataset. \nWe create counterfactuals for this window with \\method and CoDA, $(\\tilde s_t, \\dots,\\tilde s_{t+\\tau})$.\nWe reset the simulator to $\\tilde s_t$ and simulate the future with the action sequence in the original trajectory for $\\tau$ steps. \nIf the counterfactual is valid, then resulting state of the simulation should coincide with the counterfactual $\\tilde s_{t+\\tau}$.\nUnfortunately, the simulator is not perfectly deterministic (or we are unable to set the full simulator state), so measuring exact matching states is not possible.\nThus, we run the simulator $K=10$ times with different env-seeds and obtain $\\mathcal S' = [ \\bar s^k_{t+\\tau} ]_{k=1}^K$.\nWe fit a multivariate Gaussian to the set $\\mathcal S'$. \n\nWe now compute the probability of the counterfactual $\\tilde s_{t+\\tau}$ under the Gaussian distribution. High probability means valid counterfacturals, low means invalid.\nIn Figure 13 of the updated manuscript we present the histogram of log probabilities. The counterfactuals by CAIAC are mostly valid, which is not the case for the CoDA baselines."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7407/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700741409909,
                "cdate": 1700741409909,
                "tmdate": 1700741546286,
                "mdate": 1700741546286,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "GuR0lwFin8",
            "forum": "AMCaG2TAeg",
            "replyto": "AMCaG2TAeg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7407/Reviewer_GhVi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7407/Reviewer_GhVi"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a method called Causal Influence Aware Counterfactual Data Augmentation (CAIAC) that addresses the challenge of generalizing robot behaviours to new situations using pre-recorded data and human-collected demonstrations. By swapping causally action-unaffected parts of the state-space from different observed trajectories in the dataset, CAIAC creates feasible synthetic samples without the need for new environment interactions. The experimental results demonstrate the generalization capabilities and sample efficiency of the proposed method."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper proposes a data augmentation method called Causal Influence Aware Counterfactual Data Augmentation (CAIAC) that can create feasible synthetic samples from a fixed dataset without the need for new environmental interactions.\n\n- The paper is well-written and easy to follow.\n\n- The experiments on offline self-supervised skill learning and offline reinforcement learning showcase the effectiveness of the proposed method as some extent.\n\n- The proposed approach is independent and can be used with any learning algorithm."
                },
                "weaknesses": {
                    "value": "- The novelty is limited, drawing heavily on the groundwork laid by Seitzer et al., 2021, for local causal graph estimation and CAI's influence measurement. The conceptual leap from the work of CoDA (Pitis et al., 2020), which also involves counterfactual generation through connected component swapping, to the present technique of swapping uncontrollable subgraphs, seems incremental rather than revolutionary.\n\n- While the paper successfully argues the challenges and pitfalls of complete causal structure estimation, it only partially addresses the performance of CAIAC in high-dimensional, low data regime environments, leaving a gap in the analysis. A more exhaustive exploration of the method's computational demands and scalability would greatly enhance the reader's understanding.\n\n- The experimental comparisons seem to lack a critical control condition \u2014 an alternative method that also augments counterfactual data through local causal structure estimation with CAI but swap the connected components to form new transitions given two transitions that share local causal structures. Including such a benchmark would provide a clearer picture of CAIAC's relative efficacy."
                },
                "questions": {
                    "value": "- Could the authors provide more insight into CAIAC's performance in environments with abundant data? The discrepancy in performance between low and high data regimes in high-dimensional settings warrants further clarification.\n\n- Moreover, could the authors elaborate on the computational complexity and scalability of the CAIAC method, especially in comparison to existing methods?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7407/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699485484626,
            "cdate": 1699485484626,
            "tmdate": 1699636887758,
            "mdate": 1699636887758,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TRnz5oaKAz",
                "forum": "AMCaG2TAeg",
                "replyto": "GuR0lwFin8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7407/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7407/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer GhVi (Part 1)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their valuable feedback. We first address the points under weaknesses and then answer the reviewer\u2019s questions. We address weaknesses with W# and questions with Q#. \n\n**W1: Novelty:** \nTo the best of our knowledge, this is the first proposed method for data augmentation that uses an explicit measure of influence between entities in the environment to create counterfactuals. While CoDA also suggests creating counterfactuals by swapping local independent subgraphs from different transitions, it either relies on hardcoded dependencies, or uses a heuristic upon the attention weights of a transformer world model to infer the local factorization. As we show, such a heuristic is generally not accurate, and leads to the creation of unfeasible augmented samples that hurt performance. In the updated version of the paper, we provide evidence by showing a comparison between the different measures of influence on the Franka Kitchen and Fetch-Push tasks (Section A.4, Figures 6, 7 and 8), and an analysis of the accuracy of influence prediction for CAI and CoDA in Section A.5 (Figures 9,10 and 11) for the Fetch-Push task.\n\n**W2: Performance difference/ gap in analysis**:\nTo rephrase, the reviewer is asking to motivate the difference in performance between CoDA and CAIAC. To analyze this, we designed the baseline CoDA-action, which aims at discovering the same part of the causal structure as CAIAC, but using the aforementioned heuristic of transformer attention weights. The fact that CoDA-action performs comparable to CoDA suggests that the assumption of sparsity in the causal graph is not sufficient, but the more accurate measure of causal influence is crucial. \n\n**W3: Computational demands:**\nCAIAC relies on computing the CAI measure for data augmentation. In turn, CAI can be evaluated for all entities at once, through $k$ forward passes for the $k$ counterfactual actions, which are performed in a batch-wise fashion.\n$k$ is a constant factor, and does not scale with the number of entities.\nMethods relying on a transformer world model, like CoDA and CoDA-action only need one forward pass (which internally has quadratic cost in the number of entities due to cross attention). However, CoDA also needs to compute the connected components from the adjacency matrix, which has a quadratic cost.\nFor relatively few entities, as is common in the robotic manipulation environments, the computational overhead is relatively small.  For the high data regime Fetch-Push environment we timed how long it takes for each algorithm to compute influence on all 2M datapoints: \n\n| Method      | Runtime     |\n|-------------|-------------|\n| CoDA-action | 47 seconds  |\n| CoDA        | ~10 minutes |\n| CAIAC       | ~13 minutes | \n\n\nThe algorithms were benchmarked on a 12-core Intel i7 CPU.\nWe would like to mention that counterfactuals could be generated in parallel to the learning algorithm and hence not significantly impact runtime of the algorithm. Furthermore, in our offline setting, counterfactuals can be fully precomputed.\nThis information was added in the updated version of the manuscript (see Appendix A6).\n\n\n**W4: Control condition: swapping connected components:**\nTo rephrase, the reviewer is suggesting to create counterfactuals by swapping the controllable subgraphs instead of the uncontrollable ones. Both approaches are correct and would lead to feasible counterfactuals. However, the coverage of the state space is greater using the current approach. In the case that given a specific environment configuration only one task is demonstrated (such as in the kitchen), swapping the controllable subgraphs would lead to counterfactuals that are likely already part of the dataset."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7407/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687142475,
                "cdate": 1700687142475,
                "tmdate": 1700687142475,
                "mdate": 1700687142475,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XMHKg1Mw6H",
                "forum": "AMCaG2TAeg",
                "replyto": "GuR0lwFin8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7407/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7407/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer GhVi (Part 2)"
                    },
                    "comment": {
                        "value": "**Q1:High data regime performance:**\n\nThis is a good point. We have updated the results on the Fetch-Push experiment (Figure 4, left) and added a new experiment on a Fetch-Pick&Lift environment (Figure 4, right). The updated results stem from a more systematic hyperparameter tuning for **each** method (see reviewer LtoA (Part 5, Q5) and our answer there). While the results follow a similar trend to the original one, it notably demonstrates significantly higher performance for CAIAC compared to other methods. \nIn order to further analyze the obtained results, we would like to consider three conditions separately. We also added these clarifications in the updated version of the manuscript (see Section 5.2).\n\n1. When data is scarce (see Fetch-Push, low-data regimes), as long as the marginal state distributions at training and test time match for all the entities, CAIAC is able to cover the full support of the state joint distribution by creating unseen configurations of the entities.\n2. When data is abundant AND it adequately covers the full joint state space (as in Fetch-Push, high-data regime), no data augmentation is needed by definition and hence CAIAC and the No-Augmented baseline perform similarly. For CoDA and CoDA action we see a light drop in performance possibly due to the creation of unfeasible counterfactuals which harm performance.\n3. When data is abundant AND there is yet a mismatch between the joint state distribution at training and test time, CAIAC remains very effective. We showcase this in a new experiment on Fetch-Pick&Lift (see Figure 4 right). We use abundant data, namely 2M samples/40k episodes. However, the state joint distribution in the training data does not match the state joint distribution at test time. CAIAC reaches almost 100% whereas all baselines perform purely. CoDA cannot create helpful counterfactuals, even with an optimized detection threshold. \n\n**Q2: Computational demands:**\n\nPlease see answer to W3 point above."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7407/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687229169,
                "cdate": 1700687229169,
                "tmdate": 1700687447040,
                "mdate": 1700687447040,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]