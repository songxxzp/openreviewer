[
    {
        "title": "Neural Optimizer Equation, Decay Function, and Learning Rate Schedule Joint Evolution"
    },
    {
        "review": {
            "id": "StZBjO64G3",
            "forum": "YGWGhdik6O",
            "replyto": "YGWGhdik6O",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6195/Reviewer_8NVV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6195/Reviewer_8NVV"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on the automated discovery of optimization algorithms. In particular, it proposes an enlarged optimizer search space constructed using tree-based grammar using building blocks of both update equations as well as decay functions (functions of the optimization step number). To search over this space, the authors employ a mutation-only genetic algorithm that evolves optimizers by mutating and selecting the best optimizer according to its generalization performance on the Cifar-10 dataset. The authors also propose a sanity check to eliminate degenerate optimizers by first checking its performance when training on a quadratic task to save compute. The discovered optimizers are shown to outperform or match existing hand-designed optimizers on training/fine-tuning EffNetV2Small on multiple vision datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Automated discovery of optimization algorithms is an important topic.\n- The paper provides a thorough documentation of its algorithm procedure.\n- The proposed sanity check of first evaluating the optimizer on a quadratic task is reasonable and can potentially save compute."
                },
                "weaknesses": {
                    "value": "1. __Significance in the Contribution__. To my understanding, the two types of contributions the authors can make in this paper are: __1)__ proposing a new set of algorithm procedures (including new search space, search algorithm, integrity check) to find better optimizers; __2)__ the actual optimizers found and any insights obtained from analyzing them.\n    \n    In terms of __1)__, despite the authors doing a generally good job of documenting their procedures for reproducibility, the actual procedures are very specialized to the ConvNet model architecture (with multiple rounds of different types of heuristics to filter the search candidates) and might still be difficult to replicate and also generalize to a new task, architecture combination. \n    \n    In terms of __2)__, it\u2019s not clear to me how much better the discovered optimizers are compared to existing hand-designed optimizers like Adam. All of the results in Table 6 are evaluated using a single model architecture EffNetV2Small after performing some final optimizer candidate selection directly over this model architecture. Therefore, it\u2019s unclear to what degree these optimizers can general to other models. Besides, focusing on EffNetV2Small, over the non-cifar tasks (tasks not used in the optimizer selection), there always exist hand-designed optimizers that are close if not better than the discovered ones. Finally, in terms of interpreting the analytical form of the discovered optimizers, the paragraph at the end of page 8 and beginning of page 9 are more of surface-level descriptions of the experimental results rather than a distilled summary and insights, making it difficult to parse the key message the authors wish to convey.\n    \n2. **Evaluating the importance of enlarging the search space**. As one of the claimed contributions of the paper is an enlarged optimizer search with more operands, operators, and decay functions, it is expected that the authors should perform an ablation study to understand the benefit of the introduced enlarged search space. The bare-minimum ablation baseline is to train on the datasets in Table 6 using several of the optimizers discovered by Bello et al (2017) and compare whether the performances of the optimizers discovered in this paper are better than those discovered in a smaller search space.\n\n3. **Incomplete results**. Part of the results in Table 6 are unfinished as the authors claim to finish before the rebuttal period."
                },
                "questions": {
                    "value": "- In Bello et al (2017), in addition to tables comparing optimizers\u2019 performance, learning curves of optimizers\u2019 generalization performance progression are also shown. For some of the cases, it helps reader to see that Bello et al's discovered optimizers can converge faster than hand-designed methods for cases where the final performances might be similar. I suggest the authors also consider showing such graphs to provide additional information of the discovered optimizers.\n- The authors should formally define what a decay function is. I personally found it hard to understand the terminology until I read its definition in Bello et al (2017).\n- The authors mention that the mutation operator in the paper selects the best mutated child as the next position for the particle. It\u2019s not clear to me whether this best child is compared against its parent. Can the authors clarify if this is done? (If so, then the selection should guarantee monotonic performance improvement.)\n- On page 4, the authors use the term \u201cnon-distributive function\u201d. However, I wonder if the authors mean to say non-homogeneous function."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6195/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6195/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6195/Reviewer_8NVV"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6195/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698537791608,
            "cdate": 1698537791608,
            "tmdate": 1699636674686,
            "mdate": 1699636674686,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1sGcC8bHy7",
                "forum": "YGWGhdik6O",
                "replyto": "StZBjO64G3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6195/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6195/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Hello Reviewer,\n\nThank you for taking the time to detail your thoughts, concerns, and grading. We appreciate your criticism in making our work more professional, robust, and clear. Please see our official comment (**Updated Unfinished Results**) on the subject of unfinished results.\n\n> 1. Significance in the Contribution. \n\n> the actual procedures are very specialized to the ConvNet model architecture (with multiple rounds of different types of heuristics to filter the search candidates) and might still be difficult to replicate and also generalize to a new task, architecture combination.\n\nIt is common in AutoML tasks applied to neural networks to use a proxy function as training and evaluating thousands of large scale models is infeasible. Small ConvNets have been historically used as such a proxy function. Bello et al (2017) used a ConvNet when searching for their optimizers. [1] used a convnet when evolving activation functions. [2]  used a convnet when evolving loss functions. It is typical to take the best handful from the convnets and then train them large scale, as was performed by Bello et al (2017). The only difference between what we did and Bello et al (2017), was use an elimination protocol that selected the best handful by progressively upscaling the ConvNet. This was performed as our implementation of the optimizer graph was extremely memory intensive, as we had to keep track of atleast 4x the size of the model in memory ($\\hat v, \\hat s, \\hat \\lambda$ and momentum) (not counting internal state operands), which did not fit into memory when using EfficientNetV2Small given our computational resources. All final optimizers had to be hard-coded into memory efficient manners to allow for training upon EffNetV2Small. Therefore, we had to devise a way to select the most capable from the discovered optimizers other than hard-coding 150 optimizers. \n\n> \"it\u2019s not clear to me how much better the discovered optimizers are compared to existing hand-designed optimizers like Adam.\"\n\nPlease see our official comment (**Updated Unfinished Results**) as we have filled in the missing experiments. We would like to note that when training from scratch on CIFAR-10, CIFAR-100, and TinyImageNet, Opt6 greatly outperformed Adam. When fine-tuning, Opt3 greatly outperformed Adam. In addition, A1 and A5 outperformed Adam across all datasets (except CIFAR-10). \n\n>  Finally, in terms of interpreting the analytical form of the discovered optimizers, the paragraph at the end of page 8 and beginning of page 9 are more of surface-level descriptions of the experimental results rather than a distilled summary and insights, making it difficult to parse the key message the authors wish to convey.\n\nPlease see our official comment (Convergence, Sensitivity, and Theoretical Bounds for Found Deep Learning Optimizers) on the subject. There is not enough room in 9 pages to detail every insight of the final discovered optimizers. Please see Appendix G for in-depth discussion on the topic. \n\n> \"All of the results in Table 6 are evaluated using a single model architecture EffNetV2Small after performing some final optimizer candidate selection directly over this model architecture. Therefore, it\u2019s unclear to what degree these optimizers can general to other models.\"\n\nThis is semi-incorrect. Although it is true that the final optimizers were selected based upon their performance on EffNetV2Small, Table 6 does contain results on a different architecture: A ResNet9 (6M parameters) for TinyImageNet. In addition, Appendix H gives a supplementary experiment on training an LSTM (24M parameters) on the PTB dataset. \n\n> 2. Evaluating the importance of enlarging the search space.\n\nPlease see our official comment (**Updated Unfinished Results**) on the subject of unfinished results as we have included the best two discovered optimizers from Bello et al (2017) in our work. \n\n> it is expected that the authors should perform an ablation study to understand the benefit of the introduced enlarged search space\n\nUnfortunately, we did not have the computational resources to run ablation studies on different combinations of the search space. \n\n> 3. Incomplete results.\n\nPlease see our official comment (**Updated Unfinished Results**) on the subject of unfinished results.\n\n[1] Garrett Bingham, William Macke, and Risto Miikkulainen. Evolutionary optimization of deep learning activation functions. In Proceedings of the 2020 Genetic and Evolutionary Computation Conference, GECCO \u201920, page 289\u2013296, New York, NY, USA, 2020. Association for Computing Machinery. ISBN 9781450371285. doi: 10.1145/3377930.3389841. URL https://doi.org/10.1145/3377930.3389841.\n\n[2] Santiago Gonzalez and Risto Miikkulainen. Improved training speed, accuracy, and data utilization through loss function optimization. In 2020 IEEE Congress on Evolutionary Computation (CEC), pages 1\u20138, 2020. doi: 10.1109/CEC48606.2020.9185777."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699911434369,
                "cdate": 1699911434369,
                "tmdate": 1700021015084,
                "mdate": 1700021015084,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "TLBfKVLMCk",
            "forum": "YGWGhdik6O",
            "replyto": "YGWGhdik6O",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6195/Reviewer_Mvi5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6195/Reviewer_Mvi5"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed to evolve an optimizer for neural networks. The researched problem is necessary, while the technical contributions are limited. In addition, the experiments should be conducted on SOTA neural network models for verification."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "Designig suitable optimizers for specific problems is necessary, while this work is just for this aspect."
                },
                "weaknesses": {
                    "value": "There are many types of genetic algorithms in the literature, while the proposed genetic algorithm in this paper is made based on the claim that the genetic algorithm used in Real et al.'s work is not suitable for the work in this paper. In fact, many very similar evolutionary algorithms can achieve the same goals (mutation only, aging, parallelism) as the designed genetic algorithm in this paper. \n\nThis paper looks like a project implementation, instead of a research paper. To achieve the goal claimed in this paper, the authors prepare a lot of different components for the project's implementation.\n\nThe convenient way to verify if the proposed method works for the current fact is to search an optimizer on some SOTA neural networks, and then to check if the performance of the compared SOTA can be improved.\n\nThe format of references should be updated, the current form of submission is hard to read."
                },
                "questions": {
                    "value": "See above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6195/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698651424208,
            "cdate": 1698651424208,
            "tmdate": 1699636674569,
            "mdate": 1699636674569,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "EYRNHxNiH3",
                "forum": "YGWGhdik6O",
                "replyto": "TLBfKVLMCk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6195/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6195/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Hello Reviewer,\n\nThank you for taking the time to detail your thoughts, concerns, and grading. We appreciate your criticism in making our work more professional, robust, and clear. Please see our official comment (**Updated Unfinished Results**) on the subject of unfinished results.\n\n> 1. There are many types of genetic algorithms in the literature, while the proposed genetic algorithm in this paper is made based on the claim that the genetic algorithm used in Real et al.'s work is not suitable for the work in this paper. In fact, many very similar evolutionary algorithms can achieve the same goals (mutation only, aging, parallelism) as the designed genetic algorithm in this paper.\n\nWe are aware that the literature is filled with a plethora of different genetic algorithms. We have no problem using the genetic algorithm from Real et al.'s work, except that it yielded repeat optimizers most of the time in our preliminary experiments, due to the reasons discussed in the paper. Therefore, we had to use a different algorithm to search the proposed search space. Due to the success of Real et al.'s work, we modeled our algorithm after the main attributes of their algorithm. We do not see how this is a weakness as the main contribution of our work was not the genetic algorithm but the deep learning optimizer search space and discovered optimizers. \n\n> 2. \"This paper looks like a project implementation, instead of a research paper.\"\n\n The research question behind our paper can be formulated as follows: \"Can we use AutoML to discover deep learning optimizers that can achieve SOTA results compared to baseline human designed deep learning optimizers in computer vision?\" This is the backbone question for many AutoML papers, especially neural architecture search papers: \"Can we use AutoML, and a cleverly designed search space and search algorithm, to find an architecture that outperforms human engineered architectures?\". \n\n\n> 3. \"The convenient way to verify if the proposed method works for the current fact is to search an optimizer on some SOTA neural networks, and then to check if the performance of the compared SOTA can be improved.\"\n\nThis is correct. In fact, that is exactly what we have done. After searching for optimizers, the best were transferred to EfficientNetV2Small, a SOTA computer vision CNN, across multiple image classification datasets: CIFAR-10, CIFAR-100, Flowers, Cars, Caltech, and Tiny. We found multiple optimizers that consistently outperformed the baseline SOTA deep learning optimizers. Please see our discussion in Section 6 on the results. \n\n> 4. The format of references should be updated, the current form of submission is hard to read.\n\nThank you reviewer for pointing that out, we have updated our citations in our new revision."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699909534327,
                "cdate": 1699909534327,
                "tmdate": 1700028074096,
                "mdate": 1700028074096,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "z9bAsi5gKM",
            "forum": "YGWGhdik6O",
            "replyto": "YGWGhdik6O",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6195/Reviewer_XE1e"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6195/Reviewer_XE1e"
            ],
            "content": {
                "summary": {
                    "value": "The paper claims simultaneous optimization of the weight update equation, decay functions, and adaptation of the learning rate schedule. Certain operands are tested on standard data sets and a particle GA method for simultaneous optimization is proposed."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The simultaneous optimization approach is interesting."
                },
                "weaknesses": {
                    "value": "The approach lacks clarity.\nIt doesn't provide an theoretical guarantees of convergence neither does it talk about algorithmic complexity. The paper lacks theoretical soundness."
                },
                "questions": {
                    "value": "For example, how does the learning rate adapt? With the Particle-GA?\nNot sure why the LRs are bumpy"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6195/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698740502590,
            "cdate": 1698740502590,
            "tmdate": 1699636674453,
            "mdate": 1699636674453,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dIILc5r2Mh",
                "forum": "YGWGhdik6O",
                "replyto": "z9bAsi5gKM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6195/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6195/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Hello Reviewer,\n\nThank you for taking the time to detail your thoughts, concerns, and grading. We appreciate your criticism in making our work more professional, robust, and clear. Please see our official comment (**Updated Unfinished Results**) on the subject of unfinished results.\n\n> 1. \"It doesn't provide an theoretical guarantees of convergence neither does it talk about algorithmic complexity\"\n\nPlease see our official comment (**Convergence, Sensitivity, and Theoretical Bounds for Found Deep Learning Optimizers**) on the subject.\n\n> 2. \" how does the learning rate adapt?\"\n\nThe learning rates were tested for generalization by training them across multiple image classification datasets. In addition, there were also tested in language modeling on the PTB dataset using an LSTM. These results were discussed in Appendix H. \n\n> 3. \"With the Particle-GA? \"\n\nOur goal was not propose a particle based GA that could generalize to other scenarios, but to utilize the proposed approach specifically for our task of discovering deep learning optimizers. \n\n> 4. \"Not sure why the LRs are bumpy\"\n\nThe learning rates are bumpy because that is what the particle based genetic algorithm found successful. This can be demonstrated in Table 6 for CIFAR-10 where four of the learning rates achieve Top~8. The \"bump[iness]\" of the discovered learning rates, in conjunction with its success on CIFAR-10 indicates and challenges the assumption that smooth learning rates are most optimal."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699908591275,
                "cdate": 1699908591275,
                "tmdate": 1699908591275,
                "mdate": 1699908591275,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Dr1lGUO6cB",
            "forum": "YGWGhdik6O",
            "replyto": "YGWGhdik6O",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6195/Reviewer_hhkB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6195/Reviewer_hhkB"
            ],
            "content": {
                "summary": {
                    "value": "The authors investigate hyperparameter tuning in machine learning models. I think while the topic is a well-explored area, the continuous evolution of models and the increasing complexity of tasks mean that there's space for innovative approaches. The paper proposes the use of Neural Optimizer Search (NOS) in this task. The experiments ranked ten final optimizers, categorized into three main families. I do like the transferability experiments, where the algorithms are tested across various image classification tasks. The performance varies between models trained from scratch and fine-tuning scenarios, with some optimizers showing particularly strong results in one or the other. But as in many other papers in this context, I think the why the algorithms behave like that is not entirely clear."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "I do think the authors presented an interesting approach by expanding the search space for optimizer algorithms and introducing a novel particle-based GA method. \nThe authors also designed a comprehensive and extensive set of experiments, but I think increased the ablation study to help evaluate the contributions of individual components in the proposed investigation.\nThe paper is well-organized, I liked the approach of breaking down the problem, its causes, the solution, and the experimental validation in a logical sequence."
                },
                "weaknesses": {
                    "value": "Besides a large number of experiments, I think the main experiments are centered on or in variations of specific datasets like TinyImageNet and CIFAR-10.\n\nOne relevant weakness of the paper is that a relevant quantity of experiments were not completed at the time of the paper's writing, as denoted by asterisks in Table 6. The lack of results leaves a gap in the comprehensive evaluation of the results and makes it hard to evaluate the global performance of the proposed approach. \n\nThe authors focused experiments on image classification and language modeling tasks but argued that the results could be extended to other tasks.\n\nI was waiting for a more in-depth analysis of the results, considering the whys, the sensitivity analysis, tendencies, etc. The paper shows the phenomena exist but does not explain them in detail. I know this is common in papers in this field, but we need to improve that. It has an interesting empirical contribution but lacks theoretical support for why certain optimizers perform better than others.\n\nThe fine-tuning results appear to be inconsistent with the from-scratch training results.\n\nI do believe the authors benefit from a discussion on scenarios where the proposed method might not work well. This gives readers a more balanced view and sets expectations correctly. I suggest the authors explore more of that.\n\nThe paper identifies families of optimizers, but it doesn't explore the unique characteristics of each family and how they contribute to the model's performance."
                },
                "questions": {
                    "value": "The paper focuses on EfficientNet and ResNet, what about the performance in different architectures such as transformers or RNNs?\n\nGiven the stochastic nature of genetic algorithms, how consistent are the results across different runs of the optimizer discovery process?\n\nCan the authors provide details on the computational resources required for the optimizer discovery process?\n\nHow do the optimizers perform under adverse training conditions, such as noisy gradients, sparse gradients, or data with high-class imbalance?\n\nI noted seven of the final ten optimizers contain decay functions, what is the specific contribution of these decay functions to the overall performance?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6195/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698867291044,
            "cdate": 1698867291044,
            "tmdate": 1699636674328,
            "mdate": 1699636674328,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PAk13sd2KM",
                "forum": "YGWGhdik6O",
                "replyto": "Dr1lGUO6cB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6195/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6195/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Hello Reviewer,\n\nThank you for taking the time to detail your thoughts, concerns, and grading. We appreciate your criticism in making our work more professional, robust, and clear. Please see our official comment (**Updated Unfinished Results**) on the subject of unfinished results. \n\n> 1. \"I was waiting for a more in-depth analysis of the results, considering the whys, the sensitivity analysis, tendencies, etc.\" \n\nPlease see our official comment (**Convergence, Sensitivity, and Theoretical Bounds for Found Deep Learning Optimizers**)  on the subject. \n\n> 2. \"The fine-tuning results appear to be inconsistent with the from-scratch training results.\"\n\nYes, this observation does occur as the performance of the optimizers flip when training from scratch and fine-tuning. This also occurs for the baseline deep learning optimizers, such as SGD and QHM. In addition, top performing optimizers in each scenario do not flop in the other. For example, Op6, the best performer when training from scratch, performs comparably to Adam on Flowers and Caltech; and, Opt3, arguably the best performer when fine-tuning, outperformed Adam on CIFAR100 and Tiny. Therefore, we do not see this as a weakness, but an exposition of the strengths and weaknesses for different optimizers. \n\n> 3. \"The paper identifies families of optimizers, but it doesn't explore the unique characteristics of each family and how they contribute to the model's performance.\"\n\nPlease see our official comment (**Convergence, Sensitivity, and Theoretical Bounds for Found Deep Learning Optimizers**)  on the subject. In addition, Appendix F discusses the effects of the final decay functions, learning rate schedules, and weight update equations. \n\n> 4. \"The paper focuses on EfficientNet and ResNet, what about the performance in different architectures such as transformers or RNNs?\"\n\nUnfortunately, we did not have enough computational resources to test each optimizer across different deep learning domains. However, our submission does include results for training an LSTM on the PTB dataset, as recorded in Table 9. \n\n> 5. \"Given the stochastic nature of genetic algorithms, how consistent are the results across different runs of the optimizer discovery process?\"\n\nOur proposed algorithm was more exploratory than exploitive. We did not use our genetic algorithm in the classic sense, where the algorithm is ran and the best/final individuals from the last generation are taken as the best. We used our proposed genetic algorithm more as an exploratory mechanism, from which our proposed optimizer elimination protocol exploited the best. \n\n> 6. \"Can the authors provide details on the computational resources required for the optimizer discovery process?\"\n\nAs quoted from our paper: \"we only had access to one NVIDIA 4090 GPU during evolution. Each run took approximately six days to complete\".\n\n> 7. \"How do the optimizers perform under adverse training conditions, such as noisy gradients, sparse gradients, or data with high-class imbalance?\"\n\nPlease see our official comment (**Convergence, Sensitivity, and Theoretical Bounds for Found Deep Learning Optimizers**)  on the subject. \n\n> 8. \"I noted seven of the final ten optimizers contain decay functions, what is the specific contribution of these decay functions to the overall performance?\"\n\nSection 5 discussed that each optimizer which learned a decay function was trained both with and without it to assess its contribution. These are included with the results by the denotation of $_1$ to the end of the optimizer. For example, Opt6 trained without all of its decay functions is denoted by Opt6$_1$. Unfortunately, we did not have the time, nor space, to train every combination of optimizer and decay function, therefore we trained each optimizer both with and without all of its discovered decay functions."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699907984053,
                "cdate": 1699907984053,
                "tmdate": 1699907984053,
                "mdate": 1699907984053,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]