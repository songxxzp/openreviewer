[
    {
        "title": "GNeRP: Gaussian-guided Neural Reconstruction of Reflective Objects with Noisy Polarization Priors"
    },
    {
        "review": {
            "id": "32cjvDyHJb",
            "forum": "pTN8dV2pL8",
            "replyto": "pTN8dV2pL8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1298/Reviewer_BtpD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1298/Reviewer_BtpD"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a method called GNERP for reconstructing the detailed geometry of reflective objects from multi-view images. The key idea is to extend the geometry representation from scalar Signed Distance Fields (SDFs) to Gaussian fields of normals supervised by polarization priors. The paper introduces a pipeline for learning the surface by volume rendering, and presents a DoP reweighing strategy to alleviate noise and imbalance distribution problems of polarization priors. Additionally, a new multi-view dataset called PolRef, consisting of objects with reflective and less-textured surfaces, is collected to evaluate the performance of3D reconstruction methods. Experimental results show that GNERP improves the geometry details and accuracy of geometry and normals of reflective surfaces compared to existing state-of-the-art methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper integrates recent advances in Gaussian Splatting to model the polarization priors for reflective surface recovery, which is innovative and aligns with the current research trends.\n\n- The proposed reweighted polarization priors appear to serve effectively as supervision."
                },
                "weaknesses": {
                    "value": "- The explanation of the proposed method is unclear. What is the input? Is a polarization camera required for reconstruction? If not, is the polarization prior regressed during optimization?\n\n- The proposed approach neglects the effect of self-occlusions, which can be severe for complicated objects. The paper should at least include a qualitative discussion about the effects of self-occlusions.\n\n- The property of polarization is closely related to materials. The proposed approach relies on the intermediate output of a coordinate network and hence seems to handle only objects with a uniform material, as shown in Fig. 5.\n\n- The experiments are conducted only on relatively simple objects. It would be beneficial to show results on more complicated objects to better understand its performance.\n\n- It would be great if the authors could provide an illustration of how the polarization priors intuitively improve the performance of NeuS."
                },
                "questions": {
                    "value": "Please see weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1298/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698836096505,
            "cdate": 1698836096505,
            "tmdate": 1699636056768,
            "mdate": 1699636056768,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "y9iaXbMYDQ",
                "forum": "pTN8dV2pL8",
                "replyto": "32cjvDyHJb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1298/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1298/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your comments. We appreciate your acknowledgement of the novelty and effectiveness of our method. We have carefully considered your comments and listed the responses below: (Weakness - W):\n\nW1. We add an illustration to  the Appendix B Figure 6. (a) to show the pipeline of training data preparation.  Please see the training data box for intuition. The inputs include polarization images (AoP and DoP), RGB images, and object masks. A polarization camera is needed for polarization image acquisition, we add the claim to the limitation discussion in Appendix E.\n\nW2. Thanks for pointing out self-occlusion as a potential challenge. We tested additional scenes and found the shading caused by self-occlusion is a limitation of our method, and we added a failure case in the limitation discussion shown in Figure 14.\n\nW3. Thanks for the suggestion of testing scenes with mixed materials. During the discussion time, we processed the raw capture of the Camera scene in PMVIR. It\u2019s a Sony camera with various materials. The reconstruction is shown in Figure 9. As is shown in the figure, our method reconstructs more details of small structures with different materials concurrently. However, the lack of GT mesh in the dataset makes quantitative evaluation unavailable.\n\nW4. Thanks for suggesting testing complicated objects. In the initial submission, the Ironman scene shown in Figure 5 has detailed geometry such as the edges of armours. During the discussion time, we rendered two additional synthetic scenes (Bunny and Dragon) using Mistuba render. The results are shown in Figure 8 and Table 3. As shown in GT normal in Figure 8, The geometry of the Dragon is complicated such as claws, the head with feelers, and scales on the body. It shows our method reconstructs the geometry preserving more details while the geomrty of the other methods are over-smoothed.\n\nW5. Thank you for the suggestion on illustrations. We have illustrated the principle of how Gaussians of normals supervised by polarization improve NeuS in Figure 1. (b). We include the polarization prior in the Figure and modify the caption for clarification."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1298/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700244200847,
                "cdate": 1700244200847,
                "tmdate": 1700244200847,
                "mdate": 1700244200847,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "gSgRpcWB4K",
            "forum": "pTN8dV2pL8",
            "replyto": "pTN8dV2pL8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1298/Reviewer_1dU4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1298/Reviewer_1dU4"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a neural volume-based method that utilizes Gaussian-based normal representation and polarization information to improve multi-view 3D reconstruction of highly specular objects. Its volume representation and rendering framework are from NeuS. The major novelty is to model the normal direction of sampled 3D points along the ray with 3D Gaussian distributions, which then can be projected to 2D image plane using Gaussian splatting. A new loss is proposed by comparing the projected normal distribution with the normal distribution computed from polarization information. Experiments on datasets containing highly specular objects shows that the proposed method can achieve much more accurate geometry reconstruction."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. High-quality geometry reconstruction for highly specular objects.\nMulti-view reconstruction of highly specular surfaces is known to be a difficult problem. This paper shows compelling reconstruction quality on several challenging real-world objects. \n\n2. Convincing improvements compared to prior method on highly specular objects.\nBoth quantitative and qualitative comparisons show that the proposed method achieve higher geometry reconstruction accuracy compared to prior state-of-the-arts, including a method that also utilizes polarization information and a method designed for specular object. \n\n3. A polarization-based geometry reconstruction method that does not require complicated setups. \nThe proposed method does not make strong assumptions on the material properties and capturing environment, which makes it practical for many applications."
                },
                "weaknesses": {
                    "value": "1. I have some questions about Sec. 3.2.3, which I would like to understand better. They are not necessarily the weaknesses of the paper.\n\n(a) How to decide the scale factor $s$? Or do we assume the mean loss should be scale invariant and we only care its orientation?\n\n(b) Do we compute $\\mu_i^{j}$ by projecting every $x_{i}^{j}$ along the ray to 2D image, i.e. $M'$ equal to $6M$?\n\n(c) I can see that 2D convariance matrices computed from polarization and splatting can both indicate if geometry is changing rapidly in the neighborhood. But it is a bit difficult for me to understand why they should be equal. A side by side visualization of both 2D Gaussian distributions will be useful. In addition, will noisy AoP of diffuse surface cause the 2D covariance matrix from polarization to have very large eigen values?\n\n(d) Typos: there is an extra $)$ in $L_{\\text{mean}}$ and $L_{\\text{conv}}$. \n\n2. Further ablation studies can be useful to verify the effectiveness of Gaussian normal representation. \nSince Gaussian normal representation is the major novelty, it might be good to further verify its effectiveness with more ablation studies. One simple baseline is to render normal through standard volume ray tracing and then use reweighted $L_{\\mean}$ loss for training. That may give us a clear answer if we need to sample extra points to compute a Gaussian distribution. \n\n3. Results on less specular objects may be interesting.\nI notice that all real objects shown in the paper are quite glossy. Do we have results on less glossy objects? As shown in the paper, the AoP of diffuse surfaces can be noisy but hopefully the DoP weight can fix this issue. \n\n4. Missing reference.\nOne related paper is cite is: \"Sparse Ellipsometry: Portable Acquisition of Polarimetric SVBRDF and Shape with Unstructured Flash Photography, Hwang et al.\"\n\nVery minor comments:\nFigure 2: the polarized direction may use a different color from that of the x-axis. Zenith angle $\\theta$ is mentioned by never discussed in the paper. It may be more useful to label out angle $\\varphi$."
                },
                "questions": {
                    "value": "My major questions are the first two points listed in the weakness section.\n1. Can we explain in more details how to compute 2D normal distribution from a polarized image? \n2. Can we further verify if 3D Gaussian distribution is necessary? If we only compute the normal following standard volume ray tracing and then use reweighted $L_{\\text{mean}}$ loss, will the results be similar or worse?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "There is no ethic concern as far as I know."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1298/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698905298775,
            "cdate": 1698905298775,
            "tmdate": 1699636056698,
            "mdate": 1699636056698,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SSmYFE1W8U",
                "forum": "pTN8dV2pL8",
                "replyto": "gSgRpcWB4K",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1298/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1298/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for providing feedback. We appreciate your agreement with the performance and weak assumptions of our method. We have carefully considered your comments and listed the responses below (Weakness - W, Question - Q):\n\nW1. (a) We estimated the polarized 2D Gaussians based on unitary projected normals vectors derived from the Angle of Polarization ( the right term of Eq. 8). However, the projected normal vectors are unnecessarily unitary in the left term. The scale factor is multiplied for the equivalence of Eq. 8. The final loss gets rid of the dependent of it, so it isn\u2019t explicitly calculated. We added a detailed description of Gaussian estimation in the Appendix A.3.\n\n(b) In the paper, M and M\u2019 are set to 6 and 4, respectively. To estimate 3D Gaussians, we sample 2 points along the ray (before and after the center) and 4 points along the rays passing adjacent pixels. Hence, when estimating 2D Gaussians in polarization images, we only query the corresponding pixels, and M\u2019 is set to 4.\n\n(c).1 The equivalence is ensured by the relation between the azimuth angle and the Angle of Polarization (AoP), shown in Figure 2 and the equation in the last paragraph of Sec. 3.1 (azimuth angle + pi/2 = AoP mod pi).  So we can recover the orientation of 2D projected normal vectors from AoP, which should align with the orientation of splatted 3D normal vectors. Therefore, covariance should be the same, too. A visualization of 2D Gaussians is Figure 4. (e). Low saturation white pixels indicate that the 2D Gaussian at that location is close to isotropic, resembling a circle. Conversely, high saturation areas indicate strong anisotropy, resembling an ellipse, with the color representing the orientation of the ellipse. This is shown in the left column of the figure.\n\n(c).2 The eigenvalues of covariance will be irregular in diffuse regions due to noisy AoP. Hence we introduce DoP reweighting to reduce their impact since DoP will be small in these regions, as mentioned in Sec. 3.2.3. \n\n(d)Thanks for the error pointed out. We have fixed it.\n\nW2. Thanks for the suggestion on the setting of an additional ablation study. In our understanding, the required experiment is exactly w/ReW. L_{mean} in Table 2. \n\nW3. Thanks for the advice on the evaluation of diffuse scenes. We processed the raw capture of the Camera scene in PMVIR, which is a more diffuse-dominant scene. A visual comparison is shown in Appendix C.3. Since the ground truth mesh isn't provided, quantitative evaluation is unavailable. However, Figure. 9 shows that our method reconstructs more details of small structures such as buttons, knobs, and slots of the camera. This proves that our method can handle diffuse objects effectively.\n\nW4. Thanks for the additional related paper mentioned. We have added it to the Related Work Section.\n\nMinor. We have changed the Figure 2 as the suggestion. The relation between AoP and the normal vector is more clear. Hope it can help you solve W1. (c).\n\nQ1. A detailed explanation of Gaussian calculation is added to the Appendix A.3. 2D Gaussians of polarization images are introduced in the second paragraph. \n\nQ2. We think the question is the same as W2."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1298/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700244460136,
                "cdate": 1700244460136,
                "tmdate": 1700244460136,
                "mdate": 1700244460136,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pPwPFbZle0",
                "forum": "pTN8dV2pL8",
                "replyto": "SSmYFE1W8U",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1298/Reviewer_1dU4"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1298/Reviewer_1dU4"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the detailed response! After carefully reading your response, I think all my questions have been solved."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1298/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700639454468,
                "cdate": 1700639454468,
                "tmdate": 1700639454468,
                "mdate": 1700639454468,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "cjyGuOy6He",
            "forum": "pTN8dV2pL8",
            "replyto": "pTN8dV2pL8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1298/Reviewer_Kf6J"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1298/Reviewer_Kf6J"
            ],
            "content": {
                "summary": {
                    "value": "Neural SDF-based 3D reconstruction excels at smooth Lambertian objects. The paper proposes a 3D Gaussian-based representation of normals in SDF fields, and splat it to 2D Gaussians in the image plane. It shows that the 2D Gaussian can be directly extracted from Angle of Polarization (AoP). This paper proposes to use the proposed 2D Gassians represenation as the additional constraints for 3D normal recovery. Moreover, it proposes to use the Degree of Polarization (DoP) which indicates the complexity of the surface to reweight  AoPalleviate the noise issue of polarization priors.  Their experimental results on PANDORA dataset domstrate the effiectiveness of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper proposed the 3D Gaussian representation of surface normal for the volume rendering proposed in NeRF(2020) in EQ4., and furture entend it to 2D Gaussian by using the splatting approach (Zwicker et al). The research demonstrates that the 2D Gaussian representation can be efficiently computed using the Angle of Projection (AoP). Additionally, it is revealed that the Degree of Polarization (DoP) is strongly correlated with the surface complexity. Consequently, the authors propose a novel regularization technique for NeRF, involving the reweighting of constraints on the 2D Gaussian representation of surface normals. The experimental results clearly indicate that the proposed method excels in handling high-frequency BRDF surfaces."
                },
                "weaknesses": {
                    "value": "The paper presents experimental results only on the PANDORA dataset. It is essential to include discussions regarding failure cases and the limitations of the proposed method. The authors highlight \"the creation of a new and challenging multi-view dataset\" as a significant contribution. Nevertheless, there is a notable lack of information and discussion about this new dataset in the paper."
                },
                "questions": {
                    "value": "Please explain in detial about how to get $\\hat{\\Sigma}, \\hat{\\Lambda}$ and $\\tilde{\\Sigma} \\tilde{\\Lambda}$ in EQ7~9. Pleae explain the experimental setting to get the polarized data. More details are needed for the new multi-view polarized dataset, and how it collected."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1298/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1298/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1298/Reviewer_Kf6J"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1298/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699242043985,
            "cdate": 1699242043985,
            "tmdate": 1700446614127,
            "mdate": 1700446614127,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MRB252bUnf",
                "forum": "pTN8dV2pL8",
                "replyto": "cjyGuOy6He",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1298/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1298/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to express our gratitude to the reviewer for his comments and acknowledgments regarding the design of our method and the improved results achieved compared to existing methods. We respond to the weaknesses and questions below.\n\nWeaknesses:\n\n1. In the initial submission, we presented the results of our PolRef Dataset (Ironman, Snorlax, Cow, Duck, Cat, and Vase) and PANDORA dataset (Owl, Black Vase, and Gnome). During the discussion time, we additionally rendered synthetic scenes of Bunny and Dragon. The supplementary results are now provided in Table 3 and Figure 8. Furthermore, we evaluate our method on a diffuse object (Camera) captured in PMVIR, although ground truth meshes are not available for the PANDORA and PMVIR datasets. Visual comparisons are provided in lieu of quantitative evaluation. They show that our method consistently outperforms existing methods on these datasets.\n2. We have added the limitations discussion of our method in Appendix E. The primary limitation lies in the requirement of polarimetric imaging, which incurs higher costs compared to RGB cameras. Moreover, the training and inference speeds of our method are lower than those of existing NGP-based reconstruction methods. Moreover, shading caused by self-occlusion may deteriorate the performance. We add a failure case shown in Figure 14.\n3. We have included a description of our PolRef dataset, along with details of data collection and the evaluation protocol, in Appendix B and Figure 6.\n\nQuestions:\n\n1. We have provided an explanation of the formula to obtain \u03a3 and \u039b in Appendix A.3.\n2. As mentioned in Weakness 3, we have added a description of the dataset collection process in Appendix B."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1298/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700244411993,
                "cdate": 1700244411993,
                "tmdate": 1700244411993,
                "mdate": 1700244411993,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "r1PAZxFWs3",
            "forum": "pTN8dV2pL8",
            "replyto": "pTN8dV2pL8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1298/Reviewer_ANa9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1298/Reviewer_ANa9"
            ],
            "content": {
                "summary": {
                    "value": "The article introduces a 3D reconstruction technique based on Nerf, which focuses on capturing 3D geometries of glossy objects. Building on recent progress in utilizing signed distance functions (SDF), as seen in approaches like NeuS or Ref-Neus, this method also incorporates it. However, unlike the scalar SDF in these approaches, this proposed method additionally integrates polarization cues to constrain the surface normal. These added constraints are formulated using a Gaussian splatting approach. As a result, the proposed method demonstrates notably improved accuracy compared to state-of-the-art (SOTA) approaches."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The primary advantage of the proposed method lies in its utilization of polarization cues to improve the estimated geometry. This strategy is commonly employed to enhance accuracy in conventional 3D reconstruction techniques.\n- The additional constraint is devised using a Gaussian splatting technique. Specifically, the original 3D Gaussian on the 3D surface normal is transformed into a 2D Gaussian in the image plane and is constrained by polarization cue.\n- The polarization reweighting strategy can guide the proposed method to employ more polarization cues on the area with strong polarization information and employ more radiance on low polarization information.\n- The proposed method excels in reconstructing 3D geometry with high precision and capturing intricate details."
                },
                "weaknesses": {
                    "value": "- The proposed method only works for glossy objects that exhibit clear polarization information.\n- The proposed method comes with many hyperparameters which are hard for users to set in practice. Parameters like alpha and beta typically vary between 0.1 and 1, contingent on the intricacy of the geometry. Regrettably, the authors did not carry out any experiments to assess the optimal selection of these parameters, potentially hindering the method's practical implementation and performance.\n- Only the results of a few objects are shown in the experiments.\n- There are typographical errors and improper terms, which are described in the questions."
                },
                "questions": {
                    "value": "- For the parameter selection of alpha and beta, the authors did not specify the use of identical parameters across all experiments. The exact values for these parameters were not explicitly mentioned in the paper.\n\n- In Section 2.4, the authors stated that \"the learned 3D Gaussians imply the anisotropic normals distribution of 3D\npoints and capture more details of surface geometry.\" Could the authors elaborate on the description or provide some references?\nDoes it mean the learned 3D Gaussian is anisotropic? And the anisotropicity results in more details?\n\n- The ablation study could include an examination of the impact of alpha and beta. Additionally, the authors did not provide a clear rationale for why they included only two objects in Table 2 while incorporating four objects in Table 1. The ablation study of the other two objects is not supporting?\n\n- In the last paragraph of Section 3.2.3, the authors stated \"Intuitively, the first term measures the complexity of the geometry, while the second term reveals the specific geometric shape.\" Could the authors elaborate on this description?\n\n\nAdditional comments\n+ Typographical errors:\n\t- alpha in the first paragraph of page 5\n\t- common scenes in the first paragraph of section 2.3\n\t- Fig. 4(g) in the first paragraph of page 7. In fact, there is no Fig.4 (g).\n\t- In Fig. 4 caption: \"blue boxes bound diffuse ones\".\n\t\n\n+ \"exact 3D shapes\" in the abstract should be replaced by another term such as \"accurate\"."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1298/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1298/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1298/Reviewer_ANa9"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1298/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699397865776,
            "cdate": 1699397865776,
            "tmdate": 1699636056557,
            "mdate": 1699636056557,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hYLpvwY5VY",
                "forum": "pTN8dV2pL8",
                "replyto": "r1PAZxFWs3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1298/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1298/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their insightful comments. We are encouraged that the reviewer acknowledges that our method achieves good results on the typically challenging task of reconstructing reflective objects and outperforms existing methods quantitatively. We respond to the weaknesses and questions below (Weakness 1 - W1, Question 1 - Q1):\n\nW1. To validate the effectiveness of our method on diffuse objects, we processed the raw capture of the Camera scene in PMVIR. A visual comparison is shown in Appendix C.3. Since the ground truth mesh isn't provided, quantitative evaluation is unavailable. However, Fig. 9 shows that our method reconstructs more details of small structures such as buttons, knobs, and slots of the camera. This proves that our method can handle diffuse objects effectively.\n\nW2. The setting of hyper-parameters is relatively fixed in our method. For clarification, we rearrange the notation of the weights of loss functions in Eq. 9 and add a description of the settings in Appendix D.3. The only hyper-parameter that needs to be tuned is alpha. We tested different choices of alpha on the Bunny scene, as shown in Appendix D.3.2, to facilitate the practical implementation of the method.\n\nW3. In the initial submission, we showed reconstructed meshes of the Owl, Black Vase, Cat, and Vase scenes in the Appendix. Moreover, we rendered two additional synthetic scenes (Bunny and Dragon)  with ground truth normals during the discussion time, and qualitative and quantitative comparisons are shown in Appendix C.2, along with an additional evaluation metric, Mean Angular Error (MAE) of normals.\n\nW4. Thank you for pointing out the errors. We have fixed them.\n\nQ1. As mentioned in W2, we list them in Appendix D.3.\n\nQ2. Yes, as parameterized by the covariance matrix, the learned Gaussians are anisotropic. Normal vector can be seen as the mean of 3D Gaussians, and changes of normal vectors within the neighborhood are captured by covariance of Gaussians. Therefore, we claim that the 3D Gaussians capture more details. We have modified the description in Sec. 2.4.\n\nQ3. As mentioned in W2, the required experiments are listed in Appendix D.3.2. Due to the limitation of computational resources, ablation studies were only done on two of the objects in Table 1. We plan to complete them when the computational resources become available. We\u2019ll post them if the results are available during the discussion.\n\nQ4. The first term supervises the eigenvalues of the covariance matrix, and the second term supervises the eigenvectors of the covariance matrix. Similar to PCA techniques, the covariance matrix determines the magnitude and direction of normal changes through eigenvalues and eigenvectors. If the local shape is like a plane, normals will change smoothly in all directions, and the difference between eigenvalues will be small, resulting in the Anisotropy (defined as the ratio of eigenvalues in the paper) approaching 1. If there are some details like edges, normals tend to change abruptly and exhibit directionality, which is represented by eigenvectors. We have modified the description in Sec. 3.2.3."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1298/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700244371958,
                "cdate": 1700244371958,
                "tmdate": 1700244371958,
                "mdate": 1700244371958,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]