[
    {
        "title": "Attacking for Inspection and Instruction: Debiasing Self-explaining Text Classification"
    },
    {
        "review": {
            "id": "LRQtjLaBqz",
            "forum": "SdoSUDBWJY",
            "replyto": "SdoSUDBWJY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6689/Reviewer_LkPz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6689/Reviewer_LkPz"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the sampling bias problem that arises from the Rationalizing Neural Prediction (RNP) framework for text classifications. The authors demonstrate how sampling bias could be introduced by the explanation generator and how it leads to a bad impact on the label predictor. This paper then proposes to introduce an attacker to inspect the bias and instruct the predictor to prevent the predictor from adopting the bias."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Originality: The sampling bias problem of the RNP framework for the text classification setting is first proposed in this paper. Introducing an attacker to alleviate this bias is also novel and interesting.  \nQuality: Most of the statements are made with sufficient mathematical derivations. In addition, the experiment results provide a practical validation of the statements.  \nClarity: The paper has been well written and organized.  \nSignificance: This paper may have a limited impact on the NLP community. The main reason is that this paper focuses on improving the RNP framework for developing self-explainable text classification systems. Although developing such systems is a hot topic in NLP, the RNP framework is just one of the solutions. Also, the RNP framework cannot be well generalized to large pre-trained models such as BERT/GPT (according to the authors), which are more practical and common in recent academic research and industry products."
                },
                "weaknesses": {
                    "value": "The potential of this work is significantly suffered from the fact that the RNP framework cannot be practically aligned with large pre-trained models. In addition, if the authors manually label some data from broader topics and more diverse targets and conduct experiments on them, there would be evidence that the selecting bias is common and inherent exists in the RNP framework, and the proposed method could well alleviate it."
                },
                "questions": {
                    "value": "1.\tBy providing more high-quality rationales, the predictions should be more accurate. However, I found that sometimes, the baseline methods could better identify rationales with A2I, while the accuracy of predicting labels becomes worse. For example, Beer-Appearance-last grouped row, the F1 score of rationales improves from 72.3 to 74.6, but accuracy drops from 90.9 to 89.7. Similar trends could also be observed from Aroma aspect, for the sixth grouped row, where F1 score improves from 68.4 to 71.2, but accuracy drops from 90.5 to 89.7. Also, in Hotel-Cleanliness, F1 improves from 38.7 to 39.4, while accuracy drops from 96.0 to 95.5. Could the authors provide some insights into this phenomenon?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6689/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698814200044,
            "cdate": 1698814200044,
            "tmdate": 1699636767586,
            "mdate": 1699636767586,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "faTV7yzqGy",
                "forum": "SdoSUDBWJY",
                "replyto": "LRQtjLaBqz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "content": {
                    "title": {
                        "value": "BERT Encoder Experiments and Clarifications"
                    },
                    "comment": {
                        "value": "Thank you very much for your valuable comments and suggestions!\n\n**Q1.** The potential of this work is significantly suffered from the fact that the RNP framework cannot be practically aligned with large pre-trained models.\n\n**A1.** We agree with you. We have put this issue in the section of limitations, and we leave formally investigating the obstacles in utilizing powerful pre-trained language models under the rationalization framework as the future work.\n\nWe have now re-run RNP and FR with the Bert encoder on the three aspects of BeerAdvocate. Although fine-tuning Bert is still very difficult, we find that using a smaller learning rate for the Bert encoder than for the linear layer works somewhat. So we use a learning rate of $1e-5$ for the Bert encoder and $1e-4$ for the linear layer. The maximum sequence length is 256 (this is enough for the Beer dataset). The batch size is 24. \n\nFrom the second table, we see that Bert\\_RNP performs much worse than GRU\\_RNP, so there must be some unknown issues prevent RNP to work well with Bert. The sampling bias problem studied in our paper may not be the only obstacle that prevents Bert_RNP to work well, so in most cases, A2I does not improve Bert_RNP a lot.  \n\nBut from the first table, we see that Bert_FR improves Bert_RNP a lot. So the obstacles introduced by the Bert encoder may have somewhat been overcomed by FR. Under this case, our A2I improves Bert_FR a lot (more than $5\\%$ in 6 of 9 settings). We believe that future researchers will further explore harnessing the power of Bert within the RNP framework. At that point, we can also build upon subsequent methods to incorporate our A2I.\n\nNotes: We highlight the results only when FR+A2I gives an improvement over $5\\%$ compared to FR\n\n| Bert\\_FR |  | Appearance |  |  |  |  |  | Aroma |  |  |  |  |  | Palate |  |  |  |  |\n|---:|:---:|:---:|---:|---:|---:|---:|---:|:---:|---:|---:|---:|---:|---:|:---:|---:|---:|---:|---:|\n|  |  | s | acc | p | r | f1 |  | s | acc | p | r | f1 |  | s | acc | p | r | f1 |\n| $S\\approx 10\\%$ | FR | 9.9 | 80.2 | 72.5 | 39.0 | 50.8 |  | 11.7 | 80.6 | 56.7 | 41.7 | 48.1 |  | 10.0 | 81.6 | 27.4 | 21.8 | 24.3 |\n|  | FR+A2I | 10.0 | 85.0 | 91.5 | 49.8 | **64.5** |  | 10.2 | 82.3 | 75.9 | 49.0 | **59.5** |  | 9.1 | 83.7 | 35.1 | 25.3 | **29.4** |\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| $S\\approx 20\\%$ | FR | 19.6 | 84.8 | 56.6 | 60.5 | 58.5|  | 19.5 | 83.2 | 43.6 | 53.5 | 48.1 |  | 19.4 | 84.4 | 39.2 | 60.3 | 47.5 |\n|  | FR+A2I | 17.2 | 85.7 | 72.7 | 68.2 | **70.3** |  | 20.2 | 88.7 | 57.6 | 73.3 | **64.5** |  | 20.0 | 85.8 | 42.3 | 66.9 | 51.9 |\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| $S\\approx 30\\%$ | FR | 29.9 | 86.1 | 51.5 | 84.0 | 63.9 |  | 28.7 | 81.6 | 18.1 | 32.7 | 23.3 |  | 28.6 | 82.6 | 12.4 | 28.0 | 17.2 |\n|  | FR+A2I | 30.5 | 87.0 | 51.9 | 86.4 | 64.8 |  | 30.2 | 84.8 | 39.7 | 75.7 | **52.1** |  | 29.0 | 83.2 | 13.1 | 30.0 | 18.2 |\n\n| Bert\\_RNP |  | Appearance |  |  |  |  |  | Aroma |  |  |  |  |  | Palate |  |  |  |  |\n|---:|:---:|:---:|---:|---:|---:|---:|---:|:---:|---:|---:|---:|---:|---:|:---:|---:|---:|---:|---:|\n|  |  | s | acc | p | r | f1 |  | s | acc | p | r | f1 |  | s | acc | p | r | f1 |\n| $S\\approx 10\\%$ | RNP | 10.6 | 83.2 | 38.3 | 22.1 | 28.0 |  | 9.8 | 62.6 | 14.7 | 9.0 | 11.2 |  | 10.0 | 66.0 | 9.8 | 7.7 | 8.6 |\n|  | RNP+A2I | 10.2 | 85.4 | 46.8 | 26.0 | 33.5 |  | 10.4 | 77.5 | 15.0 | 9.8 | 11.9 |  | 10.5 | 76.2 | 10.1 | 8.4 | 9.2 |\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| $S\\approx 20\\%$| RNP | 19.6 | 82.4 | 50.7 | 54.4 | 52.5 |  | 19.3 | 66.5 | 14.7 | 17.8 | 16.1 |  | 20.3 | 70.4 | 10.6 | 17.1 | 13.1 |\n|  | RNP+A2I | 19.8 | 84.5 | 55.6 | 60.2 | 57.8 |  | 19.3 | 78.1 | 15.7 | 19.0 | 17.2 |  | 19.1 | 75.4 | 10.8 | 16.3 | 13.0 |\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n|$S\\approx 30\\%$ | RNP | 29.2 | 82.2 | 23.2 | 37.0 | 28.5 |  | 29.6 | 76.3 | 15.8 | 29.5 | 20.6 |  | 29.4 | 72.1 | 11.1 | 25.8 | 15.5 |\n|  | RNP+A2I | 29.9 | 91.1 | 50.7 | 82.7 | 62.9 |  | 29.7 | 77.4 | 19.5 | 36.5 | 25.4 |  | 30.9 | 79.9 | 11.7 | 28.7 | 16.7 |"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322781514,
                "cdate": 1700322781514,
                "tmdate": 1700322781514,
                "mdate": 1700322781514,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6BusSSN0N1",
                "forum": "SdoSUDBWJY",
                "replyto": "LRQtjLaBqz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Other tasks and the prediction accuracy."
                    },
                    "comment": {
                        "value": "**Q2.** If the authors manually label some data from broader topics and more diverse targets and conduct experiments on them, there would be evidence that the selecting bias is common and inherent exists in the RNP framework, and the proposed method could well alleviate it.\n\n**A2** Thank you for your valuable suggestion. We have now added an experiment conducted with GNNs. We use a very widely used graph classification dataset in the field of explainable GNNs: BA2Motifs. There are labels for the gold rationales: the house motif for class 0 and the cycle motif for class 1. We report the overlap (F1 score) of the selected nodes and gold rationales. The base model for each player is a 2-layer GCN. We report the overlap (F1 score) of the selected nodes and gold rationales. The results are as follows: \n\n| BA2Motifs | S | Acc | P | R | F1 |\n|:---:|:---:|:---:|:---:|:---:|---|\n| RNP | 20.3(2.5) | 95.2(1.9) | 36.5(5.5) | 36.5(2.2) | 36.4(3.8) |\n| RNP+A2I | 20.5(2.3) | 95.2(1.5) | 39.7(3.5) | 40.5(2.9) | **40.0(2.5)** |\n|  |  |  |  |  |  |\n| FR | 20.5(2.3) | 96.4(1.8) | 39.3(5.9) | 40.0(4.9) | 39.6(5.2) |\n| FR+A2I | 20.2(1.5) | 96.5(1.4) | 42.1(2.8) | 42.5(4.0) | **42.3(3.0)** |\n\nNotes: The numbers in \"()\" are the standard deviations.\n\n\n**Q3.** By providing more high-quality rationales, the predictions should be more accurate. \n\n**A3.** In general, high-quality rationales do improve classification accuracy. However, the prediction accuracy is also influenced by various other factors, leading to some minor fluctuations. \n\nAlso, due to the sampling bias we analyzed in this study, poor rationales do not necessarily lead to poor prediction (empirically supported by the experiments in Fig.5). Some experimental results in recent papers also show that better rationale quality does not lead to better prediction. In the paper of CR [A], the best rationale quality is achieved by CR, but the best prediction performance is achieved by FR. In the paper of A2R [B], A2R achieves the best rationale quality, but not the best classification performance.\n\nWe also find an interesting paper [C] that argues that spurious features can sometimes improve the accuracy.\n\n\nReferences  \n[A] Towards trustworthy explanation: On causal rationalization. ICML 2023.  \n[B] Understanding Interlocking Dynamics of Cooperative Rationalization. NeurIPS 2021.  \n[C] Spuriosity Didn't Kill the Classifier: Using Invariant Predictions to Harness Spurious Features. arXiv:2307."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322799801,
                "cdate": 1700322799801,
                "tmdate": 1700324794033,
                "mdate": 1700324794033,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "3nRXykaEgX",
            "forum": "SdoSUDBWJY",
            "replyto": "SdoSUDBWJY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6689/Reviewer_H4hs"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6689/Reviewer_H4hs"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors propose a method to address the problem of rationalizing neural prediction. The goal is to use a generator to identify confounding tokens within a language classification task.\n\nSpecifically, the authors focus on a binary classification task that assigns a label to a sequence of word tokens. They acknowledge that among these features, only some are causal variables, while others are spurious. The solution is to train a generator that produces a mask to exclude spurious variables. In their work, the authors introduce an adversarial module that learns to select tokens such that they cause a trained predictor to reverse its label, thereby rendering the tokens invariant to the label.\n\nThe authors have compared their method with existing studies in the same domain and demonstrated its effectiveness."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Overall this paper is well written, and the author delivered their method pretty clearly. \n\n- The motivation of providing explainable instruction for reasonable about natural language is good, especially for the current era of large language models."
                },
                "weaknesses": {
                    "value": "One of the concerns regarding this work is its contribution; the proposed method seems to be merely an add-on to a specific type of problem. The conclusions drawn from binary classification may not easily generalize to a multi-class setting. In binary classification, selecting the reversed label represents a clear worst-case scenario. However, it is not clear how this approach could extend to multi-class cases. In the appendix, the authors provide formulations for multi-class scenarios in equations (17) and (18). I encourage the authors to deliberate on the specific method for \"choosing the $Y' \\neq Y$\u2014should this $Y$\n  be sampled from a uniform distribution, for instance? Moreover, the authors' method assumes the availability of a balanced dataset. How would the algorithm be modified in the presence of imbalanced labels?"
                },
                "questions": {
                    "value": "Reasoning from language could be complicated, there could be more structured knowledge in one sentence beyond confounding information. Sometimes the same words may imply opposite meanings under different contexts. I am wondering how the authors are going to address these more complicated problems in NLP."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No issue"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6689/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699252540674,
            "cdate": 1699252540674,
            "tmdate": 1699636767482,
            "mdate": 1699636767482,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8TMALaIrLu",
                "forum": "SdoSUDBWJY",
                "replyto": "3nRXykaEgX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you very much for the thoughtful review!"
                    },
                    "comment": {
                        "value": "We are really grateful for your constructive feedback and guidance!\n\n**Q1.** One of the concerns regarding this work is its contribution; the proposed method seems to be merely an add-on to a specific type of problem. \n\n**A1.** We are sorry for the confusion, but we think this is a misunderstanding. Aside from the proposed method, the identification of the specific sampling bias problem is also one of our contributions. We are the first one to identify this problem, and this finding is supported by theoretical analysis (Section 4.2) and empirical evidence (Section 5, Fig.5, Fig.6, Fig.7-9).\n\nAlthough the proposed method is an add-on to RNP and its variants, but on the other hand, our method is flexible enough to benefit a number of approaches in this field.\n\n**Q2.** The conclusions drawn from binary classification may not easily generalize to a multi-class setting. In binary classification, selecting the reversed label represents a clear worst-case scenario. However, it is not clear how this approach could extend to multi-class cases. In the appendix, the authors provide formulations for multi-class scenarios in equations (17) and (18). I encourage the authors to deliberate on the specific method for \"choosing the $Y'\\neq Y$ \u2014should this $Y$ be sampled from a uniform distribution, for instance? \n\n**A2.** Thank you for your valuable suggestion. We would like to first clarify a misunderstanding, the $Y$ in Equation 17 is the true label of $X$. $Y'\\neq Y$ means the prediction does not match the true label. The $\\min_{Y'}$ operator means we want to find a $Y'$ that makes the attack easiest. \n\nHere is the detailed clarification on Equation 17:  \nThe general idea is the same as for binary classification:  Consider an n-class classification task. We denote $X^j$ as the text of the $j$-th class. For the $i$-th class, the goal of the attacker  is to find $Z_A$ from those $X^j$ ($j$ can be any value not equal to $i$, i.e., $X^j$ doesn't belong to the $i$-th class) and get the predictor to predict $Z_A$ as the $i$-th class. Equation 17 is a practical implementation of this idea: for an aribitrary data point $X^Y$, the attacker finds the attack rationale $Z_A=f_a(X^Y)$, and the predictor's output is $f_p(Z_A)$. The significance of the $\\min_{\\theta_a}$ operator in Equation 17 is such that $f_p(Z_A)$ is categorized as different from $Y$. And the $\\min_{Y'}$ operator is to see which class $f_p(Z_A)$ is closest to, making the attack easier. If $f_p(Z_A)$ is successfully classified as class $Y'$, then we think the predictor uses some trivial patterns that do not belong exclusively to the $Y'$-th class to make predictions about $Y'$.  \nYou can understand it in a simpler way: $Y,Y'$ in Equation 17 correspond to the above $j$ adn $i$, respectively.  There is a simple way to bridge binary and multi-class classification: In binary classification, $[i,j]=[1,0]$ or $[0,1]$. In n-class calssification, $i,j$ can be any values as long as $i\\neq j, 1\\leq i,j\\leq n$.  \nAnd Equation 18 (the instruction term) is no different from the second term of Equation 5.\n\nAlso, **our analysis about the problem is not limited to binary classification tasks.** The most important analysis about the root of the problem is Equation 7. Here we consider an n-class classification task.     \n**Equation 7 can be extended as follows:**  \nThe setup: $T\\in \\{t_1,t_2,...,t_m\\}$ ($m$ can be an arbitrary integer). $\\forall i \\in [1,m], \\ P(Y)=P(Y|t_i)$, which means $T$ is a trivial pattern independent with $Y$.     \nThe first row of Equation 7 becomes: $\\exist 1\\leq j\\leq n,\\  1\\leq i\\leq m,\\  P(Y=j|Z=t_i,g)>P(Y=j),$ which means that $t_i$ becomes an indicator for the $j$-th class under the condition of the generator.\n\n\n**Q3.**  Moreover, the authors' method assumes the availability of a balanced dataset. How would the algorithm be modified in the presence of imbalanced labels?\n\n**A3.** I guess your question stems from our assumption $P(Y=1)=P(Y=0)=0.5$ in Equation 7. This assumption is made for the sake of theoretical analysis simplicity. For example, if $P(Y=1)>P(Y=0)$ in the original dataset, then a predictor does not need any input to get a accuracy higher than $50\\%$. For unbalanced datasets, we can employ existing methods designed to handle unbalanced labels (e.g., random under-sampling). In fact, the BeerAdvocate dataset we used is a very unbalanced dataset, and the method we used to handle it is random under-sampling. Here are the statistics for the training data of BeerAdvocate:\n\n| aspect | positive | negative |\n|:---:|---|---|\n| appearance | 53114 | 16891 |\n| aroma | 46386 | 15169 |\n| palate | 47592 | 13652 |"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322757243,
                "cdate": 1700322757243,
                "tmdate": 1700322757243,
                "mdate": 1700322757243,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "J4wUTg3yQy",
            "forum": "SdoSUDBWJY",
            "replyto": "SdoSUDBWJY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6689/Reviewer_QZhC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6689/Reviewer_QZhC"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses the task of eXplainable Artificial Intelligence (XAI) where the goal is to increase the transparency of deep learning models to enhance trust in their decisions regarding fairness, security, and robustness. It explores a self-explaining framework called Rationalizing Neural Predictions (RNP) used in NLP models, which employs a cooperative game involving a generator and a predictor. \n\nIt identifies a potential sampling bias issue in the RNP framework, where the generator might select semantically unrelated trivial patterns as explanations, leading to implausible explanations. The paper proposes an adversarial game-based approach to inspect and identify this bias, and introduces a method to instruct the game to debias the predictor by penalizing it when it learns from the bias. \n\nExperimental results demonstrate the existence of sampling bias and the effectiveness of the inspection and instruction methods, which are model-agnostic and improve the performance of self-explaining models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Originality: the paper proposes an interesting strategy to identify the bias problem within self-explanation, and introduces an efficient combination of an adversarial approach, and the development of an instruction objective for mitigating bias. \n\n- Quality: the paper runs a decent set of experiments to evaluate their method against existing ones.\n\n- Clarity: the presentation of the methodology, the pipeline and the experimental results are well-structured and easy to follow.\n\n- Significance: contributions made to self-explaining rationalization and interpretable machine learning have wild impact in the literature, and the fact the authors achieved good results with their method is significant"
                },
                "weaknesses": {
                    "value": "- No code to verify the results\n\n-  While the paper discusses the theoretical aspects of sampling bias and introduces a solution for self-explanation, it falls short in discussing the real-world implications of this bias in AI applications. Providing concrete examples or case studies of how sampling bias can impact decision-making systems would enhance the paper's practical relevance.\n\n- The datasets BeerAdvocate and HotelReview seem small and basic. I am curious to see how this method performs on larger scale datasets like CIFAR10\n\n- No reporting of the mean and standard deviation of multiple experiments to see if the results are significant"
                },
                "questions": {
                    "value": "Please address the weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6689/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699276876665,
            "cdate": 1699276876665,
            "tmdate": 1699636767376,
            "mdate": 1699636767376,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4bGlRDnzof",
                "forum": "SdoSUDBWJY",
                "replyto": "J4wUTg3yQy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you very much for the insightful review and suggestions!"
                    },
                    "comment": {
                        "value": "We really appreciate your valuable comments and suggestions!\n\n**Q1.** No code to verify the results\n\n**A1.** We have now updated the code and the instructions at the general response. They are only visible to reviewers.\n\n**Q2.** While the paper discusses the theoretical aspects of sampling bias and introduces a solution for self-explanation, it falls short in discussing the real-world implications of this bias in AI applications. Providing concrete examples or case studies of how sampling bias can impact decision-making systems would enhance the paper's practical relevance.\n\n**A2.** Thank you for your suggestion. We have now added two case studies in Fig.10 of Appendix A.7.\n\n**Q3.** The datasets BeerAdvocate and HotelReview seem small and basic. I am curious to see how this method performs on larger scale datasets like CIFAR10. \n\n**A3.** While BeerAdvocate is relatively small (about 30,000 texts for each aspect), the HotelReview is much larger. Hotel-Service has more than 100,000 texts and Hotel-Cleanliness has more than 150,000 texts. We'd like to conduct experiments on CIFAR10, but the problem is that it does not have human-annotated rationales for evaluation. As we have mentioned in Section 5.2.1, the sampling bias problem makes the prediction performance not a good metric. \n\nAs an alternative, we now add experiments on a graph neural network dataset to validate the generalization capabilities of the method.  We use a wiedly used dataset in the field of explainable GNNs: BA2Motifs. This is a graph classification dataset and has labeled gold rationales for evaluation. The base model for each player is a 2-layer GCN. We report the overlap (F1 score) of the selected nodes and gold rationales.\nThe results are as follows:\n\n| BA2Motifs | S | Acc | P | R| F1 |\n|:---:|:---:|:---:|:---:|:---:|---|\n| RNP | 20.3(2.5) | 95.2(1.9) | 36.5(5.5) | 36.5(2.2) | 36.4(3.8) |\n| RNP+A2I | 20.5(2.3) | 95.2(1.5) | 39.7(3.5) | 40.5(2.9) | **40.0(2.5)** |\n|  |  |  |  |  |  |\n| FR | 20.5(2.3) | 96.4(1.8) | 39.3(5.9) | 40.0(4.9) | 39.6(5.2) |\n| FR+A2I | 20.2(1.5) | 96.5(1.4) | 42.1(2.8) | 42.5(4.0) | **42.3(3.0)** |\n\nNotes: The numbers in \"()\" are the standard deviations.\n\n**Q4.** No reporting of the mean and standard deviation of multiple experiments to see if the results are significant\n\n**A4.** We now report the standard deviation. In our original experiments, we use a fixed random seed of 12252018 (inherited from the code provided by our baseline FR), because we think that experiments with 12 different settings (beer: 3 aspects $*$ 3 sparsity, hotel: 3 aspects) under the same random seed are somewhat sufficient to verify the stability of the models. Here we rerun RNP and RNP+A2I with 4 additional seeds and report the standard deviation over the five random seeds. Notes: The format of the numbers is \"avg(std)\".\n\n|  |  | Appearance |  |  |  |  |  | Aroma |  |  |  |  |  | Palate |  |  |  |  |\n|---:|:---:|:---:|---:|---:|---:|---:|---:|:---:|---:|---:|---:|---:|---:|:---:|---:|---:|---:|---:|\n|  |  | s | acc | p | r | f1 |  | s | acc | p | r | f1 |  | s | acc | p | r | f1 |\n| $S\\approx 10\\%$  | RNP | 9.0(1.2) | 81.5(1.5) | 83.4(8.0) | 40.3(5.5) | 54.2(5.9) |  | 9.2(1.2) | 83.7(1.7) | 84.1(2.7) | 49.7(5.5) | 62.3(4.1) |  | 9.7(0.3) | 83.2(1.8) | 69.1(2.1) | 53.8(1.9) | 60.5(1.8) |\n|  | RNP+A2I | 10.0(0.6) | 82.6(1.3) | 82.2(3.6) | 44.8(1.0) | 58.1(0.7) |  | 9.9(0.3) | 83.8(2.0) | 84.5(1.0) | 53.9(1.2) | 65.8(0.9) |  | 10.1(0.5) | 85.4(1.1) | 69.3(2.3) | 56.3(1.6) | 62.1(1.3) |\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| $S\\approx 20\\%$  | RNP | 19.5(0.3) | 83.3(1.4) | 69.2(2.6) | 73.1(3.7) | 71.1(3.1) |  | 21.0(0.7) | 85.8(1.2) | 43.9(2.7) | 59.2(2.0) | 50.4(2.5) |  | 19.2(0.8) | 85.3(1.9) | 47.0(2.0) | 72.7(5.0) | 57.0(2.9) |\n|  | RNP+A2I | 20.0(0.1) | 85.2(2.6) | 72.6(0.9) | 78.6(1.0) | 75.5(1.0) |  | 19.5(0.3) | 86.3(1.7) | 50.1(1.0) | 62.7(1.4) | 55.6(1.1) |  | 18.8(0.8) | 86.2(0.6) | 48.4(3.0) | 72.8(2.9) | 58.2(2.9) |\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| $S\\approx 30\\%$  | RNP | 30.5(1.1) | 85.5(2.4) | 55.9(2.6) | 92.2(3.2) | 69.6(2.7) |  | 31.2(0.4) | 85.9(3.7) | 39.2(1.8) | 78.5(3.1) | 52.3(2.3) |  | 29.0(0.9) | 86.1(2.6) | 31.1(2.7) | 72.6(6.1) | 43.6(3.7) |\n|  | RNP+A2I | 29.7(0.2) | 85.7(1.7) | 59.5(0.7) | 95.5(1.3) | 73.4(0.9) |  | 29.4(1.1) | 88.0(1.2) | 44.8(1.6) | 84.6(3.7) | 58.5(2.0) |  | 28.5(0.9) | 86.4(0.8) | 32.5(1.7) | 74.7(5.0) | 45.3(2.5) |\n\n\nDue to the large amount of GPU resources consumed by Bert related experiments, the random seed experiments for FR are still in preparation."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322610400,
                "cdate": 1700322610400,
                "tmdate": 1700324746045,
                "mdate": 1700324746045,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "QBUSbg5SD0",
            "forum": "SdoSUDBWJY",
            "replyto": "SdoSUDBWJY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6689/Reviewer_MTBk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6689/Reviewer_MTBk"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents an interesting approach to addressing the issue of sampling bias in self-explaining text classification models. The authors propose a method called Attack to Inspection and Instruction (A2I), which uses an adversarial game to inspect and correct the predictor's behavior in a Rationalizing Neural Predictions (RNP) framework. The paper is well-motivated, and the problem of sampling bias in self-explaining models is a relevant and important one in the field of explainable AI."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper addresses a significant problem in the field of explainable AI, which is the potential for sampling bias to lead to incorrect correlations between selected explanations and labels.\n2. The authors provide a thorough theoretical motivation for their approach, explaining how the adversarial game can detect and mitigate sampling bias.\n3. The experiments conducted on two real-world benchmarks demonstrate the effectiveness of the proposed method, with significant improvements in rationale quality over the baseline RNP model and other advanced methods."
                },
                "weaknesses": {
                    "value": "1. The paper primarily focuses on binary classification tasks, and it is not clear how well the proposed method would generalize to multi-class classification or other types of machine learning tasks.\n2. While the authors mention that the proposed method is model-agnostic, the experiments are limited to the RNP framework and its variants. It would be beneficial to see the method applied to other types of models to assess its generalizability.\n3. The paper could benefit from a more detailed discussion on the limitations of the proposed method, including potential scenarios where the adversarial game might fail to detect certain types of biases or where the instruction phase might not effectively debias the predictor.\n4. The use of GRUs and GloVe embeddings, while understandable for comparison purposes, may not reflect the current state-of-the-art in NLP, where transformer-based models like BERT are prevalent. It would be interesting to see how the proposed method performs with such models."
                },
                "questions": {
                    "value": "None"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6689/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699422076621,
            "cdate": 1699422076621,
            "tmdate": 1699636767258,
            "mdate": 1699636767258,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hTpfOzFKYh",
                "forum": "SdoSUDBWJY",
                "replyto": "QBUSbg5SD0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "content": {
                    "title": {
                        "value": "About multi-class classification, other tasks, and limitations"
                    },
                    "comment": {
                        "value": "We greatly appreciate your detailed review and constructive feedback on our paper!\n\n*Q1.** The paper primarily focuses on binary classification tasks, and it is not clear how well the proposed method would generalize to multi-class classification or other types of machine learning tasks.\n\n**A1.** Although we use binary classification datasets in our experiments (since there are no proper multi-class classification datasets that have human-annotated rationales), we have also provided formulations for multi-class scenarios in Appendix A.2.  The general idea is the same as for binary classification:  Consider an n-class classification task. We denote $X^j$ as the text of the $j$-th class. For the $i$-th class, the goal of the attacker  is to find $Z_A$ from those $X^j$ ($j$ can be any value not equal to $i$, i.e., $X^j$ doesn't belong to the $i$-th class) and get the predictor to predict $Z_A$ as the $i$-th class. Equation 17 is a practical implementation of this idea: for an aribitrary data point $X^Y$, the attacker finds the attack rationale $Z_A=f_a(X^Y)$, and the predictor's output is $f_p(Z_A)$. The significance of the $\\min_{\\theta_a}$ operator in Equation 17 is such that $f_p(Z_A)$ is categorized as different from $Y$. And the $\\min_{Y'}$ operator is to see which class $f_p(Z_A)$ is closest to, making the attack easier. If $f_p(Z_A)$ is successfully classified as class $Y'$, then we think the predictor uses some trivial patterns that do not belong exclusively to the $Y'$-th class to make predictions about $Y'$.  \nYou can understand it in a simpler way: $Y,Y'$ in Equation 17 correspond to the above $j$ adn $i$, respectively.  There is a simple way to bridge binary and multi-class classification: In binary classification, $[i,j]=[1,0]$ or $[0,1]$. In n-class calssification, $i,j$ can be any values as long as $i\\neq j, 1\\leq i,j\\leq n$.  \nAnd Equation 18 (the instruction term) is no different from the second term of Equation 5.\n\nAlso, **our analysis about the problem is not limited to binary classification tasks.** The most important analysis about the root of the problem is Equation 7. Here we consider an n-class classification task.     \n**Equation 7 can be extended as follows:**  \nThe setup: $T\\in \\{t_1,t_2,...,t_m\\}$ ($m$ can be an arbitrary integer). $\\forall i \\in [1,m], \\ P(Y)=P(Y|t_i)$, which means $T$ is a trivial pattern independent with $Y$.     \nThe first row of Equation 7 becomes: $\\exist 1\\leq j\\leq n,\\  1\\leq i\\leq m,\\  P(Y=j|Z=t_i,g)>P(Y=j),$ which means that $t_i$ becomes an indicator for the $j$-th class under the condition of the generator.\n\n**Experiments on GNNs:**\nWe have now generalized our method to other machine learning tasks. In particular, we extend it to explainable graph neural networks. We conduct experiments on BA2Motifs, which is a widely used dataset in the field of explainable GNNs. It's a graph classification dataset. There are labels for the gold rationales: the house motif for class 0 and the cycle motif for class 1. The base model for each player is a 2-layer GCN. We report the overlap (F1 score) of the selected nodes and gold rationales.\n\n|  | s | acc | p | r | f1 |\n|:---:|:---:|:---:|:---:|:---:|---|\n| RNP | 20.3(2.5) | 95.2(1.9) | 36.5(5.5) | 36.5(2.2) | 36.4(3.8) |\n| RNP+A2I | 20.5(2.3) | 95.2(1.5) | 39.7(3.5) | 40.5(2.9) | **40.0(2.5)** |\n|  |  |  |  |  |  |\n| FR | 20.5(2.3) | 96.4(1.8) | 39.3(5.9) | 40.0(4.9) | 39.6(5.2) |\n| FR+A2I | 20.2(1.5) | 96.5(1.4) | 42.1(2.8) | 42.5(4.0) | **42.3(3.0)** |\n\nNotes: The numbers in \"()\" are the standard deviations.\n\n**Q2.** While the authors mention that the proposed method is model-agnostic, the experiments are limited to the RNP framework and its variants. It would be beneficial to see the method applied to other types of models to assess its generalizability.\n\n**A2.** We are grateful for the suggestion, but we think there is a misunderstanding. RNP is not a niche field, as mentioned in the related work section, with new research in this domain emerging every year. This is attributed to the fact that the cooperative game proposed by RNP is a mainstream approach in NLP for constructing self-explanatory models. When we refer to \"model-agnostic,\" we are referring specifically to RNP and its variants. Now, we have added additional experiments to show that the method can be generalized to GNNs, which is shown in **A1** above.\n\n**Q3.** The paper could benefit from a more detailed discussion on the limitations of the proposed method, including potential scenarios where the adversarial game might fail to detect certain types of biases or where the instruction phase might not effectively debias the predictor.\n\n**A3.** Thanks a lot for your suggestions. Since we are focusing on the bias introduced by the generator's selection, one type of the bias that we cannot deal with is the bias already exist in the dataset. We will add it to the present limitations."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322330223,
                "cdate": 1700322330223,
                "tmdate": 1700324695784,
                "mdate": 1700324695784,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hzVtx78Joo",
                "forum": "SdoSUDBWJY",
                "replyto": "QBUSbg5SD0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "content": {
                    "title": {
                        "value": "BERT Encoder Experiments and Clarifications"
                    },
                    "comment": {
                        "value": "**Q4.**  The use of GRUs and GloVe embeddings, while understandable for comparison purposes, may not reflect the current state-of-the-art in NLP, where transformer-based models like BERT are prevalent. It would be interesting to see how the proposed method performs with such models.\n\n**A4.** Thanks for your suggestion. We have now re-run RNP and FR with the Bert encoder on the three aspects of BeerAdvocate. Although fine-tuning Bert is still very difficult, we find that using a smaller learning rate for the Bert encoder than for the linear layer works somewhat. So we use a learning rate of $1e-5$ for the Bert encoder and $1e-4$ for the linear layer. The maximum sequence length is 256 (this is enough for the Beer dataset). The batch size is 24. \n\nFrom the second table, we see that Bert\\_RNP performs much worse than GRU\\_RNP, so there must be some unknown issues prevent RNP to work well with Bert. The sampling bias problem studied in our paper may not be the only obstacle that prevents Bert_RNP to work well, so in most cases, A2I does not improve Bert_RNP a lot.  \n\nBut from the first table, we see that Bert_FR improves Bert_RNP a lot. So the obstacles introduced by the Bert encoder may have somewhat been overcomed by FR. Under this case, our A2I improves Bert_FR a lot (more than $5\\%$ in 6 of 9 settings). We believe that future researchers will further explore harnessing the power of Bert within the RNP framework. At that point, we can also build upon subsequent methods to incorporate our A2I.\n\nNotes: We highlight the results only when FR+A2I gives an improvement over $5\\%$ compared to FR.\n\n| Bert\\_FR |  | Appearance |  |  |  |  |  | Aroma |  |  |  |  |  | Palate |  |  |  |  |\n|---:|:---:|:---:|---:|---:|---:|---:|---:|:---:|---:|---:|---:|---:|---:|:---:|---:|---:|---:|---:|\n|  |  | s | acc | p | r | f1 |  | s | acc | p | r | f1 |  | s | acc | p | r | f1 |\n| $S\\approx 10\\%$ | FR | 9.9 | 80.2 | 72.5 | 39.0 | 50.8 |  | 11.7 | 80.6 | 56.7 | 41.7 | 48.1 |  | 10.0 | 81.6 | 27.4 | 21.8 | 24.3 |\n|  | FR+A2I | 10.0 | 85.0 | 91.5 | 49.8 | **64.5** |  | 10.2 | 82.3 | 75.9 | 49.0 | **59.5** |  | 9.1 | 83.7 | 35.1 | 25.3 | **29.4** |\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| $S\\approx 20\\%$ | FR | 19.6 | 84.8 | 56.6 | 60.5 | 58.5|  | 19.5 | 83.2 | 43.6 | 53.5 | 48.1 |  | 19.4 | 84.4 | 39.2 | 60.3 | 47.5 |\n|  | FR+A2I | 17.2 | 85.7 | 72.7 | 68.2 | **70.3** |  | 20.2 | 88.7 | 57.6 | 73.3 | **64.5** |  | 20.0 | 85.8 | 42.3 | 66.9 | 51.9 |\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| $S\\approx 30\\%$ | FR | 29.9 | 86.1 | 51.5 | 84.0 | 63.9 |  | 28.7 | 81.6 | 18.1 | 32.7 | 23.3 |  | 28.6 | 82.6 | 12.4 | 28.0 | 17.2 |\n|  | FR+A2I | 30.5 | 87.0 | 51.9 | 86.4 | 64.8 |  | 30.2 | 84.8 | 39.7 | 75.7 | **52.1** |  | 29.0 | 83.2 | 13.1 | 30.0 | 18.2 |\n\n| Bert\\_RNP |  | Appearance |  |  |  |  |  | Aroma |  |  |  |  |  | Palate |  |  |  |  |\n|---:|:---:|:---:|---:|---:|---:|---:|---:|:---:|---:|---:|---:|---:|---:|:---:|---:|---:|---:|---:|\n|  |  | s | acc | p | r | f1 |  | s | acc | p | r | f1 |  | s | acc | p | r | f1 |\n| $S\\approx 10\\%$ | RNP | 10.6 | 83.2 | 38.3 | 22.1 | 28.0 |  | 9.8 | 62.6 | 14.7 | 9.0 | 11.2 |  | 10.0 | 66.0 | 9.8 | 7.7 | 8.6 |\n|  | RNP+A2I | 10.2 | 85.4 | 46.8 | 26.0 | 33.5 |  | 10.4 | 77.5 | 15.0 | 9.8 | 11.9 |  | 10.5 | 76.2 | 10.1 | 8.4 | 9.2 |\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| $S\\approx 20\\%$| RNP | 19.6 | 82.4 | 50.7 | 54.4 | 52.5 |  | 19.3 | 66.5 | 14.7 | 17.8 | 16.1 |  | 20.3 | 70.4 | 10.6 | 17.1 | 13.1 |\n|  | RNP+A2I | 19.8 | 84.5 | 55.6 | 60.2 | 57.8 |  | 19.3 | 78.1 | 15.7 | 19.0 | 17.2 |  | 19.1 | 75.4 | 10.8 | 16.3 | 13.0 |\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n|$S\\approx 30\\%$ | RNP | 29.2 | 82.2 | 23.2 | 37.0 | 28.5 |  | 29.6 | 76.3 | 15.8 | 29.5 | 20.6 |  | 29.4 | 72.1 | 11.1 | 25.8 | 15.5 |\n|  | RNP+A2I | 29.9 | 91.1 | 50.7 | 82.7 | 62.9 |  | 29.7 | 77.4 | 19.5 | 36.5 | 25.4 |  | 30.9 | 79.9 | 11.7 | 28.7 | 16.7 |"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322431905,
                "cdate": 1700322431905,
                "tmdate": 1700322431905,
                "mdate": 1700322431905,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qUPQOZWqgN",
            "forum": "SdoSUDBWJY",
            "replyto": "SdoSUDBWJY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6689/Reviewer_TefW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6689/Reviewer_TefW"
            ],
            "content": {
                "summary": {
                    "value": "The authors study the problem of self-explainable models through the lens of the Rationalizing Neural Predictions (RNP) framework, where a generator which selects a subset of the input sequence is trained jointly with the predictor to produce an extractive rationale. Here, they look to explain and tackle one particular problem with RNP -- that it may degenerate into the generator selecting a special semantically unmeaningful token, which the predictor learns to associate with a particular label. The authors first theoretically study the problem through the perspective of sampling bias. Then, they propose a method based on training an attacker which tries to produce a justification for the opposite label, and regularizing the generator with this justification. They show that their method outperforms the baselines on typical RNP datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The authors beat the baselines on typical RNP datasets.\n- The proposed method is intuitive at a high level."
                },
                "weaknesses": {
                    "value": "1. The authors do not sufficiently show that this degeneration is an issue empirically in my opinion. To start, the authors should show a few real examples where vanilla RNP gives a nonsense justification while the predictor still outputs the correct label; and show that RNP + A2I fixes these cases. In addition, the authors could consider plotting a histogram of the length of the rationale (for RNP and RNP+A2I), and showing that samples with short justifications correspond to degenerate cases (e.g. the punctuation example). Overall, the sparsity of the A2I augmented models (in Table 1) do not seem significantly different from the sparsity of the base models, and so I am not convinced that A2I solves the issue presented.\n\n2. The proposed method makes sense, but there are several much simpler solutions that the authors should try and compare with. First, it seems to me that the root cause of the problem is that the generator is overpowered -- it's able to internally detect the label, and then feed special tokens correlated with the label to the predictor which do not have semantic meaning. As such, some simple solutions would be to reduce the capacity of the generator; add regularization to the generator; or to train the generator and predictor in an alternating fashion, with more steps for the predictor. The final suggestion is similar to how GANs are trained. In addition, the problem examined is very similar to mode collapse in GANs, and some of the solutions there (e.g. a diversity regularizer [1]) could work as well.\n\n\n3. There are a few edge cases which I am not convinced that A2I will be able to fix. Primarily, these deal with the circumstance where, in the toy example, the $t_+$ do not appear in the negative samples, and vice versa -- so $t_+$ is a token that appears almost exclusively in positive examples, and $t_-$ is a token that appears almost exclusively in negative examples. Such spurious correlations have been found in natural language tasks [3-4]. In these cases, it seems like the attacker would not be able to choose the corresponding token, and would thus still output random noise. \n\n4. Another concern deals with the singular sentiment assumption. This seems like a strong assumption that is very dataset and task specific, and the authors already discuss its failure modes in the appendices. The presence of negation seems to be another case where the assumption would be violated. As such, I am not convinced in the generalizability of the method to other datasets and tasks.  Regardless, the authors should formulate this assumption mathematically in the text.\n\n\n5. Overall, the clarity of the paper could be improved. Some of the formulation sections are hard to parse. For example, the authors formulate the problem as one of sampling bias, which makes sense intuitively. However, the mathematical formulation and causal graphs for this section don't follow the prior work in sampling bias [2].\n\n\n6. The utility of the method is limited in the era of large pre-trained LLMs, which would achieve very high _zero-shot_ accuracy on all of the sentiment tasks evaluated, likely even higher than the GloVe + GRU networks studied in the paper. Such LLMs also have the capability of explaining its own reasoning (as the authors have referenced). To improve the significance of the method, the authors should consider applying their method to finetune a large-scale LLM (though the authors mention that even finetuning BERT is challenging for RNP). They could also consider applying it to images and graphs, as described in the introduction.\n\n7. The authors do not show any confidence intervals for their results, so it is unclear whether performance gains are statistically significant. They also only evaluate on two datasets, though these seem to be standard datasets in the RNP community.\n\n\n[1] Diversity-Sensitive Conditional Generative Adversarial Networks. ICLR 2019.\n\n[2] Controlling Selection Bias in Causal Inference. AISTATS 2012.\n\n[3] An empirical study on robustness to spurious correlations using pre-trained language models. TACL 2020.\n\n[4] On Feature Learning in the Presence of Spurious Correlations. NeurIPS 2022."
                },
                "questions": {
                    "value": "Please address the weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6689/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699568716053,
            "cdate": 1699568716053,
            "tmdate": 1699636767127,
            "mdate": 1699636767127,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "amSXJlujOl",
                "forum": "SdoSUDBWJY",
                "replyto": "qUPQOZWqgN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Concerns about the empirical support for the existence of the problem."
                    },
                    "comment": {
                        "value": "We sincerely appreciate your efforts to help improve the quality of this study. Here are some more detailed clarifications that may address your concerns.\n\n**Q1.** The authors do not sufficiently show that this degeneration is an issue empirically in my opinion. To start, the authors should show a few real examples where vanilla RNP gives a nonsense justification while the predictor still outputs the correct label; and show that RNP + A2I fixes these cases. In addition, the authors could consider plotting a histogram of the length of the rationale (for RNP and RNP+A2I), and showing that samples with short justifications correspond to degenerate cases (e.g. the punctuation example). Overall, the sparsity of the A2I augmented models (in Table 1) do not seem significantly different from the sparsity of the base models, and so I am not convinced that A2I solves the issue presented.\n\n**A1.1. (The authors do not sufficiently show that this degeneration is an issue empirically in my opinion.)**  \nSorry for the confusion, we indeed did not show it in the introduction. But we have shown it with practical experiments in Section 5. \n\nWe first show the risk of this bias with experiments designed from three perspectives in Section 5.1 (i.e., Fig.5, Fig.8, and Fig.9). \nWe present three types of prediction accuracies for the BeerAdvocate dataset: (1) A predictor trained\nwith the full input text. (2) A predictor trained with randomly selected patterns. For the generator, we\nremove the other objectives and only train it with the sparsity constraints. In other words, the generator\nis trained to randomly select 10% of the input text, and the predictor is then trained to classify using\nthese randomly selected texts. (3) We use the randomly selected texts from (2) to feed the predictor\ntrained in (1).  \nThe result for the Aroma aspect is shown in Figure 5. From Figure 5(a), we observe that even with the\nrandomly selected patterns (i.e., patterns unlikely to contain real rationales), the predictor can still\nachieve a very high prediction accuracy (represented by the orange line, approximately 95%). This\naccuracy is close to that of the classifier trained with the full texts. A followed question is: Does this\nresult suggest that the 10% randomly selected patterns already contain enough sentiment inclination\nfor classification? The answer is no. Consider the green line, which represents the outcome when\nwe feed the randomly selected texts to the predictor denoted by the blue line. We observe that the\ngreen line indicates a significantly lower accuracy (about 58%), implying that the randomly selected\npatterns contain only minimal sentiment information. Thus, the orange predictor incorrectly treats\ncertain randomly selected trivial patterns as indicative features. \n\nThen, we show the existence of the bias in the normally trained RNP framework with Attack Success Rate (ASR) in Section 5.2 (i.e., Fig.6 and Fig.7). In Fig.6(a), the attack success rate is very high (about $85\\%$), which indicates that the predictor indeed utilizes some category-agnostic features for classification, and the attacker has successfully identified these features.\n\n**A1.2 (the authors should show a few real examples where vanilla RNP gives a nonsense justification while the predictor still outputs the correct label; and show that RNP + A2I fixes these cases.)**   \nThank you for your suggestions. We have now added two examples of the sampling bias in Figure 10 of Appendix A.7.  The sparsity is about $10\\%$ (note that $10\\%$ is the **average** sparsity across the dataset, and it is manually determined by $s$ in Equation 4 rather than the model's power. So it is possible that some texts may have low sparsity and others have high sparsity.).\n\n**A1.3 (In addition, the authors could consider plotting a histogram of the length of the rationale (for RNP and RNP+A2I), and showing that samples with short justifications correspond to degenerate cases (e.g. the punctuation example). Overall, the sparsity of the A2I augmented models (in Table 1) do not seem significantly different from the sparsity of the base models, and so I am not convinced that A2I solves the issue presented.).**   \nWe are sorry, but we think this is a misunderstanding. The sparsity in Table 1 is the average sparsity over the entir dataset, and it is manually determined by $s$ in Equation 4 rather than the model's power. The punctuation example is just an imaginary toy example to better understand this problem. You can also refer to the example in our Fig.2, where the sentence \"I went to a hotel yesterday\" is a trivial pattern and plays the same role as \".\" in the punctuation example. In fact, short justifications do not correspond to degenerate cases and vice versa."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700321998827,
                "cdate": 1700321998827,
                "tmdate": 1700637125792,
                "mdate": 1700637125792,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WdTmxAgtPM",
                "forum": "SdoSUDBWJY",
                "replyto": "qUPQOZWqgN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Other methods to consider."
                    },
                    "comment": {
                        "value": "**Q2.** The proposed method makes sense, but there are several much simpler solutions that the authors should try and compare with. First, it seems to me that the root cause of the problem is that the generator is overpowered -- it's able to internally detect the label, and then feed special tokens correlated with the label to the predictor which do not have semantic meaning. As such, some simple solutions would be to reduce the capacity of the generator; add regularization to the generator; or to train the generator and predictor in an alternating fashion, with more steps for the predictor. The final suggestion is similar to how GANs are trained. In addition, the problem examined is very similar to mode collapse in GANs, and some of the solutions there (e.g. a diversity regularizer [1]) could work as well.\n\n**A2.** Thanks you for your insightful suggestions. Our initial focus was on training a good predictor to guide the generator in producing appropriate rationales. This is because we believe that the generator must first identify the sentiment and then select the rationales that represent the sentiment. So, our focus is on avoiding the second part of your suggestion (feed special tokens correlated with the label to the predictor which do not have semantic meaning) . \nAlso, experiments in the reviewer-author discussion of FR (one of our baselines) showed that adding more layers to the encoder of the RNP's generator does not necessarily decrease its performance (more powerful generator does not lead to worse results, so reducing the capacity may not be the first choice for us). Finally, we want to point out that the root cause is not simply that the generator is overpowered. We think the root is $Y\\perp Z\\nRightarrow Y\\perp Z|g$, meaning that any random bias in the generator's selection can make a trivial pattern (independent with $Y$) be correlated with $Y$.  Note that the punctuation example is only an extreme toy example. Experiments in Fig.5(a) show empirical evidence for this claim. The orange line corresponds to a randomly initialized generator (not trained to recognize any semantics), but the predictor can still make correct predictions with the random selected rationales.  \nFor the above reasons, reducing the capacity of the generator is not the primary focus  of our efforts. Nevertheless, we have also ever considered some of the above methods.  \n**A2.1 (about reducing the capacity of the generator).**   \nWe do not deny that some methods can work. But it is non-trivial to design a good method that works well. Since we need to maintain the generotor's power for identifing the sentiment rationales, we need to be very careful when reducing the capacity of the generator to get a trade-off. Practically, we have ever considered to add spectral normalization (SN) to the generator's linear layer to restrict its Lipschitz continuity and produce a more flatter model. But we found that this trick actually hurts the model. When the SN is added, the model cannot be trained at all.\n**A2.2 (about adding regularization to the generator).**   \nIn fact, a previous method 3PLAYER [A] has tried to do this. It takes the unselected part into consideration and the regularization term for the generator is to make the unselected part to be unable be classified correctly. But it has been empirically verified by several later papers [B,C] that it does not improve the rationale quality significantly as compared to the vanilla RNP.\n**A2.3 (about training more steps for the predictor).**  \nIn the paper of FR, it has been empirically shown (Fig.1 in FR) that training the predictor with a higher learning rate than the generator (which is somewhat similar to training the predictor for more steps) unexpectedly results in a decrease in the quality of rationales. Instead, training the generator with a higher learning rate improves the rationale quality. \n**A2.4 (mode collapse).**   \nAlthough we call the generator a generator, but actually in fact a selector which outputs binary masks (e.g., \"0,1,1,0,0,1\") instead of real text. How to measure the diversity is not easy. Also, the problem is not completely the same as mode collapse. A well-known method to address mode collapse in GANs is using a smaller learning rate for the generator [D]. But according to A2.3, this method does not work for the cooperative game of rationalization. \n\nWe are grateful for your valuable suggestions, and we do not claim that this method is the sole or optimal solution to this problem. However, exploring more advanced methods is somewhat beyond the scope of this paper. We would like to respectfully clarify that our contributions in this paper are not limited to the proposed method. Another important contribution is the identification of this special sampling bias problem (**Q1** and **A1** above)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322041069,
                "cdate": 1700322041069,
                "tmdate": 1700322041069,
                "mdate": 1700322041069,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ui0Jig2Aqt",
                "forum": "SdoSUDBWJY",
                "replyto": "qUPQOZWqgN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Edge cases, singular sentiment assumption, and the mathematical formulation."
                    },
                    "comment": {
                        "value": "**Q3.** There are a few edge cases which I am not convinced that A2I will be able to fix. Primarily, these deal with the circumstance where, in the toy example, the do not appear in the negative samples, and vice versa -- so is a token that appears almost exclusively in positive examples, and is a token that appears almost exclusively in negative examples. Such spurious correlations have been found in natural language tasks [3-4]. In these cases, it seems like the attacker would not be able to choose the corresponding token, and would thus still output random noise. \n\n**A3.** If we understand correctly, you are discussing the spurious correlations that already exist in the original dataset. It involves another line of research that is orthogonal to this paper. Existing research on causality has primarily focused on spurious correlations inherent in the dataset. However, our research investigates a novel question: if the dataset itself is clean and lacks spurious correlations, could the selection process of the generator introduce additional spurious correlations? This poses a unique research question in our study.\n\nOur research problem in this study is the spurious correlations introduced by the generator's selection (as implied in Section 4.2, trivial patterns in this paper refer to those independent with $Y$). \nWe acknowledge that we cannot deal with those spurious correlations that exist in the original dataset. We see a recent study MCD [E] in the field of rationalization has already noticed this problem and addressed it well. As we have implied in our submission, our A2I is model-agnostic, we will consider building our A2I on top of MCD in the future, just like FR+A2I in our paper.\n\n\n\n**Q4.** Another concern deals with the singular sentiment assumption. This seems like a strong assumption that is very dataset and task specific, and the authors already discuss its failure modes in the appendices. The presence of negation seems to be another case where the assumption would be violated. As such, I am not convinced in the generalizability of the method to other datasets and tasks. Regardless, the authors should formulate this assumption mathematically in the text.\n\n**A4.** \n$S\\in \\{s_+,s_-\\}$ constitutes indicative features for the category (e.g., sentiment orientation), i.e., $Y$ is primarily determined by $S$ within $X$. Additionally, there may exist descriptions $K\\in \\{k_+,k_-\\}$ in $X$ related to sentiment but not decisive for the label (e.g., softened tones).  \nFormally, the  singular sentiment assumption is $P(\\phi(x,s_-)|Y=1)=0, P(\\phi(x,s_+)|Y=0)=0$.  \nThe reason we make this assumption is that we think that $s_+$ and $s_-$ will not appear in one $x$ simultaneously, otherwise we would not be able to determine to which category this $x$ belongs. And if $s_+$ and $k_-$ appear in one $x$, that $x$ still belongs to $Y=1$. So, $K$ is still a trivial pattern, and this is what we discussed in the appendix.\n\nIf you still think this assumption is too strong, we can make it a relaxed one: $P(\\phi(x,s_-)|Y=1)=\\epsilon=P(\\phi(x,s_+)|Y=0), \\ s.t., \\epsilon \\ll P(\\phi(x,s_-))$, which means that it is very hard for the attacker to find $s_-$ from $X$ labeled $1$. Based on it, our analysis in the last paragraph of Section 4.2 still makes sense.\n\n\n\n**Q5.** Overall, the clarity of the paper could be improved. Some of the formulation sections are hard to parse. For example, the authors formulate the problem as one of sampling bias, which makes sense intuitively. However, the mathematical formulation and causal graphs for this section don't follow the prior work in sampling bias [2].\n\n**A5.** Thank you for your suggestion. But could you please provide more details about the unclarity? Sampling bias can take various forms [F], and the issue we discuss may differ from that in reference [2]. The sampling bias we discuss in this study arises from approximating $P(Y|Z,g)$ as $P(Y|Z)$. And Equation (7) shows why such an approximation can introduce a bias. The format of a causal graph depends on the process it describes. In rationalization, there are two different data-generating processes (DGP): one is the normal DGP of the original dataset, and another is the DGP of the rationale selection. In our study, the causal graph (Fig.4) describes a small local of the generator's updating process (i.e., the second DGP mentioned above) rather than the DGP of the original dataset, as most causality research does  (since our research problem is the spurious correlations introduced by the generator, rather than the spurious correlations in the original dataset). Thus, it is not surprising that our causal graph differs from that of [2]."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322067654,
                "cdate": 1700322067654,
                "tmdate": 1700649309230,
                "mdate": 1700649309230,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "htTL4Y2kgk",
                "forum": "SdoSUDBWJY",
                "replyto": "qUPQOZWqgN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Experiments with Bert and GNNs."
                    },
                    "comment": {
                        "value": "**Q6.** Concerns about applying A2I to BERT and GNNs\n**A6.** Thanks for your suggestion. We have now re-run RNP and FR with the Bert encoder on the three aspects of BeerAdvocate. Although fine-tuning Bert is still very difficult, we find that using a smaller learning rate for the Bert encoder than for the linear layer works somewhat. So we use a learning rate of $1e-5$ for the Bert encoder and $1e-4$ for the linear layer. The maximum sequence length is 256 (this is enough for the Beer dataset). The batch size is 24. \n\nFrom the second table, we see that Bert\\_RNP performs much worse than GRU\\_RNP, so there must be some unknown issues prevent RNP to work well with Bert. The sampling bias problem studied in our paper may not be the only obstacle that prevents Bert_RNP to work well, so in most cases, A2I does not improve Bert_RNP a lot.  \n\nBut from the first table, we see that Bert_FR improves Bert_RNP a lot. So the obstacles introduced by the Bert encoder may have somewhat been overcomed by FR. Under this case, our A2I improves Bert_FR a lot (more than $5\\%$ in 6 of 9 settings). We believe that future researchers will further explore harnessing the power of Bert within the RNP framework. At that point, we can also build upon subsequent methods to incorporate our A2I.\n\nNotes: Due to limited GPU resources and time, we run the experiments with a fixed random seed 12252018 (inherited from the code provided by our baseline FR). Although not very solid, having the same seed for the nine different settings (3 different aspects $*$ 3 different sparsities) may somewhat reflect the stability of the effectiveness of A2I. We highlight the results only when FR+A2I gives an improvement over $5\\%$ compared to FR.\n\n| Bert\\_FR |  | Appearance |  |  |  |  |  | Aroma |  |  |  |  |  | Palate |  |  |  |  |\n|---:|:---:|:---:|---:|---:|---:|---:|---:|:---:|---:|---:|---:|---:|---:|:---:|---:|---:|---:|---:|\n|  |  | s | acc | p | r | f1 |  | s | acc | p | r | f1 |  | s | acc | p | r | f1 |\n| $S\\approx 10\\%$ | FR | 9.9 | 80.2 | 72.5 | 39.0 | 50.8 |  | 11.7 | 80.6 | 56.7 | 41.7 | 48.1 |  | 10.0 | 81.6 | 27.4 | 21.8 | 24.3 |\n|  | FR+A2I | 10.0 | 85.0 | 91.5 | 49.8 | **64.5** |  | 10.2 | 82.3 | 75.9 | 49.0 | **59.5** |  | 9.1 | 83.7 | 35.1 | 25.3 | **29.4** |\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| $S\\approx 20\\%$ | FR | 19.6 | 84.8 | 56.6 | 60.5 | 58.5|  | 19.5 | 83.2 | 43.6 | 53.5 | 48.1 |  | 19.4 | 84.4 | 39.2 | 60.3 | 47.5 |\n|  | FR+A2I | 17.2 | 85.7 | 72.7 | 68.2 | **70.3** |  | 20.2 | 88.7 | 57.6 | 73.3 | **64.5** |  | 20.0 | 85.8 | 42.3 | 66.9 | 51.9 |\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| $S\\approx 30\\%$ | FR | 29.9 | 86.1 | 51.5 | 84.0 | 63.9 |  | 28.7 | 81.6 | 18.1 | 32.7 | 23.3 |  | 28.6 | 82.6 | 12.4 | 28.0 | 17.2 |\n|  | FR+A2I | 30.5 | 87.0 | 51.9 | 86.4 | 64.8 |  | 30.2 | 84.8 | 39.7 | 75.7 | **52.1** |  | 29.0 | 83.2 | 13.1 | 30.0 | 18.2 |\n\n| Bert\\_RNP |  | Appearance |  |  |  |  |  | Aroma |  |  |  |  |  | Palate |  |  |  |  |\n|---:|:---:|:---:|---:|---:|---:|---:|---:|:---:|---:|---:|---:|---:|---:|:---:|---:|---:|---:|---:|\n|  |  | s | acc | p | r | f1 |  | s | acc | p | r | f1 |  | s | acc | p | r | f1 |\n| $S\\approx 10\\%$ | RNP | 10.6 | 83.2 | 38.3 | 22.1 | 28.0 |  | 9.8 | 62.6 | 14.7 | 9.0 | 11.2 |  | 10.0 | 66.0 | 9.8 | 7.7 | 8.6 |\n|  | RNP+A2I | 10.2 | 85.4 | 46.8 | 26.0 | 33.5 |  | 10.4 | 77.5 | 15.0 | 9.8 | 11.9 |  | 10.5 | 76.2 | 10.1 | 8.4 | 9.2 |\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| $S\\approx 20\\%$| RNP | 19.6 | 82.4 | 50.7 | 54.4 | 52.5 |  | 19.3 | 66.5 | 14.7 | 17.8 | 16.1 |  | 20.3 | 70.4 | 10.6 | 17.1 | 13.1 |\n|  | RNP+A2I | 19.8 | 84.5 | 55.6 | 60.2 | 57.8 |  | 19.3 | 78.1 | 15.7 | 19.0 | 17.2 |  | 19.1 | 75.4 | 10.8 | 16.3 | 13.0 |\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n|$S\\approx 30\\%$ | RNP | 29.2 | 82.2 | 23.2 | 37.0 | 28.5 |  | 29.6 | 76.3 | 15.8 | 29.5 | 20.6 |  | 29.4 | 72.1 | 11.1 | 25.8 | 15.5 |\n|  | RNP+A2I | 29.9 | 91.1 | 50.7 | 82.7 | 62.9 |  | 29.7 | 77.4 | 19.5 | 36.5 | 25.4 |  | 30.9 | 79.9 | 11.7 | 28.7 | 16.7 |\n\n\n\nFollowing your valuable suggestion, we have now also further applied RNP and our AI2 to explainable GNNs. We use a very widely used graph classification dataset in the field of explainable GNNs: BA2Motifs. There are labels for the gold rationales: the house motif for class 0 and the cycle motif for class 1. We report the overlap (F1 score) of the selected nodes and gold rationales. The base model is a 2-layer GCN. The results are as follows: \n\n| BA2Motifs | S | Acc | P | R | F1 |\n|:---:|:---:|:---:|:---:|:---:|---|\n| RNP | 20.3(2.5) | 95.2(1.9) | 36.5(5.5) | 36.5(2.2) | 36.4(3.8) |\n| RNP+A2I | 20.5(2.3) | 95.2(1.5) | 39.7(3.5) | 40.5(2.9) | **40.0(2.5)** |\n|  |  |  |  |  |  |\n| FR | 20.5(2.3) | 96.4(1.8) | 39.3(5.9) | 40.0(4.9) | 39.6(5.2) |\n| FR+A2I | 20.2(1.5) | 96.5(1.4) | 42.1(2.8) | 42.5(4.0) | **42.3(3.0)** |\n\nNotes: The numbers in \"()\" are the standard deviations."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322132106,
                "cdate": 1700322132106,
                "tmdate": 1700360545217,
                "mdate": 1700360545217,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ITaJwavcnu",
                "forum": "SdoSUDBWJY",
                "replyto": "qUPQOZWqgN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6689/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Experiments with different random seeds."
                    },
                    "comment": {
                        "value": "**Q7.** The authors do not show any confidence intervals for their results, so it is unclear whether performance gains are statistically significant. They also only evaluate on two datasets, though these seem to be standard datasets in the RNP community.\n\n**A7.1. (standard deviation)** We now report the standard deviation. In our original experiments, we use a fixed random seed of 12252018 (inherited from the code provided by our baseline FR), because we think that experiments with 12 different settings (beer: 3 aspects $*$ 3 sparsity, hotel: 3 aspects) under the same random seed are somewhat sufficient to verify the stability of the models. Here we rerun RNP and RNP+A2I with 4 additional seeds and report the standard deviation over the five random seeds. Notes: The format of the numbers is \"avg(std)\".\n\n|  |  | Appearance |  |  |  |  |  | Aroma |  |  |  |  |  | Palate |  |  |  |  |\n|---:|:---:|:---:|---:|---:|---:|---:|---:|:---:|---:|---:|---:|---:|---:|:---:|---:|---:|---:|---:|\n|  |  | s | acc | p | r | f1 |  | s | acc | p | r | f1 |  | s | acc | p | r | f1 |\n| $S\\approx 10\\%$  | RNP | 9.0(1.2) | 81.5(1.5) | 83.4(8.0) | 40.3(5.5) | 54.2(5.9) |  | 9.2(1.2) | 83.7(1.7) | 84.1(2.7) | 49.7(5.5) | 62.3(4.1) |  | 9.7(0.3) | 83.2(1.8) | 69.1(2.1) | 53.8(1.9) | 60.5(1.8) |\n|  | RNP+A2I | 10.0(0.6) | 82.6(1.3) | 82.2(3.6) | 44.8(1.0) | 58.1(0.7) |  | 9.9(0.3) | 83.8(2.0) | 84.5(1.0) | 53.9(1.2) | 65.8(0.9) |  | 10.1(0.5) | 85.4(1.1) | 69.3(2.3) | 56.3(1.6) | 62.1(1.3) |\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| $S\\approx 20\\%$  | RNP | 19.5(0.3) | 83.3(1.4) | 69.2(2.6) | 73.1(3.7) | 71.1(3.1) |  | 21.0(0.7) | 85.8(1.2) | 43.9(2.7) | 59.2(2.0) | 50.4(2.5) |  | 19.2(0.8) | 85.3(1.9) | 47.0(2.0) | 72.7(5.0) | 57.0(2.9) |\n|  | RNP+A2I | 20.0(0.1) | 85.2(2.6) | 72.6(0.9) | 78.6(1.0) | 75.5(1.0) |  | 19.5(0.3) | 86.3(1.7) | 50.1(1.0) | 62.7(1.4) | 55.6(1.1) |  | 18.8(0.8) | 86.2(0.6) | 48.4(3.0) | 72.8(2.9) | 58.2(2.9) |\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n| $S\\approx 30\\%$  | RNP | 30.5(1.1) | 85.5(2.4) | 55.9(2.6) | 92.2(3.2) | 69.6(2.7) |  | 31.2(0.4) | 85.9(3.7) | 39.2(1.8) | 78.5(3.1) | 52.3(2.3) |  | 29.0(0.9) | 86.1(2.6) | 31.1(2.7) | 72.6(6.1) | 43.6(3.7) |\n|  | RNP+A2I | 29.7(0.2) | 85.7(1.7) | 59.5(0.7) | 95.5(1.3) | 73.4(0.9) |  | 29.4(1.1) | 88.0(1.2) | 44.8(1.6) | 84.6(3.7) | 58.5(2.0) |  | 28.5(0.9) | 86.4(0.8) | 32.5(1.7) | 74.7(5.0) | 45.3(2.5) |\n\n\nDue to the large amount of GPU resources consumed by Bert related experiments, the random seed experiments for FR are still in preparation.\n\n**A7.2. (datasets)** \nWe fully understand your concern. However, datasets containing manually annotated rationales are precious, and it is common to utilize only two datasets in the field of rationalization. Our baseline method FR, and two other relevant papers [C,E] all use two datasets. \nAlthough we use only two datasets, each of these datasets contains three independently annotated aspects and each aspect is trained independently. Thus, to some extent, they can be considered as six datasets to some extent.\n\n\nReferences  \n[A] Rethinking Cooperative Rationalization: Introspective Extraction and Complement Control. EMNLP 2019.  \n[B] Invariant Rationalization. ICML 2020.  \n[C] Understanding Interlocking Dynamics of Cooperative Rationalization. NeurIPS 2021.  \n[D] GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium. NeurIPS 2017.  \n[E] D-Separation for Causal Self-Explanation. NeurIPS 2023.  \n[F] A Survey on Bias and Fairness in Machine Learning. ACM computing surveys 2021."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322226787,
                "cdate": 1700322226787,
                "tmdate": 1700322251454,
                "mdate": 1700322251454,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]