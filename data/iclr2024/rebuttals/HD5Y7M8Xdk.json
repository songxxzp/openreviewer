[
    {
        "title": "Forward $\\chi^2$ Divergence Based Variational Importane Sampling"
    },
    {
        "review": {
            "id": "m8TuK97Wz0",
            "forum": "HD5Y7M8Xdk",
            "replyto": "HD5Y7M8Xdk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission827/Reviewer_T2mb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission827/Reviewer_T2mb"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes a new method of variational inference (VI) for latent variable models based on importance sampling, and shows its effectiveness with numerical experiments on toy model (synthetic), auto encoder model (real) and spike neural network (synthetic and real).\n\nThe method improves the tightness of the conventional VI by increasling the batch size of monte-carlo sampling, while giving up the exact computation/minimization of the approximation gap introduced with VI (cf. Eq. 8 and 11). This theoretical trade-off turned out to be beneficial in the experiments."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is original and well written. The performance gain obtained with the proposed method is significant, which is one of the main contribution of the paper."
                },
                "weaknesses": {
                    "value": "There is no discussion on the limitation of the proposed method.\nFrom what I understood from the paper, I expect the following potential drawbacks:\n  - Increase in training time based on the additional sampling\n  - Instability in training due to the biased approximation (due to Eq. 8 and 11).\n\nDetailed discussions on this matter are highly welcomed."
                },
                "questions": {
                    "value": "The ground truth model of the toy experiment (Sec. 4.1) seems unidentifiable. In particular, the distribution of the hidden variable has multiple modes, which seems impossible to be identified only with the binary visible variable. This observation also explains well that despite the fact that the conventional VI substantially failed to estimate the modes, there is only a tiny difference in log-likelihood compared to other methods (order of 1e-4, see Fig. 2a). So, the question is, **why do you compare the parameter convergence, HLL and CLL**, which I think are meaningful to compare only if the model is identifiable? A similar argument also applies to the synthetic experiment of spike NN."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission827/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698565591923,
            "cdate": 1698565591923,
            "tmdate": 1699636010231,
            "mdate": 1699636010231,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "e1ClIBJ0TG",
                "forum": "HD5Y7M8Xdk",
                "replyto": "m8TuK97Wz0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission827/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission827/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to T2mb (1/2)"
                    },
                    "comment": {
                        "value": "Dear Reviewer T2mb,\n\nThank you very much for your time and valuable comments on our paper. We highly appreciate your recognition of the strengths of our paper. Hopefully, the following responses could resolve most of your concerns and answer your questions.\n\n### Weaknesses\n**Discussion on limitation of VIS**: The last sentence of the discussion section does point out a limitation of VIS. \"Nevertheless, it is worth noting that while this choice of proposal distribution in VIS is statistically optimal for importance sampling, its practical significance in certain real-world applications might require further investigation and validation.\" Therefore, the proposal distribution learned by our VIS method still functions as an approximated posterior distribution. It is closest to the true posterior in terms of forward $\\chi^2$ divergence, which differs from the variational distribution learned by VI (maximizing ELBO) in terms of reverse KL divergence.\n* When the problem itself is complicated (e.g., complicated generative process and/or high latent dimensionality such as the POGLM model in Sec 4.3), a large number of Monte Carlo samples is indeed necessary, no matter for VIS or other baseline methods including VI. When working with VAE, people are already accustomed to using one Monte Carlo sample, but more Monte Carlo samples certainly improves the quality of $\\widehat{\\operatorname{ELBO}}$ since $\\operatorname{ELBO}$ is also an integral expression w.r.t. $q(\\boldsymbol z|\\boldsymbol x;\\phi)$. Anyway, however, employing a larger number of Monte Carlo samples always improves the estimation for all sampling-based estimation methods, including VI as depicted in Fig. 1. The main conclusion from Fig. 1 is that increasing the number of Monte Carlo increases the effectiveness of both $\\widehat{\\operatorname{ELBO}}$ and $\\ln \\hat p$, but it is only very helpful for tightening the bound of $\\ln \\hat p$ (with the speed of order $\\frac 1 K$) rather than $\\widehat{\\operatorname{ELBO}}$. As we mentioned below Eq. 8, when the number of Monte Carlo samples $K=1$, $\\widehat{\\operatorname{ELBO}} = \\ln \\hat p$. Therefore, we need at least two Monte Carlo samples to distinguish them. **And using larger $K$ could lead to greater improvement to VIS than VI. This doesn't mean VIS requires larger $K$ to work or VIS takes more time (same $K$, then same sampling time for all methods including VIS and VI), so no extra training time.** In practice, for example, if two samples are enough for VI to converge, then two samples are also enough for VIS to converge, and VIS should still outperform others. I.e., the number of Monte Carlo should be suitable to the complexity of the model/problem, rather than which method you choose. In our experiments, we use the same number of Monte Carlo and enough Monte Carlo samples for a fair and insightful comparison of different methods, especially the learning behavior of different methods, for example in Sec 4.1 the toy mixture model (Fig. 2). **New experiment results regarding the number of Monte Carlo are shown in Appendix 6 and Fig. 8 in our latest revision.**\n* **Approximation of Eq. 8 and 11**:\n   * **Eq. 8**: Eq. 8 is deriving the bias of the numerical estimator of IS $\\ln \\hat p(\\boldsymbol x;\\theta,\\phi)$, showing that its distance to the true $\\ln \\hat p(\\boldsymbol x;\\theta)$ is asymptotically much closer than $\\widehat{\\operatorname{ELBO}}(\\boldsymbol x;\\theta,\\phi)$. This tells us one of the reasons why we should prefer to directly maximize $\\ln \\hat p(\\boldsymbol x;\\theta,\\phi)$ rather than $\\widehat{\\operatorname{ELBO}}(\\boldsymbol x;\\theta,\\phi)$. The $\\approx$ in Eq. 8 is not related to the \"biased approximation\" since it is not an estimator.\n   * **Eq. 11**: It is a derivation of the numerically stable estimator of the forward $\\chi^2$ divergence in log space. This quantifies the bias of the importance sampling (IS) estimator in log space and the effectiveness of the IS estimator. Hence, we minimize this to improve IS. It is likely that this approximation is biased, but the only way to approximate Eq. 10 $\\ln V(\\boldsymbol x|\\theta,\\phi)$ is to use such an approximation with samples $\\boldsymbol z^{(k)}\\sim q(\\boldsymbol z|\\boldsymbol x;\\phi)$."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission827/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699993914338,
                "cdate": 1699993914338,
                "tmdate": 1699993914338,
                "mdate": 1699993914338,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "XYRRTb5XR7",
            "forum": "HD5Y7M8Xdk",
            "replyto": "HD5Y7M8Xdk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission827/Reviewer_QxSX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission827/Reviewer_QxSX"
            ],
            "content": {
                "summary": {
                    "value": "The paper focuses on the problem of approximate Bayesian inference in latent variable models and challenges the common wisdom of approximating the posterior with variational inference and maximizing the evidence lower bound (ELBO). The authors identify a mismatch between maximizing ELBO and maximizing loglikelihood, and posit that the latter is a better objective, as it is divorced from the quality of the approximate posterior. To tackle the maximization of loglikelihood, the paper proposes variational importance sampling (VIS), which maximizes the marginal directly via importance sampling. Upon inspecting the variance of the IS estimator, the paper also proposes minimizing the chi-squared divergence w.r.t. the approximate posterior. \n\nThe paper inspects the efficacy of this method on a series of latent variable models, and witness a consistent improvement on the inference of latent variable models."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "I think the paper warrants acceptance due to the fact that it tackles a well-motivated problem with a simple, yet empirically effective method. \n\n- Motivation: the maximization of ELBO as a proxy of likelihood maximization has long been a standard practice in latent variable, even though the mismatch can be significant. I agree with the authors that the mismatch should be inspected more carefully, and that one should separate the approximate posterior inference with the model itself. \n- Methodology: the paper proposes a simple, yet elegant solution to the question of likelihood maximization, and motivate the reasoning behind the optimization of the chi-squared divergence from the perspective of the bias and variance of the IS estimator. This approach seems novel, even though I am not very up-to-date about the research in this regard. \n- Experiments: the paper compares against alternative options in latent variable inference and showcase that the method can correctly infer the marginal likelihood, as well as outperforming competing methods in real-world datasets."
                },
                "weaknesses": {
                    "value": "I am not entirely sure how the method proposed in this paper differs from previous work, as the practice of using Monte Carlo samples to sharpen variational bound is a topic that has been explored by previous work. I hope the authors can make some clarifications or have a small section in the manuscript that discusses the difference across different ways to combine IS with VI. \n\n- It is neat to see the same chi-squared divergence on both the bias and effectiveness of the IS estimator, but eq. 8 contains an approximation that seems to work mostly for large $K$s, and the effectiveness is evaluated at the estimator $\\hat{p}$ and not $\\log \\hat{p}$, making the connection seem a bit artificial. Is it possible to minimize a divergence in the form of, e.g., the first line in eq. 8?"
                },
                "questions": {
                    "value": "- The experiments presented in the paper show that VIS performs well, but it seems that a large number of Monte Carlo samples are chosen in many of the experiments. This seems that it can present a significant computational cost. Could the authors include some explanation about the effect of the number of Monte Carlo samples on the efficacy of VIS, and clarify if taking many Monte Carlo samples is practical in training latent variable models?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission827/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission827/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission827/Reviewer_QxSX"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission827/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698613164291,
            "cdate": 1698613164291,
            "tmdate": 1699636010160,
            "mdate": 1699636010160,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "BohRMxjU0G",
                "forum": "HD5Y7M8Xdk",
                "replyto": "XYRRTb5XR7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission827/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission827/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to QxSX (1/2)"
                    },
                    "comment": {
                        "value": "Dear Reviewer QxSX,\n\nThank you very much for your time and valuable comments on our paper. We highly appreciate your recognition of the strengths of our paper. Hopefully, the following responses could resolve most of your concerns and answer your questions.\n\n### Weaknesses\nIn the third paragraph of Section 1, various methods of combining IS with VI are briefly mentioned. Additionally, these methods are summarized as baseline techniques at the beginning of Sec 4. Below, we aim to provide a more detailed explanation. In the context of a latent variable model $p(\\boldsymbol x, \\boldsymbol z;\\theta)$, two main challenges arise: the learning problem, which focuses on learning $\\theta$, and the inference problem, which aims to find an approximating posterior distribution $q(\\boldsymbol z|\\boldsymbol x;\\phi)$ that approximates $p(\\boldsymbol z|\\boldsymbol x;\\theta)$ for a specific $\\theta$.\n* Learning $\\theta$: The process of learning $\\theta$ involves maximizing the log-likelihood, denoted as $\\arg\\max_\\theta \\ln p(\\boldsymbol x;\\theta)$ in log space. Two distinct optimization approaches exist for this task:\n   * (a) Maximizing $\\widehat{\\operatorname{ELBO}}(\\boldsymbol x;\\theta,\\phi)$ w.r.t. to $\\theta$, which is a hard lower-bound of $\\ln p(\\boldsymbol x;\\theta)$, measured by $\\operatorname{KL}(q\\\\|p)$.\n   * (b) Maximizing $\\ln \\hat p(\\boldsymbol x;\\theta,\\phi)$ w.r.t. $\\theta$, which is an asymptotically tighter lower-bound of $\\ln p(\\boldsymbol x;\\theta)$, measured by $\\chi^2(p\\\\|q)/(2K)$.  \n\nAlthough both of them are sampling-based methods, the former one is usually called VI, and the latter one is usually called IS. Both of them requires sampling $K$ samples $\\left\\\\{\\boldsymbol z^{(k)}\\right\\\\}_{k=1}^K$ from the current approximating posterior distribution $q(\\boldsymbol z|\\boldsymbol x;\\phi)$.\n* Learning $\\phi$: The ways to learn $\\phi$ under a fixed $\\theta$ are various. For example:\n   * (1) Minimizing the reverse KL divergence $\\operatorname{KL}(q(\\boldsymbol z|\\boldsymbol x;\\phi)\\\\|p(\\boldsymbol z|\\boldsymbol x;\\phi))$ which happen to also maximizing $\\widehat{\\operatorname{ELBO}}(\\boldsymbol x;\\theta,\\phi)$ but w.r.t. $\\phi$.\n   * (2) Minimizing the forward $\\chi^2$ divergence $\\chi^2(p(\\boldsymbol z|\\boldsymbol x;\\theta)\\\\|q(\\boldsymbol z|\\boldsymbol x;\\phi))$\n   * (3) $\\alpha$ divergence-based methods or forward KL divergence\n\nSubsequently, we can comprehend the various ways of combining them:\n* VI: (a)*(1). Since they utilize the same target function $\\widehat{\\operatorname{ELBO}}$.\n* CHIVI: (a)*((1) + (2)). Since they assume squeezing the posterior by a lower-bound ELBO and an upper-bound CUBO could improve the posterior approximating, but this may not be the best approximating posterior for learning $\\theta$.\n* VBIS: (b)*(1). They assume the variational distribution found by VI (1) could serve as a proposal distribution for learning $\\theta$ (a).\n\n**For your questions regarding $K$**, please see the following **Questions** part.\n\n**Regarding your inquiry about Eq. 8**, it's challenging to analytically derive the effectiveness (variance) of the estimator $\\ln \\hat p(\\boldsymbol x;\\theta,\\phi)$ in log space. However, empirical evidence from Fig. 1 demonstrates that reducing the variance in the original space also leads to a reduction in variance in the log space.\n\n**Minimizing the first line in Eq. 8**: We argue that this is not practical, because the first line of Eq. 8 includes samples. Eq. 8 is deriving an estimator's bias. Bias is one of the metrics to evaluate a statistic, so its expression cannot include concrete samples. Mathematically we have to eliminate concrete samples $\\boldsymbol z^{(k)}$ from the expression to obtain a sample-free analytical form of the bias, i.e. the last line of Eq. 8."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission827/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699993813335,
                "cdate": 1699993813335,
                "tmdate": 1700167619104,
                "mdate": 1700167619104,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ztkaEzFhFe",
            "forum": "HD5Y7M8Xdk",
            "replyto": "HD5Y7M8Xdk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission827/Reviewer_J8Yz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission827/Reviewer_J8Yz"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes an adaptive importance-sampling algorithm which seeks to improve the proposal distribution by minimising the chi-square divergence from the target distribution to the proposal."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "There are a large number of experiments. The proposed method seems to perform well.\n\nApproximating the gradient of the logarithm of the forward $\\chi^2$-divergence (rather than the gradient of the $\\chi^2$-divergence) seems to enhance numerical stability and seems novel. Though it should be noted that existing approaches improve numerical stability by minimising not the forward $\\chi^2$-divergence itself but rather the forward $\\chi^2$-divergence multiplied by the squared normalising constant of the target distribution: $p_\\theta(x)^2$ (see, e.g., [2]). It is not clear how this compares to the log-space approach taken here.\n\n[2] Akyildiz, \u00d6. D., & M\u00edguez, J. (2021). Convergence rates for optimised adaptive importance samplers. Statistics and Computing, 31, 1-17."
                },
                "weaknesses": {
                    "value": "Targetting the $\\chi^2$-divergence as an objective for improving the proposal distribution in adaptive importance sampling is not novel. The fact that minimising the variance of the importance weights is equivalent to minimising the chi-square divergence from the target to the proposal is well known in the importance-sampling literature and has already often been used to improve proposal distributions within adaptive importance-sampling schemes, e.g. [1, 2] and references therein.\n\nFurthermore, using such adaptive-importance-sampling approaches for variational inference is already extensively discussed in [3].: \n1. Algorithm 1 of the present paper is a special case of the generic method described in [3, Section 3] (in particular, see [3, Section 3.4]);\n2. the $\\theta$-gradient from Equation 6 of the present work is already well known (see, e.g. [3]).\n3. However, from the author's rebuttal, it is now more clear to me that their $\\phi$ gradient is slightly different than in [3] because they derive the $\\phi$-gradient in log-space.\n\n[1] Jona\u2010Lasinio, G., Piccioni, M., & Ramponi, A. (1999). Selection of importance weights for monte carlo estimation of normalizing constants. Communications in Statistics-Simulation and Computation, 28(2), 441-462.\n\n[2] Akyildiz, \u00d6. D., & M\u00edguez, J. (2021). Convergence rates for optimised adaptive importance samplers. Statistics and Computing, 31, 1-17.\n\n[3] Finke, A., & Thiery, A. H. (2019). On importance-weighted autoencoders. arXiv preprint arXiv:1907.10477."
                },
                "questions": {
                    "value": "How does the approach compare with replacing the forward $\\chi^2$- with forward KL-divergence (i.e., effectively two out of the three \"phases\" of reweighted wake--sleep)?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "no concerns"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission827/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission827/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission827/Reviewer_J8Yz"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission827/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698777776113,
            "cdate": 1698777776113,
            "tmdate": 1700771751028,
            "mdate": 1700771751028,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "B8YwiYBXZv",
                "forum": "HD5Y7M8Xdk",
                "replyto": "ztkaEzFhFe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission827/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission827/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to J8Yz"
                    },
                    "comment": {
                        "value": "Dear Reviewer J8Yz,\n\nThank you very much for your time and valuable comments on our paper. We would like to make clarifications on your valuable suggestions.\n\n* [1] Jona-Lasinio et al. (1999): We acknowledge the presence of existing works that employ adaptive strategies to minimize the forward $\\chi^2$ divergence, aiming to reduce the variance of the IS estimator. However, this paper only provides a general guideline but not a concrete algorithm for achieving the goal of minimizing the forward $\\chi^2$ divergence. Additionally, our paper introduces another perspective on minimizing the forward $\\chi^2$ divergence by considering the bias of $\\ln \\hat p(\\boldsymbol x;\\theta,\\phi)$ in log space.\n* [2] Akyildiz et al. (2021): This paper primarily discusses minimizing $\\chi^2$ divergence for distributions from the exponential distribution family. In contrast, our gradient estimator is not restricted to such a distribution family; it is applicable to all distributions, as demonstrated in the toy model (Sec 4.1) and the POGLM model (Sec 4.3). The true posterior distribution family and the approximated distribution family in these two models are way more complicated than the exponential distribution family, but we can still make VIS work for these arbitrary distribution families.\n* [3] Finke et al. (2019): While this paper addresses the gradient breakdown problem in the IWAE (Burda et al., 2016) paper and by providing a correct gradient estimator for optimizing the encoder or the proposal distribution, it's still important to highlight differences. Firstly, their gradient estimator is in the original space (Dieng et al., 2017), unlike ours, which is in log space. This is nontrivial and an important way to make the gradient estimator numerically stable. **Please check Appendix 5 and Fig 7 in our latest revision for insights into the numerical stability issue.** Besides, their experiments are confined to cases where the generative model has an explicit decomposition of $p(\\boldsymbol x, \\boldsymbol z;\\theta) = p(\\boldsymbol x|\\boldsymbol z;\\theta) p(\\boldsymbol z;\\theta)$. In contrast, our POGLM model in Sec 4.3 extends the analysis to a complex and general graphical model where such an explicit decomposition does not exist. Even for such a complicated general graphical model, our VIS can still work and outperform other baselines, which proves the practical effectiveness of our method.\n\nFurthermore, to the best of our knowledge, there is a gap in the existing literature concerning extensive experiments that systematically compare the practical learning performances of various methods across a diverse range of latent variable models. We believe it is necessary to visualize the behaviors of different methods (e.g. the toy model in Section 4.1 and the POGLM model in Sec 4.3) for readers to fully understand and convince how VIS works better than others.\n\nIn conclusion, we respectfully hold a different perspective, asserting that our work indeed brings novelty and valuable contributions. We hope that our response has addressed your concerns and provided clarity regarding the significance of our research."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission827/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699993678119,
                "cdate": 1699993678119,
                "tmdate": 1699993678119,
                "mdate": 1699993678119,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zRgSBILy6B",
                "forum": "HD5Y7M8Xdk",
                "replyto": "ztkaEzFhFe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission827/Reviewer_J8Yz"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission827/Reviewer_J8Yz"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarification.\n\n1. I agree that it makes sense to minimise the chi-square divergence (or the following quantity that is proportional to it for fixed $\\theta$) \n$$E_{z \\sim q_\\phi(z|x)}\\Bigl[\\Bigl(\\frac{p_\\theta(x, z)}{q_\\phi(z|x)}\\Bigr)^2\\Bigr]$$\nin log-space. And you're right, this makes your $\\phi$-gradient slightly different from some existing adaptive-importance sampling settings (the $\\theta$-gradient is standard). I will raise my score.\n2. Yes, [2] assumes exponential families. I don't think this specific reference needs to necessarily be cited in the paper. Rather, along with [1], I only gave it as an example of the fact that minimising the variance of the importance weights (equivalently, minimising the above-mentioned chi-square divergence) is a well-known technique in the importance-sampling literature.\n3. This context needs to be made more clear in the paper, e.g., in the introduction.\n\nThere are still some typos in the revised manuscript. I haven't re-read everything carefully but noticed that Eq. 12 should probably be \"$\\approx$\" rather than \"$=$\""
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission827/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700317416674,
                "cdate": 1700317416674,
                "tmdate": 1700317472398,
                "mdate": 1700317472398,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pz0RFF0SRz",
                "forum": "HD5Y7M8Xdk",
                "replyto": "zRgSBILy6B",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission827/Reviewer_J8Yz"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission827/Reviewer_J8Yz"
                ],
                "content": {
                    "comment": {
                        "value": "I have raised my score to 5. I would be willing to raise if further if the authors can demonstrate that their approach works better than simply using the forward KL-divergence (i.e., this would be nothing other than Reweighted Wake--Sleep without the \"sleep\" phase which is often not used)."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission827/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700318651740,
                "cdate": 1700318651740,
                "tmdate": 1700318651740,
                "mdate": 1700318651740,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "c5FgkTniUc",
                "forum": "HD5Y7M8Xdk",
                "replyto": "ztkaEzFhFe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission827/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission827/Authors"
                ],
                "content": {
                    "title": {
                        "value": "New experiment results regarding forward KL"
                    },
                    "comment": {
                        "value": "Dear Reviewer J8Yz\n\nWe would like to express our sincere thanks for your acknowledgment of our paper and your new score. \n* **Regarding [2]**.\n    * Eq. 10 in our paper shows that $\\chi^2(p\\\\|q) = \\frac{1}{p(\\boldsymbol x;\\theta)^2} V(\\boldsymbol x;\\theta,\\phi) - 1$. So, our target function $V(\\boldsymbol x;\\theta;\\phi) = p(\\boldsymbol x;\\theta)^2\\chi^2(p\\\\|q) + p(\\boldsymbol x;\\theta)^2$ in original space is the same as existing works.\n    * Theoretically, $p(\\boldsymbol x;\\theta)^2$ is a constant w.r.t. $\\phi$. So, we (and existing works) drop the term of $p(\\boldsymbol x;\\theta)^2$, to only minimize $V(\\boldsymbol x;\\theta,\\phi) = \\int \\frac{p(\\boldsymbol x,\\boldsymbol z;\\theta)^2}{q(\\boldsymbol z|\\boldsymbol x;\\phi)}\\ \\mathrm d \\boldsymbol z$. We acknowledge that this step is helpful for numerical stability because the target function $V(\\boldsymbol x;\\theta,\\phi)$ will not be affected by the magnitude of $p(\\boldsymbol x;\\theta)^2$.\n    * We take an additional step to perform the minimization in log space, which further improves the numerical stability significantly.\n* **Eq. 12**. Thanks, it is $\\approx$. We will certainly do further proofreading to make sure there is no typo.\n* **Regarding [3]**. Thanks for this suggestion. We have added some new discussions to the introduction part. Due to the 9-page limit, some detailed texts are located in Appendix 8 (with a hyperlink directing from the introduction). Please check the latest revision.\n* **Comparing with forward KL**. Thanks for this suggestion. We do have the result in our hands. For example, Jerfel et al. (2021) also found the problem of the reverse KL divergence and investigated the forward KL divergence, but their algorithm is only confined to Gaussian distribution. **According to your suggestion, we had a new section in Appendix A.7 showing that forward $\\chi^2$ divergence is better than forward KL divergence.** The reason should be from Sason et al. (2016) and Nishiyama et al. (2020) that: $\\operatorname{KL}(p\\\\|q) \\leqslant \\chi^2(p\\\\|q)$. I.e., $\\chi^2(p\\\\|q)$ can bound $\\operatorname{KL}(p\\\\|q)$ but not vice versa. Therefore, minimizing forward KL divergence cannot promise a direct minimization of forward $\\chi^2$ divergence.\n\nPlease check Fig. 9 in Appendix 7 to see the new results. Thank you very much again for your valuable feedback on our initial response.\n\nNew references:  \nSason, I., & Verd\u00fa, S. (2016). $ f $-divergence Inequalities. IEEE Transactions on Information Theory, 62(11), 5973-6006.  \nNishiyama, T., & Sason, I. (2020). On relations between the relative entropy and $\u03c7^2$-divergence, generalizations and applications. Entropy, 22(5), 563."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission827/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700343042644,
                "cdate": 1700343042644,
                "tmdate": 1700365461029,
                "mdate": 1700365461029,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "g0QgmPx7E4",
            "forum": "HD5Y7M8Xdk",
            "replyto": "HD5Y7M8Xdk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission827/Reviewer_84Pi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission827/Reviewer_84Pi"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a variational algorithm for learning model and latent parameters in a latent variable model which at each step first updates the variational distribution by minimizing forward chi-square divergence and then uses this distribution to estimate the log marginal likelihood using Importance Sampling. The optimization is done by gradient ascent where the gradients are estimated by MC sampling.\nThe proposed algorithm is compared against many contemporary algorithms on simulated and real world datasets, including a large scale case study on multi-neuron interaction modelled by a custom made partially observable GLM."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper tries well to motivate itself well and the use of chi-square divergence objective as means of finding the optimal distribution for IS is theoretically sound.\n2. The paper has done experiments and analysis on may simulated and real world datasets. The experiment on GLP model for multi-neurns activation is well documented and insightful. Some of the plots look good and match the narrative. \n3. The method proposed seems sound to me and the results show that it can perform better than contemporary VI algorithms on the tasks given in the paper."
                },
                "weaknesses": {
                    "value": "1. The paper is not polished yet, although the major parts are all there, it may require another thorough pass.\nit has too many mistakes and typos:, the notation changes from bold to normal in many places, the title has a typo: 'importane', 'log function is a convex function'. \n2. Some of the references and recent literature is missing which have looked on the quality of different divergence objectives such as CUBO and ELBO for finding the optimal sampling distribution.\n3. The theory part and the algorithm part can be emphasized more, right now it feels to compressed and dense. The figure 2 is good but it has too many colors and things to unpack, maybe use solid line for true posterior as I was thoroughly confused by the legend choices, and the use of two colors for showing modes reduced readibility for me atleast. \n4. It is the bane of chi-square divergence methods that it  does not scale well with dimensions covered in the papers here: https://arxiv.org/pdf/2010.09541.pdf and https://arxiv.org/abs/1802.02538 and it seems that this method may not scale well as it uses Chi-squared divergence minimization."
                },
                "questions": {
                    "value": "1. What is the dimensionality of the POGLM model, do the authors intend to use this method as a tool for low dimensional complex posteriors because both IS and CUBO do not scale well with dimensions and even large sample size as done in this paper will not help.  \n2. Maybe include this in your conclusion section and discuss this as a limitation ? \n3. Did the authors use any other optimizers other than ADAM, did it have any effect, how did you choose the optimization algorithm hyperprameters like learning rate etc. ?\n4. Did reparameterization gradients perform better than score gradients in the case where they both were available."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission827/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission827/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission827/Reviewer_84Pi"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission827/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698837323287,
            "cdate": 1698837323287,
            "tmdate": 1699636009966,
            "mdate": 1699636009966,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XC5aegHTuR",
                "forum": "HD5Y7M8Xdk",
                "replyto": "g0QgmPx7E4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission827/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission827/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to 84Pi (1/3)"
                    },
                    "comment": {
                        "value": "Dear Reviewer 84Pi,\n\nThank you very much for your time and valuable comments on our paper. We highly appreciate your recognition of the strengths of our paper. Hopefully, the following responses could resolve most of your concerns and answer your questions.\n\n### Weaknesses:\n1. Thank you for bringing attention to the typo in the title. We apologize for any confusion caused by these errors. Please check the polished latest revision.  \n   **Notation**: In the method section, we employ vector forms $\\boldsymbol x, \\boldsymbol z$ for generality. However, in the experiments, we adapt them to the corresponding typefaces based on the model. For instance, in Sec 4.1 Toy example, both $x$ and $z$ are scalars, so we use the normal typeface. In Sec 4.3 POGLM, every observable $\\boldsymbol X \\in \\mathbb N^{\\text{time}\\times \\text{visible neurons}}$ and every latent $\\boldsymbol Z \\in \\mathbb N^{\\text{time}\\times \\text{hidden neurons}}$ are multivariate time sequences represented in matrix forms, so we use the capital bold typeface.  \n   **log**: Thanks! log is a concave function.\n2. **The papers related to CUBO and ELBO had been included in our initial submission. The second baseline method CHIVI (Dieng et al., 2017), explained at the beginning of Sec 4, is the CUBO-ELBO paper.** Specifically, they utilize CUBO as an upper-bound and ELBO as a lower-bound to squeeze the approximated posterior. However, all discussions in the CUBO paper revolve around the inference problem, i.e., approximating the posterior distribution $q(\\boldsymbol z|\\boldsymbol x;\\phi)$, rather than determining the optimal proposal distribution for learning the parameter $\\theta$ in $p(\\boldsymbol x;\\theta)$ as we were doing.\n3. We apologize for the compressed and dense nature of the method section (Sec 3). Due to the 9-page limit, we acknowledge that crucial materials, such as related works, mathematical derivations (e.g., the gradient estimator), and detailed experiment explanations, may not have been extensively expanded in the main content. Most of the important lengthy derivations are provided in the appendix, allowing readers to verify the correctness of the result equations presented in the main content. Regarding Fig. 2, we appreciate the opportunity to resolve any confusion and are prepared to carefully explain all the details to you now.  \n   **Fig 2**: To comprehensively understand why VIS outperforms other methods, it's crucial to visualize three distributions:\n   * the true posterior $p(z|x;\\theta^{\\mathrm{true}})$ (dashed)\n   * the learned posterior $p(z|x;\\theta)$ (solid)\n   * the approximated (variational/proposal) posterior $q(z|x;\\phi)$ (dotted).  \n   \n   **This linestyle assignment aligns with the convergence curves shown in Fig. 2B.** Given $x\\in\\\\{0,1\\\\}$, we use two colors: purple for $z|x=0$ and brown for $z|x=1$. We can ignore brown curves first and only focus on purple curves to understand why VIS is better than others.\n   * **Conclusion 1**: the dotted curve of VIS is the widest, providing the widest effective sampling range, which is beneficial for learning $\\theta$ through IS.\n   * **Conclusion 2**: the dotted curve (approximated posterior) and the solid curve (learned posterior) of VI exhibit the closest match, resulting in the smallest reverse KL divergence. However, the solid curve (learned posterior) is significantly distant from the dashed curve (true posterior). This suggests that maximizing ELBO in VI for learning $\\theta$ could lead to a situation where the learned and approximated posteriors are close in reverse KL divergence (yielding a high ELBO), but both are far from the true posterior (resulting in a low marginal likelihood). This significantly impedes the learning of $\\theta$.\n4. **Scale to work for high dimensional latent space: This stands as one of our significant contributions.** The two papers you mentioned, along with Pradier et al. (2019) cited in our paper, acknowledge the instability associated with minimizing $\\chi^2$ divergence, particularly in high-dimensional scenarios. **The lack of success in minimizing the $\\chi^2$ divergence could be attributed to the numerically unstable form of their gradient estimator. In contrast, our gradient estimator (Equations 12 and 24) is derived in log space and presented in a simple and numerically stable form. Please check Appendix 5 and Fig 7 in our latest revision.** Our succinct gradient estimator makes VIS always work, even for the most general case that $p(\\boldsymbol x,\\boldsymbol z;\\theta)$ cannot be explicitly decomposed into $p(\\boldsymbol x|\\boldsymbol z;\\theta) p(\\boldsymbol z;\\theta)$. The POGLM experiments indeed confirm that VIS is robust across different models, numerically stable, and scalable to high latent dimensionality (addressing Question 1). Having successfully overcome the challenges in previous research related to $\\chi^2$ divergence, we consider this a strength and a noteworthy contribution to our work, rather than a weakness."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission827/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699993286983,
                "cdate": 1699993286983,
                "tmdate": 1699993286983,
                "mdate": 1699993286983,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]