[
    {
        "title": "Efficient ConvBN Blocks for Transfer Learning and Beyond"
    },
    {
        "review": {
            "id": "EvXEulkoV2",
            "forum": "lHZm9vNm5H",
            "replyto": "lHZm9vNm5H",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3142/Reviewer_iJzH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3142/Reviewer_iJzH"
            ],
            "content": {
                "summary": {
                    "value": "This paper explored the trade-off between stability and efficiency in Convolution-BatchNorm blocks which are popular convolution neural networks\uff1aDeploy mode is efficient but suffers from training instability; Eval mode is widely used in transfer learning but lacks efficiency. \nBased on detailed analysis, the paper proposed a Tune mode, which is stable and efficient, to bridge the gap between Eval mode and Deploy mode. Numerous experiments conducted in various tasks have verified the effectiveness of the proposed Tune mode."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1. The paper provided detailed  analysis of proposed Tune mode from both theoretical and experimental perspectives.\n2. The author's writing is very good, and the entire paper is relatively easy to understand.\n3. Simple algorithm, easy to follow. (codes are available for the public according to the abstract: \"Our method has been integrated into both PyTorch (general machine learning framework) and MMCV/MMEngine (computer vision framework).\")\n4. The experimental results are reliable and sufficient to verify the effectiveness of this method."
                },
                "weaknesses": {
                    "value": "1. the proposed Tune mode looks like an engineering technique. (this method might be more suitable for patent applications) \n2. The novelty of this method is somewhat weak for top-tie conferences focused on theoretical research."
                },
                "questions": {
                    "value": "see weaknesses above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3142/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3142/Reviewer_iJzH",
                        "ICLR.cc/2024/Conference/Submission3142/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3142/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697770240122,
            "cdate": 1697770240122,
            "tmdate": 1700533590079,
            "mdate": 1700533590079,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8rcLKUkxUa",
                "forum": "lHZm9vNm5H",
                "replyto": "EvXEulkoV2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3142/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3142/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer iJzH"
                    },
                    "comment": {
                        "value": "Thank you for your appreciation. Here are our responses to your concerns:\n\n# This method might be more suitable for patent applications\n\nIndeed, we can file patent applications for the method. However, we decide to contribute the method directly to the community, so it can benefit the community without legal constraints.\n\n# Compatibility of this method in a top-tie conference focused on theoretical research like ICLR\n\nWe believe the charm of ICLR as a top-tie conference is that it is open and inclusive, including theoretical and practical papers. Also note that our paper consists of not only a practical method (Tune Mode ConvBN), but also non-trivial analyses of the instability of Deploy mode and the equivalence between Tune mode and Eval mode in terms of forward-backward computation. Therefore, in our humble opinion, our paper should be a good fit for ICLR.\n\nWe hope the above responses can address your concerns. Should you have any other questions, we will be happy to provide more information."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3142/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699980018516,
                "cdate": 1699980018516,
                "tmdate": 1699980207393,
                "mdate": 1699980207393,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ixcCG0kGql",
                "forum": "lHZm9vNm5H",
                "replyto": "8rcLKUkxUa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3142/Reviewer_iJzH"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3142/Reviewer_iJzH"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for your feedback and clarification. I agree with the technological contribution and practical significance.\nConsidering the author's response and additional contributions during the rebuttal, I have raised my rating."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3142/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700533820672,
                "cdate": 1700533820672,
                "tmdate": 1700533820672,
                "mdate": 1700533820672,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "79NPObxHup",
            "forum": "lHZm9vNm5H",
            "replyto": "lHZm9vNm5H",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3142/Reviewer_1pnn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3142/Reviewer_1pnn"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors introduce the Tune mode of ConvBN blocks, which can save memory and time costs during transfer learning. Experiments show that when transferring the backbone with ConvBN to downstream tasks, Tune mode can save 20%-40% of memory costs without loss of accuracy."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The writing and presentation of the paper are clear and easy to understand. \n2. The method (Tune mode for ConvBN blocks) is reasonable and novel.\n3. The experiments on five datasets and 12 model architectures show the method's effectiveness: Tune mode can save 20%-40% of memory costs without losing accuracy."
                },
                "weaknesses": {
                    "value": "1. Although the method to reduce the cost of Eval mode is very clever, the contribution of the paper to academic research is limited. This paper is more like introducing a useful technical trick to reduce the overhead of ConvBN's eval mode in transfer learning. There are no foreseeable follow-up research directions here. This method technically belongs to Gradient Checkpointing (Bulo et al. (2018)), but the authors cleverly use the affine transformation of BN to escape the time cost. On the other hand, this trick can only apply to BN with eval mode."
                },
                "questions": {
                    "value": "1. The conclusion that \"Eval mode gets significantly better mAP than Train mode\" is too strong for me. From my personal experience, I sometimes get better accuracy using BN's training mode than using eval mode for transfer learning. Therefore, the authors should provide more experiments than the two selected models to verify this strong conclusion.\n2. As SyncBN's eval mode has similar behavior to BN, I am not sure whether the Tune mode can be directly applied to the backbone trained with SyncBN. The author can explain this in the response."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3142/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698652209729,
            "cdate": 1698652209729,
            "tmdate": 1699636261279,
            "mdate": 1699636261279,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "UPMNpqxg38",
                "forum": "lHZm9vNm5H",
                "replyto": "79NPObxHup",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3142/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3142/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1pnn"
                    },
                    "comment": {
                        "value": "Thank you for your appreciation. Here are our responses to your concerns:\n\n# Possible follow-up research directions\n\nThere are two possible kinds of follow-up research:\n\n- To reduce further the memory/time cost on top of our Tune mode ConvBN blocks.\n- To apply our Tune mode ConvBN blocks to various domains.\n\nWhile we admit the first kind of follow-up research might be difficult, we firmly believe that **there will be a lot of follow-up research in the second direction**, especially in the computer vision and object detection community. For example, as shown in Figure 1 in the paper, our method can benefit 496 (78.2%) training configurations in the popular MMDetection library.\n\nIn addition, as mentioned in [the common response](https://openreview.net/forum?id=lHZm9vNm5H&noteId=cgxGu9HEox), to the best of our knowledge, our paper is among the first batch of papers to bridge pioneering deep learning compilers with machine learning algorithms. In this aspect, our work can also inspire future research in the intersection of machine learning algorithms and systems.\n\n# The claim \"Eval mode gets significantly better mAP than Train mode\" is too strong\n\nThanks for pointing it out. We will turn down the tone. The claim is stated in the context of object detection, where the batch size is often small and [Train mode is known to deteriorate](https://proceedings.neurips.cc/paper/2017/file/c54e7837e0cd0ced286cb5995327d1ab-Paper.pdf). Please refer to \"Batch renormalization: Towards reducing minibatch dependence in batch-normalized models\" in NeurIPS 2017 for details.\n\n# Whether the Tune mode can be directly applied to the backbone trained with SyncBN\n\nThat's a nice catch! SyncBN's Eval mode has the same behavior as BN's Eval mode, so our method can be directly applied to the backbone trained with SyncBN.\n\nWe hope the above responses can address your concerns. Should you have any other questions, we will be happy to provide more information."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3142/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699979990300,
                "cdate": 1699979990300,
                "tmdate": 1699981235607,
                "mdate": 1699981235607,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "X0SAJi1Hyf",
            "forum": "lHZm9vNm5H",
            "replyto": "lHZm9vNm5H",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3142/Reviewer_nwrB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3142/Reviewer_nwrB"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a novel calculation strategy for ConvBN by changing the order of calculation. The proposed Tune mode have exact same forward/back propagation expression with the eval mode yet are faster and has lesser memory footprint, demonstrated both theoretically and empirically. This makes it a useful component in transfer learning. The authors also attributed the instability of the training using deploy mode to the scaled weight and gradient, leading to the necessity of saving part of the parameters."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The writing is pretty clear with solid proof and extensive result.\n2. The proposed method can be used widely in computer vision tasks."
                },
                "weaknesses": {
                    "value": "Not much."
                },
                "questions": {
                    "value": "Is it possible to merge $b$ and $\\beta$?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3142/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3142/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3142/Reviewer_nwrB"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3142/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698821708770,
            "cdate": 1698821708770,
            "tmdate": 1699636261182,
            "mdate": 1699636261182,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "UDj1jkOAoU",
                "forum": "lHZm9vNm5H",
                "replyto": "X0SAJi1Hyf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3142/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3142/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer nwrB"
                    },
                    "comment": {
                        "value": "Thank you for your appreciation. Here is our response to your question:\n\n# Is it possible to merge $b$ and $\\beta$?\n\nYes, it is possible to merge $b$ and $\\beta$. When people use ConvBN blocks, they usually merge $b$ and $\\beta$. Examples include [torchvision](https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py#L49) and [timm](https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/resnet.py#L92), two widely used library for computer vision that sets `bias=False` in ConvBN blocks.\n\nOur analysis targets the general case of unmerged $b$ and $\\beta$. It also works for merged $b$ and $\\beta$ (by setting $b=0$).\n\nWe hope the above response can address your concern. Should you have any other questions, we will be happy to provide more information."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3142/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699979928438,
                "cdate": 1699979928438,
                "tmdate": 1699980159322,
                "mdate": 1699980159322,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "io9v5BCUzU",
                "forum": "lHZm9vNm5H",
                "replyto": "UDj1jkOAoU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3142/Reviewer_nwrB"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3142/Reviewer_nwrB"
                ],
                "content": {
                    "title": {
                        "value": "Response to rebuttal"
                    },
                    "comment": {
                        "value": "Thanks for the response. I will keep my score."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3142/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700526211156,
                "cdate": 1700526211156,
                "tmdate": 1700526211156,
                "mdate": 1700526211156,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "JL6XXobaGD",
            "forum": "lHZm9vNm5H",
            "replyto": "lHZm9vNm5H",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3142/Reviewer_E7re"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3142/Reviewer_E7re"
            ],
            "content": {
                "summary": {
                    "value": "This paper primarily investigates the forward computation and backpropagation process in model training or testing of three modes (i.e., Train, Eval, Deploy) of the ConvBN module (Convolution layer plus BN layer), with a focus on the instability of the Deploy mode during transfer learning. Thus, a new mode called Tune mode is proposed, which boasts the advantages of training stability and low computational time and space costs. \n\nTo verify the effectiveness of Tune mode, the authors selected 5 datasets and 12 models, and conducted extensive experiments in classification and detection tasks. The experiments show that using Tune mode for transfer learning results in a slight improvement in model performance, and a significant reduction in time and space costs. Furthermore, the authors tested the effectiveness of Tune mode in the generation of adversarial samples, thereby demonstrating the general applicability of Tune mode as a replacement for Eval mode in tasks that originally used Eval mode."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The article is clearly articulated, with detailed experimental settings, and the proposed Tune mode is simple to implement and easy to reproduce.\n2. The theoretical analysis and experimental verification of the instability in Deploy mode training presented in the article seem plausible.\n3. The author conducted a large number of experiments to validate the advantages of Tune mode in terms of training stability and low time-space cost, with the latter being significantly beneficial."
                },
                "weaknesses": {
                    "value": "1. The method proposed in this article is only applicable to methods that originally used Eval mode, its application scenarios are not very broad, and the impact is relatively small.\n2. This article only provides experimental verification for the time and space cost advantages of Tune mode. Is it possible to make theoretical estimates and give a result similar to O(N)?"
                },
                "questions": {
                    "value": "See above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3142/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699562538107,
            "cdate": 1699562538107,
            "tmdate": 1699636261123,
            "mdate": 1699636261123,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gyG6v2g3qZ",
                "forum": "lHZm9vNm5H",
                "replyto": "JL6XXobaGD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3142/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3142/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer E7re"
                    },
                    "comment": {
                        "value": "Thank you for your appreciation. Here are our responses to your concerns:\n\n# Scope and impact\n\nOur work focuses on basic building blocks (ConvBN blocks) in computer vision. As shown in Figure 1 of the paper, training ConvBN blocks with Eval mode takes up a substantial proportion (78.2%) of object detection models, underscoring our work's widespread applicability and impact especially in computer vision and object detection.\n\n# Theoretical analyses of benefit in memory/time cost\n\n## Memory analysis\n\nThe memory analysis is provided in Section 3.4.2 in the paper, and we rephrase it using the big-O notation required by reviewer E7re:\n\nMemory cost for Eval mode: $\\mathcal{O}(X + Y) = \\mathcal{O}(N C_{\\text{in}} H_{\\text{in}} W_{\\text{in}} + N C_{\\text{out}} H_{\\text{out}} W_{\\text{out}})$.\n\nMemory cost for Tune mode: $\\mathcal{O}(X + \\omega^\\prime) = \\mathcal{O}(N C_{\\text{in}} H_{\\text{in}} W_{\\text{in}} + k^2C_{\\text{in}} C_{\\text{out}})$.\n\nFor each ConvBN block, **the memory cost reduction of Tune mode** is $\\mathcal{O}(N C_{\\text{out}} H_{\\text{out}} W_{\\text{out}} - k^2C_{\\text{in}} C_{\\text{out}})$.\n\nFrom the analysis, we can conclude that networks with larger feature maps (larger $H_{\\text{out}}W_{\\text{out}}$, such as HRNet that features high resolutions), smaller kernel sizes (smaller $k$, such as RepVGG with many $k=1$ conv kernels), and larger batch sizes (larger $N$) will benefit more from the proposed Tune mode. The conclusion can be empirically validated. We take correponding results from Table 8 in the paper to present the following table for your convenience.\n\nWe can observe that:\n\n- The memory cost reduction ratio grows from $18.47$% to $34.83 $% when the batch size grows from $2$ to $16$, for the same Faster RCNN detector with ResNet101 backbone.\n- The memory cost reduction ratio grows from $18.47$% to $35.76$% when changing the network backbone from ResNet101 to HRNet while keeping the rest the same (i.e., mainly enlarge $H_{\\text{out}}W_{\\text{out}}$ ).\n- The memory cost reduction ratio grows from $34.83$% to $43.04$% when changing the network backbone from ResNet101 to RepVGG while keeping the rest the same (i.e., mainly decrease $k$).\n\n| Detector | Backbone | Batchsize | Precision | mode | mAP | Memory(GB)|\n|---------|---------|---------|---------|---------|---------|---------|\n| Faster RCNN  | ResNet101  | 2  | FP16  | Eval  | 0.3944  | 3.849   |\n| Faster RCNN  | ResNet101  | 2  | FP16  | Tune  | 0.3925  |  3.138 ($\\textbf{18.47}$%$\\downarrow$)   |\n| Faster RCNN  | ResNet101  | 8  | FP16  | Eval  | 0.3922  | 10.411   |\n| Faster RCNN  | ResNet101  | 8  | FP16  | Tune  | 0.3917  |  7.036  ($\\textbf{32.41}$%$\\downarrow$)  |\n| Faster RCNN  | ResNet101  | 16  | FP16  | Eval  | 0.3902  | 19.799   |\n| Faster RCNN  | ResNet101  | 16  | FP16  | Tune  | 0.3899  |  12.901  ($\\textbf{34.83}$%$\\downarrow$)  |\n| Faster RCNN  | HRNet  | 2  | FP32  | Eval  |  0.4017 | 8.504   |\n| Faster RCNN  | HRNet  | 2  | FP32  | Tune  |  0.4031 | 5.463  ($\\textbf{35.76}$%$\\downarrow$)   |\n| Faster RCNN  | RepVGG  | 16  | FP16  | Eval  |  0.3350 | 15.80   |\n| Faster RCNN  | RepVGG  | 16  | FP16  | Tune  |  0.3350 | 9.00 ($\\textbf{43.04}$%$\\downarrow$)  |\n\n## Time analysis\n\nAs pointed out by the [FlashAttention paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/67d57c32e20fd0a7a302cb81d36e40d5-Abstract-Conference.html) (\"Flashattention: Fast and memory-efficient exact attention with io-awareness\", in NeurIPS 2022), **the computation time of modern GPU hardware often scales with memory access** (the number of bytes the program reads from and writes to memory). The cost of memory access can be effectively estimated by summing all node sizes from computation graphs in Table 2. Therefore, we can analyze the time cost of Eval mode and Tune mode as follows:\n\nEval mode time cost: $\\mathcal{O}(X + Y + \\omega + b + \\bar{Y} + \\hat{\\mu} + \\hat{\\sigma} + \\beta + \\gamma + Z) = \\mathcal{O}(N C_{\\text{in}} H_{\\text{in}} W_{\\text{in}} + 3 N C_{\\text{out}} H_{\\text{out}} W_{\\text{out}} + k^2C_{\\text{in}} C_{\\text{out}} + 5 C_{\\text{out}})$.\n\nTune mode time cost: $\\mathcal{O}(X + \\omega + b + \\omega^\\prime + b^\\prime + \\hat{\\mu} + \\hat{\\sigma} + \\beta + \\gamma + Z) = \\mathcal{O}(N C_{\\text{in}} H_{\\text{in}} W_{\\text{in}} + N C_{\\text{out}} H_{\\text{out}} W_{\\text{out}} + 2 k^2C_{\\text{in}} C_{\\text{out}} + 6 C_{\\text{out}})$.\n\nFor each ConvBN block, **the time cost reduction of Tune mode** is $\\mathcal{O}(2 N C_{\\text{out}} H_{\\text{out}} W_{\\text{out}} - k^2C_{\\text{in}} C_{\\text{out}} - C_{\\text{out}})$. Since feature maps (size $N C_{\\text{out}} H_{\\text{out}} W_{\\text{out}}$) are typically much larger than convolutional kernels (size $k^2C_{\\text{in}} C_{\\text{out}}$) and biases (size $C_{\\text{out}}$), the proposed Tune mode can reduce time cost.\n\nWe hope the above responses address your concerns. Should you have any other questions, we will be happy to provide more information."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3142/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699979875988,
                "cdate": 1699979875988,
                "tmdate": 1699980985144,
                "mdate": 1699980985144,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vilPixyhdY",
                "forum": "lHZm9vNm5H",
                "replyto": "JL6XXobaGD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3142/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3142/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We are looking forward to your feedback."
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nFollowing your questions, we added detailed theoretical analyses for the memory benefit and time cost reduction. We also highlight the [integration with deep learning compiler](https://openreview.net/forum?id=lHZm9vNm5H&noteId=cgxGu9HEox) and [the impact on open-source community](https://openreview.net/forum?id=lHZm9vNm5H&noteId=KwTYteJUnC)  in the common response notes.\n\nWe eagerly wait for your valuable feedback on the above response."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3142/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700672030841,
                "cdate": 1700672030841,
                "tmdate": 1700672277333,
                "mdate": 1700672277333,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]