[
    {
        "title": "Towards Reliable and Efficient Backdoor Trigger Inversion via Decoupling Benign Features"
    },
    {
        "review": {
            "id": "woubkZdQVN",
            "forum": "Tw9wemV6cb",
            "replyto": "Tw9wemV6cb",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2275/Reviewer_tkgj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2275/Reviewer_tkgj"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, a trigger inversion approach is proposed by first decoupling the benign features from the backdoor features. Then the trigger is inverted on the backdoor features. The proposed method is evaluated on several datasets compared with several baseline approaches against several popular backdoor attacks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The paper is generally well-organized."
                },
                "weaknesses": {
                    "value": "* (Claimed contribution 3) The proposed BTI-DBF is almost the same as the backdoor mitigation approach in Neural Cleanse [1]!\n\nI didn't flag for ethics review for this one since I tend to believe that the authors just omitted this existing approach.\n\n[1] Wang et al,  Neural cleanse: Identifying and mitigating backdoor attacks in neural networks. In IEEE S&P, 2019.\n\n* (Claimed contribution 2) The general idea of first decoupling backdoor features from benign ones and then performing trigger inversion on backdoor features is the same as in [2] (though the formulation of the optimization problem is different).\n\n[2] Liu et al, ABS: Scanning Neural Networks for Back-doors by Artificial Brain Stimulation. CCS, 2019.\n\n* (Claimed contribution 1) \"Revealing the low efficiency and low similarity nature of existing backdoor trigger inversion (BTI) methods and their intrinsic reason\" cannot be regarded as a contribution even though you show your method performs better. Besides, there is no adequate discussion about the \"intrinsic reason\" in this paper.\n\n* The motivation of this work is weak.\n\nWhat is the motivation for proposing this trigger inversion approach? If the purpose is for better backdoor detection, there is no detection performance demonstrated in the paper. If it is for better backdoor mitigation, there is no evidence that the trigger inverted by other baselines cannot mitigate the backdoor. Moreover, intuitively, inaccurately estimated triggers will introduce more robustness to backdoor unlearning. For example, if the trigger is a 3 by 3 yellow square, unlearning using yellow squares with different shapes and sizes will be more effective than unlearning the backdoor using the exact 3 by 3 square only.\n\n* The results in Table 1 need to be double-checked.\n\nFor example, the DSR for Unicorn is much lower than the original paper [3].\n\n[3] Wang et al, Unicorn: A unified backdoor trigger inversion framework. In ICLR, 2023.\n\n* The intuition behind the proposed method does not always hold.\n\nThe proposed trigger inversion method can be defeated when there is no decoupling between benign and backdoor features. This happens when the model is compact and when the trigger is globally wide. For example, the \"chessboard\" trigger that cannot be mitigated by the method in [4] does not satisfy the decoupling assumption.\n\n[4] Wang et al, MM-BD: Post-Training Detection of Backdoor Attacks with Arbitrary Backdoor Pattern Types Using a Maximum Margin Statistic, In IEEE S&P, 2024.\n\n* Insufficient evaluation of the decoupling method.\n\nIf the decoupling method works for the proposed formulation for trigger inversion, it should also work for other formulations such as Unicorn. It is important to show that such decoupling is generalizable.\n\n* No evaluation of efficiency in the main paper.\n\nTo show that the proposed method is reliable and efficient, it is necessary to include a quantitative comparison of computational overhead in the main paper."
                },
                "questions": {
                    "value": "Please see the weakness part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2275/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2275/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2275/Reviewer_tkgj"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2275/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698283695398,
            "cdate": 1698283695398,
            "tmdate": 1700491160780,
            "mdate": 1700491160780,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Zs6h5DZt6Q",
                "forum": "Tw9wemV6cb",
                "replyto": "woubkZdQVN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2275/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2275/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response (Part I)"
                    },
                    "comment": {
                        "value": "Dear Reviewer tkgj, thank you very much for your careful review of our paper and thoughtful comments. We are encouraged by your positive comments on our **good paper presentation**. We are deeply sorry that our previous submission may lead you to some misunderstandings. We hope the following responses could help clarify misunderstandings and alleviate your concerns.\n\n---\n**Q1**: The proposed BTI-DBF is almost the same as the backdoor mitigation approach in Neural Cleanse. \n\n**R1**: Thank you for this comment! We are deeply sorry that our previous submission may lead you to some misunderstandings that we want to clarify here.\n\n- We speculate that you have this misunderstanding mainly because we all have a trigger inversion process before conducting further defenses. However, **this is the characteristic of all backdoor trigger inversion (BTI)-based methods**. We argue that it is unfair to claim our method is almost the same as neural cleanse simply based on it.\n- **Our BTI is quite different from neural cleanse in trigger inversion**. Neural cleanse used $x' = (1-m)\\cdot t + m\\cdot x$ to generate backdoor samples. Their $m$ and $t$ are fixed after training. However, **our method can generate different triggers via the UNet generator.** Moreover, Neural Cleanse only considers the backdoor behavior in pixel space. Our method further considers the backdoor behavior in feature space and finds the difference between the benign features and the backdoor features. Therefore, **our method can generate higher-quality triggers**. As shown in the Table in our paper, our defenses can succeed even when the triggers are dynamic, but neural cleanse can't.\n- **Our work considers more defense variants.** We apply our BTI in backdoor-removal defenses, pre-processing-based defenses, and detection-based defenses. However, **neural cleanse did not consider the pre-processing-based variant**. We have made certain breakthroughs in this regard.\n\n---\n\n**Q2**: The general idea of first decoupling backdoor features from benign ones and then performing trigger inversion on backdoor features is the same as in [ABS: Scanning Neural Networks for Back-doors by Artificial Brain Stimulation. CCS, 2019.] (though the formulation of the optimization problem is different).\n\n**R2**: Thank you for this comment! We are deeply sorry that our previous submission may lead you to some misunderstandings that we want to clarify here.\n\n- **We never claimed that we were the first to work on backdoor trigger inversion by separating benign and backdoor features**. In our paper, we intended to emphasize that all existing methods (including ABS) first fitted backdoor features before decoupling backdoor and benign features. In contrast, our method first fits benign features, avoiding the assumption of backdoor generation.\n- Similar to neural cleanse, **ABS also assumed that backdoor features can be completely separated from benign ones at the neuron-level**. This method ignored the complex interactions between neurons. In contrast, we exploit a soft feature mask whose elements are from $[0, 1]$ instead of $\\{0, 1\\}$ to learn interaction effects.\n\n---\n\n**Q3**: \"Revealing the low efficiency and low similarity nature of existing backdoor trigger inversion (BTI) methods and their intrinsic reason\" cannot be regarded as a contribution even though you show your method performs better. Besides, there is no adequate discussion about the \"intrinsic reason\" in this paper.\n\n**R3**: Thanks for your comments. We explained why exsiting BTI methods can't decouple the backdoor features in our Section 1. We are deeply sorry that we failed to describe it more clearly and lead you to some misunderstandings. We hereby provide more details about it.\n- We argue that revealing the common underlying limitations of an important defense paradigm (i.e., backdoor trigger inversion) is also an important contribution. This can alert the field against blind optimism about such methods. \n- **Intrinsic Reasons**: We reveal that both limitations are all because existing methods need to approximate and decouple backdoor features at first to separate benign and backdoor features, as required by BTI. Specifically, **these methods need to 'scan' all potential classes to speculate the target label since defenders have no prior knowledge about attacks and poisoned samples**. These processes are time-consuming since each scan requires iteratively solving a particular optimization problem. \n\n---"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2275/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700480709821,
                "cdate": 1700480709821,
                "tmdate": 1700480709821,
                "mdate": 1700480709821,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Spxa8ScW5y",
                "forum": "Tw9wemV6cb",
                "replyto": "h1KD6XzYEi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2275/Reviewer_tkgj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2275/Reviewer_tkgj"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "I appreciate the author's efforts in rebuttal. All my concerns have been addressed. I have changed my rating accordingly."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2275/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700489664213,
                "cdate": 1700489664213,
                "tmdate": 1700489664213,
                "mdate": 1700489664213,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "k4llhX8hx9",
            "forum": "Tw9wemV6cb",
            "replyto": "Tw9wemV6cb",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2275/Reviewer_gstB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2275/Reviewer_gstB"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new backdoor trigger inversion method. Existing inversion\nmethods optimize the backdoor features, but this paper takes a different\napproach that minimizes the feature differences between a benign image and its\ntriggered version. The method is efficient as it no longer requires scanning\nof all classes of a model."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This is an interesting paper. Its main contribution is a trigger inversion\nmethod for backdoor attacks. The main method is quite different from existing\nones, as it works as the \"opposite\" to existing ones by leveraging the benign\nfeatures rather than focusing on the trigger-related ones.\n\nThe method also overcomes the limitation of existing method that requires\nscanning all output classes to select the most likely target label and class.\n\nThe paper has compared the proposed method with state-of-the-art baselines and achieved remarkable results.\n\nThe paper also discussed potential adaptive attacks, which is based on blending\nthe adverbial features into benign ones."
                },
                "weaknesses": {
                    "value": "Besides the discussed adaptive attack that blend features, some attacks, e.g.,\nthe composite attack, \"Composite Backdoor Attack for Deep Neural Network by\nMixing Existing Benign Features\" from CCS 2020, also heavily mix benign and\nmalicious features. Similarly, the paper can benefit from evaluating on other baselines, e.g., NONE (NeurIPS'22)."
                },
                "questions": {
                    "value": "See detailed comments."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2275/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698771984667,
            "cdate": 1698771984667,
            "tmdate": 1699636160464,
            "mdate": 1699636160464,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "P6kUEdJnam",
                "forum": "Tw9wemV6cb",
                "replyto": "k4llhX8hx9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2275/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2275/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response"
                    },
                    "comment": {
                        "value": "Dear Reviewer gstB, thank you very much for your careful review of our paper and thoughtful comments. We are encouraged by your positive comments on our **novel approach**, **efficiency**, **remarkable performance**, **resistance to adaptive attacks**, and **good paper presentation**. We hope the following responses could alleviate your concerns.\n\n---\n**Q1**: Besides the discussed adaptive attack that blend features, some attacks, e.g., the composite attack, \"Composite Backdoor Attack for Deep Neural Network by Mixing Existing Benign Features\" from CCS 2020, also heavily mix benign and malicious features. Similarly, the paper can benefit from evaluating on other baselines, e.g., NONE (NeurIPS'22).\n\n\n**R1**: Thank you for these constructive suggestions!\n\n- We argue that composite attack is well-suited as the adaptive attack against our defenses. We reproduce the composite attack method with its offical code under the default setting. As shown in the following Table 1, **both BTI-DBF (U) and BTI-DBF \\(P\\) are still effective in defending against the composite attack**. It is mostly because we use a soft mask $m \\in [0, 1]$, and the benign features can still be decoupled from the backdoor features, even though they are mixed to some extent. \n\n**Table 1. The performance (%) of our methods in defending against the composite attack on CIFAR-10.**  \n\n| Defenses $\\downarrow$  Metric $\\rightarrow$    | BA  | ASR  |\n| ----  | ----  | ----  |\n| No Defense  | 92.79 | 97.10 |\n| BTI-DBF (P\\)  | 89.48 | 4.50 |\n| BTI-DBF (U)  | 90.63 | 1.88  |\n\n- Due to the time constraint, we use BadNets with different trigger sizes for discussions. We reproduce NONE based on its official code under the default setting. As shown in Table 2, our method is comparable with NONE under the trigger size in $7\\times7$ and $9\\times9$. However, we note that our defense is still effective when the trigger size is $15\\times15$ while NONE does not work well.\n\n\n\n\n**Table 2. The performance (%) of our methods and NONE in defending against BadNets with different trigger size on CIFAR-10.**\n|  Trigger Size $\\rightarrow$   | $7\\times7$ | $9\\times9$ | $15\\times15$ |\n| ----  | ----  | ----  | ----  |\n|  Defenses $\\downarrow$  Metric $\\rightarrow$   | BA / ASR | BA / ASR | BA / ASR |\n|  No Defense  | 92.32 / 100.00 | 92.24 / 100.00 | 92.06 / 100.00 |\n|  NONE  | 90.28 / 1.69  | 90.54 / 1.97 | 89.78 / 23.26|\n|  BTI-DBF (P\\)  |89.57 / 2.21 | 89.02 / 4.57 | 88.45 / 4.97|\n|  BTI-DBF (U)  |90.46 / 1.07 |90.17 / 2.36 |90.27 / 0.86 |\n\n\n\nPlease refer to Appendix P.2 of our revision for more details.\n\n\n---"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2275/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700480662180,
                "cdate": 1700480662180,
                "tmdate": 1700480662180,
                "mdate": 1700480662180,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DwVNgzEOIH",
                "forum": "Tw9wemV6cb",
                "replyto": "k4llhX8hx9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2275/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2275/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks to Reviewer gstB"
                    },
                    "comment": {
                        "value": "Please allow us to thank you again for reviewing our paper and the valuable feedback, and in particular for recognizing the strengths of our paper in terms of *novelty*, *efficiency and effectiveness*, *resistance to adaptive attacks*, and *good writing*.\n\nKindly let us know if our response and the new experiments have properly addressed your concerns. We are more than happy to answer any additional questions during the post-rebuttal period. Your feedback will be greatly appreciated."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2275/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700525855830,
                "cdate": 1700525855830,
                "tmdate": 1700525855830,
                "mdate": 1700525855830,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TiCCGD8mhF",
                "forum": "Tw9wemV6cb",
                "replyto": "k4llhX8hx9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2275/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2275/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A Gentle Reminder of the Final Feedback"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for the helpful discussion during the first round of the review. We hope our response has adequately addressed your comments related to the resistance of our methods to the composite attack and the comparison to NONE baseline. We take this as a great opportunity to improve our work and shall be grateful for any additional feedback you could give to us."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2275/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700616858806,
                "cdate": 1700616858806,
                "tmdate": 1700616858806,
                "mdate": 1700616858806,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hrSRM9QjDu",
            "forum": "Tw9wemV6cb",
            "replyto": "Tw9wemV6cb",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2275/Reviewer_SUKT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2275/Reviewer_SUKT"
            ],
            "content": {
                "summary": {
                    "value": "Existing trigger inversion techniques optimizes the trigger to find malicious\nfeatures. This paper goes the other way and tries to optimize the image so that\nthe benign features to be close. This is a new angle of optimizing the trigger.\nThe evaluation is comprehensive including a lot of datasets, models, and\nbaseline methods. Results are promising."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The inversion technique is novel and different from existing works.\n\nThe proposed method can work as different variants on different phases of the\ndefense.\n\nThe evaluation is comprehensive, using different datasets and baselines, etc."
                },
                "weaknesses": {
                    "value": "An intuition of existing backdoor trigger inversion method is that backdoor\nfeature pattern is relatively fixed and in small size, e.g., a patch or a filter\nor a generative function. However, the feature space of benign samples can be\nhuge, for example, for the class horse, there could be so many types of benign\nfeature clusters. We are not sure if there is only one cluster in the feature\nspace or there are actually many of them. Thus, the optimization directions can\nbe relatively random. Have you tried different versions of benign features\n(e.g., different distance measurement)?\n\nThe adaptive settings consider blending the benign and poisoned samples in the\nfeature space. Have you considered triggers that naturally appear in the\ntraining dataset, i.e., natural triggers?"
                },
                "questions": {
                    "value": "How is the performance on natural triggers?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2275/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698772434763,
            "cdate": 1698772434763,
            "tmdate": 1699636160367,
            "mdate": 1699636160367,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qQLWyft7Kt",
                "forum": "Tw9wemV6cb",
                "replyto": "hrSRM9QjDu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2275/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2275/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response"
                    },
                    "comment": {
                        "value": "Dear Reviewer SUKT, thank you very much for your careful review of our paper and thoughtful comments. We are encouraged by your positive comments on our **novel and different approach**, **different defense variants**, **comprehensive evaluation**, and **good paper presentation**. We hope the following responses could help clarify potential misunderstandings and alleviate your concerns.\n\n---\n**Q1**: An intuition of existing backdoor trigger inversion method is that backdoor feature pattern is relatively fixed and in small size, e.g., a patch or a filter or a generative function. However, the feature space of benign samples can be huge, for example, for the class horse, there could be so many types of benign feature clusters. We are not sure if there is only one cluster in the feature space or there are actually many of them. Thus, the optimization directions can be relatively random. Have you tried different versions of benign features (e.g., different distance measurement)?\n\n**R1**: Thanks for this insightful question! We are deeply sorry that our submission may lead you to some misunderstandings that we want to clarify.\n\n- **We did not assume that backdoor features are relatively fixed and in small size to a large extent**. One of the difference between our method and existing methods is that we did not assume that poisoned samples are with the formulation $x' = (1-m) \\cdot x + m\\cdot t$ (with the regularization term $||m||$). \n- In our method, for the backdoor features, **we only assume that we can decouple them with benign features**. In particular, we assume that all elements in our feature mask are from $[0,1]$ instead of $\\{0, 1\\}$. Accordingly, our approach can truly decouple benign and backdoor features at the feature level rather than at the neuron level. It alleviate the assumption of previous methods that backdoor features were only a very small group.\n- In our trigger inversion step, we did assume that the distance between each poisoned sample and their benign version is small. However, **it is even practical even for attacks with visible triggers** (e.g., BadNets) since they only change a few pixels.\n- However, we fully understand your concerns. To alleviate them, we conduct additional experiments with $L_1$ instead of $L_2$ norm as our distance measurement. As shown in the following table, **our methods are still highly effective under the new measurement**.\n\n\n\n\n\n**Table 1. The performance (%) of our methods in defending against six attacks when the distance measurements are L1 norm and L2 norm on CIFAR-10** \n\n|  Defense $\\rightarrow$   | No Defense |BTI-DBF (P\\) |BTI-DBF (U) |BTI-DBF (P\\) |  BTI-DBF (U) | \n| ----  | ----  | ----  |----  |  ----  |----  |\n| Attack $\\downarrow$  Metric $\\rightarrow$    | BA / ASR | BA / ASR | BA / ASR | BA / ASR |BA / ASR |\n| Distance Measurement $\\rightarrow$  | - | L1 Norm | L1 Norm  |L2 Norm | L2 Norm  |\n| BadNets   | 92.82/99.88 | 89.80/1.40 |91.09/0.44  |90.28/1.23| 92.00/1.36\n| Blend  | 93.08/97.31 | 88.97/5.14  |88.25/2.48  |89.13/1.00|  91.60/7.92\n| WaNet  | 94.53/99.59 | 89.62/5.32 |89.48/2.70  |89.14/1.60|  90.82/0.94\n| IAD  | 94.07/99.41 | 89.76/4.64 |90.10/2.14  |90.21/3.73|  91.91/1.22\n| LC  | 94.65/88.83 | 88.95/4.53 |89.26/2.22   |90.02/1.11|  90.48/4.51\n| BppAttack | 93.88/99.99 | 89.57/1.35 |91.76/4.46  |89.39/2.52| 90.98/5.02\n\n\nWe have provided more details in Appendix O of our revision.\n\n---\n\n\n\n**Q2**: The adaptive settings consider blending the benign and poisoned samples in the feature space. Have you considered triggers that naturally appear in the training dataset, i.e., natural triggers?\n\n**R2**: Thank you for this insightful question! We have to admit that we did not think about it. Following similar settings provided in the open-sourced codes of [1], we conduct additional experiments on the MeGlass dataset. As shown in the following table, **our methods are still highly effective in defending against this special attack**. It is mostly because their backdoor features are still decoupled from benign features, and their triggers are still a small part of the whole image (please find more details in our R1). We will further explore it in our future works. Please refer to Appendix P.1 of our revision for more details.\n\n**Reference**\n1. Emily Wenger, et al. \"Finding Naturally Occurring Physical Backdoors in Image Datasets.\" NeurIPS, 2022.\n\n**Table 2. The performance (%) of our methods in defending against natural backdoor attack on the MeGlass dataset.**  \n\n| Defenses $\\downarrow$  Metric $\\rightarrow$    | BA  | ASR  |\n| ----  | ----  | ----  |\n| No Defense  | 82.53 | 99.96 |\n| BTI-DBF (P\\)  | 75.54 | 2.70 |\n| BTI-DBF (U)  | 73.92 | 2.86  |\n\n\n\n---"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2275/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700480590625,
                "cdate": 1700480590625,
                "tmdate": 1700480635467,
                "mdate": 1700480635467,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IBirJYhqhf",
                "forum": "Tw9wemV6cb",
                "replyto": "hrSRM9QjDu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2275/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2275/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks to Reviewer SUKT"
                    },
                    "comment": {
                        "value": "Please allow us to thank you again for reviewing our paper and the valuable feedback, and in particular for recognizing the strengths of our paper in terms of *novelty*, *comprehensive experments*, and *good writing*.\n\nKindly let us know if our response and the new experiments have properly addressed your concerns. We are more than happy to answer any additional questions during the post-rebuttal period. Your feedback will be greatly appreciated."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2275/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700525717157,
                "cdate": 1700525717157,
                "tmdate": 1700525869290,
                "mdate": 1700525869290,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YwrIDBGIPS",
                "forum": "Tw9wemV6cb",
                "replyto": "hrSRM9QjDu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2275/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2275/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A Gentle Reminder of the Final Feedback"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for the helpful discussion during the first round of the review. We hope our response has adequately addressed your comments related to our designs for decoupling benign features and the resistance of our methods to the natural backdoor attack. We take this as a great opportunity to improve our work and shall be grateful for any additional feedback you could give to us."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2275/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700616782367,
                "cdate": 1700616782367,
                "tmdate": 1700616782367,
                "mdate": 1700616782367,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Qczipw2Jbx",
                "forum": "Tw9wemV6cb",
                "replyto": "hrSRM9QjDu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2275/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2275/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A Second Reminder of the Post-rebuttal Feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer SUKT,\n\nWe greatly appreciate your initial comments. We totally understand that you may be extremely busy at this time. But we still hope that you could have a quick look at our responses to your concerns. We appreciate any feedback you could give to us. We also hope that you could kindly update the rating if your questions have been addressed. We are also happy to answer any additional questions before the rebuttal ends.\n\nBest Regards,\n\nPaper2275 Authors"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2275/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700708449763,
                "cdate": 1700708449763,
                "tmdate": 1700708449763,
                "mdate": 1700708449763,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "6Key3h4gK0",
            "forum": "Tw9wemV6cb",
            "replyto": "Tw9wemV6cb",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2275/Reviewer_pvdL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2275/Reviewer_pvdL"
            ],
            "content": {
                "summary": {
                    "value": "In the context of backdoor, this paper delves into the challenges in Backdoor Trigger Inversion (BTI), a critical method in defending against these threats. \n\nTraditional BTI methods have been hindered by their reliance on extracting backdoor features without prior knowledge about the adversaries' trigger patterns or target labels, leading to suboptimal performance. \n\nThe authors propose a novel approach that inverts this paradigm by focusing on the decoupling of benign features (rather than backdoored features), followed by a refined trigger inversion process. This two-step method not only enhances the efficiency by obviating the need to scan all classes for potential target labels but also improves detection accuracy.\n\nThe paper's methodology encompasses minimizing the disparities between benign samples and their generated poisoned counterparts in the benign feature space, while maximizing differences in the backdoor features. \n\nThis approach also lays the groundwork for more effective backdoor-removal and pre-processing-based defenses. \nThe effectiveness of this new method is demonstrated through extensive experiments on benchmark datasets, where it achieves state-of-the-art performance in mitigating backdoor threats, showcasing a significant advancement."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper proposes a novel approach to conduct trigger inversion, which is insightful. The approach is intuitive and appears effective.\n- The paper provides a comprehensive evaluation to show the effectiveness and efficiency."
                },
                "weaknesses": {
                    "value": "- No discussion on the limitations."
                },
                "questions": {
                    "value": "1. Table 8 shows that the evaluation only picks 100 classes from ImageNet. This is wired. Has the method been tested on 1000 classes? What is the scalability of the proposed method? How does the method perform compared to other methods when the number of classes increases?\n\n2. Section 2.2 misses some latest work on feature level BTI:\n- SSL-Cleanse: Trojan Detection and Mitigation in Self-Supervised Learning, M. Zheng et al., 2023\n- Detecting Backdoors in Pre-trained Encoders, S. Feng et al., CVPR'2023\n\nAlthough these 2 works focus on self-supervised learning, they are highly related to the feature level BTI. It would be better to discuss them in Section 2.2."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2275/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2275/Reviewer_pvdL",
                        "ICLR.cc/2024/Conference/Submission2275/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2275/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698806310503,
            "cdate": 1698806310503,
            "tmdate": 1700508543541,
            "mdate": 1700508543541,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jnpHS6lzQP",
                "forum": "Tw9wemV6cb",
                "replyto": "6Key3h4gK0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2275/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2275/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response"
                    },
                    "comment": {
                        "value": "Dear Reviewer pvdL, thank you very much for your careful review of our paper and thoughtful comments. We are encouraged by your positive comments on our **insightful and novel method**, **effectiveness**, **efficiency**, **comprehensive evaluation**, and **good paper presentation**. We hope the following responses could help clarify potential misunderstandings and alleviate your concerns.\n\n---\n**Q1**: Table 8 shows that the evaluation only picks 100 classes from ImageNet. This is wired. Has the method been tested on 1000 classes? What is the scalability of the proposed method? How does the method perform compared to other methods when the number of classes increases?\n\n**R1**: Thank you for the insightful question! We are deeply sorry that our dataset selection may lead you to concerns about our effectiveness. \n\n- **Using ImageNet subset is a common setting in existing backdoor-related works** (e.g., [1, 2]). For example, Fu et al. [1] picked 20 classes and Huang et al. [2] picked 30 classes from ImageNet. In our work, we deliberately chose a relatively large number of categories (i.e., 100) to evaluate the scalability of all methods.\n- However, we do understand your concerns. To further alleviate them, we conduct additional experiments on the ImageNet-1K dataset. Due to the time constraint, we use BadNets and WaNet as attack baselines. Specifically, we set the poison rate to 5\\% and finetune the pre-trained ResNet-18 on ImageNet-1k to implant backdoors. As shown in Table 1, **both BTI-DBF (U) and BTI-DBF \\(P\\) are still effective** (BA drops less than 3%, while the ASR is within 5%), even if the number of classes is huge. \n\n\nWe have provided more details in Appendix M of our revision.\n\n\n**Reference**\n1. Kunzhe Huang, et al. \"Backdoor Defense via Decoupling the Training Process.\" ICLR 2022.\n2. Chong Fu, et al. \"FreeEagle: Detecting Complex Neural Trojans in Data-Free Cases.\" USENIX Security 2023.\n\n\n\n**Table 1. The performance (%) of our methods in defending against BadNets and WaNet on ImageNet-1K.** \n|  Defense $\\rightarrow$   |No Defense  | BTI-DBF (P\\)| BTI-DBF (U)|\n| ----  | ----  | ----  | ----  |\n| Attack $\\downarrow$  Metric $\\rightarrow$  |BA / ASR  | BA / ASR| BA / ASR|\n| BadNets  | 59.79 / 99.63 |57.82 / 4.16|57.42 / 3.57| \n| WaNet  | 61.20 / 96.13 |58.46 / 2.84|59.39 / 1.05| \n\n---\n\n**Q2**: Section 2.2 misses some latest work on feature level BTI\uff1a**(1)** SSL-Cleanse: Trojan Detection and Mitigation in Self-Supervised Learning, 2023. **(2)** Detecting Backdoors in Pre-trained Encoders, 2023. Although these 2 works focus on self-supervised learning, they are highly related to the feature level BTI. It would be better to discuss them in Section 2.2.\n\n\n**R2**: Thank you for this constructive suggestion! After carefully reading their papers, we have added some discussions in Section 2.2, as follows: **Besides, two recent research discussed how to conduct BTI in the feature space under self-supervised learning, inspired by neural cleanse**. Besides, we summarize the differences between their works and our method as follows.\n\n\n- **Motivation:** These two works focused on the BTI in self-supervised Learning in which input labels are not available. However, our work primarily address the limitations in low efficiency and effectiveness of existing BTI method under supervised learning.\n- **Method**. These two works adopted the same 'blended strategy' as neural cleanse in approximating poisoned samples, although the approximation is in the feature space instead of the input space. In contrast, our method only relies on benign samples without needing to assign a particular poisoning form for approximation.\n\n\n---\n\n**Q3**: No discussion on the limitations.\n\n**R3**: Thank you for this insightful question! We are deeply sorry that we missed the discussion about potential limitations of our method. We hereby provide it, as follows.\n\n- As illustrated in Section 3.1, our defense mainly focuses on using third-party pre-trained models. In particular, similar to existing baseline methods, we assume that defenders have a few local benign samples. Accordingly, our method is not feasible without benign samples. Besides, we need to train a model for the scenarios using third-party datasets before conducting trigger inversion and follow-up defenses, which is computation- and time-consuming. We will further explore how to conduct BTI under few/zero-shot settings in our future works.\n- Our method needs to obtain the feature layer of the backdoored model to decouple the benign features and inverse the backdoor triggers. Besides, the optimization process in our method also relies on a white-box setting. Accordingly, it does not apply to black-box scenarios in which the defenders can only access the final output of the backdoored model. We will continue the exploration of the black-box BTI in our future works.\n\nWe have added the disscussion in Appendix N of our revision.\n\n\n---"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2275/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700480553888,
                "cdate": 1700480553888,
                "tmdate": 1700480553888,
                "mdate": 1700480553888,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DuZikIPSln",
                "forum": "Tw9wemV6cb",
                "replyto": "jnpHS6lzQP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2275/Reviewer_pvdL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2275/Reviewer_pvdL"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate authors' efforts in rebuttal. Since all my concerns are well addressed, I raise the score accordingly."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2275/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700508481843,
                "cdate": 1700508481843,
                "tmdate": 1700508481843,
                "mdate": 1700508481843,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]