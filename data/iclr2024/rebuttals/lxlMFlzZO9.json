[
    {
        "title": "DS-Prover: A Dynamic Sampling Based Approach for Neural Theorem Proving"
    },
    {
        "review": {
            "id": "PZFN8ppGjB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8049/Reviewer_MSm4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8049/Reviewer_MSm4"
            ],
            "forum": "lxlMFlzZO9",
            "replyto": "lxlMFlzZO9",
            "content": {
                "summary": {
                    "value": "The paper fine-tunes a language model on Lean3 state-tactic pairs and uses it to search for proofs on college-to-university-level mathematical problems. The main innovations are an augmentation of the training data and an inference-time technique that dynamically chooses how many branches to expand depending on the remaining time."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The proposed methods are straightforward and easy to implement. They bring performance improvement on the miniF2F benchmark."
                },
                "weaknesses": {
                    "value": "I'm not entirely convinced by the claims that these changes are truly beneficial, or how much improvement to the baselines there is:\n- Data augmentation: In table 1, one can actually see that the data augmentation helps for problems in miniF2F, but is actually detrimental to performance for problems in ProofNet (which are harder) and problems in Mathlib (which cover wider mathematical domains). Therefore, the conclusion ought to be that the data augmentation might improve things for certain problems, but cannot increase performance across the board or in general.\n- Without the data augmentation, which I think should be considered as a non-general method as the above point suggests, the proposed method proves 29.0\\% of problems on miniF2F test, which is lower than Lean + Expert Iteration by Polu et al. (2022).\n\nI have more detailed comments and suggestions below:\n\n1. > End of page 1. \"To overcome the issue of limited data for training the model, various alternative attempts have been explored to improve the performance of automated theorem provers, such as reinforcement learning Polu & Sutskever (2020)\"\n\n    (Minor) It is slightly strange to refer to it as an alternative attempt since Polu & Sutskever (2020) is arguably the first work to use generative transformer with interactive theorem provers.\n\n2. (Major) One of the major contributions is \"we also release a public theorem prover website\", but this website is not provided and therefore it is impossible to assess this claim.\n\n3. (Minor) Scholarship needs improving: the related works should not be a simple stack of papers covering related topics, but should rather compare and contrast other works with this current work.\n\n4. (Minor) Citation style: A lot of instances where the citation is glued to the text with no separation, e.g., Leande Moura et al. (2015) on page 3. Use ~\\citep to cite the paper and ~\\citet to cite the authors.\n\n5. > Page 4 assumption: The assumption tactic is used to prove the goal by assuming it\u2019s true based on the available hypotheses\n\n    (Minor) This is clearly not accurate. One never assumes the goal to be true. Rather, one matches the goal with the assumptions with this tactic.\n\n7. (Critical) Misleading claim: I'm surprised that the authors mentioned the HTPS paper by Lample et al., but not their results. The HTPS paper achieved a success rate of >40\\% on the miniF2F with pass@64, compared to 30\\% in this paper with pass@1. Of course, the success rates between pass@1 and pass@64 are very different, but one should be very careful before making the claim **We achieve a new state-of-the-art performance of 30.6% on MiniF2F using Lean** if its success rate is 10\\% (absolute), or 25\\% (relative) lower than a paper published 17 months ago. Some experiments for DS-solver at a higher pass@k should be performed before such claims can be verified."
                },
                "questions": {
                    "value": "For how many steps was the model trained for? What are the training and validation metrics? What is the experimental wallclock time limit per problem for miniF2F, ProofNet and Mathlib?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8049/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697273666733,
            "cdate": 1697273666733,
            "tmdate": 1699636994761,
            "mdate": 1699636994761,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gCUmZOuiNk",
                "forum": "lxlMFlzZO9",
                "replyto": "PZFN8ppGjB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8049/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8049/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer MSm4"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their feedback and will respond to the raised questions below.\n\n**Weakness:**\n\n**W1:** Thanks for pointing this out, we now have improved our statement.\n\n**W2:** We haven't been able to find a secure way to host and share the website without disclosing our identity. As a result, we have refrained from sharing the website at this time.\n\n**W3:** Thanks for the suggestion we are are improving the related works section and also will be adding the related works of theorem provers other than Lean in our paper.\n\n**W4:** Thank you for pointing this out, we now have corrected the citations in the paper.\n\n**W5:** Thank you for highlighting this mistake, we now have corrected our statement in the paper.\n\n**W6:** Thank you for pointing this out. We acknowledge that our best performance is only for pass@1, as we did not conduct experiments for higher pass@k. We will correct our statement accordingly.\n\n\n**Questions:**\n\n**Q1:** For early stopping, we used the Pass@1 of the validation dataset. After each 0.5 epoch in the augmented data model (1 epoch in the original data model) we used the current model to attempt to prove the theorems in the validation dataset. And we selected the model with the best Pass@1 on the validation data for our final evaluation.\n\nWe had given a time limit of 10 minutes to find proof for all the theorems in each dataset. \n\n**We will be submitting our updated paper soon. Thanks for your patience.**"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8049/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700312156840,
                "cdate": 1700312156840,
                "tmdate": 1700312305697,
                "mdate": 1700312305697,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pNucFSvTjz",
                "forum": "lxlMFlzZO9",
                "replyto": "gCUmZOuiNk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8049/Reviewer_MSm4"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8049/Reviewer_MSm4"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your reply. I shall be waiting for the updated paper before considering adjusting my rating."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8049/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700392082588,
                "cdate": 1700392082588,
                "tmdate": 1700392082588,
                "mdate": 1700392082588,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "O3Mg4jGXSx",
            "forum": "lxlMFlzZO9",
            "replyto": "lxlMFlzZO9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8049/Reviewer_6Nhd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8049/Reviewer_6Nhd"
            ],
            "content": {
                "summary": {
                    "value": "Aiming to generate tactics for interactive theorem provers (ITPs) with the help of large language models (LLMs), the paper proposes two methods: the dynamic sampling that determines how many tactics are investigated depending on the remaining time, and the data augmentation that splits an application of a specific tactic with multiple arguments into multiple applications of the tactic with one argument. The effect of the proposed methods is experimentally shown on certain datasets of mathematical theorem proving."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper provides several examples of proof code and tactics in Lean. It would help readers unfamiliar with Lean find the aim and method studied in the paper.\n- The experiments show that the proposed approaches can improve the proof search with LLMs."
                },
                "weaknesses": {
                    "value": "- The improvement by the dynamic sampling seems incremental. The \"Original data\" columns in Table 1 shows only the improvement of 0.4 points against the optimized LeanDojo.\n- The effect of the data augmentation is not entirely clear because there is no experiment that employs only it.\n- Not all the experimental settings are clear. Specifically, I cannot find how many tactics are sampled in the fixed sampling.\n- I'm not convinced by the discussion for Figure 2. It shows that the difference between the dynamic and fixed sampling methods are almost fixed. I suspect it means that the dynamic sampling is effective only for theorems with short proofs because, even when the time budgets are increased, the difference is retained (rather, becomes small).\n- The paper cites other works without parenthesizing the author names. It lowers the readability."
                },
                "questions": {
                    "value": "- How many tactics are sampled in the fixed sampling? Does changing the number of sample tactics influence the result?\n- Does Figure 2 mean that the dynamic sampling is effective only for theorems with short proofs?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8049/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698464848815,
            "cdate": 1698464848815,
            "tmdate": 1699636994553,
            "mdate": 1699636994553,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5y55DY8FMO",
                "forum": "lxlMFlzZO9",
                "replyto": "O3Mg4jGXSx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8049/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8049/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer 6Nhd"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the helpful feedback and will address the raised concerns below.\n\n**Weakness:**\n\n**W1:** Although the increment in performance may be smaller in some cases, we can also observe that dynamic sampling consistently either outperforms fixed sampling or performs equally well, never exhibiting inferior performance. This consistency makes dynamic sampling a better choice of algorithm for searching proofs within a given time limit.\n\n**W2:** Using only the augmented data would result in longer proofs since all the generated tactics will only have a maximum of one premise. Consequently, we would need to search the tree in greater depth to find proof, which would increase the time required for the search. Therefore, we decided not to perform this experiment.\n\n**W3:** Thanks for pointing this out. In the fixed sampling method, we sampled 64 tactics each time. We have now included this information in the paper.\n\n**W4:** We have conducted experiments to study this matter in detail, and we will be discussing the findings in the paper.\n\n**W5:** Thank you for pointing this out, we now have corrected the citations in the paper.\n\n**Questions:**\n\n**Q1:** In fixed sampling, 64 tactics are sampled each time. \n\nYes, decreasing the number of tactics to sample and apply as time passes influences the result. We have added new results discussing this aspect in the paper.\n\n**Q2:** No, in fact, our analysis of the results demonstrates that the reverse is true. We have now included these results in the paper.\n\n**We will be submitting our updated paper soon. Thanks for your patience.**"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8049/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700314269161,
                "cdate": 1700314269161,
                "tmdate": 1700314269161,
                "mdate": 1700314269161,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6ZXpLjaQBj",
                "forum": "lxlMFlzZO9",
                "replyto": "5y55DY8FMO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8049/Reviewer_6Nhd"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8049/Reviewer_6Nhd"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for giving the response and updating the paper. I looked at the updated paper, but I don't think it is at the stage to be published due to the following concerns.\n\n- The updated paper shows the result in converting tactics to standard forms. Therefore, it is not clear that the improvement of the performance in the updated paper is owing to the data augment, the standardization, or both of them. Especially, in the original paper, the data augmentation does not contribute to the improvement of the performance on ProofNet and Mathlib, while in the updated paper, it does. Given only this result, I cannot ignore the possibility that the standardization is more important than the data augmentation.\n\n- The updated paper claims that the dynamic sampling is effective especially on longer proofs (Figure 3). However, I'm unsure how it can be made consistent with Figure 2 in the original paper which says that the dynamic sampling can solve more problems than the fixed sampling even in short time (2.5 minutes).\n\n- I'm not very convinced by the response to W2. Do the authors mean using only the data augmentation is definitely useless?"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8049/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700718154671,
                "cdate": 1700718154671,
                "tmdate": 1700718154671,
                "mdate": 1700718154671,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "VuZkKjNNMF",
            "forum": "lxlMFlzZO9",
            "replyto": "lxlMFlzZO9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8049/Reviewer_FKE8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8049/Reviewer_FKE8"
            ],
            "content": {
                "summary": {
                    "value": "In this submission, the authors consider automatic theorem proving with Transformer models. They introduce a dynamic way of sampling from a tactic space while take total time left for proving the theorem into account. They show that this makes proof search more efficient by balancing exploration vs exploitation. They additionally provide a data augmentation by decomposing tactics with multiple premises.\nThey conducted experiments by training a ByT5 model on formalized theorems in Lean (mathlib repo) and evaluating their model on MiniF2F and ProofNet, two standard datasets in the literature. The results show that they approach is resulting in performance gains."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Interactive theorem proving (especially in Lean) has gained a lot of attention recently. With more and more mathematicians picking it up and more and more machine learning support to ease the construction of the proofs, the paper is certainly relevant for ICLR and the problem is interesting.\n- Although the models are fairly small, they provide a new state of the art\n- The approach is straightforward and well-explained. Datasets are open-source; and they seemed to released their models on a public website (this makes the experiments reproducible for academics and students)"
                },
                "weaknesses": {
                    "value": "- The comparisons in Table 1 seem to be slightly unfair: (time used by LeanDojo and the optimized version vs. the proposed method is unclear)\n- Not clear from the paper, if model weights and code will be open-sourced\n- The contribution is straightforward and more on the minor side\n- Interesting ablations and more in-depth analysis is missing (more detailed analysis of time tradeoff in Figure 2)\n- The related work is highly insufficiently discussed"
                },
                "questions": {
                    "value": "- Will the code and models be open-source?\n- Would the authors consider expanding the related work section a bit including highly influential, but more non-lean related research?\n- what is the time used by LeanDojo and the optimized version vs. the sampling? Can this be added to Table 1\n- Where are the tradeoffs in exploration vs exploitation; Table 2? For example, what size are the proofs where the sampling strategy works well? Are there cases where fixed sampling is better?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8049/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698714427693,
            "cdate": 1698714427693,
            "tmdate": 1699636994355,
            "mdate": 1699636994355,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "N0K2lAzL02",
                "forum": "lxlMFlzZO9",
                "replyto": "VuZkKjNNMF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8049/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8049/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer FKE8"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their feedback and will respond to the raised questions below.\n\n**Weakness:**\n\n**W1:** We apologize for the confusion. To clarify, we maintained a consistent time limit of 10 minutes for all the experiments conducted.  This information has now been included in the table caption for clarification.\n\n**W2:** Yes, we plan to make the Model, Code, and DataSets available as open-source.\n\n**W3:** We acknowledge that the contributions may seem straightforward. However, by implementing these small improvements, we've achieved comparable performance to models with significantly higher computational requirements. This aspect makes our method highly suitable for general use, even with limited computational resources.\n\n**W4:** We've conducted additional experiments within this context and intend to incorporate these findings into our paper.\n\n**W5:** Thank you for bringing up this point. We're enhancing our related works section by including further discussions on papers related to theorem provers beyond Lean.\n\n\n**Questions:**\n\n**Q1:** Yes, we plan to make the Model, Code, and DataSets available as open-source.\n\n**Q2:** Yes, we're enhancing our related works section by including further discussions on papers related to theorem provers beyond Lean.\n\n**Q3:** In every case, we set a time limit of 10 minutes.\n\n**Q4:** **1, 2.** We now have added some more plots discussing these aspects in the paper.\n\n**3.** In our experiments, dynamic sampling consistently either outperforms fixed sampling or performs equally well, never exhibiting inferior performance.\n\n**We will be submitting our updated paper soon. Thanks for your patience.**"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8049/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700310596517,
                "cdate": 1700310596517,
                "tmdate": 1700310596517,
                "mdate": 1700310596517,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "PI55OuYxec",
            "forum": "lxlMFlzZO9",
            "replyto": "lxlMFlzZO9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8049/Reviewer_X3v4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8049/Reviewer_X3v4"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces DS-Prover, a automated theorem proving framework in the Lean proof assistant. The main feature of this framework is that it dynamically determines the number of tactics to explore taking into account the remaining time resources. Performance gain has been demonstrated against the previous Fixed Sampling strategy in the LeanDojo paper."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The idea of taking time into the explore-exploit tradeoff is novel and of practical significance. I especially appreciate the authors' effort of pushing the boundary of low-budget neural theorem proving, which could be much more useful to daily ITP users."
                },
                "weaknesses": {
                    "value": "- The writing can still be improved. For example, the \\cite or \\citep should not be used interchangeably, and there should be a space before each inline citation. Also, some sentences can use some polishing, e.g., 'where anyone can put the formal statement in Lean for their mathematical theorem' on page 2.\n- Related prior work in tactic prediction in other systems (Coq, HOL4) should have been mentioned and compared. In particular, some considerations between atomic and compound tactics have been discussed in prior work in Coq (https://arxiv.org/abs/1905.09381, https://proverbot9001.ucsd.edu).\n- The claim of 'a new state-of-the-art performance of 30.6% on MiniF2F using Lean' is not entirely accurate, as the HyperTree Proof Search (HTPS) paper has already achieved over 40% success rate over the same dateset. I understand that your approach does not use reinforcement learning nor the same amount of computation resources as in the HTPS paper, but it might be better to make those assumptions clear and perhaps draw a more detailed comparison against HTPS."
                },
                "questions": {
                    "value": "- Table 1: one of the contributions of LeanDojo was to propose the novel_premises benchmark, which is believed to better reflect the generalization ability of the proof agent. Is is possible to have DS-Prover also run on it? \n- Discussions: would it be possible to have a length distribution comparisons between the generated proofs from Dynamic Sampling and Fixed Sampling models? Some qualitative examples to illustrate the differences between these two sampling methods would be highly appreciated."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8049/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698854274777,
            "cdate": 1698854274777,
            "tmdate": 1699636994244,
            "mdate": 1699636994244,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "z7klk5Ezxh",
                "forum": "lxlMFlzZO9",
                "replyto": "PI55OuYxec",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8049/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8049/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer X3v4"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the helpful feedback and will address the raised concerns below.\n\n**Weakness:**\n\n**W1**: Thanks for pointing this out we now have corrected the citations and also made other suggested changes in the paper.\n\n**W2:** Thanks for the suggestion, we will be adding the related works of theorem provers other than Lean in our paper.\n\n**W3:** Thank you for pointing this out. We acknowledge that our best performance is only for pass@1, as we did not conduct experiments for higher pass@k. We will correct our statement accordingly.\n\n\n**Questions:**\n\n**Q1:** Yes, we can run DS-Prover on the novel_premises benchmark. However, we wanted to assess the performance of our methods on a general dataset, not on a specifically prepared dataset that uses premises unseen by the model in its proof, hence we didn't consider running it on the novel_premises benchmark.\n\n**Q2:** Yes, we have compared the lengths of proofs in Dynamic Sampling and Fixed Sampling methods, and we will be including these comparisons in the paper.\n\n**We will be submitting our updated paper soon. Thanks for your patience.**"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8049/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700313406324,
                "cdate": 1700313406324,
                "tmdate": 1700313406324,
                "mdate": 1700313406324,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FVscxnZqYM",
                "forum": "lxlMFlzZO9",
                "replyto": "Kdx0B9HmhO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8049/Reviewer_X3v4"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8049/Reviewer_X3v4"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the responses"
                    },
                    "comment": {
                        "value": "I thank the authors' effort in responding to my queries as well as revising the paper. The two extra plots make sense -- I super appreciate them. Nevertheless, I still don't think the paper is of publishable quality at this stage -- more experiments could be used to demonstrate the effectiveness of dynamic sampling. Experiments of dynamic sampling on other tactic-style systems like Coq and HOL4 might be beneficial."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8049/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700604425851,
                "cdate": 1700604425851,
                "tmdate": 1700604425851,
                "mdate": 1700604425851,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]