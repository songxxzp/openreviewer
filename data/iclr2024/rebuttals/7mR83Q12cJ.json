[
    {
        "title": "Counterfactual Data Augmentation with Contrastive Learning"
    },
    {
        "review": {
            "id": "GtGlXpgPCB",
            "forum": "7mR83Q12cJ",
            "replyto": "7mR83Q12cJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6912/Reviewer_AQb9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6912/Reviewer_AQb9"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed a pre-processing step to Conditional Average Treatment Effects estimation. The proposed method first learn a representation space and use nearest neighbors within that space for counterfactual outcome imputation. The imputed data are used to augment the original data before piping the new data set into an existing CATE estimator."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The idea is easy to follow."
                },
                "weaknesses": {
                    "value": "There are many places where the presentations are either confusing or contradictory to one another.\n\nThere are errors in the proof."
                },
                "questions": {
                    "value": "1. On page 1, it stated that \"consider the following experiment: for individuals in the control group (and reciprocally, the treatment group), we randomly impute their outcome under treatment (or reciprocally, in the absence of treatment), generating their counterfactual outcomes. Subsequently, we integrate each individual along with their imputed outcomes back into the dataset. This transformation ensures that individuals from both the control and treatment groups become identical, effectively eliminating any disparities\". I do not agree that individuals from both groups are identical. It may be the case that the id numbers are the same, but since the missing outcomes are imputed based on some random algorithm, disparities may still exist. Disparities will only disappear when the missing outcomes are replaced by their corresponding true potential outcomes.\n\n2. On page 3, it stated that \"The counterfactual distribution, denoted by pCF, is defined as the sampling distribution of the dataset in a hypothetical parallel universe where the treatment assignment mechanism is inverted.\" I want to make sure that I understand it correctly that not only the treatment assignment is inverted for every individual, the observed outcome is also updated with the corresponding potential outcome under the new/inverted treatment assignment. If it's not the case, then pCF would be completed determined/induced by pF. Moreover, the proposed imputation procedure that estimates pCF also suggest that the outcome Y in pCF is different from those in pC.\n\n    2.0 With that being said, I wonder it is true that pC(y | x,t) = pCF(y | x,t)\n\n3. On page 4 above (5), it stated that \"Let \u2113 : {0, 1} \u00d7 {0, 1} \u2192 R\". Later, function g serves as the first arguement which has range [0,1] (the probability). Hence I wonder if it should be \u2113 : [0, 1] \u00d7 {0, 1} \u2192 R\n\n4. Solving equation (5) can have two challenges. First, the number of items involve in the objective is massive, since for N subjects there are N*(N-1)/2 pairs. Second, (5) may be viewed as a binary classification problem where each pair of subjects can be viewed as an instance whose label is 1 if the pair are close or 0 if the pair are not close. From this point of view, this binary classification problem will be highly imbalanced, since most pairs are not close to each other. The authors must discuss both the computational challenge and the issue of imbalancedness.\n\n5. Definition 5 stated that \"A factual distribution pF is consistent if for every hypothesis h : X \u00d7 {0, 1} \u2192 Y, LF(h) = LCF(h)\". \n\n    5.1 However, according to my understanding of pCF (see question 2 above), since pCF is not completely induced by pF, and since the computation of LCF(h) requires knowing pCF, I think this consistent property is not just a property of pF alone, but also a joint property of both pF and pCF.\n\n    5.2 Is there any intrinsic relation between consistency and the identity mentioned earlier: pCF(x, 1 \u2212 t) = pF(x, t) (Shalit et al.,\n2017; Peters et al., 2017)?\n\n    5.3 What is the relation between consistency and unconfoundness? Does unconfoundness imply consistency or consistency imply unconfoundness?\n\n6. Theorem 2 showed that for any given individual x, the likelihood of encountering neighboring data points is sufficiently high as the number of data points grows.\n\n    6.1 While this theorem guarantees reliable imputation of its counterfactual outcome, it does not establish the asymptotic consistency of\nCOCOA (which was claimed to be the case). It only says that COCOA can estimate the counterfactual distribution well, but for consistency you need to check Definition 5.\n\n    6.2 Theorem 2 is very trivial and the proof is very elementary. I would not call this a theorem.\n\n7. Theorem 3, equation (3). Since the pAF is the result of a random alogorithm, depending on the data, the generalization bound in (11) can only hold with a probability, at best.\n\n8. The definition of $b_{\\mathcal{A}}(n)$ in Theorem 3 seems to be a MSE, instead of bias, to me.\n\n9. On page 7, regarding the generalization bound, it did \"underscores that by simultaneously minimizing disparity and imputation error, we can enhance the performance of CATE estimation models.\" But I cannot see how this provides a rigorous illustration of the trade-off\nbetween the statistical disparity across treatment groups and the imputation error. To show a trade off you need to show how does one term increase at the cost of the decrease of another term.\n\n10. More on the bound, I cannot see why as bA(n) will converge to 0 as n increases, \u03b5PEHE will converge to 0. There are still two more terms in \u03b5PEHE preventing it from converging to 0.\n\n11. Table 1 in numerical studies: how to estimate \u03b5PEHE considering that the true HTE is unknown for real data sets?\n\n12. Page 8. T-Learner and S-Learner are just general terms for groups of methods, depending on different basic learners used. Which T-Learner and S-Learner exactly did you use?\n\n13. Page 14 in the proof, it stated that \"pF(X|T = 1) = pF(X|T =0). In other words, treatment assignment is independent of the potential outcomes.\" But there is no potential outcome in the identity pF(X|T = 1) = pF(X|T =0). Do you mean pF(X,Y|T = 1) = pF(X,Y|T =0)?\n\n14. Again, in Lemma 4, pF(X|T = 1) = pF(X|T = 0) does not characterize RCT. Moreover, RCT does not have to be 50-50 between treated and control, so we may not have pF(T = 1) = pF(T = 0)\n\n15. In the proof of Lemma 4, since you only assumed that pF(X|T = 1) = pF(X|T = 0) , how did you obtain the fourth equality?\n\n16. Again, since you only assumed that pF(X|T = 1) = pF(X|T = 0) , how did you obtain the second equality in the series of equations that started with $\\mathcal{L}_{CF}(h)$?\n\n17. At the end of the proof to Theorem 1, it stated \"Therefore we have proved that for all Borel-measurable functions \u03a6\". Unfortunately you have only proved the identity for one particular function \u03a6, not for all function. Therefore, the conclusion of Theorem 1 does not hold at all."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6912/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698686219253,
            "cdate": 1698686219253,
            "tmdate": 1699636804258,
            "mdate": 1699636804258,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LoVQJZ263f",
                "forum": "7mR83Q12cJ",
                "replyto": "GtGlXpgPCB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (Part 1)"
                    },
                    "comment": {
                        "value": "Dear Reviewer AQb9,\n\nThank you for your feedback. We appreciate your attention to detail and have carefully considered your comments. We updated our manuscript accordingly (see the corrected proof of theorem 1 in Appendix B). Please find below a detailed answer for the rest of the questions. \n\n___\n> Question: \u201cI do not agree that individuals from both groups are identical...\u201d \n___\n\nIn the context of causal inference, when referring to the distribution of the treatment group and the control group we intend the marginals of the features $p(X|T=1)$ and p(X|T=0), not $p(Y,X|T=1)$ and $p(Y,X|T=0)$. Our characterization is accurate in illustrating that if $p(X|T=0) = p(X|T=1)$, standard learning theory guarantees that good performance on  $p(X|T=1)$ implies a good performance on prediction $Y_1$ on $p(X|T=0)$ after learning the potential outcome $Y_1$ on $p(X|T=1)$.Thus, the challenge in estimating counterfactual outcomes well lies in the disparity between the treatment groups, specifically in their feature distribution.\n\n___\n> Question: \u201cOn page 3, it stated that \"The counterfactual distribution, denoted by pCF, is defined as the sampling distribution\u201d\n___\n\nBy inverting the treatment assignment mechanism we indeed change the structural equation relating the treatment variable T to the features X. Hence the factual outcomes will change. If the reviewer means by completely determined that there is a deterministic function between the observed factual outcome $Y = T Y1 + (1-T)Y0 $ and the counterfactual outcome random variable $Y_{CF} = (1-T) Y1 + T Y0$ then the answer is clearly yes. If he means that there is no information between both then the answer is clearly no.It is not true that $p_{F}(y|x,t) = p_{CF}(y|x,t) $ instead it is true that $p_{F}(y|x,1-t) = p_{CF}(y|x,t) $ (follows from the provided identities above). \n\n___\n>Question: :\u201dOn page 4 above (5), it stated that \"Let \u2113 : {0, 1} \u00d7 {0, 1} \u2192 R\". Later, function g serves as the first arguement which has range [0,1] (the probability). Hence I wonder if it should be \u2113 : [0, 1] \u00d7 {0, 1} \u2192 R\u201d\n___\n\nThank you for catching this typo, we will update the manuscript accordingly. \n\n___\n>Question: \u201cSolving equation (5) can have two challenges.\n___\n\nThe computational challenge and imbalance issue in solving equation (5) is indeed significant. While it is true that the number of pairs is increasing at a rate $\\frac{N*(N-1)}{2}$, we only need to select a subset of all possible pairs for the training. For the imbalanced problem, we only select a subset of individuals for which we perform well, that is why we don\u2019t augment every point in the dataset. Moreover, the regions where we have high overlap between the different treatment groups are the regions where we will do most of the imputation and these are the regions where there is the least imbalance between the different treatment groups. In practice, to overcome the imbalance problem, it is easy to sample a mini-batch with an equal number of positive and negative pairs during the learning of the contrastive learning module. \n\n\n___\n>Question:  think this consistent property is not just a property of pF alone, but also a joint property of both pF and pCF\n___\n\nThe mentioned identity $p_{CF}(x, 1 \u2212 t) = p_{F}(x, t) $ is always true for any binary treatment assignment while consistency only holds when the treatment assignment is independent of the features $X$. There is no direct relationship between unconfoundedness, a property about observing all the features that are causally affecting $T$ and $Y$, and consistency, as defined in Definition 5, a property that is equivalent to the factual and the counterfactual distribution being identical. As an example, we can imagine a scenario where the treatment is assigned by flipping a coin without knowing any of the patient's information. We know that unconfoundedness doesn\u2019t hold in this case (since the features are not observed) but consistency holds. Also, we can have a case where we observe all the features affecting T and Y but there is still a bias and unconfoundedness doesn\u2019t hold. Similarly, we can construct scenarios where they both hold and both don\u2019t. \n\n___\n>Question:  While this theorem guarantees reliable imputation of its counterfactual outcome, it does not establish the asymptotic consistency of COCOA (which was claimed to be the case). It only says that COCOA can estimate the counterfactual distribution well, but for consistency you need to check Definition 5. 6.2 Theorem 2 is very trivial and the proof is very elementary. I would not call this a theorem.\n___\n\nWe will label it as a proposition instead. While being easy to prove, it highlights the important point that the likelihood of encountering similar individuals under positivity is increasing, which is crucial for local imputation of missing outcomes. We will clarify this in the manuscript."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700293098596,
                "cdate": 1700293098596,
                "tmdate": 1700293121373,
                "mdate": 1700293121373,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "8JdbGCGY8R",
            "forum": "7mR83Q12cJ",
            "replyto": "7mR83Q12cJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6912/Reviewer_NLwi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6912/Reviewer_NLwi"
            ],
            "content": {
                "summary": {
                    "value": "The work proposes a heuristic data augmentation procedure for the estimation of Conditional Average Treatment Effects. The procedure first identifies a set of candidate samples and then generates augmented data by performing local approximation on the samples.  Due to insufficient theoretical understanding, it remains unclear why the method should work."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Using contrastive learning for data augmentation for CATE estimation is novel and interesting."
                },
                "weaknesses": {
                    "value": "1. There are no direct theoretical results regarding the learned representation $g_{\\theta}$, the augmented data $D_{AF}$, or the local approximations. The claim that the convergence guarantees for COCOA are provided is misleading. Theorem 2 is almost trivial under the positivity assumption. Theorem 3 is a simple corollary of Theorem 7 in Appendix. They provided very limited insights into how COCOA works. \n\n2. Ideally, there should be a principle way to decide $\\varepsilon$ for generating the positive and negative datasets and $K$ for the selection of the nearest neighbors. Otherwise, the method should be extensively evaluated. More synthetic data experiments with larger classes of data distributions will help to understand when the method works or fails. \n\n3. It could be challenging to provide finite-sample guarantees for the procedure. However, there should be experiments that examine how sensitive the method is with respect to small sample sizes."
                },
                "questions": {
                    "value": "The main weakness of the procedure is the lack of theoretical guarantees that truly reveal why and when the data augmentation helps. I think the idea is promising, but additional exploration of the theoretical understanding is needed."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6912/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6912/Reviewer_NLwi",
                        "ICLR.cc/2024/Conference/Submission6912/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6912/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698824274823,
            "cdate": 1698824274823,
            "tmdate": 1700369329519,
            "mdate": 1700369329519,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "K1tzffhRIp",
                "forum": "7mR83Q12cJ",
                "replyto": "8JdbGCGY8R",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Dear Reviewer NLwi,\n\nThank you for your feedback. \n\n1. Theoretical Results Significance: We respectfully disagree with the reviewer, the provided theoretical analysis establishes a foundation for understanding data augmentation methods in causal inference. Mainly Theorem 3, postulates that the error in estimating treatment effects is bounded by the loss on the training augmented data, the distance between the **features** distribution in the augmented data and that of a Randomized Controlled Trial, and the average error for the local approximator. It is important to note that the first term is guaranteed to converge to $0$ by standard learning theory, the second term is guaranteed to converge to 0 as soon as we select all the individuals to impute their outcomes, and the third term depends on the quality of imputation but is also guaranteed to converge to 0 as the number of data points increase. This being said we agree with the reviewer that further investigation of using contrastive learning to identify smooth local regions for local approximation is an open research question that requires a more theoretical understanding of contrastive learning in general. We will be happy if the reviewers can point us to good theoretical works for contrastive learning that will help us in this research direction. We will also change the wording in our updated manuscript to make the limitations of our preliminary theoretical analysis clearer. \n\n2. Hyperparameters $\\epsilon$ and $K$: We agree with the reviewer that these hyperparameters are very important for the efficacy of the method, which is why we conducted **extensive ablation studies** on them presented in the main text and in Appendix C.3. We conducted our experiments in benchmark causal inference datasets (IHDP, Twins, and News) as well two synthetic datasets (a Linear and Nonlinear dataset). Our experimental results suggest that our method is robust to a wide range of choices of hyper-parameters: it is not challenging to find a set of hyper-parameters that consistently improve the performance. This being said, we believe developing principal ways to tune these hyperparameters (as well as other widely used hyperparameters in Machine Learning in general and causal inference in particular) is a very important research direction that is beyond the scope of the current presentation.\n\n3. Sample Size Effect: Semi-synthetic datasets such as IHDP already have a limited number of individuals, and reducing the dataset size further complicates the learning process, particularly for data augmentation methods. As the dataset shrinks, finding close neighbors becomes increasingly challenging. Consequently, when the number of data points is very small, the method may struggle to identify suitable neighbors, potentially leading to no data points being selected for data augmentation. However, we would like to note that compared to other methods, our algorithm will not perform any data augmentation in this case. This is one of the key properties of our algorithm that it only imputes with high confidence, thus never worsening the problem.\n\nWe thank the reviewer again for his feedback and we will be happy to answer any further questions."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700292590965,
                "cdate": 1700292590965,
                "tmdate": 1700292590965,
                "mdate": 1700292590965,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KtmpXHxwe1",
                "forum": "7mR83Q12cJ",
                "replyto": "K1tzffhRIp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6912/Reviewer_NLwi"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6912/Reviewer_NLwi"
                ],
                "content": {
                    "comment": {
                        "value": "Let me clarify the concern regarding the lack of theoretical guarantees in this work. Intuitively, generating more samples at places where the samples are dense does not necessarily make the empirical distribution of the samples closer to the true distribution. There are many settings where this data augmentation strategy may fail. For instance, when the dimension of $X$ is relatively high, there could many sparse regions. Only generating samples for dense regions will lead to poor estimations. The authors should provide theoretical justification for this data augmentation strategy. This will help the readers see when the proposed method is applicable. Otherwise, if there is a rich literature on this strategy, please use it to support your work. \n\nThe contrastive learning method is simple, I do not think theoretical guarantees have to be provided. \n\nI am pleased with the response to my other questions. Based on the response, I adjust my score, but I keep my decision."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700369313961,
                "cdate": 1700369313961,
                "tmdate": 1700369313961,
                "mdate": 1700369313961,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "K19HTBijtU",
            "forum": "7mR83Q12cJ",
            "replyto": "7mR83Q12cJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6912/Reviewer_Lde6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6912/Reviewer_Lde6"
            ],
            "content": {
                "summary": {
                    "value": "A data augmentation technique to improve accuracy of causal effect estimation. A method is proposed to augment units with their estimated potential outcomes. Such an augmentation can help any downstream effect estimator by increasing overlap."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Good idea on using data augmentation based on a learnt representation.\n- Can apply to all dowstream methods\n- An attempt to characterize theoretical bounds of the method"
                },
                "weaknesses": {
                    "value": "- The main technique is to apply contrastive learning. However, the loss does not align with the causal effect problem. Ideally, we would like the individuals with the same causal effect to be close to each other. But the proposed method constraints individuals with the same outcome (under same treatment) to be close to each other. I understand that the former is not identified from observed data, but stating this distinction is important. As a result, I do not see a conceptual justification on why the proposed method will work well. It is easy to generate a counter-example. E.g., consider a dataset where treatment only affects young people, but not old people. Assume outcome values are as follows: \nYoung: (T=0, Y=0), (T=1, Y=10)\nOld: (T=0, Y=0), (T=1, Y=0)\nNow the proposed algorithm will move untreated young and old people together. For T=1, it will also have young and old people as negative examples. The net result will be that the feature \"age\" in the representation will be significantly weakened. \n\n-  The theory is obfuscating the real issue. While the theory provides bounds based on quality of augmented data, the key concern is the quality of data generated by proposed algorithm (and whether it is likely to be close to the randomized distribution). So the theory does not provide any more confidence in the method's soundness--it could have been written for any data augmentation method.\n\n- I would suggest that the authors compare to more state-of-the-art methods, such as ReiszNet. https://arxiv.org/abs/2110.03031 Would the stated gains be still significant?\n\nFinally, it may be useful to connect to existing literature on data augmentation and matching in causal ML. Some references:\n1. https://icml.cc/virtual/2021/spotlight/8888 selecting data augmentation for simulating intervention \n2. http://proceedings.mlr.press/v139/mahajan21b.html"
                },
                "questions": {
                    "value": "- Justify the contrastive loss.\n- Can you compare to ReiszNet?\n- The selection criterion uses g(xi,xj)=1. Can the similarity be exactly one, or do you use a threshold in practice?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6912/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698907391709,
            "cdate": 1698907391709,
            "tmdate": 1699636804006,
            "mdate": 1699636804006,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4CsNss0VFY",
                "forum": "7mR83Q12cJ",
                "replyto": "K19HTBijtU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Dear Reviewer Lde6,\n\nThank you for your constructive feedback and for the relevant resources you shared with us. We will include them in our revised related work section. \n\n1. The contrastive loss: Contrastive Learning is used as a heuristic (proven to be effective in various applications) to identify similar individuals **within the same treatment group**. To clarify the potential misunderstanding, as in the provided example the pair $\\{X = \\text{\u201cyoung\u201d}, T=0, Y=0\\}$ and $\\{X = \\text{\u201cold\u201d}, T=0, Y=0\\}$ will be in the positive dataset. And the pair $\\{X = \\text{\u201cyoung\u201d}, T=1, Y=10\\}$ and $\\{X = \\text{\u201cold\u201d}, T=1, Y=0\\}$ will be in the negative dataset. In this case, no data augmentation will happen. This is indeed the key to the success of our algorithm: it does not impute unreliable outcomes. Assuming that we have more points. Therefore if we get individual $a=\\{X = \\text{\u201cold\u201d}, T=1, Y=0\\}$ (Y value is hidden from us), we can test that it will be similar to the individuals $b=\\{X = \\text{\u201cold\u201d}, T=0, Y=0\\}$ and we can hence impute his outcome and have $Y \\approx 0$ (a has the same $X$ value as $b$ hence $b$ is a close neighbor of $a$, and we use $b$\u2019s factual outcome as the imputation results for $a$).\n\n2. The place of the theory: The proposed theoretical analysis applies to general data augmentation in causal inference. While local approximators are guaranteed to converge (there has been a considerate amount of work that studies the statistical consistency of local approximation methods as in [1], hence we believe it is unnecessary to repeat these results in this work), the contrastive learning part is a heuristic that we use to identify similar individuals. The other natural choice is using Euclidean distance but that doesn\u2019t generalize well for high dimensional data. We will add a remark to our revised manuscript outlining this. \n\n3. Comparison to ReiszNet: To the best of our understanding the provided reference builds a method to estimate the average treatment effect (ATE). Our proposed method is mainly built to estimate the conditional average treatment effect (CATE) at an individual level. Hence, we fail to see a direct way of applying Reisznet to CATE estimation. We would appreciate it if the reviewer could share advice on how to adapt ReiszNet to CATE estimation. This being said, we will include this method for completeness in the related work when discussing ATE estimation methods.\n\n4. Selection Criteria: Yes we use the same threshold $\\epsilon$ in practice, hence if $\\|g(x_i,x_j)\\|\\leq \\epsilon$ we classify the individuals as similar otherwise we classify them as non-similar. We will add this detail to the algorithm section for enhanced clarity. \n\nThank you again for your constructive feedback.\n\n[1] Tj\u00f8stheim, D., Otneim, H. and St\u00f8ve, B., 2021. Statistical Modeling Using Local Gaussian Approximation. Academic Press."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700292357018,
                "cdate": 1700292357018,
                "tmdate": 1700427121626,
                "mdate": 1700427121626,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rQAsmqTMIk",
            "forum": "7mR83Q12cJ",
            "replyto": "7mR83Q12cJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6912/Reviewer_FUqM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6912/Reviewer_FUqM"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a framework named COCOA which aims to estimate the conditional average treatment effects (CATE) by imputing the counterfactual outcomes for a subset of the subjects. The subset to be imputed is selected by learning a representation space and a similarity measure with the assumption that in the learned representation space close individuals identified by the learned similarity measure have similar potential outcomes. Theoretical analysis is performed and empirical experiments show improved performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is overall well-written and the development of the main ideas is easy to follow.\n- The idea of performing counterfactual outcome imputation over a subset of individuals guided by a learned latent space is quite interesting and seems novel.\n- Although the contrastive learning algorithm used in this paper is not new, its use in the overall learning framework is reasonable.\n- The proposed method is model-agnostic, making it possible to be plugged in for any CATE estimation model, including the potentially better ones to be developed in the future.\n- The paper theoretically builds the generalization bound and provides insights into the theoretical development.\n- Empirical evaluation shows significant improvement by combining the proposed augmentation method with the existing CATE estimation methods."
                },
                "weaknesses": {
                    "value": "- No analysis of the computational complexity is provided. It is known how the proposed method scales with large datasets.\n- The pairs of similar individuals are defined as individuals having a difference of outcomes less or equal to a threshold. When applied to data with binary outcomes (e.g., product purchase or not), the positive dataset $D^+$ will potentially contain too many individuals. It is unclear if this will have a negative impact on the proposed method and how this can be further addressed.\n- Definition 4 defines a factual loss and a counterfactual loss, which takes the integral over time, implying that a continuous-time loss/model is used. However, the exact form of the loss function used in later sections (except the theoretical analysis) seem to imply the opposite. It would be great to clarify how and why Definition 4 is used."
                },
                "questions": {
                    "value": "- What is the computational complexity of the proposed method?\n- Can the method apply to datasets with binary outcomes? How to reduce the size of $D^+$ in this case?\n- How and why is Definition 4 used in the learning procedures?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6912/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699205370077,
            "cdate": 1699205370077,
            "tmdate": 1699636803874,
            "mdate": 1699636803874,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MGiHImqD63",
                "forum": "7mR83Q12cJ",
                "replyto": "rQAsmqTMIk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Dear Reviewer FUqm,\n\nThank you for your valuable feedback. \n\n1. Computational Complexity: The computational complexity of identifying the similar and the non-similar individuals is $\\frac{N^2}{2}$ in the worst-case scenario. The complexity of the rest of the learning algorithm is on par with that of the other modules. For very large datasets, we can select a subset of the possible similar and non-similar pairs. In practice, when the pairs of positive samples are moderate, we can select only a small set of negative samples for every gradient update of the contrastive learning module. Please note that when the dataset contains lots of pairs of similar individuals, data augmentation is not needed as performance is guaranteed by our error bound (simply setting $\\alpha = 0$).\n\n2. Binary Outcomes: Since we assume that the functions are locally smooth and can be approximated locally by a linear model or a Gaussian Process, the method currently does not generalize well to classification tasks. We will incorporate this clarification in our revised manuscript.\n\n3. Definition 4:  Definition 4 establishes the counterfactual and factual losses, which are crucial in the proposed theoretical analysis in Section 4. Please note that $t$ in the definition is the treatment assignment (that is discrete in our case). This analysis introduces a notion of consistency for data augmentation in causal inference. \n\nWe hope these clarifications address your concerns and reinforce the value of our work. Thank you once again for your insightful comments."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700291304723,
                "cdate": 1700291304723,
                "tmdate": 1700291304723,
                "mdate": 1700291304723,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]