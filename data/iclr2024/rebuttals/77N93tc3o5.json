[
    {
        "title": "Deep Independent Vector Analysis"
    },
    {
        "review": {
            "id": "okWxTH16ap",
            "forum": "77N93tc3o5",
            "replyto": "77N93tc3o5",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8343/Reviewer_FDhN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8343/Reviewer_FDhN"
            ],
            "content": {
                "summary": {
                    "value": "Authors propose DeepIVA, an approach for identifying non-linearly mixed sources across different datasets (modalities). DeepIVA combined the iVAE approach with the MISA algorithm, by utilizing a two-step training procedure. Authors propose a set of extended metrics to evaluate their proposed model against the iVAE and MISA baselines, and show that their approach achieves satisfying results in both the uni- and cross-modal settings, whereas the baselines perform well only in either of these. Furthermore experiments on fMRI data from UK Biobank are performed as an example of a real-life application."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed method performs well both in terms of cross-modal source identification, as well as in the unimodal setting - although for a higher number of segments iVAE is still better in the unimodal one\n- Authors developed novel metric formulations for the cross modal setup, and described them in a clear manner\n- The experimental setup is clearly described in the main text, along with all hyperparameter values"
                },
                "weaknesses": {
                    "value": "I am missing a more theoretically grounded justification for why the approach of combining MISA and iVAE would yield an identifiable solution in the cross-modal setting (especially with the alternating two-step training procedure, see Question 2). So far the approach seems like stitching existing methods together without further introspection. Pointing out to at least a sketch of a proof, e.g., in the appendix would be desirable."
                },
                "questions": {
                    "value": "- While interesting, it is hard to interpret the soundness of the MRI results. UK Biobank contains a wide range of brain MRI-derived variables, e.g., volumetrical informations of different brain regions of interest (ROIs). Did the authors consider incorporating these into the analysis - perhaps as a proxy for ground-truth sources, since the underlying ROI volumes stay the same regardless of MRI type?\n- Maybe I am missing something, but why does DeepIVA have to be trained with a two-step procedure? Since iVAE is identifiable, can\u2019t we first train each separate modality-specific VAE and then align the sources using MISA?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8343/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698416678728,
            "cdate": 1698416678728,
            "tmdate": 1699637037695,
            "mdate": 1699637037695,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Vzm8R501hn",
                "forum": "77N93tc3o5",
                "replyto": "okWxTH16ap",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8343/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8343/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "1. Thank you for the suggestion on the sketch of proof. We have restated key assumptions and Theorems in the identifiability theory (Khemakhem et al. 2020), and provided a conceptual sketch of proof showing that the generative model assumed in DeepIVA is identifiable up to a permutation and component-wise transformation in Appendix A. We have also updated Section 2.1 iVAE and DeepIVA parts accordingly in the revised manuscript. \n\n2. We are not clear about what the reviewer is suggesting we could do with the ROIs specifically. We aim to identify latent sources in a data-driven manner, and it is not necessary that linked sources are located at similar brain regions. Thus, a predefined ROI atlas might not be ideal as a proxy for ground-truth sources. Also, ROIs are not always the same for all types of MRI (for example, white matter tracts vs gray matter ROIs). While not seemingly a good depiction of the ground-truth, ROI-based data may be a good alternative to dimensionality reduction. We will consider that in future experiments.\n\n3. Thank you for the thoughtful question. We train DeepIVA in a two-step procedure because of computational efficiency and practical consideration. If we train iVAE and then use MISA to align unimodal sources, it will require solving a combinatorial problem, which can be computationally expensive as the number of sources and datasets scale up. Additionally, if we first train iVAE independently, it is possible that parameters of one iVAE model might be stuck in local minima and the learned sources might not be linked. For example, in Figure 2 first row, we trained two iVAE models independently, and each model can identify sources fairly well, but cross-modal alignment is poor between two sets of independently identified sources. Iteratively training iVAE and MISA can guide the model to a solution not only maximizing for identifiability but also simultaneously maximizing for linkage."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8343/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700510353300,
                "cdate": 1700510353300,
                "tmdate": 1700510353300,
                "mdate": 1700510353300,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "91l8tYyWze",
                "forum": "77N93tc3o5",
                "replyto": "Vzm8R501hn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8343/Reviewer_FDhN"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8343/Reviewer_FDhN"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response. I will retain my score, as the method is rather incremental at this point."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8343/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700667525866,
                "cdate": 1700667525866,
                "tmdate": 1700667525866,
                "mdate": 1700667525866,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "XAqCApHNQs",
            "forum": "77N93tc3o5",
            "replyto": "77N93tc3o5",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8343/Reviewer_queK"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8343/Reviewer_queK"
            ],
            "content": {
                "summary": {
                    "value": "The paper suggests a combination of identifiable variational autoencoders (iVAEs) and multidataset independent subspace analysis (MISA). The approach iteratively (i) maximizes the iVAE EVBO separately for each modality; and (ii) minimizes the KL divergence between the joint conditional prior distribution of the latents and their marginal product. Experiments on synthetic data and neuroimaging data illustrate that the approach improves the latent identifiability and cross-modal linkages, compared to iVAE and MISA."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The idea of combining iVAE and MISA is new as far as I am aware. Using MISA to align the latent representation seems quite interesting and could be a promising alternative for example to self-supervised learning approaches such as [1,2]. The approach might be in particular useful (compared e.g. with contrastive approaches) for M>2 modalities. However, this has not been explored in the current experiments. \n\nNumerical experiments on simulated data and a neuroimaging data show improvements for the inferred representations according to the considered evaluation measures, when compared with iVAE and MISA. The paper is largely well written and easy to follow.\n\n[1] Lyu, Qi, et al. \"Understanding Latent Correlation-Based Multiview Learning and Self-Supervision: An Identifiability Perspective.\" International Conference on Learning Representations. 2021.\n[2] Daunhawer, Imant, et al. \"Identifiability results for multimodal contrastive learning.\" arXiv preprint arXiv:2303.09166 (2023)."
                },
                "weaknesses": {
                    "value": "The submission claims to learn identifiable representation. However, I could not find a proof of it. It has also not been defined what this identifiability means in the multi-modal context. In particular, what are the equivalence classes? What are the necessary conditions required for identifiability? Does the availability of multiple datasets/modalities lead to less restrictive conditions? Do the conditions hold in practice? \n\nLikewise, the submission claims to learn disentangled representations. I could not find a proof of this either. Is it obvious that iterating between training steps 1 and 2 yields a disentangled representation at convergence?\n\nIt is not clear to me how scalable the method is as it requires computing the log-determinant of the encoder Jacobian.\n\nIt is not clear to me how the MISA steps affects other generative performances that look not just at the latent variables of the model. For example, does it lead to worse LLH (or lower bounds thereof), FID score etc. compared to iVAE?"
                },
                "questions": {
                    "value": "To clarify, the iVAE models in the experiments mean training individual iVAEs for each modality and then learning a rotation matrix to align the latents (as done for the MCC evaluation under weak identifiability)?\n\nHow does the approach compare to a single iVAE model on the modality-concatenated data? This would learn shared/perfectly aligned sources.\n\nCan you clarify how you have modified the encoder architecture to make sure for example that \u2018MISA updates only the model weights pertaining to the input features but not the auxiliary variables\u2019? Does this exclude any interaction between input features and auxiliary variables?\n\nIn 2.2, is it possible to generalise the seemingly very restrictive assumption that the data is independent within each modality?\n\nCan you clarify what is the advantage of the introduced MC measure compared to the MCC measure that is often also based on RDC?\n\nDo MISA and iVAE latent representations also lead to similar clusters of age or sex phenotpyes? Does the multimodal dimensionality reduction in the pre-processing step impact the identifiability?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8343/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698633648250,
            "cdate": 1698633648250,
            "tmdate": 1699637037579,
            "mdate": 1699637037579,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wTRr8EeljY",
                "forum": "77N93tc3o5",
                "replyto": "XAqCApHNQs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8343/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8343/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors (1/2)"
                    },
                    "comment": {
                        "value": "We appreciate that the reviewer acknowledged the strengths of our work and include our point-to-point response as follows. \n\n1. Identifiable representation. We have restated key assumptions and Theorems in the identifiability theory (Khemakhem et al. 2020), and provided a conceptual sketch of the proof showing that the generative model assumed in DeepIVA is identifiable up to a permutation and component-wise transformation in Appendix A. We have also updated Section 2.1 iVAE and DeepIVA parts accordingly in the revised manuscript.\n\n2. Disentangled representation. We have updated \u201cdisentangled representations\u201d to \u201clatent sources\u201d.\n\n3. Scalability. Note that we utilize an approximate Jacobian by taking the average across all samples for subsequent computation (i.e. eigendecomposition), instead of using the Jacobian of each sample. Such an approximation leads to similar results while also providing computational efficiency gains. Moreover, we can compute the Jacobian for all modalities in parallel. Lastly, the identifiability theory of iVAE extends trivially to flow models (as discussed in Khemakhem et al. 2020), which have simple Jacobian form and could enable better scalability. \n\n4. Generative performance. The iVAE loss from DeepIVA is typically not lower (better) than the vanilla iVAE loss after training for the same number of epochs, but this issue can be potentially mitigated by training the iVAEs alone following alignment at the last step of DeepIVA. Once aligned, it is likely that iVAE training would stay at the same local basin and keep the source permutation unchanged. Yet another solution is to update only the decoder weights for iVAE training while training the MISA loss on the encoder weights. This would help compensate for any negative effects of MISA on reconstruction. \n\n5. Yes, the reviewer\u2019s understanding is mostly correct, except that we did not apply a rotation matrix on the iVAE recovered sources (the synthetic dataset meets the conditions for P-identifiability within each modality) when we plotted the RDC matrices, such as Figure 2. Instead, we merely applied the same permutation matrix to all modalities such that high MCC values were along the main diagonal when we computed per-segment per-modality MCC. \n\n6. Thank you for the thoughtful question. Let each dataset be a $N \\times V$ matrix where $N$ is the number of samples and $V$ is the number of features. There are two ways to concatenate data: One is to concatenate data along the sample dimension (as in joint ICA, learning a shared transformation $f$ for both modalities and different latents for each modality) and the other is to concatenate data along the feature dimension (as in group ICA, learning shared latents and a single transformation $f$ that mixes all modalities indistinctly from one another). Either way, we learn a shared nonlinear transformation across datasets. If datasets were generated from a shared latent variable, it might be reasonable to use one of these two approaches. However, we are interested in studying different heterogeneous data modalities generated from modality-specific, non-shared conditionally independent latent variables and modality-specific nonlinear mixing processes. Thus, it makes more sense to estimate sources for each dataset separately, as in IVA, utilizing iVAE to obtain identifiability and  MISA to capture linkage. \n\n7. Sorry for the lack of clarification. Yes, our modification excludes the interaction between input features and auxiliary variables. We have updated Figure 1 and revised the related text in Section 2.1: \u201cAdditionally, since MISA is not designed to handle auxiliary information, we modify the original encoder architecture to distinguish between data features $\\mathbf{x}^{m}$ and auxiliary variables $\\mathbf{u}$ such that 1) the iVAE updates model parameters with respect to both $\\mathbf{x}^{m}$ and $\\mathbf{u}$ at the input layer, and 2) the MISA updates only those pertaining to $\\mathbf{x}^{m}$ but not $\\mathbf{u}$. The original iVAE model uses a single input layer taking the concatenated $\\mathbf{x}^{m}$ and $\\mathbf{u}$. In DeepIVA, we split this layer into two: one for data features $\\mathbf{x}^{m}$ and another for auxiliary variables $\\mathbf{u}$. The parameters with respect to $\\mathbf{u}$ will only be updated at the iVAE training step but will remain frozen at the MISA training step. Also, the inputs for the auxiliary variables are set to $0$ during MISA training to ensure no influence from the frozen weights.\u201d"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8343/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700509876170,
                "cdate": 1700509876170,
                "tmdate": 1700509876170,
                "mdate": 1700509876170,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QNsNPU18M8",
                "forum": "77N93tc3o5",
                "replyto": "4RyHnXbiZq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8343/Reviewer_queK"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8343/Reviewer_queK"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response and updating the submission. The response has addressed some of my questions and concerns. I appreciate that the authors have added Appendix A that makes the proposed theoretical claims clearer, although it has not become fully clear to me how the presented proof translates to the actually implemented method (via alternating between two losses, using gradients; do the stated conditions apply)."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8343/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700708091629,
                "cdate": 1700708091629,
                "tmdate": 1700708091629,
                "mdate": 1700708091629,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "MHwxHCeC7j",
            "forum": "77N93tc3o5",
            "replyto": "77N93tc3o5",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8343/Reviewer_dLxh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8343/Reviewer_dLxh"
            ],
            "content": {
                "summary": {
                    "value": "This work discusses a nonlinear extension of independent vector analysis (Kim et al., 2006) termed DeepIVA. The authors argue, based on (Abrol et al., 2021), that DeepIVA may be useful in neuroimaging applications. Synthetic experiments, as well as experiments on neuroimaging datasets, are presented."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The authors introduce a nonlinear representation learning method which may be applicable to neuroimaging datasets, building on previous works on linear and nonlinear ICA."
                },
                "weaknesses": {
                    "value": "1. The generative model assumed in the DeepIVA framework is never explicitly written in the paper. \nThis critical flaw not only diminishes the clarity of the presentation, but also greatly hinders the ability to assess the rigour and soundness of several claims in the paper, particularly regarding identifiability (see point below).\n\n2. The paper lacks a proper identifiability result. \nModeling assumptions and assumptions for identifiability are never properly stated. My understanding is that the paper assumes that identifiability for DeepIVA follows trivially from previous works (e.g., iVAE). \nThis is, in my view, unclear, or misleading, see Questions. \n\n(Note that, in principle, solid empirical work which does not prove identifiability results may nonetheless be relevant and worthwhile. \nHowever, identifiability is referred to multiple times in the paper, in a way which may be deceptive if compared to other works in the nonlinear ICA literature.) \n\n3. There is insufficient discussion of related literature on multi-view ICA, both linear and nonlinear, and its applications to neuroimaging, see Questions.\n\n4. In Fig. 5, the reported MCC of (a maximum of roughly) 0.7 seems rather low compared to results reported in other nonlinear ICA works for identifiable models.\n\n\n__________\n\n**Edit:** After discussion with the authors, I raised my evaluation to a 5."
                },
                "questions": {
                    "value": "1. The first question would be to explicitly write down the full generative model. If the work is intended to claim identifiability for this model, a Theorem proving under which assumptions said generative model is identifiable should be provided.\n\n2. In the manuscript, it sounds like identifiability should follow trivially from previous works, such as the iVAE framework (Khemakhem et al., 2020). Even if this were the case, it would be helpful to restate and discuss the required assumptions.\nMoreover, I find it hard to understand how to apply the results in (Khemakhem et al., 2020) in the context of this work. In particular, the results in (Khemakhem et al., 2020) lead to a specific kind of identification of the latent components, which is not up to permutation and element-wise nonlinear transformations: in fact, an additional linear indeterminacy remains (note also that the results refer to identifiability of sufficient statistics). It is unclear to me why the MISA network should be the right model to undo those transformations which may be unresolved in reconstructed components (with respect to the true ones), and to match components across datasets; and on what basis identifiability of the resulting two-step procedure would be guaranteed. \n\n2. What is the relationship of the model proposed in this paper with previous literature on multi-view ICA, both linear [1, 2, 3] and nonlinear [4]?\nMy understanding is that multi-view ICA models the dependence of (in this paper's notation) the components of $\\mathbf{s}_i$ differently---e.g., [1], eq. (1), in the linear case; or [4], eqs. (5-7) and Definition 2, in the nonlinear case. \nCrucially, in the nonlinear case [4], Def. 2 introduces a technical assumption which rules out trivial cases and constitutes one of the required \nassumptions for identifiability. I am confused by the lack of discussion of analogous assumptions in this work. Note also that multi-view nonlinear ICA [4] allows for identifiability in the absence of an additional auxiliary variable besides the collection of views, something the authors refer to in the Limitations section of the present paper.\n\n4. I found the description of the neuroimaging data lacking. Could you please describe the dataset used in the experiments, and relate them to the DeepIVA model? What aspect of the neuroimaging data used in the experiments is supposed to be modelled with a statistical dependence across datasets/subjects (i.e., among components of $\\mathbf{s}_i$)? \nMoreover, is it task-based neuroimaging data, or resting state? If task-based, how does the proposed method compare to [1, 2] or [5]? If not (resting state), how is the statistical dependence among components of the $\\mathbf{s}_i$ vector to be interpreted?\n\n5. How would you explain the results in Fig. 5? Why is the MCC so low?\n\nReferences:\n\n[1] Richard, Hugo, et al. \"Modeling shared responses in neuroimaging studies through multiview ICA.\" Advances in Neural Information Processing Systems 33 (2020): 19149-19162.\n\n[2] Richard, Hugo, et al. \"Shared independent component analysis for multi-subject neuroimaging.\" Advances in Neural Information Processing Systems 34 (2021): 29962-29971.\n\n[3] Pandeva, Teodora, and Patrick Forr\u00e9. \"Multi-view independent component analysis with shared and individual sources.\" Uncertainty in Artificial Intelligence. PMLR, 2023.\n\n[4] Gresele, Luigi, et al. \"The Incomplete Rosetta Stone problem: Identifiability results for Multi-view Nonlinear ICA.\" Uncertainty in Artificial Intelligence. PMLR, 2020.\n\n[5] Chen, Po-Hsuan Cameron, et al. \"A reduced-dimension fMRI shared response model.\" Advances in neural information processing systems 28 (2015)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8343/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8343/Reviewer_dLxh",
                        "ICLR.cc/2024/Conference/Submission8343/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8343/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698773124906,
            "cdate": 1698773124906,
            "tmdate": 1700731882969,
            "mdate": 1700731882969,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FNRDQ3R7jQ",
                "forum": "77N93tc3o5",
                "replyto": "MHwxHCeC7j",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8343/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8343/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors (1/2)"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer\u2019s insightful and constructive feedback. We include our point-to-point response as follows.\n\n1. Thank you for the important suggestion. We have explicitly written the generative model assumed in DeepIVA, and provided a sketch of the conceptual proof showing that the generative model is identifiable up to a permutation and component-wise transformation in Appendix A. We have also updated Section 2.1 iVAE and DeepIVA parts accordingly in the revised manuscript. \n\n2. Thank you for pointing out the multi-view ICA literature. Multi-view ICA assumes that the data can be modeled as a linear transformation of a common/shared source with an additive Gaussian noise. This assumption holds if all datasets are generated from a single shared latent variable, such as naturalistic datasets where subjects might share a similar temporal response. However, it doesn\u2019t hold if each dataset is generated from a separate multidimensional latent variable, such as the expression level of structural and functional imaging features across subjects. The key assumption difference between multi-view ICA and DeepIVA is that sources are $\\textbf{shared}$ across subjects in multi-view ICA while sources are $\\textbf{linked}$ across data modalities in DeepIVA. In the context of multimodal fusion, it is more reasonable to assume that each data modality is generated by modality-specific latent variables, instead of a shared latent variable, especially for data modalities that are inherently heterogeneous (such as imaging and genomics). Thus, we believe that DeepIVA is more capable in multimodal fusion tasks, as it aims to identify a set of linked sources for each modality.\n\nWe have added a discussion to distinguish our approach and multi-view ICA in Section 1 Introduction: \u201cRecent studies on multi-view BSS assume that observations from different views originate from a shared source variable and distinct additive noise variables (Richard et al., 2020; 2021; Pandeva & Forre, 2023; Gresele et al., 2020). However, in the context of multimodal fusion, it is more reasonable to assume that each modality is generated by modality-specific latent variables which, in turn, are linked across modalities, rather than a shared set, especially for data modalities that are inherently heterogeneous.\u201d\n\n3. Sorry for the lack of details about the neuroimaging dataset. We use structural MRI data (gray matter segmentation maps from T1-weighted images) and the voxel-wise amplitude of low frequency fluctuations (ALFF) from a resting-state fMRI dataset collected on the same subjects. The statistical dependence between modalities is modeled using subject expression levels. While we assume expression levels change (i.e., are nonstationary) according to age and sex groups, we assume the statistical dependence between data modalities remains the same and, thus, can be interpreted as structural and functional relationships associated with each latent source. \n\nWe have revised Section 2.3 Neuroimaging Data: \u201cWe utilize the UK Biobank dataset (Miller et al., 2016) $\\mathbf{X}\\in \\mathbb{R}^{N \\times V \\times M}$ including two imaging modalities T1-weighted sMRI and resting-state fMRI ($M=2$) from $2907$ subjects ($N=2907$). We preprocess sMRI and fMRI to obtain the gray matter tissue probability segmentation (GM) and amplitude of low frequency fluctuations (ALFF) feature maps, respectively. Each GM or ALFF feature map includes $44318$ voxels ($V=44318$). Here, we use age and sex groups as auxiliary information, assuming that sources within each modality are conditionally independent given the age and sex group. This assumption is based on studies demonstrating the significant impact of age and sex on both brain structure and function (Raz et al., 2004; Good et al., 2001; Ruigrok et al., 2014).\u201d"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8343/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700509186843,
                "cdate": 1700509186843,
                "tmdate": 1700509459056,
                "mdate": 1700509459056,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LobPPDFLNr",
                "forum": "77N93tc3o5",
                "replyto": "MHwxHCeC7j",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8343/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8343/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors (2/2)"
                    },
                    "comment": {
                        "value": "4. Regarding the MCC results, please first note that the per-modality per-segment MCC metric evaluates the MCC in the same way as in the nonlinear ICA literature, and these per-modality per-segment MCC values for 5 sources (>0.9) are very close to those reported in Khemakhem et al. 2020. Furthermore, in order to account for cross-modal linkage and cross-segment consistency, we propose a new approach to measure the MCC values (see Section 2.4 for details), and the proposed per-modality MCC, per-segment MCC and aggregated MCC metrics may be lower because the iVAE fails to align linked sources across modalities or consistent sources across segments. \n\nMCC values are lower when we estimate more latent sources (15 sources) with the same sample size (2800 samples). Our hypothesis is that the sample size was not sufficient to accurately recover more latent sources. We repeated the experiments with a double sample size (5600 samples) and an intermediate problem scale (10 sources). According to the new result, we observe that 1) model performance decreases as the number of sources increases when the sample size stays the same; 2) DeepIVA performance improves as the sample size increases when the number of sources stays the same. \n\nPlease see Figure 4 and Section 3.1 in the revised manuscript: \u201cWe perform a systematic evaluation of model performance across different data-generating configurations by varying both the problem scale ($5$, $10$ and $15$ sources) and the sample size ($2800$ and $5600$ samples). The aggregated MD and MCC metrics are shown in Figure 4. Remarkably, DeepIVA outperforms iVAE and MISA in every configuration, showcasing its superior performance across all evaluated scenarios. Within each panel, we observe a consistent drop in model performance as the number of latent sources increases, suggesting that the optimization problem becomes more challenging as the latent dimension increases. Across horizontal panels, the DeepIVA performance improves for configurations with $10$ and $15$ sources when the sample size increases from $2800$ to $5600$, indicating that a larger sample size is necessary to better recover sources in a harder problem.\u201d"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8343/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700509224171,
                "cdate": 1700509224171,
                "tmdate": 1700509486926,
                "mdate": 1700509486926,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zVgkjvC1Jt",
                "forum": "77N93tc3o5",
                "replyto": "MHwxHCeC7j",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8343/Reviewer_dLxh"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8343/Reviewer_dLxh"
                ],
                "content": {
                    "title": {
                        "value": "How to align linked sources?"
                    },
                    "comment": {
                        "value": "I thank the authors for their reply, and for adding Appendix A. \n\nWhile it helps clarify the method, the identifiability theory provided therein (mostly relying on results in (Khemakhem et al., 2020)) still leaves me with a few doubts. I will detail this below. Please let me know in case I am misunderstanding something.\n\n**Distinction between shared and linked.** May I kindly ask you to elaborate on the distinction between shared and linked sources? Does \"linked\" mean that there is some kind of statistical dependence? In multi-view ICA, each view is generated by mixing a corrupted version of some shared sources ($\\mathbf{s}$ are the shared sources, $\\mathbf{s}+\\mathbf{n}_i$ would be the corrupted version for the $i$-th view). So the $i$-th component of the corrupted sources is not independent across different views. Can I think of these corrupted components, or sources, as linked according to your terminology? My impression is that these could be considered linked, albeit possibly with a different kind of statistical dependence from the one in your equation (3). \n\n**MISA in the nonlinear case.** Based on my understanding, the MISA procedure relies on \"all-order statistics\" to match linked sources. However, in nonlinear ICA (including the iVAE results), an identifiable model may separate the true sources, but element-wise non-linearly distort them w.r.t. the true ones. This element-wise distortion has, in principle, the capability to transfrom any univariate distribution into a completely different one, thereby potentially modifying statistics of all orders, and (in my understanding) destroy the signal MISA relies on to operate the matching. (Note that this problem does not arise for linear models, for which MISA was originally developed.) Separately training different models on different datasets may recover sources which are distorted up to distinct element-wise distortions. Based on this, I'm having difficulty understanding the rationale behind the possibility of matching linked sources.\n\n**fMRI.** Thanks for the provided explanation. May I kindly ask you to further clarify what the linked sources are expected to capture, i.e., what is the meaning of linked sources across data modalities? Should I think of them as capturing some subject-specific characteristics influencing both functional activity in fMRI and structural properties captured by sMRI? Can I think of a generating process in which a first variable captures properties which depend on subject identity, $I_i$, and in turn this influences both structural properties $S_i$ and functional activity $F_i$, thus rendering them dependent? I would represent this as a DAG with arrows $S_i \\leftarrow I_i \\rightarrow F_i$. Is this a correct picture? If so, I believe that this would strengthen the connection to multi-view ICA (see e.g. Fig. 2 in (Gresele et al., 2019)), related to my concerns expressed above."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8343/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700643432854,
                "cdate": 1700643432854,
                "tmdate": 1700643945711,
                "mdate": 1700643945711,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4on46bzfjc",
                "forum": "77N93tc3o5",
                "replyto": "MHwxHCeC7j",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8343/Reviewer_dLxh"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8343/Reviewer_dLxh"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your reply; raising my evaluation"
                    },
                    "comment": {
                        "value": "Thank you for your reply, which answered some of the points I raised.\n\n**Distinction between shared and linked; fMRI.** My understanding of your reply is that corrupted sources with additive noise, $\\mathbf{z}_1 := \\mathbf{s}+\\mathbf{n}_1$ and $\\mathbf{z}_1 := \\mathbf{s}_2+\\mathbf{n}_2$, can only model simple (linear) dependence between $\\mathbf{z}_1, \\mathbf{z}_2$. More complicated statistical dependence cannot be modelled accurately by the additive model in (Richard et al., 2020), whereas the model you use may provide more expressivity. This sounds like a valid argument, where it appears that there is a strong connection between corrupted sources $\\mathbf{z}_1, \\mathbf{z}_2$, as defined above, and the linked sources you consider; your considered case may be more expressive and, potentially, more useful for neuroimaging data:\n\n> If it were the case that $p(I^S_i, I^F_i)$ is fully explained by linear dependence, then a model of shared sources might be useful, but that is currently unknown, and it is necessary to develop approaches that capture higher-order dependence.\n\nI accept the explanation in principle, although it would be interesting to have some empirical check and comparison of the two methods, to verify whether approaches that capture higher-order dependence (and nonlinear mixing), as yours, allow for an improved performance or discovery of interesting biomarkers. \n\nI would suggest discussing this in more detail in the paper, particularly because more complex (non-additive) corruptions $\\mathbf{z}_i := \\mathbf{g}(\\mathbf{s},\\mathbf{n}_i)$ have already been considered in the literature on the theory of nonlinear multi-view ICA (Gresele et al., 2019).\n\n**MISA in the nonlinear case.** Thank you for the provided explanation. I agree that element-wise transformations cannot erase dependence among the linked sources. I would appreciate it if you could provide a self-contained proof along with a formal illustration demonstrating how this argument leads to identifiability for the method you proposed (the current presentation of the proof in Appendix A may be seen as not fully explicating all the formal passages, as also observed by other reviewers).\n\nI appreciate the authors' efforts in replying to my questions. Since the answers clarified some of the points I raised, I will raise my evaluation."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8343/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700731809430,
                "cdate": 1700731809430,
                "tmdate": 1700731911752,
                "mdate": 1700731911752,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ET3ehpSq6t",
            "forum": "77N93tc3o5",
            "replyto": "77N93tc3o5",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8343/Reviewer_Uwfa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8343/Reviewer_Uwfa"
            ],
            "content": {
                "summary": {
                    "value": "The manuscript introduces a method that combines iVAE and MISA in order to learn linked and identifiable latent sources from multiple data modalities. Comprehensive experiments on both synthetic and real-world datasets show that the proposed method outperforms both iVAE and MISA. However, the contribution is limited due to its lack of novelty beyond the combination."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The experiments are comprehensive."
                },
                "weaknesses": {
                    "value": "1. The contribution is limited. It is essentially a combination of two existing methods (MISA and iVAE) without any theoretical results. Since the key contributions of MISA and iVAE are their identifiability proofs instead of the estimation (e.g., the estimation model of iVAE is basically the vanilla VAE), combining their estimation methods without any theoretical contribution might be incremental. \n\n2. Almost half of the manuscript is dedicated to the introduction of existing works, and the other half focuses on experiments. Meanwhile, only **half a page** describes the proposed method. The brevity of the description might be understandable if the contribution is simply a combination of existing methods. However, if that's not only a combination, a more detailed explanation regarding the motivation and unique contributions of the proposed method is necessary."
                },
                "questions": {
                    "value": "In the section of the conclusion, it is mentioned that there exist some recent works on nonlinear ICA without auxiliary variables. However, in the introduction, only methods with auxiliary variables are introduced. Any specific reason for that?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8343/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698821980612,
            "cdate": 1698821980612,
            "tmdate": 1699637037239,
            "mdate": 1699637037239,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "R3WBFeQW1P",
                "forum": "77N93tc3o5",
                "replyto": "ET3ehpSq6t",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8343/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8343/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "$\\textbf{Q1}:$ More detailed explanation regarding the motivation and unique contributions.\n\n$\\textbf{A1}:$ We thank the reviewer for requesting clarification on the motivation and contributions of our proposed method.\n\nRegarding motivation, we have revised the manuscript to explain why we are interested in multimodal fusion in Section 1 Introduction: \u201cJointly analyzing two imaging modalities can uncover cross-modal relationships that cannot be detected by a single imaging modality, providing new insights into structural and functional interactions in the brain and its disorders (Calhoun & Sui, 2016).\u201d \n\nAlso, another reason we choose MISA is that we want to utilize its flexible subspace modeling to further solve nonlinear independent subspace analysis (ISA) problems. We have added one more reason why we choose MISA to align latent sources in Section 4 Discussion: \u201cWe plan to extend our proposed method from nonlinear IVA problems to nonlinear ISA problems, aiming to capture source dependence by leveraging higher-dimensional subspaces.\u201d\n\nRegarding contributions, our study is an initial step towards learning linked and identifiable sources from multimodal data. We empirically demonstrate that DeepIVA can learn linked and identifiable sources by unifying iVAE and MISA, and \u201cthe idea of combining iVAE and MISA is new\u201d, as acknowledged by reviewer queK. We would like to point out that our proposed method is not \u201csimply a combination of existing methods\u201d. We modified the iVAE encoder architecture to process data features and auxiliary information separately, as noticed by reviewer dLxh. Additionally, the linear demixing matrix in the original MISA framework was replaced by a nonlinear encoder, and we adjusted the loss term accordingly as described in Section 2.1 Deep Independent Vector Analysis. \n\nWe have updated Figure 1 to illustrate the extra details of our method, including the data input and the encoder layer. We have also updated Section 2.1 Deep Independent Vector Analysis to explain the architecture change: \u201cAdditionally, since MISA is not designed to handle auxiliary information, we modify the original encoder architecture to distinguish between data features $\\mathbf{x}^{m}$ and auxiliary variables $\\mathbf{u}$ such that 1) the iVAE updates model parameters with respect to both $\\mathbf{x}^{m}$ and $\\mathbf{u}$ at the input layer, and 2) the MISA updates only those pertaining to $\\mathbf{x}^{m}$ but not $\\mathbf{u}$. The original iVAE model uses a single input layer taking the concatenated $\\mathbf{x}^{m}$ and $\\mathbf{u}$. In DeepIVA, we split this layer into two: one for data features $\\mathbf{x}^{m}$ and another for auxiliary variables $\\mathbf{u}$. The parameters with respect to $\\mathbf{u}$ will only be updated at the iVAE training step but will remain frozen at the MISA training step. Also, the inputs for the auxiliary variables are set to $0$ during MISA training to ensure no influence from the frozen weights.\u201d\n\nFurthermore, we have restated the identifiability theory in Khemakhem et al., 2020, and provided a conceptual sketch of proof showing that the generative model assumed in DeepIVA is identifiable up to a permutation and component-wise transformation in Appendix A. We have also updated Section 2.1 iVAE and DeepIVA parts accordingly in the revised manuscript. \n\n$\\textbf{Q2}:$ Related works on nonlinear ICA without auxiliary variables. \n\n$\\textbf{A2}:$ We introduce methods relevant to the current work in the introduction section and mention methods worth exploring in the future work section. We are interested in the application of neuroimaging analysis, and the iVAE has been shown to work on an fMRI dataset (Khemakhem et al. 2020) among the mentioned papers. Thus, we chose iVAE for this present work, and we will keep exploring other methods."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8343/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700508350434,
                "cdate": 1700508350434,
                "tmdate": 1700508350434,
                "mdate": 1700508350434,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GeZr6pr5fj",
                "forum": "77N93tc3o5",
                "replyto": "6yWCE8AOsQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8343/Reviewer_Uwfa"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8343/Reviewer_Uwfa"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks so much for your response. I'm still not fully convinced regarding the significance of the theoretical contribution compared to previous works, since the identifiability of the proposed method (iVAE+MISA) is mostly based on existing results. Thus, I would like to maintain my score for now."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8343/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700632135918,
                "cdate": 1700632135918,
                "tmdate": 1700632135918,
                "mdate": 1700632135918,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]