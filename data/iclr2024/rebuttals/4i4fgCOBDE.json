[
    {
        "title": "Networked Inequality: Preferential Attachment Bias in Graph Neural Network Link Prediction"
    },
    {
        "review": {
            "id": "94SuW60irW",
            "forum": "4i4fgCOBDE",
            "replyto": "4i4fgCOBDE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3726/Reviewer_LXYw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3726/Reviewer_LXYw"
            ],
            "content": {
                "summary": {
                    "value": "This paper theoretically and empirically shows that graph convolutional networks (GCNs) can exhibit preferential attachment (PA) bias in link prediction, where GCNs tend to predict more links between high-degree nodes that belong to the same social group. The authors propose a simple training-time strategy, based on a fairness regularization term, to mitigate within-group unfairness in GCN link prediction. Experiments show this term reduces unfairness without severely impacting prediction performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "(1) This paper provides abundant theoretical analysis under the specified settings.\n\n(2) This paper proposes a new metric to quantify within-group unfairness in link prediction, which measures disparities in link prediction scores between social groups. The proposed fairness regularizer also provides a simple and effective way to address the newly characterized unfairness.\n\n(3) Experiments are comprehensive in terms of the number of datasets, showing the effectiveness of the proposed training time debiasing solution."
                },
                "weaknesses": {
                    "value": "(1) This paper mainly analyzes the GCN model, failing to consider more widely used alternatives in LP tasks, e.g., SOTA contrastive methods. In addition, this paper relies on relatively simple settings. For example, this paper only considers performing LP with an inner-product decoder, while adopting an MLP classification model on top of the Hadamard product between a pair of node embeddings is more widely used.\n\n(2) There is no baseline adopted for comparison in this paper, and it is not reasonable to avoid such a comparison by claiming the studied problem is novel. It would be necessary to see whether the studied problem is a prevalent problem among different commonly used LP methods.\n\n(3) The evaluation of fairness regularizer utilizes the loss itself as a metric, which seems to be not convincing: the loss would be reduced as long as the gradient descent is effective in most cases."
                },
                "questions": {
                    "value": "(1) Does this studied fairness issue widely exist in those commonly used link prediction models, such as those contrastive GNNs? Is the theoretical analysis in this paper generalizable to them?\n\n(2) Will those commonly used LP models naturally underperform or outperform the reported performance under fairness regularization?\n\n(3) Is there any particular reason why the analysis is performed on GCN? Since the vanilla GCN is not commonly used for LP tasks, this seems questionable to me.\n\n(4) What is the time complexity of the proposed regularization-based method?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3726/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698416794520,
            "cdate": 1698416794520,
            "tmdate": 1699636329053,
            "mdate": 1699636329053,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mOOS7h7kbF",
                "forum": "4i4fgCOBDE",
                "replyto": "94SuW60irW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3726/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3726/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their helpful and specific feedback! To address your stated weaknesses and questions:\n\n- Weakness (1), Questions (1)-(2): By theoretically and empirically uncovering preferential attachment bias and within-group unfairness issues in GCN link prediction, we lay a foundation to study these issues in other link prediction methods in the future. This will include SOTA contrastive methods for link prediction (1) and how they are affected by fairness regularization (2). Overall, this is an important and interesting direction of research. \n\n**We also include experiments for a link predictor that uses a Hadamard product and MLP score function (instead of an inner product) in Appendix G.2. We find that our theoretical analysis is still relevant to and reasonably supports the experimental results, both qualitatively and quantitatively.** This could be because MLPs have an inductive bias towards learning simpler, often linear functions [1, 2], and our theoretical findings are generalizable to linear LP score functions.\n\n- Weakness (2): Because we unveil a new form of unfairness, it is difficult for us to find comparable methods to use as baselines. While we describe methods for alleviating degree bias in the \u201cDegree bias in GNNs\u201d paragraph in our related work section, these methods address performance disparities for low-degree nodes. In contrast, we do not study performance issues but rather how GCN often scales node representations proportionally to the square root of their within-group degree, which affects the magnitude of their link prediction scores.\n\n- Weakness (3): We do not use the loss as our fairness metric, but rather the fairness metric as a regularization term in our loss. We theoretically motivate and ground the fairness metric in Section 4.2, and because the metric is differentiable, we are able to directly add it to our loss function. While it is not surprising that the fairness regularization approach will minimize our metric, it is significant that our experiments show that the regularization does not severely impact link prediction performance.\n\n- Question (3): We focus on GCN (with symmetric and random walk normalized filters) because it provides us with a reasonable setting to develop a rigorous theory of preferential attachment bias in GNN link prediction while leveraging tools from spectral graph theory. We believe that our results may be generalizable to GNN architectures that use a symmetric degree-normalized diffusion operator. Furthermore, it is not uncommon to use vanilla GCN for link prediction; for example, PyTorch Geometric (a popular graph learning library) has code examples that apply vanilla GCN to link prediction: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/link_pred.py.\n\n- Question (4): The time complexity of calculating the regularization term is $O(\\sum_{b = 1}^B  |S^{(b)} \\cap T^{(1)}| \\cdot S^{(b)} +  |S^{(b)} \\cap T^{(2)}| \\cdot S^{(b)})$, as we have already computed the link prediction scores for the cross-entropy loss term and simply need to sum them appropriately with respect to the groups and subgroups. The time complexity of computing gradients for the regularization term should be on the same order as backpropagation for the cross-entropy loss term.\n\n[1] Nakkiran, Preetum, et al. \"Sgd on neural networks learns functions of increasing complexity.\" arXiv preprint arXiv:1905.11604 (2019).\n\n[2] Valle-Perez, Guillermo, Chico Q. Camargo, and Ard A. Louis. \"Deep learning generalizes because the parameter-function map is biased towards simple functions.\" arXiv preprint arXiv:1805.08522 (2018)."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3726/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700203184070,
                "cdate": 1700203184070,
                "tmdate": 1700203704681,
                "mdate": 1700203704681,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SbQirz2H8H",
                "forum": "4i4fgCOBDE",
                "replyto": "94SuW60irW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3726/Reviewer_LXYw"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3726/Reviewer_LXYw"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the rebuttal"
                    },
                    "comment": {
                        "value": "Thanks for the response from the authors. \n\nMy concerns are partially addressed, but two of my major concerns remain: (1) it is not surprising that if a term is added to the objective function, then this term will be optimized when the objective is optimized, so it seems not comprehensive to only present the fairness performance from this specific perspective; (2) There should be a comprehensive discussion about why it is impossible to adopt existing frameworks as baselines for the studied problem. For example, does any of the existing fairness-aware frameworks contribute to the optimization of the proposed fairness metric? How does the proposed fairness metric connect with other existing metrics? It would be more reasonable to avoid adopting any baseline after properly placing the proposed approach in a broader literature background about the studied problem."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3726/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700713796723,
                "cdate": 1700713796723,
                "tmdate": 1700713796723,
                "mdate": 1700713796723,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KdA1gRBfwA",
            "forum": "4i4fgCOBDE",
            "replyto": "4i4fgCOBDE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3726/Reviewer_bJuY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3726/Reviewer_bJuY"
            ],
            "content": {
                "summary": {
                    "value": "The paper investigates the bias towards high degree nodes in link prediction when the underlying model is a  Graph Convolutional Network based on one of two filters: the symmetric normalized graph laplacian or on the random walk normalization. It does so by proving two theorems. For the first filter, it shows that the expected raw score output for an edge (i,j) is proportional to the geometric mean of the (\"in-block\") degrees of the adjacent nodes, under the assumptions of (1) social stratification, (2) expander graphs and that (3) each path from i to j in the computation graph is independently activated with a constant probability dependent on i. For the second filter, it did not uncover a direct relationship with degree. The authors conduct experiments on 10 datasets to validate their theoretical analysis (i.e., comparing the expected raw score with the actual GCN output for several pairs). Moreover, the work bridges this preferential attachment bias and within-group fairness in graph-based recommendation. It proposes a within-group (un-)fairness metric, which measures the disparity among (disjoint) social subgroups within a group. The paper proposes a simple regularization term based on the aforementioned metric to improve fairness and show its efficacy through additional experiments."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "S1. The paper provides a theoretical analysis to explain preferential attachment biases in GCN-based link prediction.\n\nS2. The assumptions made in the proofs are either supported by experiments or based on empirical evidence from other papers that analyze social network graphs.\n\nS3. Based on the estimate derived for the raw output score, the paper proposes a within-group fairness metric and uses it a (in-processing) fairness regularization method to correct for bias.    \n\nS4. The work bridges preferential attachment bias in graph link prediction and current work in within-group fairness.\n\nS5. The text flows nicely and it is very well-written."
                },
                "weaknesses": {
                    "value": "W1. The theoretical analysis is done for two types of filter (symmetric graph Laplacian and random walk), but only the first one is reasonably validated by the experiments. The second one still seems to yield a wide range of scores for different node pairs but this variance is not captured by the estimate.\n\nW2. Some aspects of the initial motivation can be clarified.\n\nW3. There are some other works that attempt to mitigate degree biases in GNN-based link prediction that have not been discussed."
                },
                "questions": {
                    "value": "Q1. The authors offer a potential explanation as to why the theoretic LP scores are not strong predictors of the $\\Phi_r$ scores: the extra dependence on the square root of the maximum ration between (in-block) node degrees.\n- How to test this conjecture? Did you observe that the relative error is smaller for lower values of this ratio?\n- How is the variance in the prediction score related to the node degrees? Did you try plotting a similar graph where the y-axis is some function of $\\widehat{D}_i$, $\\widehat{D}_j$ or both? \n- What are the connections between this result and steady-state of the classic RW on a non-bipartite connected graph?\n\nQ2. Some excerpts were not entirely clear until later in the paper:\n- In the explanation for Figure 1, does \"social group\" refer to gender or discipline?\n- In the previous example, if men may receive more collaboration recommendations, why not to fix the maximum number of recommendations per individual? Fewer recommendations could be provided if the model is not very confident about some of them. Is it a problem of calibration (i.e., the model tends to make overconfident predictions for certain subgroups)?\n- In  Eq. (5), which ones takes precedence: exponentiation to the L-th power or subscripting ij? Consider using\n$[(D^{-1/2} A D^{-1/2})^L]_{ij}$ and $[( D^{-1} A)^L]_{ij}$.\n\nQ3. Are you familiar with these works? Please discuss whether they should be included as part of related work.\n- Kojaku, Sadamori, Jisung Yoon, Isabel Constantino, and Yong-Yeol Ahn. \"Residual2Vec: Debiasing graph embedding with random graphs.\" Advances in Neural Information Processing Systems 34 (2021): 24150-24163.\n- Harry Shomer, Wei Jin, Wentao Wang, and Jiliang Tang. 2023. Toward Degree Bias in Embedding-Based Knowledge Graph Completion. In Proceedings of the ACM Web Conference 2023 (WWW '23). Association for Computing Machinery, New York, NY, USA, 705\u2013715. https://doi.org/10.1145/3543507.3583544"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3726/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3726/Reviewer_bJuY",
                        "ICLR.cc/2024/Conference/Submission3726/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3726/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698634621476,
            "cdate": 1698634621476,
            "tmdate": 1700217688037,
            "mdate": 1700217688037,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "B7E9pEPJjW",
                "forum": "4i4fgCOBDE",
                "replyto": "KdA1gRBfwA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3726/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3726/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their detailed and valuable feedback! To address your concerns and questions:\n\n- W2: Could you please elaborate on which aspects of the initial motivation can be clarified? (e.g., specific lines). We greatly appreciate your help in making our motivation clear and accessible to readers.\n\n- W3, Q3: Thank you for bringing [1, 2] to our attention; we will add these papers to the \u201cDegree bias in GNNs\u201d paragraph in our related work section. However, these works touch upon different forms of degree bias (i.e., sampling and performance bias) than the type of degree bias we uncover: GCNs often scale node representations proportionally to the square root of their within-group degree, which affects the magnitude of their link prediction scores.\n\n- Q1: **We did not observe that the relative error is smaller for lower values of the ratio. We add plots demonstrating this in Appendix I (Figure 11).**\n\n**Furthermore, $\\Phi_r$ link prediction scores are not associated with either $\\widehat{D}_{i i}$, $\\widehat{D}_{j j}$, or the product thereof. We add plots demonstrating this in Section I (Figure 12).**\n\nThere are intimate connections between our result and the steady-state probabilities of the classic RW. The stationary probabilities of classic RW are the same regardless of the starting node. This is why $\\Phi_r$ produces similar representations for all the nodes in each group, regardless of the degree of the node (with a larger number of layers, $\\Phi_r$ would oversmooth all the representations to the same vector). Hence, $\\Phi_r$ link prediction scores do not have a degree dependence, theoretically or empirically.\n\n- Q2: In Figure 1, we treat the disciplines as groups and gender as subgroups; in particular, we are concerned about GCN link prediction further marginalizing the subgroup of women within the group of CS researchers.\n\nWe agree that fixing the number of recommendations per individual is a possible solution, but doing this with utility in mind requires identifying a utility-maximizing subset of link predictions. As our theoretical and empirical results reveal, GCN link prediction scores are often inherently proportional to the geometric mean of the degrees of the incident nodes, which can make them a poor indicator of prediction confidence. From a calibration perspective, GCN naturally makes overconfident predictions for links between high-degree nodes.\n\nIn Eq. (5), the power takes precedence over the subscripting.\n\n[1] Kojaku, Sadamori, Jisung Yoon, Isabel Constantino, and Yong-Yeol Ahn. \"Residual2Vec: Debiasing graph embedding with random graphs.\" Advances in Neural Information Processing Systems 34 (2021): 24150-24163.\n\n[2] Harry Shomer, Wei Jin, Wentao Wang, and Jiliang Tang. 2023. Toward Degree Bias in Embedding-Based Knowledge Graph Completion. In Proceedings of the ACM Web Conference 2023 (WWW '23). Association for Computing Machinery, New York, NY, USA, 705\u2013715. https://doi.org/10.1145/3543507.3583544"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3726/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700203099261,
                "cdate": 1700203099261,
                "tmdate": 1700203532068,
                "mdate": 1700203532068,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yzujCD4QWn",
                "forum": "4i4fgCOBDE",
                "replyto": "B7E9pEPJjW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3726/Reviewer_bJuY"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3726/Reviewer_bJuY"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the authors' thoughtful responses and additional experiments to improve the paper.\n\n> W2: Could you please elaborate on which aspects of the initial motivation can be clarified? (e.g., specific lines).\n\nThose aspects were specified in Q2. Thank you for addressing them."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3726/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700219648944,
                "cdate": 1700219648944,
                "tmdate": 1700219648944,
                "mdate": 1700219648944,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "gE55ZxJHKN",
            "forum": "4i4fgCOBDE",
            "replyto": "4i4fgCOBDE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3726/Reviewer_LDLM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3726/Reviewer_LDLM"
            ],
            "content": {
                "summary": {
                    "value": "This paper explores the impact of degree bias in networks on Graph Convolutional Network (GCN) link prediction (LP). The authors investigate how the preferential attachment mechanism, which creates degree discrepancies between nodes, can impact link prediction scores. Moreover, they explore within-group fairness to investigate if the bias in link prediction is additionally enlarged by considering subgroups considering two attributes, such as ethnic background and gender. The research focuses on GCNs with symmetric and random walk normalized graph filters and examines their LP scores within the same social group. They find that GCNs with symmetric normalized filters exhibit within-group preferential attachment bias in link prediction. This bias can result in disparities in link prediction scores between social groups, potentially amplifying degree and power imbalances in networks. \n\nIn particular, the authors provide a theoretical analysis of a within-group preferential attachment bias in link prediction of GCNs with symmetric normalized graph filters. They empirically validate these findings on 10 real-world networks. For GCNs with a random walk normalized filter, the authors theoretically do not find a PA bias, which is however contradicted by empirical evidence. Building on these findings, the authors contribute a new within-group fairness metric for LP, which quantifies disparities in LP scores between social groups. Lastly, the authors propose a training-time strategy to alleviate within-group unfairness, which they assess on three real-world networks revealing its effectiveness."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The manuscript is well written and, in my opinion, a valuable contribution to the literature. The authors carefully derive their theoretical results and perform experiments on real-world datasets which (mostly) back up their results. Even when the authors find discrepancies between their theoretical predictions and their experiments, the limitations are discussed appropriately. \nThe extension of the fairness assessment to within-group fairness is an important consideration that is often missing in the current literature. The authors also point towards intersectionality literature, which would be an interesting extension which is probably not possible due to space constraints."
                },
                "weaknesses": {
                    "value": "Right before Section 4.2 the authors rightly state that \u201csuch \u201crich get richer\u201d dynamics can engender group unfairness when nodes\u2019 degrees are statistically associated with their group membership\u2026\u201d\n\nWhether or whether not nodes\u2019 degrees are statistically associated with their group membership largely depends on their group size and homophily of the interactions. Maybe a discussion of the impact of homophily would be appropriate here. \nThe authors only state in their future work, that it would be useful to study heterophilic networks as well, but never touch on the concept of homophily in the rest of the paper. \n\nMoreover, it would have been interesting if there would have been a larger discussion of the interpretation of the different intersections of groups in the within-fairness part and how marginalisation of certain social groups paper aligns or contradicts with social science literature.\n\nIn Figure 2, a legend of the colour code of the dots would be helpful.\n\nTo me, the adaption of node classification datasets to LP did not become as clear. Is it true, that the labels are associated to network structure and are now used as the group truth for the groups? If this is true, the networks would anyways be largely homophilic, that could be stated somewhere.\n\nVery minor: page 21 C: \u201cWe we row-normalise\u2026\u201d"
                },
                "questions": {
                    "value": "see weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3726/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3726/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3726/Reviewer_LDLM"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3726/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698671876243,
            "cdate": 1698671876243,
            "tmdate": 1700318677329,
            "mdate": 1700318677329,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VwJ0gRmSws",
                "forum": "4i4fgCOBDE",
                "replyto": "gE55ZxJHKN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3726/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3726/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their insightful and thorough feedback! To address your concerns:\n\n- We agree that the association between node degrees and group membership depends on group size and homophily. In our camera-ready (after working out space constraints), we will add the following text before Section 4.2:\n\n*\u201dAn association between node degrees and group membership depends on group size and homophily; in particular, when a group has many nodes and intra-links (i.e., is homophilous), there may be more nodes with a high within-group degree.\u201d* \n\nWe touch upon social group homophily in Section 4.1 using the term \u201csocial stratification\u201d from the social science literature. In particular, the intra-link approximation error term $\\sum_{l = 1}^L {L \\choose l} \\left\\| \\Xi^{(0)} \\right\\|^l_{op} \\left\\| \\widehat{P} \\right\\|^{L - l}_{op}$ captures homophily.\n\n- We will add a discussion of how our findings relate to Intersectionality in the \u201cWithin-group fairness\u201d paragraph of Section 2:  \n\n*\u201dOur theoretical and empirical findings reveal that GCN link prediction can further marginalize social subgroups. This relates to the \u201ccomplexity\u201d tenet of Intersectionality, which expresses that the marginalization faced by, e.g., Black women, is non-additive and distinct from the marginalization faced by Black men and white women [1].\u201d*\n\n- In Figure 2, the colors represent different groups. We describe the type of groups in each dataset in Section C; for example, in the LastFMAsia dataset, the groups are the home countries of users. However, we were unable to find the exact group names (e.g., Vietnam, India) from the dataset documentation.\n\n- We adopt the class labels for each dataset as the social group labels. This design choice is reasonable, as in all the datasets, the classes naturally correspond to socially-relevant groupings of the nodes, or proxies thereof (e.g., in the LastFMAsia dataset, the classes are the home countries of users). We will add the following discussion of homophily in Section 5:\n\n*\u201dBecause we adopt the class labels for each dataset as the social group labels, the social groups are largely homophilic. This aligns with our assumptions when interpreting Theorems 4.3 and 4.4 that social groups are stratified in networks.\u201d*\n\n[1] Collins, Patricia Hill, and Sirma Bilge. Intersectionality. John Wiley & Sons, 2020."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3726/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700202783306,
                "cdate": 1700202783306,
                "tmdate": 1700202783306,
                "mdate": 1700202783306,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qYrCdFlo4N",
                "forum": "4i4fgCOBDE",
                "replyto": "VwJ0gRmSws",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3726/Reviewer_LDLM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3726/Reviewer_LDLM"
                ],
                "content": {
                    "title": {
                        "value": "thanks for the answer"
                    },
                    "comment": {
                        "value": "I have increased my score accordingly."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3726/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700318708000,
                "cdate": 1700318708000,
                "tmdate": 1700318708000,
                "mdate": 1700318708000,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ruWrsm4qG6",
            "forum": "4i4fgCOBDE",
            "replyto": "4i4fgCOBDE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3726/Reviewer_qGCf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3726/Reviewer_qGCf"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the fairness of link prediction in Graph Neural Networks (GNN), focusing on within-group fairness and the \"rich get richer\" effect in networks. Its main result, as given in Theorem 4.3, is that GCNs with symmetric normalized graph filters exhibit a bias toward within-group preferential attachment. Numerical experiment verifies this theoretical result to a good extent."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper has good mathematical rigor, and the results are significant.\n2. I find Lemma 4.1 and Theorem 4.3 interesting and enjoyable to read. They should be of great interest to community interested in deciphering the societal implications of GNN-based LP when they are deployed on large-scale social systems.\n3. The experiments are well-designed and well support the theory."
                },
                "weaknesses": {
                    "value": "1. The assumption about the independence of path activation probabilities (\u03c1s(i) and \u03c1r(i)) is rather strong and may not hold true in real world. This can have great effect on the theoretical result. It would be helpful to discuss more.\n\n2. Canonical GNNs nowadays are rarely used for link prediction task due to some of their inherent limitation. Some of the classical works on link predictions, like [1, 2, 3], all use some additional signals one top canonical GNNs. It would be great, if possible, to also give some theoretical discussions on these works.\n\n\n\n\n[1] Graph Neural Networks for Link Prediction with Subgraph Sketching, ICLR 2023\n[2] Link Prediction Based on Graph Neural Networks, NeurIPS 2018\n[3] Distance Encoding: Design Provably More Powerful Neural Networks for Graph Representation Learning, NeurIPS 2020"
                },
                "questions": {
                    "value": "See weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3726/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698893776408,
            "cdate": 1698893776408,
            "tmdate": 1699636328805,
            "mdate": 1699636328805,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "izju4MPAsU",
                "forum": "4i4fgCOBDE",
                "replyto": "ruWrsm4qG6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3726/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3726/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their thoughtful feedback! To address your concerns:\n\n- We agree that the independence of path activation probabilities may not always hold true in the real world. However, we verify that this assumption is plausible via our extensive experiments on real-world datasets to validate our theoretical analysis (Section 5.1). This assumption also aligns with findings that deep neural networks have an inductive bias towards learning simpler, often linear functions [1, 2]. Furthermore, a variant of our assumption (where $\\rho(i) = \\rho$ is constant for all nodes) has been used in the literature to simplify theoretical analysis (e.g., [3, 4]); our assumption may be more realistic than this variant, as it captures that the probability of paths activating can differ across nodes (e.g., due to differences in features, neighborhood structure).\n\n- Thanks for highlighting works [5, 6, 7] on link prediction using GNNs. To address these, we will add the following text to the end of Section 3 in our camera-ready (once we work out space constraints):\n\n*\"In recent years, researchers have proposed methods to improve the expressivity of node representations for link prediction by capturing subgraph information [5, 6, 7]. Our theoretical findings remain relevant to methods that ultimately use a GCN to predict links (e.g., [6, 7]), as we do not make assumptions about the features passed to the GCN (i.e., they could be distance encodings, SEAL node embeddings, etc.) Studying the fairness of more expressive link prediction methods is an interesting direction for future research.\"*\n\n**We also include experiments for a link predictor that uses a Hadamard product and MLP score function (instead of an inner product) in Appendix G.2. We find that our theoretical analysis is still relevant to and reasonably supports the experimental results, both qualitatively and quantitatively.** This could be because MLPs have an inductive bias towards learning simpler, often linear functions [1, 2], and our theoretical findings are generalizable to linear LP score functions.\n\n[1] Nakkiran, Preetum, et al. \"Sgd on neural networks learns functions of increasing complexity.\" arXiv preprint arXiv:1905.11604 (2019).\n\n[2] Valle-Perez, Guillermo, Chico Q. Camargo, and Ard A. Louis. \"Deep learning generalizes because the parameter-function map is biased towards simple functions.\" arXiv preprint arXiv:1805.08522 (2018).\n\n[3] Xu, Keyulu, et al. \"Representation learning on graphs with jumping knowledge networks.\" International conference on machine learning. PMLR, 2018.\n\n[4] Tang, Xianfeng, et al. \"Investigating and mitigating degree-related biases in graph convoltuional networks.\" Proceedings of the 29th ACM International Conference on Information & Knowledge Management. 2020.\n\n[5] Graph Neural Networks for Link Prediction with Subgraph Sketching, ICLR 2023\n\n[6] Link Prediction Based on Graph Neural Networks, NeurIPS 2018\n\n[7] Distance Encoding: Design Provably More Powerful Neural Networks for Graph Representation Learning, NeurIPS 2020"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3726/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700202572835,
                "cdate": 1700202572835,
                "tmdate": 1700202692788,
                "mdate": 1700202692788,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DQzZiaCnei",
                "forum": "4i4fgCOBDE",
                "replyto": "izju4MPAsU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3726/Reviewer_qGCf"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3726/Reviewer_qGCf"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the response. My concerns have been resolved, and I would like to maintain my current score."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3726/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700674141741,
                "cdate": 1700674141741,
                "tmdate": 1700674141741,
                "mdate": 1700674141741,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]