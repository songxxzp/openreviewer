[
    {
        "title": "Rayleigh Quotient Graph Neural Networks for Graph-level Anomaly Detection"
    },
    {
        "review": {
            "id": "USbvd2yjQC",
            "forum": "4UIBysXjVq",
            "replyto": "4UIBysXjVq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3058/Reviewer_X1rz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3058/Reviewer_X1rz"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes the first spectral GNN-based graph-level anomaly detection method named RQGNN. Considering the disparity in the accumulated spectral energy between the anomalies and normal graphs, RQGNN leverages the Rayleigh Quotient learning component to capture the accumulated spectral energy of graphs. In addition, RQGNN also proposes the Chebyshev Wavelet GNN to represent nodes. RQ-pooling that regards the Rayleigh Quotient coefficient as the node importance score will be employed to obtain graph representation. The final graph representation is the concatenation of the Rayleigh Quotient learning component and the Chebyshev Wavelet GNN. Finally, class-balanced focal loss is introduced to optimize RQGNN and obtain graphs\u2019 binary labels."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThe topic of graph-level anomaly detection focused by this paper is an interesting but under-explored research area.\n2.\tThis paper is the first to consider solving the problem of graph-level anomaly detection from the perspective of spectral graph. Before this, leveraging graph wavelet to identify anomalous nodes within a single graph has achieved empirical successes [1].\n3.\tThis paper proposes a sufficient survey on graph anomaly detection.\n\n[1] Tang et al. Rethinking Graph Neural Networks for Anomaly Detection. ICML 2022."
                },
                "weaknesses": {
                    "value": "1.\tThe insight of this paper seems to be on shaky ground. Figures 1 and 4-12 do not clearly show the statistical difference between anomalous graphs and normal graphs with respect to Rayleigh Quotient. Detailed text description about the ''significant disparity\" between two classes is necessary but not found on the current version. (This is the main reason why I currently tend to reject this paper.)\n2.\tI recommend briefly introducing Rayleigh Quotient in the introduction or preliminaries section.\n3.\tIn page 4,  authors wrote  \"If the graph Laplacian $\\mathbf L$ and graph signal $\\mathbf x$ of two graphs are close, then their Rayleigh Quotients will be close to each other and these two graphs will highly likely belong to the same class.\" I tend to think this statement is correct, but it seems not applicable for anomalies. Anything that is different from normal can be regarded as an anomaly, but we actually cannot get training data that can represent the full picture of anomalies. In addition, two anomalous graphs can also be very different. This paper uses two-class datasets for experiments, but what will be the result if we regard the third class that has never appeared in the training set as anomalies to test the proposed model?\n4.\tIn page 5, authors wrote \"However, as analyzed in Section 3.1, to capture the spectral properties of anomalous graphs, it is necessary to consider the spectral energy with respect to each eigenvalue.\" But, the reason for using graph wavelet convolution is still unclear."
                },
                "questions": {
                    "value": "1. How about the graph-level anomaly detection performance of ChebyNet, BernNet, GMT, Gmixup, and TVGNN if the loss function is replaced by the class-balanced focal loss?\n2. What is the ratio between the normal and anomalous graphs utilized during model training?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3058/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3058/Reviewer_X1rz",
                        "ICLR.cc/2024/Conference/Submission3058/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3058/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697774336544,
            "cdate": 1697774336544,
            "tmdate": 1700617340719,
            "mdate": 1700617340719,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8URUXG38Rx",
                "forum": "4UIBysXjVq",
                "replyto": "USbvd2yjQC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response (1/3)"
                    },
                    "comment": {
                        "value": "We appreciate your comprehensive and constructive review. Your crucial comments on the statistical differences between anomalous graphs and normal graphs are exceedingly helpful for us to improve our manuscript. Our point-to-point responses to your comments are given below.\n\n---\n\n**W1**: The insight of this paper seems to be on shaky ground. Figures 1 and 4-12 do not clearly show the statistical difference between anomalous graphs and normal graphs with respect to Rayleigh Quotient. Detailed text description about the ''significant disparity\" between two classes is necessary but not found on the current version. (This is the main reason why I currently tend to reject this paper.)\n\n**RW1**: Thanks for your constructive suggestions. Your feedback will greatly contribute to improving the quality of our manuscript. Our detailed explanation is as follows.\n\nIn the field of graph-level anomaly detection, researchers mainly rely on the chemical compound datasets available from TUDataset [2]. To the best of our knowledge, these datasets are the only datasets directly applicable to the graph-level anomaly detection task. Each dataset consists of several chemical compounds (graphs) whose labels are decided by whether they are inactive or active to a tumor. Despite being categorized into two classes, these chemical compounds still share many similar characteristics, so it is natural that the Rayleigh Quotient of these two classes presents similarity in some dimensions, which reflects the reviewer\u2019s concern. \n\nHowever, it is important to note that the values of Rayleigh Quotient on anomalous graphs and normal graphs can be extremely distinct from each other in some specific dimensions, showing the key differences between the compounds in the two classes. Our proposed model is capable of capturing these differences and hence achieves better performance as shown in the experiment. To better show the \u201csignificant disparity\u201d of the Rayleigh Quotient between anomalous graphs and normal graphs, we further add the following experiment. \n\nIn particular, we calculate the intra-distance of the normalized Rayleigh Quotient on normal graphs and anomalous graphs, respectively. Besides, we calculate the inter-distance of the normalized Rayleigh Quotient between normal graphs and anomalous graphs. \n\nDue to the time limit, we present the result on the SN12C dataset. We first calculate the pairwise inter-distances and pairwise intra-distances for the normalized Rayleigh Quotient of two classes. To keep consistency with the experiments described in Figure 1 (refer to Section 1),  we still construct 10 equal-width bins. Subsequently, we report the results of inter-distances divided by intra-distances of the normalized Rayleigh Quotient for the two classes, respectively. The detailed experimental result is presented below, where $d_i / d_a = \\frac{\\text{inter-distance between normalized RQ of different classes}}{\\text{intra-distance between normalized RQ of anomalous graphs}}$ and $d_i / d_n=\\frac{\\text{inter-distance between normalized RQ of different classes}}{\\text{intra-distance between normalized RQ of normal graphs}}$. \n\n|          Ratio          |    bin0    |   bin1   |    bin2    |   bin3    |   bin4    |   bin5    |   bin6    |   bin7    |    bin8    |   bin9   |\n| :---------------------: | :------: | :-----: | :------: | :-----: | :-----: | :-----: | :-----: | :-----: | :------: | :-----: |\n| $d_i / d_a$  | 5.2940 | 8.8330 | 0.5253 | 8.9315 | 11.8474 | 6.2311 | 1.9104 | 0.6942 | 0.7776 | 114.3876 |\n| $d_i / d_n$ | 3.0953  | 2.4427  | 16.7566  | 17.5596 | 114.7632  | 30.4557 | 5.3002  | 1.2671  |  1.4012  | 5.6286  |\n\nAs shown in the above table, the result clearly shows a significant disparity between the inter-distance and intra-distance values. Notice that in certain cases, the values of inter-distances can be 10 times or even 100 times larger than that of intra-distances, and the larger the ratios are, the more distinguishable these two classes are. Moreover, it is apparent that normal and anomalous graphs exhibit different patterns in many cases. which clearly demonstrates the \u201csignificant disparity\u201d between the two classes. \n\n[2] https://chrsmrrs.github.io/datasets/docs/datasets/\n\n---\n\n**W2**: I recommend briefly introducing Rayleigh Quotient in the introduction or preliminaries section.\n\n**RW2**: Thanks for your constructive suggestions. We will incorporate the relevant content into our revised manuscript. \n\n---"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3058/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700401937409,
                "cdate": 1700401937409,
                "tmdate": 1700401937409,
                "mdate": 1700401937409,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tARRNQJXNF",
                "forum": "4UIBysXjVq",
                "replyto": "USbvd2yjQC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response (2/3)"
                    },
                    "comment": {
                        "value": "**W3**: In page 4, authors wrote \"If the graph Laplacian and graph signal of two graphs are close, then their Rayleigh Quotients will be close to each other and these two graphs will highly likely belong to the same class.\" I tend to think this statement is correct, but it seems not applicable for anomalies. Anything that is different from normal can be regarded as an anomaly, but we actually cannot get training data that can represent the full picture of anomalies. In addition, two anomalous graphs can also be very different. This paper uses two-class datasets for experiments, but what will be the result if we regard the third class that has never appeared in the training set as anomalies to test the proposed model?\n\n**RW3**: Thanks for raising this point. The problem you mentioned can be categorized as an out-of-distribution detection task rather than an anomaly detection task. We acknowledge that this problem is out of the scope of this manuscript since there are notable distinctions between anomaly detection and out-of-distribution detection. \n\nTypically, in out-of-distribution datasets, we only have one class called in-distribution data, so out-of-distribution detection focuses on determining whether a new sample belongs to the in-distribution data. However, anomaly datasets usually contain data with two distinct characteristics. Therefore, anomaly detection aims to determine that a new sample belongs to one of the two classes. \n\nFor example, anomaly detection involves identifying all the tigers from a dataset that contains both cats and tigers, whereas out-of-distribution detection focuses on determining whether a new cat sample, such as a Birman cat, can be correctly classified as a cat given training dataset that exclusively contains Ragdoll cats. \n\nIn our manuscript, we follow the settings of iGAD and further include additional related baselines to conduct experiments. To the best of our knowledge, the datasets we employ are the only ones available in the field of graph-level anomaly detection.\n\nDespite our primary focus not being on the out-of-distribution task, we still conduct additional experiments to evaluate the performance of our proposed model. We use a modified COLORS-3 [1] dataset from TUDataset [2], which is an 11-class graph classification dataset. We randomly select two classes as out-of-distribution graphs and the remaining classes serve as normal graphs. One of the out-of-distribution classes is included in the training and validation sets, while the other is added to the testing set. \n\nThe results of this set of experiments are as follows: \n\n| Metrics |   RQGNN   |  iGAD  | HimNet |  GMT   | TVGNN  | BernNet | ChebyNet |\n| :-----: | :--------: | :----: | :----: | :----: | :----: | :-----: | :------: |\n|   AUC   | **0.9421** | 0.7630 | 0.4522 | 0.5000 |  0.5000   | 0.6486  |  0.6500  |\n|   F1    | **0.8423** | 0.6674 | 0.4707 | 0.3710 | 0.3710 | 0.3710  |  0.3710  |\n\nCompared with other baseline models, our proposed RQGNN achieves significant improvements in both AUC and F1 scores although RQGNN does not focus on out-of-distribution detection. \n\nWe will include these results in our revised manuscript.\n\n[1] Boris Knyazev, Graham W. Taylor, Mohamed R. Amer. Understanding attention and generalization in graph neural networks. NeurIPS, pages 4204-4214, 2019.\n\n[2] https://chrsmrrs.github.io/datasets/docs/datasets/\n\n---\n\n**W4**: In page 5, authors wrote \"However, as analyzed in Section 3.1, to capture the spectral properties of anomalous graphs, it is necessary to consider the spectral energy with respect to each eigenvalue.\" But, the reason for using graph wavelet convolution is still unclear.\n\n**RW4**: Graph wavelet convolution has been demonstrated to possess a strong capability to learn representations in the spectral domain from previous research, making it a natural choice as our backbone model. We also compared our RQGNN with other spectral GNNs, such as BernNet and ChebyNet, but as shown in our experiments in Section 4, even the state-of-the-art spectral GNN models can not handle complex graph-level anomaly detection tasks. \n\nIn addition, as proven in Section 3, we need to consider spectral energy in terms of each eigenvalue. According to BernNet [8], each graph filter can be viewed as a band filter, and each band filter only allows certain spectral energy to pass, so it is necessary to adopt a model with multiple graph filters. The graph wavelet convolution model can be considered as a combination of different graph filters, enabling us to consider the spectral energy associated with each eigenvalue. By employing different band filters, we can focus on the spectral energy of different eigenvalues. Therefore, leveraging graph wavelet convolution provides advantages compared to using single graph filters. \n\n[8] Bernnet: Learning arbitrary graph spectral filters via bernstein approximation. In NeurIPS, pp. 14239\u201314251, 2021.\n\n---"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3058/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700401974605,
                "cdate": 1700401974605,
                "tmdate": 1700401974605,
                "mdate": 1700401974605,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sSdmgbkN7J",
                "forum": "4UIBysXjVq",
                "replyto": "USbvd2yjQC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response (3/3)"
                    },
                    "comment": {
                        "value": "**Q1**: How about the graph-level anomaly detection performance of ChebyNet, BernNet, GMT, Gmixup, and TVGNN if the loss function is replaced by the class-balanced focal loss?\n\n**RQ1**: We have conducted experiments for GMT, Gmixup, and TVGNN. Please refer to Table 3 in the Appendix in the original manuscript for detailed experimental results. \n\nThe following table reports the results of ChebyNet and BernNet, where BernNet-CB and ChebyNet-CB denote the corresponding model with the class-balanced focal loss function, respectively.\n\n| Datasets | Metrics | BernNet | BernNet-CB | ChebyNet | ChebyNet-CB | RQGNN  |\n| :------: | :-----: | :-----: | :-------------: | :------: | :--------------: | :----: |\n|  MCF-7   |   AUC   | 0.6172  |     0.6215      |  0.6612  |      0.6617      | 0.8354 |\n|          |   F1    | 0.4784  |     0.4784      |  0.4780  |      0.4804      | 0.7394 |\n|  MOLT-4  |   AUC   | 0.6144  |     0.6068      |  0.6647  |      0.6650      | 0.8316 |\n|          |   F1    | 0.4794  |     0.4794      |  0.4854  |      0.4875      | 0.7240 |\n|   PC-3   |   AUC   | 0.6094  |     0.6040      |  0.6051  |      0.6065      | 0.8782 |\n|          |   F1    | 0.4853  |     0.4853      |  0.4853  |      0.4853      | 0.7184 |\n|  SW-620  |   AUC   | 0.6072  |     0.6081      |  0.6759  |      0.6823      | 0.8550 |\n|          |   F1    | 0.4847  |     0.4847      |  0.4898  |      0.4947      | 0.7335 |\n| NCI-H23  |   AUC   | 0.6114  |     0.6289      |  0.6728  |      0.6734      | 0.8680 |\n|          |   F1    | 0.4869  |     0.4869      |  0.4930  |      0.5203      | 0.7214 |\n| OVCAR-8  |   AUC   | 0.5850  |     0.5803      |  0.6303  |      0.6294      | 0.8799 |\n|          |   F1    | 0.4868  |     0.4868      |  0.4900  |      0.4992      | 0.7215 |\n|   P388   |   AUC   | 0.6707  |     0.6694      |  0.7266  |      0.7324      | 0.9023 |\n|          |   F1    | 0.5001  |     0.5002      |  0.5635  |      0.5656      | 0.7963 |\n|  SF-295  |   AUC   | 0.6353  |     0.6302      |  0.6650  |      0.6670      | 0.8825 |\n|          |   F1    | 0.4871  |     0.4871      |  0.4871  |      0.4871      | 0.7416 |\n|  SN12C   |   AUC   | 0.6014  |     0.5992      |  0.6598  |      0.6634      | 0.8861 |\n|          |   F1    | 0.4874  |     0.4874      |  0.4972  |      0.4970      | 0.7660 |\n| UACC257  |   AUC   | 0.6115  |     0.6130      |  0.6584  |      0.6645      | 0.8724 |\n|          |   F1    | 0.4895  |     0.4895      |  0.4894  |      0.4933      | 0.7362 |\n\nAs we can see, the class-balanced focal loss does not yield benefits for ChebyNet and BernNet. This further demonstrates that even though tackling the imbalanced problem of datasets, these spectral GNNs fail to capture the properties of anomalous graphs.\n\nWe will include these results in our revised manuscript.\n\n---\n**Q2**: What is the ratio between the normal and anomalous graphs utilized during model training?\n\n**RQ2**: Please refer to Table 1 in the original manuscript for the statistical information of all datasets, which includes the number of normal and anomalous graphs. The anomalous ratio for each dataset is around 5%. In addition, in Section 4, we have stated that \u201cwe randomly divide each dataset into training/validation/test sets with 70%/15%/15%, respectively. During the sampling process, we ensure that each set maintains a consistent ratio between normal and anomalous graphs.\u201d Therefore, the ratio between normal and anomalous graphs utilized during model training for each dataset remains consistent with the original dataset.\n\n---\n\nWe sincerely appreciate your time, and we are glad to answer any additional questions you may have."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3058/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700402001600,
                "cdate": 1700402001600,
                "tmdate": 1700402001600,
                "mdate": 1700402001600,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MCK07SQCZx",
                "forum": "4UIBysXjVq",
                "replyto": "sSdmgbkN7J",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3058/Reviewer_X1rz"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3058/Reviewer_X1rz"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the reply."
                    },
                    "comment": {
                        "value": "The data presented in the manuscript (figure 1, figures 4-12) indicates that this contrast in Rayleigh Quotient between normal and anomalous graphs  is not statistically significant. The current version of these figures does not help this article be published. Despite the authors show that the SN12C dataset exhibits a substantial difference in Rayleigh Quotient between normal and anomalous graphs in bin4 and bin9, I am apprehensive about the consistency of this pattern across other datasets. As this forms the foundational premise of the paper, I am particularly concerned about addressing this issue."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3058/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700451668274,
                "cdate": 1700451668274,
                "tmdate": 1700451668274,
                "mdate": 1700451668274,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3EhuXwU5S1",
                "forum": "4UIBysXjVq",
                "replyto": "w5rsmEFoaT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3058/Reviewer_X1rz"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3058/Reviewer_X1rz"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the author's response. Based on the information provided in this table, my current interpretation of the article is as follows. The Rayleigh Quotient serves as an auxiliary feature, employed by the author to assist Chebyshev Wavelet GNN in conducting graph-level anomaly detection, leveraging the subtle distinctions between anomalous and normal graphs. However, I did not discern clear patterns in the numerical data presented in this table (for instance, the Rayleigh Quotient of normal graphs consistently appears higher in certain bins than that of anomalous graphs). Therefore, I am concerned that the Rayleigh Quotient may not be specifically tailored for graph-level anomaly detection. Given this consideration, I am currently inclined to adjust my score to 5 as an expression of gratitude for the author's patient response."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3058/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700461603417,
                "cdate": 1700461603417,
                "tmdate": 1700461603417,
                "mdate": 1700461603417,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PqifSQGAOO",
                "forum": "4UIBysXjVq",
                "replyto": "mYWgu040IE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3058/Reviewer_X1rz"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3058/Reviewer_X1rz"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you to the author for addressing my concerns. I recommend that the author consider revising Figure 1, as well as Figures 7-15, as they appear to be confusing. Additionally, I suggest incorporating the rebuttal stage experiments into the manuscript, as this would significantly enhance the persuasiveness of the article. I acknowledge the author's efforts in providing rebuttals and presenting numerous experiments to convince me, and I am open to raising my rating to 6."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3058/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700617319161,
                "cdate": 1700617319161,
                "tmdate": 1700617319161,
                "mdate": 1700617319161,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "DXN6FQ1PJj",
            "forum": "4UIBysXjVq",
            "replyto": "4UIBysXjVq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3058/Reviewer_oJCz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3058/Reviewer_oJCz"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors introduce spectral analysis and identify significant differences in the spectral energy distributions between anomalous and normal graphs, leading to the development of the Rayleigh Quotient Graph Neural Network (RQGNN). This approach combines the explicit capture of the Rayleigh Quotient and implicit spectral exploration, outperforming existing methods in comprehensive experiments."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This paper is well-organized and easy to follow.\n2. Investigate Rayleigh Quotient Learning to graph anomaly detection is promising.\n3. The experiment demonstrates the effectiveness of the proposed method."
                },
                "weaknesses": {
                    "value": "1. The reviewer thinks that the motivation and rationale of Rayleigh Quotient Learning should emphasized. It is a quite general problem that \u201cexisting methods fail to capture the underlying properties of graph anomalies\u201d. \n2. An algorithm describing the training process is required.\n3. From the objective function in Section 3, the method proposed in this paper is a supervised method. This implies that some of the comparisons in the experiments are unfair because many graph-level anomaly detection methods are fully unsupervised to my knowledge, e.g., OCGIN, OCGTL, GlocalKD, etc.\n4. The authors only test on chemical datasets in this paper, while there are other data types that are constructed as graphs, such as social networks.\n5. It seems that the proposed RQGNN fluctuates a lot with the change of hyperparameters and shows instability. The authors should explain the reasons for this observation.\n6. The impact of hyperparameters on loss function is encouraged to be explored.\n7. From the ablation study results, the performance of RQGNN does not consistently outperform the other degradation models, and their performance is quite close in many cases. It seems the improvement from the several proposed components is somewhat limited."
                },
                "questions": {
                    "value": "1. Can the Rayleigh Quotient Learning be used to detect node anomalies?\n2. The authors should show the ratio between normal and anomalous graphs. Are they balanced or not?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3058/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3058/Reviewer_oJCz",
                        "ICLR.cc/2024/Conference/Submission3058/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3058/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698725943497,
            "cdate": 1698725943497,
            "tmdate": 1701051067538,
            "mdate": 1701051067538,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "QpH69d7yqb",
                "forum": "4UIBysXjVq",
                "replyto": "DXN6FQ1PJj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response (1/2)"
                    },
                    "comment": {
                        "value": "We appreciate your comprehensive and constructive review. Your crucial comments on experiments are exceedingly helpful for us to improve our manuscript. Our point-to-point responses to your comments are given below.\n\n---\n\n**W1**: The reviewer thinks that the motivation and rationale of Rayleigh Quotient Learning should be emphasized. It is a quite general problem that \u201cexisting methods fail to capture the underlying properties of graph anomalies\u201d.\n\n**RW1**: Thanks for your constructive suggestion. We will revise the claim as \u201cexisting methods fail to capture the property of Rayleigh Quotient in graph anomalies\u201d to emphasize it.\n \nAs you can observe from Figure 1 in Section 1, a noticeable distinction between the Rayleigh Quotient of the normal graphs and that of the anomalous graphs can be observed. Subsequent experiments have demonstrated that using this characteristic significantly boosts the performance of graph-level anomaly detection tasks. To avoid confusion, we have revised the manuscript as \u201cthe spectral property of graph anomalies\u201d. Furthermore, we will incorporate an additional table to emphasize the importance of the Rayleigh Quotient in graph-level anomaly detection. For more detailed information, please refer to **RW1 (Reviewer X1rz)**.\n\n---\n\n**W2**: An algorithm describing the training process is required.\n\n**RW2**: Thanks for your valuable suggestion. We will include an algorithm in the Appendix of our revised manuscript to provide a detailed description of the training process.\n\n---\n\n**W3**: From the objective function in Section 3, the method proposed in this paper is a supervised method. This implies that some of the comparisons in the experiments are unfair because many graph-level anomaly detection methods are fully unsupervised to my knowledge, e.g., OCGIN, OCGTL, GlocalKD, etc.\n\n**RW3**: Yes, almost all graph-level anomaly detection methods tested in our paper are fully unsupervised. Indeed, the lack of fairness in this area is primarily due to its under-exploration. The main reason is the scarcity of supervised learning methods that can serve as baseline models. To the best of our knowledge, iGAD is the only supervised learning model available for the graph-level anomaly detection task. Consequently, we follow the experimental settings of iGAD. Furthermore, we include more baselines that are related to this task to demonstrate the effectiveness of our proposed model. The existence of this phenomenon also highlights the urgent need to develop new and robust supervised learning models, showing the importance of our work. \n\n---\n\n**W4**: The authors only test on chemical datasets in this paper, while there are other data types that are constructed as graphs, such as social networks.\n\n**RW4**: Since there is currently no existing dataset specifically designed for graph-level anomaly detection in other domains, we modify a synthetic dataset (COLORS-3) and a social network classification dataset (DBLP_v1) to conduct additional experiments. For more detailed information regarding this set of experiments, please refer to **RW2 (Reviewer qWnD)**. \n\n---\n\n**W5**: It seems that the proposed RQGNN fluctuates a lot with the change of hyperparameters and shows instability. The authors should explain the reasons for this observation.\n\n**RW5**: Despite observing variations in the model performance, our model still outperforms other baselines in almost all datasets. Notice that other baselines, such as iGAD, also display performance variations in their experiments when varying hyperparameters. \n\n---"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3058/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700401641111,
                "cdate": 1700401641111,
                "tmdate": 1700401641111,
                "mdate": 1700401641111,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "u7DubzDhmp",
                "forum": "4UIBysXjVq",
                "replyto": "DXN6FQ1PJj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response (2/2)"
                    },
                    "comment": {
                        "value": "**W6**: The impact of hyperparameters on loss function is encouraged to be explored.\n\n**RW6**: Thanks for your valuable suggestion. Due to the time limit, we conduct experiments of parameter analysis on four datasets. The experimental results of varying hyperparameters are as follows. To summarize, when the $\\gamma$ is set to 1.5, RQGNN achieves a relatively stable performance on these datasets. Meanwhile, RQGNN presents a relatively satisfactory when $\\beta$ is set to 0.999. \n\nThe results of varying the hyperparameter $\\beta$: \n\n| Datasets | Metrics |  0.99  | 0.999  | 0.9999 | 0.99999 |\n| :------: | :-----: | :----: | :----: | :----: | :-----: |\n|  MCF-7   |   AUC   | 0.8454 | 0.8354 | 0.8213 | 0.8381  |\n|          |   F1    | 0.7226 | 0.7394 | 0.7281 | 0.7050  |\n|  SF-295  |   AUC   | 0.8680 | 0.8825 | 0.8674 | 0.8701  |\n|          |   F1    | 0.7159 | 0.7416 | 0.7509 | 0.7142  |\n|  SN12C   |   AUC   | 0.8889 | 0.8861 | 0.8845 | 0.8874  |\n|          |   F1    | 0.7522 | 0.7660 | 0.7466 | 0.7294  |\n| UACC257  |   AUC   | 0.8544 | 0.8724 | 0.8630 | 0.8621  |\n|          |   F1    | 0.6928 | 0.7362 | 0.7323 | 0.6712  |\n\nThe results of varying the hyperparameter $\\gamma$:\n\n| Datasets | Metrics |  1.0   |  1.5   |  2.0   |  2.5   |\n| :------: | :-----: | :----: | :----: | :----: | :----: |\n|  MCF-7   |   AUC   | 0.8297 | 0.8354 | 0.8570 | 0.8445 |\n|          |   F1    | 0.7433 | 0.7394 | 0.7340 | 0.7187 |\n|  SF-295  |   AUC   | 0.8800 | 0.8825 | 0.8773 | 0.8838 |\n|          |   F1    | 0.7499 | 0.7416 | 0.7329 | 0.7473 |\n|  SN12C   |   AUC   | 0.8817 | 0.8861 | 0.8774 | 0.8851 |\n|          |   F1    | 0.7593 | 0.7660 | 0.7603 | 0.7319 |\n| UACC257  |   AUC   | 0.8710 | 0.8724 | 0.8616 | 0.8599 |\n|          |   F1    | 0.7117 | 0.7362 | 0.7107 | 0.7107 |\n\nWe will add these experimental results in the Appendix of our revised manuscript. \n\n---\n\n**W7**: From the ablation study results, the performance of RQGNN does not consistently outperform the other degradation models, and their performance is quite close in many cases. It seems the improvement from the several proposed components is somewhat limited.\n\n**RW7**: Not exactly. In contrast, the conclusion can be quite the opposite. Our experiments reveal that both RQGNN-1 and RQGNN-2 achieve improvements compared to other baselines, clearly demonstrating the effectiveness of each proposed component in boosting graph-level anomaly detection performance. By combining these two powerful components, we get our proposed RQGNN model.\n\nAs we can observe from experiments conducted in Section 4, there are several reasons to highlight the necessity of combining these two components: \nRQGNN vs. RQGNN-1 \nRQGNN outperforms RQGNN-1 in all the datasets in terms of both metrics. \nRQGNN vs. RQGNN-2\nRQGNN outperforms RQGNN-2 in 7 datasets in terms of both metrics.\nAlthough RQGNN-2 slightly outperforms RQGNN in 3 datasets in terms of one metric, it significantly falls behind RQGNN in terms of the other metric.\n\nThese findings clearly demonstrate the necessity of combining both components to achieve superior and more stable performance in the graph-level anomaly detection task. Besides, we aim to find the unified hyperparameters that can achieve good performance for all datasets. \n\nIn summary, the proposed two components demonstrate their individual strengths, and we can even combine them together to achieve superior and more stable performance. It is evident that the improvement is not limited, instead, each of the proposed components will provide a new design direction for future research in this area. \n\n---\n\n**Q1**: Can the Rayleigh Quotient Learning be used to detect node anomalies?\n\n**RQ1**: Yes, the Rayleigh Quotient can be used to detect node anomalies. In the original manuscript, we have cited Tang et al. [7] where the authors introduce an interesting idea for node anomaly detection related to the Rayleigh Quotient. However, their focus primarily lies on designing a spectral GNN for node anomaly detection, rather than delving into the properties of the Rayleigh Quotient in the context of anomaly detection. As shown in our paper, Rayleigh Quotient can reveal the properties underlying anomalies and can be further explored in the GNN design for node-level anomaly detection. \n\n[7] Jianheng Tang, Jiajin Li, Ziqi Gao, and Jia Li. Rethinking graph neural networks for anomaly detection. In ICML, pp. 21076\u201321089, 2022. \n\n---\n\n**Q2**: The authors should show the ratio between normal and anomalous graphs. Are they balanced or not?\n\n**RQ2**: We have provided the number of normal and anomalous graphs of each dataset in Table 1 in the original manuscript. The anomalous ratio of each dataset is around 5%, which shows that these datasets are highly imbalanced. Please refer to Table 1 in Section 4 for more details. \n\n---\n\nWe sincerely appreciate your time, and we are glad to answer any additional questions you may have."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3058/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700401695364,
                "cdate": 1700401695364,
                "tmdate": 1700401695364,
                "mdate": 1700401695364,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "f26kqoLBaz",
                "forum": "4UIBysXjVq",
                "replyto": "DXN6FQ1PJj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We would like to express our gratitude for your valuable comments"
                    },
                    "comment": {
                        "value": "We sincerely hope that we have addressed your concerns satisfactorily, and we will gladly answer any additional questions you may have."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3058/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700662915028,
                "cdate": 1700662915028,
                "tmdate": 1700662915028,
                "mdate": 1700662915028,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "p4Mp4BhNnd",
            "forum": "4UIBysXjVq",
            "replyto": "4UIBysXjVq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3058/Reviewer_qWnD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3058/Reviewer_qWnD"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers the problem of detecting anomalies in graphs.  Related work in GNNs is reviewed, and it is argued that the Rayleigh quotient (RQ) supplies feature information that is useful and hasn\u2019t been adequately explored.  This is based on some data exploration of a chemical dataset.  The authors set up a learning problem that incorporates the RQ, and incorporates several pieces including graph wavelets and using the RQ as an attention mechanism.  Experiments compare baseline GNNs, including GNN classifiers and GNN anomaly detectors, and show the benefits of the proposed approach for the datasets studied."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is well written and provides a good statement of the problem, prior GNN related work, and the motivation for the approach.   Exploring the Rayleigh quotient in this context is well motivated and interesting.\n\nThe paper has some nice innovation, incorporating RQ pooling for example, and the use of RQ as a means of attention in the context of the graph wavelet.  The use of wavelets seems well motivated for this \u201cstep change\u201d problem, when the change is an anomaly.\n\nThe comparisons with other GNN-based methods are well documented and show the benefit of the proposed method for the datasets considered.  The hyperparameter choices are well described, and the ablation studies are useful indicators."
                },
                "weaknesses": {
                    "value": "The relation between Rayleigh quotient and perturbation is well known and studied, for example, in physics.  For example:  Pierre, C. (December 1, 1988). \"Comments on Rayleigh\u2019s Quotient and Perturbation Theory for the Eigenvalue Problem.\" ASME. J. Appl. Mech. December 1988; 55(4): 986\u2013988. When the vector is close to an eigenvector, then the RQ has a value that is close to the corresponding eigenvector.  There is also the Rayleigh-Schr\u00f6dinger procedure that yields approximations to the eigenvalues and eigenvectors of a perturbed matrix by a sequence of successively higher order corrections to the eigenvalues and eigenvectors of the unperturbed matrix.\n\nThe paper explores an important application and datasets, and experimentally shows that the RQ provides a useful feature for detecting change.  However, it isn\u2019t clear how general this is beyond the application considered.  \n\nThe anomaly here is a change detector between the baseline distribution (the normal graph class), and some deviation from this graph.  Apparently for this data there is no clear class after change (so it isn\u2019t surprising that the graph classifiers don\u2019t work well)."
                },
                "questions": {
                    "value": "Given the large literature on RQ\u2019s it seems likely that eqn (1) is well known?\n\nLemma 1 and leading to eqn (4), using L \u2013 I_n to compute is from Rivlin or some other reference?\n\nSection 4.5 (and throughout the paper).  \u201cRayleigh Quotient is an intrinsic characteristic of the graph-level anomaly detection task.\u201d  Should this be altered to say \u201cfor the application studied\u201d?  How general is the claim?\n\nIsn\u2019t the anomaly for this application the same as an \u201cout of distribution\u201d test?  \n\nIt seems this area of study would benefit from good baseline data sets.  For example, for what random classes of graphs is the RQ approach well founded?  This could be studied through simulation and theory.  \n\nSection 4.1: Perhaps you could say a little more about \u201cvarious chemical compounds and their reactions to different cancer cells\u201d, and how a chemical leads to a graph?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3058/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698854920035,
            "cdate": 1698854920035,
            "tmdate": 1699636250785,
            "mdate": 1699636250785,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZMr5ZLBdJJ",
                "forum": "4UIBysXjVq",
                "replyto": "p4Mp4BhNnd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response (1/2)"
                    },
                    "comment": {
                        "value": "We appreciate your comprehensive and constructive review. Your crucial comments on experiments are helpful for us to improve our manuscript. Our point-to-point responses to your comments are given below. \n\n---\n\n**W1**: The relation between Rayleigh quotient and perturbation is well known and studied, for example, in physics. For example: Pierre, C. (December 1, 1988). \"Comments on Rayleigh\u2019s Quotient and Perturbation Theory for the Eigenvalue Problem.\" ASME. J. Appl. Mech. December 1988; 55(4): 986\u2013988. When the vector is close to an eigenvector, then the RQ has a value that is close to the corresponding eigenvector. There is also the Rayleigh-Schr\u00f6dinger procedure that yields approximations to the eigenvalues and eigenvectors of a perturbed matrix by a sequence of successively higher order corrections to the eigenvalues and eigenvectors of the unperturbed matrix.\n\n**RW1**: Thanks for bringing that up. We acknowledge that the relation between Rayleigh Quotient and perturbation is well known and studied in physics. However, the inherent properties of the Rayleigh Quotient in the graph domain are still relatively under-explored. Furthermore, to the best of our knowledge, no previous work has considered using Rayleigh Quotient for the graph-level anomaly detection task. Our key observation of Rayleigh Quotient on graph-level anomaly detection as shown in Figure 1 in the original manuscript can provide a new direction for this under-explored field. We will ensure to cite these related papers in our revised manuscript. \n\n---\n\n**W2**: The paper explores an important application and datasets, and experimentally shows that the RQ provides a useful feature for detecting change. However, it isn\u2019t clear how general this is beyond the application considered. The anomaly here is a change detector between the baseline distribution (the normal graph class), and some deviation from this graph. Apparently for this data there is no clear class after change (so it isn\u2019t surprising that the graph classifiers don\u2019t work well).\n\n**RW2**: Thanks for the constructive suggestions. Indeed, although the main application of graph-level anomaly detection is typically focused on detecting chemical compounds, there are still applications in other domains such as social networks. However, due to the lack of datasets specifically collected for graph-level anomaly detection in other domains, we construct our own datasets and conduct experiments on them. To be comprehensive, we use two graph classification datasets to evaluate our RQGNN, one is COLORS-3 [1], which is a synthetic dataset in the TUDataset repository [2], and the other is DBLP_v1 [3], which is a social network dataset as classified in TUDataset [2]. \n\nSpecifically, we first conduct experiments on the COLORS-3 [1] dataset, which contains 11 classes. We use 10 classes to form normal graphs and use the remaining class as anomalous graphs. The experimental results are as follows: \n\n| Metrics |    RQGNN    |  iGAD  | HimNet |  GMT   | TVGNN  | BernNet | ChebyNet |\n| :-----: | :--------: | :----: | :----: | :----: | :----: | :-----: | :------: |\n|   AUC   | **0.9378** | 0.7385 | 0.5129 | 0.5063 |  0.5000   | 0.6136  |  0.6192  |\n|   F1    | **0.7640** | 0.5301 | 0.5934 | 0.4764 | 0.4764 | 0.4764  |  0.4764  |\n\nThen, we conduct additional experiments in the social network domain using the DBLP_v1 [3] dataset, which is a well-balanced social network classification dataset in the field of computer science. In this dataset, each graph denotes a research paper belonging to either DBDM (database and data mining) or CVPR (computer vision and pattern recognition) field, where each node denotes a paper ID or a keyword and each edge denotes the citation relationship between papers or keyword relations in the title. To create a new graph-level anomaly detection dataset, we randomly sample 5% of one class as the anomaly class and use the other class as the normal class. The experimental results are as follows: \n\n| Metrics |    RQGNN    |  iGAD  | HimNet |  GMT   | TVGNN  | BernNet | ChebyNet |\n| :-----: | :--------: | :----: | :----: | :----: | :----: | :-----: | :------: |\n|   AUC   | **0.8808** | 0.7346 | 0.6656 | 0.8234 | 0.8455 | 0.8549  |  0.8369  |\n|   F1    | **0.7709** | 0.6648 | 0.6133 | 0.4877 | 0.6449 | 0.4877  |  0.5472  |\n\nCompared with other baseline models, our proposed RQGNN achieves significant improvements in both AUC and F1 scores in these two new domains, which demonstrates the effectiveness of our RQGNN in detecting anomalies beyond the application considered.\n\n[1] Boris Knyazev, Graham W. Taylor, Mohamed R. Amer. Understanding attention and generalization in graph neural networks. NeurIPS, pages 4204-4214, 2019.\n\n[2] https://chrsmrrs.github.io/datasets/docs/datasets/\n\n[3] Shirui Pan, Xingquan Zhu, Chengqi Zhang, and Philip S. Yu. Graph Stream Classification using Labeled and Unlabeled Graphs, ICDE, pages 398-409, 2013.\n\n---"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3058/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700401307990,
                "cdate": 1700401307990,
                "tmdate": 1700401307990,
                "mdate": 1700401307990,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EuXgo2dPOC",
                "forum": "4UIBysXjVq",
                "replyto": "p4Mp4BhNnd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response (2/2)"
                    },
                    "comment": {
                        "value": "**Q1**: Given the large literature on RQ\u2019s it seems likely that eqn (1) is well known?\n\n**RQ1**: Yes. We acknowledge that the relation between Rayleigh Quotient and perturbation is well known and studied in physics. However, the inherent properties of the Rayleigh Quotient in the graph domain are still relatively under-explored. Furthermore, to the best of our knowledge, no previous work has considered using Rayleigh Quotient for the graph-level anomaly detection task. Our key observation of Rayleigh Quotient on graph-level anomaly detection as shown in Figure 1 in the original manuscript can provide a new direction for this under-explored field.\n\n---\n\n**Q2**: Lemma 1 and leading to eqn (4), using L \u2013 I_n to compute is from Rivlin or some other reference?\n\n**RQ2**: The theory of Chebyshev\u2019s series comes from Rivlin et al. [4], and the Eqn. 4 is mainly from Hammond et al. [5]. We will cite this paper in our revised manuscript. \n\n[4] GTheodore J. Rivlin. The Chebyshev polynomials. John Wiley & Sons, 1974.\n\n[5] Hammond D K, Vandergheynst P, Gribonval R. Wavelets on graphs via spectral graph theory[J]. Applied and Computational Harmonic Analysis, 2011, 30(2): 129-150.\n\n---\n\n**Q3**: Section 4.5 (and throughout the paper). \u201cRayleigh Quotient is an intrinsic characteristic of the graph-level anomaly detection task.\u201d Should this be altered to say \u201cfor the application studied\u201d? How general is the claim?\n\n**RQ3**: We admit that we should add the description to weaken the claim and we have revised the description as \u201cRayleigh Quotient is an intrinsic characteristic of the graph-level anomaly detection task for the application studied\u201d. However, in addition to its application in detecting chemical compounds, Rayleigh Quotient can also be applied in various other domains such as social network areas.  Please refer to **RW2** for more details. \n\n---\n\n**Q4**: Isn\u2019t the anomaly for this application the same as an \u201cout of distribution\u201d test?\n\n**RQ4**: Not exactly, there are notable distinctions between anomaly detection and out-of-distribution detection. \n\nTypically, in out-of-distribution datasets, we only have one class called in-distribution data, so out-of-distribution detection focuses on determining whether a new sample belongs to the in-distribution data. However, anomaly datasets usually contain data with two distinct characteristics. Therefore, anomaly detection aims to determine that a new sample belongs to one of the two classes. \n\nFor example, anomaly detection involves identifying all the tigers from a dataset that contains both cats and tigers, whereas out-of-distribution detection focuses on determining whether a new cat sample, such as a Birman cat, can be correctly classified as a cat given training dataset that exclusively contains Ragdoll cats. \n\n---\n\n**Q5**: It seems this area of study would benefit from good baseline data sets. For example, for what random classes of graphs is the RQ approach well founded? This could be studied through simulation and theory.\n\n**RQ5**: We conduct additional experiments on both a synthetic dataset and a social network classification dataset. For more detailed information regarding these experiments, please refer to **RW2**.\n\n---\n\n**Q6**: Section 4.1: Perhaps you could say a little more about \u201cvarious chemical compounds and their reactions to different cancer cells\u201d, and how a chemical leads to a graph?\n\n**RQ6**: The raw data is collected from the PubChem website [6]. This website provides comprehensive information on the biological activities of small molecules, including bioassay records for anti-cancer screen tests with different cancer cell lines. Each dataset corresponds to a specific type of cancer screen with the outcomes categorized as either active or inactive, where the active instances are labeled as 1 and the inactive ones are labeled as 0. Please refer to the Appendix for detailed information on the specific tumor associated with each dataset. \n\nTo represent the chemical compounds as graphs, we can consider the atoms in the chemical compounds as nodes, and the chemical bonds between two atoms as edges. Therefore, each chemical compound can be represented as a graph. \n\nWe will include these discussions in the Appendix of our revised manuscript.\n\n[6] http://pubchem.ncbi.nlm.nih.gov.\n\n---\n\nWe sincerely appreciate your time, and we are glad to answer any additional questions you may have."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3058/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700401516721,
                "cdate": 1700401516721,
                "tmdate": 1700401516721,
                "mdate": 1700401516721,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uBGEEZkusl",
                "forum": "4UIBysXjVq",
                "replyto": "u7DubzDhmp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3058/Reviewer_qWnD"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3058/Reviewer_qWnD"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarifications and the additional numerical experiments.  \n\nWhile \"out of distribution\" seems easy for common understanding, defining an anomaly might easily differ from author to author.  Perhaps include a sentence or two as in your response to help the reader.\n\nI still believe Q5 above is an important theoretical question that also gets to generality.  It seems the key question is how much perturbation is detectable, starting with some given graph class.  And has this problem been studied, given the large literature in physics, statistics, and signal processing."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3058/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700428400030,
                "cdate": 1700428400030,
                "tmdate": 1700428400030,
                "mdate": 1700428400030,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rnyhKT18Mf",
                "forum": "4UIBysXjVq",
                "replyto": "p4Mp4BhNnd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We would like to express our gratitude for your valuable comments"
                    },
                    "comment": {
                        "value": "We sincerely hope that we have addressed your concerns satisfactorily, and we will gladly answer any additional questions you may have."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3058/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700617948335,
                "cdate": 1700617948335,
                "tmdate": 1700617948335,
                "mdate": 1700617948335,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RxVVcI4aUV",
                "forum": "4UIBysXjVq",
                "replyto": "p4Mp4BhNnd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3058/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Update for the response of Q5"
                    },
                    "comment": {
                        "value": "---\n\n**Q5**: It seems this area of study would benefit from good baseline data sets. For example, for what random classes of graphs is the RQ approach well founded? This could be studied through simulation and theory.\n\n**RQ5**: To further address your concern, we show how much perturbation is detectable by RQGNN by simulation. We use SN12C to create 5 new synthetic datasets. Specifically, we first randomly select 5% of normal graphs to perform perturbations. For these graphs, each edge is changed with probability $p$, where $p=0.05, 0.10, 0.15, 0.20,$ or $0.25$. Then we use these perturbed samples as anomalous graphs and all the remaining 95% normal graphs in SN12C to construct these five new datasets. We present the results in the following table:\n\n| Metrics |   0.05  |  0.10 | 0.15 |  0.20  | 0.25 |\n| :-----: | :--------: | :----: | :----: | :----: | :----: | \n|   AUC   | 0.6525 | 0.7592 | 0.9736 | 0.9884 |  0.9798   | \n|   F1    | 0.6966 | 0.8126 | 0.9113 | 0.9471 | 0.9623 | \n\nAs we can see from the table, Even if the perturbation probability is only 0.05, RQGNN can still achieve a reasonable result. When the probability of perturbation reaches 0.15, our RQGNN achieves AUC around 1 and F1 over 0.9, which means RQGNN can nicely distinguish the two classes. \n\n---\n\nWe sincerely hope that we have addressed your concerns satisfactorily, and we will gladly answer any additional questions you may have."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3058/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700731224740,
                "cdate": 1700731224740,
                "tmdate": 1700731224740,
                "mdate": 1700731224740,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]