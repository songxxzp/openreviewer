[
    {
        "title": "Fairness Through Matching for better group fairness"
    },
    {
        "review": {
            "id": "GAczl5BBAo",
            "forum": "3IyC5lQTSi",
            "replyto": "3IyC5lQTSi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4999/Reviewer_9FFn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4999/Reviewer_9FFn"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a refined group fairness regularization through matchings. Specifically, they introduce matched demographic parity, which treats individuals in the same demographic group more fairly."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The authors present a novel method, which is interesting and performs well. In addition, they propose a sound and detailed theoretical analysis of the methods."
                },
                "weaknesses": {
                    "value": "Two main limitations of the proposed work and presentation stand out:\n- Regarding the motivation. Subgroup discrimination is indeed a problem of Group-Fairness approaches. However, since you do not require any specific structure of the matching, it seems that you also enforce non-discrimination against features for which we want to discriminate. Take for example $X=[gender, race, skill]$ is a job application. If I apply matched group fairness on gender, then I agree that this should not lead to discrimination against e.g. african american woman. However, I am very happy with discriminating agains unskilled workers. Could you please explain how your approach would work in this case?\n- While motivated from the side of group fairness, your approach has many relations to individual fairness. Specifically, (Step 1) identifies \"similar\" individuals while (Step 2) requires the \"similar individuals\" to be treated similarly by the classifier. I see that the \"similar individuals\" in step 2 are synthetic, but I still believe that the relation to individual fairness ought to be discussed."
                },
                "questions": {
                    "value": "Some questions and comments in the order they appear in the paper:\n- In the first paragraph of section 3.2, you use $\\|\\cdot\\|^2$ to find the OT map. Which distance do you choose, and how is the performance influenced by (a) the distance and (b) the preprocessing? (no need to run experiments, I would just like to understand it better)\n- Figure 4 is quite small. If you find some space increasing the size would be nice"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4999/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4999/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4999/Reviewer_9FFn"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4999/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698662779898,
            "cdate": 1698662779898,
            "tmdate": 1699636487591,
            "mdate": 1699636487591,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LcOFoPBFKf",
                "forum": "3IyC5lQTSi",
                "replyto": "GAczl5BBAo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4999/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4999/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Point-by-point reply"
                    },
                    "comment": {
                        "value": "> **W1**:\nRegarding the motivation. Subgroup discrimination is indeed a problem of Group-Fairness approaches. However, since you do not require any specific structure of the matching, it seems that you also enforce non-discrimination against features for which we want to discriminate. Take for example $X=[gender, race, skill]$ is a job application. If I apply matched group fairness on gender, then I agree that this should not lead to discrimination against e.g. african american woman. However, I am very happy with discriminating agains unskilled workers. Could you please explain how your approach would work in this case?\n\n**Response:**\nIn the above example, when the model trained by FTM with $S=gender$ similarly treats a man and a corresponding matched woman, whose skill levels are similar (also having similar race attributes), it is because the matching function searches for such pairs of a man and a woman with similar features.\nThat is, the matching function has **a structure of finding the most similar pairs with respect to given features between two sensitive groups.**\n\nWhen $gender$ and $skill$ are independent, a group-fair learned by FTM can **freely discriminate individuals based on $skill$** since it does not affect the fairness of FTM at all. \nHowever, whey they are dependent, we should be careful because discrimination based on $skill$ may lead to discrimination based on $gender$. \nFTM is designed to minimize the effect of discrimination based on $skill$ to discrimination based on $gender$.\nThe concept of the OT map is used for this purpose.\n\n> **W2**:\nWhile motivated from the side of group fairness, your approach has many relations to individual fairness. Specifically, (Step 1) identifies \"similar\" individuals while (Step 2) requires the \"similar individuals\" to be treated similarly by the classifier. I see that the \"similar individuals\" in step 2 are synthetic, but I still believe that the relation to individual fairness ought to be discussed.\n\n**Response:**\nA clear difference between our proposed approach and the individual fairness is that\n- our proposed approach aims to treat two individuals similarly **from different sensitive groups only** in order to achieve group fairness,\n- while the individual fairness requires to treat similar individuals similarly **regardless of sensitive attribute** (even when it is unknown).\n\nThat is, similar individuals in FTM can be dissimilar in view of individual fairness, especially when the two sensitive groups are significantly different.\n\nEven though similar individuals in FTM can be dissimilar from those in view of individual fairness, we observed that FTM improves individual fairness compared to other strong group-fair models (e.g., FRL methods).\nWe included this additional discussion and related empirical results in the revision (Section C.6).\n\n> **Q1**:\nIn the first paragraph of section 3.2, you use $\\vert \\cdot \\vert^{2}$ to find the OT map. Which distance do you choose, and how is the performance influenced by (a) the distance and (b) the preprocessing? (no need to run experiments, I would just like to understand it better)\n\n**Response:**\n\n- (a) Distance: We use the Euclidean distance ($L_{2}$) as the cost function when finding the (relaxed) OT map,\nas many previous works have used it with some theoretical guarantees (Seguy et al., 2018; Yang & Uhler, 2019; Hutter & Rigollet, 2021).\nIn the paper, we denoted it as $\\Vert \\cdot \\Vert^{2}.$\nFurthermore, in practice, we observed that learning the OT map with the $L_{2}$ distance tends to yield more stable results compared to the $L_{1}$ distance.\n\n- (b) Preprocessing: \nPreprocessing is necessary to make the scales of all features similar.\nThis is indispensable since the scales have a significant impact on the transport cost.\nExcept for the scaling, we observed that FTM is not significantly sensitive to other data preprocessing techniques (e.g., handling outliers).\nThe reported performances in this paper were computed only using the standardization.\n\n> **Q2**:\nFigure 4 is quite small. If you find some space increasing the size would be nice\n\n**Response:**\nThank you for the suggestion.\nFor better readability, we selected one dataset (Adult) and increased its size in the revision. \nYou can still find the remaining results in Figure 6 in Section E.2 of the Appendix."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4999/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700461744847,
                "cdate": 1700461744847,
                "tmdate": 1700461744847,
                "mdate": 1700461744847,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EHKf5tWvDE",
                "forum": "3IyC5lQTSi",
                "replyto": "LcOFoPBFKf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4999/Reviewer_9FFn"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4999/Reviewer_9FFn"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your clarifications"
                    },
                    "comment": {
                        "value": "I thank the authors for their clarifications. I would like to retain my score."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4999/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700473223387,
                "cdate": 1700473223387,
                "tmdate": 1700473223387,
                "mdate": 1700473223387,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "zF7dCJEeKZ",
            "forum": "3IyC5lQTSi",
            "replyto": "3IyC5lQTSi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4999/Reviewer_diD4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4999/Reviewer_diD4"
            ],
            "content": {
                "summary": {
                    "value": "The authors introduce an algorithm to find models which satisfy both group fairness and within-group fairness called FTM or fairness through matching. This algorithm uses a new group fairness measure called MDP or matched demographic parity. They provide theoretical justification as well as some empirical results."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The authors provide good theoretical justification for their algorithm.\nThe authors provide some empirical results that show better performance to other similar methods - with fewer outliers when looking at subset fairness (or group fairness)."
                },
                "weaknesses": {
                    "value": "The language in the paper is hard to follow. Both grammatically as well as inconsistencies in terms used throughout the paper. The authors should be sure to update grammar throughout the paper (for example \"a group fair model that less discriminates subsets or individuals in the same sensitive group\" -> a group fairness model that discriminates less between subsets or individuals in the same sensitive group), as well as making sure their terminology throughout the paper is consistent (example: group fairness, subset fairness).\n\nUnless I missed it in the proofs of the appendix, it is not made clear why MDP is necessary, and why total variation, strong demographic parity, or 1-Wasserstein distances should not be used. The authors provide the similarity between the measures but do not clearly state why MDP is important.\n\nThe authors make the claim that one of their contributions is the new group fairness measure MDP, but state in section 3.4 that Black et al. (2020) employs the MDP constraint. Could the authors please clarify if and how their MDP definition is different from the earlier paper.\n\nThe plots in the paper are not at all readable with very small text.\n\nThis paper seems incremental in nature, being very close to FRL, Gorsaliza et al, and pulls together techniques from other areas.\n\nMinor nits:\nIt would be good to include the accuracy table in the main paper."
                },
                "questions": {
                    "value": "Please see the questions associated with \"Weaknesses\" above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4999/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4999/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4999/Reviewer_diD4"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4999/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698799049441,
            "cdate": 1698799049441,
            "tmdate": 1699636487485,
            "mdate": 1699636487485,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "rdmtHav72H",
                "forum": "3IyC5lQTSi",
                "replyto": "zF7dCJEeKZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4999/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4999/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Point-by-point reply (1)"
                    },
                    "comment": {
                        "value": "> **W1**:\nThe language in the paper is hard to follow. Both grammatically as well as inconsistencies in terms used throughout the paper. The authors should be sure to update grammar throughout the paper (for example \"a group fair model that less discriminates subsets or individuals in the same sensitive group\" -> a group fairness model that discriminates less between subsets or individuals in the same sensitive group), as well as making sure their terminology throughout the paper is consistent (example: group fairness, subset fairness).\n\n**Response:**\nWe apologize for the poor English. \nWe tried our best to enhance the readability in the revision. \nIn particular, a native English colleague proofread our manuscript. \nHowever, the contents of our manuscript are highly technical, and thus proofreading by a non-expert may be insufficient. \n**Your understanding would be greatly appreciated.**\n\n> **W2**:\nUnless I missed it in the proofs of the appendix, it is not made clear why MDP is necessary, and why total variation, strong demographic parity, or 1-Wasserstein distances should not be used. The authors provide the similarity between the measures but do not clearly state why MDP is important.\n\n**Response:**\nFor a given $f \\in \\mathcal{F}^{\\textup{MDP}} (\\delta),$ we define $ \\mathbf{T}\\_{s}^{f} = argmin_{\\mathbf{T}\\_{s} \\in \\mathcal{T}\\_{s, 0}} \\mathbb{E}\\_{s} \\vert f( \\mathbf{X}, s ) - f( \\mathbf{T}\\_{s}(\\mathbf{X}), s' ) \\vert $ as the corresponding matching function (Section 3).\n\nWe would like to remind that the aim of this paper is to eliminate undesirable and problematic group-fair models  (e.g., subset unfairness, within-group unfairness).\nTo achieve this objective, we discard $f \\in \\mathcal{F}^{\\textup{MDP}} (\\delta)$ those whose corresponding matching function ($\\mathbf{T}_{s}^{f}$) has too large transport cost (Section 3.2).\n\nIn contrast, **such restriction would not be possible for the total variation or 1-Wasserstein distance**, at least to the best of our knowledge. \nTo us, it was surprising that MDP is similar to strong demographic parity with respect to the total variation or 1-Wasserstein distance (i.e., Proposition 2.1), because any distance between the distributions of two sensitive groups is not explicitly used in the definition of MDP.\n\n> **W3**:\nThe authors make the claim that one of their contributions is the new group fairness measure MDP, but state in section 3.4 that Black et al. (2020) employs the MDP constraint. Could the authors please clarify if and how their MDP definition is different from the earlier paper.\n\n**Response:**\nWe apologize for the rough and insufficient description of FlipTest (Black et al. (2020)).\nWe did not pay much attention to FlipTest because it is not used for learning group-fair model.\nIndeed, the measure used in FlipTest is similar to the MDP constraint, but they are not exactly the same.\nBelow, we explain how **the measures for FlipTest and the MDP constraint are fundamentally different.**\n\nFor a given prediction model $f$ and $s \\in \\{0, 1\\},$ FlipTest first finds two sets of individuals whose predictions are flipped, as defined by\n$ F\\^{+}(f; s) := \\\\{ i : s_i = s, \\mathrm{I} ( f(\\mathbf{x}_i, s) > 0 ) > \\mathrm{I}( f(\\hat{\\mathbf{T}}\\_{s}(\\mathbf{x}_i), s') > 0 ) \\\\} $ \nand\n$ F\\^{-}(f; s) := \\\\{ i : s_i = s, \\mathrm{I} ( f(\\mathbf{x}_i, s) > 0 ) < \\mathrm{I} ( f(\\hat{\\mathbf{T}}\\_{s}(\\mathbf{x}_i), s') > 0 ) \\\\}, $\nwhere $\\hat{\\mathbf{T}}_s, s \\in \\\\{ 0,1 \\\\}$ are the OT map.\nUsing these sets, FlipTest measures the unfairness of $f$ as $|F\\^{+}(f; s)| - |F\\^{-}(f; s)|$.\n\nOne may argue that our proposed constraint ($REG_{s}(f)$ in STEP 2) is similar to $|F\\^{+}(f; s)| - |F\\^{-}(f; s)|$ from FlipTest.\nHowever, it is not the case because the regularization term induced by FlipTest would be formulated as:\n$\n\\left\\vert \\mathbb{E}\\_{n, s} \\left( \\mathrm{I}( f(\\mathbf{X}, s) > 0 )\\right) - \\mathbb{E}\\_{n, s} \\left( \\mathrm{I} ( f(\\hat{\\mathbf{T}}\\_{s}(\\mathbf{X}), s') > 0 ) \\right) \\right\\vert\n$\nor\n$\n\\left\\vert \\mathbb{E}\\_{n, s} \\left( f(\\mathbf{X}, s)\\right) -  \\mathbb{E}\\_{n, s} \\left(f(\\hat{\\mathbf{T}}_{s}(\\mathbf{X}), s') \\right) \\right\\vert,\n$\nwhich is completely different from our regularization term:\n$ REG\\_{s}(f) = \\mathbb{E}\\_{n, s} \\vert f(\\mathbf{X}, s) - f(\\hat{\\mathbf{T}}\\_{s}(\\mathbf{X}), s') \\vert. $\n\n**The former (FlipTest) is the difference of the expectations, while the latter (FTM) is the expectation of the (absolute) differences.**\nThis seemingly tiny difference would make big differences in many ways.\nFor example, the measure of **FlipTest would not imply the strong group fairness, while our regularization term does** (i.e., Proposition 2.1).\nMoreover, it would **not be clear whether the measure of FlipTest improves better subset/within-group fairness.**\n\nIn conclusion, the only thing FlipTest and MDP share is the use of the OT map, but they are fundamentally different. \nWe added these additional explanation in the revision."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4999/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700461623213,
                "cdate": 1700461623213,
                "tmdate": 1700612358152,
                "mdate": 1700612358152,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nJbrjglqo5",
                "forum": "3IyC5lQTSi",
                "replyto": "zF7dCJEeKZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4999/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4999/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Point-by-point reply (2)"
                    },
                    "comment": {
                        "value": "> **W4**:\nThe plots in the paper are not at all readable with very small text.\n\n**Response:**\nWe have made modifications in the revision by increasing the font sizes to improve readability (Figures 3 and 4).\n\n> **W5**:\nThis paper seems incremental in nature, being very close to FRL, Gorsaliza et al, and pulls together techniques from other areas.\n\n**Response:**\nThe key contribution of this paper is to verify the theoretical properties of MDP, including its relationship with existing well-known group fairness measures, including the strong demographic parity with respect to the total variation and 1-Wasserstein distance (Proposition 2.1).\nIn addition, we showed that **FTM can improve subset and within-group fairness (Sections 3.2 and 4.2).**\n\nSimilarity between FTM and FRL is **a kind of coincidence**, since the motivations of these two approaches are quite different.\nFRL methods have been developed to obtain fair representations which can be used for downstream tasks.\nIn contrast, FTM is developed to eliminate undesirable group-fair models, specifically subset/within-group unfair models. \n\nOur empirical results amply illustrate that **FTM does improve subset/within-group fairness compared to FRL methods**. \nIn our numerical studies, we compared FTM with FRL not only because FTM can be interpreted as a FRL algorithm but also because the both methods can learn strongly group-fair models.\nAdditionally, there are other advantages of FTM over FRL, which are highlighted in Section 4.3.\n\n> **W6**:\nMinor nits: It would be good to include the accuracy table in the main paper.\n\n**Response:**\nThank you for the suggestion.\nFollowing your thoughtful suggestion, we added the table showing the relative changes of accuracy in the revision (Table 2)."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4999/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700461658448,
                "cdate": 1700461658448,
                "tmdate": 1700551456696,
                "mdate": 1700551456696,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]