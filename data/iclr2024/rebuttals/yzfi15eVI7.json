[
    {
        "title": "iHyperTime: Interpretable Time Series Generation with Implicit Neural Representations"
    },
    {
        "review": {
            "id": "DDMfQU2hAx",
            "forum": "yzfi15eVI7",
            "replyto": "yzfi15eVI7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8397/Reviewer_y35Q"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8397/Reviewer_y35Q"
            ],
            "content": {
                "summary": {
                    "value": "This paper uses INRs to synthesize time series data. The synthesized time series is an addition of three parts: trend, seasonality and residual components. A hyper network is used to generate parameters of each part given different data. The training of iHyperTime is performed in three stages, in order to improve stability"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The idea is simple and should work well. \n2. Experimental results are promising.\n3. The model supports interpretability."
                },
                "weaknesses": {
                    "value": "1. The author claims that \"a single layer SIREN has been shown to be structurally similar to a Fourier mapped\nperception (FMP)\". I am not clear whether the author use SIREN (equation 4) or FMP (equation 5) to implement fr(t) in the paper.\n\n2. If f(t) is multidimensional, does the author model each dimension as ftr(t) + fs(t) + fr(t) independently?\n\n3. How does the proposed model achieve unconditional generation? The proposed model requires {t, f(t)} as input to synthesize time series. However, how can the model synthesize new samples without {t, f(t)}?\n\n4. It would be better to cite Deep Sets when discussing the set encoder."
                },
                "questions": {
                    "value": "None"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8397/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697500180343,
            "cdate": 1697500180343,
            "tmdate": 1699637045879,
            "mdate": 1699637045879,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4MWA1rUm3L",
                "forum": "yzfi15eVI7",
                "replyto": "DDMfQU2hAx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8397/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8397/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## Weaknesses\nWe thank the reviewer for their comments and suggestions. We hope they find our answers useful, and we are happy to answer any additional questions.  \n\n### **W.1.**\n\nWe apologize for the lack of clarity in the description of the method. TSNet uses a SIREN to model the Residual component, and a Fourier decomposition to model the Seasonality component. We do not actually use a Fourier mapped perceptron (FMP), and we corrected the related section. In particular, we have rewritten all Section 3.1.1 to provide a more concise and clear explanation of the TSNet architecture.\n\n### **W.2.**\n\nWe thank the reviewer for raising this question. If f(t) is multidimensional, iHT models each dimension as $f_T(t) + f_S(t) + f_R(t)$ independently. Following an $m$-dimensional time series, the trend block outputs $m$ trends, the seasonality block outputs $m$ time series that correspond to the seasonality of each feature, and the same is for the residual block. Each of the features are then added together obtaining an $m$-dimensional time series.\n\n### **W.3.**\n\nWe apologize for the lack of clarity in the description of the generation mechanism. The model does require samples of time series to generate a new one. Generation of new time series is produced by randomly selecting pairs of time series, and performing linear a interpolation between their embeddings $Z^{(1)}$ and $Z^{(2)}$:\n$$\n        Z^{\\text{gen}} = Z^{(1)} + \\lambda (Z^{(2)} - Z^{(1)})\n$$\n    where $\\\\lambda$ is also sampled randomly. Optionally, the interpolation can be performed on individual components $Z_T$, $Z_S$, $Z_R$ of the embeddings, enabling the conditional generation of time series. \n\nIn the current setting the model cannot synthesize new samples without {t, f(t)}. This could be achieved in a variational setting or by incorporating adversarial training, which we plan for a future work. We have now refactored Section 3.2 of the main paper to include more details on the generative process.\n\n\n### **W.4.**\n\nWe thank the reviewer for the suggested reference, we have now cited Deep Sets in the revised paper version, in the set encoder subsection in Section 3.2."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8397/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700319420735,
                "cdate": 1700319420735,
                "tmdate": 1700319420735,
                "mdate": 1700319420735,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lVM3JMtdwP",
                "forum": "yzfi15eVI7",
                "replyto": "4MWA1rUm3L",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8397/Reviewer_y35Q"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8397/Reviewer_y35Q"
                ],
                "content": {
                    "title": {
                        "value": "thanks for clarification"
                    },
                    "comment": {
                        "value": "I believe W2 and W3 are two major weakness of the proposed method. For W2, this model doesn't consider the influence from other dimensions. For W3, this method can't achieve unconditional generation. Therefore I keep my score."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8397/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700464435796,
                "cdate": 1700464435796,
                "tmdate": 1700464435796,
                "mdate": 1700464435796,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Y5xCGI9fGU",
            "forum": "yzfi15eVI7",
            "replyto": "yzfi15eVI7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8397/Reviewer_3ERW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8397/Reviewer_3ERW"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes to use implicit neural representations / coordinate-based neural networks to model time series data. The proposed method decomposes time series into season, trend, and residual components, and leverages a hypernetwork to predict the coefficients of the season, trend, and residual basis functions. The proposed method is applied on time series generation tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper introduces an interesting new method for time series generation based on implicit neural representations with the added benefit of seasonal-trend-residual decomposition. Empirical and qualitative experiments show significant improvement over baselines."
                },
                "weaknesses": {
                    "value": "The writing is currently very unclear and is unable to convey the critical ideas of the paper.\n\n1. How is the model used to perform generation? Based on the writing, I am unable to understand how this formulation, which requires taking data as input with the set encoder, can be used for unconditional generation of new time series.\n2. The paragraph on __Residual blocks__ in Section 3.1.1 does not make sense at all. Why is it describing the seasonal component, \"In this work, we propose to model the seasonal component of the time series as a ...\", which was already addressed in the previous paragraph? The notation is suddenly changed from $t$ to $x$? Why talk about random Fourier features if the paper proposes to use SIREN? I do not understand what is the implemented/proposed model for the residual component after reading this paragraph.\n3. What are the details of the hypernetwork component/iHyperTime architecture? More details with mathematical description needs to be given for this part. How is the Set Encoder and SIREN layers used here? Details of the hypernetwork are not given.\n4. Important details on problem formulation and training are not included. Concretely, what are the time coordinates $t_i$? For long sequences, is the whole time series encoded into a set, or divided into windows? Section 4.2 states \"Performance results for regularly sampled time series are provided in Table 1, for univariate and multivariate datasets of varying lengths.\" -- which datasets are univariate, which are multivariate? What are the varying lengths? How do I interpret 24/72/360 in Table 1?\n\nI would be happy to increase my score to \"marginal accept\" if writing is improved, and to \"accept\" if more evidence is presented on interpretability of real world data."
                },
                "questions": {
                    "value": "1. Is the model actually able to disambiguate between season, trend, and residual in an interpretable manner for real world data? Can you visualize the seasonal-trend decomposition on real world datasets with strong seasonality/trend?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8397/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8397/Reviewer_3ERW",
                        "ICLR.cc/2024/Conference/Submission8397/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8397/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698637157834,
            "cdate": 1698637157834,
            "tmdate": 1700474559701,
            "mdate": 1700474559701,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oIi6Ru6pFB",
                "forum": "yzfi15eVI7",
                "replyto": "Y5xCGI9fGU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8397/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8397/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the suggestions. We acknowledge that the paper presentation was not clear enough. In the new version of the paper we extensively rewrite section 3, and we have colored the rewritten parts in blue to highlight the modifications/additions. \nAs suggested, we have also evaluated our approach on three real datasets, showing that the model is able to disambiguate between season, trend, and residual in an interpretable manner for real world data. \n\nI hope the reviewer finds our results useful in assessing the quality of our work. We are happy to answer any additional questions.\n\n## **Weaknesses** \n\n### **W.1**\n  We apologize for the lack of clarity in the description of the generative method. In the main paper we have now added a subsection at the end of section 3.2 explaining how we perform generation. Generation of new time series is produced by randomly selecting pairs of time series from the training-set, and performing a linear interpolation between their embeddings $Z^{(1)}$ and $Z^{(2)}$:\n    $$ Z^{\\\\text{gen}} = Z^{(1)} + \\\\lambda (Z^{(2)} - Z^{(1)}) $$\nwhere $\\\\lambda$ is also sampled randomly. Optionally, the interpolation can be performed on individual components $Z_T$, $Z_S$, $Z_R$ of the embeddings, enabling the conditional generation of time series. \n\n\n### **W.2**\nWe apologize for the mistake in explaination of the seasonal component: when we said \"seasonal\" we should have said \"residual\". \n\n**Change of notation** In the trend and seasonality networks, we used $t$ because there is a single layer. And in residual, we used $x$ to indicate the outputs of the successive layers. We should have clarified this, also stating that $x_0 = t$. We have now rewritten this section ensuring consistency of the notation.\n\n**Random Fourier Features** We apologize for the lack of clarity in this aspect. Our initial goal was to convey that using SIRENs or random Fourier Features was equivalent w.r.t. having a good representation of frequencies in the signal, following [1]. However, we agree that this leads to confusion. We have now revised Section 3.1.1 to clarify this and we removed any misleading statements about Fourier Features Networks (FFNs).\n\n[1] Benbarka, Nuri et al. \u201cSeeing Implicit Neural Representations as Fourier Series.\u201d 2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) (2021).\n\n\n### **W.3**\nWe thank the reviewer for pointing out an important missing aspect. We have now included two subsections in Section 3.2 detailing how the set encoder and hypernetworks are used. For the Set encoder we have provided a mathematical description and how it is parameterized using SIREN layers. We have provided implementation details in Section D.2 of the appendix, which is now referred in the main paper. Furthermore, in section D.2 we have also added more information on how the Set Encoder is used, and provided more details about the hypernetwork architecture."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8397/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700314686309,
                "cdate": 1700314686309,
                "tmdate": 1700314686309,
                "mdate": 1700314686309,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "i7yMOfTQ0C",
                "forum": "yzfi15eVI7",
                "replyto": "Y5xCGI9fGU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8397/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8397/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "### **W.4.**\n\nWe thank the reviewer for pointing out aspects that were not clearly explained in the paper.\n\n**Time coordinate.** In our model, we use a single floating point value as temporal coordinate (time $t$). As data pre-processing, all the values are scaled to the interval $[-1, 1]$, with a common global factor for all time series of a dataset. In all cases, regardless of sequence length, the time series is fed to the set encoder as a single set, and is hence converted into a single embedding $Z$. We have now included this information in Appendix D.2.\n    \n**Datasets.** Following previous methods [1, 2, 3], we used the Stock and Energy datasets [5] sliced into 24 time-steps windows. These datasets are multivariate, with 6 and 28 features, respectively. Furthermore, in order to make a fair comparison with  [3] and  [4], who show performances in longer time series of Stock data, we generated an univariate version of the Stock dataset by selecting one single feature (Close Price), and slicing it in two ways: using a window of 72 time steps (Stock72), and a window of 360 time steps (Stock 360).\n\nAdditionally, in Section 4.4 we consider 4 univariate datasets with longer real-world time-series from Monash repository [6], namely FRED-MD, NN5 Daily, Temperature Rain, and Solar Weekly. The first three datasets have time series of approx. $750$ time steps, while the last one contains time series of length $52$. This information is summarized in Appendix B, where Table 8 presents the main characteristics of each dataset. We have improved this table to clarify the difference between the different datasets, in terms of sequence length and number of channels. And we refer this table in Section 4.1 of the main paper.\n    \nFinally, in Section 4.3 we evaluate our method on irregular data. Following existing literature [2], we create irregular time-series datasets by randomly dropping 30, 50, 70\\% of observations from the original datasets. We select each observation to drop uniformly at random, and independently for each time series $\\{(t_i, y_i)\\}_{i=0}^N$ in the original dataset. \n\n- [1] J. Yoon, D. Jarrett, M. van der Schaar. Time-series generative adversarial networks. In NeurIPS, 2019.\n\n- [2] J. Jeon, J. Kim, H. Song, S. Cho, N. Park. GT-GAN: General purpose time series synthesis with generative adversarial networks. In NeurIPS, 2022.\n\n- [3] A. Coletta, S. Gopalakrishan, D. Borrajo, S. Vyetrenko. On the constrained time-series generation problem. In NeurIPS, 2023.\n\n- [4] A. Alaa, A. Chan, M. van der Schaar. Generative time-series modeling with fourier flows. In ICLR, 2021.\n\n- [5] L. Candanedo, V. Feldheim, D. Deramaix. Data driven prediction models of energy use of appliances in a low-energy house. Energy and buildings, 140:81\u201397, 2017.\n\n- [6] R. Godahewa, C. Bergmeir, G. Webb, R. Hyndman, P. Montero-Manso. Monash time series forecasting archive. In NeurIPS, 2021."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8397/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700315150479,
                "cdate": 1700315150479,
                "tmdate": 1700315150479,
                "mdate": 1700315150479,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7xQPJf2PL3",
                "forum": "yzfi15eVI7",
                "replyto": "Y5xCGI9fGU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8397/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8397/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## Questions\n\n### **Q.1**\n\nWe thank the reviewer for suggesting an interesting new experiment. We have now conducted an analysis on three real world datasets to show that iHT is able to disambiguate between trend, season and residual components after training.\n\nThe new experiments are included in Section 1.6 of a new supplementary material, submitted along the main paper. We will add the experiments in the final version of the paper.\n    \n**Datasets** \n\nWe used two well known real-world time series datasets that exhibit strong seasonality and trend: Atmospheric CO2 and Airline Passenger, and used the Stock72 dataset described in section B of the supplementary material that exhibits strong trend but low seasonality.  \n\nThe Atmospheric CO2 dataset corresponds to monthly data (January 1959 to December 1987) with a total of 348 observations with a seasonality period of 12 [1]. We sliced the data into time series of sequence length 60, obtaining a total of 288 time series. \n\nThe Airline Passenger dataset corresponds to monthly data (January 1948 to December 1960) with a total of 144 observations with a seasonality period of 12 [2]. We sliced the data into time series of sequence length 36, obtaining a total of 108 time series. \n\nTo estimate the presence of trend and seasonality of each dataset we use two metrics defined in [3]: the strength of trend and strength of seasonality. As these datasets do not include ground-truth trend and seasonality, we estimate them using STL [1]. Given a time series with additive decomposition in trend, seasonality and residual:\n    $\n        y_t = T_t+ S_t + R_t\n   $\n , we can define the strength of trend as:  \n$$\n        F_T = \\max\\left(0, 1 - \\frac{\\text{Var}(R_t)}{\\text{Var}(T_t+R_t)}\\right)\n$$\n\nThis measures the relative variance of the residual component $R_t$ to the variance of the trend with the residual component. The value ranges from 0 to 1, with 0 indicating no trend and 1 indicating a strong trend.  \n\nStrength of seasonality is defined by:    \n$$\n        F_S = \\\\max\\\\left(0, 1 - \\\\frac{\\\\text{Var}(R_t)}{\\\\text{Var}(S_t+R_t)}\\\\right)\n$$\n Which measures the relative variance of the residual component $R_t$ to the variance of the seasonality with the residual component. A value close to 0 indicates little to no seasonality, and a value close to 1 indicates strong seasonality.\n\nTable below shows these metrics for the three datasets. As expected, Stock72 doesn't exhibit strong seasonality (as stock data usually have not such component), while the other two datasets exhibit strong trends and seasonality, with all values on average above 0.98.\n    \n$$\n\\\\begin{array}{cccc}\n\\\\hline\n\\\\text{Component} & \\\\text{CO2} & \\\\text{Air Pass} & \\\\text{Stock 72} \\\\\\\\ \\\\hline \n    \\\\text{Trend strength}   & 0.99 \\\\pm 0.01 & 0.98 \\\\pm0.01 & 0.99 \\\\pm 0.01 \\\\\\\\\n        \\\\text{Seasonal strength} &  0.99 \\\\pm 0.00 & 0.99 \\\\pm0.01  & 0.32 \\\\pm 0.09 \\\\\\\\    \n\\\\hline\n\\\\end{array}\n$$\n\n**Results**\n\nWe trained iHT on each dataset and we show in Figures 8 and 9 of the Supplementary the reconstructed time series and the output of each of the individual blocks for the CO2 and Air Passanger datasets, respectively. For the output of the trend, seasonality and residual block, we compare with the STL method. We observe that there is a good agreement in the trend and seasonality components in both datasets. The STL method requires as parameter the period of the seasonality, which is known for both datasets, while our approach is able to estimate the seasonality from the data. In the case of the Stock72 dataset, for the STL comparison, we estimated the period using a Fourier transform and retrieving the dominant frequency. Figure 10 of the supplementary shows the decomposition generated by iHT and compared against STL. We can see in this case that the seasonal component is quite small in magnitude compared to the residuals.\n    \nWe will include this new analysis on real-world data in the revised version of the manuscript. \n    \n[1] Cleveland, R. B., Cleveland, W. S., McRae, J. E. & Terpenning, I. (1990). STL: A Seasonal-Trend Decomposition Procedure Based on Loess (with Discussion). Journal of Official Statistics.\n\n[2] Downloaded from https://www.kaggle.com/datasets/rakannimer/air-passengers\n\n[3] Wang, X., Smith, K. A., & Hyndman, R. J. (2006). Characteristic-based clustering for time series data. Data Mining and Knowledge Discovery, 13(3), 335\u2013364."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8397/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700316323663,
                "cdate": 1700316323663,
                "tmdate": 1700318708663,
                "mdate": 1700318708663,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "r6xFJOL7ky",
                "forum": "yzfi15eVI7",
                "replyto": "Y5xCGI9fGU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8397/Reviewer_3ERW"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8397/Reviewer_3ERW"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the extensive response. I have raised my score since my queries have been addressed, and I think this work introduces a novel method with good performance.\n\nHowever I do have a few comments:\n1. Section 3.2 is titled \"TIME SERIES GENERATION WITH IHYPERTIME\" but is still addressing architecture and training, only addressing generation in the last paragraph. This section/title should be changed to something more appropriate.\n2. It turns out the model can only do conditional generation. This was not explained in the original manuscript, and in the updated manuscript, it is only mentioned once in the middle - this needs to be highlighted more clearly in the introduction, and preferably the abstract as well.\n3. Furthermore, it is clear that the proposed method would outperform baselines on the evaluation metrics being used, due to the fact that it is a conditional generation method. This should be highlighted in a limitations section."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8397/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700474535869,
                "cdate": 1700474535869,
                "tmdate": 1700474535869,
                "mdate": 1700474535869,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "8omifPonld",
            "forum": "yzfi15eVI7",
            "replyto": "yzfi15eVI7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8397/Reviewer_h6ka"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8397/Reviewer_h6ka"
            ],
            "content": {
                "summary": {
                    "value": "This paper deals with the generation of time series by employing implicit neural representation (INR) networks. The main advantage of INR lies in handling irregularly sampled grids of different sizes. To avoid training one INR per instance, the INR weights are modulated through a hypernetwork based on a permutation invariant set encoder. The INR consists of three blocks (trend, seasonality, and residual blocks) that are additively recombined to reconstruct the time series. Each block is modulated by a different portion of the latent vector (the output of the set encoder), which is passed through its corresponding decoder. Once the model is trained, a new time series can be generated by linearly interpolating two existing latent vectors (corresponding to two different samples). Then, this new latent vector $z^{(gen)}$ modulates the trained INR to characterize a new time series $x^{(gen)}_{t}$ that can be queried for any timestamp $t$. The approach is tested against several baselines on regular, irregular, and long-time series datasets, and quantitative and qualitative evaluations are presented. In addition, the model allows for a trend-seasonality decomposition analysis."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- S1. IHyperTime can handle irregularly sampled time series allowing the model to learn robust representations across series with different grid measurement. Once trained, iHyperTime can generate new time series,  at any timestamp $t$, opening interesting applications.\n    \n- S2. The model follows a classic time series decomposition, which allows for some degree of interpretability and for some constrained generation on some of the factors, for instance the trend.\n\n- S3. Extensive experiments are conducted in the paper. In addition, plenty of qualitative analysis of the model are available in the appendix, leading to a better comprehension of the model behavior. In addition, the experiments show competitive results compared to the baselines."
                },
                "weaknesses": {
                    "value": "Major weaknesses\n\n- W.1. Time series generation is done by interpolating linearly latent codes of two existing series, thus limiting the diversity and expressiveness of the generated time series. Moreover, it would be interesting to understand qualitatively what happened in the latent space when interpolating linearly between two instances (please see Q.1.).\n\n- W.2. The results are good at highlighting that the generated time series is faithful to the original distribution through the \\textit{predictive}, \\textit{discriminative}, and \\textit{marginal} scores, but there is no qualitative or quantitative experiment on the diversity of the generated time series. My concerns comes from the generation procedure. If $z^{(gen)} = 0.9 z^{(1)} + 0.1 z^{(2)}$, the new time series $x^{(gen)}$ would be very likely $x^{(1)}$ leading to good fidelity scores but not really generating novel time series. Moreover it is standard in generation to split the time series into train/test datasets before the generation phase. Then, generate some new $x^{(gen)}$ according to $z^{(i)}$'s from the train dataset and then compute the \\textit{predictive}, \\textit{discriminative}, and \\textit{marginal} scores between the $x^{(gen)}$ and the $x^{(j)}$'s from the test dataset. From the evaluation metrics paragraph, it is unclear if the dataset is split before generation.\n\nMinor weaknesses \n\n- MW1. The point arguing that SIREN outperforms Fourier Features Network (FFN) for learning and representing high frequencies is at my knowledge not true for time series. Indeed, classical Fourier Features where frequencies are sampled in the linear scale can suffer from spectral bias. But if the frequencies are sampled in the logarithm scale or drawn from a Gaussian distribution as in [2] the spectral bias doesn't stand anymore.\n    In the context of DeepTime [3], the authors demonstrate the superiority of FFN over SIREN in time series forecasting. \n- MW2. Figure 4 is not completely clear. More details are needed to understand how this figure was generated. At first glance, even if the method is efficient for different sequence lengths, the training and inference time should increase with the sequence length, at least due to the loading of the data. Moreover, it is quite peculiar to see a method, Fourier Flows, having a convex curve in time with the sequence length. This makes the argument on the independence with respect to the sequence length less convincing, even though the model still is efficient at training time as shown in Table 12.\n- MW3. In Figures 14-20, the distribution of the original data is different for each baseline, this limits the conclusion that can be drawn from these experiments.\n- MW4. The interpolation process for generating new time series is clear when reading the code, however it is not really described in the paper. This would be important for better clarity of the paper to have this description at least in the appendix.\n    \n- W.3. One key feature of the IHyperTime architecture is the permutation invariant set encoder which allows to encode time series with different sampled grids. However the set encoder is known for underfitting [1] because of the naive aggregation mechanism. And there is no metrics in the experiments allowing to understand the quality of the reconstruction. Moreover, the dimension of $Z_{T}, Z_{S}$ and $Z_{R}$ seems to be crucial and are not discussed in the paper (they are set to 10, 15, 15). It would be interesting to understand the trade-off between the quality of reconstruction and the quality of generation according to the dimension of the $Z's$ (please see Q.3).\n\n[1]: Kim, H., Mnih, A., Schwarz, J., Garnelo, M., Eslami, A., Rosenbaum, D., ... Teh, Y. W. (2019). Attentive neural processes. arXiv preprint arXiv:1901.05761.\n\n[2]: Tancik, M., Srinivasan, P., Mildenhall, B., Fridovich-Keil, S., Raghavan, N., Singhal, U., ... Ng, R. (2020). Fourier features let networks learn high frequency functions in low dimensional domains. Advances in Neural Information Processing Systems, 33, 7537-7547.\n\n[3]: Gerald Woo, Chenghao Liu, Doyen Sahoo, Akshat Kumar, and Steven Hoi. Deeptime: Deep time-\nindex meta-learning for non-stationary time-series forecasting. arXiv preprint arXiv:2207.06046,\n2022."
                },
                "questions": {
                    "value": "- Q.1. It would be interesting for a given latent vector $z^{(1)}$ and another latent vector $z^{(2)}$ to compute  $z_{\u03bb}^{(gen)}$ for $\u03bb$ in $\\{0, 0.1, 0.2, 0.3, ..., 0.9, 1\\}$ and then to visualize $x^{(gen)}_{\u03bb}$ for each $\u03bb$.\n\n- Q.2. Please refer to W.2.\n\n- Q.3. It would also be nice to have an ablation on the modulation mechanism (other than the classical set encoder) for instance the attentive set encoder proposed by Max Horn et al. in [set functions for times series]. In addition, it would be interesting to see the effect of the dimension of $Z_{T}, Z_{S}$ and $Z_{R}$ on the reconstruction loss and on the generation quality.\n\n- Q.4. As describe in MW1, the argument of using SIREN over FFN is not theoretically true. It would then be interesting to see an ablation study on SIREN vs FFN. In the same spirit, no ablation study is performed on $w_0$, which is a crucial and sensitive hyper-parameter of SIREN.\n    \n- Q.5. Could you give some quantitative and qualitative results on the reconstruction quality using IHyperTime?\n    \n- Q.6. Why is the marginal score is used only on the four Monash datasets ?\n    \n- Q.7. Could you comment the results of Table 5 for the Temp Rain dataset? It seems strange that LS4 has such a low marginal score while IHyperTime outperforms greatly LS4 in the other two metrics. Overall this table needs to be more commented. %Why not use the same notations for the metrics in Tables 1-4 and Table 5?\n    \n- Q.8. In Tables 1-2, could you explain why DiffTime discriminative score greatly improves with $30\\%$ missing data ? and then decreases again with $50\\%$  and $70\\%$ missing data. This looks like an anomaly.\n\n- Q9. Why is DiffTime not implemented on the four Monash datasets (cf Table 11)?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8397/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8397/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8397/Reviewer_h6ka"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8397/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698677318839,
            "cdate": 1698677318839,
            "tmdate": 1699637045656,
            "mdate": 1699637045656,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "a0xyaZgqtE",
                "forum": "yzfi15eVI7",
                "replyto": "8omifPonld",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8397/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8397/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to sincerely thank the reviewer for their effort and interesting comments. We now included an additional supplementary material along the main paper. The supplementary contains our new experiments to address reviewer's concerns. \n\n## **Major Weaknesses**\n\n### **W.1. / Q.1.**\n\nIn Figure 1 and Figure 2 we show the reconstructed time-series from interpolations between pairs of embeddings generated by our architecture on the Stock72 dataset, and Figures 3 and 4 correspond to the Stock 360 dataset. \nThe figures show the time-series reconstruction and the embeddings interpolation for a given latent vector z1 and another latent vector z2, at varying $\\lambda \\in [0, \\ldots, 1]$ (as requested in Q.1). \n\nIn the top row, we show a smooth transition from $z_1$ to $z_2$, in terms of the fully reconstructed time series. Our architecture also performs a TSR decomposition of the time series, and hence in the three bottom rows we display the smooth transition between $z_1$ and $z_2$ of each individual component of the time series (Trend, Seasonality, Residual).\n\nWe will add these plots in the main paper. We better discuss the diversity of generated time-series in the next comment. \n\n\n### **W.2. / Q.2.**\n\n**Train-Test Split.**\n We agree that splitting the time series into train/test is the best approach for a fair evaluation of the generative models. However, we found that some of state-of-art approaches train and test the model on the whole dataset for Stock and Energy data[1,2,3]; and to perform a consistent comparison w.r.t. the performance reported in their original paper, we decided to keep the same approach in our paper.\nWe however agree with the reviewer's concern, and thus we are happy to report in the table below (also Table 1 of supplementary) our initial effort in evaluating approaches while randomly splitting data between training set (i.e., 80$\\\\%$ of dataset) and test set (i.e., 20$\\\\%$ of dataset). The Table reports the quantitative metrics for the regular Stock data with length 24. While Figure 5 in the supplementary material shows the t-SNE visualization and the data distribution. These results confirm the findings from the our paper. Notice that, for the Monash datasets we already divided the dataset in training ($80\\%$) and test ($20\\%$) set, similar to the benchmark model LS4 [4]. \n\n**Diversity.** Finally, we also agree that diversity of generated time-series plays a key role in the evaluation of generative models. We can qualitatively evaluate the diversity and coverage from t-SNE of Figure 5 (as well as in t-SNE plots of the main paper). The t-SNE plots show that iHyperTime synthetic data mostly overlap with real data: i.e., iHyperTime is able to have enough diversity to reconstruct the real data distribution. Following reviewer suggestion, we also use a novel metric to quantitatively evaluate the diversity of time-series, namely $sym$-Recall[6] which extends the $\\\\beta$-Recall from[5]. Such metric quantifies the diversity of time-series as the extent to which synthetic samples cover the full variability of real samples. Initial results are reported in the Table below. \n\n$\\\\begin{array}{l|ccccccc}\n\\\\hline\n\\\\text{Metric} & \\\\text{iHT (Ours)} & \\\\text{GT-GAN} & \\\\text{TimeGAN} &  \\\\text{DiffTime} & \\\\text{LS4} & \\\\text{FFlows} \\\\\\\\ \\\\hline\n\\\\text{Discr-score} \\\\downarrow & 0.054\\\\pm0.028 &  0.273\\\\pm0.046 & 0.068\\\\pm0.018 & 0.079\\\\pm0.014 & 0.154\\\\pm0.080 & 0.426\\\\pm0.032 \\\\\\\\\n\\\\text{Pred-score} \\\\downarrow & 0.037\\\\pm0.000 & 0.046\\\\pm0.001 & 0.043\\\\pm0.001& 0.044\\\\pm0.001 & 0.039\\\\pm0.000 & 0.055\\\\pm0.003 \\\\\\\\\n\\\\text{Marginal Score} \\\\downarrow  &  0.355 & 0.403 & 0.434 & 0.359 & 0.513 & 0.335 \\\\\\\\\n\\\\text{sym-Recall} \\\\uparrow &  0.594 & 0.500 & 0.413 & 0.787 & 0.206 & 0.000 \\\\\\\\\n\\\\hline\n\\\\end{array}$\n\n\nWe will add a more extensive discussion, and new experiments in the final version of the paper. \n\n\n**References**\n\n[1] - Yoon, Jinsung, Daniel Jarrett, and Mihaela Van der Schaar. \"Time-series generative adversarial networks.\" Advances in neural information processing systems 32 (2019).\n\n\n[2] - Jeon, Jinsung, et al. \"GT-GAN: General Purpose Time Series Synthesis with Generative Adversarial Networks.\" Advances in Neural Information Processing Systems 35 (2022): 36999-37010.\n\n[3] - Alaa, Ahmed, Alex James Chan, and Mihaela van der Schaar. \"Generative time-series modeling with fourier flows.\" International Conference on Learning Representations. 2020.\n\n[4] - Zhou, Linqi, et al. \"Deep latent state space models for time-series generation.\" International Conference on Machine Learning. PMLR, 2023.\n\n[5] - Alaa, Ahmed, et al. \"How faithful is your synthetic data? sample-level metrics for evaluating and auditing generative models.\" International Conference on Machine Learning. PMLR, 2022.\n\n[6] - Khayatkhoei, Mahyar, and Wael AbdAlmageed. \"Emergent Asymmetry of Precision and Recall for Measuring Fidelity and Diversity of Generative Models in High Dimensions.\" arXiv preprint arXiv:2306.09618 (2023)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8397/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700175653990,
                "cdate": 1700175653990,
                "tmdate": 1700175772612,
                "mdate": 1700175772612,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gRiyIimX4h",
                "forum": "yzfi15eVI7",
                "replyto": "8omifPonld",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8397/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8397/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## **Minor Weaknesses** \n\n### **MW1 /. Q.4.**\n\nWe have now revised Section 3.1.1 to clarify and remove any misleading statements about SIREN outperforming Fourier Features Networks (FFNs) in terms of spectral bias. Following Q4, we will provide an ablation study shortly comparing SIREN and FFN and will add a more extensive discussion in the final version of the paper.   \n**[UPDATE]** We have added the additional ablation studies in the supplementary material, and we discuss them in a comment below.\n\n\n### **MW2**\n\nWe acknowledge that Figure 4 is missing essential details and a more accurate discussion of the results. We also agree with the reviewer that the main goal of our analysis is showing a relatively low computational time for our approach w.r.t. existing methods, as also shown in Table 12. In re-writing the final paper, we are making sure of not claiming any independence with respect to the sequence length.\n\n**More details** Our experiments use the same synthetic data-set of 8192000 data-points (e.g. number of samples $\\times$ sequence length), organized in 5 datasets of different sequence lengths $l \\\\in \\\\{80, 320, 1280, 5120, 20480\\\\}$. Thus, we obtain 5 datasets of $\\\\{102400, 25600, 6400, 1600, 400\\\\}$ number of samples, which we process using $\\\\{1024, 256, 64, 16, 4\\\\}$ as batch-size, respectively.  Thanks to this batch-size, we can fairly train each model for 100 iteration and always loading to GPU the same amount of data-points, for each sequence length and iteration.For inference, we only sample a single batch of data.\n\n**Impact of data loading** All the times are computed directly in the training and testing loop, after the model has been already loaded in the GPU memory, using a NVIDIA T4 GPU. Moreover, we found that the data loading (both for training and inference) is negligible w.r.t. model computational time. We measure the loading being around $ 0.0145$ sec for training (100 iterations) and inference $0.001$ sec (1 epoch). \n\n**Fourier Flow** Finally, we repeated the experiments with Fourier Flows with the new computational times reported in Table 2 of supplementary. However, we still have some convexing. We believe the slightly drop likely comes from not optimized code to handle large batch-sizes: longer time-series (e.g., 320 and 1280) worsen the computational time, but the model is also relieved by the smaller batch-size (e.g., 256 and 64).\n\n### **MW3**\n\nWe thank the reviewer for spotting this issue. We are improving the charts in the final version of the paper with the same scale for both the x and y axes. Figure 5 of the supplementary material already shows some of the new charts. \n\n\n### **MW4**\n\nWe apologize for the lack of clarity in the description of the method. We are incorporating a new detailed description of our time series generation procedure.\n\n### **MW5 / W.3 / Q.3.**\nWe thank the reviewer for the suggestion. \n\n**Reconstruction.** In the supplementary material we now report both the quantitative and qualitative metrics to assess the quality of the reconstruction in train and test set. In Table 5 of supplementary we report the reconstruction error for the iHyperTime for the Energy24, Stock24, Stock72, and Stock360 datasets. While Figure 6 and Figure 7 show the actually quality of reconstructed time-series for Stock 72 and Stock 360, respectively. \n\n**Latent dimension**\nThe model results at varying of the latent dimensions $Z_T$, $Z_S$ and $Z_R$ are shown in the supplementary material on Table 3 and Table 4 for stock 24 and stock 72, respectively. As suggested we evaluate both the reconstruction error and the generation metrics, for different z\\_{T}\\_{S}\\_{R} values (e.g., z\\_4\\_6\\_8 represents $Z_T=4$, $Z_S=6$ and $Z_R=8$). The results show comparable results for Stock 72. For Stock 24 we have slightly better generative performance for small dimensions at the cost of higher reconstruction error, and vice versa.\n\n## **Other Questions** \n\n### **Q.5.**\n\nIn Table 5 of supplementary we report quantitative metrics to evaluate the reconstruction quality using iHyperTime for  Energy24, Stock24, Stock72, and Stock360 datasets. Figure 6 and Figure 7 report the qualitative results, showing the reconstructed time-series for Stock 72 and Stock 360, respectively.\n\n### **Q.6.**\nWe apologize for not introducing the Marginal Score for all the datasets. For simplicity, for each dataset we decided to use only the most common metrics used in the related benchmark papers. Therefore, only Monash uses the marginal score[1]. In our current effort we are in integrating Marginal score also for the other datasets. Table 1 of supplementary material shows the marginal score results for Stock 24. \n\n[1] - Zhou, Linqi, et al. \"Deep latent state space models for time-series generation.\" International Conference on Machine Learning. PMLR, 2023."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8397/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700177557778,
                "cdate": 1700177557778,
                "tmdate": 1700337588606,
                "mdate": 1700337588606,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "55uurry7NY",
                "forum": "yzfi15eVI7",
                "replyto": "8omifPonld",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8397/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8397/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## **Other Questions**\n\n### **Q.7.**\n\n**Temp Rain.** The Temp Rain dataset has more complex temporal dynamics, which make the generative process more difficult. In particular, Temp Rain data has stiff transitions: i.e., most of the data points lie around on the x-axis (y=0) with very sharp spikes [1]. Therefore, a model could achieve very low marginal score by just generating data closely to the x-axis. Such data however are also easily distinguishable from the real data, for a good predictive model.  Therefore, we believe LS4[2] generates good data, but with less sharp spikes than the real data, achieving better marginal score but lower Classification score w.r.t. our approach. This would also explain the high predictive score in LS4, where less sharp spikes would also hinder the predictive power of a model trained on synthetic data but tested on real. \n\n  We will add more detailed discussion in the final version of the paper. \n\n**Notation.**  Regarding the different notations for the metrics in Tables 1-4 and Table 5, in order to make a fair comparison with the state-of-the-art benchmarks, Tables 1-4 follow the predictive and discriminative scores as they are set up in TimeGAN, GT-GAN, DiffTime, etc, whilst in Table 5 we follow the same set up for Classification and predictive score as LS4. Moreover, in Table 5 we show results in the Monash dataset, where three of the datasets have time series with sequence length greater than 700. Given that the predictive and discriminative scores in Tables 1-4 are RNN-based, the time to compute the metrics would be impractical. In addition, the RNN-based metrics might not be able to capture the more complex dynamics from the Monash datasets.\n\n\n[1] - Temperature Rain Dataset without Missing Values, https://zenodo.org/records/5129091\n\n[2] - Zhou, Linqi, et al. \"Deep latent state space models for time-series generation.\" International Conference on Machine Learning. PMLR, 2023.\n\n\n### **Q.8. and Q.9.**\n\nWe thank the reviewer for the good suggestion. We are actually training DiffTime for Monash, which we initially omitted due to the longer training times. We also agree that the performance seems to have an anomaly for 30 Stock missing data. We will add the new results soon, and we will integrate them in the final version of the paper."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8397/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700177859439,
                "cdate": 1700177859439,
                "tmdate": 1700177859439,
                "mdate": 1700177859439,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PkxRArJd5o",
                "forum": "yzfi15eVI7",
                "replyto": "8omifPonld",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8397/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8397/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "### **Q.4** \n\nWe appreciate the reviewer's suggestion for these important ablation studies. We have included both analyses in the supplementary material, and discuss them below. We will include these additional results in the final version of the paper. \n\n**Analysis of $w_0$.** In Section 1.7 of the supplementary material, we have included the performance of iHT using different values of $w_0$ in the SIREN layers. In the Tables A and B below, we report the reconstruction and generation metrics for the Stock24 and Stock72 datasets. In Stock24, the best reconstruction and generation metrics are obtained with $w_0=30$. In the case of Stock72, the best reconstruction metric is also obtained with $w_0=30$, but the discriminative and predictive scores show a slight improvement for $w_0=100$.\n\n_Table A: Results for iHT with different values of $w_0$ for the Stock24 dataset._\n$$\n\\\\begin{array}{cccccc}\n\\\\hline\n &    w_0=5 &   w_0=10 &   w_0=30 &  w_0=100 &  w_0=300  \\\\\\\\ \n\\\\hline \n\\\\text{MAE (train)} &  0.0119 &  0.0119 &  0.0069 &  0.0243 &  0.1851 \\\\\\\\\n\\\\text{MAE (test)}  &  0.0120 &  0.0121 &  0.0082 &  0.0245 &  0.1788 \\\\\\\\\n\\\\hline\n\\\\text{Discr-score} &  0.151 \\\\pm 0.059 &  0.212 \\\\pm 0.044 &  0.054 \\\\pm0.028 & 0.087 \\\\pm 0.066 &  0.489 \\\\pm 0.007 \\\\\\\\\n\\\\text{Pred-score}  &  0.041 \\\\pm 0.001 &   0.040 \\\\pm 0.001 &  0.037 \\\\pm 0.000  & 0.037 \\\\pm 0.000 &  0.059 \\\\pm 0.002 \\\\\\\\    \n\\\\hline\n\\\\end{array}\n$$\n  \n  \n_Table B: Results for iHT with different values of $w_0$ for the Stock72 dataset._\n$$\n\\\\begin{array}{cccccc}\n\\\\hline\n &    w_0=5 &   w_0=10 &   w_0=30 &  w_0=100 &  w_0=300  \\\\\\\\ \n\\\\hline \n\\\\text{MAE (train)} &  0.0156 &  0.0115 &  0.0093 &  0.0182 &  0.2052  \\\\\\\\\n\\\\text{MAE (test)}  &  0.0157 &  0.0116 &  0.0096 &  0.0187 &  0.1963 \\\\\\\\\n\\\\hline\n\\\\text{Discr-score} &  0.045 \\\\pm 0.034 &  0.058 \\\\pm 0.038 & 0.028 \\\\pm 0.027 & 0.026 \\\\pm 0.011 &  0.250 \\\\pm 0.037 \\\\\\\\\n\\\\text{Pred-score}  &  0.188 \\\\pm 0.002 &  0.186 \\\\pm 0.001 & 0.185 \\\\pm 0.001 & 0.183 \\\\pm 0.001 &   0.196 \\\\pm 0.000  \\\\\\\\    \n\\\\hline\n\\\\end{array}\n$$\n\n**Comparison with FFN.**  In Section 1.8 of the supplementary material, we now report the performance of a variant of iHT that uses Random Fourier Features (FFN) instead of SIREN for the representation of residuals. Given the importance of the scale factor in FFN as explained in [1], we evaluated FFN with multiple scale factor values: 5, 10, 100.\nThe Tables C and D below show the reconstruction and generation metrics for the Stock24 and Stock72 datasets, respectively. For the Stock24 dataset, SIREN achieves the best reconstruction performance as well as the lowest discriminative score. In the case of Stock72, FFN with scale factor 10 achieves better reconstruction errors, and shows slightly better performance in discriminative score than SIREN network.\n\n_Table C: Results for with SIREN layers and with FFN for Stock24 dataset._\n\n$$\n\\\\begin{array}{ccccc}\n\\\\hline\n &    \\\\text{SIREN} (w_0=30) & \\\\text{FFN} (\\sigma=5) &  \\\\text{FFN} (\\sigma=10) & \\\\text{FFN} (\\sigma=100) \\\\\\\\ \n\\\\hline \n\\\\text{MAE (train)} &  0.0069   &     0.0094 &        0.0095 &         0.0101   \\\\\\\\\n\\\\text{MAE (test)}  &  0.0082  &     0.0094 &        0.0095 &         0.0100 \\\\\\\\\n\\\\hline\n\\\\text{Discr-score} &  0.054 \\\\pm 0.028   &  0.244 \\\\pm 0.162 &  0.346 \\\\pm 0.169 &  0.36 \\\\pm 0.183 \\\\\\\\\n\\\\text{Pred-score}  &  0.037 \\\\pm 0.000  &    0.036 \\\\pm 0.000 &    0.036 \\\\pm 0.000 &   0.036 \\\\pm 0.000   \\\\\\\\    \n\\\\hline\n\\\\end{array}\n$$\n\n_Table D: Results for with SIREN layers and with FFN for Stock72 dataset._\n\n$$\n\\\\begin{array}{ccccc}\n\\\\hline\n &    \\\\text{SIREN} (w_0=30) & \\\\text{FFN} (\\sigma=5) &  \\\\text{FFN} (\\sigma=10) & \\\\text{FFN} (\\sigma=100) \\\\\\\\ \n\\\\hline \n\\\\text{MAE (train)} &  0.0093 &      0.0078 &        0.0085 &         0.0083   \\\\\\\\\n\\\\text{MAE (test)}  &  0.0096 &     0.0079 &        0.0086 &         0.0082 \\\\\\\\\n\\\\hline\n\\\\text{Discr-score} & 0.028 \\\\pm 0.027    &  0.028 \\\\pm 0.014 &  0.024 \\\\pm 0.026 &  0.054 \\\\pm 0.029 \\\\\\\\\n\\\\text{Pred-score}  &  0.185 \\\\pm 0.001  &  0.184 \\\\pm 0.001 &  0.185 \\\\pm 0.002 &  0.184 \\\\pm 0.001   \\\\\\\\    \n\\\\hline\n\\\\end{array}\n$$\n\n[1] Woo, Gerald et al. \u201cLearning Deep Time-index Models for Time Series Forecasting.\u201d International Conference on Machine Learning (2022)."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8397/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700336977025,
                "cdate": 1700336977025,
                "tmdate": 1700336977025,
                "mdate": 1700336977025,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "I11mU5CPUe",
                "forum": "yzfi15eVI7",
                "replyto": "PkxRArJd5o",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8397/Reviewer_h6ka"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8397/Reviewer_h6ka"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your answers and details."
                    },
                    "comment": {
                        "value": "I would first like want to thank the authors for their thorough and honest responses about the different raised issues. \n\n**W1**. As illustrated in Figures 1 and 2, with the current generation approach, the generated time series is very similar to the closest one it is created from. This illustrates my main concern about the approach, that the generated time series are just small alterations of the training data.\n\n**W2**. Thank you for clarifying this point. This is critical as with the current generation mechanism, generated time series are very close to the training set. It is good also to have added a diversity metric.\n\n**MW1**. Thank you for the ablation study, and as also stated by reviewers y35Q and 3ERW, it is a good thing that the residual blocks paragraph be more clearly written.\n\n**MW2**. Thank you for the details.\n\n**MW5**. Thank you for the experiments. They confirm that the reconstruction is not of very good quality, especially for Stock 72. Also, I don't understand why the reconstruction scores for Stock 72 are better than for Stock 240, whereas the qualitative results show otherwise. \n\nThe ablation on the dimension of the latent space is interesting because it illustrates the trade-off between reconstruction and generation. iHyperTime probably has good performances for generation because it underfits when learning to reconstruct. I am not convinced by this approach. I think that a well-trained INR with a more interesting generation mechanism would be more valuable. In general, a way to improve reconstruction would be to use something less prone to underfitting than the current set encoder.\n\n**Q7**. Thank you for the explanation. Regarding the notations, it would be important to have a small paragraph in the appendix to clarify this point as you just did.\n\nOverall, I think that this is a serious work with many experiments. However, I do not believe that the approach is sound enough, and the new experiments support this claim, with new generated time series being very close to the learned ones and the generative properties of the model probably being mostly due to the reconstruction error. Thus I will keep my score."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8397/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700476868828,
                "cdate": 1700476868828,
                "tmdate": 1700476868828,
                "mdate": 1700476868828,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VCp4OfOpkg",
                "forum": "yzfi15eVI7",
                "replyto": "CMRY7xXAEK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8397/Reviewer_h6ka"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8397/Reviewer_h6ka"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your responses. I still believe that this work could be improved and that the approach is not sound enough to be accepted yet. More specifically, I think that the reconstruction error needs to be reduced (for instance with a better encoder) and that the generation mechanism could be more sound (for instance with the ideas that you propose here). Overall I appreciated our exchanges and I think that with these further improvements (that could not be done in the rebuttal due to the time constraint), this work would be valuable for the community.\n\nPS: Thank you for the clarification for the differences between Stock 72 and stock 360, it is clear now for me. \n\nPS2: You stated \u2018in our work we randomly sampled lambda values from the interval [0.0, 0.3]\u2019 but in the code there is \u2018lambd = np.random.uniform(low=0.0, high=0.5)\u2019, which mechanism is the one that you used in the additional experiments ?"
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8397/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700732896544,
                "cdate": 1700732896544,
                "tmdate": 1700732896544,
                "mdate": 1700732896544,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "4ersSPRieo",
            "forum": "yzfi15eVI7",
            "replyto": "yzfi15eVI7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8397/Reviewer_3NpH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8397/Reviewer_3NpH"
            ],
            "content": {
                "summary": {
                    "value": "The proposed work is concerned with time series generation and introduces an approach into encode the time series in the form of implicit neural representation through a TSNET,  a trend-seasonality-residual representation. The framework is applied to several regular and irregular time-series generation tasks with various percentages of missing data and compared with other approaches."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. iHyperTime is able to synthesize time series and decompose the representation into configurable feature sets: trends- slow components of the signal, seasonality - periods of the signal and residuals.\n\n2. Results show more accurate generation ability than compared GAN and other networks.\n\n3. Training and inference times of ihyperTime appear to be more optimal than other compared approaches."
                },
                "weaknesses": {
                    "value": "1. It is unclear which data is missing in experiments with irregular timeseries. Is this missing data in training or testing? The procedure of removing data needs to be defined.\n\n2. It is unclear how the method performs in terms of clustering/classification score.\n\n3. The results are not compared to GNN based generation methods."
                },
                "questions": {
                    "value": "1. Recent works show that RNN encoder-decoder with various training strategies such as weak decoder or contrastive or attractive losses can both generate clustered interpretable latent representation and generate sequences. How these models compare with iHyperTime?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8397/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8397/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8397/Reviewer_3NpH"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8397/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699604644689,
            "cdate": 1699604644689,
            "tmdate": 1699637045532,
            "mdate": 1699637045532,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SSN5sw3baw",
                "forum": "yzfi15eVI7",
                "replyto": "4ersSPRieo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8397/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8397/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for pointing out aspects that were not clearly explained and discussed in the paper.\n\n### **Weaknesses:**\n\t\n**W1**\n\nFollowing existing literature [1,2,3] we create irregular time-series datasets by randomly dropping 30, 50, 70\\% of observations from the original datasets. We select each observation to drop uniformly at random, and independently for each time series  {$(t_i, y_i)$}$_{i=0}^N$ in the original dataset.  The randomly removed data is the same for every model and every repeat, and used both in training and testing. We will add citations and more details for the irregular time-series dataset generation in the final version of the paper. \n\n**W2**\n\nWe thank the reviewer for pointing out two interesting tasks that were not sufficiently discussed.  While our work primarily focuses on learning an interpretable trend-seasonality time series representation for time-series generation, we agree with the reviewer that this latent representation could be easily used and leveraged in broader applications, like cluster or classification. In particular, these applications could extensively benefit from the learned interpretable decomposition that separates trend, seasonality and residuals. We will discuss the possible different applications in the final version of the paper. \n\n**W3**\n\nWe thank the reviewer for the suggestion. In our current effort, we are improving the state-of-art section discussing related GNN work [4,5,6,7]. Among this work we note that: \n\n- the work in [4] is the only one directly addressing the generation of time-series using a Graph-based model. Although contemporaneous, we plan to compare our proposed approach against this model, and we contacted the authors to access their code. \n\n- the work in [5] proposes an interesting graph neural network approach to embed irregularly sampled and multivariate time-series. While the work focuses on forecasting, it can be extended to other applications including generation. We are evaluating the complexity and effort of adapting such model for a comparison.\n\n\n### **References:**\n\n[1] - Jeon, Jinsung, et al. \"GT-GAN: General Purpose Time Series Synthesis with Generative Adversarial Networks.\" Advances in Neural Information Processing Systems 35 (2022): 36999-37010.\n\n[2] - Kidger, Patrick, et al. \"Neural controlled differential equations for irregular time series.\" Advances in Neural Information Processing Systems 33 (2020): 6696-6707.\n\n[3] - Tang, Xianfeng, et al. \"Joint modeling of local and global temporal dynamics for multivariate time series forecasting with missing values.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 04. 2020.\n\n[4] - Iyer, Srikrishna, and Teng Teck Hou. \"GAT-GAN: A Graph-Attention-based Time-Series Generative Adversarial Network.\" arXiv preprint arXiv:2306.01999 (2023).\n\n[5] -Zhang, Xiang, et al. \"Graph-Guided Network for Irregularly Sampled Multivariate Time Series.\" International Conference on Learning Representations. 2022.\n\n[6] - Andrea, Cini, Marisca Ivan, and Cesare Alippi. \"Filling the Gaps: Multivariate Time Series Imputation by Graph Neural Networks.\" ICLR 2022. 2021. 1-20.\n\n[7] - Jin, Ming, et al. \"A survey on graph neural networks for time series: Forecasting, classification, imputation, and anomaly detection.\" arXiv preprint arXiv:2307.03759 (2023)."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8397/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699958929642,
                "cdate": 1699958929642,
                "tmdate": 1699958929642,
                "mdate": 1699958929642,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "v0txqwA5Uw",
                "forum": "yzfi15eVI7",
                "replyto": "4ersSPRieo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8397/Reviewer_3NpH"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8397/Reviewer_3NpH"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for clarifications"
                    },
                    "comment": {
                        "value": "I would like to thank the authors for clarifying the weaknesses and questions that I have raised. While W1 & W2 have been addressed by the authors, W3 and Q1 remain to be a concern since comparison appears to lack important methods/baselines."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8397/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700546614939,
                "cdate": 1700546614939,
                "tmdate": 1700546614939,
                "mdate": 1700546614939,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]