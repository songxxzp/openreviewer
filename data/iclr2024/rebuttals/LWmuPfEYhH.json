[
    {
        "title": "Attention-Guided Contrastive Role Representations for Multi-agent Reinforcement Learning"
    },
    {
        "review": {
            "id": "zgpnltNd0H",
            "forum": "LWmuPfEYhH",
            "replyto": "LWmuPfEYhH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1047/Reviewer_jtxX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1047/Reviewer_jtxX"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a method of attention-guided promotion (incorporating attention mechanisms in the global state to participate in value decomposition) to maximize mutual information to formalize role representation and derive a contrastive learning objective function. ACORM choose the StarCraft multi-agent challenge (SMAC) benchmark and achieves state-of-the-art performance on most hard and superhard maps."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Using mutual information to distinguish roles\n\nThe experiment was conducted on a difficult map in StarCraft\n\nThe experimental diagram is very detailed"
                },
                "weaknesses": {
                    "value": "There is no reasonable explanation or formula for the promotion of credit assignment  by attention, and the paper only demonstrates the effectiveness of the method through experiments"
                },
                "questions": {
                    "value": "1. Does GRU encoding S play a more significant role in the effect ?\n\n2. How do you know the state encoding after this attention, input to the mix network can have an impact on credit assignment ?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1047/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1047/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1047/Reviewer_jtxX"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1047/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698215778193,
            "cdate": 1698215778193,
            "tmdate": 1699636031127,
            "mdate": 1699636031127,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2Kqo3M9szi",
                "forum": "LWmuPfEYhH",
                "replyto": "zgpnltNd0H",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "**Q1: There is no reasonable explanation or formula for the promotion of credit assignment by attention, and the paper only demonstrates the effectiveness of the method through experiments.**\n\nA1: Thank you for your insightful comments.\nThroughout the paper, we have provided explanations for the promotion of more expressive credit assignment in many places.\nFor example, the first paragraph of Sec. 2.2 (top, page 5) presents the line our research motivation for introducing the attention mechanism as \"Popular CTDE algorithms, such as QMIX, realize behavior coordination across agents via a mixing network that estimates joint action-values as a monotonic combination of per-agent values, and the mixing network weights are conditioned on the system\u2019s global state. Naturally, it is interesting to incorporate the learned role information into the mixing network to facilitate skillful coordination across roles. The simplest approach is to concatenate the global state and role representations for generating mixing network weights, while it fails to exploit the internal structure to effectively extract correlations in the role space. Fortunately, the attention mechanism aligns perfectly with our intention by prompting the global state to attend to learned role patterns, thus providing more expressive credit assignment in value decomposition.\"\nOn the other hand, the visualization in Sec. 3.3 clearly illustrates that the global state has successfully attended to the learned role patterns, which in turn provides evidence for our attention-guided promotion of credit assignment.\n\n**Q2: Does GRU encoding $\\bf{s}$ play a more significant role in the effect?**\n\nA2: We have included an additional ablation baseline \"ACORM\\_w/o\\_MHA (Vanilla)\" that removes both the attention module and the additional GRU-MLP structure.\nIn this way, the input to the mixing network is only the current global state $\\bf{s}$$^t$, which is kept the same as the original QMIX algorithm.\nIn Sec. 3.1 of the updated paper and the updated Appendix F, it can be observed that ACORM\\_w/o\\_MHA (Vanilla) obtains very similar performance compared to ACORM\\_w/o\\_MHA.\nIt can be concluded that the effectiveness of our attention module comes from prompting the global state to attend to role representations other than the GRU encoding of the global state trajectory.\n\n\n**Q3: How do you know the state encoding after this attention, input to the mix network can have an impact on credit assignment?**\n\nA3: As stated in A1, the idea of our attention-guided role coordination comes from QMIX's value decomposition.\nQMIX realizes behavior coordination across agents (i.e., credit assignment) via the mixing network whose weights are conditioned on the system\u2019s global state.\nIntuitively, if we could condition the mixing network weights on extra role representations, we might realize more efficient role coordination for better credit assignment.\nFortunately, the attention mechanism aligns perfectly with our intention by prompting the global state to attend to learned role patterns, thus providing more expressive credit assignment in value decomposition.\nMoreover, ablation studies (Sec. 3.1 and Appendix F) and visualization of role coordination (Sec. 3.3) have also verified that our attention module indeed has a positive impact on credit assignment."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1047/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700284616173,
                "cdate": 1700284616173,
                "tmdate": 1700284616173,
                "mdate": 1700284616173,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "35xZwDWct8",
                "forum": "LWmuPfEYhH",
                "replyto": "zgpnltNd0H",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to further discussions!"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nWe were wondering if our response and revision have resolved your concerns. \n\nIn our responses, we have provided the source code and significantly extended the experimental evaluation. We conduct ablation studies with the same network size, and add another ablation baseline to **identify the respective effects of the attention module and the state trajectory encoding**. We have also **provided detailed explanations and insights on the attention-guided role coordination for more expressive credit assginment**.\n\nIf our response has addressed your concerns, we would be grateful if you could re-evaluate our work.\n\nIf you have any additional questions or suggestions, we would be happy to have further discussions.\n\nBest regards,\n\nThe Authors"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1047/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700534222083,
                "cdate": 1700534222083,
                "tmdate": 1700534222083,
                "mdate": 1700534222083,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "zrV9ByiiF6",
            "forum": "LWmuPfEYhH",
            "replyto": "LWmuPfEYhH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1047/Reviewer_1yPm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1047/Reviewer_1yPm"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a novel framework of attention-guided contrastive role representation learning for multi-agent reinforcement learning, ACORM. On the one hand, the role representation of each agent is inferred from the agent embedding through contrastive learning and clustering algorithms. On the other hand, the paper introduces an attention mechanism in value decomposition to enhance agent coordination in the role space. By introducing the above two contributions, ACORM performs better than other role-based multi-agent reinforcement learning algorithms in the SMAC environment. The paper also has intuitive visualizations to illustrate the role of the corresponding modules."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is well-organized and easy to understand.\n2. The experimental part has detailed case studies, which is very important for understanding the role of the two modules proposed in the paper. The figures about the t-sne embedding or weights corresponding to each snapshot have reasonable analysis.\n3. The proposed framework is suitable for reinforcement learning algorithms based on value functions and those based on policy gradient. The relevant algorithms have been tested on SMAC and show that the ACORM variant is much better than the vanilla algorithm.\n4. The proof of the ELBO is given in the appendix, which is correct to me and improves the soundness of the submission."
                },
                "weaknesses": {
                    "value": "1. In cooperative multi-agent reinforcement learning, inferring the role of an agent based on its trajectory is not a novel method and has been proposed in many previous works [1, 2]. Moreover, none of the above-mentioned important papers are cited in the paper.\n2. The number of baselines used for comparison with ACORM is relatively tiny. Why not use CDS [3] as a baseline, since you mentioned it in the paper?\n3. SMAC is a relatively old multi-agent testbed. Recently, it has been pointed out that it has a series of problems [4]. I am not against the author evaluating the performance of the algorithm on SMAC, but I feel that the performance of the algorithm should be tested in multiple different domains. Many environments, such as the Google Research Football [5] mentioned in the paper, can be used to enhance the credibility of experimental results.\n4. Ablation experiments are insufficient. Compared with the vanilla QMIX, ACORM_w/o_MHA still has an additional MLP and GRU for the global state. One wonders whether what really works is just the representation learning of the state trajectory before input to the Mixing Network.\n5. It is not possible to reproduce the results from the description given in the paper. Some key details (such like $T_{cl}$) are unclear, and some key resources (code) are not furnished.\n\n\n\n**Reference**\n\n[1] Cao, Jiahang et al. LINDA: multi-agent local information decomposition for awareness of teammates. 2021.\n\n[2] Yang, Jiachen et al. Hierarchical Cooperative Multi-Agent Reinforcement Learning with Skill Discovery. 2019.\n\n[3] Li, Chenghao et al. Celebrating Diversity in Shared Multi-Agent Reinforcement Learning. 2021.\n\n[4] Ellis, Benjamin et al. SMACv2: An Improved Benchmark for Cooperative Multi-Agent Reinforcement Learning. 2022.\n\n[5] Kurach, Karol et al. Google Research Football: A Novel Reinforcement Learning Environment. 2019."
                },
                "questions": {
                    "value": "Please see the questions in the weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1047/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1047/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1047/Reviewer_1yPm"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1047/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698503987798,
            "cdate": 1698503987798,
            "tmdate": 1700550767089,
            "mdate": 1700550767089,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4z0cFpPclK",
                "forum": "LWmuPfEYhH",
                "replyto": "zrV9ByiiF6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "**Q1: Experimental evaluation on more multi-agent testbeds.**\n\nA1: In the original version, we evaluated our method on six *representative* SMAC maps.\nFollowing your suggestion, we have conducted additional experiments on more SMAC maps and on Google research football environments, and provided the extended results in the updated Appendices B and C.\nThe results on massively extended experiments are generally consistent with our previous conclusion that ACORM obtains the best performance in most scenarios and outperforms baselines by a larger margin on harder tasks.\n\n\n**Q2: About reproducibility and some experimental details (e.g., $T_{cl}$).**\n\nA2: Thank you for your careful reading. \nWe have provided the source code of ACORM in the updated supplementary material to ensure reproducibility.\nIn the original appendices, $T_{cl}$ is the time interval for updating contrastive loss as shown in Algorithm 1 and Tables 2 \\& 4.\nTo make these details clearer, we have modified these notations to be consistent across all appendices.\n\n\n**Q3: More sufficient ablation experiments, since ACORM\\_w/o\\_MHA still has an additional MLP and GRU for the global state.**\n\nA3: Thank you for your helpful advice.\nWe have included an additional ablation baseline \"ACORM\\_w/o\\_MHA (Vanilla)\" that removes both the attention module and the additional GRU-MLP structure.\nIn this way, the input to the mixing network is only the current global state $\\bf{s}$$^t$, which is kept the same as the original QMIX algorithm.\nIn Sec. 3.1 of the updated paper and the updated Appendix F, it can be observed that ACORM\\_w/o\\_MHA (Vanilla) obtains very similar performance compared to ACORM\\_w/o\\_MHA.\nIt can be concluded that the effectiveness of our attention module comes from prompting the global state to attend to role representations other than the representation learning of the state trajectory via GRU.\n\n\n**Q4: The number of baselines is relatively tiny. Why not use CDS as a baseline, since you mentioned it in the paper?**\n\nA4: As mentioned in our original paper, there are a large number of related methods that involve agent heterogeneity and role emergence.\nFor a moderate demonstration, we chose the basic QMIX and the four most relevant methods as our *five* baselines. \nWe skipped some methods that generally perform worse than the selected baselines.\nFor example, ROMA and RODE are both classical role-based methods, and RODE generally outperforms ROMA in the literature.\nHence, we compare ACORM to RODE only.\nFurther, we have included CDS as an additional baseline in the updated paper to make our evaluation more persuasive.\nExtended experimental results are consistent with our previous conclusion, and our method outperforms CDS in most scenarios.\n\n\n**Q5: More related works that infer the role of an agent based on its trajectory.**\n\nA5: We agree with you that inferring the role of an agent based on its trajectory has been investigated in many previous works, such as those role-based methods in our original paper.\nWe have indeed included [2] as a Role Emergence method in the Related Work section (top, page 9) of the original paper, and we will also include [1] in our related work in the updated paper to make our literature review more complete and comprehensive.\nCompared to existing role-based methods, our method introduces two innovative components, i.e., the contrastive learning formulation for learning discriminative role representations and the attention mechanism to coordinate learned role representations for more expressive credit assignment, and our method obtains SOTA performance on most experiments compared to them.\n\n[1] Cao, Jiahang et al. LINDA: multi-agent local information decomposition for awareness of teammates, Science China Information Science 2021.\n\n[2] Yang, Jiachen et al. Hierarchical Cooperative Multi-Agent Reinforcement Learning with Skill Discovery, AAMAS 2020."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1047/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700284585177,
                "cdate": 1700284585177,
                "tmdate": 1700284585177,
                "mdate": 1700284585177,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Q9ou924m6t",
                "forum": "LWmuPfEYhH",
                "replyto": "zrV9ByiiF6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Your feedback is critical to us!"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nWe were wondering if our response and revision have resolved your concerns. We are grateful for your recognition of the suitability and organization of our framework, the detailed case studies, and the soundness of the ELBO derivation.\n\nIn our responses, we have **provided the source code** and **significantly extended experimental evaluation**, including experiments on more SMAC maps and **the Google research football testbed**, **an additional ablation study**, and **another baseline method**. We have **included more related work** on inferring an agent's role based on its trajectory.\n\nIf our response has addressed your concerns, we would be grateful if you could re-evaluate our work.\n\nIf you have any additional questions or suggestions, we would be happy to have further discussions.\n\nBest regards,\n\nThe Authors"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1047/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700533854900,
                "cdate": 1700533854900,
                "tmdate": 1700533854900,
                "mdate": 1700533854900,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aDBeNcigw6",
                "forum": "LWmuPfEYhH",
                "replyto": "Q9ou924m6t",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1047/Reviewer_1yPm"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1047/Reviewer_1yPm"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks to authors for the detailed reply. I agree that the experimental results show the strong performance of ACORM. Many of my concerns were substantially addressed by authors, and I have updated my score. If more convincing results such as the performance of MAPPO-based ACORM are updated in the future, I will further improve my score."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1047/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700550858076,
                "cdate": 1700550858076,
                "tmdate": 1700550858076,
                "mdate": 1700550858076,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hCG1utJpHq",
            "forum": "LWmuPfEYhH",
            "replyto": "LWmuPfEYhH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1047/Reviewer_WWCs"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1047/Reviewer_WWCs"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces the ACORM framework, which utilizes mutual information maximization to formalize role representation learning through a contrastive learning objective. It also incorporates an attention mechanism to encourage the global state to attend to learned role representations.\nEmpirical evaluations carried out on SMAC scenarios demonstrated that ACORM surpasses the performance of baseline methods. Additionally, visualizations and ablation studies show the pivotal roles played by the contrastive role representation and attention mechanism in this task."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The proposed ACORM framework integrates representation learning, encoding the trajectory history from the traditional framework into a latent variable z. This representation associated with the role is learned through clustering and using positive-negative samples.\n* Compared to the traditional framework, the global state used incorporates role-related representations through an attention mechanism."
                },
                "weaknesses": {
                    "value": "* **Novelty and Reliability**: ACORM is not the first work to introduce the attention mechanism in the mixing network. For instance, works like [Qatten](https://arxiv.org/pdf/2002.03939.pdf) have introduced certain constraints in the network to satisfy the IGM principle. However, this paper does not provide evidence of complying with the IGM principle or any explanations.\n* **Experimental Evaluation**: The experiments in the article are conducted solely on SMAC. To my knowledge, various versions of SMAC exist, and different algorithm implementations often involve custom modifications to this environment. Relying solely on SMAC for experiments may not be sufficiently persuasive. It might be beneficial to include experiments from other environments such as GRF and Ma-MuJoCo.\n* **Reproducibility**: The supplementary materials do not include the source code, making reproducibility uncertain."
                },
                "questions": {
                    "value": "* As previously mentioned, ACORM does not impose constraints on the attention mechanism, and it even utilizes the learned latent variable $z$. How can we ensure its correct execution under the CTDE paradigm?\n* Regarding the analysis of Contrastive role representation, Figure 4 is not particularly convincing:\n    * In subfigure (b), *(0) is even further from other points in its cluster compared to *(5). While I understand that clustering is done in higher dimensions, this example can be confusing.\n    * While it's claimed that the role representation better forms coordination teams, in actuality, in subfigure (b) and (c), it seems just the agent embedding alone might suffice.\n* Additional experiments are needed to bolster the paper's persuasiveness.\n* The supplementary materials do not include the source code, making reproducibility uncertain.\n\nI would like to raise my score if my concerns are addressed."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1047/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1047/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1047/Reviewer_WWCs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1047/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698825996420,
            "cdate": 1698825996420,
            "tmdate": 1699636030960,
            "mdate": 1699636030960,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "N18pTu7qxc",
                "forum": "LWmuPfEYhH",
                "replyto": "hCG1utJpHq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (Part 1/2)"
                    },
                    "comment": {
                        "value": "**Q1: Reproducibility and more experimental evaluation.**\n\nA1: We have provided our source code in the updated supplementary material to ensure reproducibility.\nIn the original version, we evaluated our method on six *representative* SMAC maps.\nFollowing your advice, we have conducted additional experiments on more SMAC maps and on Google research football environments, and provided the extended results in the updated Appendices B and C.\nThe results of massively extended experiments are generally consistent with our previous conclusion that ACORM obtains the best performance in most scenarios and outperforms baselines by a larger margin on harder tasks.\n\n**Q2: More related work of introducing the attention mechanism in the mixing network.**\n\nA2: We agree with you that ACORM is not the first work to introduce the attention mechanism in the mixing network. \nAs stated in Related Work of the original paper (bottom, page 9), attention has been widely applied to MARL domains for various utilities, including Qatten.\nHowever, our method differs largely from Qatten in how to use attention in the mixing network.\nQatten proposes a novel value decomposition formulation that transforms individual Q-values to $Q_{tot}$ with a multi-head attention mechanism.\nThat is, Qatten introduces a new mixing network structure and uses the attention mechanism *within* the mixing network.\nIn contrast, we introduce the attention mechanism to incorporate role representations into the mixing network's input for better value decomposition.\nThat is, we maintain the same mixing network architecture as QMIX and use the attention mechanism *at the input* of the mixing network.\nFurther, our method mainly contains two innovative modules, i.e., the contrastive learning formulation for learning discriminative role representations and the attention mechanism to coordinate learned role representations for more expressive credit assignment.\nThe two components work as a whole to efficiently incorporate the role information into MARL.\n\n\n**Q3: The compatibility with the IGM principle of ACORM.**\n\nA3: As claimed in A2, ACORM uses the same mixing network architecture as QMIX.\nHence, ACORM's compatibility with the IGM principle is the same as that of QMIX.\nFormally, with QMIX's mixing network architecture, ACORM can enforce the monotonicity through the constraint on the relationship between $Q_{tot}$ and each $Q_a$ as $\\frac{\\partial Q_{tot}}{\\partial Q_a}\\ge 0, \\forall a\\in A$, and can naturally satisfy the IGM principle.\nModifying the input to the mixing network (other than the mixing network structure itself) will not influence the monotonicity and the compatibility with the IGM principle."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1047/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700284499636,
                "cdate": 1700284499636,
                "tmdate": 1700284499636,
                "mdate": 1700284499636,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "amOnodYUm9",
                "forum": "LWmuPfEYhH",
                "replyto": "hCG1utJpHq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (Part 2/2)"
                    },
                    "comment": {
                        "value": "**Q4: ACORM's correct execution under the CTDE paradigm.**\n\nA4: As stated in A2 and A3, we use the same mixing network architecture as QMIX and just modify the input to the mixing network.\nDuring centralized training, we can access the global state $\\bf{s}$ and role representations $z_i$ of each agent $i$.\nAfter prompting the global state to attend to role representations, we concatenate the attention output and the original global state as the input to the mixing network for value decomposition (where the hypernetworks produce the weights and biases for mixing network layers).\nDuring execution, each agent can make decisions according to the individual Q-network only, without access to the global state or others' role representations, i.e., decentralized execution.\nAs we have emphasized in our original paper, ACORM strictly follows the CTDE paradigm and is fully compatible with CTDE methods.\n\n\n**Q5: In Fig. 4(b),  agent 0 is even further from other points in its cluster compared to agent 5.**\n\nA5: We cluster agent embeddings in an *unsupervised* way, and there is no ground truth to indicate the oracle cluster assignment.\nThe effectiveness of our method relies on the mechanism of whether agents with similar behavior patterns tend to be grouped into the same cluster, and whether the contrastive learning objective can push points within the same cluster closer to each other and promote different clusters to be notably separated. \nFortunately, our method meets this condition in most cases, as shown in Figs. 4-5.\nSeveral outliers, e.g., Agent 0 is even further from other points in its cluster compared to Agent 5 in Fig. 4(b), will not have a fundamental impact on the effectiveness of our method.\n\n\n**Q6. In Figs. 4(b) and 4(c), it seems that just the agent embedding alone might form good coordination teams.**\n\nA6: Thank you for your careful reading.\nYour observation totally matches the experimental analysis in our original paper (middle, page 7) as: \"Initially ($t=1,12$), all agent embeddings tend to be crowded together with limited discrimination, and the K-means algorithm moderately separates them into several clusters. Via contrastive learning, the acquired role representations within the same cluster are pushed closer to each other, and those in different clusters are notably separated. \nAt a later stage ($t=40$), agent embeddings are scattered widely throughout the space with a good clustering effect. This phenomenon indicates that the system has learned effective role assignment with heterogeneous behavior patterns. \nThen, the role encoder transforms these agent embeddings into more discriminative role representations.\"\nThe discriminative patterns of agent embeddings in later stages could benefit from the early training of contrastive role representations.\nWhile the agent embedding alone might form good coordination teams at later stages, our contrastive learning module can help yield better coordination teams with more discriminative patterns.\nAblation studies in Sec. 3.1 and Appendix F have also verified this point."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1047/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700284538516,
                "cdate": 1700284538516,
                "tmdate": 1700284538516,
                "mdate": 1700284538516,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2bdplIE968",
                "forum": "LWmuPfEYhH",
                "replyto": "hCG1utJpHq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Your feedback is critical to us!"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nWe were wondering if our response and revision have resolved your concerns. In our responses, we have **provided the source code** and **significantly extended experimental evaluation**, including experiments on more SMAC maps and the Google research football testbed, an additional ablation study, and another baseline method. We have **clarified ACORM's full compatibility with the IGM principle and the CTDE paradigm**. \n\nWe are really looking forward to discussing this with you so that we could continually improve our work. Your feedback is critical to us.\n\nIf our response has addressed your concerns, we would be very grateful if you could re-evaluate our work.\n\nBest regards,\n\nThe Authors"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1047/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700533306081,
                "cdate": 1700533306081,
                "tmdate": 1700533306081,
                "mdate": 1700533306081,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Jg7tXLw0fe",
                "forum": "LWmuPfEYhH",
                "replyto": "hCG1utJpHq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Please share with us if you have any additional concerns!"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nApologies for reaching out once more, as today might be the final day of the discussion phase.\n\nWe were wondering what could we do to further address your concerns for a higher rating. Our first guess on the reason that prevents you from a higher rating is that you might share the concerns on the reproducibility and experimental evaluation (also raised by two Reviewers 53j5 and 1yPm). We would like to raise your attention that Reviewer 1yPm replied to us very recently, approved **the significantly extended experimental results**, and increased the rating. We thus hope our responses to them could also solve your potential concerns.\n\nAt the same time, we will be extremely happy if you still have any additional concerns to share with us. Your opinion is critical to us. We will try our best to address your concerns.\n\nBest regards,\n\nThe Authors"
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1047/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700626639842,
                "cdate": 1700626639842,
                "tmdate": 1700626639842,
                "mdate": 1700626639842,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "H3Tz2jhgYt",
            "forum": "LWmuPfEYhH",
            "replyto": "LWmuPfEYhH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1047/Reviewer_53j5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1047/Reviewer_53j5"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a method that combines a multi-head attention structure and the InfoNCE contrastive learning framework to enhance learning efficiency in MARL tasks by learning and utilizing role representations."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.\tThe description of the methodology is clear and accurate.\n2.\tThe performance of the experiments' results is really promising and impressive.\n3.\tThe chapter of related works is rich and comprehensive."
                },
                "weaknesses": {
                    "value": "1.\tExtremely Lack of Experiments. There is a lack of experiments as the author only conducted experiments on 6 maps in SMAC. The same applies to the ablation experiments. Hope there will be additional experiments in a wider range of environments and on more maps within SMAC.\n2.\tThe author did not provide the source code to verify.\n3.\tThere might be some errors in the analysis. Such as the analysis in Appendix D, there is room for debate regarding the phenomenon of sub-groups. It is incorrect to measure the distance between 2 points within 1 cluster in the original space based on their proximity in the t-SNE space. Evaluating the emergence of sub-groups should start from the original space rather than the two-dimensional space after t-SNE reduction. Similarly, after t-SNE reduction, the distance between clusters still does not reflect the real distance. Therefore, the conclusion of 'their role representations are still closer to each other' in the later part still requires the author's reconsideration.\n4.\tThe relationship between the two parts, MHA and CL, in the article is not particularly close; they seem more like two relatively independent components.\n5.\tThere are some typos and the writing of the paper needs some improvement."
                },
                "questions": {
                    "value": "1.\tIn Fig 4. (c), both Agent 5 and 8 are 'Dead Marines'. Why are they clustered into different classes?\n2.\tWhy was a new map, 2s3z, introduced for the experiments in MAPPO? Why not directly use the previously employed 3s5z_vs_3s6z map? I would like to see an additional MAPPO experiment on 3s5z_vs_3s6z.\n3.\tHow is the setting cluster_num = 3 applied on the map 2c_vs_64zg when there are only 2 agents available for control on this map? Besides, why didn't the performance decline since it forces the strategies of each agent to diverge as same as the experiment about cluster_num = 5 applied on the map 5m_vs_6m?\n4.\tIn the derivation, both the approximation and logK indicate that a larger value of K yields better results. The experiments conducted in the selected maps have a limited number of agents. It is suggested to have more agents and experiment with larger values of K. For example, experiments with larger K values, such as K=2, 4, 8, 16, can be run in scenarios like 30m and bane_vs_bane.\n5.\tThe paper doesn't explicitly clarify the difference between clustering directly on agent embeddings and on role representations. As it considers role representations to be more discriminative, it's important to further elucidate the necessity of obtaining discriminative representations through contrastive learning.\n6.\tThe model has been added with a global state GRU and a MHA structure. Therefore it increase the number of parameters of the networks. It is recommended to conduct ablation studies with the same network size.\n\nMinor: Bigger size of networks and additional contrastive learning procedure may limit the application. The theoretical derivation of Theorem 1. is very similar to previous work."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1047/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699420095262,
            "cdate": 1699420095262,
            "tmdate": 1699636030884,
            "mdate": 1699636030884,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VJmMxlqsek",
                "forum": "LWmuPfEYhH",
                "replyto": "H3Tz2jhgYt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (Part 1/2)"
                    },
                    "comment": {
                        "value": "**Q1: Lack of source code and experiments.**\n\nA1: We have provided the source code of our paper in the updated supplementary material to ensure reproducibility.\nIn the original version, we evaluated our method on six *representative* SMAC maps.\nFollowing your suggestion, we have conducted additional experiments on more maps within SMAC and on Google research football environments, and provided the extended results in the updated Appendices B and C.\nThe results of massively extended experiments are generally consistent with our previous conclusion that ACORM obtains the best performance in most scenarios and outperforms baselines by a larger margin on harder tasks.\n\n**Q2: It is suggested to have more agents and experiments with larger values of K.**\n\nA2: Following your suggestion, we have conducted additional experiments with larger numbers of agents, including the maps of 30m and bane\\_vs\\_bane.\nResults can be found in the updated Appendix B.\n\n\n**Q3: It is recommended to conduct ablation studies with the same network size, as our model is added with a global state GRU and an MHA structure.**\n\nA3: Following your advice, we have kept the network size of ACORM the same as all ablations for a fair comparison.\nFurther, we have added another ablation baseline to identify the respective effects of the attention module and the state trajectory encoding via GRU.\nThe updated experimental results are shown in Sec. 3.1 of the revised paper and in the revised Appendix F.\nIt can be observed that the ablation performance is generally consistent with that of our original paper.\n\n\n**Q4: Analysis on the visualization of agent embeddings and role representations via t-SNE.**\n\nA4: We agree with you that after t-SNE reduction, the distance between clusters does not match the real *absolute* distance. \nHowever, what we care about is the *relative* distance between points or clusters.\nThe t-SNE is a widely used dimensionality reduction technique for embedding high-dimensional data for visualization in a low-dimensional space, in such a way that similar objects are modeled by nearby points and dissimilar objects are modeled by distant points with high probability.\nHence, the distance between points or clusters via t-SNE reduction can reflect their relative distances in the original space.\n\n\n**Q5: Why dead Marines 5 and 8 are clustered into different classes in Fig. 4(c).**\n\nA5: We cluster agent embeddings in an *unsupervised* way, and there is no ground truth to indicate the Oracle cluster assignment.\nThe effectiveness of our method relies on the mechanism that agents with similar behavior patterns tend to be grouped into the same cluster. \nFortunately, our method meets this condition in most cases, as shown in Figs. 4-5.\nSeveral outliers, e.g., dead Marines 5 and 8 are clustered into different groups, will not have a fundamental impact on the effectiveness of our method.\nAs we can see in Fig. 4(c), Marines \\{2,3,4,6,7\\} are in the offense team, Marauders \\{0,1\\} and Marine 5 form one dead group, Marine 8 alone represents another dead group, and Medivac 9 alone forms the rescue group."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1047/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700284350559,
                "cdate": 1700284350559,
                "tmdate": 1700284350559,
                "mdate": 1700284350559,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lArjPgA4fG",
                "forum": "LWmuPfEYhH",
                "replyto": "H3Tz2jhgYt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (Part 2/2)"
                    },
                    "comment": {
                        "value": "**Q6: How is the setting cluster\\_num=3 applied on the map 2c\\_vs\\_64zg? Besides, why didn't the performance decline since it forces the strategies of each agent to diverge?**\n\nA6: The number of clusters is less or equal to the number of agents. \nWe have specifically pointed out that the cluster number is 2 on the 2c\\_vs\\_64zg map in the updated Appendices B and D.\nWhen each agent represents a distinct role cluster that forces the strategies of each agent to diverge, the performance may decline compared to those with effective team composition (e.g., K=5 compared to K=2,3,4 on the map 5m\\_vs\\_6m).\nHowever, it could still obtain improved performance compared to most baselines in Fig. 2, since it can explore cooperatively heterogeneous behaviors via our discriminative role representation learning.\n\n\n**Q7: Relationship between MHA and CL.**\n\nA7: We use CL to promote discriminative role representation learning, and utilize an MHA mechanism to coordinate learned role representations for more expressive credit assignment. \nThe two innovative components work as a whole to efficiently incorporate the role information into MARL to promote behavior heterogeneity, knowledge transfer, and skillful coordination across agents.\n\n\n**Q8: Clarify the difference between clustering directly on agent embeddings and on role representations, and further elucidate the necessity of obtaining discriminative representations through contrastive learning.**\n\nA8: As we clarified in the 'Negative Pairs Generation' part of the original paper (bottom, page 4), we perform clustering according to agent embeddings, not role representations.\nFirst, we obtain agent embedding by encoding the agent's trajectory as $e_i^t=f_{\\phi}(o_i^t, a_i^{t-1}, e_i^{t-1})$, and the agent embedding is transformed into role representation by a role encoder as $z_i^t=f_{\\theta}(z_i^t|e_i^t)$ where the role encoder $\\theta$ is optimized by a contrastive learning objective.\nAs shown in the original paper, we have elucidated the necessity of obtaining discriminative representations through contrastive learning in Sec. 2.1.\nFurther, experimental performance and ablation studies in Sec. 3.1 have also verified the effectiveness of our constrastive learning module, and visualization in Sec. 3.2 has clearly shown that the role encoder is capable of transforming agent embeddings into more discriminative representations.\n\n\n**Q9: There are some typos and the writing of the paper needs some improvement.**\n\nA9: Thank you for your careful advice. We have fixed several typos and improved the writing as much as we can.\n\n**Q10: Additional MAPPO experiment on 3s5z\\_vs\\_3s6z.**\n\nA10: In the original version, we evaluated MAPPO-based ACORM on three *representative* SMAC maps.\nDue to the very limited time for rebuttal revision, the performance of MAPPO-based ACORM on more SMAC maps is not updated.\nDebugging MAPPO-style algorithms is generally more time-consuming, since it involves many hyperparameters and empirical tricks.\nWe hope that the extended experimental evaluation could demonstrate adequate persuasiveness of our method, and we are rushing to complete the evaluation results and trying to update them before the rebuttal deadline."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1047/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700284386318,
                "cdate": 1700284386318,
                "tmdate": 1700292536589,
                "mdate": 1700292536589,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QLGQLBm5TL",
                "forum": "LWmuPfEYhH",
                "replyto": "H3Tz2jhgYt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to further discussions!"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nWe were wondering if our response and revision have resolved your concerns. In our responses, we focus on ensuring the reproducibility of our work and significantly extending empirical evaluation, including experiments on more SMAC maps and the Google research football testbed, an additional ablation study, and another baseline method. \n\nIf our response has addressed your concerns, we would be grateful if you could re-evaluate our work.\n\nIf you have any additional questions or suggestions, we would be happy to have further discussions.\n\n\nBest regards,\n\nThe Authors"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1047/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700532976632,
                "cdate": 1700532976632,
                "tmdate": 1700532976632,
                "mdate": 1700532976632,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UPKHvmm4o0",
                "forum": "LWmuPfEYhH",
                "replyto": "H3Tz2jhgYt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Please share with us if you have any additional concerns!"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nApologies for reaching out once more, as today might be the final day of the discussion phase.\n\nWe were wondering what could we do to further address your concerns for a higher rating. Our first guess on the reason that prevents you from a higher rating is that you might share the concerns on the reproducibility and experimental evaluation (also raised by two Reviewers WWCs and 1yPm). We would like to raise your attention that Reviewer 1yPm replied to us very recently, approved the **significantly extended experimental results**, and increased the rating. We thus hope our responses to them could also solve your potential concerns.\n\nAt the same time, we will be extremely happy if you still have any additional concerns to share with us. Your opinion is critical to us. We will try our best to address your concerns.\n\nBest regards,\n\nThe Authors"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1047/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700626457436,
                "cdate": 1700626457436,
                "tmdate": 1700626457436,
                "mdate": 1700626457436,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "trtZA4kcsi",
                "forum": "LWmuPfEYhH",
                "replyto": "H3Tz2jhgYt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1047/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Updated results on MAPPO-based ACORM in Appendix D."
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nWe are rushing to complete the evaluation results all these days. Promisingly, we have updated more experimental results on MAPPO-based ACORM in Appendix D (pages 19-20 in the updated main PDF), with **a total of six representative maps: 2s3z, 3s5z, 5m_vs_6m, MMM2, corridor, and 3s5z_vs_3s6z**. Akin to the QMIX-based version, ACORM improves the performance by the largest margin on super-hard maps that demand a significantly higher degree of behavior diversity and coordination. Extended experimental results consistently demonstrate ACORM\u2019s superior learning efficiency in complex multi-agent domains.\n\nIf our response has addressed your further concerns, we would be grateful if you could re-evaluate our work again. We will be extremely happy if you still have any additional concerns to share with us. We will try our best to address your concerns.\n\nBest regards,\n\nThe Authors"
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1047/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700626874189,
                "cdate": 1700626874189,
                "tmdate": 1700626874189,
                "mdate": 1700626874189,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]