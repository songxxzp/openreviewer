[
    {
        "title": "SuperFormer: Superpixel-based Transformers for Salient Object Detection"
    },
    {
        "review": {
            "id": "HrnwKFsCf4",
            "forum": "8phE9BVRWS",
            "replyto": "8phE9BVRWS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6560/Reviewer_tMkj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6560/Reviewer_tMkj"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a superpixel-based salient object detection (SOD) method. Firstly, they transform the pixel-wise SOD into superpixel SOD by transforming the pixel-wise mask into superpixel masks. Additionally, they propose a transformer-based framework including a dynamic centroid positional embedding (DCPE)."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- Utilizing superpixel for salient object detection is interesting.\n- Provide technical details in Section 3, so that the readers could reproduce the methods based on descriptions."
                },
                "weaknesses": {
                    "value": "- Though Section 3 provides technical details, the motivation is somehow unclear or from technical aspects, which may lack novelty.\n- The experiments are not fully conducted and the \"new state-of-the-art\" performance stated in the paper is doubtful. In Table 2, only 6 methods are compared and most of them are proposed before 2020.\n- The writing style needs to be improved. Inappropriate words and abbreviations should be avoided in formal academic writing.\n- The supplementary materials are missing."
                },
                "questions": {
                    "value": "- Please compare your method with more superpixel-based methods, light weight pixel-wise methods, and salient object detection methods that are proposed in recent years (2021, 2022, 2023)?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6560/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6560/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6560/Reviewer_tMkj"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6560/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698733605329,
            "cdate": 1698733605329,
            "tmdate": 1699636740894,
            "mdate": 1699636740894,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "lnC6btv2DP",
            "forum": "8phE9BVRWS",
            "replyto": "8phE9BVRWS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6560/Reviewer_DeSV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6560/Reviewer_DeSV"
            ],
            "content": {
                "summary": {
                    "value": "This paper centers its attention on superpixel segmentation for the SOD task. It endeavors to leverage the Transformer for processing superpixel representations, employ Fourier transformation to depict the shape attributes of superpixels, and apply dynamic centroid positional embedding to address the issue of superpixel heterogeneity. With SOTA models, it appears to attain commendable performance."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tSmall number of model parameters for easy deployment.\n2.\tThe structure of paper is well organized."
                },
                "weaknesses": {
                    "value": "1.\tThe paper's justification for the need for superpixels is not persuasive and there is limited novelty to use Fourier descriptors for extraction of feature.\n2.\tIncorporating the non-differentiable SLIC method can present obstacles when attempting end-to-end training or integration into other deep learning models.\n3.\tThe experimental results are quite unusual, with the SOTA algorithm differing significantly from the results presented in the original paper (VST, etc.). \n4.\tPixel-level sod models are insufficient and the visualization results are hardly satisfying.\n5.\tDetails of the evaluation on speed and computation are missing."
                },
                "questions": {
                    "value": "1.\tWhy not use the saliency maps or trained weights released in the SOTA paper when comparing other algorithms? The data in the paper is far from the real SOTA.\n2.\tThe correspondence between the amount of computation and the speed of inference is strange. Please describe the hardware environment in which the evaluation was performed. Also explain the main difference with GF that leads to a comparable number of parameters and computation but a large difference in inference speed."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6560/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698802121904,
            "cdate": 1698802121904,
            "tmdate": 1699636740765,
            "mdate": 1699636740765,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "W5dx7xtkh7",
            "forum": "8phE9BVRWS",
            "replyto": "8phE9BVRWS",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6560/Reviewer_P45W"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6560/Reviewer_P45W"
            ],
            "content": {
                "summary": {
                    "value": "This paper advocates employing SLIC-generated superpixels as a foundation. It suggests utilizing GNN to address irregular shapes, employing Fourier transform for shape characterization, and incorporating dynamic centroid positional embedding to manage non-uniform superpixel positions. The resulting SuperFormer demonstrates state-of-the-art performance in Salient Object Detection (SOD)."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This approach presents a simple yet effective technique for extracting features from superpixels.\n1. The proposed method is fast compared with other SOD methods."
                },
                "weaknesses": {
                    "value": "1. The novelty is constrained, as the integration of superpixels with Transformers has been explored in prior works [1][2].\n2. The reported performance of the baseline is inaccurate. The VST model's MAE and F-measure on the DUTS-TE dataset are stated as 0.037 and 0.877, respectively.\n3. There is a lack of information regarding the specific architecture employed in this paper, which makes the comparison in Table 2 not clear enough.\n\n[1] Vision Transformer with Super Token Sampling\n\n[2] Superpixel Transformers for Efficient Semantic Segmentation"
                },
                "questions": {
                    "value": "Please see the weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6560/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698901097150,
            "cdate": 1698901097150,
            "tmdate": 1699636740655,
            "mdate": 1699636740655,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]