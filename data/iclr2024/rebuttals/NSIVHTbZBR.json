[
    {
        "title": "Image Inpainting via Tractable Steering of Diffusion Models"
    },
    {
        "review": {
            "id": "sFKgqJ67ra",
            "forum": "NSIVHTbZBR",
            "replyto": "NSIVHTbZBR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2418/Reviewer_dUar"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2418/Reviewer_dUar"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a method of incorporating Probabilistic Circuits (PCs) into diffusion models, with the authors claiming that this approach can encourage diffusion models to generate structurally more coherent images in image inpainting."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "In this paper, the Tractable Probabilistic Models (TPMs) are first introduced into the task of controllable image inpainting. Experimental results demonstrate that this approach encourages the model to generate higher-quality samples with only a limited computational cost increase.\nThe experimental results seem visually plausible."
                },
                "weaknesses": {
                    "value": "1) The readability of this paper is relatively low. We believe that the author should explain in the introduction and method sections whether the method proposed is training or non-training. If it is the former, the loss function and the parts of the network that need to be updated should be stated explicitly. If it is the latter, the pseudo-code of the algorithm should be given.\n\n2) The experimental section lacks metrics. \n\n3) Have the authors tried irregular masks?"
                },
                "questions": {
                    "value": "1) I cannot fully understand the details of the method proposed in this paper (e.g., how were the weights in the PC obtained). I would appreciate it if the authors could provide pseudocode to enhance the method's readability further.\n\n2) LPIPS alone may not be sufficient to assess the quality of generated images. We recommend that the authors report metrics such as FID, U-IDS, etc.\n\n\nIf I have misunderstood, please point it out.\n\nI am very willing to improve the rating after reading your rebuttal and considering the opinions of other reviewers."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2418/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698142363190,
            "cdate": 1698142363190,
            "tmdate": 1699636177158,
            "mdate": 1699636177158,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lKYnac95iy",
                "forum": "NSIVHTbZBR",
                "replyto": "sFKgqJ67ra",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2418/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2418/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer dUar"
                    },
                    "comment": {
                        "value": "> We believe that the author should explain in the introduction and method sections whether the method proposed is training or non-training. \u2026 I cannot fully understand the details of the method proposed in this paper (e.g., how were the weights in the PC obtained)\n\nThank you for pointing out aspects of the paper that were not explained clearly in the main text. The PC used in the proposed inpainting algorithm needs to be first trained (unconditionally) on the datasets (e.g., CelebA-HQ, ImageNet, and LSUN-Bedroom) using the MLE objective: $\\max \\sum_{\\mathbf{x} \\in \\mathcal{D}} \\log p_{n} (\\mathbf{x})$, where $p_{n}$ is the PC and $\\mathcal{D}$ is the dataset.\n\nFollowing prior art, a natural way to optimize PC parameters w.r.t. the MLE objective is by the Expectation-Maximization algorithm since PCs can be viewed as a latent variable model with a hierarchically nested latent space. The implementation of the EM algorithm is very similar to the backpropagation algorithm since the feedforward computation following Definition 1 can be treated as a computational graph. To update the parameters, we first run the standard backpropagation algorithm to compute the gradient of all parameters (w.r.t. the MLE objective, which is the output of the feedforward PC computation). Suppose the gradient of $\\theta_{n,c}$ is $g_{n,c}$, for every sum node $n$, we update all its child parameters by \n\n$$\\theta_{n,c} \\leftarrow (1 - \\alpha) \\cdot \\theta_{n,c} + \\alpha \\cdot \\frac{g_{n,c} \\cdot \\theta_{n,c}}{\\sum_{m \\in \\mathtt{in}(n)} g_{n,m} \\cdot \\theta_{n,m}},$$\n\nwhere $\\alpha$ is the step size. In addition to the EM update, we follow prior arts and use the LVD technique to initialize the parameters. The full details of the learning process of PCs are included in Appendix C of the revised paper. At the end of Section 4.1, we also added a paragraph to explain the PC learning pipeline and points to the Appendix for more details.\n\nWe are happy to make further clarifications if there are other unclear parts in the paper.\n\n> LPIPS alone may not be sufficient to assess the quality of generated images. \n\nWe conduct a user study based on all three datasets and two masks (\u201cExpand1\u201d and the newly added \u201cWide\u201d masks adopted from [1,2]). Detailed settings and results are added in the updated paper (Appendix E.1). We copy the result table from the paper:\n\n| &nbsp;&nbsp;&nbsp;&nbsp; Dataset & Mask     &nbsp;&nbsp; &nbsp;  |  &nbsp;  Tiramisu &nbsp; | CoPaint | RePaint | DPS |\n\n| CelebAHQ & Expand1  |  Reference    |   &nbsp;&nbsp;&nbsp;&nbsp;  22    &nbsp;&nbsp;&nbsp;&nbsp;  |    &nbsp;&nbsp;&nbsp;&nbsp; 34   &nbsp;&nbsp;&nbsp;&nbsp;  |  &nbsp;14 &nbsp; |\n\n| CelebAHQ & Wide  &nbsp; &nbsp; &nbsp; |  Reference    |   &nbsp;&nbsp;&nbsp;&nbsp;  26    &nbsp;&nbsp;&nbsp;&nbsp;  |    &nbsp;&nbsp;&nbsp;&nbsp; 30   &nbsp;&nbsp;&nbsp;&nbsp;  |  &nbsp; 22 &nbsp; |\n\n| ImageNet & Expand1  |  Reference    |   &nbsp;&nbsp;&nbsp;&nbsp;  32    &nbsp;&nbsp;&nbsp;&nbsp;  |    &nbsp;&nbsp;&nbsp;&nbsp; 20   &nbsp;&nbsp;&nbsp;&nbsp;  |  &nbsp; 24 &nbsp; |\n\n| ImageNet & Wide &nbsp;&nbsp; &nbsp;&nbsp;    |  Reference    |   &nbsp;&nbsp;&nbsp;&nbsp;  14    &nbsp;&nbsp;&nbsp;&nbsp;  |    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  |  &nbsp; 12 &nbsp; |\n\n| LSUN & Expand1&nbsp; &nbsp;&nbsp; &nbsp; &nbsp;    |  Reference    |   &nbsp;&nbsp;&nbsp;&nbsp;  18    &nbsp;&nbsp;&nbsp;&nbsp;  |    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  |  &nbsp; 8 &nbsp; |\n\n| LSUN & Wide &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;   |  Reference    |   &nbsp;&nbsp;&nbsp;&nbsp; &nbsp; 4    &nbsp;&nbsp;&nbsp;&nbsp; &nbsp; |    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  |  &nbsp; -6 &nbsp; |\n\nWe use the vote difference (%) metric, which is the percentage of votes to Tiramisu subtracted by that of the baseline. A positive vote difference value means images generated by Tiramisu are preferred compared to the baselines, while a negative value suggests that the baseline is better than Tiramisu.\n\nWe compare against the three strongest baselines (CoPaint, RePaint, and DPS) as their average LPIPS scores are not significantly worse than Tiramisu. As shown in the table, in all but one task the vote difference score is positive (and often quite large), which indicates the superiority of Tiramisu compared to the baselines.\n\nWe also tried the metrics suggested by the reviewer. However, FID is not specific to image pairs and is less informative for image inpainting tasks; when using the official U-IDS metric, we found that in most cases we got a U-IDS close to 0 and the results are not very informative."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2418/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700383039962,
                "cdate": 1700383039962,
                "tmdate": 1700383511808,
                "mdate": 1700383511808,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "FLb1y47QJ9",
            "forum": "NSIVHTbZBR",
            "replyto": "NSIVHTbZBR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2418/Reviewer_rz93"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2418/Reviewer_rz93"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigated image inpainting using a pre-trained diffusion model by using the proposed TPM approach to enforce the inpainting constraints. Unlike repaint or copaint that either enforce the inpainting constraints through the time travel technique or gradient-based methods to optimize, this paper proposes to model p_\\theta{x_0} by PC, which turns the computation into a normalized multiplication of the model weight based on the graph. The proposed method was combined with copaint and compared with existing methods. The LPIPS value got slightly improved on three commonly used datasets: CelebA-HQ, ImageNet, LSUN-Bedroom. Visual examples were presented and computing cost was discussed."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Inpainting using pre-trained diffusion is an interesting direction to explore and modeling p_\\theta{x_0} provides an alternative angle to look into this problem. \n- The presentation is clear and results show the potential of the proposed method. On the three datasets, CelebA-HQ, ImageNet, LSUN-Bedroom, with masks of different shapes or at different positions, the proposed approach achieved higher LPIPS scores mostly. \n- A practical approximation to apply the proposed methods for high-resolution imprinting was discussed and proposed."
                },
                "weaknesses": {
                    "value": "- The computing cost is related to the size of the hole as well as the network architecture. As authors have mentioned, it also related to resolution. So instead of claiming 10% additional computation overhead, a detailed analysis is more helpful. \n- Number-wise the improvement on LPIPS value compared to CoPaint, or even RePaint is minor. How about other metrics? Or user studies?\n- Section 4.2 reads slightly disconnected from Section 4.1, especially the introduction of the equation 7."
                },
                "questions": {
                    "value": "Will code be released upon publication of this work?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2418/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698734758271,
            "cdate": 1698734758271,
            "tmdate": 1699636177085,
            "mdate": 1699636177085,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "n8rfVFQIsK",
                "forum": "NSIVHTbZBR",
                "replyto": "FLb1y47QJ9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2418/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2418/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer rz93 (part 1)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their constructive feedback.\n\n> So instead of claiming 10% additional computation overhead, a detailed analysis is more helpful.\n\nThank you for the suggestion. In the updated paper (Section 6.2, the \u201ccomputational efficiency\u201d paragraph), we provide an ablation study over the % of denoising steps using PCs, and report the LPIPS score and runtime-per-image for each case. We adopt the \u201cCelebA-HQ + the Expand1 mask\u201d task. As shown in Figure 4 of the updated paper (for convenience, we copied the results in the figure to the table below) as we engage the PC in more denoising steps, the LPIPS score first decreases and then increases. Therefore, incorporating PCs in a moderate amount of steps gives the best performance (around 20% in this case). In terms of computational efficiency, the additional computation cost is around 10% when we engage the PC for the first 20% of the denoising steps and around 25% when the PC is used in the first 50% of the denoising steps.\n\nOne explanation for the diminishing performance gain when using PCs in too many denoising steps is that the later stages of denoising are mainly responsible for refining the details in the image. And the guidance of PCs could be less effective in this aspect. This could be the consequence of using latent space PC (latent space generated by VQ-GAN). In the future, we will explore possibilities to train good PCs directly in the pixel space. This could lead to better performance in terms of refining details in generated images.\n\n| % denoising steps using PC  |   &nbsp;&nbsp;&nbsp;  5    &nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;   10    &nbsp;&nbsp;&nbsp;|&nbsp; &nbsp;&nbsp;   20   &nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;    30   &nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;   40    &nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;  50 &nbsp;&nbsp; |\n\n| &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; LPIPS &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |  0.470 | 0.459 | &nbsp; 0.454  | 0.456 | 0.464 &nbsp; | 0.476 |\n\n| &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Runtime &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |  &nbsp; 109 &nbsp;  | &nbsp; 111 &nbsp;  |  &nbsp; 115 &nbsp;  |  &nbsp; 118 &nbsp; |  &nbsp;121 &nbsp;  | &nbsp; 125 &nbsp; |"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2418/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700382549553,
                "cdate": 1700382549553,
                "tmdate": 1700382549553,
                "mdate": 1700382549553,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "IJedVQ5xq1",
            "forum": "NSIVHTbZBR",
            "replyto": "NSIVHTbZBR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2418/Reviewer_fJmV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2418/Reviewer_fJmV"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a novel method that integrates Tractable Probabilistic Models, particularly Probabilistic Circuits, to address the challenges in controlling diffusion models for image inpainting tasks. This approach aims to achieve more precise and efficient inpainting by leveraging the exact computation of constrained posteriors provided by TPMs.\u200b"
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper appears to present a novel approach to the problem of image inpainting using diffusion models. The integration of Tractable Probabilistic Models (TPMs), specifically Probabilistic Circuits (PCs), to guide the denoising process of diffusion models is an inventive combination of existing ideas. \nThis creative synergy seems to address the intractability issue inherent in exact conditioning required for tasks like inpainting. Additionally, the paper builds upon prior advances to scale up PCs for guiding the image generation process, which could be considered an original contribution in terms of improving and extending existing methodologies."
                },
                "weaknesses": {
                    "value": "1. The TPMs seem to be a general design, while this work constrain the application to image inpainting only, I am not sure about the intuition of this specific application. How about the potential of this method for general conditional generation? \n\n2. In section 6.2, it says \"we only need to incorporate guidance from the TPM in the early denoising stages to control the global semantics of the image; fine-grained details can be later refined by the diffusion model. As a result, TPM is only required in the first \u223c20% denoising steps\". Here, more experimental analysis of the TPM steps are expected, including the effect on generation quality, semantic coherence, and computational efficiency.\n\n3. Limitations and Failure Cases: A discussion of the method's limitations and failure cases are not addressed in this research, which would be beneficial for the application of this work."
                },
                "questions": {
                    "value": "See above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2418/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698765266070,
            "cdate": 1698765266070,
            "tmdate": 1699636177004,
            "mdate": 1699636177004,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wuwnVFxpVI",
                "forum": "NSIVHTbZBR",
                "replyto": "IJedVQ5xq1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2418/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2418/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer fJmV"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their constructive feedback.\n\n> How about the potential of this method for general conditional generation?\n\nThere are various conditional/constrained image generation tasks that could be done by (variants of) the proposed method. As a first attempt at using TPMs (PCs) for conditional image generation tasks, this paper uses image inpainting to demonstrate the effectiveness and potential of the proposed method. In the following, we list several classes of conditional generation tasks that could be accomplished by the proposed method or some (non-trivial) extension of our method.\n\n- Other types of constraints belong to the independent soft evidence constraint family (formally defined in Section 4.2). For example, the constraint of image super-resolution and deblurring could be written in the form of such constraints and thus can be tackled by the proposed method.\n\n- Other inverse problems that can be formulated into \u201csimple\u201d constraints could potentially be tackled by a generalized version of the proposed method thanks to the ability of PCs to efficiently *condition on certain logical constraints*. For example, in image coloring, the constraint would be that for every pixel, its R, G, B value have a fixed weighted sum (specified by the input gray-scale image).\n\n- Controlled generation tasks without formally described conditions. For example, the semantic fusion task described in Section 6.3 aims to \u201cfuse\u201d the semantics of several reference images while maintaining the \u201cnaturalness\u201d of the resultant image.\n\n> Here, more experimental analysis of the TPM steps are expected, including the effect on generation quality, semantic coherence, and computational efficiency.\n\nThank you for the suggestion. In the updated paper (Section 6.2, the \u201ccomputational efficiency\u201d paragraph), we provide an ablation study over the % of denoising steps using PCs, and report the LPIPS score and runtime-per-image for each case. We adopt the \u201cCelebA-HQ + the Expand1 mask\u201d task. As shown in Figure 4 of the updated paper (for convenience, we copied the results in the figure to the table below) as we engage the PC in more denoising steps, the LPIPS score first decreases and then increases. Therefore, incorporating PCs in a moderate amount of steps gives the best performance (around 20% in this case). In terms of computational efficiency, the additional computation cost is around 10% when we engage the PC for the first 20% denoising steps and around 25% when the PC is used in the first 50% denoising steps.\n\nOne explanation for the diminishing performance gain when using PCs in too many denoising steps is that the later stages of denoising are mainly responsible for refining the details in the image. And the guidance of PCs could be less effective in this aspect. This could be the consequence of using latent space PC (latent space generated by VQ-GAN). In the future, we will explore possibilities to train good PCs directly in the pixel space. This could lead to better performance in terms of refining details in generated images.\n\n| % denoising steps using PC  |   &nbsp;&nbsp;&nbsp;  5    &nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;   10    &nbsp;&nbsp;&nbsp;|&nbsp; &nbsp;&nbsp;   20   &nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;    30   &nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;   40    &nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;  50 &nbsp;&nbsp; |\n\n| &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; LPIPS &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |  0.470 | 0.459 | &nbsp; 0.454  | 0.456 | 0.464 &nbsp; | 0.476 |\n\n| &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Runtime &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |  &nbsp; 109 &nbsp;  | &nbsp; 111 &nbsp;  |  &nbsp; 115 &nbsp;  |  &nbsp; 118 &nbsp; |  &nbsp;121 &nbsp;  | &nbsp; 125 &nbsp; |\n\n\n> Limitations and Failure Cases: A discussion of the method's limitations and failure cases are not addressed in this research, which would be beneficial for the application of this work.\n\nAs described in the response to the above question, engaging the guidance of PCs in too many denoising steps could lead to worse performance. This suggests that the current method may not be good at refining details. Therefore, Tiramisu could be less effective when dealing with small-hole inpainting.\n\nAnother potential weakness of the proposed method is the expressiveness of PCs. While we are able to train good PCs on datasets such as ImageNet 256*256, it is not sure whether this could be generalized to higher-dimensional images."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2418/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700382435852,
                "cdate": 1700382435852,
                "tmdate": 1700382435852,
                "mdate": 1700382435852,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wgrrcLA7zo",
            "forum": "NSIVHTbZBR",
            "replyto": "NSIVHTbZBR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2418/Reviewer_yw5k"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2418/Reviewer_yw5k"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes to use TPM for conditional image generation, specifically image inpainting, in diffusion models. Previous methods usually use a hard pixel reset or gradient backward to enforce the image to be coherent with the input image for image inpainting using pre-trained diffusion models. This paper, on the other hand, attempts to utilize the TPM along with the diffusion models to enforce the image to be coherent. At each timestep, the proposed method reconstructs the $x_0$ with both the diffusion model and TPM and takes the geometric mean to get the output. Results are compared on multiple datasets including CelebA, LSUN-Bedroom, and ImageNet."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The use of TPM for the conditional generation of diffusion models is interesting.\n2. The overall quantitative results look good compared to previous methods."
                },
                "weaknesses": {
                    "value": "1. The comparison only contains six different masks. In real application, the cases where the images are masked by some texts or patterns are also very common. It would be ideal to see more comparisons of such masks in arbitrary shapes.\n2. The table only contains LPIPS for quantitative measurement, however, as image inpainting is an ill-posed problem, a user study would be beneficial in this case as previous works such as [1][2] perform.\n\n[1] Towards Coherent Image Inpainting Using Denoising Diffusion Implicit Models\\\n[2] Repaint: Inpainting using denoising diffusion probabilistic models"
                },
                "questions": {
                    "value": "From Figure 1 and Table 3, there are some hyper-parameters specifically tuned for different datasets especially $t_{cut}$ which has also been applied in many previous works, could the authors provide an ablation study over the selection of the hyper-parameters?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2418/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2418/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2418/Reviewer_yw5k"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2418/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698820642183,
            "cdate": 1698820642183,
            "tmdate": 1699636176911,
            "mdate": 1699636176911,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tTjwTdg864",
                "forum": "NSIVHTbZBR",
                "replyto": "wgrrcLA7zo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2418/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2418/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer yw5k (part 1)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their insightful comments.\n\n> It would be ideal to see more comparisons of such masks in arbitrary shapes\n\nThank you for the suggestion. We additionally adopted a set of randomly generated \u201cwide\u201d masks following [1] and [2]. The masks are generated by uniformly sampling from polygonal chains dilated by a high random width and rectangles of arbitrary aspect ratios. We downloaded a set of 100 such masks provided by [1] and ran all algorithms with the same set of hyperparameters used in other tasks (no hyperparameter tuning specific to these masks is done). We have added the full results in the updated paper (Table 1) and below is a summary of the new results:\n\n|    Dataset & Mask &nbsp;&nbsp;&nbsp;  | Tiramisu |  CoPaint  |  RePaint  |  DDNM  |  DDRM  |  &nbsp; DPS   &nbsp;  | Resampling |\n\n| CelebAHQ & Wide  |  &nbsp; 0.069 &nbsp; &nbsp;  |   0.072   &nbsp;&nbsp; |   &nbsp; 0.075  &nbsp;  |  &nbsp; 0.112  &nbsp; |   0.132 &nbsp;  |  0.078    |   &nbsp;  0.128     &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |\n\n| ImageNet & Wide  |  &nbsp;  0.125 &nbsp; &nbsp;  |    0.128  &nbsp;&nbsp; |   &nbsp;  0.127 &nbsp;  |  &nbsp;   0.198 &nbsp; |  0.197  &nbsp;  |  0.132 |   &nbsp;  0.196 &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |\n\n| LSUN & Wide &nbsp;  &nbsp;  &nbsp;  &nbsp;    |  &nbsp;    0.116  &nbsp; &nbsp;  |     0.115 &nbsp;&nbsp; |   &nbsp;   0.124 &nbsp;  |  &nbsp;   0.135 &nbsp; |  0.204  &nbsp;  |  0.108  |   &nbsp;   0.202 &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |\n\nTiramisu achieves the best LPIPS score on CelebA-HQ and ImageNet, and is behind DPS in LSUN-Bedroom. Overall, Tiramisu achieves the best LPIPS score on 14 out of 21 tasks. Since the LPIPS scores alone may not fully justify the performance of Tiramisu, please also refer to the response to the next question (about user study).\n\n> a user study would be beneficial in this case as previous works such as [1][2] perform\n\nWe conduct a user study based on all three datasets and two masks (\u201cExpand1\u201d and the newly added \u201cWide\u201d masks adopted from [1,2]). Detailed settings and results are added in the updated paper (Appendix E.1). We copy the result table from the paper:\n\n| &nbsp;&nbsp;&nbsp;&nbsp; Dataset & Mask     &nbsp;&nbsp; &nbsp;  |  &nbsp;  Tiramisu &nbsp; | CoPaint | RePaint | DPS |\n\n| CelebAHQ & Expand1  |  Reference    |   &nbsp;&nbsp;&nbsp;&nbsp;  22    &nbsp;&nbsp;&nbsp;&nbsp;  |    &nbsp;&nbsp;&nbsp;&nbsp; 34   &nbsp;&nbsp;&nbsp;&nbsp;  |  &nbsp;14 &nbsp; |\n\n| CelebAHQ & Wide  &nbsp; &nbsp; &nbsp; |  Reference    |   &nbsp;&nbsp;&nbsp;&nbsp;  26    &nbsp;&nbsp;&nbsp;&nbsp;  |    &nbsp;&nbsp;&nbsp;&nbsp; 30   &nbsp;&nbsp;&nbsp;&nbsp;  |  &nbsp; 22 &nbsp; |\n\n| ImageNet & Expand1  |  Reference    |   &nbsp;&nbsp;&nbsp;&nbsp;  32    &nbsp;&nbsp;&nbsp;&nbsp;  |    &nbsp;&nbsp;&nbsp;&nbsp; 20   &nbsp;&nbsp;&nbsp;&nbsp;  |  &nbsp; 24 &nbsp; |\n\n| ImageNet & Wide &nbsp;&nbsp; &nbsp;&nbsp;    |  Reference    |   &nbsp;&nbsp;&nbsp;&nbsp;  14    &nbsp;&nbsp;&nbsp;&nbsp;  |    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  |  &nbsp; 12 &nbsp; |\n\n| LSUN & Expand1&nbsp; &nbsp;&nbsp; &nbsp; &nbsp;    |  Reference    |   &nbsp;&nbsp;&nbsp;&nbsp;  18    &nbsp;&nbsp;&nbsp;&nbsp;  |    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  |  &nbsp; 8 &nbsp; |\n\n| LSUN & Wide &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;   |  Reference    |   &nbsp;&nbsp;&nbsp;&nbsp; &nbsp; 4    &nbsp;&nbsp;&nbsp;&nbsp; &nbsp; |    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  |  &nbsp; -6 &nbsp; |\n\n\nWe use the vote difference (%) metric, which is the percentage of votes to Tiramisu subtracted by that of the baseline. A positive vote difference value means images generated by Tiramisu are preferred compared to the baselines, while a negative value suggests that the baseline is better than Tiramisu.\n\nWe compare against the three strongest baselines (CoPaint, RePaint, and DPS) as their average LPIPS scores are not significantly worse than Tiramisu. As shown in the table, in all but one task the vote difference score is positive (and often quite large), which indicates the superiority of Tiramisu compared to the baselines."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2418/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700382004403,
                "cdate": 1700382004403,
                "tmdate": 1700382004403,
                "mdate": 1700382004403,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]