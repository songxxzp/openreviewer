[
    {
        "title": "Discovering modular solutions that generalize compositionally"
    },
    {
        "review": {
            "id": "ERGOKlFual",
            "forum": "H98CVcX1eh",
            "replyto": "H98CVcX1eh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3724/Reviewer_KGfv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3724/Reviewer_KGfv"
            ],
            "content": {
                "summary": {
                    "value": "The authors provide a theoretical analysis of the compositional generalization capabilities of linear hypernetworks under a teacher-student setup where the teacher network is the ground-truth data-generating model, and is itself a linear hypernetwork. The key result is that under 3 assumptions (compositional support, connected support, and no over-parameterization), the student can provably _identify_ the modules of the teacher. This identification is further demonstrated to be a necessary and sufficient condition for compositional generalization. The authors provide a series of experiments to validate their theoretical findings and test how sensitive the empirical results are to various violations of the assumptions."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "######## Strengths ########\n- The problem of compositional generalization is of great interest to the ML/AI communities, and there are very few theoretical treatments of the problem\n- The combination of theoretical results and empirical evidence that tests beyond the bounds of the theory is well balanced"
                },
                "weaknesses": {
                    "value": "######## Weaknesses ########\n- The experimental setting is unclear, especially the sequential decision-making portion, which makes it hard to assess its impact\n- It is unclear whether the three assumptions (compositional support, connected support, and no over-parameterization) are necessary conditions or just sufficient\n- The choice of linear hypernetworks as the base modular model somewhat limits the intepretability of the compositionality\n\n######## Recommendation ########\n\nI perceive this work as borderline acceptable. The balance of strengths and weaknesses, I believe, works out in favor of the strengths slightly. That being said, I encourage the authors to address my comments below to improve their manuscript.\n\n######## Arguments ########\n\nThere are very few theoretical treatments of compositionality in the context of neural nets in the literature. In particular, I am only aware of [1] (which the authors actually fail to mention). The two works study very distinct settings, and so I do believe that this submission proposes a novel piece of work. Moreover the authors execute a fairly comprehensive experimental evaluation of their ideas, which is rare for theoretical works. To me, this merits acceptance of the work.\n\nHowever, there are a few shortcomings that the authors should address.\n- Clarity of the experimental setting\n    - Sec 4.1\n        - How is compositional generalization measured? Does the agent train the task-specific coefficients on the new task without training the basis vectors? This isn't really described anywhere.\n        - \"certain overparameterization is necessary for meta-learning to succeed\" -- what does this mean? Doesn't this contradict the theory? Why is it necessary? Haven't all previous results used the \"right\" number of modules? Also, all results in Fig. 3F seem to show that more module overparameterization is consistently better. It isn't clear how this connects to the theory or the remaining results and claims. \n    - Sec 4.2\n        - Am I reading right that the agents are trained on _tens of millions_ of tasks? Though it seems that convergence occurs much earlier on. Could the authors zoom in to the left portion of 4E?\n        - The training setting for 4.2 is very unclear. Is there a teacher? If not, what is the training process? Why is \"accuracy\" used as the metric in a sequential decision making problem? How many total tasks are there (training on 10M out of 1B maybe isn't that bad, but 10M out of 30M isn't super encouraging)? Does accuracy correlate with actual performance on the task (i.e. does the agent actually compositionally generalize to new RL tasks)? How are we measuring \"OOD generalization\" in this setting?\n- Necessary or sufficient conditions \n    - The authors' aim, as stated in the introduction, is to understand \"what properties of the data generating process allow to discover modular solutions enabling compositional generalization\"\n    - However, the phrasing of the first lines of page 4 suggests that assumpions i-iii are _sufficient_ conditions, but not _necessary_ conditions for identification\n    - This means that what we really get is an understandong of _some_ of the properties that allow to discover modular solutions that compositionally generalize\n    - The authors do take steps to understand empirically what the \"cost\" is of violating those assumptions, and the assumptions themselves are fairly intuitive, so that's a positive\n- Interpretability of linear hypernetworks\n    - Other modular solutions (such as the neural module networks of [2]) have very intuitive explanations of what each module does _and how that composes with other modules_\n    - Linear parameter combinations within a hypernet don't seem to have such a straightforward intuition\n    - The authors' attempt at understanding what kinds of composition the model can learn is in the experiments of Sec 4.2, but since those are not clearly explained, it's hard to get any intuition from them. I encourage the authors to include an intuitive description of what the compositionality is in those tasks and how linear hypernets should capture that compositionality.\n\n\n[1] Ghazi et al., \"Recursive Sketches for Modular Deep Learning.\" ICML, 2019.\n\n[2] Andreas et al., \"Neural Module Networks.\" CVPR, 2016"
                },
                "questions": {
                    "value": "######## Additional feedback ########\n\nThe following points are provided as feedback to hopefully help better shape the submitted manuscript, but did not impact my recommendation in a major way.\n\nAbstract\n- Throughout the abstract and much of the text, it's unclear what types of problems the authors are tackling. There's a mention of \"demonstrations\" and \"action-value functions\", which somewhat hints at a solution geared toward RL. Much later, it becomes clear that a \"demonstration\" is the output of the teacher network, and that action-value prediction is just one application of the linear hypernets.\n\nSec 3\n- Up to this point, it was still unclear to me what the authors meant by identification of modules\n    - Is it that the student can determine which modules to use, or that it can find the right set of modules?\n    - Is this in a setting where the student knows the latent codes?\n    - These are later clarified, but it might be worth doing so earlier on\n\nSec 5\n- It's odd that the authors combined a related work section with the discussion, but I think it works okay. \n\nTypos/style/grammar\n- Intro, page 1 first paragraph: series of tasks --> set of tasks [a series is sequential]"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3724/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698369836697,
            "cdate": 1698369836697,
            "tmdate": 1699636328760,
            "mdate": 1699636328760,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bUmxJchx2o",
                "forum": "H98CVcX1eh",
                "replyto": "ERGOKlFual",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3724/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3724/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part 1"
                    },
                    "comment": {
                        "value": "Thank you for your comprehensive review and for the useful feedback that we incorporated in the revised version of our manuscript.\nWe are grateful that you appreciated the combination of theoretical results and empirical evidence despite your concerns with the clarity of the exposition of the experimental setting.\nFollowing your suggestions, we have made substantial efforts to improve the presentation of the latter and address your individual questions point by point below.\nWe hope this strengthens your assessment for acceptance of our work.\n\n\n> The experimental setting is unclear, especially the sequential decision-making portion, which makes it hard to assess its impact\n\nWe have substantially reworked the experimental section to clarify the experimental setting in our updated version of the manuscript.\nIn addition, we provide detailed descriptions of the experimental setting in Appendix C.\n\n\n> It is unclear whether the three assumptions (compositional support, connected support, and no over-parameterization) are necessary conditions or just sufficient\n\nThank you for raising this issue. We have now added a sentence immediately after Theorem 1 clarifying this point. In short, under the same conditions with no additional assumptions, the three conditions of connected support, compositional support as well as no over-parameterization are not only sufficient but necessary conditions for the implication in Theorem 1 to hold. We illustrate this by constructing counterexamples to the implication when some of the three conditions are violated, which we detail in Appendix A2.\n\n\n> The choice of linear hypernetworks as the base modular model somewhat limits the intepretability of the compositionality\n\nThis is indeed an interesting point to consider as it is not clear if parameter module composition as done by hypernetworks generally leads to interpretable modules.\nOne part of the problem is certainly that interpreting individual modules boils down to interpreting the neural network they individually parameterize which is an open research problem.\nIn general, it is not clear if the compositional structure discovered by hypernetworks reflects the abstract compositional structure of the task (e.g. compositional goals or compositional preferences).\nIn the case of the modular teacher-student and the extended hyperteacher setting, our linear identification result shows, that it is possible to decode the ground-truth modules given the learned embeddings.\nWe show that this is indeed possible in practice in Figures 3C and D.\nFuture work is needed to understand under what conditions parameter modules reflect the potentially more abstract compositional structure in more complex settings.\n\n\n> There are very few theoretical treatments of compositionality in the context of neural nets in the literature. In particular, I am only aware of [1] (which the authors actually fail to mention).\n\nThank you for pointing us to this reference which we indeed missed.\nWe have added it to the updated manuscript.\n\n### Section 4.1\n\n> How is compositional generalization measured? Does the agent train the task-specific coefficients on the new task without training the basis vectors\n\nYes, this is correct!\nWe were indeed missing a paragraph on the evaluation during test time which we have now added to Section 2.\nIn short, we use a support set to allow the model to infer the task-specific coefficients while keeping the basis vectors fixed and measure performance on an independent query set.\n\n> \"certain overparameterization is necessary for meta-learning to succeed\" -- what does this mean? Doesn't this contradict the theory? Why is it necessary? Haven't all previous results used the \"right\" number of modules? Also, all results in Fig. 3F seem to show that more module overparameterization is consistently better. It isn't clear how this connects to the theory or the remaining results and claims.\n\nThank you for raising this important point.\nWe have now added a sentence clarifying this point in Section 3.3.\nIn short, while the compositional generalization *when achieving 0 training loss* can only be guaranteed for non over-parameterized students, optimization, i.e. achieving 0 loss, is itself difficult for non over-parameterized models.\nFortunately, the empirical results suggest that gradient descent seems to find the generalizing solutions even when the student is slightly over-parameterized, up to some extent.\nInterestingly, the other conditions, and in particular ensuring connected support, seem to be much more important."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3724/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700138679807,
                "cdate": 1700138679807,
                "tmdate": 1700138679807,
                "mdate": 1700138679807,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XXj0ASIV94",
                "forum": "H98CVcX1eh",
                "replyto": "ERGOKlFual",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3724/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3724/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part 3"
                    },
                    "comment": {
                        "value": "> Interpretability of linear hypernetworks:  Other modular solutions (such as the neural module networks of [2]) have very intuitive explanations of what each module does and how that composes with other modules. Linear parameter combinations within a hypernet don't seem to have such a straightforward intuition. The authors' attempt at understanding what kinds of composition the model can learn is in the experiments of Sec 4.2, but since those are not clearly explained, it's hard to get any intuition from them. I encourage the authors to include an intuitive description of what the compositionality is in those tasks and how linear hypernets should capture that compositionality.\n\nThank you for this suggestion.\nWe have tried to better motivate and explain the two environments in this light in our updated version of the manuscript.\n\n> Throughout the abstract and much of the text, it's unclear what types of problems the authors are tackling. There's a mention of \"demonstrations\" and \"action-value functions\", which somewhat hints at a solution geared toward RL. Much later, it becomes clear that a \"demonstration\" is the output of the teacher network, and that action-value prediction is just one application of the linear hypernets.\n> Up to this point [Section 3], it was still unclear to me what the authors meant by identification of modules.  Is it that the student can determine which modules to use, or that it can find the right set of modules? Is this in a setting where the student knows the latent codes? These are later clarified, but it might be worth doing so earlier on\n\nThank you for raising these issues.\nWe have made substantial efforts to improve the presentation of the paper and attempted to clarify these points earlier in the text.\n\n\n> It's odd that the authors combined a related work section with the discussion, but I think it works okay.\n\nIndeed as you point out, we have treated related work as part of our discussion section. We clarify this now by changing the section title to \"Related work and Discussion\". In addition, we added an \"Extended related work\" section to Appendix~E.\n\n\n[1] Barreto, Andr\u00e9, et al. \"Fast reinforcement learning with generalized policy updates.\" Proceedings of the National Academy of Sciences 117.48 (2020): 30079-30087."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3724/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700138801166,
                "cdate": 1700138801166,
                "tmdate": 1700138801166,
                "mdate": 1700138801166,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2qtDrOBmyu",
                "forum": "H98CVcX1eh",
                "replyto": "XXj0ASIV94",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_KGfv"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_KGfv"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the thorough response"
                    },
                    "comment": {
                        "value": "I thank the authors for their thorough response. In particular, their answers here (and their updates to the draft) have clarified the main concerns I had with the presentation. \n\nI still have one question about the RL evaluation. The authors claim that \"Since the accuracy is measured with respect to the ground truth optimal policy, it is a conservative measure of actual performance on the task.\" But, as I understand, the authors are measuring accuracy of action-value prediction, and don't obtain 100% accuracy (per Fig. 4 E/F, the accuracy converges to ~90%). But we don't know what level of _accumulated reward_ that corresponds to by acting given the learned action-value function, compared to the optimal action-value function. Without this, it is unclear how useful 90% accuracy is."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3724/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700313268269,
                "cdate": 1700313268269,
                "tmdate": 1700313268269,
                "mdate": 1700313268269,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DNr3fWoAWe",
                "forum": "H98CVcX1eh",
                "replyto": "p0A1pnLImz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_KGfv"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_KGfv"
                ],
                "content": {
                    "comment": {
                        "value": "Great! Something like Figure A9 is exactly what I was looking for, and indeed it validates the authors' claims. Am I correct in interpreting the results of A9 as being _stronger_ than just achieving the final reward? If I'm not mistaken, the agent could follow a different trajectory and still obtain a reward, yes?\n\nOverall, 2 of my 3 main concerns were adequately addressed by the authors, and hence I will increase my score to 7. In particular:\n- The authors add multiple clarifications in their response and updated manuscript that make the experimental setting a lot more precise.\n- The authors further provide examples that illustrate that the conditions for compositional generalization are not only sufficient but also necessary. It's unclear to me that these examples provide definitive proof, but they are useful.\n- The authors accept the limited interpretability of linear hypernetworks and provide some discussion around that. I would encourage them to include this discussion in their final manuscript."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3724/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700585495851,
                "cdate": 1700585495851,
                "tmdate": 1700585495851,
                "mdate": 1700585495851,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7zKiTW0Px3",
            "forum": "H98CVcX1eh",
            "replyto": "H98CVcX1eh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3724/Reviewer_9UrZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3724/Reviewer_9UrZ"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a multi-task teacher-student approach with modular architecture for compositional generalization.\nIt uses hypernetworks to convert the generalization to the identification of modules and theoretically show the result up to linear transformation.\nExperiments also support the ability."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- It focuses on an important question of how to learn modular structure for compositional generalization.\n- The hypernetwork and modularity approach cast the generalization problem into an identification\nproblem.\n- Both theory and experiments support the result.\n- It proposes connected support to address permutation invariance."
                },
                "weaknesses": {
                    "value": "My largest concern is that the framework is very constrained, and some constraints, e.g., linearity, may be essential to deriving the results.\nIt indicates that there may be difficulty when generalizing the result to more complex situations.\n\n(1) Linear assumption in hypernetwork.\n\n(2) It uses two two-layer neural networks.\n\n(3) It assumes knowing the correct (teacher) architecture.\n\n(4) The theory assumes knowing the number of modules (M) and hidden units (h)."
                },
                "questions": {
                    "value": "Please respond to the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3724/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3724/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3724/Reviewer_9UrZ"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3724/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698764298288,
            "cdate": 1698764298288,
            "tmdate": 1701075180251,
            "mdate": 1701075180251,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7YNGgkwBFx",
                "forum": "H98CVcX1eh",
                "replyto": "7zKiTW0Px3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3724/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3724/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your encouraging review bringing to attention the importance of the question on how to learn modular structure for compositional generalization.\nBelow we aim to contextualize your concerns on the constraints of our framework replying to your questions point-by-point. We hope these clarifications will convince you to vote for acceptance of the paper, and we remain available for any further questions.\n\n> My largest concern is that the framework is very constrained, and some constraints, e.g., linearity, may be essential to deriving the results. It indicates that there may be difficulty when generalizing the result to more complex situations.\n>\n> (1) Linear assumption in hypernetwork.\n\nWe would like to emphasize that we study a general class of compositional problems that can be captured as parameterized functions whose parameters are combinations of parameter modules.\nWhile we assume that parameter modules are linearly combined to make our theoretical derivation in the modular teacher-student setup tractable, we have carefully designed our experiments to understand how our results extend to complex situations where these assumptions are violated.\nWe have tried to clarify this point in the introductory paragraphs to the experiments.\n\nSpecifically, we train both a linear and a nonlinear hypernetwork and we consider two tasks - the compositional goals and compositional preferences grid worlds - where the data generating distribution has no known closed-form expression as a linear hypernetwork.\nDespite this setting not being linear, our theoretical insights extend to this setting as we can show that both compositional and connected support are required to achieve compositional generalization in the linear and nonlinear hypernetwork. \n\nWe would also like to highlight that the MLP parameterized by the linear hypernetwork is nonlinear and we prove our theoretical results both for the ReLU nonlinearty and a general class of smooth activation functions.\n\n\n> (2) It uses two two-layer neural networks.\n\nOur theoretical analysis of the modular teacher-student setup focuses on two-layer networks, as we are not aware of identification results in the standard teacher-student setup for arbitrary depth which our modular teacher-student setting generalizes.\n\nMoreover, our experiments use neural networks of varying depth beyond two layers - both for the learned models and for the teacher.\n\n> (3) It assumes knowing the correct (teacher) architecture.\n>\n> (4) The theory assumes knowing the number of modules (M) and hidden units (h).\n\nWe would like to clarify that in the teacher-student analysis, our theory explicitly considers the case where the number of modules and hidden units is unmatched, showing that it is theoretically possible to construct counterexamples in these cases.\n\nMoreover, we run a number of experiments on the effect of over-parameterization in the student when verifying the theory in Figure 2C (formerly 2D), in the hyperteacher setting in Figure 3F, in the compositional preferences environment in Figure A8 and in the compositional goals environment in Figure A9.\nThey show that the sensitivity to over-parameterization is less crucial than suggested by the theory, especially in the more complex environments and compositional generalization is possible despite a mismatch in the number of modules (and hidden units in case a teacher is present).\nWe further clarify this point when presenting our experimental results."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3724/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700138577562,
                "cdate": 1700138577562,
                "tmdate": 1700138621630,
                "mdate": 1700138621630,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ZHVBCqwiad",
                "forum": "H98CVcX1eh",
                "replyto": "7YNGgkwBFx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_9UrZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_9UrZ"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the detailed answers. I have further comments on the following points.\n\n> (1) Linear assumption in hypernetwork.\n\nAs far as I understand, theoretical derivation is still important for non-linear combinations.\nThough the derivation may not be easily tractable, there are many ground-truth non-linear combinations of parts in the real world.\nAlso, the experiments are not in real and complex settings, so a strong theoretical result is important.\n\n> (3) It assumes knowing the correct (teacher) architecture.\n\nDoes the theory assume that the teacher architecture (e.g., fully connected or convolutional) is known?\nIf so, why is it reasonable?\nHow about in human-computer interaction settings, where the teacher is a human?"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3724/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700376052678,
                "cdate": 1700376052678,
                "tmdate": 1700376052678,
                "mdate": 1700376052678,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KygLCZqLao",
                "forum": "H98CVcX1eh",
                "replyto": "7zKiTW0Px3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3724/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3724/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for taking the time to consider our responses. We are replying to your remaining questions point-by-point below. We hope these clarifications will convince you to vote for acceptance of the paper, and we remain available for any further questions.\n\n>    (1) Linear assumption in hypernetwork.\n> As far as I understand, theoretical derivation is still important for non-linear combinations. Though the derivation may not be easily tractable, there are many ground-truth non-linear combinations of parts in the real world.\n\nWe agree that there are many ground-truth nonlinear combinations of parts in the real world that are very interesting and important to consider.\nWe would like to clarify however that this is distinct from linearly combining the parameters of a (nonlinear) neural network as is done in the linear hypernetwork we consider in the theory.\nOur experimental results in Figure 4C, 4E and 4F suggest that it is indeed possible to model such nonlinear combinations of parts as you describe (e.g. compositional goals) with linear parameter compositions.\nIn particular, note that the linear hypernetwork performs very similarly to the nonlinear hypernetwork in these experiments, both clearly outperforming the nonlinear monolithic baselines.\n\n>    (3) It assumes knowing the correct (teacher) architecture.\n> Does the theory assume that the teacher architecture (e.g., fully connected or convolutional) is known? If so, why is it reasonable? How about in human-computer interaction settings, where the teacher is a human?\n\nThe analysis does not assume that the teacher architecture is known given that the irreducibility assumption is not violated.\nThe teacher can be any architecture that can be implemented by a MLP, including a convolutional architecture.\nOther parts that specify the architecture in terms of width of the hidden dimension $h$ and the number of modules $M$ are part of the analysis.\n\n> Also, the experiments are not in real and complex settings, so a strong theoretical result is important.\n\nWe would like to emphasize that our teacher-student analysis extends state-of-the-art teacher-student analyses, like for example [1,2], to the full multi-task case where task latent variables must be inferred.\nWe believe it is a strong theoretical result in the context of the literature.\n\n[1] Tian, Yuandong. \"Student specialization in deep rectified networks with finite width and input dimension.\" International Conference on Machine Learning. PMLR, 2020.\n\n[2] Simsek, Berfin, et al. \"Geometry of the loss landscape in overparameterized neural networks: Symmetries and invariances.\" International Conference on Machine Learning. PMLR, 2021."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3724/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700569878232,
                "cdate": 1700569878232,
                "tmdate": 1700569941672,
                "mdate": 1700569941672,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "WV2t2Q0rMB",
            "forum": "H98CVcX1eh",
            "replyto": "H98CVcX1eh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3724/Reviewer_bgW6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3724/Reviewer_bgW6"
            ],
            "content": {
                "summary": {
                    "value": "This work explores the ability of hyper-networks to detect the ground-truth task generating functions and have modules (rows of the linear hyper-network weights) specialise to these underlying factors of variation. Moreover these modules can then be composed in previously unused combinations to generalise to new tasks. Experiments demonstrating the benefit of modular meta-learning algorithms over monolithic meta-learners are also shown."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "## Originality\nThis paper uses an established technique, the teacher-student setup, to understand the necessary conditions for a dataset to promote systematic generalisation. Moreover, a connection between the teach-student setup and meta-learners is drawn, which I have not seen been made frequently before. Also considering ANIL, MAML and hyper-networks as the class of monolithic and modular meta-learners is interesting a new. Thus, the combination of concepts, theoretical technique and models considered in this work is  new.\n\n## Quality\nThe theoretical setup of this work seems appropriate for addressing the main concerns of this work - under what dataset conditions do meta-learners naturally generalise compositionally. The overall structure and logical setup of the work is good and sections naturally lead from one to the next. Section 3.3 directly tests the theory which is presented and in the case of Discrete task distributions the experiments support the theoretical findings. As far as I can tell the assumptions of the setup are clearly stated and the setup is clearly defined.\n\n## Clarity\nFigures are visually clear and well designed.\n\n## Significance\nI reiterate here that I think this work uses a very interesting combination of previous ideas. As a result the reported findings are interesting and I could certainly see the results leading to future work and guiding research on meta learning. Thus, I think this work does have the potential for high significance. I would say this is contingent on some of the weaknesses discussed below being mitigated."
                },
                "weaknesses": {
                    "value": "I have two broad concerns for this work. One is on clarity and the other is on quality. I will begin with clarity as I think this may be a factor in the concerns on quality.\n\n## Clarity\nOverall I found this work to be relatively unclear. Notation is used but not properly introduced, for example $(U_k)$ where it is not mentioned what the double subscript $k$ refers to, or why the second subscript is necessary. Another example is where it is said $\\forall k,l$ where it is necessary to infer from context what $k,l$ is referring to. Also where it says $U_{k_i}$ what does the $i$ or $k$ refer to and why is this necessary. Similarly in Theorem 3.1 where it says \"The if $\\mathcal{L}(W_2,\\Theta)$...\", what is this new $\\mathcal{L}$ referring to? Is it the loss and this is just a mistake in the font? If so, why does this loss function not accept the same  parameters as previous loss functions. Finally, the notation introduced in the paragraph beginning \"We can now present our main result\" is particularly confusing because the superscript $(i)$ is overloaded three times, once referring to a row, the other referring to a column and the third for a full matrix sliced out from a tensor.\n\nSecondly, Definitions 3.1,3.2 and 3.3 are not clear and no intuition or interpretation is provided. For example, where defining irreducibility, the fact that all rows of $W_1$ are pairwise different means that each hidden neuron will be activated for a different feature - and extremely important point for a work concerned with whether meta-learners can extract ground-truth features from a \"metateacher\". This is not stated. Similarly, how this interacts with nonlinearities on the hidden neurons is ignored and what it means for no columns of $W_2$ to be $0$ is also not mentioned. Why would a full column of $W_2$ be $0$? Similarly, \"Compositional Support\" seems to just be saying that $U$ is a basis of $\\mathbf{R}^M$ and so I am not certain of how this new terminology is necessary. Is compositional support a weaker case of having a basis as $U$ does not need to be the **minimal** spanning set? Would Definition 3.1 and 3.2 together then imply that $U$ is a basis? Definition 3.3 is just extremely difficult to parse in general and so is Theorem 3.1. This is due to a lot of terminology being mentioned without definition and needing to be inferred based on context. For example, what is $\\hat{M}$ and why is Theorem 3.1 making a distinction between even and odd values of $n$? The difficulty in following these definitions alone makes the rest of the work difficult to follow.\n\nMy final point on clarity is that the figures, while visually neat and well done, are vague and their captions unhelpful. This is particularly bad when the figures are relied on heavily to explain concepts. For example, where it is said \"See Figure 2B for an illustration of a connected support\" and then the caption does not explain what a connected support is or how the connected vs disconnected task families connects to the actual Definition 3.3. Essentially, every figure caption should be elaborated on and potentially more information be placed in the figures to depict what is actually going on. For example, in Figure 1B, the tiling of the $x,y$ space is not connected at all to the rest of the work beyond the notation of $p(\\tau)$.\n\n## Quality\nMy concerns on quality are likely due to misunderstanding from the above. I would like to reiterate that I do believe this work has potential significance. I am, however, struggling to connect this work to the general literature on compositional generalisation. For example, assuming that $P_x$ has full support over the input space. I see how the learned weights of the linear hyper-network are compositional, in the sense that they operate similar to a set of basis vectors, which in the case of a linear mapping is also features for the network. However, this is then more similar to feature learning rather than exact modules. Or is the idea here that the features being learned which align with ground truth is the same as identifying a composable module? How would this then tie in with disentanglement, which implies compositionality. While I would be open to such claims - the most obvious on to me here being that feature learning and module learning in the limited setting you study are the same thing - I think that argument needs to be made explicit. This would be a different take on modularity in general though and systematic generalisation which tends to focus more on how separate pieces are learned to be separate in spite of covariances and this makes the problem easier [1]. In your case it seems more like a claim that if the input space is sufficiently explored then the network will learn the ground truth features but just because this is the only way to learn the task (to learn a full-rank basis set) and is not in fact learning to identify or solve a smaller problem which is then composable.\n\nThe experiments of Section 4 seem to be more in line with the standard notions of compositionality [2], however due to the above issues grounding the theory to larger scale models of compositionality I also struggle to see how Section 4 fits in with the rest of the work, beyond just demonstrating that hyper-networks are better in compositional domains than ANIL and MAML. Is there a greater connection beyond this (I do think this result is important in its own right though)?\n\nI would be open to increasing my score quite substantially if it is shown that I have indeed missed something crucial. Alternatively if the clarity issues are addressed and the connection to prior work made more explicit I would also increase my score. Likely to a 7. I would certainly prioritise improving the clarity, with the figures being particularly low hanging fruit which would make quite a big difference if improved upon.\n\n## Minor Points\n1. \"with each row representing one parameter module\" - I believe I understood what you were saying, but this was not an easily understandable sentence.\n\n[1] Hadley, Robert F. \"Systematicity in connectionist language learning.\" Mind & Language 9.3 (1994): 247-272.\n[2] Ruis, Laura, et al. \"A benchmark for systematic generalization in grounded language understanding.\" Advances in neural information processing systems 33 (2020): 19861-19872."
                },
                "questions": {
                    "value": "I have raised a number of questions in my discussion above. I think the only outstanding question or point of clarification I have at this point is the following:\nCould the authors please explain what Figure 2A is aiming to show with the permutation invariance? It is only referenced in condition (ii) but then not explained in the figure. I think I would benefit from understanding this point better."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3724/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3724/Reviewer_bgW6",
                        "ICLR.cc/2024/Conference/Submission3724/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3724/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698774008687,
            "cdate": 1698774008687,
            "tmdate": 1700686364039,
            "mdate": 1700686364039,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ajhXHk3eZB",
                "forum": "H98CVcX1eh",
                "replyto": "WV2t2Q0rMB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3724/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3724/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part 1"
                    },
                    "comment": {
                        "value": "Thank you for expressing appreciation for the significance of our work and your very constructive feedback. Based on your input, we have significantly revised the presentation of the theory in the main text as well as the appendix, and are overall confident the quality of the paper improved as a result. We address your questions point by point below, and do our best to clarify important miscommunications. Please do not hesitate to let us know if anything remains unclear.\n\n\n> Notation is used but not properly introduced [...]\n\nThank you for raising this issue.\nWe have revised our notation by simplifying it where possible and ensuring that symbols are properly introduced.\nWe hope this makes it easier to parse our theory and addresses your questions concerning the notations. \n\n>  Definitions 3.1,3.2 and 3.3 are not clear\n\nFollowing the revised notation, we have tried to improve the clarity of the definitions in Section 3.2.\nWe refrain from restating them here to avoid cluttering our response and would like to kindly ask you to revisit our updated manuscript. \n\n> For example, where defining irreducibility, the fact that all rows of are pairwise different means that each hidden neuron will be activated for a different feature - and extremely important point for a work concerned with whether meta-learners can extract ground-truth features from a \"metateacher\". This is not stated. Similarly, how this interacts with nonlinearities on the hidden neurons is ignored and what it means for no columns of to be is also not mentioned. Why would a full column of be ?\n\nThank you for raising this point.\nTo understand the purpose of the irreducibility condition, consider the standard (i.e. single task) teacher-student setting with two-layer neural networks. \nNote that there are many different two-layer neural networks that are functionally equivalent.\nWhen aiming at characterizing the exact set of neural networks that are functionally equivalent to a given teacher network, we are free to pick the teacher network to be any member of that equivalence class. A convenient choice is to choose it to be minimal, i.e. with the smallest possible number of hidden units. The definition of irreducibility is a necessary (and sufficient in the case of the smooth nonlinearity originally used in the main text) condition for such minimality: whenever two input weights are equal, one can merge the associated hidden neurons without changing the function implemented by the network. Likewise, if an output weight is 0, one can remove the associated hidden neuron.\nWe have added a paragraph that explains this point at the beginning of Appendix A.1, and revised the definition of irreducibility to more clearly communicate the above point.\n\n> Compositional Support seems to just be saying that $U$ is a basis $\\mathbb{R}^m$ of and so I am not certain of how this new terminology is necessary.  Is compositional support a weaker case of having a basis as $U$ does not need to be the minimal spanning set? Would Definition 3.1 and 3.2 together then imply that $U$ is a basis?\n\nCompositional support indeed simply ensures that all modules have been encountered at least once during training.\nWe adopt the notion of \"compositional support\" from related work [1].\nIt is a useful definition for our theory as violating it will pose an obvious but important problem for compositional generalization and we can use this property as an experimental intervention to inform to what extent a learned model has discovered underlying compositional structure (c.f. Figures 3C, 4C and 4F). \n\nIndeed as you correctly state, compositional support is a weaker case than having a basis of $\\mathbb{R}^m$ as $Z$ (formerly $U$) does not need to be the minimal spanning set.\n\n> Definition 3.3 is just extremely difficult to parse in general and so is Theorem 3.1.\n\nThank you for raising this point.\nWe have revised the formalism used to state Definition 3.3 and Theorem 3.1 in an attempt to make them easier to parse."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3724/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700138401163,
                "cdate": 1700138401163,
                "tmdate": 1700138401163,
                "mdate": 1700138401163,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QywthjZx3C",
                "forum": "H98CVcX1eh",
                "replyto": "WV2t2Q0rMB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3724/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3724/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part 2"
                    },
                    "comment": {
                        "value": "> The figures, while visually neat and well done, are vague and their captions unhelpful.\n> For example, where it is said \"See Figure 2B for an illustration of a connected support\" and then the caption does not explain what a connected support is or how the connected vs disconnected task families connects to the actual Definition 3.3.\n> For example, in Figure 1B, the tiling of the $x,y$ space is not connected at all to the rest of the work beyond the notation of $p(\\tau)$.\n\nThank you for pointing out the issues with our figures and corresponding captions.\nAccording to your suggestions, we have tried to improve their clarity.\nIn particular, we give a detailed explanation of the example visualized in Figure 2A (formerly 2B) in the beginning of section 3.2, and have reworked Figure 1B to better aid its purpose of illustrating the modular teacher-student setup and how we can use it to investigate compositional generalization.\nIt now shows a concrete toy example that illustrates how during training only a subset of module compositions of the teacher hypernetwork is used to construct the tasks and how this allows us to test for compositional generalization by presenting a novel composition. \n\n> For example, assuming that $\\mathcal{P}_x$ has full support over the input space. I see how the learned weights of the linear hyper-network are compositional, in the sense that they operate similar to a set of basis vectors, which in the case of a linear mapping is also features for the network. However, this is then more similar to feature learning rather than exact modules. Or is the idea here that the features being learned which align with ground truth is the same as identifying a composable module?\n\nIn our setting, the linear hypernetwork takes a low dimensional task embedding $z$ and generates the weights of a base network which is a two-layer MLP. Each of these generated networks will have their own feature extractors over the input $x$, and the linear hypernetwork thus parametrizes a complex family of feature extractors by linearly combining the parameter modules (meta-features) through $z$. \n\nIn our teacher-student result, we show a characterization of what these modules and the distribution over $z$ must be, in order for the identification of these meta-features. Crucially, while we assume the input distribution $\\mathcal{P}_x$ provided for each of the generated networks to have full support, we only require the support of the (hidden) task latent variables $\\mathcal{P}_z$ to be compositional and connected for Theorem 1 (compositional generalization) to hold. In practice, this means we can show tasks from a subset of module combinations during training (in fact, a finite number of tasks linear in the number of modules), holding out a large number of combinations to test for out-of-distribution generalization as a measure of compositional generalization during evaluation.\n\n> How would this then tie in with disentanglement, which implies compositionality. While I would be open to such claims - the most obvious on to me here being that feature learning and module learning in the limited setting you study are the same thing - I think that argument needs to be made explicit. This would be a different take on modularity in general though and systematic generalisation which tends to focus more on how separate pieces are learned to be separate in spite of covariances and this makes the problem easier [1]. In your case it seems more like a claim that if the input space is sufficiently explored then the network will learn the ground truth features but just because this is the only way to learn the task (to learn a full-rank basis set) and is not in fact learning to identify or solve a smaller problem which is then composable.\n\nEach parameter module defines a number of features in the teacher network that are composable in the parameter space of the teacher.\nOur result on linear identification in the student intuitively says that the learned student modules are a linear combination of the teacher modules.\nThis means for each module in the teacher, there is a linear combination of student modules that will recover the teacher features in the student (up to permutation) on each task.\nThese results are therefore somewhat complementary to the typical study of disentangelment in feature learning in the sense that each teacher module defines a whole set of features and we tackle the question whether a student is able to discover the teacher modules when only exposed to tasks that contain a subset of the possible module combinations. \nWe hope that this explanation helped clarify your point.\nPlease let us know if this did not fully answer your question."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3724/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700138487566,
                "cdate": 1700138487566,
                "tmdate": 1700138487566,
                "mdate": 1700138487566,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cUit7dNWQQ",
                "forum": "H98CVcX1eh",
                "replyto": "WV2t2Q0rMB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3724/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3724/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part 3"
                    },
                    "comment": {
                        "value": "> The experiments of Section 4 seem to be more in line with the standard notions of compositionality [2], however due to the above issues grounding the theory to larger scale models of compositionality I also struggle to see how Section 4 fits in with the rest of the work, beyond just demonstrating that hyper-networks are better in compositional domains than ANIL and MAML. Is there a greater connection beyond this (I do think this result is important in its own right though)?\n\nWe have tried to improve the introductory paragraphs in the experimental section to make the connection to the rest of the paper more comprehensible in an attempt to clarify that the experiments of Section 4 consider a similar setup as the theory in Section 3 with the difference that\n\n1. We learn from finite data, i.e. we no longer assume the input distribution $\\mathcal{P}_\\vx$ has full support\n2. As a result we cannot consider the simplified objective of equation (2) but instead employ the bilevel optimization objective of equation (1), better suited for the many-shot setting, and computationally friendlier as it does not require a full optimization in the inner loop.\n3. We move beyond the modular teacher-student setting, introducing a mismatch in the data generating process and the model architecture. In particular, we consider tasks for which it is a priori not clear how well neural networks can capture the underlying compositional structure.\n4. We contrast the performance of our modular architectures with monolithic architectures to highlight the benefits of the former despite their less frequent use in practice.\n\nWithin this practical and more complex setting, we test predictions made by our theory and show that the central assumptions of compositional and connected support play a crucial role.\n\n> Could the authors please explain what Figure 2A is aiming to show with the permutation invariance? It is only referenced in condition (ii) but then not explained in the figure. I think I would benefit from understanding this point better.\n\nThank you for pointing out the missing explanation of Figure 2A in our initial submission.\nWe have extended our explanation of this and other failure cases in Appendix A2 and moved the figure to this section. The caption for what is now Figure A1 now reads as follows:\n\nToy example of how correct identification of individual modules can lead to inconsistent neuron permutations preventing compositional generalization to unseen module compositions: Consider the simplified setting of a teacher and student network with two input neurons and three hidden neurons. Both the teacher and the student have $M=3$ modules. The upper right defines the teacher weights for each module and each neuron. For instance the weights denoted by B correspond to the weights connecting neuron 2 to the input for module 1. We now assume the student during training encounters three tasks. For each task exactly one of the teacher modules is used. Since in MLPs the ordering of neurons is permutation invariant, the student can perfectly match the teacher outputs, even when it uses a different ordering of the neurons. As a result, the student modules can perfectly fit all three tasks, despite permuting the neuron indices. For instance, neuron 2 in module 3 of the student contains the weights H whereas the corresponding neuron in the teacher contains the weights G. When we now present a new task during out-of-distribution evaluation that mixes all three modules in the teacher, the student is required to mix the weights of each neuron across modules. Since the neuron permutations in the student are inconsistent with those of the teacher, the student is unable to create the correct neuron weights and ends up unable to generalize to the OOD task.\n\n[1] Wiedemer, Thadd\u00e4us, et al. \"Compositional generalization from first principles.\" arXiv preprint arXiv:2307.05596 (2023)."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3724/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700138528384,
                "cdate": 1700138528384,
                "tmdate": 1700138528384,
                "mdate": 1700138528384,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GxctIAUtZm",
                "forum": "H98CVcX1eh",
                "replyto": "cUit7dNWQQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_bgW6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_bgW6"
                ],
                "content": {
                    "title": {
                        "value": "Response to New Draft (Part 1 of 2)"
                    },
                    "comment": {
                        "value": "Firstly, let me apologize for the formatting issue in my original review. It seems the authors managed to get the meaning I was intending, but still I should have caught this error.\n\nI will respond to the new draft of the paper and make comments as I read it. Hopefully this will give the authors a better sense of a readers experience while going through it.\n\nI am at the end of the Methods section now. This is much clearer than the original version and I commend the authors for their quick effort. However, there is still room for improvement.  For example in the Compositionality paragraph \"task-shared function g\" is brought up but not described or used until the following page. Thus, at this point while reading this is just another ungrounded symbol taxing my working memory. Similarly the latent code z is brought up but left competely abstract. It is the brought up again half a page later where it is now mentioned that it has compositional structure, but even by the end of the methods section very little is told to use about z. Why not reference Figure 1B here since it is very simply depicted there. But also, why not say z has binary elements with at least two non-zero elements for any task? I think restructuring section 2 so that it is first **Modular and Monolithic Architectures**, then **Compositionality** and finally **Meta-learning** would provide a more grounded and seamless introduction of notation. At least then the actual architecture would be introduced first too. Also the two different uses of $\\phi$ is jarring. I understand the authors are trying to use the same symbols for task-specific parts of the architecture, but for the hyper-network it is a vector used inside of the $g$ function while for ANIL it is a matrix which acts on the output of the $g$ function. Finally, where it says \"we allow the model to infer the task latent code\" and then says \"...by adapting task-specific parameters $\\phi_z(\\theta)$\" this is confusing. As far as I can tell the function $\\phi$ is producing task-specific parameters from task-general parameters. So it is not inferring $z$ (the task latent code) and nor is it adapting task-specific parameters (surely it adapts the task-general feature to be more task-specific)? This entire discussion on the data split is also quite complex and formal to express the fact that the training data needs to be split to do learning and meta-learning on separate portions of the dataset. Especially considering this split is then immediately ignored. At this point while reading it seems like a complicated detour. Not enough discussion is then given on how equation 2 is then optimized. Is this just the same as using equation 1 without splitting the data?\n\nI'm at the end of Section 3.1. The first half of Section 3.1 is what Section 2 should be. You essentially re-introduce the model architecture and latent variables here for you model. It is clearer here, but similarly, why not reference Figure 1? Also you should mention what values **z** can take still, such as $z^{(i)} \\in R$. There's also a couple point where things are said which seem like contradictions but might be due to a lack of detail. The worst case of this is where it says \"hidden dimension potentially different from the teacher\" but assumption (iii) says \"no over-parametrization of the student wrt the teacher\".\n\nIn Section 3.2. Why are \"task families\" now being introduced? We are at least half way through the paper and still having to learn new notation and definitions. The example is helpful though. I'm still not convinced by the notion of neuron permutations being inconsistent. I see more explanation is in the appendix, but this is quite crucial to the main work and needs to be clearer here. Does this just mean that the same hidden neurons might be used by both tasks? Is the main idea of connected support just that it forces the network to partition it's hidden layer for each task? Theorem 1 then says that the student matches the teacher number of hidden neurons which contradicts what is said above. Saying \"under some additional technical conditions\" is frustrating. I appreciate presenting theory in a short format is difficult, but this is not a theorem statement. I know it says \"informal\" as well but this is just unhelpful. I would usually argue for a proof sketch but at this point a proper theorem would be helpful. Does Theorem 2 imply Theorem 1? If this is the case why not just give a full account of Theorem 2 and then note that it implies compositional generalization? I am running out of characters and so will split this here. I will post the second part soon with the rest. I hope this is at least helpful to the authors. I do not intent to be petty or antagonistic but I do still see room for improvement (beyond the already significant improvement)."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3724/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700325059011,
                "cdate": 1700325059011,
                "tmdate": 1700325059011,
                "mdate": 1700325059011,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vXgnhprH5O",
                "forum": "H98CVcX1eh",
                "replyto": "GxctIAUtZm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_bgW6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_bgW6"
                ],
                "content": {
                    "title": {
                        "value": "Response to New Draft (Part 2 of 2)"
                    },
                    "comment": {
                        "value": "I am at Section 4. Why is Section 3,3 made separate from Section 4? Is Section 4 not empirical verification? Section 4 seems more like a results section. My original issues with the paper centred less on the experiments and from what I can tell the other reviewers also seem to believe that they support the findings of this work. The captions of Figure 3 and 4 are much more detailed which is great. I'm still not certain of the main concept of the theory which is limiting my evaluation of the experiments and so I will move on to this now.\n\nI think on a conceptual level I would really benefit from some indication of what it means for the hyper-network to learn the correct modules. Does it imply that a module learns the same features as if it was trained on a task vector of $z = [1,0,0,0,0]$ for example. In other words it identifies a single base or primitive task? This then allows for composition because it has learned different features than if it specialized to $z = [1,0,0,0,1]$ lets say? Is this what you mean by \"linear combination of teachers\"? It seems like it is very really stated in concrete terms what is desired. Even the example at the top of page 5 is not completed somewhere. I would really like to \"close the loop\" so to speak on what is being discussed.\n\nAs a slightly off-topic question. How would this work align with findings on double descent where generalization is hurt most when a network is only sufficiently parametrized and improves when it is over-parametrized? It seems your results would indicate the opposite. I'm just asking here, the authors can ignore this if they like.\n\nI would like to acknowledge that I have read the authors rebuttals prior to re-reading the new draft and so the rebuttal has been incorporated into my understanding of this work and subsequent questions. However, if I am still missing something key I encourage the authors to point this out. To acknowledge the significant improvement that has already been made I am raising my score to a 5, but still feel more is needed before I advocate for acceptance. I'm happy to engage further."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3724/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700326217125,
                "cdate": 1700326217125,
                "tmdate": 1700326217125,
                "mdate": 1700326217125,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Uao8mQRNUx",
                "forum": "H98CVcX1eh",
                "replyto": "6mACEjjxfj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_bgW6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_bgW6"
                ],
                "content": {
                    "title": {
                        "value": "Response to Part 1"
                    },
                    "comment": {
                        "value": "I thank the authors for continuing to elaborate more. Did the authors upload a third version of the paper? Based on Figure 1B it seems so.\n\nI must say I think a lot of what was just stated needs to be said in the paper. The discussion around learning to match every teacher module with a student module having the failure case is even more concrete in the above comment - and I now think I see better why the permutation invariance argument is necessary.\n\nAs for the suggestion on restructuring section 2, if the authors say it did not help then I will accept this. I hope my suggestions will still be incorporate to improve the clarity with the current structure of section 2."
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3724/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700684712161,
                "cdate": 1700684712161,
                "tmdate": 1700684712161,
                "mdate": 1700684712161,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GZPGL7iJ3z",
                "forum": "H98CVcX1eh",
                "replyto": "TpRo1z6gCg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_bgW6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_bgW6"
                ],
                "content": {
                    "title": {
                        "value": "Response to Part 2"
                    },
                    "comment": {
                        "value": "Once again, thank you for the elaboration. I accept all the above. I am still a bit uncertain about the manner in which over-parametrization is spoken about. I would recommend the authors perhaps be clear about when they are discussing hidden layer width as over-parametrization and when they are discussion the number of modules. This would definitely help a lot, for example in the last subsection of Section 3.3."
                    }
                },
                "number": 27,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3724/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700685211523,
                "cdate": 1700685211523,
                "tmdate": 1700685211523,
                "mdate": 1700685211523,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yQPdjkHThx",
                "forum": "H98CVcX1eh",
                "replyto": "UnxILNqoNH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_bgW6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_bgW6"
                ],
                "content": {
                    "title": {
                        "value": "Response to Part 3"
                    },
                    "comment": {
                        "value": "On the definition of task families, I do acknowledge that it is difficult. This point was more to guide the authors on my confusion. Given the improved Figure 3B and overall presentation this is also less of an issue. Perhaps Figure 3B could once again be reference or used as an example. More importantly, the statement in the above comment: \"the distinction between a task (a sparse vector) and a task family (a set of task vectors that all share the same sparsity pattern defined with a binary mask)\" is perfect. This was clear and concise and I understand perfectly why this is needed. I urge the authors to add this into the paper and aim for more of these sorts of statements.\n\nThe above discussion on linear identification does indeed clear-up my confusion for why permutation invariance matters. I hope this discussion is helpful for guiding how these concepts are introduced in the paper - but I am now much more comfortable with why the paper raises this as an important point. This is also making it clear to me why connected support would be an important point. To be concrete, I recommend the authors make the notion of linear identification as concrete in the paper as they did in Part 1 above. Even going so far as to explain that the one-to-one student-teach module correspondence can still fail. Figure 3B is a significant improvement, but I think some more could be done with the caption to really hammer home this concept.\n\nThank you for clarifying Theorem 1 and 2. I agree now that they can be left separate. I think something similar to \"Specifically, Theorem 2 states that when the student achieves zero loss for all task latent variables (i.e. not only on the training tasks), then the student modules are a linear combination of the teacher modules. Theorem 1 on the other hand establishes the conditions under which zero loss on the training distribution leads to zero loss on all task latent variables.\" should be added to the paper if it hasn't already been."
                    }
                },
                "number": 28,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3724/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700685941457,
                "cdate": 1700685941457,
                "tmdate": 1700685941457,
                "mdate": 1700685941457,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3jVuGSdGwe",
                "forum": "H98CVcX1eh",
                "replyto": "NI65l0h7dq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_bgW6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_bgW6"
                ],
                "content": {
                    "title": {
                        "value": "Response to Part 4"
                    },
                    "comment": {
                        "value": "I will note that I have not read a third draft of the paper if one was uploaded after my first round of rebuttal responses. That said, based on the authors most recent set of comments, I understand the work far better. I also think that it is clear in what ways the authors can improve on clarity based on this discussion. Thus, I believe a final draft will meet the standard for acceptance and I am increasing my score to a 6.\n\nThank you again to the authors for the constructive discussion."
                    }
                },
                "number": 29,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3724/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700686333043,
                "cdate": 1700686333043,
                "tmdate": 1700686333043,
                "mdate": 1700686333043,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "8hqkGa1Q2A",
            "forum": "H98CVcX1eh",
            "replyto": "H98CVcX1eh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3724/Reviewer_4knX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3724/Reviewer_4knX"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the problem of compositional generalization in modular architectures. The authors show that in the teacher-student setting, it is possible to identify the underlying modules up to linear transformations purely from demonstrations. They further show that meta-learning from finite data can discover modular solutions that generalize compositionally in modular but not monolithic architectures. The authors also demonstrate how modularity implemented by hypernetworks allows discovering compositional behavior policies and action-value functions."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper theoretically shows that students can learn the underlying modules from the teachers under certain conditions.\n2. The results are supported by empirical experiments."
                },
                "weaknesses": {
                    "value": "1. The paper is not very well written and is hard to follow. There are no simple examples explaining the problems the authors are trying to solve.\n2. There is no section that explicitly discusses related work."
                },
                "questions": {
                    "value": "1. Could you rearrange the paper to have a background section explaining things like MAML, hypernetworks, etc, for readers who are not familiar with these concepts?\n2. Could you explain why the network modules have to be hypernetworks in your setting?\n\n\n-----------\nupdate: raised to 6."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3724/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3724/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3724/Reviewer_4knX"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3724/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698798746474,
            "cdate": 1698798746474,
            "tmdate": 1700444113076,
            "mdate": 1700444113076,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "atRsP00wzX",
                "forum": "H98CVcX1eh",
                "replyto": "8hqkGa1Q2A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3724/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3724/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your comments and for taking the time to review our work. \nWe have spend considerable effort to improve the presentation of the paper in order to address your main point about the difficulty of understanding our initial submission.\nBelow we address your individual suggestions and questions point by point.\nWe hope these clarifications will convince you to vote for acceptance of the paper, and we remain available for any further questions.\n\n> The paper is not very well written and is hard to follow. There are no simple examples explaining the problems the authors are trying to solve.\n\nWe have revised the presentation of the paper in general and the theoretical exposition in particular. We hope this makes the paper easier to follow. In particular, section 3.2 which contains our main theoretical result has been revised. It now starts with a concrete example accompanied by an illustration in Figure 2B and states definitions and theorems in a way we hope is easier to parse.\n\n> There is no section that explicitly discusses related work.\n\nThank you for making us aware of this potential misunderstanding.\nWe have treated related work as part of our discussion section. We clarify this now by changing the section title to \"Related work and Discussion\". In addition, we added an \"Extended related work\" section in Appendix~E.\n\n> 1. Could you rearrange the paper to have a background section explaining things like MAML, hypernetworks, etc, for readers who are not familiar with these concepts?\n\nWe have revised the methods section to make the exposition to hypernetworks and MAML easier to digest for readers not familiar with these concepts and added a missing reference to the corresponding appendix section D, where we provide a detailed description of all models.\n\n> 2. Could you explain why the network modules have to be hypernetworks in your setting?\n\nThank you for pointing out that this was not clearly communicated.\nWe clarified the setting we consider in Section 2:\n\nTo endow our data generating distributions with compositional structure, for each task we recombine sparse subsets of up to $K$ components from a pool of $M$ modules.\nEach task can be fully described by a  latent code $z$ that specifies the combination of module parameters $(\\Theta^{(m)})_{1 \\leq m \\leq M}$ which parameterizes a task-shared function $g$ with parameters\n\n$\\omega(z) = \\sum^{M}_{m=1} z^{(m)} \\Theta^{(m)}$.\n\nGiven this vantage point, hypernetworks are one possible choice to capture this class of compositional problems using neural networks.\nWe believe they are a natural choice, as they can be seen as implementing functions with composable parameters using neural networks both to implement the function itself as well as to implement the parameterization of the function using module composition.\nThe strong performance of the hypernetworks in our experiments on the compositional preferences and compositional goals grid worlds provide evidence, that this module composition in weight space is indeed an expressive architecture to capture varied compositional structure."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3724/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700138170066,
                "cdate": 1700138170066,
                "tmdate": 1700138170066,
                "mdate": 1700138170066,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JxYzw7ye1B",
                "forum": "H98CVcX1eh",
                "replyto": "atRsP00wzX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_4knX"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3724/Reviewer_4knX"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the response"
                    },
                    "comment": {
                        "value": "Thanks for your explanation and revision to improve the readability.\nI would slightly raise my score to 6 but still in a borderline position."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3724/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700444084733,
                "cdate": 1700444084733,
                "tmdate": 1700444084733,
                "mdate": 1700444084733,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]