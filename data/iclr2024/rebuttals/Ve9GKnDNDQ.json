[
    {
        "title": "Diffusion-Stego: Training-free Diffusion Generative Steganography via Message Projection"
    },
    {
        "review": {
            "id": "AI34E5df59",
            "forum": "Ve9GKnDNDQ",
            "replyto": "Ve9GKnDNDQ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4733/Reviewer_xvqX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4733/Reviewer_xvqX"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces Diffusion-Stego, a Generative Steganography scheme. It employs ODE-solvers to handle diffusion images/noises, which can be approximately considered as invertible data pairs."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The proposed method achieves a high capacity while preserving impressive visual quality."
                },
                "weaknesses": {
                    "value": "1) Apart from MN, both MB and MC alter the original Gaussian distribution, which results in a reduction of diversity in the produced stego images. For instance, the stego samples depicted in Figure 9 and Figure 11 of the supplement appear visually inadequate. In contrast, there are several demonstrably secure generative steganography techniques [A-D] that are able to maintain the original distribution.\n2) Slight distortions, as indicated in supplementary materials like image storage quantization, can result in significant performance degradation. Moreover, it's relatively easy to distinguish between AIGC-generated images and natural images [E-F]. Thus, in terms of Security and Robustness, Diffusion-Stego might be less practical in real-world applications.\n3) The three mapping rules are hand-crafted, which is too simple. I think using MLPs or some lightweight networks to learn mapping rules may be a better choice.\n\nRef:\n\n[A] Cachin C. An information-theoretic model for steganography[C]//Information Hiding: Second International Workshop, IH\u201998 Portland, Oregon, USA, April 14\u201317, 1998 Proceedings. Berlin, Heidelberg: Springer Berlin Heidelberg, 1998: 306-318.\n\n[B] Yang K, Chen K, Zhang W, et al. Provably secure generative steganography based on autoregressive model[C]//International Workshop on Digital Watermarking. Cham: Springer International Publishing, 2018: 55-68.\n\n[C] Ding J, Chen K, Wang Y, et al. Discop: Provably Secure Steganography in Practice Based on \u201cDistribution Copies\u201d[C]//2023 IEEE Symposium on Security and Privacy (SP). IEEE Computer Society, 2023: 2238-2255.\n\n[D] Kaptchuk G, Jois T M, Green M, et al. Meteor: Cryptographically secure steganography for realistic distributions[C]//Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security. 2021: 1529-1548.\n\n[E] Wang S Y, Wang O, Zhang R, et al. CNN-generated images are surprisingly easy to spot... for now[C]//Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020: 8695-8704.\n\n[F] Lorenz P, Durall R L, Keuper J. Detecting Images Generated by Deep Diffusion Models using their Local Intrinsic Dimensionality[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023: 448-459."
                },
                "questions": {
                    "value": "See Weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4733/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698588260571,
            "cdate": 1698588260571,
            "tmdate": 1699636455171,
            "mdate": 1699636455171,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TzcRqmEhB9",
                "forum": "Ve9GKnDNDQ",
                "replyto": "AI34E5df59",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4733/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4733/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your comments about our paper.\n\n# Response to Weakness 1.\n\nFigure 9-(c) and 11 depict images generated using the MN method, which does not distort the distribution. This suggests that the perceived inadequacy in these images may stem from the dataset or the trained model. We consider the quality of the proposed images in our appendix (Figure 9, and 11) is comparable to those proposed samples from [1]. The model trained on LSUN Bedroom images, has demonstrated high quality, suggesting that generating images from the LSUN Cat dataset might pose a challenge.\nIndeed, images generated by the EDM model trained on the  easily learnable afhq-v2 dataset exhibit high quality.\n\n# Response to Weakness 2.\n\nWe acknowledge that the mentioned issues raised may be inherent in the broader field of generative steganography research. Nonetheless, our approach, utilizing models specifically trained for image generation, yields higher-quality images in comparison to traditional generative steganography methods. This enhanced image quality contributes to increased indistinguishability from real images.\n\nMoreover, when employing distortion-free methods such as the MN method, steganalyzers are unable to discern whether the generated images are stego images or not.\n\n# Response to Weakness 3.\n\nIn our methodology, two players only need to share the same generative model and the method of message projection. \nWhile it is possible to train new networks for message mapping, this approach significantly increases the amount of information that needs to be shared between the two participants. \nIt also imposes an additional burden of learning new models, aside from diffusion models.\nSpecifically, if we train an additional network to improve the trade-off between accuracy and image quality, we would need to evaluate the diffusion models during the training process, incurring computational cost.\nDue to these considerations, we propose our training-free message projection, which is free from information-sharing requirements.\n\n[1] Song, Yang, et al. \"Consistency models.\" International Conference on Machine Learning. PMLR, 2023."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4733/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700022119109,
                "cdate": 1700022119109,
                "tmdate": 1700022119109,
                "mdate": 1700022119109,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4Goeo9sTRL",
                "forum": "Ve9GKnDNDQ",
                "replyto": "AI34E5df59",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4733/Reviewer_xvqX"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4733/Reviewer_xvqX"
                ],
                "content": {
                    "comment": {
                        "value": "After reading the rebuttal, I think the author's comments are similar to what is written in the paper, with limited new points conveyed. The response to Weakness 3 is relatively good, however the responses to Weakness 1-2 are not. These two issues would affect the practical application value of the proposed method. Especially for Weakness 2, the author agreed that minor distortion can also cause information extraction to fail. However, in my opinion, this problem should not be literally circumvented, but should be solved. If we continue to encourage bypassing the robustness problems in generative steganography, this would only encourage the field to become more useless in the future. In addition, there have been many diffusion-based steganography works recently (I list them down below). Compared to these works, this paper has basically no outstanding features. Therefore, I suggest that the quality of the current version is not up to the overall level of ICLR.\n\n[A] Wei, Ping, Qing Zhou, Zichi Wang, Zhenxing Qian, Xinpeng Zhang, and Sheng Li. \"Generative Steganography Diffusion.\" arXiv preprint arXiv:2305.03472 (2023).\n\n[B] Peng, Yinyin, Donghui Hu, Yaofei Wang, Kejiang Chen, Gang Pei, and Weiming Zhang. \"StegaDDPM: Generative Image Steganography based on Denoising Diffusion Probabilistic Model.\" In Proceedings of the 31st ACM International Conference on Multimedia, pp. 7143-7151. 2023.\n\n[C] Liu, Tengjun, Ying Chen, and Wanxuan Gu. \"Deniable Diffusion Generative Steganography.\" In 2023 IEEE International Conference on Multimedia and Expo (ICME), pp. 67-71. IEEE, 2023.\n\n[D] Yu, Jiwen, Xuanyu Zhang, Youmin Xu, and Jian Zhang. \"CRoSS: Diffusion Model Makes Controllable, Robust and Secure Image Steganography.\", NeurIPS 2023."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4733/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700621202859,
                "cdate": 1700621202859,
                "tmdate": 1700632885922,
                "mdate": 1700632885922,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "QIIo3V4SsG",
            "forum": "Ve9GKnDNDQ",
            "replyto": "Ve9GKnDNDQ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4733/Reviewer_LtLp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4733/Reviewer_LtLp"
            ],
            "content": {
                "summary": {
                    "value": "This article presents a special mapping method to encode secret information into the latent z, and then generates stego images using an existing diffusion model. The article is well-structured and easy to understand. However, in my opinion, the main contribution of this article lies in the three mapping methods, and there is relatively less innovation in this regard."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This article explores the impact of the distribution of latent z on the quality of generated images, which is indeed a question that exists and is worth investigating."
                },
                "weaknesses": {
                    "value": "The key contribution of the article is the introduction of three mapping methods to embed secret information into the latent z. The image generation models are all pre-trained. I think the workload is relatively small, and there is limited innovation."
                },
                "questions": {
                    "value": "1. The text mentions, \"As generative steganography models do not have cover images, third-party players cannot train their steganalyzer models.\" When training a steganalyzer, real images are used as cover images, what about the stego images?Stego images are synthesized images containing secret information or real images with secret information? If stego images are synthesized images with secret information, how can third parties obtain them?\n2. In the comparative experiments, both GSN and S2IRT use generated cover images and generated stego images to train the steganalyzer. What is the purpose of the author using real images for training?\n3. Is there any theoretical derivation that can prove that the zm after message projection follows a Gaussian distribution, or is there any related experimental evidence?\n4. In the experiments, in what format are the images generated by GSN and S2IRT saved, and has there been a standardized format? In reference [32], the images are saved in PNG format, why is it not used in the comparative experiments?\n5. The author mentions, \"The MC projection performs higher extracted message accuracy than the MN projection and better sample quality than the MB projection.\" The MC mapping method produces better image quality, but when generating stego images with the stable diffusion, why use the MB mapping method instead of the MC mapping?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None."
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4733/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698650959281,
            "cdate": 1698650959281,
            "tmdate": 1699636455088,
            "mdate": 1699636455088,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3y05h0dWBe",
                "forum": "Ve9GKnDNDQ",
                "replyto": "QIIo3V4SsG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4733/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4733/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your comments about our paper.\n\n# Response to Weakness.\n\nIn our method, two players only need to share the same generative model and the method of message projection. \nWhile it is possible to train new networks for message mapping, this approach significantly increases the amount of information that needs to be shared between the two participants. \nIt also imposes an additional burden of learning new models, aside from diffusion models. Due to these considerations, we propose our training-free message projection, which is free from information-sharing requirements.\n\n# Response to Question 1.\n\nThe mentioned stego images are indeed synthesized. \nIt is challenging for the defender to obtain these stego images. \nThe assumption in our experiment is that the defender somehow manages to acquire stego images and subsequently trains the steganalyzer.\n\n# Response to Question 2.\n\nIn the context of generative steganography, we believe that a robust model should be capable of generating stego images that are indistinguishable from real images.\nFor instance, models like GSN, which generate both stego and non-stego images, could be defended against by the adversary. \nAfter detecting the images generated by the model, the defender could employ techniques to remove the encryption, irrespective of whether the image is stego or non-stego. \n\n# Response to Question 3.\n\nExcept for the MN methodology, $z_m$ does not follow the Gaussian distribution. \nHowever, since our goal is to create high-quality steganography using pre-trained diffusion models, we have devised a Gaussian distortion method that minimizes the degradation of image quality, as shown in figure 3,6,7, and 8. \nWhile MB distorts the distribution the most, it offers significant advantages in terms of accuracy.\n\n# Response to Question 4.\n\nAll images generated by GSN and S2IRT are saved in the PNG format, consistent with our approach. \nAs for reference [32] you mentioned, I'm not sure which specific reference it refers to.\n\n# Response to Question 5.\n\nWe assume that the stable diffusion experiment you mentioned refers to a high-resolution EDM experiment.\n\nWhile the exact reason remains uncertain, one possible speculated reason is that the high-resolution model may not be well-trained for inputs that deviate significantly from Gaussian noise.\n\nDiffusion models are trained to denoise random noise during the learning process.\nTherefore, distorted $z_m$ through the MB or MC method may exhibit a noise distribution different from what the model learns to denoise.\nConsequently, denoising truncation errors in processing such images might be more pronounced compared to a low-resolution model. \nThis could lead to difficulties in accurately restoring messages during the subsequent message extracting process, potentially due to excessively large truncation errors.\nThe MB method, by maintaining a greater distance between two points, preserves accuracy well, whereas the MC method, with a shorter distance, might not perform as effectively.\n\nIt's worth noting that the EDM proposed in our method primarily targets low-resolution images.\nTraining EDM models on high-resolution images introduces potential instability during learning and might be a contributing factor to the observed decrease in the quality of the MC method."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4733/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700021717440,
                "cdate": 1700021717440,
                "tmdate": 1700021717440,
                "mdate": 1700021717440,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "TfQy1hA8Cm",
            "forum": "Ve9GKnDNDQ",
            "replyto": "Ve9GKnDNDQ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4733/Reviewer_Yv3H"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4733/Reviewer_Yv3H"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes to use diffusion model for generative steganography, where three message projection strategies are proposed to encode the secret into Gaussian noise to fit the diffusion process."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. The use of diffision model for generative image steganography.\n2. The authors propose three strategies to map the secret into the Gaussion noises."
                },
                "weaknesses": {
                    "value": "1. Limited technical contribution. Apart from the usage of the diffusion model, the only technical part is the message mapping strategy, which is rather limited and does not involved any learning process. \n\n2. Experimental issue. There have been studies showing that, once the training images are available, it is farely easy to training a classifier to distinguish the diffusion model generated images from the real images[1]. However, according to the reported results, it seems that the classifier can hardly spot out the diffusion model generated images from the real images. As a matter of fact, in generative image steganography, a common knowledge is that it is almost impossible to generate stego-images with the same distribution as the real images. This is why we always evaluate the undetectability of the stego-images in terms of AIGC images without secret vs. stego-AIGC images.  \n[1] Zhu et al, GenImage: A Million-Scale Benchmark for Detecting AI-Generated Image, arXiv 2023.\n\n3. Limited application value. Most of the images transmitted over the internet are in compressed format like the JPEG. As a matter of fact, most of the social network platforms do not allow the uploading of uncompressed images like the PNG. Therefore, the application value of such a scheme is rather limited.\n\n4. Issues of illigal data extraction. Anyone who knows the mapping machenism will be able to do the message recovery, isn't it?"
                },
                "questions": {
                    "value": "See weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4733/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4733/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4733/Reviewer_Yv3H"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4733/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698738529053,
            "cdate": 1698738529053,
            "tmdate": 1699636454995,
            "mdate": 1699636454995,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dB9oKANV7x",
                "forum": "Ve9GKnDNDQ",
                "replyto": "TfQy1hA8Cm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4733/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4733/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your comments about our paper.\n\n# Response to Weakness 1.\nWe did not introduce additional technical sources such as a learning process. \nThe reason behind this decision is that incorporating elements like a learning process would increase the amount of information that the sender and receiver need to be aware of. \nIf we were to train a new network for use in the projection, both players would have to share the additional weights of the network. \nMoreover, introducing training would entail extra computational costs in the process.\nDue to these considerations, we propose our training-free message projection, which is free from information-sharing requirements.\n\n\n# Response to Weakness 2.\n\n[1] suggests that the distinguishability between generated and real images is contingent upon the dataset's size, which, in the proposed study, is extensive, comprising 1.3 million images. Notably, the effectiveness of discrimination is shown to decline when the dataset is limited, emphasizing the pivotal role of dataset size. \nIn our experiments, the steganalyzers are trained with 5,000 real images, potentially leading to scenarios where the model fails to discern whether an image is a stego image or not, especially if the image quality is sufficiently high.\n\n# Response to Weakness 3.\n\nThat's true, but considering formats like PNG, which offer a reasonable balance between quality and file size compared to high-capacity formats like TIFF, we believe there's still practical value. \nOvercoming this limitation could be a subject for future research.\n\n# Response to Weakness 4.\n\nTo decipher the message embedded in our steganography method, the receiver needs to possess information about the message projection method and the parameters of the diffusion model. If third-party players are unaware of the specific model used to generate the image, even if they understand the mapping mechanism, they cannot recover the message."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4733/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700021484845,
                "cdate": 1700021484845,
                "tmdate": 1700021484845,
                "mdate": 1700021484845,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "diBqy4MjFX",
                "forum": "Ve9GKnDNDQ",
                "replyto": "dB9oKANV7x",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4733/Reviewer_Yv3H"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4733/Reviewer_Yv3H"
                ],
                "content": {
                    "title": {
                        "value": "Comments from Reviewer Yv3H"
                    },
                    "comment": {
                        "value": "I maintain my rating after reading the rebuttal. Note that, according to Kerckhoffs's principle, we should assume that the attacker knows the algorithm  to analyze the security."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4733/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700729512439,
                "cdate": 1700729512439,
                "tmdate": 1700729512439,
                "mdate": 1700729512439,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hRjTm0fgrq",
            "forum": "Ve9GKnDNDQ",
            "replyto": "Ve9GKnDNDQ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4733/Reviewer_Ny5h"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4733/Reviewer_Ny5h"
            ],
            "content": {
                "summary": {
                    "value": "A diffusion based generative steganography method is presented. Secrete messages are projected into the noise of the diffusion model and produces stego images during the reverse process. The projection trades off between message accuracy, antidetection ability and quality of the image. The proposed method generates high quality stego image with high capacity message."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "-The readability of the paper is good. \n- The proposed diffusion based generative steganography produces high fidelity stego images with higher capacity message than compared methods."
                },
                "weaknesses": {
                    "value": "-The high stego image quality is achieved not by any novelty but it comes from the diffusion model itself. In addition, the other properties that you look for in a stego image probably comes from the diffusion process and not from any novelty that the paper proposes. \n\n-Although the projection is a way for introducing message into the diffusion model but it would be difficult to prove that it is a mathematically optimum way of introducing the message. Multiple bits can be introduced in the projection. The paper discusses two bits but you can generalize to more than two bits. It would be interesting to know their performance. \n\n-This paper provides one working method for producing stego images but it lack mathematical analysis or theory. The paper is suggesting one engineering method for generating stego images based on the diffusion process and it is difficult to say it is anyway unique.\n\n- How do you deal with the scalability issues with the proposed method?\n\n- What can you say about the computation and latency issue with the proposed method?"
                },
                "questions": {
                    "value": "Please see weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4733/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699529536134,
            "cdate": 1699529536134,
            "tmdate": 1699636454930,
            "mdate": 1699636454930,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xfgkXtdrMU",
                "forum": "Ve9GKnDNDQ",
                "replyto": "hRjTm0fgrq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4733/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4733/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your comments about our paper.\n# Response to Weakness 1.\n\nWe acknowledge the novelty of proposing a method that capitalizes on the characteristics of previously suggested models to undertake a distinct task, such as steganography.\n\nAs shown in Figures 3,6,7, and 8, we noted a degradation in image quality and the incapacity to generate images when manipulating the noise of diffusion models. Consequently, we introduced message projection as a means of manipulating the noise using diffusion models for steganography, which, we believe, introduces novelty.\n\nThis novelty extends to the features obtained from stego images. Our method not only ensures higher image quality compared to other existing generative steganography approaches but also facilitates the use of the proposed novelty, message projection, without significantly impacting the model's training or the generation process of the trained model. Furthermore, the accuracy of our model, manipulated by the noise through our message projection, allows us to adjust the accuracy-quality trade-off, addressing issues that could arise from naive methods, as demonstrated in Appendix Figures 6,7, and 8.\n\nRather than treating diffusion models as a black box, we introduced a new method by combining the mathematical properties proposed in previous diffusion model research [1, 2] and our experimental analysis. Considering these factors, it is challenging to argue that there is no novelty in our proposal.\n\n# Response to Weakness 2.\n\nWe evaluate the message accuracy using 3 bpp, 6 bpp,9 bpp and 12 bpp messages, considering 1,000 stego images with a pre-trained EDM on the AFHQv2 dataset.\n|Capacity|Accuracy|\n|-|-|\n|3 bpp | 99.37 |\n|6 bpp | 91.56 |\n|9 bpp | 83.18 |\n|12 bpp | 60.40 \n\n# Response to Weakness 3.\n\nWe believe that we are adequately following the mathematical analysis of existing diffusion models. Through previous research on diffusion models, the image generation process is represented by stochastic differential equations (sde) or ordinary differential equations (ODE). Consequently, truncation errors occur during the generation process due to these characteristics. Additionally, data loss occurs during the image storage process. These outcomes result in errors when utilizing diffusion models for steganography. Therefore, to overcome these errors, we propose message projection, based on our analysis, we do not consider our method, including message projection, to be unique.\n\nA1. Our approach inherits the computational characteristics of the underlying diffusion models, as we directly leverage existing diffusion models. \nMoreover, the algorithm implemented in our method exhibits a time complexity of $O(N)$, with $N$ representing the number of binary messages. \n\nA2. Compared to DDPM, recent diffusion models demand a lower computational cost for image generation. Moreover, various methods[3,4] have been suggested to address the latency issue associated with them. We demonstrated the applicability of our approach to recently proposed various diffusion models, and we anticipate its relevance to future research. While the models we employed in this paper are already adept at mitigating this issue, we believe that further research will provide additional solutions.\n\n[1] Karras, Tero, et al. \"Elucidating the design space of diffusion-based generative models.\" Advances in Neural Information Processing Systems 35 (2022): 26565-26577.\n\n[2] Song, Yang, et al. \"Score-based generative modeling through stochastic differential equations.\" In the 9th International Conference on Learning Representations, 2021.\n\n[3] Vahdat, Arash, Karsten Kreis, and Jan Kautz. \"Score-based generative modeling in latent space.\" Advances in Neural Information Processing Systems 34 (2021): 11287-11302.\n\n[4] Rombach, Robin, et al. \"High-resolution image synthesis with latent diffusion models.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4733/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700021324703,
                "cdate": 1700021324703,
                "tmdate": 1700021740686,
                "mdate": 1700021740686,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]