[
    {
        "title": "Communication-Efficient Federated Non-Linear Bandit Optimization"
    },
    {
        "review": {
            "id": "9lTtI9qB9t",
            "forum": "nFI3wFM9yN",
            "replyto": "nFI3wFM9yN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6665/Reviewer_6154"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6665/Reviewer_6154"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces Fed-GO-UCB, a federated bandit optimization algorithm designed for generic non-linear objective functions, addressing the limitations of existing methods that are confined to simplistic function classes. Federated optimization enables collaborative model estimation across decentralized datasets, ensuring data privacy and allowing large-scale computing. This is particularly beneficial for tasks requiring online interactions, such as next-word prediction in keyboard applications. Fed-GO-UCB operates under the coordination of a central server and multiple clients, ensuring data decentralization. The algorithm comprises two phases: uniform exploration and optimistic exploration, allowing clients to collaboratively minimize cumulative regret and make quality decisions during the learning process. The paper highlights the challenges in federated bandit optimization, particularly in constructing confidence sets for generic nonlinear functions and managing communication costs. Fed-GO-UCB addresses these issues through a novel confidence set construction and an efficient communication strategy. Empirical evaluations demonstrate the algorithm's superiority over existing federated bandit algorithms, particularly in approximating nonlinear functions. The paper also proves that Fed-GO-UCB achieves sub-linear rates for both cumulative regret and communication cost, making it a promising tool for decentralized machine learning applications involving sensitive data."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Novelty: Fed-GO-UCB is a new approach in federated bandit optimization for generic non-linear function optimization.\n\n2. Theoretical Guarantees: The paper provides rigorous proofs for the sub-linear rates of cumulative regret and communication cost, ensuring the algorithm's reliability and efficiency.\n\n3. Empirical Validation: The effectiveness of Fed-GO-UCB is demonstrated through extensive empirical evaluations, showcasing its superiority in approximating nonlinear functions and its practical applicability."
                },
                "weaknesses": {
                    "value": "1. Limited Discussion on Assumptions: The paper mentions \u201csome mild conditions\u201d under which the algorithm performs well, but it could provide a more detailed discussion on these conditions and their practical implications.\n\n2. Comparison with State-of-the-Art: While the paper demonstrates the superiority of Fed-GO-UCB over existing federated bandit algorithms, a more comprehensive comparison with state-of-the-art methods in decentralized machine learning would strengthen the paper's contributions.\n\n3. Over-reliance on Communication: The need for occasional communications to aggregate local learning parameters may lead to potential inefficiencies or delays."
                },
                "questions": {
                    "value": "1. How does the performance of Fed-GO-UCB compare with centralized global optimization methods, particularly in scenarios with a high number of clients?\n\n2. Can Fed-GO-UCB be extended to handle heterogeneous clients with different reward functions, and if so, what modifications would be necessary?\n\n3. What are the practical implications of the \u201cmild conditions\u201d under which Fed-GO-UCB operates, and how do these conditions influence the algorithm's applicability in real-world scenarios?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6665/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6665/Reviewer_6154",
                        "ICLR.cc/2024/Conference/Submission6665/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6665/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698735037494,
            "cdate": 1698735037494,
            "tmdate": 1700578531828,
            "mdate": 1700578531828,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2CQQ6ETMQa",
                "forum": "nFI3wFM9yN",
                "replyto": "9lTtI9qB9t",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6665/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6665/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 6154 [Part 1/2]"
                    },
                    "comment": {
                        "value": "**[Q1] Discussion on assumptions and their practical implications**\n\nPlease find our answer to CQ1 in the common response for discussions about the assumptions made in our paper. \n\nHere we want to emphasize that the function class defined by Assumptions 1-3 generalizes the parametric function classes studied in existing federated bandit papers (Wang et. al. 2020; Li and Wang, 2022a; He et. al., 2022; Li and Wang, 2022b), and also covers additional nonlinear, nonconvex functions that have not been considered in existing works in federated bandits. We want to emphasize that this is already a nontrivial improvement.\n\nIn terms of applicability in real-world scenarios, it is worth noting that linear and generalized linear models (both are special cases of ours) have already been shown to perform well in applications like news recommendation (Li et. al., 2010), and our generalization offers even more flexibility in the modeling choices during federated optimization, i.e., any parametric functions, including neural networks, that satisfy our local strongly convexity assumption.\n\n**[Q2] Comparison with decentralized machine learning methods**\n\nThanks for the suggestion. We have added a section in Appendix B to discuss existing works in offline federated learning / decentralized machine learning to help further highlight the contribution of our paper.\n\nHowever, we want to clarify that, due to the fundamental differences in the problem formulation and learning objectives between federated bandit learning and decentralized machine learning, direct comparison in theoretical analysis and experiments is not possible. \nSpecifically, the focus of decentralized machine learning is to collaboratively learn a good *point estimate* over a fixed dataset, i.e., convergence to the minimizer with fewer communications/iterations, while federated bandit learning requires collaborative *confidence set estimation* for efficient regret reduction over a finite time horizon $T$.\n\nOne perspective to understand their relation is that federated bandit learning studies decision making over the whole time horizon $T$, while decentralized machine learning aims to solve the optimization problem on the dataset collected up to a fixed time step $t \\in [T]$, i.e., the latter can be viewed as a component of the former. For example, in our Fed-GO-UCB algorithm, we can adopt any decentralized machine learning method as the *Oracle* to optimize Equation (2), but we still need the other components, e.g., confidence set construction (line 4) and OFU principle (line 3) for effective decision making. Therefore, these two are not directly comparable.\n\n\n**[Q3] The need for occasional communications may lead to inefficiencies or delays**\n\nWe definitely agree with the reviewer that such communication \u201cmay lead to potential inefficiencies or delays\u201d, but as discussed in our response to CQ2, in order to avoid the suboptimal regret $\\tilde O(N \\sqrt{T})$, communication among clients is necessary.\n\nThis is why we need a well-designed federated bandit optimization method like Fed-GO-UCB to attain a good tradeoff between the conflicting objectives of regret minimization and communication efficiency, i.e., we wish to have the most regret reduction per communication. We have shown both theoretically and empirically, that our Fed-GO-UCB algorithm achieved this goal for the federated bandit optimization of nonlinear functions."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6665/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700422431708,
                "cdate": 1700422431708,
                "tmdate": 1700422431708,
                "mdate": 1700422431708,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2u0Jfe0rEI",
                "forum": "nFI3wFM9yN",
                "replyto": "2CQQ6ETMQa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6665/Reviewer_6154"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6665/Reviewer_6154"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the detailed response, solving my questions greatly. I will raise my score."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6665/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700578508563,
                "cdate": 1700578508563,
                "tmdate": 1700578508563,
                "mdate": 1700578508563,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "jsqY3W40sb",
            "forum": "nFI3wFM9yN",
            "replyto": "nFI3wFM9yN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6665/Reviewer_yBxF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6665/Reviewer_yBxF"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the federated bandit optimization where the objective functions are non-linear yet i.i.d across $N$ agents. Existing works focus on either simplistic function classes or non-parametric function classes with bounded RKHS norms. In this paper, the authors propose a new Fed-GO-UCB algorithm, which contains two phases: the uniform exploration phase and the online learning phase. The authors prove that Fed-GO-UCB ahives $O(\\sqrt{NT})$ regret while achieving $O(N^{1.5}\\sqrt{T})$ communication cost. Finally, the authors conduct empirical experiments on both synthetic and real-world data to validate their theoretical results."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The problem setting is new and well-motivated. Compared with existing works that follow either simplistic function classes or non-parametric function classes with bounded RKHS norm, this work considers a more general non-linear form of objective function.\n2. The results are sound and complete, with both theoretical analysis and empirical evaluation.\n3. The algorithms and the analysis both have some novelty, for example, the two phase algorithms and the analysis built upon it."
                },
                "weaknesses": {
                    "value": "1. Novelty: Though the setting is new and the two-phase design is interesting, after the uniform exploration (phase 1), it seems to me that one can combine the techniques from centralized non-linear bandit optimization problem with the communication protocol from the federated linear bandits (Li & Wang, 2022a) and federated generalized linear bandits (Li & Wang, 2022b).\n2. Comparison with federated generalized linear bandits (Li & Wang, 2022b): From the algorithmic perspective, Li & Wang 2022b also uses some global updates (similar to uniform exploration) after the communication condition (line 6 of Algorithm 1) is satisfied, I am wondering if the current paper also uses this way to update $\\hat{w}_0$, will there be any difference or improvement in the regret analysis? Moreover, I find that Li & Wang, 2022b can only achieve $O(dN^2\\sqrt{T})$ communication. Since I suppose the current paper is more general and can cover Li & Wang 2022b, does this mean that the current paper can achieve a $O(\\sqrt{N})$ improvement because of the difference in the algorithm design?  \n3. Lower bound: I do not find any discussion about the lower bound result or any discussion about it. Without it, one cannot see how tight the results are in terms of $$N, T$$ and all other parameters. I hope the authors can discuss the tightness of their results during the rebuttal."
                },
                "questions": {
                    "value": "Please justify or comment on the three weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6665/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698751322375,
            "cdate": 1698751322375,
            "tmdate": 1699636762844,
            "mdate": 1699636762844,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xtNnm6I8UJ",
                "forum": "nFI3wFM9yN",
                "replyto": "jsqY3W40sb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6665/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6665/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer yBxF"
                    },
                    "comment": {
                        "value": "**[Q1] Novelty**\n\nAs mentioned in the Technical novelties paragraph in Section 1, the approximation method from centralized non-linear bandit optimization (Liu and Wang, 2023) cannot be applied to the federated setting. Specifically, the confidence sets for the optimal parameter $\\omega^\\star$ constructed in (Liu and Wang, 2023) is $\\{\\omega: \\lVert \\omega - \\hat \\omega_t \\rVert_{\\Sigma_{t}} \\leq \\beta_{t}\\}$, where $\\Sigma_t =\\lambda \\mathbf{I} + \\sum_{s=1}^{t} \\nabla f_{x_s}(\\hat \\omega_{s}) \\nabla f_{ x_s}(\\hat \\omega_{s})^\\top$ and $b_t =\\sum_{s=1}^{t} \\nabla f_{x_s}(\\hat \\omega_{s}) \\bigl[\\nabla f_{ x_s}(\\hat \\omega_{s})^\\top \\hat \\omega_{s} + y_s - f_{x_s}(\\hat \\omega_{s}) \\bigr]$, where the gradients $\\nabla f_{x_s}(\\hat \\omega_{s})$ have to be calculated w.r.t. the model $\\hat \\omega_{s}$ at step $s$.\n\nDue to local model updates in federated settings, now each client $i$ has a different sequence of local models $\\hat \\omega_{s,i}$ for $s=1,2,\\dots,t$. By directly aggregating the statistics $\\Sigma_{t,i}$ and $b_{t,i}$ computed based on such $N$ different sequences of local models, one cannot obtain a valid confidence set. To address this issue, we improve the analysis of Liu and Wang (2023), and show that we can construct a valid confidence set using the gradients w.r.t. a common initial model $\\hat \\omega_0$, instead of clients\u2019 locally updated ones. \n\nTherefore, after obtaining $\\hat \\omega_0$ at the end of Phase I, the clients can collaborate on confidence set estimation via a common embedding function defined by the gradient $\\nabla f_{x_s}(\\hat \\omega_{0})$. This is why we are able to utilize the communication protocol designed for federated linear bandits (Wang et. al. 2020). We want to emphasize that being able to utilize communication protocols designed for federated linear bandits for nonlinear functions via our novel confidence set construction is already non-trivial and may be of independent interest for future research. For example, one can also extend our method to asynchronous protocols (Li and Wang, 2022a; He et. al, 2022), as well as heterogeneous clients setting (Liu et. al. 2022). Moreover, as discussed in our response to CQ2, this new algorithm design helps us improve upon FedGLB-UCB (Li and Wang, 2022b) by a factor of $d_x \\sqrt{N}$ for federated optimization of nonlinear functions, because in Phase II we are able to use the efficient closed-form update as federated linear bandits, instead of the expensive iterative optimization as FedGLB-UCB.\n\n\n**[Q2] Improvement compared with federated generalized linear bandits (Li & Wang, 2022b)**\n\nYes, our paper has an $\\tilde O(d_x \\sqrt{N})$ improvement on communication cost thanks to the new algorithm design. Please see our answer to CQ2 in the general response for more details about how this is achieved. \n\n**[Q3] Tightness of communication cost upper bound**\n\nPlease see our answer to CQ2 in the common response for discussions on the tightness of our communication cost upper bound in terms of $N$ and $T$.\n\n\n**Additional References**\n\n- Xutong Liu, Haoru Zhao, Tong Yu, Shuai Li, and John CS Lui. \"Federated online clustering of bandits.\" In Uncertainty in Artificial Intelligence, pp. 1221-1231. PMLR, 2022."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6665/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700421358285,
                "cdate": 1700421358285,
                "tmdate": 1700421358285,
                "mdate": 1700421358285,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wXNdm7Fll1",
            "forum": "nFI3wFM9yN",
            "replyto": "nFI3wFM9yN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6665/Reviewer_emcJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6665/Reviewer_emcJ"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a communication-efficient federated algorithm, Fed-GO-UCB, for a bandit optimization problem with non-linear function. Their analysis shows that the regret upper bound of Fed-GO-UCB matches that of Fed-GO-UCB's centralized counterpart with sub-linear communication costs. The authors explain the main logics behind analysis in details. Empirical experiment results are also included."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This work is one of the pioneering effort in studying federated bandit optimization with non-linear function\n- This work generalizes a distributed regression theoretical guarantee to account for approximation error, which may be of interest to the federated learning community \n- This paper is in general well written and easy to follow"
                },
                "weaknesses": {
                    "value": "- The literature review provided is somewhat brief and limited in scope and detail\n- Though this work features considering non-linear function optimization, it seems that its main contribution is on addressing the challenges of federated setting. Could the authors discuss more about the special challenges of non-linear function optimization?"
                },
                "questions": {
                    "value": "- The novel technical contributions of this work are Lemma 6 and 8 if I understand correctly. Shouldn't these two lemmas be named as Propositions instead? \n- Could the authors comment on the difficulties in obtaining Lemma 6 and 8? Which part of difficulties is due to the federated setting and which part of the difficulties is due to the non-linear function?\n- Could the authors comment on the tightness of the communication cost bound?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6665/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6665/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6665/Reviewer_emcJ"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6665/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698809060222,
            "cdate": 1698809060222,
            "tmdate": 1699636762721,
            "mdate": 1699636762721,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0Ca2L4KMul",
                "forum": "nFI3wFM9yN",
                "replyto": "wXNdm7Fll1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6665/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6665/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer emcJ"
                    },
                    "comment": {
                        "value": "**[Q1] Additional discussions on related works** \n\nWe agree with Reviewer emcJ that more detailed and comprehensive discussions on related works would better highlight the contribution of our paper, so in Appendix B we have added a section to discuss related works in federated bandit learning and offline federated learning, as well as a table summarizing existing federated bandit algorithms. Please also see our answer to CQ2 in the common response for a detailed discussion about theoretical comparison with existing works on federated bandit learning.\n\n\n**[Q2] Challenges of nonlinear function optimization**\n\nWe want to clarify that the unique challenge addressed in this paper is bandit optimization of **nonlinear functions under federated settings**. We cannot view them separately as suggested by the reviewer. Specifically, federated setting requires communication efficiency, and bandit optimization of nonlinear functions requires construction of confidence sets. Therefore, the unique question answered in our paper is, how to construct confidence sets for the nonlinear functions collaboratively by all clients in a communication efficient manner, which cannot be addressed by prior works. \n\n\nAs mentioned in the Technical novelties paragraph in Section 1 of our paper, the approximation method we propose is a non-trivial extension of (Liu and Wang, 2023), i.e., their method cannot be applied to federated settings as their approximation relies on a sequence of continuously updated models $\\hat \\omega_{s}$ for $s=1,2,\\dots,t$. But in federated settings, each client has a different sequence of locally updated models, which leads to difficulty in aggregating local statistics (see also our answer to Q1 of Reviewer yBxF). This problem does not exist for federated linear bandits, since the confidence set for linear models can be directly constructed using feature vector $x$, instead of gradient $\\nabla f_{ x_s}(\\hat{\\omega}_{s})$.\n\n\nTo address this issue, we propose a new approximation procedure with improved analysis over Liu and Wang (2023), such that the statistics computed by all clients are now based on a common embedding function $\\nabla f_{x_s}(\\hat{\\omega}_{0})$, i.e., the gradient w.r.t. the shared model $\\hat \\omega_0$. Note that $\\hat \\omega_0$ is obtained at the end of Phase I and then always remains fixed.\n\n\nCompared with prior works in federated linear bandits, which conveniently enjoys closed-form solutions, nonlinear function faces another challenge, i.e., it requires iterative optimization for each model update, which is expensive in federated settings. As mentioned in our answer to CQ2, prior work that studies generalized linear models [Li and Wang 2022b] needs to call the distributed regression oracle during each global synchronization to execute such an expensive iterative optimization procedure. We alleviate this issue by only executing the iterative optimization at the end of Phase I, and then resorting to approximated function value during Phase II, so that more efficient communication is enabled thanks to its closed-form update. \n\n**[Q3] Lemma 6 and Lemma 8**\n\n\nYes, Lemma 6 and Lemma 8 are the main technical contributions of this paper. We currently name them as Lemmas instead of Propositions, because they will be invoked as intermediate steps to prove Theorem 5, instead of being standalone technical results. \n\n\nAs mentioned in Section 5.1, prior work in centralized nonlinear bandit optimization (Liu and Wang, 2023) assumes the distributed regression oracle outputs the exact minimizer of Equation (2). However, this is unreasonable in a federated setting, since finding the exact minimizer would require an infinite number of iterations, which is not communication efficient. Therefore, when deriving Lemma 6, we need to take into account the additional approximation error $\\epsilon$ in optimizing Equation (2), and analyze the number of iterations required to attain $\\epsilon$ (this is needed in the communication cost analysis later).\n\n\nFor the difficulty in constructing the confidence sets in Lemma 8, please see our response to Q2.\n\n\n**[Q4] Tightness of the communication cost upper bound**\n\nPlease see CQ2 in the common response for discussions on tightness of the communication cost bound."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6665/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700420799445,
                "cdate": 1700420799445,
                "tmdate": 1700420816031,
                "mdate": 1700420816031,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "i3raIUKxC4",
                "forum": "nFI3wFM9yN",
                "replyto": "wXNdm7Fll1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6665/Reviewer_emcJ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6665/Reviewer_emcJ"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the authors' response to my questions and the revisions in their paper."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6665/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700649812336,
                "cdate": 1700649812336,
                "tmdate": 1700649812336,
                "mdate": 1700649812336,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "TNrNKxCf0Q",
            "forum": "nFI3wFM9yN",
            "replyto": "nFI3wFM9yN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6665/Reviewer_rFun"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6665/Reviewer_rFun"
            ],
            "content": {
                "summary": {
                    "value": "This paper's primary focus is on tackling the non-linear bandit optimization problem within a federated setting. It introduces the innovative Fed-GO-UCB algorithm, which represents a substantial improvement over previous centralized algorithms. Remarkably, this federated algorithm achieves a theoretical regret guarantee comparable to previous centralized approaches, specifically $O(\\sqrt{NT})$, while also demonstrating sub-linear communication complexity. Additionally, the empirical results robustly confirm the efficiency and effectiveness of the proposed algorithm."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed algorithm excels in providing a near-optimal guarantee for federated learning with generic non-linear function optimization.\n\n2. The empirical results robustly confirm the efficiency and effectiveness of the proposed algorithm.\n\n3. This paper is well-written and easily comprehensible."
                },
                "weaknesses": {
                    "value": "1. The theoretical guarantee of Fed-GO-UCB relies on several critical assumptions (Assumptions 1 to 3), and it may be challenging to establish whether these assumptions hold in common situations, such as neural networks with ReLU activation functions. Even if the assumptions hold, determining the values of the parameters in Fed-GO-UCB that depend on these assumptions can be a non-trivial task. It remains an open question how to calculate these constants and set the algorithm's parameters effectively in practical applications.\n\n2. The communication complexity, as indicated by Theorem 5, is stated as $O(\\sqrt{T})$, which is significantly higher than the communication complexity of $O(\\log T)$ achieved by previous works. Presenting this level of communication cost as efficient without providing lower bound results for communication complexity can be misleading. Furthermore, the experimental results in Figure 2 show a communication complexity of $10^7$ for round $T=500$, which seems highly inefficient in practice.\n\n3. In the context of federated learning, there is often a tradeoff between communication complexity and performance, specifically in terms of regret guarantee. It's a common observation that algorithms with higher communication complexity can potentially achieve better performance. To gain a clearer understanding of the algorithms' relative performances, it would be beneficial for the author to conduct experiments where the selected parameters makes different algorithms have similar communication complexity. This approach would enable a direct and fair comparison that isolates the impact of communication complexity from the approximation capabilities, providing more conclusive insights into the algorithm's efficiency and effectiveness in a practical federated learning setting."
                },
                "questions": {
                    "value": "1. In the Fed-GO-UCB algorithm, it's important to clarify that agents should reset $\\Delta\\Sigma$ and $\\Delta b$ to zero after uploading their respective datasets.\n\n2. In Figure 3, the observation that the communication complexity for several algorithms does not start from zero at time $T=0$ can be puzzling. It would be beneficial if the author could offer an explanation for this behavior.\n\n3. For the Theorem 5, is it possible to provide a corresponding lower bound to suggest that $\\Omega(\\sqrt{T})$ communication is necessary. For instance, Min el al., 2023 [1] provide a lower bound showing\nthat a minimal $\\Omega(dM)$ communication complexity is required to improve the performance of linear bandit (or MDPs) through\ncollaboration. Insights into lower communication complexity bounds would strengthen the support for the Fed-GO-UCB algorithm and provide a more comprehensive understanding\n\n[1] Cooperative Multi-Agent Reinforcement Learning: Asynchronous Communication and Linear Function Approximation"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6665/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698959369178,
            "cdate": 1698959369178,
            "tmdate": 1699636762611,
            "mdate": 1699636762611,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "77OmfsWzRr",
                "forum": "nFI3wFM9yN",
                "replyto": "TNrNKxCf0Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6665/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6665/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer rFun [Part 1/2]"
                    },
                    "comment": {
                        "value": "**[Q1] Whether the assumptions hold in common situations and how to determine the values of the parameters**\n \nPlease find our answer to CQ1 in the common response for discussions about the assumptions made in our paper. \n\nHere we want to emphasize that, though still with its limitations, the function class defined by Assumptions 1-3 generalizes the parametric function classes studied in existing federated bandit papers (Wang et. al. 2020; Li and Wang, 2022a; He et. al., 2022; Li and Wang, 2022b), and also covers additional nonlinear, nonconvex functions that have not been considered in prior works. It is worth noting that linear and generalized linear models (both are special cases of ours) have already been shown to perform well in real-world applications like news recommendation (Li et. al., 2010), and our generalization offers even more flexibility in the modeling choices during federated optimization.\n\nMoreover, we want to clarify that, Fed-GO-UCB algorithm does not need to know the values of the constants appearing in Assumptions 1-3, except for the bound of function value $F$ and the strong convexity parameter $\\mu$ in order to set the width of the confidence set $\\beta$ (as given in Lemma 8). Both constants are assumed to be known in bandit learning literature, e.g. linear bandits (Abbasi-yadkori, 2011; Wang et. al., 2020), logistic bandits (Faury et. al., 2020), and generalized linear bandits (Filippi et. al., 2010; Li and Wang, 2022b), so we are not introducing any additional assumption on the knowledge of these constants compared with prior works. \n\nIn practical applications, since these two constants, and the standard deviation $\\sigma$ of reward noise that also appears in $\\beta$, are unknown before observing the data, people typically directly tune the value of $\\beta$ when applying bandit algorithms under different scenarios. But we agree that it would be an interesting future direction to investigate whether one can design no-regret bandit algorithms that do not require such knowledge as input, i.e., automatically adapt the strength of exploration to these unknown constants in an online manner.\n\n\n**[Q2] Tightness of communication cost upper bound and comparison with prior works**\n\nPlease find our answer to CQ2 in the common response about the communication lower bound and detailed comparison with prior works. \n\nSpecifically, we want to clarify that, the mentioned $O(\\log(T))$ rate is attained by prior works on federated linear bandits (Wang et. al., 2020; Li and Wang, 2022a; He et al., 2022; Min et al. 2023), and federated kernelized bandits (Li et al., 2022; Li et al., 2023), where closed-form solutions are available, so that only one round of communication is needed to aggregate the local sufficient statistics for model update. \n\nIn comparison, our work is more similar to (Li and Wang, 2022b) that studies federated generalized linear bandits, in the sense that, both consider nonlinear functions with no closed-form solution, and thus iterative optimization is needed to compute model update. This is intrinsically more expensive, because at least $\\Omega(\\sqrt{NT})$ rounds of communication is needed to collect and aggregate local gradients/models when calling the distributed regression oracle (see the discussions in Section 4.1 and 4.2 of Li and Wang (2022b), as well as the lower bound result of Arjevani and Shamir (2015)). Moreover, as discussed in our answer to CQ2, we strictly improve upon the result of Li and Wang (2022b) by a factor of $d_x \\sqrt{N}$, since we only need to call the regression oracle once at the end of Phase I, instead of at each global synchronization as Li and Wang (2022b). As shown in the table in CQ2, Fed-GO-UCB is currently the most communication efficient solution for federated bandit optimization of nonlinear function, which is already a nontrivial contribution to the literature."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6665/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700419893679,
                "cdate": 1700419893679,
                "tmdate": 1700424360750,
                "mdate": 1700424360750,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SIN2WylyUs",
                "forum": "nFI3wFM9yN",
                "replyto": "3gY2jQir5v",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6665/Reviewer_rFun"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6665/Reviewer_rFun"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the response and I will keep my positive score."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6665/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700528370487,
                "cdate": 1700528370487,
                "tmdate": 1700528370487,
                "mdate": 1700528370487,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]