[
    {
        "title": "Threaten Spiking Neural Networks through Combining Rate and Temporal Information"
    },
    {
        "review": {
            "id": "2O8NbTd7qQ",
            "forum": "xv8iGxENyI",
            "replyto": "xv8iGxENyI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission56/Reviewer_4VCV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission56/Reviewer_4VCV"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents HART, an adversarial attack for SNNs. An analysis of rate and temporal information in SNNs identifies the importance of rate information in SNNs. The proposed attack combines rate and temporal information. The results show better attack success rates than related works on CIFAR-10 and CIFAR-10-DVS datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The tackled problem is relevant to the community.\n\n2. The proposed attack is novel.\n\n3. The results outperform related works."
                },
                "weaknesses": {
                    "value": "Some aspects are not completely clear. Please see the questions below."
                },
                "questions": {
                    "value": "1. In Table 1, please clarify what results are relative to CBA and what results are relative to the proposed attack.\n\n2. In Section 4.2: \u201cTherefore, we attempt to measure the retention degree of temporal information in SNNs through the following equation.\u201d Please provide more details of the intuitions and design decisions made to develop Eq.12.\n\n3. Please describe the proposed attack through a detailed algorithm that collects all the operations and equations involved. The current description with several equations may be unclear.\n\n4. Section 5 contains the results when varying the parameters of the attack. However, there is very little discussion on the results and reasons why certain values of the parameters achieve higher attack success rates than others. Please discuss it in a more comprehensive manner."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission56/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698149025282,
            "cdate": 1698149025282,
            "tmdate": 1699635930195,
            "mdate": 1699635930195,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ajlQKhHGzu",
                "forum": "xv8iGxENyI",
                "replyto": "2O8NbTd7qQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission56/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission56/Authors"
                ],
                "content": {
                    "title": {
                        "value": "To Reviewer 4VCV (Part I)"
                    },
                    "comment": {
                        "value": "## To Reviewer 4VCV\nThanks for your invaluable and constructive feedback! We are encouraged that you find our paper novel and relevant to the community, as well as outperforming related works. We would like to address your concerns and your questions in the following.\n\n\n**Q1: In Table 1, please clarify what results are relative to CBA and what results are relative to the proposed attack.**\n\n**A1:** Thanks for pointing it out! In Table 1, the regular font on the left side of the table represents CBA (the baseline method), while the bold font on the right side represents our proposed attack method. We have made a clarification in our newly submitted version.\n\n\n**Q2: Please provide more details of the intuitions and design decisions made to develop Eq.12.**\n\n**A2:** From Figure 1, it is evident that the same average input current ($W^lr^{l-1}(T)$) can lead to different spike firing rates ($r^l(T)$) due to the non-uniform distribution of input current across multiple consecutive time-steps. Previous studies on ANN-SNN conversion [1, 2] have found that assuming a uniform input current, we have the relationship $r^l(T) = \\frac{1}{T}\\text{clip}\\left( \\left\\lfloor \\frac{TW^lr^{l-1}(T)+v^l(0)}{\\theta^l} \\right\\rfloor, 0, T \\right)$. This implies that the average firing rate of adjacent layers follows an approximate linear transformation, and there exists a one-to-one mapping between $r^l(T)$ and $W^lr^{l-1}(T)$. Although the equation $r^l(T) = \\frac{1}{T}\\text{clip}\\left( \\left\\lfloor \\frac{TW^lr^{l-1}(T)+v^l(0)}{\\theta^l} \\right\\rfloor, 0, T \\right)$ is based on the IF model, it holds true that the one-to-one mapping relationship still applies to general LIF models. In this scenario, the SNN is predominantly influenced by rate information, and the computational relationship between two adjacent SNN layers is entirely equivalent to that of an ANN. Moreover, in this situation, for any $W^lr^{l-1}(T)$, the variance of $\\frac{r^l(T)}{W^lr^{l-1}(T)}$ is zero, that is, $\\mathbf{Var}\\left( \\frac{r^l(T)}{W^lr^{l-1}(T)} \\right)=0$.\n\nFor SNNs with more temporal information, the same average input current ($W^lr^{l-1}(T)$) can lead to different spike firing rates ($r^l(T)$), and the variance of $\\frac{r^l(T)}{W^lr^{l-1}(T)}$ is not zero. Thus, it is reasonable to consider to use the variance of $\\frac{r^l(T)}{W^lr^{l-1}(T)}$ to measure the temporal information and we propose Eq. 12 to measures the richness of temporal information according to the expectation of the variance. As $\\chi^l$ increases, the variations in firing more or fewer spikes due to different spike arrival sequences in Figure 1 become more pronounced. This signifies a stronger influence of temporal information within the SNN.\n\n\n**Q3: Please describe the proposed attack through a detailed algorithm that collects all the operations and equations involved.**\n\n**A3:** Thanks for your constructive suggestion! We have made a detailed algorithm to describe our HART attack framework step by step. Please refer to Section A.3 in the Appendix of our newly submitted version."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission56/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700384033408,
                "cdate": 1700384033408,
                "tmdate": 1700384033408,
                "mdate": 1700384033408,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "m6tUjCz4Fi",
                "forum": "xv8iGxENyI",
                "replyto": "jHWyOsxWk1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission56/Reviewer_4VCV"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission56/Reviewer_4VCV"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors' Rebuttal"
                    },
                    "comment": {
                        "value": "Thank you for your responses. Considering together the other reviews and responses, my score is confirmed."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission56/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700721457492,
                "cdate": 1700721457492,
                "tmdate": 1700721457492,
                "mdate": 1700721457492,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "83gpdCTv5A",
            "forum": "xv8iGxENyI",
            "replyto": "xv8iGxENyI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission56/Reviewer_w1gJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission56/Reviewer_w1gJ"
            ],
            "content": {
                "summary": {
                    "value": "This paper analyzes the temporal information in SNNs and establishes its relationship with the membrane decay constant and the number of time-steps. Then the authors propose a novel approach to combine rate and temproal information in SNNs, leveraging it to generate effective gradients for attacking SNNs. The experimental results demonstrate the proposed method achieve the SOTA attack success rate."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This paper is well-written.\n2. The idea of combining rate and temporal information in SNNs is highly noteworthy. The temporal information in SNNs has not been fully utilized in the current model. \n3. The work is solid. The authors provide a rigorous theoretical analysis of the retention degree of temporal information in SNNs and showcase the influencing factors involved."
                },
                "weaknesses": {
                    "value": "1. My main concern is about equation 8. I find it hard to derive equation 8 by combining equations 1 and 2. I am wondering about the absence of the threshold in equation 8. The authors should clarify why the threshold is not included in equation 8.\n2. The authors primarily focus on demonstrating how the combination of rate temporal information can enhance the attack of SNNs. How about defense? Can the proposed method also be used to improve the robustness of SNNs."
                },
                "questions": {
                    "value": "Refer to the weaknesses above. \nPlease provide a more comprehensive explanation of Figure 2(c)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission56/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698575301546,
            "cdate": 1698575301546,
            "tmdate": 1699635930103,
            "mdate": 1699635930103,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7mG8ruCoJ4",
                "forum": "xv8iGxENyI",
                "replyto": "83gpdCTv5A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission56/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission56/Authors"
                ],
                "content": {
                    "title": {
                        "value": "To Reviewer w1gJ"
                    },
                    "comment": {
                        "value": "## To Reviewer w1gJ\nThanks for your insightful and constructive feedback! We are encouraged that you find our paper novel, solid, well-written and highly noteworthy, as well as providing a rigorous theoretical analysis. We would like to address your concerns and your questions in the following. \n\n**Q1: I find it hard to derive equation 8 by combining equations 1 and 2. I am wondering about the absence of the threshold in equation 8. The authors should clarify why the threshold is not included in equation 8.**\n\n**A1:** Thanks for pointing it out. To simplify the subsequent mathematical analysis, we actually set $\\theta^l=1$ here. We have clarified in page 3 and added detailed derivation in the Appendix, Section A.6.\n\n**Q2: How about defense? Can the proposed method also be used to improve the robustness of SNNs.**\n\n**A2:** Thanks for your constructive comment! We have explored the use of images perturbed by the HART gradient as adversarial samples to enhance the robustness of SNNs through adversarial training. Our experiments encompass both vanilla SNNs and robust SNNs obtained via HART adversarial training, evaluated under FGSM and PGD attack scenarios with a white-box setting. We employ the attack success rate as our metric and set $\\lambda$ to 0.9.\nAs depicted in Table R1, our results demonstrate a significant improvement in the defense capability of robust SNNs across various attack scenarios, including BPTR, STBP, and RGA attacks. Notably, during our adversarial training, we did not introduce adversarial samples specifically tailored to these three mentioned attack algorithms. This finding indicates that HART not only enhances the defense capability of SNNs but also exhibits superior generalization ability, making it applicable for defending against a wide range of attack algorithms.\n\n\n**Table R1: Comparison between the vanilla and robust models on the CIFAR-100 dataset.**\n| Dataset | model | Architecture | attack | BPTR | BPTT | RGA |\n| ------- | --- | ------------ | ------ | ---- | ---- | --- |\n| CIFAR-100 | vanilla | VGG-11 | FGSM |92.47|92.88|94.72|\n| CIFAR-100 | robust | VGG-11 | FGSM |49.09|59.31|57.45|\n| CIFAR-100 | vanilla | VGG-11 | PGD |99.59|99.86|99.92|\n| CIFAR-100 | robust | VGG-11 | PGD* |59.51|72.46|69.36|\n\n$*$ denotes a stronger PGD attack ($\\alpha=2.55,\\text{steps}=7$).\n\n**Q3: Please provide a more comprehensive explanation of Fig.2$\\text{(c)}$.**\n\n**A3:** Thank you for your insightful comment! We have made improvements to Fig. 2$\\text{(c)}$  in our newly submitted version. In the updated figure, we illustrate the impact of different scales of $\\gamma$ on the gradient discrepancy. We specifically select three spiking neurons with distinct $m^l(t)$ values at the $t$-th time-step. It can be observed that as $\\gamma$ decreases, the discrepancy of surrogate gradients among the spiking neurons increases. Consequently, HART tends to focus on a subset of spiking neurons that fall within a specific membrane potential range at each time-step. This leads to the gradient with enhanced temporal attributes. Conversely, as $\\gamma$ increases, the gradient discrepancy among the three spiking neurons diminishes, and HART exhibits a more pronounced rate attribute."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission56/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700383912933,
                "cdate": 1700383912933,
                "tmdate": 1700383912933,
                "mdate": 1700383912933,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "RSyXGorCTw",
            "forum": "xv8iGxENyI",
            "replyto": "xv8iGxENyI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission56/Reviewer_RoZ6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission56/Reviewer_RoZ6"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes an adversarial attack method for SNN, which combines both rate and temporal information. Based on detailed analysis and experiments, this work demonstrates the efficiency of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.\tIt is interesting to consider both rate and temporal characters in SNN when considering adversarial attack.\n2.\tAuthor provide detailed experiment to demonstrate the effectiveness of the proposed framework."
                },
                "weaknesses": {
                    "value": "1.\tThe theory is hard to follow, it is better to provide an illustration of how to utilize temporal information during BP (as Fig.1)\n2.\tDoes the pruning has negative effect on the gradient computation? I think it is also interesting to discuss whether the proposed gradient computation can be directly applied to SNN training.\n3.\tIt is better to discuss the complexity of gradient computation in HART. \n4.\tFig.2(c) is hard to understand. In Fig.2(b), it is not clear the meaning of solid arrows."
                },
                "questions": {
                    "value": "Overall, I think this work provide an interesting attack method, and the experiments are well presented. The theory is not easy to follow, please see my comments for detail."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission56/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission56/Reviewer_RoZ6",
                        "ICLR.cc/2024/Conference/Submission56/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission56/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698654855745,
            "cdate": 1698654855745,
            "tmdate": 1700719351566,
            "mdate": 1700719351566,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZOwHvHfPvp",
                "forum": "xv8iGxENyI",
                "replyto": "RSyXGorCTw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission56/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission56/Authors"
                ],
                "content": {
                    "title": {
                        "value": "To Reviewer RoZ6"
                    },
                    "comment": {
                        "value": "## To Reviewer RoZ6\nThanks for your constructive and thoughtful comments! We are encouraged that you find our paper interesting and effective, as well as providing detailed experiments. We would like to address your concerns and your questions in the following. \n\n**Q1: It is better to provide an illustration of how to utilize temporal information during BP (as Fig.1).**\n\n**A1:** Thanks for your advice. We have improved Figure 2 and the related content to better illustrate the details of utilizing temporal information during BP in our newly submitted version.\n\n**Q2: Does the pruning has negative effect on the gradient computation? Whether the proposed gradient computation can be directly applied to SNN training?**\n\n**A2:** Thanks for your insightful comment! We would like to clarify that in this work, the gradient pruning and merging techniques are combined within the HART framework to enhance the extraction of rate and temporal information. This combination has a positive impact on improving attack success rates. In Table A1 (found in the Appendix), we present a series of ablation experiments that compare \"STBP+optimal $\\gamma$\" with HART. The key distinction between the two lies in the inclusion or exclusion of pruning and merging. The experimental results demonstrate that pruning and merging indeed contribute to improved attack effectiveness. Thanks for your suggestion! We agree that the potential application of these gradient techniques to SNN training is a fascinating direction for further research. We have included this point in the conclusion section.\n\n\n**Q3: It is better to discuss the complexity of gradient computation in HART.**\n\n**A3:** Thanks for pointing it out. As discussed in the \"Pre-calculation Property\" section, we employ a pre-calculation technique for the spiking neuron layers in the HART framework. This involves calculating the sum of surrogate gradients across multiple time-steps. By doing so, we can compute the gradient of HART in a single step during the back-propagation process, similar to ANNs. Consequently, the time complexity of pre-calculation for spiking neurons is $O(T)$, while the gradient computation complexity for each synaptic layer remains at $O(1)$. In the case of deeper SNNs with more synaptic layers, we believe that this property will lead to a more significant reduction in computational cost compared to the vanilla STBP attack. We have also added the discussion in the Appendix, Section A.4.\n\n\n**Q4: In Fig.2(b), it is not clear the meaning of solid arrows. Fig.2$\\text{(c)}$ is hard to understand.**\n\n**A4:** Thanks for pointing it out. We have made improvements to Fig. 2(b) and Fig.2$\\text{(c)}$ in the revised version. In the updated figures, the solid lines representing gradient pruning and merging are connected to Fig. 2(a), indicating that the design of these techniques ensures the establishment of the pre-calculation property in HART during forward propagation. The solid line related to the adjustable surrogate gradient is connected to Fig.2$\\text{(c)}$. In Fig.2$\\text{(c)}$, we illustrate the impact of different scales of $\\gamma$ on the gradient discrepancy. We have selected three spiking neurons with varied $m^l(t)$ values at the $t$-th time-step. It can be observed that as $\\gamma$ decreases, the discrepancy of surrogate gradients among spiking neurons increases. This causes HART to focus on a subset of spiking neurons within a specific membrane potential range at each time-step. Consequently, this enables us to observe a gradient with more pronounced temporal attributes."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission56/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700383850721,
                "cdate": 1700383850721,
                "tmdate": 1700383850721,
                "mdate": 1700383850721,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8Rn78mSjDm",
                "forum": "xv8iGxENyI",
                "replyto": "ZOwHvHfPvp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission56/Reviewer_RoZ6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission56/Reviewer_RoZ6"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "Thanks for the detailed response to address my concerns. The design framework is much clearer for me now. The exploration of temporal aspects and incorporating ratings in the context of SNN security is an intriguing research direction. I appreciate this innovative approach and would like to increase my score accordingly."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission56/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700719312087,
                "cdate": 1700719312087,
                "tmdate": 1700719312087,
                "mdate": 1700719312087,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "JgvXhO7UdA",
            "forum": "xv8iGxENyI",
            "replyto": "xv8iGxENyI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission56/Reviewer_hCfa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission56/Reviewer_hCfa"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed a hybrid adversarial attack framework, named HART, based on both rate and temporal information. The proposed method offers the flexibility to dynamically adjust the proportion between rate and temporal attributes according to the defined variable known as the retention degree of temporal information. Experiments indicated that HART can significantly improve the attack success rate of SNNs in various attack scenarios."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1.The analytical perspective of this paper is novel. The author starts with the propagation mode between SNN layers and summarizes the two types of information: rate and temporal information. Then they explored how to obtain more precise attack gradients by analyzing the optimal integration methods for both types of information.\n\n2.This paper takes an important initial stride in showcasing the potential of combining rate and temporal information to enhance SNN attacks.\n\n3.The theoretical derivation and mathematical analysis encompassed in this paper are solid.\n\n4. The results of extensive experiments effectively demonstrate that HART exhibits remarkable performance improvements under different hyperparameter configurations when compared to previous SOTA works."
                },
                "weaknesses": {
                    "value": "1. The authors should provide a more detailed analysis on the specific role of gradient pruning and merging within the proposed framework.\n\n2. The figures and legends of the paper can be further improved."
                },
                "questions": {
                    "value": "1. In Figure 1, it is unclear why the purple curve appears to be identical to the curve representing case 1.\n\n2.  I kindly request the authors to assess which specific information (rate or temporal) from the SNN was leveraged by several previous attack algorithms, namely CBA, STBP, BPTR, and RGA, in their experimental evaluations. It may shed light on the attack and defense exploration. \n\n3. In Table 1, the authors juxtapose their rate-based gradient attack method with CBA. Given that CBA also employs rate information for its attack strategy, could the authors elucidate the factors that make the proposed rate gradient method superior?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission56/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698759359522,
            "cdate": 1698759359522,
            "tmdate": 1699635929946,
            "mdate": 1699635929946,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YGLQ4KUFDW",
                "forum": "xv8iGxENyI",
                "replyto": "JgvXhO7UdA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission56/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission56/Authors"
                ],
                "content": {
                    "title": {
                        "value": "To Reviewer hCfa"
                    },
                    "comment": {
                        "value": "## To Reviewer hCfa\nThanks for your insightful and invaluable comments! We are encouraged that you find our paper novel and solid, as well as taking an important initial stride, having theoretical derivations and exhibiting remarkable performance improvements. We would like to address your concerns and your questions in the following. \n\n**Q1: The authors should provide a more detailed analysis on the specific role of gradient pruning and merging.**\n\n**A1:** Thanks for your constructive comment! Gradient pruning and merging have two primary functions. Firstly, they facilitate the comprehensive utilization of both rate and temporal information. Pruning prevents gradient interference between different time-steps, while merging performs overall statistics for surrogate gradients, specifically the membrane potential information, across multiple time-steps. The synergistic use of pruning and merging promotes the integration of rate and temporal information, thereby guaranteeing the establishment of Theorem 2. Secondly, gradient pruning and merging ensure the desirable pre-calculation property of the HART framework, which requires only a single-time gradient calculation for each synaptic layer, effectively reducing the computational complexity of the algorithm. \n\n\n**Q2: The figures and legends of the paper can be further improved.**\n\n**A2:** Thanks for your advice! We have made modifications for the figures and legends in this paper, and submitted a new version.\n\n**Q3: In Fig.1, it is unclear why the purple curve appears to be identical to the curve representing case 1.**\n\n**A3:** In fact, there is no correlation between these two curves. We have revised the colors of Fig.1 in our newly submitted version. \n\n**Q4: I kindly request the authors to assess which specific information (rate or temporal) was leveraged by CBA, STBP, BPTR, and RGA.**\n\n**A4:**  CBA directly transfers the gradients obtained from pre-trained ANNs to SNNs by leveraging the rate information, assuming a uniform input current. STBP utilizes gradients calculated through spatial-temporal back-propagation across multiple consecutive time steps, primarily relying on temporal information. BTPR and RGA employ the vanilla forward propagation of spiking neurons while incorporating rate information during gradient calculation. BPTR masks the gradient based on whether a neuron has emitted spikes, while RGA replaces the surrogate gradient function used in STBP with the activation gradient obtained from the Rate-Input Curve.\n\n**Q5: Given that CBA also employs rate information for its attack strategy, could the authors elucidate the factors that make the proposed rate gradient method superior?**\n\n**A5:** Thanks for pointing it out. In terms of forward propagation, CBA relies on the assumption of uniform input current to determine the output in each layer, whereas our approach utilizes the actual output of spiking neurons across multiple time steps. When it comes to gradient calculation, CBA typically employs a conventional activation function like ClipReLU, whereas we derive our activation gradient by averaging the statistical information of spike firing on a layer-by-layer basis. We believe that these two aspects have enabled our method to achieve more precise gradient estimations."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission56/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700383775803,
                "cdate": 1700383775803,
                "tmdate": 1700383775803,
                "mdate": 1700383775803,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rjUW1gr5LQ",
                "forum": "xv8iGxENyI",
                "replyto": "YGLQ4KUFDW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission56/Reviewer_hCfa"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission56/Reviewer_hCfa"
                ],
                "content": {
                    "title": {
                        "value": "Responses"
                    },
                    "comment": {
                        "value": "Thanks for the response.\nThe authors have well addressed my concerns\uff0c I recommend acceptance."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission56/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700663383787,
                "cdate": 1700663383787,
                "tmdate": 1700663383787,
                "mdate": 1700663383787,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]