[
    {
        "title": "The Emergence of Reproducibility and Consistency in Diffusion Models"
    },
    {
        "review": {
            "id": "zLcqxbB7b4",
            "forum": "UkLSvLqiO7",
            "replyto": "UkLSvLqiO7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2834/Reviewer_uEsZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2834/Reviewer_uEsZ"
            ],
            "content": {
                "summary": {
                    "value": "This paper found that diffusion models for image and text-to-image generation uniquely produce almost identical results when given the same starting conditions, regardless of their design or training. This happens in two ways: either by memorizing training data or by learning broadly from large datasets. This consistent output trait, present in various diffusion model types, could make these models more understandable and controllable."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "It is quite interesting to investigate the memorization and generalization of diffusion models, which help us to understand current generative model better."
                },
                "weaknesses": {
                    "value": "Although the author discovered an interesting phenomenon and used rich theories and experiments as supplementary explanations. But it seems that there is no further improvement in the training of the current diffusion model.\n\nThe experiments are conducted on small datasets (CIFAR)? It is not clear the performance on larger datasets."
                },
                "questions": {
                    "value": "How does the ODE solver and the NFE influence the image? (Few NFE will brings corrupted image)\n\nHave the authors investigated larger datasets, such as CoCo, ImageNet?\n\nHow can we get a better training strategy from the current conclusion?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2834/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2834/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2834/Reviewer_uEsZ"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2834/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698643884772,
            "cdate": 1698643884772,
            "tmdate": 1699636226987,
            "mdate": 1699636226987,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Tso6cJMz16",
                "forum": "UkLSvLqiO7",
                "replyto": "zLcqxbB7b4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for acknowledging the quality of our presentation, experiments, and the timeliness of our results. We value the constructive feedback that the reviewer provided. In the following, we carefully respond to each of the concerns and suggestions that the reviewer raised.\n\n\n___\n\n> **Q1**:\n> \u201cBut it seems that there is no further improvement in the training of the current diffusion model.\u201d\n\n**A1**:\n\nWe agree with the reviewer that improving the training of diffusion models is not the main focus of this work. However, we believe that research progress can be driven by two distinct avenues: (i) technical enhancements and (ii) the pursuit of deeper insights. Both aspects hold equal significance. In our investigation, we directed our efforts towards gaining a deeper understanding of diffusion models, unveiling several intriguing phenomena, which we would like to highlight as follows.\n\n-   The first systematical and quantitative study of the model reproducibility phenomenon on the unconditional diffusion model.\n    \n-   Moreover, we discovered that model reproducibility occurs in two distinct regimes, the \u201cmemorization regime\u201d and \u201cgeneralizability regime\u201d, and model reproducibility has a strong correlation with model generalizability. Moreover, we have theoretically and experimentally justified the reproducibility in the memorization regime.\n    \n-   We generalized the study of model reproducibility in a variety of settings, including conditional diffusion models, diffusion models for inverse problems, and fine-tuning diffusion models. For these different settings, we showed that the model reproducibility manifests in different but principled ways.\n    \nOur findings could have a variety of potential applications that we discuss in Q2.\n\n___\n\n> **Q2**:\n> \u201cHow can we get a better training strategy from the current conclusion?\u201d\n\n**A2**:\n\nWe thank the reviewer for this important question, and we believe that our understanding opens many interesting application ideas beyond improving training efficiency. One major insight gained from this study is that the mapping from the noise space to the image space is a unique one-to-one mapping, regardless of network architectures or training procedures.\n\n  As we discussed in Section 1, this observation implies that the noise space contains valuable information that can be utilized for controlled and efficient data-generative processes using diffusion models. For instance,\n\n  \n\n-  In text-driven image generation, insights into this question could help to guide the content generation (e.g., adversarial attacking [1], robust defending [2], copyright protection [3]) using the same prompt but varying noise inputs.\n    \n\n-   Moreover, in the context of solving inverse problems, an answer to this question could guide us to select the input noise for improving the sampling efficiency, and reducing the uncertainty and variance in our signal reconstruction [4, 5, 6].\n    \n-   Theoretically, understanding the question will shed light on how the mapping function is learned and constructed between the noise and data distributions, which is crucial for understanding the generation process through the distribution transformation or identifiable encoding [7, 8].\n    \n\n  \n\n[1] Zou, Andy, Zifan Wang, J. Zico Kolter, and Matt Fredrikson. \"Universal and transferable adversarial attacks on aligned language models.\" arXiv preprint arXiv:2307.15043 (2023).\n\n[2] Zhu, Kaijie, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong Wang, Linyi Yang et al. \"PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts.\" arXiv preprint arXiv:2306.04528 (2023).\n\n[3] Somepalli, Gowthami, Vasu Singla, Micah Goldblum, Jonas Geiping, and Tom Goldstein. \"Understanding and Mitigating Copying in Diffusion Models.\" arXiv preprint arXiv:2305.20086 (2023).\n\n[4] Jalal, Ajil, Marius Arvinte, Giannis Daras, Eric Price, Alexandros G. Dimakis, and Jon Tamir. \"Robust compressed sensing mri with deep generative priors.\" Advances in Neural Information Processing Systems 34 (2021): 14938-14954.\n\n[5] Chung, Hyungjin, and Jong Chul Ye. \"Score-based diffusion models for accelerated MRI.\" Medical image analysis 80 (2022): 102479.\n\n[6] Luo, Guanxiong, Moritz Blumenthal, Martin Heide, and Martin Uecker. \"Bayesian MRI reconstruction with joint uncertainty estimation using diffusion models.\" Magnetic Resonance in Medicine 90, no. 1 (2023): 295-311.\n\n[7] Roeder, Geoffrey, Luke Metz, and Durk Kingma. \"On linear identifiability of learned representations.\" In International Conference on Machine Learning, pp. 9030-9039. PMLR, 2021.\n\n[8] Khemakhem, Ilyes, Diederik Kingma, Ricardo Monti, and Aapo Hyvarinen. \"Variational autoencoders and nonlinear ica: A unifying framework.\" In International Conference on Artificial Intelligence and Statistics, pp. 2207-2217. PMLR, 2020."
                    },
                    "title": {
                        "value": "Response to Reviewer uEsZ"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2834/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700035258250,
                "cdate": 1700035258250,
                "tmdate": 1700147142177,
                "mdate": 1700147142177,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FEAT4WgzsX",
                "forum": "UkLSvLqiO7",
                "replyto": "zLcqxbB7b4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> **Q3**: \u201cHow does the ODE solver and the NFE influence the image?\u201d\n\n**A3**:\n\nWe thank the reviewer for the question. We want to clarify that the model reproducibility is regarding the content or shape of the image, not image quality. Starting from the same noise, we find that different diffusion models generate the same content, but the image quality can be different depending on the model.\n\nTo the reviewer\u2019s question, for the ODE solver, we have covered DPM-Solver [1], Heun-Solver [2], and DDIM [3] for unconditional reproducibility. We find that different ODE solvers do not affect model reproducibility, although they may affect the image quality. The experiment settings are in Table 1, Appendix B. The reproducibility scores are shown in Figure 14.\n\nFor NFE, we added more experiments in Appendix A.4 during the revision. While a lower NFE tends to degrade the generated image quality, our observations reveal that the content of the generated images remains remarkably consistent across varying NFE levels; see Figure 12.\n\n[1] Lu, Cheng, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. \"Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps.\" _Advances in Neural Information Processing Systems_ 35 (2022): 5775-5787.\n\n[2] Karras, Tero, Miika Aittala, Timo Aila, and Samuli Laine. \"Elucidating the design space of diffusion-based generative models.\" _Advances in Neural Information Processing Systems_ 35 (2022): 26565-26577.\n\n[3] Song, Jiaming, Chenlin Meng, and Stefano Ermon. \"Denoising diffusion implicit models.\" _arXiv preprint arXiv:2010.02502_ (2020)."
                    },
                    "title": {
                        "value": "Response to Reviewer uEsZ"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2834/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700035328812,
                "cdate": 1700035328812,
                "tmdate": 1700147172334,
                "mdate": 1700147172334,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oi6FRo7TZ0",
                "forum": "UkLSvLqiO7",
                "replyto": "zLcqxbB7b4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "content": {
                    "comment": {
                        "value": ">**Q4**: \u201cHave the authors investigated larger datasets, such as CoCo, ImageNet?\u201d\n\n**A4**:\nWe thank the reviewer for the valuable suggestions to study the phenomenon more comprehensively. During the revision, we conducted more experiments considering two extra cases: (i) the Conditional Diffusion Model on the ImageNet Dataset [1], and (ii) Stable Diffusion [2] on the LAION-5B dataset [3]. The results can be found in Appendix A.1 and A.2 of the revised paper. As such, our new experiments not only covered larger datasets in (i, ii), but also text-to-image diffusion models in (ii). Specifically, we find the following:\n\n1. Conditional Diffusion Model on the ImageNet Dataset: We evaluated the reproducibility of EDM [4] and ADM [5], as shown in the following table:\n\n\t| $\\text{RP} \\text{ Score}$| EDM  | ADM  |\n\t|----------|------|------|\n\t| **EDM**      | 1.0  | 0.81 |\n\t| **ADM**      | 0.81 | 1.0  |\n\n\tDetailed experimental settings and visual results are presented in Appendix A.1. We find that the model reproducibility still exists on ImageNet.\n\n2. Stable Diffusion on the LAION-5B Dataset: We evaluated the reproducibility of stable diffusion models with versions v1-1 to v1-4, with their respective reproducibility scores shown in the table below:\n\n\t| $\\text{RP} \\text{ Score}$ | V1-1 | V1-2 | V1-3 | V1-4 |\n\t|----------|------|------|------|------|\n\t| **V1-1**     | 1.0  | 0.10 | 0.03 | 0.03 |\n\t| **V1-2**     | 0.10 | 1.0  | 0.21 | 0.20 |\n\t| **V1-3**     | 0.03 | 0.21 | 1.0  | **0.63** |\n\t| **V1-4**     | 0.03 | 0.20 | **0.63** | 1.0  |\n\t\n\tThe relationship between V1-1 to V1-4 could be summarized as \n\t- Versions v1-1, v1-2, and v1-3 each are trained on different subsets of the LAION-5B dataset.\n\t- Versions v1-3 and v1-4 share the same training subset from LAION-5B.\n\t- Version v1-2 is resumed from v1-1, while v1-3 and v1-4 are resumed from v1-2.\n\t\n\tNotably, only versions v1-3 and v1-4 were trained on the exact same dataset, resulting in the highest reproducibility scores (0.63). Lesser but noticeable reproducibility scores (below 0.21) are observed among v1-1, v1-2, and v1-3, this can be attributed to their sequential training and overlapping datasets. There is no model reproducibility between v1-1 and others, because the training datasets are nonoverlapping and different. Further details on the experimental setup and visual results can be found in Appendix A.2.\n\nIn conclusion, our findings suggest that this phenomenon persists for larger diffusion models trained on large datasets.\n\n[1]Deng, Jia, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. \"Imagenet: A large-scale hierarchical image database.\" In 2009 IEEE conference on computer vision and pattern recognition, pp. 248-255. Ieee, 2009.\n\n[2]Rombach, Robin, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. \"High-resolution image synthesis with latent diffusion models.\" In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 10684-10695. 2022.\n\n[3] Schuhmann, Christoph, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes et al. \"Laion-5b: An open large-scale dataset for training next generation image-text models.\" Advances in Neural Information Processing Systems 35 (2022): 25278-25294.\n\n[4] Karras, Tero, Miika Aittala, Timo Aila, and Samuli Laine. \"Elucidating the design space of diffusion-based generative models.\" _Advances in Neural Information Processing Systems_ 35 (2022): 26565-26577.\n\n[5] Dhariwal, Prafulla, and Alexander Nichol. \"Diffusion models beat gans on image synthesis.\" _Advances in neural information processing systems_ 34 (2021): 8780-8794."
                    },
                    "title": {
                        "value": "Response to Reviewer uEsZ"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2834/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700035420154,
                "cdate": 1700035420154,
                "tmdate": 1700147179887,
                "mdate": 1700147179887,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YVvEAlFBJj",
                "forum": "UkLSvLqiO7",
                "replyto": "zLcqxbB7b4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to your feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer uEsZ:\n\nI would like to begin by expressing my sincere gratitude for the time and effort you have dedicated to reviewing our work. Your insights and feedback are invaluable to us. We hope our responses addressed your questions. If you have any further concerns, we are appreciated and more than willing to provide any further information or clarification. \n\nIf our responses have addressed your concerns, we would appreciate it a lot if you could improve the score. \nThank you once again for your valuable contribution to improving our work. Looking forward to your feedback."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2834/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700289872687,
                "cdate": 1700289872687,
                "tmdate": 1700290103799,
                "mdate": 1700290103799,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EnflDfKuyb",
                "forum": "UkLSvLqiO7",
                "replyto": "hsUg4AZjwh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2834/Reviewer_uEsZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2834/Reviewer_uEsZ"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your response. It is good to see the results on larger datasets. However, justifications looks not very sound to me. One of the reasons is that different versions of stable diffusion depend on each other, which makes the analysis really confusing. I understand the challenges of training models on LAION-5B dataset. But I think it is necessary to do the ablation study on ImageNet, such as model size, model type, training epochs, and training parameters, etc. Otherwise, the evaluation on these pertained model makes things really ambiguous.\n\nMoreover, I still think there should be the inspiration for the training strategy is important, as other work (even myself) also found this phenomenon but do not really understand the impact and implications. This paper just verifies the phenomenon without clear implications for practitioners, which limit the significance of the work."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2834/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700541037715,
                "cdate": 1700541037715,
                "tmdate": 1700541037715,
                "mdate": 1700541037715,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "VY3SiRfK0k",
            "forum": "UkLSvLqiO7",
            "replyto": "UkLSvLqiO7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2834/Reviewer_6ysm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2834/Reviewer_6ysm"
            ],
            "content": {
                "summary": {
                    "value": "Diffusion models have demonstrated a strong ability to generate high-quality images. This paper presents a novel discovery referred to as \"consistent model reproducibility\": regardless of different training configurations, model architectures, and sampling strategies, diffusion models produce nearly identical output content given the same initial noise. The authors theoretically justify the above claim. Besides, they divide model reproducibility manifests in two regimes: memorization regime and generalization regime based on whether the model capacity matches the dataset size. This work provides insights for interpretable and controllable data generation based on diffusion models"
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- The authors both theoretically and empirically show that the same initial noise input results in nearly identical output regardless of the model architecture and training procedure, which is impressive.\n- The study is thorough. It covers both unconditional and conditional diffusion models, and considers different sampling strategies, training configurations and model architectures.\n- The writing is clear and easy to follow."
                },
                "weaknesses": {
                    "value": "- Lack of discussion about text-to-image diffusion models.\n- [minor] \"controlable\" in the abstract should be controllable."
                },
                "questions": {
                    "value": "Why are the reproducibility scores between transformer-based models and unet-based models low as shown in Figure 7(b)? According to Theorem 1, the reproducibility scores should be high. Could you please provide more explanation?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2834/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2834/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2834/Reviewer_6ysm"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2834/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698739092068,
            "cdate": 1698739092068,
            "tmdate": 1699636226918,
            "mdate": 1699636226918,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YeYzoQ7m6w",
                "forum": "UkLSvLqiO7",
                "replyto": "VY3SiRfK0k",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for appreciating the quality of our presentation, experiments, and the timeliness of our results. We value the constructive feedback that the reviewer provided. In the following, we will carefully respond to each of the concerns and suggestions that the reviewer raised.\n\n  \n  ___\n\n> **Q1**: Lack of discussion about text-to-image diffusion models.\n\n**A1**:\nWe thank the reviewer for the valuable suggestions to study the phenomenon more comprehensively. During the revision, we conducted more experiments considering two extra cases: (i) the Conditional Diffusion Model on the ImageNet Dataset [1], and (ii) Stable Diffusion [2] on the LAION-5B dataset [3]. The results can be found in Appendix A.1 and A.2 of the revised paper. As such, our new experiments not only covered larger datasets in (i, ii), but also text-to-image diffusion models in (ii). Specifically, we find the following:\n\n1. Conditional Diffusion Model on the ImageNet Dataset: We evaluated the reproducibility of EDM [4] and ADM [5], as shown in the following table:\n\n\t| $\\text{RP} \\text{ Score}$| EDM  | ADM  |\n\t|----------|------|------|\n\t| **EDM**      | 1.0  | 0.81 |\n\t| **ADM**      | 0.81 | 1.0  |\n\n\tDetailed experimental settings and visual results are presented in Appendix A.1. We find that the model reproducibility still exists on ImageNet.\n\n2. Stable Diffusion on the LAION-5B Dataset: We evaluated the reproducibility of stable diffusion models with versions v1-1 to v1-4, with their respective reproducibility scores shown in the table below:\n\n\t| $\\text{RP} \\text{ Score}$ | V1-1 | V1-2 | V1-3 | V1-4 |\n\t|----------|------|------|------|------|\n\t| **V1-1**     | 1.0  | 0.10 | 0.03 | 0.03 |\n\t| **V1-2**     | 0.10 | 1.0  | 0.21 | 0.20 |\n\t| **V1-3**     | 0.03 | 0.21 | 1.0  | **0.63** |\n\t| **V1-4**     | 0.03 | 0.20 | **0.63** | 1.0  |\n\t\n\tThe relationship between V1-1 to V1-4 could be summarized as \n\t- Versions v1-1, v1-2, and v1-3 each are trained on different subsets of the LAION-5B dataset.\n\t- Versions v1-3 and v1-4 share the same training subset from LAION-5B.\n\t- Version v1-2 is resumed from v1-1, while v1-3 and v1-4 are resumed from v1-2.\n\t\n\tNotably, only versions v1-3 and v1-4 were trained on the exact same dataset, resulting in the highest reproducibility scores (0.63). Lesser but noticeable reproducibility scores (below 0.21) are observed among v1-1, v1-2, and v1-3, this can be attributed to their sequential training and overlapping datasets. There is no model reproducibility between v1-1 and others, because the training datasets are nonoverlapping and different. Further details on the experimental setup and visual results can be found in Appendix A.2.\n\nIn conclusion, our findings suggest that this phenomenon persists for larger diffusion models trained on large datasets.\n\n[1]Deng, Jia, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. \"Imagenet: A large-scale hierarchical image database.\" In 2009 IEEE conference on computer vision and pattern recognition, pp. 248-255. Ieee, 2009.\n\n[2]Rombach, Robin, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. \"High-resolution image synthesis with latent diffusion models.\" In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 10684-10695. 2022.\n\n[3] Schuhmann, Christoph, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes et al. \"Laion-5b: An open large-scale dataset for training next generation image-text models.\" Advances in Neural Information Processing Systems 35 (2022): 25278-25294.\n\n[4] Karras, Tero, Miika Aittala, Timo Aila, and Samuli Laine. \"Elucidating the design space of diffusion-based generative models.\" _Advances in Neural Information Processing Systems_ 35 (2022): 26565-26577.\n\n[5] Dhariwal, Prafulla, and Alexander Nichol. \"Diffusion models beat gans on image synthesis.\" _Advances in neural information processing systems_ 34 (2021): 8780-8794."
                    },
                    "title": {
                        "value": "Response to Reviewer 6ysm"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2834/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700034986483,
                "cdate": 1700034986483,
                "tmdate": 1700147115951,
                "mdate": 1700147115951,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iVGwdoSmSv",
                "forum": "UkLSvLqiO7",
                "replyto": "VY3SiRfK0k",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> **Q2**: Why are the reproducibility scores between transformer-based models and unet-based models low as shown in Figure 7(b)? According to Theorem 1, the reproducibility scores should be high. Could you please provide more explanation?\n\n\n**A2:** Thanks the reviewer for this very good question. When solving inverse problems with diffusion models, our experiments in Figure 7 showed that the model reproducibility between different type of network architectures are very low. We use Diffusion Posterior Sampling (DPS) [1] to solve the inpainting problem, with details provided in Appendix F. We conjecture that the lack of reproducibility across network architectures is due to the following reasons:\n1. Here, DPS introduces the gradient term $\\dfrac{\\partial \\epsilon_{\\theta} ( x_t, t)}{\\partial x_t}$ during the sampling, and this extra term might break the reproducibility for different type of architectures. In contrast, for the unconditional diffusion model, the reproducibility holds as long as the denoiser function $\\epsilon_{\\theta} ( x_t, t)$ is reproducible.\n2. Second, for image inpainting or inverse problem solving in general, the data $ x_t$ passed into the denoiser  $\\epsilon_{\\theta}( x_t, t)$ is out-of-distribution. As such, the reproducibility between different types of architectures might not hold for out-of-distribution data generation.\n    \nWe will incorporate this discussion into the revised paper in Section 4 (when the extra page is provided).\n\n[1] Chung, Hyungjin, Jeongsol Kim, Michael T. Mccann, Marc L. Klasky, and Jong Chul Ye. \"Diffusion posterior sampling for general noisy inverse problems.\" arXiv preprint arXiv:2209.14687 (2022)."
                    },
                    "title": {
                        "value": "Response to Reviewer 6ysm"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2834/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700035129949,
                "cdate": 1700035129949,
                "tmdate": 1700668732239,
                "mdate": 1700668732239,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ULVM2ppdqo",
                "forum": "UkLSvLqiO7",
                "replyto": "VY3SiRfK0k",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to your feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer 6ysm:\n\nI would like to begin by expressing my sincere gratitude for the time and effort you have dedicated to reviewing our work. Your insights and feedback are invaluable to us. We hope our responses addressed your questions. If you have any further concerns, we are appreciated and more than willing to provide any further information or clarification. \n\nIf our responses have addressed your concerns, we would appreciate it a lot if you could improve the score. \nThank you once again for your valuable contribution to improving our work. Looking forward to your feedback."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2834/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700289831304,
                "cdate": 1700289831304,
                "tmdate": 1700290086568,
                "mdate": 1700290086568,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4hC494Z6Nt",
                "forum": "UkLSvLqiO7",
                "replyto": "iVGwdoSmSv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2834/Reviewer_6ysm"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2834/Reviewer_6ysm"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the responses"
                    },
                    "comment": {
                        "value": "Thank the authors for the detailed responses.\n\nI appreciate the supplemented experiments on text-to-image diffusion models.\n\nYet the explanation for the low scores between diffusion models with different architectures is not convincing. According to theorem 1, the score function also follows the pattern even given out-of-domain data.\nWhy low reproducibility scores between transformer-based and unet-based models might need further exploration.\n\nAlso, I agree with Reviewer LTJ7 that Theorem 1 might be rather trivial. \nThe model in Theorem 1 is too simple and too ideal: Theorem 1 only considers the optimal score function, which is impossible to obtain in practical training.\nThe result in Eq.(2), which can be derived by computing the minimizer of a quadratic function, is trivial due to the simple modeling.\n\nTherefore, I would like to lower my rating to 5."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2834/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700642183519,
                "cdate": 1700642183519,
                "tmdate": 1700642183519,
                "mdate": 1700642183519,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "d9e2pYWEQx",
                "forum": "UkLSvLqiO7",
                "replyto": "VY3SiRfK0k",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your further questions and concerns."
                    },
                    "comment": {
                        "value": "Dear Reviewer 6ysm,\n\nThanks for your further questions and concerns. \n\n\n>Q3 ``Also, I agree with Reviewer LTJ7 that Theorem 1 might be rather trivial. The model in Theorem 1 is too simple and too ideal: Theorem 1 only considers the optimal score function, which is impossible to obtain in practical training. The result in Eq.(2), which can be derived by computing the minimizer of a quadratic function, is trivial due to the simple modeling.''\n\n**A3:** We agree with the reviewer that Theorem 1 is simple, but the result is nontrivial. This is corroborated by our experiments in **Figure 5**, where we showed that practical diffusion models do obtain the analytical results **in practice** when the training data size is small. As such, it well explains the reproducibility phenomenon in the **memorization regime**. \n\nMoreover, we want to highlight our results in **Figure 2**, where our work has identified an interesting **generalization regime** where reproducibility and generalizability co-emerge. **The phenomenon in the generalization regimes is very different from that of the memorization regime**, which cannot be simply explained by Reviewer LTJ7\u2019s claim.\n\n>Q4 ``Yet the explanation for the low scores between diffusion models with different architectures is not convincing. According to theorem 1, the score function also follows the pattern even given out-of-domain data. Why low reproducibility scores between transformer-based and unet-based models might need further exploration.''\n\n**A4:** We thank the reviewer for raising the concerns, but we believe that there are some misunderstandings on the phenomenon between the **memorization regime** and **generalization regime** (see Figure 2) that we discovered in our paper. \n\nFor inverse problem solving using the diffusion model, the experiment settings are **in the generalization regime**, which is out-of-score of Theorem 1. Our claim on Theorem 1 is only to explain the phenomenon in the memorization regime, as we discussed in A1. We have highlighted this in the figures of our paper.\n\nMoreover, as pointed out by Reviewer vqyB, the low reproducibility between transformer-based and unet-based models for inverse problems in the generalization regime is counter-intuitive and also refutes the claim by Reviewer LTJ7 that this phenomenon is well-known or well-studied. We have provided potential explanations of this in our previous response **A2** that are worth further investigation. Again, this opens a new theoretical question for the diffusion model community.\n\nWe hope our responses addressed your questions. If you have any further concerns, we are more than willing to provide any further clarification. Thank you once again for your valuable feedback on improving our work."
                    }
                },
                "number": 25,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2834/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700671395183,
                "cdate": 1700671395183,
                "tmdate": 1700683102165,
                "mdate": 1700683102165,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "20luuqHYyC",
            "forum": "UkLSvLqiO7",
            "replyto": "UkLSvLqiO7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2834/Reviewer_vqyB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2834/Reviewer_vqyB"
            ],
            "content": {
                "summary": {
                    "value": "The paper takes a deep dive into the identifiability of the diffusion model latent space induced by deterministic sampling procedures. In particular, it starts by showcasing the phenomenon that if initialized with the same noisy images and using a deterministic sampler, well-trained diffusion models with widely ranging architectures, training and sampling procedures all produce highly similar images on CIFAR-10. The paper analyses this further and uncovers two distinct regimes where this happens: The overparametrized, \u2018memorization regime\u2019, where only a small part of the CIFAR-10 data set is used, and the \u2018generalization regime\u2019, where the full CIFAR-10 data set is used. Importantly, there is a gap in between these extremes where the different models do not agree. The effect is measured quantitatively using metrics for comparing image pairs, confirming the result. The mapping from noise to images is visualized and shown again to be similar among different models, as well as smooth. A theoretical study in the \u2018memorization\u2019 regime is provided, and reproducibility is demonstrated in conditional generation, inverse problems and fine-tuned models as well."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "+ The experiments are thorough and demonstrate the phenomenon clearly, and the phenomenon itself is quite striking.\n+ The research is well-motivated\n+ Although preliminary results on the phenomenon were reported in Song et al (2021), the paper uncovers new effects:\n\t- The generation is consistent across vastly different architectures, training and sampling procedures\n\t- The phenomenon occurs in two distinct phases, the \u2018memorization\u2019 and \u2018generalization\u2019 and regimes, with a clear transition in between where it doesn\u2019t occur.\n\t- The model reproducibility holds across different types of conditional diffusion models and fine-tuned models as well\n+ Potentially the paper opens up more avenues for theoretical work towards understanding diffusion models and how diffusion models generalize, in particular.\n\nReferences:\nSong et al., Score-Based Generative Modeling through Stochastic Differential Equations, 2021, ICLR"
                },
                "weaknesses": {
                    "value": "- The present study is mainly on CIFAR-10, and it would be interesting to see how do the results transfer to larger data sets, like ImageNet. Especially when moving to the very large data sets used for text-conditional generation, it doesn't seem obvious that similar results would hold. It would be interesting to see how far can this be extended."
                },
                "questions": {
                    "value": "- When studying the encoding from the noise hyperplane to the image manifold, would it be more appropriate to interpolate the noises using spherical linear interpolation instead of direct linear interpolation? From what I understand, the issue with linear interpolation is that because two randomly sampled high-dimensional noise vectors are, with a high probability, orthogonal to each other, the magnitude of a linearly interpolated vector decreases halfway by a factor of sqrt(2).\n\nOverall, I think that the paper demonstrates and highlights the claimed effects very clearly, and that in addition to the new and more detailed characterization of the phenomenon make the paper worthy of publishing."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2834/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2834/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2834/Reviewer_vqyB"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2834/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698758215159,
            "cdate": 1698758215159,
            "tmdate": 1699636226822,
            "mdate": 1699636226822,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "H3UXIRWPS1",
                "forum": "UkLSvLqiO7",
                "replyto": "20luuqHYyC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We very much appreciate the reviewer for acknowledging the quality of our presentation, experiments, and the timeliness of our results. We also thank the reviewer for carefully reading our paper and detailed comments. We value the constructive feedback and encouragement that the reviewer provided. In the following, we carefully respond to each of the concerns and suggestions that the reviewer raised.\n\n___\n\n> **Q1**: \u201cThe present study is mainly on CIFAR-10, and it would be interesting to see how do the results transfer to larger data sets, like ImageNet. Especially when moving to the very large data sets used for text-conditional generation.\u201d\n\n**A1**:\nWe thank the reviewer for the valuable suggestions to study the phenomenon more comprehensively. During the revision, we conducted more experiments considering two extra cases: (i) the Conditional Diffusion Model on the ImageNet Dataset [1], and (ii) Stable Diffusion [2] on the LAION-5B dataset [3]. The results can be found in Appendix A.1 and A.2 of the revised paper. As such, our new experiments not only covered larger datasets in (i, ii), but also text-to-image diffusion models in (ii). Specifically, we find the following:\n\n1. Conditional Diffusion Model on the ImageNet Dataset: We evaluated the reproducibility of EDM [4] and ADM [5], as shown in the following table:\n\n\t|$\\text{RP} \\text{Score}$|EDM|ADM|\n\t|------|------|------|\n\t| **EDM**      | 1.0  | 0.81 |\n\t| **ADM**      | 0.81 | 1.0  |\n\n\tDetailed experimental settings and visual results are presented in Appendix A.1. We find that the model reproducibility still exists on ImageNet.\n\n2. Stable Diffusion on the LAION-5B Dataset: We evaluated the reproducibility of stable diffusion models with versions v1-1 to v1-4, with their respective reproducibility scores shown in the table below:\n\n\t| $\\text{RP} \\text{ Score}$ | V1-1 | V1-2 | V1-3 | V1-4 |\n\t|----------|------|------|------|------|\n\t| **V1-1**     | 1.0  | 0.10 | 0.03 | 0.03 |\n\t| **V1-2**     | 0.10 | 1.0  | 0.21 | 0.20 |\n\t| **V1-3**     | 0.03 | 0.21 | 1.0  | **0.63** |\n\t| **V1-4**     | 0.03 | 0.20 | **0.63** | 1.0  |\n\t\n\tThe relationship between V1-1 to V1-4 could be summarized as \n\t- Versions v1-1, v1-2, and v1-3 each are trained on different subsets of the LAION-5B dataset.\n\t- Versions v1-3 and v1-4 share the same training subset from LAION-5B.\n\t- Version v1-2 is resumed from v1-1, while v1-3 and v1-4 are resumed from v1-2.\n\t\n\tNotably, only versions v1-3 and v1-4 were trained on the exact same dataset, resulting in the highest reproducibility scores (0.63). Lesser but noticeable reproducibility scores (below 0.21) are observed among v1-1, v1-2, and v1-3, this can be attributed to their sequential training and overlapping datasets. There is no model reproducibility between v1-1 and others, because the training datasets are nonoverlapping and different. Further details on the experimental setup and visual results can be found in Appendix  A.2.\n\nIn conclusion, our findings suggest that this phenomenon persists for larger diffusion models trained on large datasets.\n\n[1]Deng, Jia, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. \"Imagenet: A large-scale hierarchical image database.\" In 2009 IEEE conference on computer vision and pattern recognition, pp. 248-255. Ieee, 2009.\n\n[2]Rombach, Robin, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. \"High-resolution image synthesis with latent diffusion models.\" In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 10684-10695. 2022.\n\n[3] Schuhmann, Christoph, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes et al. \"Laion-5b: An open large-scale dataset for training next generation image-text models.\" Advances in Neural Information Processing Systems 35 (2022): 25278-25294.\n\n[4] Karras, Tero, Miika Aittala, Timo Aila, and Samuli Laine. \"Elucidating the design space of diffusion-based generative models.\" _Advances in Neural Information Processing Systems_ 35 (2022): 26565-26577.\n\n[5] Dhariwal, Prafulla, and Alexander Nichol. \"Diffusion models beat gans on image synthesis.\" _Advances in neural information processing systems_ 34 (2021): 8780-8794."
                    },
                    "title": {
                        "value": "Response to Reviewer vqyB"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2834/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700034218370,
                "cdate": 1700034218370,
                "tmdate": 1700147086083,
                "mdate": 1700147086083,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "chywVJmanF",
                "forum": "UkLSvLqiO7",
                "replyto": "20luuqHYyC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> **Q2**: \u201dWhen studying the encoding from the noise hyperplane to the image manifold, would it be more appropriate to interpolate the noises using spherical linear interpolation instead of direct linear interpolation?\u201d\n\n **A2**:\nThanks for your very insightful suggestion. Given the spherical linear interpolation is confined to a single dimension and time limit, we opted not to visualize the manifold reproducibility in a figure. Instead, we developed a manifold reproducibility score to measure the manifold reproducibility. The metric is defined as follows:\n\nThe metric begins by selecting two initial noise vectors, $(\\mathbf{\\epsilon}^{(0)}, \\mathbf{\\epsilon}^{(1)})$, from the noise space $\\mathcal E$. These vectors are then processed through two distinct diffusion model architectures, resulting in pairs of clear images: ($\\mathbf x^{(0)}_1$, $\\mathbf x^{(1)}_1$) from the first model and ($\\mathbf x^{(0)}_2$, $\\mathbf x^{(1)}_2$) from the second. The manifold reproducibility score for the two unconditional diffusion models is defined as:\n\n\n$RP_{manifold} Score :=  \\mathbb{P}( \\mathcal M_{SSCD} ( x^{(\\alpha)}_1,  x^{(\\alpha)}_2)>0.6 \\mid \\alpha \\in [0,1] )$\n\nwhere $\\mathbf x^{(\\alpha)}_i$ are generated from spherical linear interpolation based on ($\\mathbf x^{(0)}_i$, $\\mathbf x^{(1)}_i$):\n$$\n\\begin{align*}\n    & \\mathbf x^{(\\alpha)}_i = \\frac{\\text{sin}((1 - \\alpha) \\theta)}{\\text{sin}(\\theta) } \\mathbf x^{(0)}_i + \\frac{\\text{sin}(\\alpha \\theta)}{\\theta} \\mathbf x^{(1)}_i, \\ \\ i \\in \\{1, 2\\} \\\\\n    & \\theta = \\text{arccos} \\left(\\frac{ \\left(x^{(0)}_i\\right )^T x^{(1)}_i}{||x^{(0)}_i|| ||x^{(1)}_i||} \\right)\n\\end{align*}\n$$\n\nWe applied this score to compare the manifold reproducibility across various unconditional diffusion models.  Results are shown below. Detailed descriptions of the experimental settings can be found in Appendix A.3. In this case, our observation of model reproducibility is still consistent with our current findings.\n\n| $\\text{RP}_{manifold} \\text{ Score}$   | DDPMv6 | EDMv1 | Multistagev1 |\n|--------------|--------|-------|--------------|\n| **DDPMv6**       | 1.0    | 0.90  | 1.0          |\n| **EDMv1**        | 0.90   | 1.0   | 0.93         |\n| **Multistagev1** | 1.0    | 0.93  | 1.0          |"
                    },
                    "title": {
                        "value": "Response to Reviewer vqyB"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2834/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700034845708,
                "cdate": 1700034845708,
                "tmdate": 1700147093697,
                "mdate": 1700147093697,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dTOsQMESfy",
                "forum": "UkLSvLqiO7",
                "replyto": "hhnfEJVzx3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2834/Reviewer_vqyB"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2834/Reviewer_vqyB"
                ],
                "content": {
                    "title": {
                        "value": "On whether we expect similar images in the \"generalization regime\""
                    },
                    "comment": {
                        "value": "I would like to briefly here also raise discussion on how obvious is the result that all the different models produce similar images. From what I can see, it is true that the goal in diffusion models is to estimate the $\\mathbb{E}[x_0|x_t]$, and if all the models accurately estimate this (and thus the ground-truth score function for the data set), it seems clear to me that all models behave similarly: They reproduce the original data set. This is also pointed out in Theorem 1 of the paper, regarding the \"memorization regime\". I may be mistaken, but I do not see a similar result holding in the \"generalization regime\", where none of the models recover the ground-truth score, but instead make \"errors\" and thus generalize. Intuitively, it seems that all models make highly similar errors for some reason or the other. This seems quite non-obvious to me, and in that sense an interesting direction for research. \n\nAdditionally, from what I can see (but again may be wrong), the paper contains new aspects of the phenomenon that have not been noticed in previous work. For instance,  1) The fact that there's a point between the \"generalization\" and \"memorization\" regimes where the models do not produce similar results. 2) The paper points out a case where reproducibility does not hold (UViT/DiT compared to DDPM models in inpainting). \n\nI wonder if the others would agree on these points?"
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2834/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700575461897,
                "cdate": 1700575461897,
                "tmdate": 1700575461897,
                "mdate": 1700575461897,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ItOaLC1adQ",
                "forum": "UkLSvLqiO7",
                "replyto": "58OP5vdRVP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2834/Reviewer_vqyB"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2834/Reviewer_vqyB"
                ],
                "content": {
                    "title": {
                        "value": "Response to rebuttal"
                    },
                    "comment": {
                        "value": "I thank the authors for the new results! I agree that the new results do make the paper more convincing than before. I will not change the score for now, but will consider it after discussion with the reviewers."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2834/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700575861932,
                "cdate": 1700575861932,
                "tmdate": 1700575861932,
                "mdate": 1700575861932,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "HYwB8b1KpL",
            "forum": "UkLSvLqiO7",
            "replyto": "UkLSvLqiO7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2834/Reviewer_LTJ7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2834/Reviewer_LTJ7"
            ],
            "content": {
                "summary": {
                    "value": "The authors observe that different trained diffusion models map to almost identical output images when the deterministic ODE sampling starts from the same initial noise. They validate this experiment with different models and they measure that the behavior is consistent for models that are trained separately, with different architectures, different samplers, and even different perturbation kernels. The authors provide a theoretical justification for this phenomenon in a toy setting (with infinite model capacity and a target distribution of many diracs)."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- The paper is easy to follow. \n- The authors conduct numerous experiments to verify their findings.\n- Understanding the behavior of deterministic samplers is an interesting and timely research topic."
                },
                "weaknesses": {
                    "value": "I believe the main finding of this paper is already known. The Probability Flow ODE depends on the functions $f$, $g$, and the score. For given functions $f$, $g$, the score function is unique! There is a unique score function because there is a unique likelihood function induced by corrupting the data distribution. All diffusion models are trained to estimate the exact same score function \u2014 even if they have different architectures and are trained separately \u2014 the target is always the same. Hence, if the diffusion models are trained perfectly, then it is actually expected that they will all map the same noise to the same output. The small deviations in the shown images in Figure 1, just indicate that there are some learning errors. The finding should stay the same even if we use different samplers, as long as the samplers arrive with guarantees that given enough steps and access to the score they will sample from the right distribution. The only surprising fact to me in this paper is the claim that models trained with different corruption processes will have this property. This doesn\u2019t make much sense to me because for VE SDE and VP SDE for example, even the terminal distribution is different, so how do we even start from the same noise? What distribution does this noise follow?"
                },
                "questions": {
                    "value": "There is a chance that I am missing something fundamental about this paper. I would really like the authors to clarify, if possible, why their main finding is different compared to prior work."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2834/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699225315627,
            "cdate": 1699225315627,
            "tmdate": 1699636226762,
            "mdate": 1699636226762,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HYJF8CDJyO",
                "forum": "UkLSvLqiO7",
                "replyto": "HYwB8b1KpL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for acknowledging the quality of our presentation, experiments, and the timeliness of our results. We value the constructive feedback that the reviewer provided. Although we agree that the some preliminary observations on the reproducibility phenomenon were reported by Song et al (2021) [1] in a very empirical way, our investigation delves deeper and provides a more systematic study about the fundamentals for this phenomenon for generic diffusion models which haven\u2019t been done in previous works to our best knowledge, offering a much more thorough analysis. In particular, the key contributions/findings of our paper that differ from prior works include:\n\n-   we introduced quantitative measures to study reproducibility more systematically;\n    \n-   we demonstrate that reproducibility manifests in two unique regimes and is closely tied to the generalizability of diffusion models, as depicted in Figure 2 of our study\u2014an interesting relationship that has never been explored previously.\n    \n-   we also studied model reproducibility in conditional diffusion models, diffusion models for inverse problems, and fine-tuning, which indicates how this phenomenon could be useful in these different applications.\n    \n\nReviewer vqyB has also noted these significant findings in his comments. In the following, we carefully respond to each of the concerns that the reviewer raised.\n___\n\n> **Q1**:   \u201cI believe the main finding of this paper is already known.\u201d \u201cwhy their main finding is different compared to prior work.\u201d\n  \n**A1**: \nWe agree with the reviewer that Song et al. (2021) presented initial findings on the reproducibility phenomenon with a brief description of this observation. Please note that we've also acknowledged this point at the bottom of Page 3 of our paper. However, we respectfully disagree that our main discovery is well-known or extensively researched. This has also been pointed out by Reviewer vqyB.\n\n1. First, in Section 2, we introduced reproducibility metrics to study this phenomenon more systematically and quantitatively. Our findings that reproducibility appears across different noise corruption processes have not been shown in prior works and the phenomenon is nontrivial, which we will discuss in detail in A2 for Q2.\n\n2. Second, in Section 3, our work showed that model reproducibility occurs in two distinct regimes, the \u201cmemorization regime\u201d and \u201cgeneralizability regime\u201d, and model reproducibility has a strong correlation with model generalizability (see Figure 2). This phenomenon has never been discovered nor studied in previous works, and we believe this is very important for understanding the generalizability properties of diffusion models. Moreover, we have theoretically and experimentally justified the reproducibility in the memorization regime, as illustrated in Figure 5.\n  \n3. Third, in Section 4 we studied the model reproducibility of diffusion models under different settings, such as conditional diffusion models, diffusion models for inverse problems, and fine-tuning diffusion models. For each of these different settings, the model reproducibility manifests in different but principled ways. These have never been studied in previous works.\n\n[1] Song, Yang, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. \"Score-based generative modeling through stochastic differential equations.\" _arXiv preprint arXiv:2011.13456_ (2020)."
                    },
                    "title": {
                        "value": "Response to Reviewer LTJ7"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2834/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700033643607,
                "cdate": 1700033643607,
                "tmdate": 1700147043718,
                "mdate": 1700147043718,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XIlGzR3QWc",
                "forum": "UkLSvLqiO7",
                "replyto": "HYwB8b1KpL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> **Q2**:  \"The Probability Flow ODE depends on the functions f, g, and the score. For given functions f, g, the score function is unique! There is a unique score function because there is a unique likelihood function induced by corrupting the data distribution. All diffusion models are trained to estimate the exact same score function \u2014 even if they have different architectures and are trained separately \u2014 the target is always the same. Hence, if the diffusion models are trained perfectly, then it is expected that they will all map the same noise to the same output.\u201d\n\n**A2**:\nFirst of all, we appreciate the reviewer's thoughtful remarks regarding the model reproducibility. However, to the best of our knowledge, except for the preliminary findings reported by Song et al. in 2021 [1], we have not come across any empirical or theoretical evidence substantiating the above claims that (i) \u201call diffusion models (in terms of all different settings and cases) are designed to estimate exactly the same score function in practice\u201d, and (ii) \u201call diffusion models (in terms of all different settings and cases) can always be perfectly trained for score estimation\u201d. We would appreciate it if the reviewer could share the references that can support these claims other than Song et al. 2021.\n\nOn the other hand, to partially support/refute the reviewer\u2019s claims, our work has quantitatively conducted extensive experiments to study this problem in both memorization and generalization regimes under various settings, and we provided a theoretical study in our work in the memorization regime.\n\n1.  First, in the memorization regime when the training data is limited, we demonstrate that the diffusion model can only reproduce or \u201cmemorize\u201d training data. And the reviewer\u2019s Claims (i) and (ii) are corroborated by both our theoretical analysis and experimental findings. Our research demonstrates the existence of an optimal denoiser and scoring function, as established in our Theorem 1. Furthermore, our work showed that the practical diffusion models converge towards this optimal denoiser, which is unique given f and g, as evidenced in Figure 5. Therefore, in the memorization regime, this observation is in agreement with the reviewer's statement.\n  \n2.  In the generalization regime, where the model reproducibility and generalizability co-exist, whether and how the diffusion model has been trained perfectly is not clear. As depicted in Figure 13 of our revised paper, it is evident that in the generalization regime, the denoiser obtains a relatively high training loss, but still has good generations, good generalizability, and also has reproducibility. This requires additional investigation before we can assert this claim, and our empirical results have raised numerous intriguing theoretical questions that merit further exploration.\n\n3.  Moreover, our results surprisingly show that model reproducibility still exists in the generalization regime, even if we use different functions $f$,$g$ by using different perturbation kernels (we address the noise distribution question in Q3). This observation may diverge from the assumption of the reviewer\u2019s claim.\n\n[1] Song, Yang, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. \"Score-based generative modeling through stochastic differential equations.\" ICLR, 2021."
                    },
                    "title": {
                        "value": "Response to Reviewer LTJ7"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2834/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700033689110,
                "cdate": 1700033689110,
                "tmdate": 1700147058511,
                "mdate": 1700147058511,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7hKuCNAiF7",
                "forum": "UkLSvLqiO7",
                "replyto": "HYwB8b1KpL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> **Q3**:  \u201cThe claim, that models trained with different corruption processes will have this property, doesn\u2019t make much sense to me. This is because for VE SDE and VP SDE for example, even the terminal distribution is different, so how do we even start from the same noise? What distribution does this noise follow?\u201d\n\n**A3**:\nAlthough  using different perturbation kernels will result in different noise distributions, the distribution difference only lies in the scaling of the variance for the Gaussian. Therefore, for a fair comparison, we can always get rid of the scaling issues by normalizing the variance and then sampling from the noise.  We have discussed this in detail in \u201cInitial Noise Consistency\u201d of Appendix B of our work.\n\nFor example, for VP and subVP noise perturbation kernels in [1], we define the noise space as $\\mathcal E = \\mathcal{N}(\\mathbf 0, \\mathbf I)$, whereas the VE noise perturbation kernel [1] introduces a distinct noise space with $\\mathcal E = \\mathcal{N}(\\mathbf 0,  \\sigma^2_{\\text{max}} \\cdot \\mathbf I)$, where $\\sigma_{\\text{max}}$ is predefined. So during the experiment, we sample 10K initial noise $\\mathbf \\epsilon_{\\text{vp, subvp}} \\sim \\mathcal{N}(\\mathbf 0, \\mathbf I)$ for the generation with VP and subVP noise perturbation kernel. For VE noise perturbation kernel, the initial noise is scaled as $\\mathbf \\epsilon_{\\text{ve}} = \\sigma_{\\text{max}} \\mathbf \\epsilon_{\\text{vp, subvp}}$. \n\n[1] Song, Yang, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. \"Score-based generative modeling through stochastic differential equations.\" ICLR, 2021."
                    },
                    "title": {
                        "value": "Response to Reviewer LTJ7"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2834/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700033847939,
                "cdate": 1700033847939,
                "tmdate": 1700147065230,
                "mdate": 1700147065230,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "crkQcTZ0lV",
                "forum": "UkLSvLqiO7",
                "replyto": "HYwB8b1KpL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2834/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to your feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer LTJ7:\n\nI would like to begin by expressing my sincere gratitude for the time and effort you have dedicated to reviewing our work. Your insights and feedback are invaluable to us. We hope our responses addressed your questions. If you have any further concerns,  we are appreciated and more than willing to provide any further information or clarification. \n\nIf our responses have addressed your concerns, we would appreciate it a lot if you could improve the score.\nThank you once again for your valuable contribution to improving our work. Looking forward to your feedback."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2834/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700289731530,
                "cdate": 1700289731530,
                "tmdate": 1700290050309,
                "mdate": 1700290050309,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]