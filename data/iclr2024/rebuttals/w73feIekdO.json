[
    {
        "title": "Real-time computer vision on low-end boards via clustering motion vectors"
    },
    {
        "review": {
            "id": "zvRFKIdLnu",
            "forum": "w73feIekdO",
            "replyto": "w73feIekdO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9453/Reviewer_aQsA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9453/Reviewer_aQsA"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a clustering approach based on the idea of coresets. It is demonstrated in the paper that the proposed formulation helps perform tracking and 3D map creation from videos in real time. Few experimental results are shown to demonstrate the claims made in the paper."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* Real-time solution to a couple of popular computer vision problems."
                },
                "weaknesses": {
                    "value": "* Not a well-written paper. So many typos and grammatical mistakes.\n* The paper widely discusses the existing literature in theory and emphasizes less of the actual contributions of the paper other than making few methods real-time.\n* The results are poorly demonstrated. I am unable to conclude how good of a map is obtained using the proposed method.\n* Also confusion about video tracing and tracking \u2014see Sec. 3. \n\nRefer Questions section for more comments."
                },
                "questions": {
                    "value": "## Abstract:\n* To this end, we utilize motion vectors and clusters. What clusters authors are referring to. I believe it should be clustering algorithms/methods.\n\n* with real-time running time -> that gives real-time performance.\n\n## Introduction\n* A meta-survey on such approaches Zou et al. (2019) states that in recent years -> kindly use \\citep{} to put parentheses for citation or rewrite this line.\n\n* \u201cfool\" -> use `` and \u2019\u2019 for the apt quotes.\n\n\n* Figure 1 -> the blue motion vector is hardly visible. Furthermore, kindly use a different color for the blue motion vector as it correlates with the flower in the background. \n* Figure 2 -> figures are placed side to side, whereas captions suggest top and bottom. Kindly correct.\n\n\n* There are many grammatical mistakes in the paper. Kindly improve the writing of the paper.\n\n \n\n\n## General Comment:\n\nWith all due respect, tracking and map creation is not computer vision. These are a couple of  problems studied in computer vision. Kindly modify your paper title."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9453/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698658760505,
            "cdate": 1698658760505,
            "tmdate": 1699637189917,
            "mdate": 1699637189917,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "WSHMlrOX9s",
            "forum": "w73feIekdO",
            "replyto": "w73feIekdO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9453/Reviewer_qadD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9453/Reviewer_qadD"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a fully polynomial randomized approximation scheme for the clustering of motion vectors, which is then applied to the motion vectors produced by standard video encoders to the problem of visual tracking. The approximation scheme is an adaptation of the results of Feldman and Schulman (2012), which is concerned with robust clustering of points in arbitrary metric spaces, to *segments* as defined by the paper. Specifically, points on segments are sampled at uniform intervals, under a condition on the number of points $\\epsilon'$ such that the approximation in Feldman and Schulman (2012) is preserved."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "# Originality\nThe idea of directly using vector motions produced by video codecs as inputs to computer-vision tasks is interesting, as it is the broader approach of designing FPRAS for computer vision problems.\n\n# Quality\nThe paper brings a broad review of the literature and is self-contained, including detailed proofs of its several lemmas and theorems.\n\n# Clarity\nEvery term is defined, and the illustration in Figure 2 helps the reader to understand the geometric meaning of the cost function defined in Equation 1.\n\n# Significance\nThe paper brings to the attention of the computer-vision community an important class of \"probably approximately correct\" algorithms, as in the title of Valiant's book."
                },
                "weaknesses": {
                    "value": "# General\n\nThe paper is not well organized. The first two sections of the Introduction, titled \"Video Tracking\" and \"Motion Vectors,\" do not describe the problem addressed by the paper. The subsection \"Our Approach\" does not describe the approach at all but introduces and illustrates the definition of a cost function which is discussed only much later in the paper. The subsection \"Coresets\" brings a definition of coreset, followed by an unusually long quote from the paper by Denisov et al. (2023). That section makes a reference to a \"segment clustering problem stated in Section 2.1\" that has a small coreset, but I was not able to parse the remaining of that paragraph. The references to Jubran et al. (2021) and Rosman et al. (2014) seem unnecessary, as they refer to exceptions (or so I understood) to the stated goal of having coresets which are weighted subsets of the inputs.\n\nAlgorithm 1 should be replaced for the simple formula that computes $\\epsilon'$. This value is then used to produce samples at uniform intervals on the motion vectors. It is not clear how the claimed novelty of Algorithm 1 generalizes, as stated, previous work by Rosman et al. (2014), which is concerned with fitting segments to points, rather than sampling from segments.\n\nThe structure of Algorithm 2 is not at all illustrated by Figure 3, as attempted. A key component of that algorithm (Feldman and Shulman CORESET algorithm (2012)) was replaced in Figure 3 with a different method (Bachem et al. (2018)) for \"easier implementation.\"\n\n# Evaluation\nExperimental evaluation is insufficient. There is scant comparison, and no quantitative evaluation other than an unusual computation of frames-per-second (FPS). It is not valid to subtract all computing times but clustering from the pipeline, divide the number of frames by whatever remains and claim that as an FPS.\n\nThe role of Artuhr and Vassilvitskii (2007) in the empirical evaluations is unclear since the output of Algorithm 2 should be a clustering of the segments. One the other hand, there is no mention of Algorithm 2 in that section, only of Algorithm 1.\n\nThe steps of the video tracking method are unclear. The is no explanation for what \"Add for each motion vector its degree to (0, 10 and (1, 0)\". The is no discussion of how one moves on beyond $k = 2$.\n\nThe jump from clustering of motion vectors to map creation leaves a gaping hole in the paper. The empirical evaluation of 3D map creation follows similar steps, which are repeated almost verbatim and should be omitted.\n\nThere are citations that are unusual to the computer-vision community: the OpenCV library, the Python 3 reference Manual, an Ubuntu Linux guide, the Rasberry Pi user guide, Vigdear manual, CutstomTkInter, and others.\n\nThe Conclusion section of the paper cannot be moved to an appendix."
                },
                "questions": {
                    "value": "- It is curious that the number of samples on a segment does not depend on the length of the segment, according to Algorithm 1. Is there any intuition for why?\n\n- Still in Algorithm 1, it is correctly stated that $r$ is defined in Definition 2.3; however, given the comment on the second paragraph following the description of the algorithm (\"Note that $r$ in Algorithms 1...\"), it should be provided as an input, since the function $D$ to which $r$ corresponds is not.\n\n- I assume the word \"tracing,\" which appears twice in Section 3, is at typo, and \"tracking\" was meant instead?\n\n- Was Algorithm 2 used at all? What is the purpose of using Arthur and Vassilvitskii (2007) if Algorithm 2 already produces a clustering? How is it possible for Arthur and Vassilvitskii (2007) algorithm to have been implemented in Bradski (2000)?\n\n- How is a motion-vector clustering algorithm applied to map creation? Why computations on Raspberry-Pi and utilization of gyroscope contribute to \"fair comparison\"?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9453/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9453/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9453/Reviewer_qadD"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9453/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698793178617,
            "cdate": 1698793178617,
            "tmdate": 1699637189798,
            "mdate": 1699637189798,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "FG7cu1nT3G",
            "forum": "w73feIekdO",
            "replyto": "w73feIekdO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9453/Reviewer_wXa9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9453/Reviewer_wXa9"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces innovative computer vision techniques that integrate classical machine learning strategies to enhance efficiency and robustness. The authors showcase the practical impact of their clustering method in video tracking and map creation from video, successfully executing it in real-time on micro-computers. The contributions of the paper encompass a novel clustering algorithm for motion vectors, a coreset-based approach that reduces the computational complexity of the clustering algorithm, and the implementation of the clustering algorithm on low-end boards, enabling real-time performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "S1. The paper is well-written and most of the content is quite easy to follow. \nS2. The main contribution of this work is significantly interesting by incorporating traditional machine learning techniques in the age of deep learning. \nS3. The proposed vector clustering is theoretically sound, I tried my best to examine most of them and did not find obvious errors. \nS4. Overall, I have significant concerns regarding the experimental section of the paper. Firstly, the proposed method is only validated in three application scenarios, and the experimental results are not extensively reported or analyzed, neither in the main text nor in the supplementary material."
                },
                "weaknesses": {
                    "value": "W1. The proofs in Section 2 are rather obscure and difficult for readers without relevant background knowledge to comprehend. Additionally, many crucial steps are relegated to the supplementary material, greatly impacting the readability of this paper.\nW2. This paper lacks an introduction and discussion of related works, making it challenging for readers unfamiliar with the field to fully understand the contributions of this article."
                },
                "questions": {
                    "value": "Please check the weaknesses listed above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9453/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698825770361,
            "cdate": 1698825770361,
            "tmdate": 1699637189674,
            "mdate": 1699637189674,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "NLKFsY27K9",
            "forum": "w73feIekdO",
            "replyto": "w73feIekdO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9453/Reviewer_MMZa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9453/Reviewer_MMZa"
            ],
            "content": {
                "summary": {
                    "value": "The paper focuses on a tracking algorithm that takes as input motion vectors obtained from standard video encoders.  The main contribution is the leveraging of the notion of coresets applied to segments, obtaining representative clusters and tracking. The bulk of the paper is on the extension of coresets for point sets to segments.  The tracking algorithm result is illustrated in two examples - big buck bunny video example, and 3D map estimation from drone video."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The main claim of the paper is in the generalization coreset ideas for points to segments and in the derivation of a tracking algorithm that is computationally efficient.  Certain claims are made about generalization of previous theoretical work (that I am not fully familiar with and cannot comment)."
                },
                "weaknesses": {
                    "value": "While I understand the rationale and setup of the problem for translating motion vector inputs as coresets and tracking,  the  results on the two datasets are not convincing.  While the paper talks a lot about how this approach is substantially better in comparison to neural-net based methods, it fails to refer to any of the classic methods in tracking where clustering, robust statistical methods are used.  The paper does refer to a review paper and states that there are over 1000 articles on the subject.  However, if the central aim of the paper is to demonstrate the advancement in tracking algorithms the paper should demonstrate the effectiveness of the algorithm designed by comparing it with at least one alternative (e.g. mean-shift based tracking ,  Comaniciu et al (CVPR 2000)).  I note that the mean-shift based tracker performed in real-time in low computational power settings for given candidate regions in a video over two decades ago."
                },
                "questions": {
                    "value": "I have several questions that will help me identify what the central contributions are and on how the proposed method outperforms over other methods in the state of the art.\n\n1) Is your contribution mainly the extension of coreset idea to segments?   There has been work on coresets for sets of lines (e.g. Coreset for Line-Sets Clustering, Lotan et al, 2022).  Please elaborate on how your method is different.\n2) Have you compared your tracker with other methods in opencv and if so, what was the outcome? You refer to OpenCV in your paper and it is not clear from the paper how it was used in your experiments.\n3) Can you elaborate on the tradeoff between computational complexity of your technique and (epsilon, delta) choices during coreset construction?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9453/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699561892523,
            "cdate": 1699561892523,
            "tmdate": 1699637189558,
            "mdate": 1699637189558,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]