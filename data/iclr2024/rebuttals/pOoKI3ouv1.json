[
    {
        "title": "Robust agents learn causal world models"
    },
    {
        "review": {
            "id": "UEJtxOTC7A",
            "forum": "pOoKI3ouv1",
            "replyto": "pOoKI3ouv1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2566/Reviewer_VrNg"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2566/Reviewer_VrNg"
            ],
            "content": {
                "summary": {
                    "value": "The paper shows that any agent that could effectively \"learn\" the optimal decision under distribution shifts MUST have learned the (approximate) causal model of the data generating process. The implications of this result on the related research areas such as transfer learning and causal inference have been discussed."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The problem considered is fundamental.\n\n2. The idea is cute and clean."
                },
                "weaknesses": {
                    "value": "Only necessary condition is proved but not the sufficient condition. It will be stronger to prove something like, if the agent has learned some \"approximate\" causal relationship, it can efficiently learn the optimal decision under distribution shift."
                },
                "questions": {
                    "value": "How to identify and prove the sufficient condition for learning the causal model for learning the optimal decision making under distribution shift?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2566/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2566/Reviewer_VrNg",
                        "ICLR.cc/2024/Conference/Submission2566/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2566/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698553119113,
            "cdate": 1698553119113,
            "tmdate": 1700557122863,
            "mdate": 1700557122863,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "QQKiJm5lWj",
                "forum": "pOoKI3ouv1",
                "replyto": "UEJtxOTC7A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2566/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2566/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to reviewer VrNg"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their encouraging review and helpful comments. \n\nAs the reviewer has requested, we have derived a new theorem which proves the sufficiency condition corresponding to the necessity condition proven in the original submission. This new theorem is included in the updated manuscript (Theorem 3)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2566/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700431706523,
                "cdate": 1700431706523,
                "tmdate": 1700489021456,
                "mdate": 1700489021456,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mDsYG0TslZ",
                "forum": "pOoKI3ouv1",
                "replyto": "QQKiJm5lWj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2566/Reviewer_VrNg"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2566/Reviewer_VrNg"
                ],
                "content": {
                    "comment": {
                        "value": "This is a nice addition to the paper."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2566/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700557158196,
                "cdate": 1700557158196,
                "tmdate": 1700557158196,
                "mdate": 1700557158196,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "v7bE5YG9xr",
            "forum": "pOoKI3ouv1",
            "replyto": "pOoKI3ouv1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2566/Reviewer_vFfA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2566/Reviewer_vFfA"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes some theoretical results about decision making tasks that, if the environment is generated by a Bayesian network, and an agent is able to learn a low regret strategy for all mixture of local interventions on the environment, including hard intervention and randomized experiments on any number of variables, then we can recover the causal structure of the environment from the optimal decision learned by the agent. Therefore, if we want to obtain such an agent, it is necessary to learn the causal structure."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. They propose theoretical results connecting decision making and causal structure learning. As suggested by their results, a robust enough agent should always learn the causal structure.\n2. The limitation for learning causal structure can be transferred to limitation of robust decision making by their results.\n3. Their result gives an example about inferring causal structure when only one variable is observed under each intervention."
                },
                "weaknesses": {
                    "value": "1. They do not conduct an experiment for justifying their results.\n2. Their results can only be applied to a small range of scenarios, where we need to reach small regret for all mixture of local interventions. However, most applicable tasks, such as transfer learning, only consider interventions on a subset of variables.\n3. There are some spelling mistakes in their text, and some usage of notations are unclear in their text and proof."
                },
                "questions": {
                    "value": "see  in Weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2566/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2566/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2566/Reviewer_vFfA"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2566/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698675687590,
            "cdate": 1698675687590,
            "tmdate": 1699636193847,
            "mdate": 1699636193847,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Z4XMyOvtaQ",
                "forum": "pOoKI3ouv1",
                "replyto": "v7bE5YG9xr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2566/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2566/Authors"
                ],
                "content": {
                    "title": {
                        "value": "reply to reviewer vFfa"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their helpful comments, and have made the following changes to the manuscript in response to their recommendations\n\n1. Experiments section (appendix F.1, end of appendices). We now empirically validate our results using a simulation example as suggested by the reviewer. This involves converting the proof of theorem 1 into an algorithm for learning the underlying CBN from the agents policy under distributional shifts, and testing it on randomly generated CIDs. We also explore how the accuracy of the learned CBN scales with the agent\u2019s regret bound. \n\n2. New appendix F with simplified overview of proof.\n\nWe agree our results would be stronger and more applicable to current systems if we could extend theorems 1 & 2 to shifts on a small subset of environment variables. Unfortunately, this would be a significant extension of the current proofs and we were unable to do this extension in the time available. We agree this is an important direction for future work."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2566/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700431666177,
                "cdate": 1700431666177,
                "tmdate": 1700557553522,
                "mdate": 1700557553522,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "tUMhfkMi14",
            "forum": "pOoKI3ouv1",
            "replyto": "pOoKI3ouv1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2566/Reviewer_4TT8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2566/Reviewer_4TT8"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents theoretical results showing that any agent that learns well under distributional shifts, must have learned the causal structure of the environment. Here distributional shifts that are most important are shifts of the latent causal variables. That is, if one can generalize across the set of possible changes in these variables, one has learned the causal structure. The result is both deep and intuitive, and has widespread implications. Although theoretical in important senses, e.g. it assumes some unspecified learning method, the result is no less powerful in arguing that to transfer one must learn causal structure."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "This paper is a gem. The theoretical analysis is simple and clear, the implications are broad and powerful."
                },
                "weaknesses": {
                    "value": "The only weakness, in my opinion, is that the statement of the result in the introduction felt pretty slippery. (See detailed comments below.) All of this was satisfyingly resolved, but I do think the paper would benefit from an effort to sharpen that first section. \n\nDetails comments: \n- Please define these: \n\"distributional shifts\"\n\"distributionally shifted environments\"\n\"target domains\"\n\"causal modelling and transfer learning\"\n- \" used to derive out results\" typo\n- \"Our analysis focuses on distributional shifts that involve changes to the causal data generating process, and hence can be modelled as interventions (Sch\u00f6lkopf et al., 2021)\" This would have been nice in the intro. \n- \"This does not assume that all shifts an agent will encounter can be modelled as interventions, but requires that the agent is at least capable of adapting to these shifts.\" I don't know that I understand this sentence. \n- \"By cCreftheorem: main,theorem: main approx agents\" typo?"
                },
                "questions": {
                    "value": "I would like to hear what changes to the introduction might look like."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "10: strong accept, should be highlighted at the conference"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2566/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698711928285,
            "cdate": 1698711928285,
            "tmdate": 1699636193769,
            "mdate": 1699636193769,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "uFGOMUe6Cn",
                "forum": "pOoKI3ouv1",
                "replyto": "tUMhfkMi14",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2566/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2566/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to reviewer 4TT8"
                    },
                    "comment": {
                        "value": "We want to very much thank the reviewer for their encouraging review and helpful comments. We have updated the introduction to be clearer and in line with the reviewers suggestions. On top of this we have also introduced a simplified overview of the proof and an experiments section (appendix F). To answer the reviewers questions, \n\n1. \"Please define these ...\". We have added definitions for these terms in sections with the corresponding titles, and removed the term `causal modelling\u2019. If the reviewer would prefer definitions in the form e.g. Definition 1 (Bayesian networks) we will include these.\n2. Have clarified in the introduction that we are focusing on interventional shifts. \n3. \"This does not assume that all shifts... I don't know that I understand this sentence\". Apologies, this was confusingly written. What we are trying to say is, imagine an agent that is robust to `all\u2019 distributional shifts (including those that cannot be represented with local interventions, such as changing the set of variables). This agent will also be subject to our theorems, because it is robust to all distributional shifts which includes interventional shifts as a subset. So our results apply to agents that are robust to a larger set of shifts. Will remove if the reviewer recommends.\n4. Typos fixed"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2566/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700431091608,
                "cdate": 1700431091608,
                "tmdate": 1700440516926,
                "mdate": 1700440516926,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xX61ZCr28Q",
                "forum": "pOoKI3ouv1",
                "replyto": "uFGOMUe6Cn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2566/Reviewer_4TT8"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2566/Reviewer_4TT8"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the detailed response"
                    },
                    "comment": {
                        "value": "Thank you for the detailed response. The revisions look great. Very cool work. \n\nFYI - At the beginning of section 5 there appears to be a note that I don't think you intended to include."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2566/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700670775706,
                "cdate": 1700670775706,
                "tmdate": 1700670775706,
                "mdate": 1700670775706,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "DIlJnd32YJ",
            "forum": "pOoKI3ouv1",
            "replyto": "pOoKI3ouv1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2566/Reviewer_gS4b"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2566/Reviewer_gS4b"
            ],
            "content": {
                "summary": {
                    "value": "This paper shows a formal connection between generalizing under distribution shits and learning causal models, a connection that has been expressed as hypothesis before (e.g. in Sch\u00f6lkopf 2021). Specifically, they show that if the agent performs well under distribution shifts (bounded regret), then it must have learned a representation that captures the causal structure of the world - in this case, the conditional independencies and causal relationships in the true causal bayesian network."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper makes an original and significant theoretical contribution by formally establishing a fundamental connection between causal learning and generalisation under distribution shifts.\n## Originality:\n* They provide a proof for showing that an agent that is sufficiently adaptive has learned a causal model of the environment. This is an impressive achievement and a stronger statement than the one stated by good regulator theorem (which as the authors have cited, has been misunderstood and misrepresented in the past)\n## Quality:\n* The theoretical results are technically strong, with detailed proofs provided in the appendices. \n* The assumptions are clearly stated and well-motivated. The analysis meaningfully relaxes the assumption of optimality.\n* The writing is clear, well-structured, and accessible given the technical nature of the work.\n## Clarity:\n* The paper is well written and easy to read.\n## Significance:\n* The results have important implications in safety and robustness under distribution shifts.\n* The proof is non-trivial and provides a great stepping stone for extending to richer settings (e.g. mediated decision tasks)"
                },
                "weaknesses": {
                    "value": "- As the authors acknowledge, the results are mainly theoretical. Even a minimal empirical validation of the key insights would strengthen the paper. For example it would be great even if you turn the informal overview (appendix C) into a simple simulation example rather than remain a thought experiment.\n- The scope is currently limited to unmediated decision tasks. Extending the results to broader RL settings would increase applicability (although I acknowledge that seems significantly more challenging task and out of scope of this work - it\u2019s just a personal curiosity at this point and would be excited to see the next paper already).\n- The proof is still quite challenging to understand and I believe that there a more informal / simplified sketch that can be introduced to help the reader before dive into the more formal proof.\n- On a similar note, the implications of the assumptions are not discussed. (e.g. I\u2019d like to see things like, \u201cassumption 2 implies that there exist distribution shifts for which the optimal policies are different\u201d."
                },
                "questions": {
                    "value": "(apologies for repetition from weaknesses)\n- The implications of the assumptions are not discussed. (e.g. I\u2019d like to see things like, \u201cassumption 2 implies that there exist distribution shifts for which the optimal policies are different\u201d.\n- \"The environment is described by a set of random variables C...\" this sentence belongs to the main text since it you don't explain C random variable although it's heavily used.\n- Although discussed in the appendix, i'd like to see the description of what squares, circles and diamonds mean in the CID\n- In assumption 1 you stated $\\text{Desc}_D \\cap \\text{Anc}_U = \\emptyset$ but this doesn't exclude the trivial setting (which you state in the appendix is not of focus). Can you either extend the assumption or comment in the main text that it's not of interest the trivial setting? (i know it's a nitpick but got me wondered while reading it in the main text and i feel that since you thought about it you could have mentioned it earlier in the text).\n- Definition 6 in the appendix: Shouldn't it be $\\mathbb{E}^{\\pi_\\sigma}$ (subscript on policy)? Also, $\\delta \\geq 0$ is missing.\n- Can you please give a simple sketch of the proof? This would help the readability significantly. Also i feel there is a simple sentence that can be written on each theorem that explains its implications"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2566/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2566/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2566/Reviewer_gS4b"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2566/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698776149546,
            "cdate": 1698776149546,
            "tmdate": 1700907261774,
            "mdate": 1700907261774,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xNvLY8G2AW",
                "forum": "pOoKI3ouv1",
                "replyto": "DIlJnd32YJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2566/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2566/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to reviewer gS4b"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their thoughtful review, and have made the following changes to the manuscript in response to their recommendations\n\n1. Experiments section (appendix F.1, end of appendices). We now empirically validate our results using a simulation example as suggested by the reviewer. This involves converting the proof of theorem 1 into an algorithm for learning the underlying CBN from the agents policy under distributional shifts, and testing it on randomly generated CIDs. We also explore how the accuracy of the learned CBN scales with the agent\u2019s regret bound. \n\n2. Simplified sketch of proof (appendix F, end of appendices). The previous proof overview was too involved, as we have re-written it to be 3 paragraphs long. The example covers a simple binary decision task with two latent variables. There is also an algorithm in appendix F.1 detailing how to learn the CBN in this setting. \n\n3. Discussed implications of assumptions immediately after their statement and suggested. \n\n4. Added missing description of chance nodes \u201cC\u201d on page 3.\n\n5. Added description of CID nodes (circles, squares diamonds) to caption of figure 1.  \n\n6. Added sentence description immediately after / before each theorem.\n\n7. The reviewer also points out that it was not made clear how our assumptions deal with the trivial case (i.e. where the agent\u2019s action does not cause the utility). In this case, all policies are optimal, and hence the assumption of domain independence is violated (there is a single policy that is optimal under all domain shifts). We have added a note making this clear. \n\n8. Typos corrected\n\nWe tried to extend the results to unmediated decision tasks, but unfortunately this was too challenging in the time available. We agree this is an important direction for future work."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2566/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700430653968,
                "cdate": 1700430653968,
                "tmdate": 1700489308385,
                "mdate": 1700489308385,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gDqmZAbnPa",
                "forum": "pOoKI3ouv1",
                "replyto": "DIlJnd32YJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2566/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2566/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "As the discussion period comes to an end, we would greatly appreciate any response to the changes made, which include the requested experiments and proof overview (summarised here and presented in appendix F). Either way, many thanks for the helpful review."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2566/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700609665570,
                "cdate": 1700609665570,
                "tmdate": 1700663211242,
                "mdate": 1700663211242,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]