[
    {
        "title": "P2RBOX:A SINGLE POINT IS ALL YOU NEED TRAINING ORIENTED OBJECT DETECTOR"
    },
    {
        "review": {
            "id": "hoaSUIJXZy",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission689/Reviewer_KHmW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission689/Reviewer_KHmW"
            ],
            "forum": "3LFy3dUS86",
            "replyto": "3LFy3dUS86",
            "content": {
                "summary": {
                    "value": "The authors introduce a novel framework P2RBOX for oriented object detection under point supervision. P2RBOX consists of mask generator, constrainer module and inspector module. The authors made reasonable designs for these modules and finally achieved good performance on mainstream datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The motivation is interesting, and the proposed method is theoretically feasible. Experimental results show that the framework achieves good performance."
                },
                "weaknesses": {
                    "value": "The content of Fig. 2 is not enough to intuitively understand the process of the proposed framework. It is suggested that the author include more details and explanations in Fig.2."
                },
                "questions": {
                    "value": "The proposed framework is not innovative enough and is not a completely point-based supervision method."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission689/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission689/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission689/Reviewer_KHmW"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission689/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697290345844,
            "cdate": 1697290345844,
            "tmdate": 1700811485642,
            "mdate": 1700811485642,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2Mh5Ad2N5b",
                "forum": "3LFy3dUS86",
                "replyto": "hoaSUIJXZy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission689/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission689/Authors"
                ],
                "content": {
                    "comment": {
                        "value": ">W1: The content of Fig. 2 is not enough to intuitively understand the process of the proposed framework. It is suggested that the author include more details and explanations in Fig.2.\n\nThank you for your feedback. I appreciate your suggestion to enhance the clarity of our training process overview (Fig. 2). We will incorporate additional visual aids and improve the representation of the point selection in the Point Bag Generation module for better comprehension. \n>Q1: Oriented object detection is a generalized form of general object detection. Please discuss the effect of the proposed framework on horizontal object detection.\n\nThank you for your comments. haven't conducted experiments on widely-used detection datasets like COCO. But in my analysis, the final performance mainly depends on the performance of the SAM model as an anchor generator. The method proposed in this article determines a new criterion to select a more matching mask. For a general target detection data set, SAM may perform better than the DOTA data set. At the same time, the SAE module will become useless. When applied to a more diverse dataset like COCO, especially for categories like humans with challenges such as occlusion and varying poses, the boost from semantic scores might not be as pronounced. Since I have not done experiments on COCO, I will be happy to show the experimental results on COCO in the future."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700542558156,
                "cdate": 1700542558156,
                "tmdate": 1700542558156,
                "mdate": 1700542558156,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LXitYuAQPM",
            "forum": "3LFy3dUS86",
            "replyto": "3LFy3dUS86",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission689/Reviewer_4XWe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission689/Reviewer_4XWe"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on  point-supervised oriented object detection task, and presnts the P2RBox network. The method first leverages the SAM-based mask generator to produce the mask proposals based on single point, and then  presents Constrainer and Inspector modules to select the high-quality mask proposal. The Symmetry Axis Estimation (SAE) module are further proposed to better  generate the fitting rotated box for some categories. Based on the generated rotated bounding box, a fully-supervised method  can be trained. The extensive experiments are conducted to demstrate the effectiveness of the proposed method on DOTA."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The point-supervised oriented object detection is a challenging task with only point-based information. Well, weakly-spervised oriented object task is also an interesting research topic.\n\n2. The proposed method can benefit the high-quality mask selection based on point prompt  for current zero-shot mask generator like SAM for aerial image aera."
                },
                "weaknesses": {
                    "value": "1. In this paper,  some unreasonable aspects exist:\n(1) Strictly speaking, this method is not a pure point-supervised oriented object detection approach. This method depends on mask proposals from SAM-based mask generator, which has been trained with lots of data.  \n(2)  Oriented object detection is a compromise solution between the hbox-based object detection and fine-grained segmentation tasks. This paper adopts the  \"point-to-mask-to-rbox\" manner. Compared with rbox with orientation information,  mask has fine-grained pose information. The approach  designs to generate the relatively coarse rbox based on the selected masks, which may put the cart before the horse.  The proposed method can solve the high-quality mask selection based on point prompt  for general mask generator like SAM for aerial image filed, which is applicable.\n(3)This method follows the assumption that the annotated point of an object is close proximity to the center of the mask.  This assumption  is also not rigorous enough.\n2. The proposed Symmetry Axis Estimation (SAE) module is not general for all categories, which is effective for PL and HC for DOTA dataset. For most  of categories, the peformance is descreased form the Table 7 in Appendix.  For other datasets, how to determine whether to use this module.\n3. Some experimental settings is not clear, such as all models adopts r-50 model with 1x trianing schedul? Some reported results miss  the mAP results in some ablation studies, why only report mIoU?"
                },
                "questions": {
                    "value": "Please see the Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission689/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698667844805,
            "cdate": 1698667844805,
            "tmdate": 1699635996246,
            "mdate": 1699635996246,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qWJc7OgEnM",
                "forum": "3LFy3dUS86",
                "replyto": "LXitYuAQPM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission689/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission689/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> W1.1:(1) Strictly speaking, this method is not a pure point-supervised oriented object detection approach. This method depends on mask proposals from SAM-based mask generator, which has been trained with lots of data.\n\nYou're correct in saying that our method doesn't depend only on one specific type of guidance, but it's not strongly supervised either. I want to highlight that I didn't train SAM model's details for the DOTA dataset; I used the settings given by the official website. The comparison baseline is also created using SAM. I truly value your insights on this issue.\n> W1.2:(2) Oriented object detection is a compromise solution between the hbox-based object detection and fine-grained segmentation tasks. This paper adopts the \"point-to-mask-to-rbox\" manner. Compared with rbox with orientation information, mask has fine-grained pose information. The approach designs to generate the relatively coarse rbox based on the selected masks, which may put the cart before the horse. The proposed method can solve the high-quality mask selection based on point prompt for general mask generator like SAM for aerial image filed, which is applicable. \n\nThanks to the reviewers for their feedback. I understand your point of view, that is, if you already have mask-level annotation, you may not need to pay attention to the rotation box-level annotation, because the latter is relatively rough. However, I would like to highlight application-specific aspects of our method for rotating box annotation. In some scenarios, rotating box annotation still has unique advantages, such as in applications that deal with tilted targets, directional detection, or where the target direction needs to be considered. In these cases, rotating box annotations may provide more accurate information rather than just being redundant as mask-level annotations. I hope this will make you reconsider this article.\n> W1.3:(3)This method follows the assumption that the annotated point of an object is close proximity to the center of the mask. This assumption is also not rigorous enough.\n\nThis is to refer to the following two articles to obtain some priors for point annotation[1][2]. Therefore, the article makes an assumption that the labeling points often present an approximate Gaussian distribution at the center of the object.\n\n> W2: The proposed Symmetry Axis Estimation (SAE) module is not general for all categories, which is effective for PL and HC for DOTA dataset. For most of categories, the peformance is descreased form the Table 7 in Appendix. For other datasets, how to determine whether to use this module.\n\nThank you for bringing up important concerns about how well the Symmetry Axis Estimation (SAE) module works in different situations. Let me address a few points: first, it's crucial to mention that a decrease in performance when using SAE doesn't happen a lot across most categories. Also, we've explained in detail why there's a significant drop in performance for category BD in the additional information section. Additionally, the small decrease in mIoU doesn't strongly affect either the training results (measured by mAP). When deciding whether to use the SAE module, it basicly depends on whether the object is symmetric or not, which needs prior knowledge.\n> W3: Some experimental settings is not clear, such as all models adopts r-50 model with 1x trianing schedul? Some reported results miss the mAP results in some ablation studies, why only report mIoU?\n\nThank you for giving us feedback on how we set up our experiment. I used the ResNet-50 architecture for all our models and trained them with a 1x schedule. I choose to report mIoU instead of mAP because, in my observation, mAP values for each category can vary a lot due to inaccurate label in the same training condition. Using mIoU seemed like a better way to show the differences accurately in our situation.\n\n* [1] Point-to-Box Network for Accurate Object Detection via Single Point Supervision\n* [2] AttentionShift: Iteratively Estimated Part-Based Attention Map for Pointly Supervised Instance Segmentation"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700540750663,
                "cdate": 1700540750663,
                "tmdate": 1700540750663,
                "mdate": 1700540750663,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "0O83pUfhRS",
            "forum": "3LFy3dUS86",
            "replyto": "3LFy3dUS86",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission689/Reviewer_hRnG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission689/Reviewer_hRnG"
            ],
            "content": {
                "summary": {
                    "value": "The first attempt is proposed at training an oriented object detector with point supervision. P2RBox achieves impressive detection accuracy, with the exception of complex categories like BR. P2RBox offers a training paradigm that can be based on any proposal generator, and its generated rotated bounding box annotations can be used to train various strong supervised detectors, making it highly versatile and performance-adaptive without the need for additional parameters."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1. The author ingeniously design the p2rbox to establish a seamless connection between point annotations and rotated boxes through the generation, constraint, and inspection of mask proposals.\n2. This is an interesting attempt to train an oriented object detector with point supervision, reducing dependence on data annotation.\n3. The SAE module was designed based on the spectral theorem of symmetric matrices, utilizing prior information of the object to improve the effectiveness of rotating target detection.\n4. The author introduce a semantic score for the masks, enhancing the quality of the selected mask proposals from the mask generator."
                },
                "weaknesses": {
                    "value": "1. Generator (SAM) is a high-performance segmentation method, and its introduction may not be fair to other methods.\n2. Table 1 should include some recent SOTA methods (such as GWD[1], KLD[2], CGCDet[3], OSKDet[4], KFIoU[5],). Although the proposed p2rbox has significantly improved compared to baseline, there is still a significant gap in its performance compared to supervised methods. Is its performance persuasive enough?\n3. Compared to supervised methods, the method adopts a segmentation mask generator. Will its speed be significantly affected? Please provide an analysis.\n\n[1] Rethinking rotated object detection with gaussian wasserstein distance loss. ICML 2021.\n[2] Learning high-precision bounding box for rotated object detection via kullback-leibler divergence. NeurIPS 2021.\n[3] Learning Oriented Object Detection via Naive Geometric Computing. TNNLS 2023.\n[4] OSKDet: Orientation-sensitive Keypoint Localization for Rotated Object Detection. CVPR 2022\n[5] The KFIoU Loss for Rotated Object Detection. ICLR 2023."
                },
                "questions": {
                    "value": "1. The Constrainer Module selects high-quality masks to create the union mask. Is it better to choose an optimal mask, or to generate the optimal mask through the mask generated by SAM?\n2. By using SAM to segment the target, the quality of the segmentation mask obtained is relatively high. By filtering false positives through the Constrainer Module, higher performance should be achieved. However, compared to supervised methods, the performance difference is still significant. What is the main reason for the performance loss?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission689/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission689/Reviewer_hRnG",
                        "ICLR.cc/2024/Conference/Submission689/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission689/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698677258844,
            "cdate": 1698677258844,
            "tmdate": 1700734560452,
            "mdate": 1700734560452,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GiyKbAK1BR",
                "forum": "3LFy3dUS86",
                "replyto": "0O83pUfhRS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission689/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission689/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> W1: Generator (SAM) is a high-performance segmentation method, and its introduction may not be fair to other methods.\n\nYour observation regarding the high-performance segmentation method SAM is valid, and we appreciate your concern. SAM makes this article not a purely weakly supervised work, and it is unreasonable to compare its performance with weakly supervised methods. Thus, our baselines are also built upon SAM and we directly use SAM with given weights without any change. \n>W2: Table 1 should include some recent SOTA methods (such as GWD[1], KLD[2], CGCDet[3], OSKDet[4], KFIoU[5],). Although the proposed p2rbox has significantly improved compared to baseline, there is still a significant gap in its performance compared to supervised methods. Is its performance persuasive enough?\n\n>Q2: By using SAM to segment the target, the quality of the segmentation mask obtained is relatively high. By filtering false positives through the Constrainer Module, higher performance should be achieved. However, compared to supervised methods, the performance difference is still significant. What is the main reason for the performance loss?\n\nOur baseline have shown the performance of SAM with only one point on DOTA. Moreover, we have conducted experiments to explore the upper limit of P2RB. Selecting the highest IoU Rbox from three different masks and training on RetinaNet yields a performance of 58.94 mAP.In contrast, our achieved result of 55.50 (selected based on our criterion) outperforms the result of 47.91 (selected based on the highest score given by SAM), showcasing substantial improvement under the same settings. The gap mainly from performance of SAM, result of not receiving specialized training in DOTA. In the future, I hope to find some inductive approach to breaking through the upper bound.\n>W3: Compared to supervised methods, the method adopts a segmentation mask generator. Will its speed be significantly affected? Please provide an analysis.\n\nThank you for your feedback. The training speed may be affected a little. For an image with given annotated points, the \u201cget mask\u201d step(generate masks with given annotated points and image) cost within one second. Moreover, this article will eventually use the results of P2RBox to train strong supervised detectors. In practical applications, only strong supervision detectors are involved.\n>Q1: The Constrainer Module selects high-quality masks to create the union mask. Is it better to choose an optimal mask, or to generate the optimal mask through the mask generated by SAM?\n\nYep, through choosing the optimal mask based on the IoU with ground truth, the performance will get to its upper limit. During training, the only information we get is a single point of every object. Our purpose is to select the best performance mask using our design criterion."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700538985558,
                "cdate": 1700538985558,
                "tmdate": 1700538985558,
                "mdate": 1700538985558,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bLkuriUZMg",
                "forum": "3LFy3dUS86",
                "replyto": "0O83pUfhRS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission689/Reviewer_hRnG"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission689/Reviewer_hRnG"
                ],
                "content": {
                    "title": {
                        "value": "Comments after rebuttal"
                    },
                    "comment": {
                        "value": "After carefully reading the author's response and comments from other reviewers, though I think this paper proposes an interesting attempt on oriented object detection, I agree this paper should be further improved. Thus, I would update my rating from \"7: accept\" to \"6: marginally above the acceptance threshold\". Thanks."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700734522659,
                "cdate": 1700734522659,
                "tmdate": 1700734620139,
                "mdate": 1700734620139,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "pHbFwnVuRx",
            "forum": "3LFy3dUS86",
            "replyto": "3LFy3dUS86",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission689/Reviewer_JsqB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission689/Reviewer_JsqB"
            ],
            "content": {
                "summary": {
                    "value": "The P2RBox is a method that connects point annotations and rotated boxes for object detection. It uses mask proposals generated from annotated points, refines the masks with a Constrainer Module, and captures semantic nuances with an Inspector Module. The SAE module facilitates the annotation transformation. The main contribution lies in the design of more loss functions to align spatial positions."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ This paper combines the ability of single point weakly supervised target detection and interactive large model to construct a new process of rotating target detection and obtain convincing results.\n\n+ The mathematical representation in this paper is very clear, showing an understanding of the definition of spatial offset, positive and negative sample extraction, and various evaluation criteria."
                },
                "weaknesses": {
                    "value": "+ To study target detection methods, it is important to design a novel network structure. However, most of the structures in this paper are borrowed from Oriented-RCNN, and there is no discussion on the performance/computational gain of the structure introduced by Oriented-RCNN, so it is difficult to evaluate the effectiveness of the proposed methods.\n\n\n+  Extracting masks from SAM itself can be a labor-intensive task. Additionally, this approach may not scale well to larger datasets beyond just rotating target datasets like DOTA. From the standpoint of SAE, it is unclear if the axis of symmetry problem is statistically characteristic. The explanation regarding whether eigenvalue decomposition represents the statistical characteristics of the symmetry axis problem still needs further clarification.\n\n\n+  Most of the loss functions proposed in this paper are fine-tuned or error-corrected based on spatial relations, without essentially changing the output representation to introduce new loss functions. For example, the centroid offset penalty of the constraint module is not actually a novel contribution point. It is only a penalty item after considering the spatial relationship. It is not recommended to describe it as a separate chapter."
                },
                "questions": {
                    "value": "The part of the SAE discussion is very interesting, but does it ignore the proportion of axisymmetric targets? What is the proportion of axisymmetric targets that cause problems?  How do you consider other special situations, such as circular targets, playgrounds, baseball fields, etc?\n\nThe experimental part of this article is actually weak. This work proposes a lot of loss functions, but the experiments didn't perform the ablation study on these loss functions.  Besides, it lacks visual comparisons with other methods and lacks the analysis of failure cases."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission689/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698685337240,
            "cdate": 1698685337240,
            "tmdate": 1699635996072,
            "mdate": 1699635996072,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tRU02D70X2",
                "forum": "3LFy3dUS86",
                "replyto": "pHbFwnVuRx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission689/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission689/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> W1: To study target detection methods, it is important to design a novel network structure. However, most of the structures in this paper are borrowed from Oriented-RCNN, and there is no discussion on the performance/computational gain of the structure introduced by Oriented-RCNN, so it is difficult to evaluate the effectiveness of the proposed methods.\n\nP2RBox is the first step of two stage method in this article(generate rotated box from point and train with a fully supervised detector). P2RBox is a point-to-mask network to generate rotated box as pseudo label (1st stage). Then the generated pseudo label is used to train a fully supervised detector. The performance of the supervised detector is used to measure the quality of generated pseudo label. The performance of P2RBox combined with different fully supervised detectors will not be compared together as they have different baseline to compare with. The structure of P2RB have little relationship with Oriented-RCNN, and is totally original.\n\n> W2.1: Extracting masks from SAM itself can be a labor-intensive task. Additionally, this approach may not scale well to larger datasets beyond just rotating target datasets like DOTA.\n\nThank you for your feedback. For an image with given annotated points, the \u201cget mask\u201d step(generate masks with given annotated points and image) cost within one second. Moreover, this article will eventually use the results of P2RBox to train strong supervised detectors. In practical applications, only strong supervision detectors are involved.\n\n> W2.2: From the standpoint of SAE, it is unclear if the axis of symmetry problem is statistically characteristic. The explanation regarding whether eigenvalue decomposition represents the statistical characteristic. \n\nSince DOTA is a data set from an overhead perspective, occlusion problems usually do not exist, and the objects are all rigid bodies. Therefore, the problem about the symmetry direction described in the main text only exists in the PL and HC categories, and is prevalent in these two categories.\n> Q1.1: The part of the SAE discussion is very interesting, but does it ignore the proportion of axisymmetric targets?\n\nIn the DOTA dataset, most object categories show symmetry, except for the HARBOR category. DOTA, being a dataset of remote sensing images, is mainly captured from a top-down view, meaning that whether the object is symmetrical or not is only related to its category excluding occlusion situations.\n> Q1.2: What is the proportion of axisymmetric targets that cause problems?\n\nThe ambiguity occurs when the orientation of the minimum bounding rectangle differs from the annotation direction, particularly in the helicopter and aircraft categories. This creates a unique challenge for these categories, unlike the others.\n\n> Q1.3: How do you consider other special situations, such as circular targets, playgrounds, baseball fields, etc?\n\nThe SAE module is versatile across various object shapes, providing two perpendicular directions. While directions for nearly circular objects may not have clear geometric significance, it doesn't seem to affect detection performance because a rectangle represented by any two vertical direction is suitable. For other categories that is symmetric like baseball fields, ship and palygrounds, SAE module\u2019s outputs are same with minimum bounding boxes, showing its direction.\n\n> Q2: The experimental part of this article is actually weak. This work proposes a lot of loss functions, but the experiments didn't perform the ablation study on these loss functions. Besides, it lacks visual comparisons with other methods and lacks the analysis of failure cases.\n\nThank you for your valuable advice. I will add more experiments to ensure the generalizability of the method."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700537457123,
                "cdate": 1700537457123,
                "tmdate": 1700537457123,
                "mdate": 1700537457123,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "E1TsjlKELd",
            "forum": "3LFy3dUS86",
            "replyto": "3LFy3dUS86",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission689/Reviewer_oNSm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission689/Reviewer_oNSm"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a P2RBox network, which leverages point annotations and a mask generator to create mask proposals, followed by filtration through Inspector Module and Constrainer Modulel. Specifically, in order to achieve point-supervised oriented object detection, the paper uses a powerful SAM model to generate initial higher-quality masks, and then refines it through several well-designed designed modules, finally the the generated masks are converted into pseudo rotated bounding box for training the oriented object detector."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This topic is currently new and no one seems to have studied it yet.\n- The issue about the masks generated by SAM, i.e the ambiguity arises between companion scores and the best-performing mask, is interesting and reflects the current problems that may need to be solved when using SAM as a tool.\n- Compared with the baseline, the proposed algorithm significantly improves the performance."
                },
                "weaknesses": {
                    "value": "In my opinion, the most controversial point of the article is the use of SAM.\n- As we all know, SAM is a fully supervised visual model, and its training data over 1 billion masks on 11M licensed and privacy respecting images. Therefore, the method proposed in this paper does not seem to be the so-called weakly supervised oriented object detection, more like zero shot object detection. This is extremely unfair to compare with other truly weakly supervised algorithms.\n- The authors used the mask generated by SAM to generate the rotated bounding box, which seems to be redundant and unnecessary. In my opinion, if a higher quality mask can be produced, there is no need to study other rough object representations, i.e. horizontalrotated/poly bounding box. Therefore, I'm more curious the performance comparison of instance segmentation models trained by masks before and after refinement on commonly used segmentation data sets (i.e. COCO, LVIS). Relevant experiments are given in SAM.\n- As mentioned earlier, the issue of masks generated by SAM found by the authors is interesting, but the proposed solution seems to be engineered and customized. The large number of hyperparameters and thresholds/scores makes me question the generality of the proposed method, and the authors only used one dataset (i.e. DOTA) for verification in the paper, which is not credible.\n- The title is too exaggerated (i.e. single point is all you need). According to the author's experimental results, even if a powerful SAM is used, the performance is still far behind the fully supervised algorithm, e.g. RetinaNet vs. P2RBox (RetinaNet): 67.83% vs. 55.50% (-12.33%).\n- Based on the above analysis, I think the name of the method is more suitable to be called SAM2RBox.\n\nIn general, the method proposed (i.e. SAM based) in the paper does not completely match the topic (i.e. weakly supervised object detection) it is trying to solve, resulting in an unsatisfactory discussion. Moreover, the customized method design and insufficient experiments make me think that this article is not suitable for publication yet, and I temporarily reject it."
                },
                "questions": {
                    "value": "- The article lacks details on how point annotations are generated.\n- The authors need to rethink the story of the proposed method, i.e this is not a simple weakly supervised detection method. It seems more appropriate to call it zero shot or a combination of the two?\n- The writing of the article needs to be better improved, especially the organization of formula symbols.\n- Experiments on more dataset are needed, especially the ablation experiments of hyperparameters. It is better to use datasets from different scenarios and not just remote sensing datasets.\n- Appropriate failure cases need to be discussed to analyze why the current performance is still far below the performance of fully supervised algorithms.\n- For Figure 3, I would rather recommend a visual comparison of other similar methods, e.g. P2RBox-H2RBox and SAM (xxx) in Table 1.\n- Please place the table or figure at the top of each page."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission689/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission689/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission689/Reviewer_oNSm"
                    ]
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission689/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698738821136,
            "cdate": 1698738821136,
            "tmdate": 1699635995999,
            "mdate": 1699635995999,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "IjRXrivHNk",
                "forum": "3LFy3dUS86",
                "replyto": "E1TsjlKELd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission689/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission689/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> W1: As we all know, SAM is a fully supervised visual model, and its training data over 1 billion masks on 11M licensed and privacy respecting images. Therefore, the method proposed in this paper does not seem to be the so-called weakly supervised oriented object detection, more like zero shot object detection. This is extremely unfair to compare with other truly weakly supervised algorithms.\n\nThe use of the SAM model makes it no longer a purely weakly supervised task, but the baseline in the article is also designed based on SAM. I hope this will make you reconsider this article.\n\n> W2: The authors used the mask generated by SAM to generate the rotated bounding box, which seems to be redundant and unnecessary. In my opinion, if a higher quality mask can be produced, there is no need to study other rough object representations, i.e. horizontalrotated/poly bounding box. Therefore, I'm more curious the performance comparison of instance segmentation models trained by masks before and after refinement on commonly used segmentation data sets (i.e. COCO, LVIS). Relevant experiments are given in SAM.\n\nThanks to the reviewers for their feedback. I understand your point of view, that is, if you already have mask-level annotation, you may not need to pay attention to the rotation box-level annotation, because the latter is relatively rough. However, I would like to highlight application-specific aspects of our method for rotating box annotation. In some scenarios, rotating box annotation still has unique advantages, such as in applications that deal with tilted targets, directional detection, or where the target direction needs to be considered. In these cases, rotating box annotations may provide more accurate information rather than just being redundant as mask-level annotations. We will further consider how to explicitly highlight the unique features of our approach and adapt accordingly in the paper. Thank you again for your helpful suggestions, we will take them seriously and make improvements accordingly.\n\n>W3: As mentioned earlier, the issue of masks generated by SAM found by the authors is interesting, but the proposed solution seems to be engineered and customized. The large number of hyperparameters and thresholds/scores makes me question the generality of the proposed method, and the authors only used one dataset (i.e. DOTA) for verification in the paper, which is not credible.\n\nThank you for your feedback. The problem of large number of parameters in this article is indeed a shortcoming. As an author, I will add more experiments to prove that my experimental settings are actually relatively general and not specially designed.\n\n> W4: The title is too exaggerated (i.e. single point is all you need). According to the author's experimental results, even if a powerful SAM is used, the performance is still far behind the fully supervised algorithm, e.g. RetinaNet vs. P2RBox (RetinaNet): 67.83% vs. 55.50% (-12.33%).\n\nThank you for your reply. I'm sorry that the title of this article is indeed exaggerated and I will change it. I hope it does not affect the contribution and innovation of this article. I hope this will make you reconsider this article.\n\n> Q1: The article lacks details on how point annotations are generated.\n\nThe generation of point annotation is not the mean point of this article. In fact, the point annotations are generated through center point with slightly adjustment [1][2] to ensure it always locate on the object even for object of shape L.\n\n> Q5: Appropriate failure cases need to be discussed to analyze why the current performance is still far below the performance of fully supervised algorithms.\n\nThanks for your advice. I will add more analysis experiments in the article, including parameter ablation and results on more data sets. I will also refer to your valuable opinions to add contrast in the visualization part.\n\n* [1] Point-to-Box Network for Accurate Object Detection via Single Point Supervision\n* [2] AttentionShift: Iteratively Estimated Part-Based Attention Map for Pointly Supervised Instance Segmentation"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700534129435,
                "cdate": 1700534129435,
                "tmdate": 1700534129435,
                "mdate": 1700534129435,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1OgADqfrdL",
                "forum": "3LFy3dUS86",
                "replyto": "E1TsjlKELd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission689/Reviewer_oNSm"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission689/Reviewer_oNSm"
                ],
                "content": {
                    "comment": {
                        "value": "After reading the comments of other reviewers, I find that many comments are consistent, and some of the comments are also acknowledged by the authors. Due to the extensive revisions needed to this paper and the lack of substantial feedback from the authors, I think the current version is not suitable for publication. Therefore, I maintain my original rating."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700731775915,
                "cdate": 1700731775915,
                "tmdate": 1700731775915,
                "mdate": 1700731775915,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "dOfPDTxkVb",
            "forum": "3LFy3dUS86",
            "replyto": "3LFy3dUS86",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission689/Reviewer_a8aF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission689/Reviewer_a8aF"
            ],
            "content": {
                "summary": {
                    "value": "Oriented object detection excels in identifying objects of any orientation, while point annotation provides a cost-effective method but lacks size and orientation data. The study introduces the P2RBox network that uses point annotations and a mask generator to produce mask proposals, which are then refined and transformed into rotated box annotations for training advanced detectors. With the integration of the Oriented R-CNN, the P2RBox achieves notable performance, marking the first attempt to train an oriented object detector using point supervision."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.\tUsing points to generate oriented bounding box is interesting.\n2.\tThis paper proposed SAE module to generate the oriented bounding box from masks."
                },
                "weaknesses": {
                    "value": "1.\tThe MIL is widely used in weakly supervised object detection[1] and point-based object detection[2].\n2.\tThis paper used SAM to generate the mask proposals. However, the training of SAM used many complete mask annotations. Therefore, the proposed method still rely on the complete mask supervision, which is not suitable to be considered as a point-supervised method. It is also not consistent with the tile \u201cA SINGLE POINT IS ALL YOU NEED.\u201d\n3.\tThe proposed SAE only significantly outperforms minimum in PL category. In some other cases, it is even lower than minimum.\n4. Can the authors compare the proposed method with point supervised instance segmention[3], in the same supervision setting?\n\nMinor:\n1.\t\u201cIn many cases, the annotated point of an object is typically positioned in close proximity to the center of the mask (Chen et al., 2022). \u201d \u201cclose proximity\u201d is a redundancy. Proximity means closeness, nearness; therefore \u201cclose proximity\u201d means \u201cclose closeness\u201d or \u201cnear nearness.\u201d\n[1] Bilen, Hakan, and Andrea Vedaldi. \"Weakly supervised deep detection networks.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.\n[2] Papadopoulos, Dim P., et al. \"Training object class detectors with click supervision.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017.\n[3] Bowen Cheng, Omkar Parkhi, and Alexander Kirillov. Pointly-supervised instance segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2617\u20132626, 2022"
                },
                "questions": {
                    "value": "See the weakness. My main concern is the usage of SAM, which makes this method not suitable to be considered as a pure point-supervised oriented object detector."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 6,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission689/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698743691331,
            "cdate": 1698743691331,
            "tmdate": 1699635995906,
            "mdate": 1699635995906,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "M2se1ZIbjU",
                "forum": "3LFy3dUS86",
                "replyto": "dOfPDTxkVb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission689/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission689/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> W1: The MIL is widely used in weakly supervised object detection[1] and point-based object detection[2].\n\nA1: While MIL finds extensive application in the field of weak supervision, in specific situation, how to define and design the Bag to provide a valid supervision, guiding the model to optimize in the right direction is the crucial part. The key contribution of this article lies in the design of point bag construction, which differs from previous weak supervision tasks.\n> W2: This paper used SAM to generate the mask proposals. However, the training of SAM used many complete mask annotations. Therefore, the proposed method still rely on the complete mask supervision, which is not suitable to be considered as a point-supervised method. It is also not consistent with the tile \u201cA SINGLE POINT IS ALL YOU NEED.\u201d\n\nA2: Thank you for your thoughtful feedback. Regarding my title, it's really inappropriate. The use of the SAM model makes it no longer a purely weakly supervised task, but the baseline in the article is also designed based on SAM. I hope this will make you reconsider this article.\n> W3: The proposed SAE only significantly outperforms minimum in PL category. In some other cases, it is even lower than minimum.\n\nA3: Thank you for your comment. The purpose of the design of the SAE module is to solve the problem of inconsistent orientations of the minimum circumscribed rectangle of the symmetry target. This problem is currently only observed on aircraft and helicopter categories. For other categories, the applicability of asymmetric targets is not as good as the minimum circumscribed rectangle, such as the SP category (mini 63.5 vs SAE 62.95), but the difference is not significant. For other symmetry categories, such as SH (mini 67.97 vs SAE 68.15), LV (mini 69.22 vs SAE 69.12), BC (mini 44.80 vs SAE 43.80), the overall positive or negative IoU impact is not certain. Through some visualization, when SAM cannot give an accurate mask or the object is occluded, the impact of different decisions (mini or SAE) on IoU becomes unpredictable. To sum up, SAE is only suitable for the generation of directional frames with symmetrical targets as the direction.\n> W4: Can the authors compare the proposed method with point supervised instance segmention[3], in the same supervision setting?\n\nA4: Thank you for your comment. Adding a point-supervised instance segmentation as a reference experiment is indeed a solution that can be used as a baseline. However, the reference you gave is based on multi-point supervision rather than a segmentation work based on single-point supervision. I think the following work may meet the requirements of single-point supervision: AttentionShift: Iteratively Estimated Part-Based Attention Map for Pointly Supervised Instance Segmentation. Since there is no mask-level annotation on DOTA, training this model is not yet possible."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700534078666,
                "cdate": 1700534078666,
                "tmdate": 1700534078666,
                "mdate": 1700534078666,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "b0wOTeQT7i",
                "forum": "3LFy3dUS86",
                "replyto": "dOfPDTxkVb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission689/Reviewer_a8aF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission689/Reviewer_a8aF"
                ],
                "content": {
                    "comment": {
                        "value": "I have read the responses and the comments of other reviewers. I decided to keep my original rating."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission689/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700651443322,
                "cdate": 1700651443322,
                "tmdate": 1700651443322,
                "mdate": 1700651443322,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]