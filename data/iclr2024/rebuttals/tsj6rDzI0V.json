[
    {
        "title": "STAGE Net: Spatio-Temporal Attention-based Graph Encoding for Learning Multi-Agent Interactions in the presence of Hidden Agents"
    },
    {
        "review": {
            "id": "lZAsrnYU0a",
            "forum": "tsj6rDzI0V",
            "replyto": "tsj6rDzI0V",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4647/Reviewer_d9Cc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4647/Reviewer_d9Cc"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed a Spatio-Temporal Graph Attention Network (called STAGE Net) to learn multi-agent dynamics where some agents are completely unobserved (hidden) all the time. The network used the spatiotemporal attention mechanism with neural inter-node messaging to capture high-level behavioral semantics of the multi-agent system. They showed analytical results motivating STAGE Net using spatiotemporal graphs with time anchors to effectively model complex multi-agent interactions with unobserved agents and no prior information about interaction graph topology. They also show the evaluation results on multi-agent simulations with spring and charged dynamics and a motion trajectory dataset. STAGE Net outperformed existing multiagent interaction modeling networks in predicting trajectories of complex multiagent interactions even when having a large number of unobserved agents."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper developed a framework to address the problem about complex multi-agent systems with unobserved agents. \n- The STAGE Net used a dynamic spatiotemporal graph to model structural information across time using observations from visible nodes to recover knowledge representations missing due to unobserved agents.\n- They performed theoretical analyses provided on why the spatio-temporal graph obtained superior representations compared to just using the visible agents' interaction graph.\n- The experimental results showed that the method outperformed several baselines on multiple datasets with spring, charged, and motion trajectory dynamics."
                },
                "weaknesses": {
                    "value": "- There have been many spatiotemporal graph attention networks in previous work (in Google scholar, 56 items), but the proposed method\u2019s name is based on this. Can the authors reconsider the name and clarify the differences from these papers? In other words, the novelty of the methodology in STAGE Net was unclear and in the experiments, some similar networks can be compared (the baselines were old; dNRI was proposed in 2020). \n- In the experiments, the model performances were evaluated extensively on simulated physics datasets and single-agent (and multi-joint with physical constraints) CMU dataset, but real-world multi-agent trajectory datasets can be used to demonstrate applicability.\n- As written in conclusion, there is no analysis provided on how the performance changes for heterogeneous agents with diverse dynamics, but this may not be a fatal problem in this paper (considered as the limitation)."
                },
                "questions": {
                    "value": "- Again, there have been many spatiotemporal graph attention networks in previous work. Can the authors reconsider the name and clarify the differences from these papers? In other words, the novelty of the methodology in STAGE Net was unclear.\n- P3: may be a typo:  \u201cthe is\u201d\n- P4: subscripts of \\mathcal{X} (time interval) in the third and fourth lines of the first paragraph in 2.2.2. Did they correspond with the definition of 2.2.1 and are they correct? Can the t be arbitrary and is the T_h necessary for the former? \n- P4: The definitions of the nonlinear activation function and the concatenation operation after Eq. (2) can be moved to Eq. (1). \n- Experiments (methods): again, some similar (spatiotemporal graph attention) networks can be compared (the baselines were old; dNRI was proposed in 2020).  \n- Experiments (datasets): again, the model performances were evaluated extensively on simulated physics datasets and single-agent (and multi-joint with physical constraints) CMU dataset, but real-world multi-agent trajectory datasets can be used to demonstrate applicability. For example, dNRI paper used an NBA basketball dataset."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4647/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698499433278,
            "cdate": 1698499433278,
            "tmdate": 1699636444906,
            "mdate": 1699636444906,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fU7pPTTBZk",
                "forum": "tsj6rDzI0V",
                "replyto": "lZAsrnYU0a",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Heterogenous Agents"
                    },
                    "comment": {
                        "value": "> As written in conclusion, there is no analysis provided on how the performance changes for heterogeneous agents with diverse dynamics, but this may not be a fatal problem in this paper (considered as the limitation).\n\n\nWe thank the reviewer for highlighting the importance of analyzing the performance of our model in scenarios involving heterogeneous agents with diverse dynamics. In response to this valuable feedback, we have included a new section in our manuscript titled \"Exploring Systems with Heterogeneous Agent Characteristics.\" This section specifically addresses the dynamics of systems comprising agents with varying characteristics, a crucial aspect that was not fully explored in our initial submission.\n\nIn this new section, we investigate the implications of heterogeneity in agent dynamics through a series of experiments set in a spring system. Here, each agent is treated as a heterogeneous entity with distinct and unknown coupling parameters. We explore three distinct scenarios to comprehensively understand the impact of agent heterogeneity:\n\n1. **Visible Heterogeneity, Hidden Homogeneity**: In this scenario, only the visible agents exhibit heterogeneity in their dynamics, while the hidden agents maintain homogeneous characteristics.\n\n2. **Universal Heterogeneity**: This scenario considers every agent in the system, both visible and hidden, as heterogeneous. Each agent's coupling parameters are randomly assigned, introducing a high degree of variability in the system.\n\n3. **Hidden Heterogeneity, Visible Homogeneity**: This setup is the inverse of the first scenario, where only the hidden agents are heterogeneous, while the visible agents are homogeneous.\n\nFor each of these scenarios, we define three sets of coupling parameters to represent different levels of heterogeneity among agents. During our simulations, each heterogeneous agent's coupling parameter is randomly selected from these sets, introducing a controlled yet significant level of complexity to the system dynamics.\n\nOur empirical results for prediction error, presented in Table below demonstrate that baseline models struggle to accurately capture the intricate dynamics introduced by agent heterogeneity. In contrast, our proposed model shows a significantly better performance in handling these complex scenarios, as evidenced by lower error rates and more accurate predictions.\n\n*Performance MSE Metrics for Different Models for Heterogeneous Agents*\n| **Number of Het. Types** | **Stage Net**       | **DNRI**           | **FC**            | **SingleRNN**         | **JointRNN**        |\n|:------------------------:|:-------------------:|:------------------:|:-----------------:|:---------------------:|:-------------------:|\n| 3                        | 0.0104 \u00b1 0.0096     | 7.12 \u00b1 0.4076      | 2.28 \u00b1 0.39       | 2.92 \u00b1 0.26           | 3.55 \u00b1 0.31         |\n| 4                        | 0.0081 \u00b1 0.0077     | 7.16 \u00b1 0.38        | 2.26 \u00b1 0.377      | 2.91 \u00b1 0.2639         | 3.53 \u00b1 0.288        |\n| 5                        | 0.0089 \u00b1 0.0079     | 7.27 \u00b1 0.37        | 2.28 \u00b1 0.377      | 2.9 \u00b1 0.2454          | 3.5 \u00b1 0.27          |\n\n\nBy incorporating this analysis into our manuscript, we aim to address the previously identified limitation and provide a more comprehensive understanding of our model's capabilities in diverse and complex multi-agent systems.\n**Refer to Section B.7 of Supp for more details and plots**"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4647/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700718619984,
                "cdate": 1700718619984,
                "tmdate": 1700718619984,
                "mdate": 1700718619984,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hw9oXelqTk",
                "forum": "tsj6rDzI0V",
                "replyto": "lZAsrnYU0a",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Real World Datasets"
                    },
                    "comment": {
                        "value": "> In the experiments, the model performances were evaluated extensively on simulated physics datasets and single-agent (and multi-joint with physical constraints) CMU dataset, but real-world multi-agent trajectory datasets can be used to demonstrate applicability.\n\nThank you for your comment. We have addressed this concern by incorporating two real-world datasets to showcase the applicability of our approach:\n\na. **CMU Motion Mocap dataset**: We leveraged the Carnegie Mellon University (CMU) Motion Capture dataset, a comprehensive collection of human motion capture data. This dataset encompasses a wide range of activities, including walking, running, and dancing, recorded from diverse subjects. Specifically, we focused on Subject 35 and their walking trajectories, comprising 8,063 frames, each documenting 31 specific joints. Each joint is treated as an agent connected to others through linkages. The dataset attributes, encompassing position and velocity, were normalized to have a maximum absolute value of 1. Our models were trained on 30-timestep sequences and evaluated on sequences of the same length. The table below presents prediction results for motion datasets with different sets of joints randomly hidden during training. Our network consistently outperforms baseline models in this context.\n\n| Unobserved Joints | 0    | 5    | 10   | 15   | 20   |\n|-------------------|------|------|------|------|------|\n| MultiBlock RNN    | 0.17 | 0.18 | 0.16 | 0.18 | 0.13 |\n| FC Graph          | 0.14 | 0.13 | 0.19 | 0.16 | 0.16 |\n| JointRNN          | 0.30 | 0.34 | 0.28 | 0.23 | 0.23 |\n| D-NRI             | 0.16 | 0.30 | 0.17 | 0.30 | 0.20 |\n| STAGE Net (ours)  | 0.11 | 0.13 | 0.11 | 0.10 | 0.13 |\n\n\nb. **Basketball Dataset**: Our second real-world dataset involves detailed 2D position and velocity trajectories of the offensive team, consisting of 5 players. Trajectories were initially divided into 49 frames, capturing approximately 8 seconds of gameplay. During training, models were trained on the first 30 frames from the training trajectories. For evaluation, models were presented with input data comprising sampled trajectories from the initial 30 frames, with sampling adjusted based on temporal sparsity. For example, with 10% temporal sparsity, we selected 27 observations from the initial 30 for each player, and the models predicted the subsequent 19 frames. The table below displays the results of the basketball dataset, where only 50% of the agents are observable. Introducing temporal sparsity through random sparse sampling of encoder observations, our observations indicate that STAGE Net outperforms baseline models in scenarios involving concealed agents and limited temporal observability.\n\n| \\% Temporal Observability | STAGE Net | DNRI | FC  | Joint RNN | Single RNN |\n|---------------------------|-----------|------|-----|-----------|------------|\n| 33%                       | 1.40 \u00b1 2.45 | 2.60 \u00b1 1.79 | 2.67 \u00b1 1.67 | 1.94 \u00b1 1.51 | 1.86 \u00b1 1.47 |\n| 50%                       | 1.36 \u00b1 2.39 | 2.35 \u00b1 1.57 | 2.45 \u00b1 1.90 | 1.62 \u00b1 1.29 | 1.55 \u00b1 1.26 |\n| 66%                       | 1.37 \u00b1 2.40 | 2.00 \u00b1 1.33 | 2.21 \u00b1 1.25 | 1.29 \u00b1 1.03 | 1.22 \u00b1 1.00 |\n| 100%                      | 1.32 \u00b1 2.33 | 2.069 \u00b1 1.23 | 1.72 \u00b1 0.93 | 1.022 \u00b1 7.6 | 0.98 \u00b1 0.77 |\nThese real-world datasets serve to validate the effectiveness of our approach in practical scenarios."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4647/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700718682822,
                "cdate": 1700718682822,
                "tmdate": 1700718682822,
                "mdate": 1700718682822,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4bdrsJwAf5",
                "forum": "tsj6rDzI0V",
                "replyto": "lZAsrnYU0a",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Spatiotemporal graph attention networks"
                    },
                    "comment": {
                        "value": "> Again, there have been many spatiotemporal graph attention networks in previous work. Can the authors reconsider the name and clarify the differences from these papers? In other words, the novelty of the methodology in STAGE Net was unclear.\n\nWe thank the reviewer for their insightful comments. Our response aims to clarify the distinctiveness of our methodology and its novelty in comparison to existing works:\n\n1.  **Problem Statement**: Our study uniquely addresses a scenario characterized by inherently unobservable agents within multi-agent systems, a challenge not commonly tackled in existing research. Most prior studies assume complete observability of agents, either with sparse or continuous sampling. Our work explores a more complex scenario where certain agents remain perpetually unobservable. This specificity sets our research apart, as it deals with a system having fewer independent degrees of freedom than its intrinsic dimension.\n   \n   \n   | **Scenario** | **Description of Problem** | **References** |\n   |--------------|----------------------------|----------------|\n| Complete observability with known interaction topology | Multi-agent systems where all agents are observable at all times, with a known interaction topology, facilitating the modeling process. | Watters et al., 2017 |\n| Complete observability with unknown interaction topology | All agents are observable at all times; however, the interaction topology is not predefined and must be inferred from observational data. | Alahi et al., 2016; Banijamali, 2022; Graber et al; Kips et al. 2018; Alet et al. 2019; Steenkiste et al 2018, Santoro et. al. 2017 |\n| Complete observability with Irregular sampling of observations or temporally sparse data | All agents are observable but the observation events are sporadic or irregular, leading to temporal data sparsity. | Rubanova et al., 2019; Zhu et al., 2021; Huang et al. 2020; Marisca et al., 2022; Sun et al., 2019 |\n| Only few agents observable with sparse temporal sampling and unknown interaction topology | Not all agents are observable, with some never being observed, coupled with sparse temporal data collection. | (Ours) |\n\n\n2. **Spatio-Temporal Graph**: While it is true that methods like the Dynamics Neural Relational Inference (dNRI) also utilize spatio-temporal graphs, our approach distinctly integrates the temporal dimension within the spatial domain. In our method, we construct a graph encompassing both spatial and temporal edges for each timestep. Each agent's observation is represented as a temporal node, with temporal relations established among agents. These nodes feature unique vectors encapsulating spatial location and velocity, further enriched by time anchors that reflect the chronological context of each observation. Our edge construction process is based on the temporal disparity between nodes, with edges formulated within a predefined temporal threshold. This approach leads to the formation of a comprehensive spatiotemporal graph, denoted as $\\mathcal{G}$, on which we apply a graph neural network. This network is instrumental in approximating the initial latent posterior distribution, effectively facilitating long-term predictions in partially observable systems. This methodology differs significantly from the typical approach of processing spatial information through an attention network (like in papers cited below) and then applying temporal modeling via LSTM or similar frameworks. Our integrated spatio-temporal representation enables a more nuanced understanding of agent interactions over time, setting our method apart from existing techniques. In conclusion, our paper not only addresses a less-explored problem in the realm of multi-agent systems but also introduces a novel approach in constructing and utilizing spatiotemporal graphs. These aspects underscore the originality and contribution of our work to the field.\n\n*[Spatial and Temporal Attention Networks]*\n\na.  Spatial-Temporal Graph Attention Networks: A Deep Learning Approach for Traffic Forecasting\n\nb. ST-GRAT: A Novel Spatio-temporal Graph Attention Network for Accurately Forecasting Dynamically Changing Road Speed\n\nc. Dynamic Neural Relational Inference"
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4647/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700718789923,
                "cdate": 1700718789923,
                "tmdate": 1700719405524,
                "mdate": 1700719405524,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rSVqRMii6p",
                "forum": "tsj6rDzI0V",
                "replyto": "lZAsrnYU0a",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Typos and other formatting changes"
                    },
                    "comment": {
                        "value": "> P3: may be a typo: \u201cthe is\u201d\n\nThank you for pointing out this potential typo. We have carefully reviewed the mentioned section and corrected the typo. Ensuring clarity and accuracy in our manuscript is paramount, and we appreciate your attention to detail.\n\n\n> P4: subscripts of \\mathcal{X} (time interval) in the third and fourth lines of the first paragraph in 2.2.2. Did they correspond with the definition of 2.2.1 and are they correct? Can the t be arbitrary and is the T_h necessary for the former?\n\nYou raised an important question about the consistency of the subscripts of $\\(\\mathcal{X}\\)$ in section 2.2.2 with the definitions provided in 2.2.1. We have re-examined these sections and confirm that the subscripts are indeed consistent with our definitions. Specifically, the subscript $\\(t\\)$ in section 2.2.2 refers to an arbitrary time step within the interval under consideration, aligning with the usage in section 2.2.1. Regarding the necessity of $T_h$, it represents the historical time interval relevant to the context and is essential for defining the scope of our analysis within the time series data. We believe this clarification maintains the integrity and consistency of our model's formulation.\n\n\n> P4: The definitions of the nonlinear activation function and the concatenation operation after Eq. (2) can be moved to Eq. (1).\n\n  We appreciate your suggestion to move the definitions of the nonlinear activation function and the concatenation operation from the text following Eq. (2) to the vicinity of Eq. (1). This adjustment will indeed make the presentation more coherent and reader-friendly. We have revised our manuscript accordingly, ensuring that these definitions are now placed in a more appropriate context, directly alongside Eq. (1), for clearer understanding and flow."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4647/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700719558434,
                "cdate": 1700719558434,
                "tmdate": 1700719558434,
                "mdate": 1700719558434,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "gC1N7dFOaK",
            "forum": "tsj6rDzI0V",
            "replyto": "tsj6rDzI0V",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4647/Reviewer_iVtG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4647/Reviewer_iVtG"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses the task of multi-agent trajectory prediction in a system with a fixed number of total agents, where a consistent ratio of agents remains hidden throughout the entire prediction process. \n\nThe paper proposes a sequential attention-based generative model that learns latent representations of observable agents with a learned temporal graph. It provides an analytical analysis of the advantages of learning representations through constructing a temporal sub-graph over a spatial sub-graph. \n\nThis work conducts experiments on three datasets where the hidden agents are simulated by randomly hiding M out of the total N agents. It compares with two types of prior methods. One deals with the multi-agent trajectory prediction with full observability on the agents' topological graph. Another one is a latent RNN model. The proposed method outperforms the others on the three datasets with simulated hidden agents."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "This paper presents an interesting and challenging task, and it provides both analytical analysis and comprehensive empirical experiments."
                },
                "weaknesses": {
                    "value": "1. The paper introduces a scenario where a fixed number of agents are constantly hidden, presenting a challenging and intriguing task. However, my concern lies in its constrained nature; it seems to be a specific case within a broader context where agents may not be observable throughout specific horizons (rather than constantly unobservable as in this paper). This may limit the method's real-world applicability, potentially diminishing its overall impact.\n2. The paper lacks any discussion about its connection to prior research on multi-agent trajectory prediction under partial observation, e.g., Stochastic Prediction of Multi-Agent Interactions from Partial Observations ICLR 2019. I think this paper has strong relevance to prior works on multi-agent trajectory prediction under partial observation.\n3. The method of constructing a spatiotemporal graph for multi-agent trajectory prediction seems not novel."
                },
                "questions": {
                    "value": "1. The hidden agents in the three datasets are all simulated; can the authors provide experiments on datasets where the hidden agents are not simulated or provide real-world examples where systems of a fixed number of hidden agents? The paper has already provided motivating examples where agents are partially observable on page 1 and page 23, but those are not the scenarios under the problem definition in sec 2.1. \n2. confusing notations in sec. 2.2.4 on page 4, \"M is the total number of observed agents.\" which conflicts with the definition in sec 2.1 -where it says, \"N agents could be observed.\" \n3. confusing colorization in Figure 1: the color for latent states z_{1}^{0}, z_{2}^{0}, z_{3}^{0} does not match with the observable nodes, and the color of z_{2}^{0}  is the same as one of the unobservable nodes o_{3}."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4647/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4647/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4647/Reviewer_iVtG"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4647/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698626015110,
            "cdate": 1698626015110,
            "tmdate": 1699636444798,
            "mdate": 1699636444798,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YFtbiLpY1o",
                "forum": "tsj6rDzI0V",
                "replyto": "gC1N7dFOaK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Constrained nature of problem statement | Comparisons with works with agent observable throughout specific horizons"
                    },
                    "comment": {
                        "value": "> The paper introduces a scenario where a fixed number of agents are constantly hidden, presenting a challenging and intriguing task. However, my concern lies in its constrained nature; it seems to be a specific case within a broader context where agents may not be observable throughout specific horizons (rather than constantly unobservable as in this paper). This may limit the method's real-world applicability, potentially diminishing its overall impact.\n\nWe appreciate the reviewer's insight into the nature of our study focusing on the scenario with a fixed number of constantly hidden agents. To provide clarity, we have systematically classified various multi-agent observation scenarios, as outlined below, to position our work within the broader research domain:\n\n| **Scenario** | **Description of Problem** | **References** |\n|--------------|----------------------------|----------------|\n| Complete observability with known interaction topology | Multi-agent systems where all agents are observable at all times, with a known interaction topology, facilitating the modeling process. | Watters et al., 2017 |\n| Complete observability with unknown interaction topology | All agents are observable at all times; however, the interaction topology is not predefined and must be inferred from observational data. | Alahi et al., 2016; Banijamali, 2022; Graber et al; Kips et al. 2018; Alet et al. 2019; Steenkiste et al 2018, Santoro et. al. 2017 |\n| Complete observability with Irregular sampling of observations or temporally sparse data | All agents are observable but the observation events are sporadic or irregular, leading to temporal data sparsity. | Rubanova et al., 2019; Zhu et al., 2021; Huang et al. 2020; Marisca et al., 2022; Sun et al., 2019 |\n| Only few agents observable with sparse temporal sampling and unknown interaction topology | Not all agents are observable, with some never being observed, coupled with sparse temporal data collection. | (Ours) |\n\nIn our paper, we delve into a particularly challenging scenario, dealing with unobservable agents due to inherent sensing and observation constraints, leading to a system with fewer independent degrees of freedom than its intrinsic dimension. This problem, while seemingly specific, represents a critical and complex challenge within the realm of multi-agent systems. Most prior research in this domain, as summarized in our classification, assumes full observability of agents, whether the sampling is sparse or continuous. Our work, however, tackles a more intricate scenario where some agents are inherently unobservable. \n\nWhile we acknowledge that our  study focus on constantly unobservable agents, our method could still handle agents that  may not be observable throughout specific horizons due to inherent design of the network. We present the deatiled study for this case in our paper in Supp Section B.5 in our paper (Results also summarized in the next comment).  In conclusion, our work extends the realm of multi-agent trajectory prediction under partial observation by tackling the additional complexity of completely unobservable agents. This aspect makes our problem more challenging compared to the scenarios assumed in prior works, including the one presented in the ICLR 2019 paper. Our comprehensive discussion and the added ablation study in the revised manuscript aim to highlight these differences and the advancements our research contributes to this field.\n\n\n***[Citations]***\n\n  \n\n- Watters et al., 2017, Social LSTM: Human Trajectory Prediction in Crowded Spaces\n\n- Alahi et al., 2016, Social LSTM:\nHuman Trajectory Prediction in Crowded Spaces\n\n- Banijamali, 2022, Neural Relational Inference with Node-Specific Information\n\n- Marisca et al. Learning to Reconstruct Missing Data from Spatiotemporal Graphs with Sparse Observations\n\n- Sunet al 2019, Stochastic Prediction of Multi-Agent Interactions from Partial Observations\n\n- Steenkiste et al 2018, Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions\n\n- Graber et al. Dynamic Neural Relational Inference\n\n- Kips et al. 2018 Neural Relational Inference for Interacting Systems\n - Huang et al. 2020, Learning Continuous System Dynamics from Irregularly-Sampled Partial Observations\n\n- Rubanov at al. 2019, Latent ODEs for Irregularly-Sampled Time Series\n\n- Zhu et al. Networked Time Series Prediction with Incomplete Data\n\n- Alet et al. 2019, Neural Relational Inference with Fast Modular Meta-learning\n\n- Santoro et al. 2017, A simple neural network module for relational reasoning\n\n-------"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4647/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700717401937,
                "cdate": 1700717401937,
                "tmdate": 1700717480755,
                "mdate": 1700717480755,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1VTLxj13PE",
                "forum": "tsj6rDzI0V",
                "replyto": "gC1N7dFOaK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Comparisons with works with agent observable throughout specific horizons | ICLR 2019 paper"
                    },
                    "comment": {
                        "value": "> The paper lacks any discussion about its connection to prior research on multi-agent trajectory prediction under partial observation, e.g., Stochastic Prediction of Multi-Agent Interactions from Partial Observations ICLR 2019. I think this paper has strong relevance to prior works on multi-agent trajectory prediction under partial observation.\n\n**We have added the discussion and relation of this work to our main paper with an ablation study B.5 in the appendix.**\n\nThank you for pointing out the importance of discussing the connection of our work to prior research on multi-agent trajectory prediction under partial observation, specifically referencing the ICLR 2019 paper \"Stochastic Prediction of Multi-Agent Interactions from Partial Observations.\" We acknowledge this oversight and have incorporated a comprehensive discussion and comparison in our revised manuscript, including an ablation study (Section B.5 in the appendix) that closely examines the relationship and distinctions between these works.\n\n\nThe ICLR 2019 paper presents a novel approach that combines a learned dynamics model with a vision model for forecasting multi-agent interactions, assuming a known number of agents with partial observation availability. This method leverages a graph-structured variational recurrent neural network (Graph-VRNN) and demonstrates superior performance on sports dataset-based benchmarks. It operates under the premise of complete but irregularly sampled observations, where the agents' trajectories are accessible, albeit sporadically.\n\nIn contrast, our work addresses a more complex scenario where certain agents are entirely unobservable due to inherent sensing limitations, leading to a system with fewer independent degrees of freedom than its intrinsic dimension. This difference in observable system dynamics presents unique challenges, as summarized in our systematic classification of observation scenarios in multi-agent systems."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4647/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700717760263,
                "cdate": 1700717760263,
                "tmdate": 1700717760263,
                "mdate": 1700717760263,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SXmhg4qB55",
                "forum": "tsj6rDzI0V",
                "replyto": "gC1N7dFOaK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Spatiotemporal graph for multi-agent trajectory prediction"
                    },
                    "comment": {
                        "value": "> The method of constructing a spatiotemporal graph for multi-agent trajectory prediction seems not novel.\n\nThank you for your query regarding the construction of the spatiotemporal graph in our multi-agent trajectory prediction method. We appreciate the opportunity to clarify aspects of our approach:\n\n\n1.  **Multiagent prediction framework for system with Hidden agents**: Our current focus on the scenario of constantly hidden agents serves as foundational research that addresses a critical gap in the understanding of multi-agent systems under extreme conditions of partial observability. Our work extends the realm of multi-agent trajectory prediction under partial observation by tackling the additional complexity of completely unobservable agents. This aspect makes our problem more challenging compared to the scenarios assumed in prior works, including the one presented in the ICLR 2019 paper.\n\n  \n\n2.  **Dynamics SpatioTemporal Graph with Temporal Anchors**: The core component of STAGE is its **dynamics temporal graph**, which leverages observed data from the sub-graph to propagate structural temporal information. Unlike approaches that use encoders for temporal feature extraction (Watters et al., 2017), our method constructs a temporal graph directly from agents\u2019 observations. For each i-th agent's observation at time t, a temporal node with a feature vector combining spatial location (`xi,t`) and velocity (`vi,t`) is created. These nodes are **anchored in time**, `ai = ti - t0,i`, capturing chronological information and defining temporal relationships within the graph. Edges are formed based on an edge matrix indicating temporal disparities between nodes, with edges established and characterized by time differences if within a certain threshold. This structured temporal graph, denoted as `G`, effectively represents the nuanced temporal dynamics of the agents, with the novelty lying in the use of time anchors to encapsulate temporal positions and relationships.\n\n3.  **Analytical Motivation for the framework**:  In Section 2.2.6 in the main paper, we provide the analytical motivation that constructing a spatiotemporal graph from visible nodes in a multi-agent system yields a superior representation of the entire system, subsequently enhancing the performance of visible agent trajectory prediction. Specifically, we prove that the spatiotemporal graph used in our work is a better covariance estimator of the dynamics of full graph with all the hidden and visible nodes than the graph with only visible nodes. This enhanced representation improves the performance"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4647/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700718017426,
                "cdate": 1700718017426,
                "tmdate": 1700718017426,
                "mdate": 1700718017426,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3kwtwuU0es",
                "forum": "tsj6rDzI0V",
                "replyto": "gC1N7dFOaK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Real World Datasets"
                    },
                    "comment": {
                        "value": "Thank you for your comment. We have addressed this concern by incorporating two real-world datasets to showcase the applicability of our approach:\n\na. **CMU Motion Mocap dataset**: We leveraged the Carnegie Mellon University (CMU) Motion Capture dataset, a comprehensive collection of human motion capture data. This dataset encompasses a wide range of activities, including walking, running, and dancing, recorded from diverse subjects. Specifically, we focused on Subject 35 and their walking trajectories, comprising 8,063 frames, each documenting 31 specific joints. Each joint is treated as an agent connected to others through linkages. The dataset attributes, encompassing position and velocity, were normalized to have a maximum absolute value of 1. Our models were trained on 30-timestep sequences and evaluated on sequences of the same length. The table below presents prediction results for motion datasets with different sets of joints randomly hidden during training. Our network consistently outperforms baseline models in this context.\n\n| Unobserved Joints | 0    | 5    | 10   | 15   | 20   |\n|-------------------|------|------|------|------|------|\n| MultiBlock RNN    | 0.17 | 0.18 | 0.16 | 0.18 | 0.13 |\n| FC Graph          | 0.14 | 0.13 | 0.19 | 0.16 | 0.16 |\n| JointRNN          | 0.30 | 0.34 | 0.28 | 0.23 | 0.23 |\n| D-NRI             | 0.16 | 0.30 | 0.17 | 0.30 | 0.20 |\n| STAGE Net (ours)  | 0.11 | 0.13 | 0.11 | 0.10 | 0.13 |\n\n\nb. **Basketball Dataset**: Our second real-world dataset involves detailed 2D position and velocity trajectories of the offensive team, consisting of 5 players. Trajectories were initially divided into 49 frames, capturing approximately 8 seconds of gameplay. During training, models were trained on the first 30 frames from the training trajectories. For evaluation, models were presented with input data comprising sampled trajectories from the initial 30 frames, with sampling adjusted based on temporal sparsity. For example, with 10% temporal sparsity, we selected 27 observations from the initial 30 for each player, and the models predicted the subsequent 19 frames. The table below displays the results of the basketball dataset, where only 50% of the agents are observable. Introducing temporal sparsity through random sparse sampling of encoder observations, our observations indicate that STAGE Net outperforms baseline models in scenarios involving concealed agents and limited temporal observability.\n\n| \\% Temporal Observability | STAGE Net | DNRI | FC  | Joint RNN | Single RNN |\n|---------------------------|-----------|------|-----|-----------|------------|\n| 33%   | 1.40 \u00b1 2.45 | 2.60 \u00b1 1.79 | 2.67 \u00b1 1.67 | 1.94 \u00b1 1.51 | 1.86 \u00b1 1.47 |\n| 50%   | 1.36 \u00b1 2.39 | 2.35 \u00b1 1.57 | 2.45 \u00b1 1.90 | 1.62 \u00b1 1.29 | 1.55 \u00b1 1.26 |\n| 66%   | 1.37 \u00b1 2.40 | 2.00 \u00b1 1.33 | 2.21 \u00b1 1.25 | 1.29 \u00b1 1.03 | 1.22 \u00b1 1.00 |\n| 100% | 1.32 \u00b1 2.33 | 2.069 \u00b1 1.23 | 1.72 \u00b1 0.93 | 1.022 \u00b1 7.6 | 0.98 \u00b1 0.77 |\nThese real-world datasets serve to validate the effectiveness of our approach in practical scenarios."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4647/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700718133495,
                "cdate": 1700718133495,
                "tmdate": 1700718176679,
                "mdate": 1700718176679,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5gQ7cbYC26",
                "forum": "tsj6rDzI0V",
                "replyto": "gC1N7dFOaK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Notations"
                    },
                    "comment": {
                        "value": "> confusing notations in sec. 2.2.4 on page 4, \"M is the total number of observed agents.\" which conflicts with the definition in sec 2.1 -where it says, \"N agents could be observed.\"\n\nThank you for pointing out the inconsistency in the notations used in sections 2.2.4 and 2.1. We have revised the document for clarity. Now, both sections consistently use 'N' to denote the number of agents that can be observed and 'M' to represent the total number of agents in the system. This correction should resolve the confusion and provide better coherence in our notation throughout the document.\n\n> confusing colorization in Figure 1: the color for latent states z_{1}^{0}, z_{2}^{0}, z_{3}^{0} does not match with the observable nodes, and the color of z_{2}^{0} is the same as one of the unobservable nodes o_{3}.\n\nThank you for your observation regarding the colorization in Figure 1 of our document. We have carefully reviewed the figure and addressed the issue you highlighted. The colors for the latent states $ z_{1}^{0}, z_{2}^{0} , z_{3}^{0}$ have been adjusted to accurately match with the observable nodes."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4647/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700718478335,
                "cdate": 1700718478335,
                "tmdate": 1700718478335,
                "mdate": 1700718478335,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "MLCHXCyLIS",
            "forum": "tsj6rDzI0V",
            "replyto": "tsj6rDzI0V",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4647/Reviewer_A4XG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4647/Reviewer_A4XG"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces StageNet, a machine learning model designed to predict the trajectory of multi-agent systems with unknown (hidden) dynamics and in the presence of unknown (hidden) agents. StageNet leverages a spatiotemporal attention mechanism with neural inter-node messaging to capture high-level behavioral semantics of the multi-agent system. The proposed framework utilizes a dynamic spatiotemporal graph attention mechanism, specifically tailored for systems where only a subset of agents is observable at any given time. The paper demonstrates the effectiveness of StageNet in learning meaningful representations for multi-agent systems, using three datasets with different dynamics and a real-world dataset of motion trajectories experiencing sensor failures."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper provides analytical motivation for constructing a spatiotemporal graph from visible nodes in a multi-agent system, yielding a superior representation of the entire system.\n2. StageNet presents a novel approach to predicting the trajectory of multi-agent systems with unknown dynamics and hidden agents, which is a complement to the research field of multi-agent trajectory prediction, providing new insights and methodologies for future studies.\n3. The paper is clearly written and easy to understand, making it accessible to a wide audience."
                },
                "weaknesses": {
                    "value": "1. Could you provide more insight into the scalability and computational efficiency of StageNet in more complex and large-scale tasks?\n2. Discussing potential issues related to the robustness of the model in the presence of noisy or incomplete data could further strengthen the paper.\n3. One potential improvement to the paper could be to visualize the dynamic spatial-relational patterns in the simulated datasets. This could give a more intuitive understanding of the underlying dynamics and interactions."
                },
                "questions": {
                    "value": "See weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4647/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4647/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4647/Reviewer_A4XG"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4647/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698843975197,
            "cdate": 1698843975197,
            "tmdate": 1699636444706,
            "mdate": 1699636444706,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SVKWd3BYGt",
                "forum": "tsj6rDzI0V",
                "replyto": "MLCHXCyLIS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Scalability and computational efficiency of StageNet"
                    },
                    "comment": {
                        "value": ">Could you provide more insight into the scalability and computational efficiency of StageNet in more complex and large-scale tasks? \n\nThe encoder in StageNet is predominantly responsible for computational demands. Let's consider a multi-agent system with $M$  agents, where only $N$ agents are observable at any given time, and the remaining $(M-N)$ agents are hidden. Given a spatiotemporal observation sequence of these observable agents across $T$ timesteps, the encoder constructs a dynamic spatiotemporal graph to model the system's interactions. This graph consists of approximately $O(KM)$ nodes and $O((E+K)M^2)$ edges, where $K$ represents the average number of observations per agent, \\(M\\) the total number of observed agents, and $E$ the average number of spatial edges in the interaction graph. Thus, the computational demand of the encoder scales quadratically with the observation duration for a given graph structure.\n\nEmpirical evidence of the system's computational complexity is provided in our paper in Section A.4 of supp. We examine a spring system with 10 agents and varied interaction topologies. Figure 8A in Appendix A.4 shows how the average number of temporal edges correlates with the number of visible edges in the interaction graph. As the number of visible agents increases, so does the edge count in the temporal graph, scaling at $O((E + M)K^2$. Figure 8b further illustrates the GFLOPs of StageNet's encoder relative to the increase in visible agents.\n\n\n[Representation of Encoder GFLOPS against the  Number of Visible Agents.](https://anonymous.4open.science/api/repo/ICRL_Rebuttal2023-440A/file/encoder_gflops%20%282%29.png)\n\n[A comparative representation of the average visible edges and average temporal graph  edges against the number of visible agents](https://anonymous.4open.science/api/repo/ICRL_Rebuttal2023-440A/file/average_edges_log_scale%20%281%29.png)\n\n\nOur model manages large systems with minimal computational cost. However, further reductions in computational complexity are achievable by optimally selecting the graph representation. Below are the two primary methods:\n\n1. **Optimal Selection of Observation Time Period**: Our analysis demonstrates that sparser attention maps in temporal context feature studies allow for reduced observation times without sacrificing accuracy. This directly translates to enhanced computational efficiency, with costs scaling as \\(O((E+M)K^2)\\). By adjusting the observation period based on the sparsity of attention maps, we can significantly lower computational demands while preserving the integrity of model predictions. This approach is especially beneficial in cases where longer observation periods do not proportionately improve accuracy. As detailed in Section B.2 of our supplementary materials, the relationship between the ratio of hidden agents and attention map density underscores the potential for computational optimization. In essence, by tailoring observation periods to the sparsity of the attention maps, we can achieve a more efficient balance between computational load and predictive accuracy.\n  \n\n2.  **Sparse Temporal Graph Representation via Edge Pruning/Dropout**: \nWe use dropout to randomly eliminate edges in the temporal graph, striking a balance between sparsity and accuracy, and preventing overfitting. Specifically, we nullify selected edges in the temporal graph during training iterations to achieve desired sparsity levels. This strategy lowers the graph's complexity, thus decreasing computational load, crucial for large-scale temporal graphs with extensive edges. Furthermore, we propose integrating adaptive edge pruning, based on techniques from recent studies (Li et al., 2023; Wang et al., 2022), which use unsupervised learning to dynamically adjust sparsity in response to graph structure changes. This ensures only essential edges are retained, optimizing both computational efficiency and model accuracy."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4647/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700714013059,
                "cdate": 1700714013059,
                "tmdate": 1700714013059,
                "mdate": 1700714013059,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iLfS06bOYV",
                "forum": "tsj6rDzI0V",
                "replyto": "MLCHXCyLIS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Robustness of the model in the presence of noisy or incomplete data"
                    },
                    "comment": {
                        "value": "> Discussing potential issues related to the robustness of the model in the presence of noisy or incomplete data could further strengthen the paper.\n\n\n### A. Noisy Data\n\n  \n\nIn response to the reviewer's comment on the robustness of our model, we conduct additional experiments to evaluate StageNet's performance against noisy observations and incomplete data. We train our model on noise-free data and evaluated it on datasets corrupted with Gaussian noise of mean 0. Prior to adding noise, the data was normalized, and the noise is introduced with various standard deviations ranging from 0.001 to 0.1. The results, presented in the tables below, demonstrate StageNet's robustness across different noise levels and percentages of unobservable data. \nOur analysis shows that StageNet consistently outperforms other baseline models under varying noise conditions, indicating its strong capability to handle noisy data. The detailed plots are also included in the updated paper in section B.5 of supp.\n\n  \n\n\n\n**Table for System with 50% Unobservable Agents for various noise levels**\n\n| Noise ($\\sigma$) | StageNet (mean \u00b1 std) | DNRI (mean \u00b1 std) | FC Baseline (mean \u00b1 std) | Single RNN (mean \u00b1 std) | Joint RNN (mean \u00b1 std) |\n|-------|-----------------------|-------------------|--------------------------|-------------------------|------------------------|\n| 0.001 | 0.0078 \u00b1 0.0074 | 0.029485 \u00b1 0.018683 | 0.0551 \u00b1 0.022276 | 0.04518 \u00b1 0.027153 | 0.021048 \u00b1 0.015033 |\n| 0.005 | 0.0078 \u00b1 0.0074 | 0.029498 \u00b1 0.01868 | 0.0559 \u00b1 0.022332 | 0.0452 \u00b1 0.027162 | 0.0211 \u00b1 0.015059 |\n| 0.01 | 0.008 \u00b1 0.0075 | 0.0298 \u00b1 0.018938 | 0.0581 \u00b1 0.0228 | 0.0453 \u00b1 0.0272 | 0.0212 \u00b1 0.015103 |\n| 0.05 | 0.0146 \u00b1 0.0119 | 0.0385 \u00b1 0.0229 | 0.1011 \u00b1 0.0358 | 0.0491 \u00b1 0.0278 | 0.0258 \u00b1 0.016 |\n| 0.1 | 0.0352 \u00b1 0.0271 | 0.0568 \u00b1 0.0287 | 0.1513 \u00b1 0.0503 | 0.0605 \u00b1 0.0298 | 0.0402 \u00b1 0.019 |\n\n---\n\n**Table for noise level $\\sigma = 0.1$ for different \\% of unobservable agents**\n\n  \n\n| Unobservable % | StageNet (mean \u00b1 std) | DNRI (mean \u00b1 std) | FC Baseline (mean \u00b1 std) | Single RNN (mean \u00b1 std) | Joint RNN (mean \u00b1 std) |\n|----------------|-----------------------|-------------------|--------------------------|-------------------------|------------------------|\n| 20% | 0.0272 \u00b1 0.0214 | 0.0401 \u00b1 0.0142 | 0.1332 \u00b1 0.0364 | 0.047 \u00b1 0.0196 | 0.0319 \u00b1 0.0128 |\n| 30% | 0.0285 \u00b1 0.0223 | 0.0445 \u00b1 0.0165 | 0.1437 \u00b1 0.0412 | 0.0542 \u00b1 0.0248 | 0.0362 \u00b1 0.0155 |\n| 40% | 0.0313 \u00b1 0.0252 | 0.05 \u00b1 0.0227 | 0.1468 \u00b1 0.0436 | 0.0539 \u00b1 0.0256 | 0.0376 \u00b1 0.0167 |\n| 50% | 0.0352 \u00b1 0.0271 | 0.0568 \u00b1 0.0287 | 0.1513 \u00b1 0.0503 | 0.0605 \u00b1 0.0298 | 0.0402 \u00b1 0.019 |\n| 60% | 0.0364 \u00b1 0.0291 | 0.0493 \u00b1 0.0234 | 0.1529 \u00b1 0.0589 | 0.0584 \u00b1 0.0298 | 0.0426 \u00b1 0.0217 |\n| 70% | 0.0402 \u00b1 0.0313 | 0.0541 \u00b1 0.0273 | 0.157 \u00b1 0.0695 | 0.0477 \u00b1 0.0255 | 0.0645 \u00b1 0.0373 |\n| 80% | 0.0446 \u00b1 0.0355 | 0.0678 \u00b1 0.0397 | 0.1642 \u00b1 0.091 | 0.0615 \u00b1 0.0376 | 0.0711 \u00b1 0.0437 |"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4647/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700714531524,
                "cdate": 1700714531524,
                "tmdate": 1700714531524,
                "mdate": 1700714531524,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tG3N0OGrfJ",
                "forum": "tsj6rDzI0V",
                "replyto": "MLCHXCyLIS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Visualization of the  the dynamic spatial-relational patterns in the simulated datasets"
                    },
                    "comment": {
                        "value": "> One potential improvement to the paper could be to visualize the dynamic spatial-relational patterns in the simulated datasets. This could give a more intuitive understanding of the underlying dynamics and interactions.\n\n\nThank you for your valuable suggestion. We have taken your feedback into account and have incorporated several visualization plots to provide a more intuitive understanding of the dynamic spatial-relational patterns in our simulated datasets. Here's how we have addressed this:\n\n1.  Real-world Basketball Dataset: We have integrated a real-world basketball dataset featuring trajectories of 5 out of 11 agents, including offensive players, defensive players, and the ball. In Section 3 of our paper, we present findings that demonstrate our method's enhanced capability in predicting the movements of unobservable agents within this real-world context. Additionally, we have included visualization plots for the basketball dataset in Appendix Section E.\n    \n2.  Simulated Dataset Visualizations: Visualizations of the simulated dataset are provided on Page five in Figure 3 of the main paper. These visualizations help in understanding the model's performance with unobservable agents.\n    \n3.  Evolution Error Visualization: In the main paper, Figure 4 illustrates the evolution error in dynamics over a 30-step future projection, particularly focusing on scenarios with 50% and 75% unobservable agents. \n    \n4.  Correlation and Phase Plots: To delve deeper into the quality of prediction, we have added correlation and phase plots for the simulated datasets in Appendix Section E. \n    \n5.  Temporal Context Feature Attention Maps: Figure 10 in Section B.2 visually illustrates the temporal context feature attention maps for spring systems with varying proportions of hidden agents, ranging from 50% to 87.5%. This visualization highlights the network's attention maps as the proportion of hidden agents increases, emphasizing the network's need for more comprehensive data to enhance predictive accuracy, especially in scenarios with a high percentage of unobservable agents.\n    \n\nThese visualizations enhance the clarity of our results and provide a better grasp of the spatiotemporal relational interactions in our datasets."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4647/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700714872278,
                "cdate": 1700714872278,
                "tmdate": 1700714872278,
                "mdate": 1700714872278,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "xoOnf3hKpF",
            "forum": "tsj6rDzI0V",
            "replyto": "tsj6rDzI0V",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4647/Reviewer_TH3v"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4647/Reviewer_TH3v"
            ],
            "content": {
                "summary": {
                    "value": "This paper deals with a trajectory prediction task with unobservable hidden objects in the system, which focuses on interaction modeling between hidden and visible agents. The authors propose STAGE Net, a sequential spatiotemporal attention-based generative model to learn system dynamics with multiple interacting agents where some agents are completely unobserved all the time. This framework utilizes a dynamic spatiotemporal graph attention mechanism, specifically tailored for systems where only a subset of agents is observable at any given time. The proposed network utilizes the spatiotemporal attention mechanism with neural inter-node messaging to capture high-level behavioral semantics of the multi-agent system. They employ a graph neural network applied to a spatiotemporal graph to approximate the initial latent posterior distribution. The proposed method was evaluated on multiagent simulations with spring and charged dynamics and a motion trajectory dataset."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is generally well-written and easy to follow.\n\n2. The problem of modeling the influence of unobservable hidden objects is interesting.\n\n3. The experimental results seem to support the authors' claims."
                },
                "weaknesses": {
                    "value": "1. This paper deals with unobservable hidden agents in trajectory prediction. However, it is not clear which parts of the proposed model have specific advantages in addressing this issue. Meanwhile, it would be better to elaborate on more theoretical rationale about why the proposed mechanism or model design could improve the prediction performance in addition to empirical results.\n\n2. Given a certain set of trajectories of observable agents, there may be multiple different settings of hidden agents (e.g., different numbers, different states) that lead to the same observations of the observable agents, so the future could be multi-modal due to different potential situations. It is not clear how the proposed model handles this issue. \n\n3. With unknown numbers of hidden agents, the future trajectories should naturally have uncertainty or multi-modality. However, there seems no discussion regarding this.\n\n4. Regarding the experiments with different percentages of hidden agents, it is not clear how hidden agents are determined. Was it based on random sampling? Different choices of hidden agents may significantly influence the predictability of the system. Therefore, it would be better to clearly explain the experimental setting regarding this aspect to ensure a fair comparison with baseline methods.\n\n5. It would be better to also provide qualitative results on the motion prediction dataset as well as for the ablation study, which will be more straightforward to understand how the proposed model handles unobservable objects better."
                },
                "questions": {
                    "value": "1. In Figure 3, should \"velocity\" be changed to \"trajectory\"?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4647/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699250980790,
            "cdate": 1699250980790,
            "tmdate": 1699636444628,
            "mdate": 1699636444628,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "L8e1W0vlDG",
                "forum": "tsj6rDzI0V",
                "replyto": "xoOnf3hKpF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Stochasticity and Multi Modal prediction"
                    },
                    "comment": {
                        "value": "> Given a certain set of trajectories of observable agents, there may be multiple different settings of hidden agents (e.g., different numbers, different states) that lead to the same observations of the observable agents, so the future could be multi-modal due to different potential situations. It is not clear how the proposed model handles this issue.\n\nWe thank the reviewer for their insightful observations. Our work indeed considers two primary cases of stochasticity: stochasticity in the configuration of hidden agents and stochasticity in trajectory prediction. The first case involves scenarios where different settings of hidden agents (varying numbers and states) could lead to identical observations of the observable agents. The second case pertains to inherently unpredictable trajectories, such as a pedestrian suddenly stopping to interact with an environmental element (e.g., petting a cat on the road).\n\nIn our datasets, the stochastic elements primarily arise from the varying number and initial interactions of hidden agents, a key focus of our study as we aim to understand how system predictions are affected in cases with hidden agents. However, once the initial configuration of these agents is established, the trajectory becomes deterministic. Our approach inherently accounts for the stochasticity introduced by the number and initial interactions of hidden agents. While the trajectory prediction is deterministic given the initial configuration, the stochastic latent state is designed to learn the distribution of potential configurations for the agents. Based on the observations and its updated belief, the model outputs a latent state that best represents the system for that particular configuration.\n\n\nIn addressing these challenges, our model employs a spatio-temporal graph to encode interactions among observable agents. This graph forms the basis for our encoder, which assimilates observations from all agents to update a shared belief space. The belief space is modeled using Gaussian distributions for both the prior and posterior, leading to the generation of a stochastic latent state $( z_t^i )$ for each visible agent. This process is followed by a Neural ODE that samples from the stochastic latent state, advancing the latent dynamics, which are then decoded to produce the final output.\n\n\nHowever, we acknowledge the reviewer's point regarding the high stochasticity in trajectories, such as the pedestrian example mentioned earlier. To enhance our model's capability in handling such scenarios, we propose the following modifications:\n\na. **Neural SDEs for Latent Dynamics**: We propose to replace Neural ODEs with [Stochastic Differential Equations (SDEs)](https://github.com/google-research/torchsde) for modeling the evolution of the latent state. This approach introduces randomness in the trajectory of the latent state over time, effectively capturing the stochastic nature of both the hidden agent configurations and the trajectories.\n\nb. **Multimodal Decoder with Uncertainty Quantification**: To achieve multimodal outputs, we suggest incorporating mixture models, such as Gaussian Mixture Models (GMMs), into our decoder. In this setup, each component of the GMM would represent a different plausible outcome, with the parameters of the mixture model (means, variances/covariances, and mixture weights) being output by the decoder. This modification would enable our model to handle a wide range of scenarios, including those with high stochasticity or chaotic dynamics, by providing a probabilistic representation of multiple potential future states.\n\nWe plan to integrate these enhancements into our model and explore their effectiveness in future work, particularly as we scale our network to handle increasingly complex and stochastic systems.\n\n*[References for SDEs]*\n\n[1] Xuechen Li, Ting-Kam Leonard Wong, Ricky T. Q. Chen, David Duvenaud. \"Scalable Gradients for Stochastic Differential Equations\".  _International Conference on Artificial Intelligence and Statistics._  2020.  [[arXiv]](https://arxiv.org/pdf/2001.01328.pdf)\n\n[2] Patrick Kidger, James Foster, Xuechen Li, Harald Oberhauser, Terry Lyons. \"Neural SDEs as Infinite-Dimensional GANs\".  _International Conference on Machine Learning_  2021.  [[arXiv]](https://arxiv.org/abs/2102.03657)\n\n\n*[Reference for multimodel decoder]*\n\n[1] Christopher M. Bishop. \"Mixture Density Networks\". _Aston University, Neural Computing Research Group Report_. 1994. [[PDF]](https://publications.aston.ac.uk/id/eprint/373/1/NCRG_94_004.pdf)\n\n[2] Alex Graves. \"Generating Sequences With Recurrent Neural Networks\". 2013. [[arXiv]](https://arxiv.org/abs/1308.0850)"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4647/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700715373412,
                "cdate": 1700715373412,
                "tmdate": 1700715373412,
                "mdate": 1700715373412,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KBa4KvicZA",
                "forum": "tsj6rDzI0V",
                "replyto": "xoOnf3hKpF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Experimental setting for Hidden Agents"
                    },
                    "comment": {
                        "value": "> Regarding the experiments with different percentages of hidden agents, it is not clear how hidden agents are determined. Was it based on random sampling? Different choices of hidden agents may significantly influence the predictability of the system. Therefore, it would be better to clearly explain the experimental setting regarding this aspect to ensure a fair comparison with baseline methods.\n\n### Clarification on the Method for Determining Hidden Agents in Experiments\n\nWe appreciate your query regarding the selection of hidden agents in our experiments. To ensure a robust and fair analysis, we have adopted the following approach:\n\n1. **Random Sampling of Hidden Agents from the Total Graph**: In our experimental setup, we consider a system comprising \\(O\\) observable agents and \\(U\\) unobservable agents. Initially, we simulate the dynamics of the entire system, which includes all agents. Subsequently, we randomly select \\(U\\) agents from this system. These selected agents are then treated as the 'hidden' or 'unobservable' agents, and their trajectories are not provided to the model during the training or testing phases. The model is thus exposed only to the trajectories of the remaining \\(O\\) observable agents.\n\n   The impact of this methodology, along with comparative analysis against baseline methods, is presented in Tables 1, 2, and 3 of the main paper. This random sampling approach ensures that the selection of hidden agents is unbiased and varied, allowing for a comprehensive evaluation of the system's predictability under different scenarios.\n\n2. **Controlled Setup with Varying Degree Centrality of the Hidden Agents**: Consider a system comprising \\(O\\) observable agents and \\(U\\) unobservable agents. In this setup, we first establish a fully connected network among observable agents. Then, for each hidden agent, we connect it to \\(r\\) observable agents, where \\(r\\) ranges from 1 to \\(U\\). It's important to note that there are no connections between two hidden agents. This approach provides deeper insight into how hidden agents influence observable ones. The results of this analysis are presented on Page 9 of the main paper, with Figure 6 depicting the comparison of the model against baselines.\n\n3. **Controlled Setup with varying Hidden Agent Interactions Strength**: For this analysis, we adopt the random sampling approach from point 1, and then modify the interaction strength among the hidden agents. The interaction (coupling) strength is systematically adjusted between 0.5 to 5.0. This system's analysis is provided in Supplementary B.1, with a detailed comparison with baselines shown in Figure 9.\n\nIn all three analyses, we observe that our network demonstrates superior predictive power over the baselines when hidden agents are present in the system."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4647/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700715658644,
                "cdate": 1700715658644,
                "tmdate": 1700715658644,
                "mdate": 1700715658644,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ADxjw9eUf2",
                "forum": "tsj6rDzI0V",
                "replyto": "xoOnf3hKpF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Theoritical Rationale and Model Description"
                    },
                    "comment": {
                        "value": "> This paper deals with unobservable hidden agents in trajectory prediction. However, it is not clear which parts of the proposed model have specific advantages in addressing this issue. Meanwhile, it would be better to elaborate on more theoretical rationale about why the proposed mechanism or model design could improve the prediction performance in addition to empirical results.\n\nWe thank the reviewer for their comment and to address this we give a dynamical perspective of the problem to prove why the model works. In the problem formulation, we have a total of M agents in the system, of which only $N < M$ are observable while the rest are unobservable. We further assume that we do not know the total number of agents in the system or the interaction topology of the overall graph. We would like to know the evolution of the dynamics of the overall system to predict the visible agents accurately. This can be represented mathematically as follows:  \nLet $x(t)$, an $m$-dimensional time-dependent state vector for the full system defined on the domain $D \\in \\mathbb{R}^m \\times \\mathbb{R}_+$, with $m \\in \\mathbb{N}$ and $t > 0$, be the solution of a nonlinear differential equation\n$$\n\\begin{equation}\n    \\frac{d}{dt}x(t) = f(x(t); \\mu)\n\\end{equation}\n$$\nwhere $f$ is a smooth and nonlinear function and $\\mu$ a vector of system parameters. Further, let $y \\in \\mathbb{R}^n$ represent noisy measurements of visible agents system, given by\n$$\n\\begin{equation}\n    y(t) = g(x(t)) + \\eta,\n\\end{equation}\n$$\nwhere $\\eta$ is a noise process. The goal is then to learn an approximate dynamical system\n$$\n\\begin{equation}\n    \\frac{d}{dt}z(t) = \\hat{f}(z(t); \\hat{\\mu})\n\\end{equation}\n$$\nin terms of a new state $z$, which may either be the measured state $y$ or an invertible function of $y$:\n$$\n\\begin{equation}\n    z(t) = \\phi(y(t)).\n\\end{equation}\n$$\n\nHere $y$ represents the visible agents and $x$ represents the overall system. In general, it is not possible to learn the dynamics $f$ in the original dimension in terms of measurement vector $y$ of visible agents. Hence, to solve this problem, we must map the input observations to a latent state $h$ such that the new mapped manifold is an attractor that is diffeomorphic to the original system. Using Taken's embedding theorem [1], it is then possible to learn the dynamics of such systems. Takens\u2019 embedding theorem proves that a diffeomorphic map between the delay-embedded attractor $h$ and the original attractor $x(t)$ exists under certain conditions. The theorem doesn\u2019t specify how to find this map. Hence in this work we use the universal approximation properties of neural networks [2] to approximate the diffeomorphism and others where the dynamics are simplified. Below is how our model learns this mapping. \n\n*[References]*\n\n1. Taken et al. 1980, Dynamical Systems and Turbulence, Warwick 1980, \n\n2. Devore et al. 2022, Neural Network Approximation"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4647/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700716012298,
                "cdate": 1700716012298,
                "tmdate": 1700716012298,
                "mdate": 1700716012298,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KiwM8RnfIe",
                "forum": "tsj6rDzI0V",
                "replyto": "xoOnf3hKpF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Questions: In Figure 3, should \"velocity\" be changed to \"trajectory\"?"
                    },
                    "comment": {
                        "value": "> In Figure 3, should \"velocity\" be changed to \"trajectory\"?\n\nThank you for your observation regarding the terminology used in Figure 3. In our study, we predict both position and velocity for all datasets, specifically $(x, y, \\dot{x}, \\dot{y})$ for the spring and charged datasets, and $(x, y, z, \\dot{x}, \\dot{y}, \\dot{z})$ for the motion datasets. In the initial version of the figure, we inadvertently labeled the \"position\" as \"trajectory.\" We acknowledge this oversight and have revised the figure accordingly in the updated manuscript. The corrected figure now accurately depicts the comparison between the true and predicted values for both position and velocity, enhancing the clarity of our results."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4647/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700717035589,
                "cdate": 1700717035589,
                "tmdate": 1700717035589,
                "mdate": 1700717035589,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0HdOxhs7of",
                "forum": "tsj6rDzI0V",
                "replyto": "xoOnf3hKpF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4647/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Qualitative results for the datasets"
                    },
                    "comment": {
                        "value": "> It would be better to also provide qualitative results on the motion prediction dataset as well as for the ablation study, which will be more straightforward to understand how the proposed model handles unobservable objects better.\n\n\n  \nThank you for your valuable suggestion. We have taken your feedback into account and have incorporated several visualization plots to provide a more intuitive understanding of the dynamic spatial-relational patterns in our  datasets. Here's how we have addressed this:\n\n1.  **Real-world Basketball Dataset:** We have integrated a real-world basketball dataset featuring trajectories of 5 out of 11 agents, including offensive players, defensive players, and the ball. In Section 3 of our paper, we present findings that demonstrate our method's enhanced capability in predicting the movements of unobservable agents within this real-world context. Additionally, we have included visualization plots for the basketball dataset in Appendix Section E.\n    \n2.  **Simulated Dataset Visualizations:** Visualizations of the simulated dataset are provided on Page five in Figure 3 of the main paper. These visualizations help in understanding the model's performance with unobservable agents.\n    \n3.  **Evolution Error Visualization:** In the main paper, Figure 4 illustrates the evolution error in dynamics over a 30-step future projection, particularly focusing on scenarios with 50% and 75% unobservable agents. This visual representation offers insight into the model's predictive accuracy under varying conditions of agent observability.\n    \n4.  **Correlation and Phase Plots:** To delve deeper into the quality of prediction, we have added correlation and phase plots for the simulated datasets in Appendix Section E. These plots provide a more nuanced understanding of the model's performance.\n    \n5.  **Temporal Context Feature Attention Maps:** Figure 10 in Section B.2 visually illustrates the temporal context feature attention maps for spring systems with varying proportions of hidden agents, ranging from 50% to 87.5%. This visualization highlights the network's adaptive response in refining predictions as the proportion of hidden agents increases, emphasizing the network's need for more comprehensive data to enhance predictive accuracy, especially in scenarios with a high percentage of unobservable agents.\n    \n\nThese visualizations enhance the clarity of our results and provide a better grasp of the spatiotemporal relational interactions in our datasets."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4647/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700721621042,
                "cdate": 1700721621042,
                "tmdate": 1700721621042,
                "mdate": 1700721621042,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]