[
    {
        "title": "Emergent Language based Dialog for Collaborative Multi-agent Navigation"
    },
    {
        "review": {
            "id": "KHYZoQPfkD",
            "forum": "WsHaBoucSG",
            "replyto": "WsHaBoucSG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5358/Reviewer_1ZPo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5358/Reviewer_1ZPo"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a collaborative multi-agent navigation via emergent dialogue, where the Tourist and the Guide learn expressions aligned with both the real-world environments and task-specific dialogue intents. The proposed method enables both agents to generate and understand emergent language, and develop optimal dialogue decisions with a long-term goal of solving the task. The paper provides a real-world navigation scene with matterport3D simulator to showcase the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The authors propose a novel multi-agent reinforcement learning (RL) framework complemented by auxiliary pre-training to effectively align emergent language with both the environment and the task.\n2. Experimental results on a real-world navigation scene with matterport3D simulator to showcase the effectiveness of the proposed method."
                },
                "weaknesses": {
                    "value": "1. The paper does not provide a detailed analysis of the underlying rules that the emergent language adheres to, which may limit the understanding of the method.\n2. The design of each module of the method is relatively conventional, and no particular contribution was found."
                },
                "questions": {
                    "value": "Can you provide some text examples to compare the differences between the text learned from the best baseline and the method learned from your own method?\nCan you explain again what advantages the design of each module in the method has compared to the previous method?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5358/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698769657787,
            "cdate": 1698769657787,
            "tmdate": 1699636540295,
            "mdate": 1699636540295,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NGoFK9uYmm",
                "forum": "WsHaBoucSG",
                "replyto": "KHYZoQPfkD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5358/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5358/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the valuable comments, and hope the following point-by-point responses address the reviewer\u2019s concern. \n\nQuestion 1: \n\nAmong the mentioned baselines, RMM [1] is the only work concerning language generation ability. Unfortunately, it\u2019s hard to reproduce RMM to get sufficient text examples for comparison. We take the example provided in the RMM paper, run our model using the same start position and the same target, and compare the emergent texts of our model with the natural language of RMM, as depicted in Appendix Table 5. There is no obvious alignment between the natural language and the emergent language. This observation draws a similar conclusion as that of Appendix A, i.e., the emergent language captures different views about the surrounding and the task ontology with the natural language learned from a large scale of human-annotated data. This will lead to an interesting content of our future work.\n\nQuestion 2:\n\nMuch existing research on navigation task concerns only language understanding ability of one agent. The most similar work is RMM [1], which focuses on training the natural language generation and understanding of two agents, under the supervision of a large scale of labelled dialogues. While our work concerns about the emergent language generation and understanding, without any labelled language data. The intrinsic advantage of our design is to train a multi-agent navigation model all from the scratch, without any human intervention, which is, to the best of our knowledge, the first work that proves the feasibility of multi-pass emergent communication in realistic dynamic environments, and provides an empirical method for the implementation. \n\nWeakness 1:\n\nThank you for pointing out this concern. There is no explicit underlying rules or heuristics that the emergent language adheres to. Actually, we performed intensive analysis of the emergent language, by detecting the alignment of emergent language with visual surrounding, and of emergent language with task, which we consider as two essential characters of language. In order to make further study on whether there are implicit rules underlying the emergent language, following [2], we analyzed the compositionality of emergent language, by calculating the topographic similarity between observation pairs and corresponding message pairs under two different settings. \n\nIn the first setting, we calculate the editing distances of two dialogue histories up to the same turn $t$ as following:\n\n$$LevenshteinDistance(H_{utterance, t}^{T, i}, H_{utterance, t}^{T, j})$$\n\n$$H_{utterance, t}^{T, i} = \\langle U_1^{T, i}, U_2^{T, i}, ..., U_t^{T, i}\\rangle$$\n\n$$H_{utterance, t}^{T, j} = \\langle U_1^{T, j}, U_2^{T, j}, ..., U_t^{T, j}\\rangle$$\n\nIn the second setting, we calculate the editing distances of two messages in the same turn $t$:\n\n$$LevenshteinDistance(U_t^{T, i}, U_t^{T, j})$$\n\nThe curves of topographic similarity are shown in the Figure 5 in the paper. The first setting observes an uptrend in topographic similarity (colored in orange), while the second setting a downtrend (colored in blue). The uptrend suggests that the longer history conveys the more information. The downtrend suggests that each message progressively enriches information given the previous turns, and the messages at the beginning of the task carry more information than that of the later steps. As a metric evaluating the compositionality of the emergent language, this score suggests that the emergent language could composite task-specific features helpful for task solving. \n\nWeakness 2: \n\nPlease refer to the response to Question 2.\n\n[1] Roman H R, Bisk Y, Thomason J, et al., RMM: A recursive mental model for dialogue navigation, EMNLP 2020.  \n\n[2] Lazaridou A, Hermann K M, Tuyls K, et al., Emergence of linguistic communication from referential games with symbolic and pixel input, ICLR 2018"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5358/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700561572168,
                "cdate": 1700561572168,
                "tmdate": 1700564001211,
                "mdate": 1700564001211,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "VhvKBPdjPP",
            "forum": "WsHaBoucSG",
            "replyto": "WsHaBoucSG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5358/Reviewer_YMT3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5358/Reviewer_YMT3"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors introduce a model of communication between two agents, a Tourist and a Guide. The former must navigate an environment to reach a unknown target location following instructions provided by the latter. The Guide, without knowing the current position of the Tourist, must communicate to provide information about the path to the target position. Using two objective functions, one optimizing for Guide localization of the Tourist and one for optimizing for Tourist navigation, they report better results over previous work on two visual-language navigation datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "I think the authors investigate the interesting problem of embodies agents communicating while having different roles, a follower and a guide. The lack of any human-annotation in the training process makes it for cheap method to train embodies agents and the ablation study conducted supports the modelling choices made by the authors. Furthermore, the usage of realistic datasets shows that the method can scale to natural setups and is an important step towards deploying agents in the wild. \n\nOverall, I find the only weaknesses to be in the lack of an in-depth analysis of the emergent language. (more in the following section) The only analysis shown is qualitative one and is relegated to the appendix. Although, I don't see it a fundamental requirement to accept the paper, what prevented me from giving it a higher score is the lack of a deeper analysis. \n\nFinally, provided a minor restructuring of the manuscript is done, such as moving the analysis to the main body of the paper, I am in favor of including the paper at the conference."
                },
                "weaknesses": {
                    "value": "As I mentioned in the previous section, I think the major weakness of the paper is in the lack of deep analysis of the emergent language. Computing metrics of emergent languages like topographic similarity (using environment encodings and agent messages) [1] could give an idea of the structure of the agents' protocols. \n\nA minor weakness that I found is the usage of agents without any pre-encoded linguistic knowledge. Using a LLM as navigation planner, which has shown some potential [2, 3], could solve the problem of training agents that have an opaque communication protocol. \nI am thinking that your method could be used as a fine-tuning approach over existing language-aware models, keeping in mind that the language drift problem [4] should be taken into account. I'd be happy to hear the authors' opinion on this\n\n\n[1] Lazaridou et al.,  Emergence of linguistic communication from referential games with symbolic and pixel input, ICLR 2018\n\n[2] Rana et al, SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Robot Task Planning, CoRL 2023\n\n[3] Rajvanshi et al., SayNav: Grounding Large Language Models for Dynamic Planning to Navigation in New Environments, 2023\n\n[4] Lazardou et al., Multi-agent communication meets natural language: Synergies between functional and structural language learning, ACL 2020"
                },
                "questions": {
                    "value": "- At the end of the related work section you claim: \"we also empower the oracle agent to provide instructions progressively\", how is it guaranteed that messages are sent progressively and not all at the beginning? While I'm not challenging your claim, I'm wondering whether it's backed by any analysis work or just by the nature of your sequential communication modules.\n\n- In the training setup section I don't understand why you call the two objective \"pre-training\" tasks. Aren't they used jointly to train the agents? From the paper, I don't understand, the division, if any, between pre-training and training.\n\n- Why do you choose a vocabulary size of 26? I first thought it was to draw a similarity with the English language, but I then realized by looking a figure 3b that it could be the result of an hyperparameter optimization following an ablation study. Could you please clarify?\n\n- In sec 5.5, how do you compute the reduced 2D space? Could please you provide additional details? They could easily be added to the appendix for a camera-ready version\n\n\n---------\n\nmisc/typos\n\n- In section 4.1 you mention Guest position, do you mean Tourist position?\n\n- In the related work section you mention: \"[...] has a similar setting to our work but lets the Guide describe the target position\u2019s observation in a kind of emergent language\". I find \"a kind of emergent language\" unclear, please fix it.\n\n- Please provide a more descriptive Figure 4 caption than the rather vague \"Emergent language analysis\" \n\n- \"Language based\" in the title is probably missing a \"-\" -> Language-based\n\nAnother related paper about navigation and emergent communication is [1]. Despite their communication modules being simpler than your, I think it makes sense to include it in your section surveying the literature.\n\n[1] Patel et al., Interpretation of Emergent Communication in Heterogeneous Collaborative Embodied Agents, ICCV 2021."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5358/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698781076573,
            "cdate": 1698781076573,
            "tmdate": 1699636540083,
            "mdate": 1699636540083,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0u6mUt4pnO",
                "forum": "WsHaBoucSG",
                "replyto": "VhvKBPdjPP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5358/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5358/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the valuable and constructive comments, and add the following clarifications to address the reviewer\u2019s concerns:\n\nQuestion 1: \n\nThe claim \u201cwe also empower the oracle agent to provide instructions progressively \u201cis backed by the experiment results on different settings of dialogue strategy which is shown in Table 4. When comparing the \u201conly in beginning\u201d setting with other settings with more dialogue frequency, it observes that the \u201conly in. beginning\u201d setting has a poorer performance, indicating that providing all information only at the beginning is not enough, and the message in each turn conveys additional helpful information for the following task. To better verify this point, we conducted experiments of \u201cdirect communication\u201d (i.e., sending the shortest path repeatedly in each turn) and observed a similar performance with that of the \u201conly in beginning\u201d setting (tl=10.09, ne=6.88, sr=25.74, spl=22.78, vs tl=10.79, ne=6.44, sr=25.37, spl=21.13), proving that the subsequent utterances provide additional helpful information instead of repeating the same information. Our further study also found that especially when the Tourist made wrong movement actions, the multi-turn communication could provide helpful instructions, leading to a much better performance.\n\nQuestion 2:  \n\nAt the very beginning of our research, we tried to directly train a multi-agent navigation model in an end-to-end manner using reinforcement learning, and observed a discouraging non-convergence of the training. Under this setting, we jointly trained the language generation module and understanding module for both agents (i.e., four modules in total) by simultaneously maximizing the whole accumulated rewards. However, the model collapsed into a poor status since the generation and understanding are not coordinated at the start of training which can cause the state to quickly become large and chaotic. Therefore, we formulate the navigation task as a two-pass task and train each pass separately in a supervised learning manner: In the first pass (the so-called \u201cLocalization\u201d task), the Tourist was encouraged to learn how to generate language accurately describing its visual surrounding, and the Guide to correctly understand the message from the Tourist to predict where the Tourist is, with the goal of making proper guideline for future steps. In the second pass (the so-called \u201cMovement\u201d task), the Guide was encouraged to generate language accurately describing its guideline, and the Tourist to correctly understand the message conveying the guideline, in order to make proper movement. Then we returned back to jointly training for the navigation task as mentioned at the beginning, but with parameters initialized by the two-pass training tasks. Therefore, we call each pass a pre-training task of the targeted navigation task, the principled fundamentals of which are explained in Section 4.5.\n\nQuestion 3:\n\n Yes, your thought is right. We do choose the vocabulary size of 26 to draw a similarity with the English language. The experiment in Figure 3b is to explore the effect of the vocabulary size on the performance and the 26 may not be the best choice among all possible choices of vocabulary size in the proposed navigation task.\n\nQuestion 4: \n\nIn Figure 4 (a) of section 5.5, we use PCA as a dimension reduction technique to reduce the encoded Tourist\u2019s visual image $\\bar{e} _o^t \\in \\mathbb{R}^{dim}$, and encoded dialog history $\\bar{e} _{H _{dialog}}^G \\in \\mathbb{R}^{dim}$ into 2D space. Similarly, in Figure 4 (b), the encoded dialogue history $\\bar{e} _{H _{dialog}}^T \\in \\mathbb{R}^{dim}$, and the encoded next step action $\\bar{e} _p^{pos _i \\rightarrow pos _j } \\in \\mathbb{R}^{dim}$ are reduced via PCA dimension reduction tool. Then, in Figure 4 (a), we cluster the encoded visual images using KMeans and connect the center of the clusters and the center of the corresponding messages, then we find the parallel. Similarly, in Figure 4 (b), we cluster the encoded next step action using KMeans and connect the center of the clusters and the center of the corresponding messages. Thanks for your advice, and we have added those details to the appendix."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5358/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700509958143,
                "cdate": 1700509958143,
                "tmdate": 1700510153636,
                "mdate": 1700510153636,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ktxh6ZCxjp",
                "forum": "WsHaBoucSG",
                "replyto": "VhvKBPdjPP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5358/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5358/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Weakness 1:\n\nThanks very much for the suggestion, inspired by your suggestions we have conducted some analysis about the emergent language, and have added it to the paper. More efforts will be made to have a deeper analysis of the language. \n\nwe conducted an experiment to analyze the compositionality of emergent language, by calculating the topographic similarity between observation pairs and corresponding message pairs under two different settings. \n\nIn the first setting, we calculate the Levenshtein distances of two dialogue histories generated by the Tourist up to the same turn $t$.\n\n$$LevenshteinDistance(H _{utterance, t}^{T, i}, H _{utterance, t}^{T, j})$$\n\n$$H _{utterance, t}^{T, i} = \\langle U _1^{T, i}, U _2^{T, i}, ..., U _t^{T, i}\\rangle$$\n\n$$H _{utterance, t}^{T, j} = \\langle U _1^{T, j}, U _2^{T, j}, ..., U _t^{T, j}\\rangle$$\n\nIn the second setting, we calculate the Levenshtein distances of two messages in the same turn $t$.\n\n$$LevenshteinDistance(U _t^{T, i}, U _t^{T, j})$$\n\nThe curves of Topographic similarity are shown in Figure 5 in the paper. The first setting observes an uptrend in topographic similarity (colored in orange), while the second setting is a downtrend (colored in blue). The uptrend suggests that the longer history conveys the more information. The downtrend suggests that each message progressively enriches information given the previous turns, and the messages at the beginning of the task carry more information than those of the later steps. As a metric evaluating the compositionality of the emergent language, this score suggests that the language could composite task-specific features helpful for task solving.\n\nThose results and more details have been added to the paper and we are trying hard to explore more characteristics of the emergent language.\n\nWeakness 2:\n\nIt is a very interesting idea to apply our method to fine-tune a language-aware model. Since the proposed method is formulated for navigation tasks, the emergent language could capture the most task-related information directly. By comparison, training both of the agents (the Tourist and the Guide) learning natural language, requires the language to capture two types of information: the distribution of natural language and the task-specific information. In natural language setup, a direct method is to take a supervised method to train the language modules to achieve the task. However, in supervised training, the quality of natural language is learned directly but the task-related information lays behind the language which is learned indirectly. This is a possible reason why the natural language has a poorer performance (proved by the comparison between our method with the RMM). Applying our method to a language-aware model could mitigate this problem. With our method learning the task-related information, the supervised method learning the language structure, a much better performance could be achieved.\n\nSome possible methods to incorporate our method into the existing language-aware model without causing much language drift could be tried:\n\n1. Use our method as a finetuning approach with KL loss making sure that the fine-tuned model is not too far from the initial language-aware model, similar to the RLHF methods applied on LLM.\n2. Train the supervised method and our RL methods on the language modules iteratively. The supervised method is used to maintain the quality of natural language, and our RL method to learn task-related information following [1].\n\n \nWe apologize for the misc/typos, and have fixed them and also added the missing reference. We will also move Figure 4 (Emergent language analysis) to the main body of the paper in the revised version.\n\n\n[1] Lowe R, Gupta A, Foerster J, et al., On the interaction between supervision and self-play in emergent communication, ICLR 2020."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5358/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700509979668,
                "cdate": 1700509979668,
                "tmdate": 1700562016899,
                "mdate": 1700562016899,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ggXuE6BV51",
            "forum": "WsHaBoucSG",
            "replyto": "WsHaBoucSG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5358/Reviewer_cd7K"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5358/Reviewer_cd7K"
            ],
            "content": {
                "summary": {
                    "value": "This study introduces a multi-agent navigation task in which one agent, the Tourist, perceives its immediate surroundings, while the other agent, the Guide, has an overarching view of the environment but lacks knowledge of the Tourist's location. The primary objective is for the Guide to direct the Tourist to a specific destination using evolving multi-turn dialogues. The paper details an empirical study centered on developing agents that can collaborate effectively through multi-turn emergent dialogues. To exemplify this, the authors introduce a collaborative multi-agent reinforcement learning technique that enables both agents to generate and understand emergent language. This method is tested with the Matterport3D simulator."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1. The paper introduces a novel framework for emergent communication based on a vision-language navigation task.\n1. An empirical study is provided as an example. That will be used as a baseline in future studies.\n1. The reviewer believes that the task design will contribute significantly to expanding the study of emergent communication."
                },
                "weaknesses": {
                    "value": "1. The paper does not sufficiently assess the quality and characteristics of the emergent language, such as its compositionality and its relation to the plan set out by the Guide.\n1. The figures contain very small text, making them hard to understand.\n1. While the main contribution seems to be the proposal of the task, a large portion of the description is dedicated to the network architecture (Section 3). The authors should provide a more intuitive explanation of the general task framework. Adding pseudocode could help potential readers grasp the proposal more effectively.\n1, The characteristics and details of the compared baseline methods in the experiments are not clear. It would be beneficial to include these descriptions in the Appendix."
                },
                "questions": {
                    "value": "The most straightforward communication approach the Guide could adopt is to repeatedly send the shortest path. How does the emergent language compare with such direct communication? If this hasn't been explored, it would be worthwhile to discuss."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5358/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5358/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5358/Reviewer_cd7K"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5358/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698826663386,
            "cdate": 1698826663386,
            "tmdate": 1699636539826,
            "mdate": 1699636539826,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Q5a6K7rGDB",
                "forum": "WsHaBoucSG",
                "replyto": "ggXuE6BV51",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5358/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5358/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the valuable comments, and hope the following clarification addresses the reviewer\u2019s concern.\n\nQuestions:\n\nThank you for your thought-provoking question. We had conducted experiments in a similar setting, referring to \u201conly in beginning\u201d in Table 4. We let the Tourist encode the shortest path instruction as a part of dialog history in each turn. Inspired by your question, we immediately conducted experiments using \u201cdirect communication\u201d (i.e., sending the shortest path repeatedly in each turn) and observed a similar performance with that of the \u201conly in beginning\u201d setting (tl= 10.09, ne=6.88, sr=25.74, spl=22.78, vs tl = 10.79, ne=6.44, sr=25.37, spl=21.13). By comparing with other results in Table 4, both performance of \u201cdirect communication\u201d and \u201conly in beginning\u201d are poorer than that under other settings (\u201csoft\u201d, \u201c20%\u201d,  \u201c50%\u201d,  \u201c100%\u201d), suggesting that the dialogue progressively provides additional information. Our further study also found that especially when the Tourist made wrong movement actions, the multi-turn communication could provide helpful instructions, leading to a much better performance. \n\nWeakness 1:\n\nThank you for your suggestion, and we had noticed this problem before but did not make much attempt at it. We performed language analysis by detecting the alignment of emergent language with visual surroundings, and that of emergent language with task, which we consider as the essential characters of language. Motivated by your suggestion, we conducted an experiment to analyze the compositionality of emergent language, by calculating the topographic similarity between observation pairs and corresponding message pairs under two different settings. \n\nIn the first setting, we calculate the Levenshtein distances of two dialogue histories generated by the Tourist up to the same turn $t$.\n\n$$LevenshteinDistance(H_{utter, t}^{T, i}, H_{utter, t}^{T, j})$$\n\n$$H_{utter, t}^{T, i} = \\langle U_1^{T, i}, U_2^{T, i}, ..., U_t^{T, i}\\rangle$$\n\n$$H_{utter, t}^{T, j} = \\langle U_1^{T, j}, U_2^{T, j}, ..., U_t^{T, j}\\rangle$$\n\nIn the second setting, we calculate the Levenshtein distances of two messages in the same turn $t$.\n\n$$LevenshteinDistance(U_t^{T, i}, U_t^{T, j})$$\n\nThe curves of Topographic similarity are shown in the Figure 5 of the paper. The first setting observes an uptrend in topographic similarity (colored in orange), while the second setting is a downtrend (colored in blue). The uptrend suggests that the longer history conveys the more information. The downtrend suggests that each message progressively enriches information given the previous turns, and the messages at the beginning of the task carry more information than those of the later steps. As a metric evaluating the compositionality of the emergent language, this score suggests that the language could composite task-specific features helpful for task solving.\n\nThose results and more details have been added to the paper and we are trying hard to explore more characteristics of the emergent language.\n\nWeakness 2:\n\nThanks for your suggestion. We do find the font size is too small when we zoom in, which is unfriendly to readers. We have adjusted (and further improvements will be made) Figures 2 & 3 carefully and hope it could improve the readability of this paper. \n\nWeakness 3:\n\nThank you for your suggestion and the old version is indeed not clear enough. We have added the pseudocode and the descriptions of the baseline methods to the Appendix (and more improvements will be made). And hope the revised version could be more friendly to readers."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5358/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700410578500,
                "cdate": 1700410578500,
                "tmdate": 1700561753155,
                "mdate": 1700561753155,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "f9Ry19V1b6",
                "forum": "WsHaBoucSG",
                "replyto": "Q5a6K7rGDB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5358/Reviewer_cd7K"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5358/Reviewer_cd7K"
                ],
                "content": {
                    "title": {
                        "value": "Thanks"
                    },
                    "comment": {
                        "value": "Thanks for your clarification.  I hope the revision has made the paper more productive and inspiring.\nI am almost satisfied with your update.\n\n>We had conducted experiments in a similar setting, referring to \u201conly in beginning\u201d in Table 4. We let the Tourist encode the shortest path instruction as a part of dialog history in each turn. Inspired by your question, we immediately conducted experiments using \u201cdirect communication\u201d (i.e., sending the shortest path repeatedly in each turn) and observed a similar performance with that of the \u201conly in beginning\u201d setting\n\nConsidering that potential readers may have a similar question, it would be better to explicitly describe the similarity between \"only in the beginning\" and \"direct communication\" in the body or in a footnote.\n\nMy score has been updated based on your response and revision."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5358/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700606398162,
                "cdate": 1700606398162,
                "tmdate": 1700606398162,
                "mdate": 1700606398162,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZQqeCPGZWz",
            "forum": "WsHaBoucSG",
            "replyto": "WsHaBoucSG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5358/Reviewer_oveQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5358/Reviewer_oveQ"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies how to build agents that can collaborate effectively with multi-turn emergent dialogues, it proposes a multi-agent navigation task, to guide the Tourist (the agent) to reach the target place via multi-turn dialogues. It proposes a collaborative multi-agent reinforcement learning method that enables both agents to generate and understand language, and make decisions with a long-term goal of solving the task. Empirical experiments on R2R and CVDN tasks show promising results."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. It introduces a multi-turn dialog for goal oriented navigation tasks. \n2. It proposes a multi-agent RL algorithm for the task, and shows promising results on two tasks (R2R and CVDN)."
                },
                "weaknesses": {
                    "value": "Based on the motivation of this work, CVDN is a natural task for this method. It is better to show the performance on the test splits (unseen) comparing with SoTA methods, rather than only showing the val split."
                },
                "questions": {
                    "value": "1. Is it possible to show the results for Test Unseen on R2R? besides the results on val seen and unseen. Similarly for CVDN dataset.\n\nMinor suggestions:\n1. Figure 2 & 3, the font is too small to read."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5358/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698989497390,
            "cdate": 1698989497390,
            "tmdate": 1699636539747,
            "mdate": 1699636539747,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JnCyWO0eLi",
                "forum": "WsHaBoucSG",
                "replyto": "ZQqeCPGZWz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5358/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5358/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the valuable comments, and hope the following clarification addresses the reviewer\u2019s concern.\n\nWeaknesses: \nwe thank the reviewer for giving us valuable advice. The R2R and CVDN datasets are initially designed for natural language navigation between two agents, therefore their test data are used to evaluate the alignment quality of natural language with the environment, which are demonstrated on the corresponding leaderboards (but with the environment settings unknown to the public). Our work focuses on emergent language communication therefore it is infeasible to draw a comparison with related work on the leaderboard using test data. However, in order to assess the language understanding and generation ability of our method, we train and evaluate it under paralleled environment settings (i.e., with the same visual groundings of train and val dataset) with the related work on R2R and CVDN. We have mentioned this in section 5.1 and will give more explanations in the future revised version.\n\nQuestion1:\nPlease refer to the above response to Weaknesses.   \n\n\nQuestion 2:\nThanks for your suggestion. We do find the font size is too small when we zoom in, which is unfriendly to readers. We have adjusted (and further improvements will be made) Figures 2 & 3 carefully and hope it could improve the readability of this paper."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5358/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700409654686,
                "cdate": 1700409654686,
                "tmdate": 1700619727161,
                "mdate": 1700619727161,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]