[
    {
        "title": "Beyond Laplace and Gaussian: Exploring the Generalized Gaussian Mechanism for Private Machine Learning"
    },
    {
        "review": {
            "id": "53BoGISMHq",
            "forum": "JG9PoF8o07",
            "replyto": "JG9PoF8o07",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3644/Reviewer_qfzX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3644/Reviewer_qfzX"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigates the Generalized Gaussian mechanism in Differential Privacy, as extention of typical Laplace and Gaussian noise additions. It proves that the GG family satisfies DP and adapts an existing privacy accounting tool, the PRV accountant, for this purpose. Applying the GG mechanism to PATE and DP-SGD machine learning tools, the authors claim that the Gaussian distribution often optimally balances privacy and accuracy."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The flow of this paper is very easy to follow."
                },
                "weaknesses": {
                    "value": "The exploration of alternative distributions for DP in this paper does not offer new insights. Previous research, such as the work by Awan and Dong (2022), already provides a comprehensive study on log-concave and multivariate canonical noise distributions in DP. These studies not only predate but also surpass the current paper's approach by offering tightly derived privacy profiles instead of relying on the numerical experiment method adopted here.\n\nThe paper's \"Privacy Accounting for GG Mechanisms\" relies heavily on numerical experiments without robust error control or rigorous proofs. This methodology is particularly concerning since the privacy profile of this noise family is already well-established in the literature. The paper's focus on a single privacy budget (\\(\\delta=10^{-5}\\)) is both arbitrary and unconvincing. For instance, releasing a \\(10^{-5}\\) portion of the total data satisfies \\(\\delta=10^{-5}\\) with \\(\\epsilon=0\\), making it theoretically superior to all other mechanisms discussed in terms of this metric.\n\nThe experiments (PATE, DP-SGD) conducted under the privacy budget of \\(\\delta=10^{-5}\\) are too limited to convincingly demonstrate the superiority of any specific \\(\\beta\\) values. At this \\(\\delta\\) setting, the noise variance added by the mechanisms varies widely, which is very likely to be the true reason behind the differing outcomes. \n\nFor example. for a fixed \\(\\epsilon\\), the Gaussian mechanism will perform poorly for very small \\(\\delta\\) values as the required variancediverge rapidly. In contrast, for the Laplace mechanism, the scale of the Laplace noise remains approximately unchanged. Conversely, when considering Gaussian Differential Privacy (GDP) as the privacy budget, the Gaussian mechanism generally outperforms the Laplace mechanism. There is no intrinsic advantage or disadvantage for either of these two algorithms; their efficacy largely depends on the specific form of the privacy constraint. The statement \"This provides a justification for the widespread adoption of the Gaussian mechanism in DP learning\" seems coincidental within the scope of this research approach. The preference for the Gaussian mechanism may be more attributed to its strong alignment with GDP accounting, rather than any inherent superiority deduced from the methods used in this research.\n\nIt is incorrect (vastly loose) to compute composition privacy budget from a single pair of epsilon and delta (think about composition of Gaussian mechanisms).\n\n\nIn Section B.2, titled \"Mechanisms with Equivalent Privacy Guarantees,\" the selection of \\(\\sigma\\) is derived through random search, not through analytical computation. This approach does not guarantee the avoidance of numerical stability issues (which is very likely to happen for very small $\\delta$ when using the PRV accountant's random search to determine \\(\\epsilon\\). The method should at least be executed using well-established mechanisms (Gaussian and Laplace) to validate the outputs against their analytically true values.\n\nSome citations in this paper can be improved to be more relevant. For example, (Kairouz, P., Oh, S., & Viswanath, P. (2015)) as optimal compostion for epsilon,delta DP is more suitable than (Abadi et al., 2016) which is not directly related to the topic after definition 4.\n\nThere are some confusions in the proof and presentation (see questions).\nFor example:\nHolder\u2019s Inequality is listed as a lemma\nPage 19: \"As x goes to infinity, the power of the exponent is negative\". It might be better to say \" ... is negative for sufficiently large x in terms of ...\"\nAlso see questions\n\n\n\n\nThere is some broken link (for example, at the beginning of C.6).\n\nKairouz, P., Oh, S., & Viswanath, P. (2015). The composition theorem for differential privacy. In International conference on machine learning (pp. 1376-1385). PMLR.\n\nAwan, J., & Dong, J. (2022). Log-concave and multivariate canonical noise distributions for differential privacy. Advances in Neural Information Processing Systems, 35, 34229-34240."
                },
                "questions": {
                    "value": "What is the purpose for Figure 11? What are the pattens to be shown here?\n\nOn page 23 what does \"bound the probability of not being (\u03f5, 0)-DP\" mean? Being DP or not is an intrinsic property of an algorithm, where does the randomness come from?\n\nWhat is a \"'single composition' of the GG mechanism\"?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3644/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698621415091,
            "cdate": 1698621415091,
            "tmdate": 1699636320336,
            "mdate": 1699636320336,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hhs9N8UCYe",
                "forum": "JG9PoF8o07",
                "replyto": "53BoGISMHq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3644/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3644/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their time and respond to points below (in 2 comments).\n\nThank you for pointing the paper from Awan and Dong (2022) to us, we now incorporate it into the updated paper. Generally we do not believe there are any conflicts between the works; instead both complement each other and point to the same direction \u2013  DP could gain a boost from a correctly tuned noise distribution. More in-detail analysis of the differences is given below:\n* The work by Awan and Dong is both important and very impressive, but our works differ in some key ways. Their work is an important work exploring the theoretical foundations of privacy mechanisms, but does not actually answer the question of what mechanisms are optimal for private machine learning.\n* While Canonical Noise Distributions (CNDs) are a great notion, they are fundamentally a privacy guarantee, and do not make a claim about the utility of a mechanism. Our work looks at the privacy-accuracy tradeoff in machine learning for a family of mechanisms - something otherwise minimally studied. While intuitively it may seem that the CND should be an optimal mechanism because they minimize noise added for a given f-DP trade-off function, this assumes that all parts of the tradeoff functions are equally valuable to the utility. Imagine a utility function that strongly punishes outliers - in that setting, you want a mechanism that minimizes noise above some level, rather than more than one that minimizes total noise. We explore this in Appendix B.5.\n* Proposition 4.2 and Theorem 4.3 only provide CNDs for l_infinity and l_1 bounds (respectively). L_infinity is an uncommon sensitivity, and not used in practice, while our own experiments using multivariate Laplace (GG for beta =1) lead us to believe that l_1 sensitivity with IID noise is suboptimal from an accuracy perspective.  \n* Privacy accounting is critical for tracking privacy during private ML. Their paper does provide theorems for composition of the CND mechanisms in f-DP, however, it remains unclear how to tightly compute the privacy of CNDs to compute an epsilon-delta bound using a known privacy accountant. Our work provides an accountant for each member of the GG family.\n* Subsampling has been critical for making private ML applications work for reasonable privacy budgets. Their work does not directly consider how to compute the proper CND for the subsampled setting, nor how to do privacy accounting for subsampled variants of mechanisms based on CNDs.\n* The two most useful DP formulations are GDP and  F_{epsilon,delta}-DP. However, the paper does not build a CND for F_{epsilon,delta}-DP (Section 4.4) which is usable for ML. Their mechanism does not consider subsampling, and only considers the CND when using l_infinity sensitivity.  \n* They show that for Gaussian-DP, Gaussian mechanisms are CNDs. However, the GDP Accountant can significantly underreport the true \\epsilon (https://arxiv.org/abs/2106.02848), and so unfortunately this does not directly translate into a useful application.\n\n**Below we address other specific comments in the review.**\n\n`` The paper's \"Privacy Accounting for GG Mechanisms\" relies heavily on numerical experiments without robust error control or rigorous proofs.``\n* We address the error of the privacy accountant in Appendix B.3. More specifically, Theorem 6 provides an error analysis of the privacy accountant, which provides an arbitrarily tight privacy accountant. (We set our acceptable tolerance for \\epsilon to be 0.01, and round our reported values up to the nearest 0.01.)\n\n``The paper's focus on a single privacy budget ((\\delta=10^{-5})) is both arbitrary and unconvincing. For instance, releasing a (10^{-5}) portion of the total data satisfies (\\delta=10^{-5}) with (\\epsilon=0), making it theoretically superior to all other mechanisms discussed in terms of this metric\u2026. The experiments (PATE, DP-SGD) conducted under the privacy budget of (\\delta=10^{-5}) are too limited to convincingly demonstrate the superiority of any specific (\\beta) values. At this (\\delta) setting, the noise variance added by the mechanisms varies widely, which is very likely to be the true reason behind the differing outcomes. ``\n\n* We thank you for this comment, we actually run our DPSGD experiments with delta=1e-6. However, it appears that in our paper, we wrote 1e-5 in one place (Appendix E.2), as a vestige of a previous version. We have updated this, thank you for catching this.\n* It\u2019s worth also noting that presenting results for a single choice of delta= 1e-5 is standard for many DPSGD experiments. Two well-cited and well-regarded papers that achieve SOTA results use delta=1e-5 for CIFAR-10  https://arxiv.org/abs/2011.11660  and \u200b\u200bhttps://arxiv.org/abs/2204.13650. \n* Regarding the comment that at this delta, the variance varies widely. We are unsure what the reviewer is referring to, as the PRV accountant is correct to arbitrary precision. \n\n[1/2]"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3644/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700368260298,
                "cdate": 1700368260298,
                "tmdate": 1700368260298,
                "mdate": 1700368260298,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "PPvLyuKNAz",
            "forum": "JG9PoF8o07",
            "replyto": "JG9PoF8o07",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3644/Reviewer_QnfG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3644/Reviewer_QnfG"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the generalized Gaussian mechanism for private machine learning, especially DP-SGD and PATE. The generalized Gaussian mechanism is a mechanism utilizing the generalized Gaussian noise that encompasses Laplace, Gaussian, and arbitrary noise distribution associated with the density function proportional to $e^{-\\frac{|x-\\mu|^\\beta}{\\sigma}}$. The paper investigates the optimal $\\beta$ in the generalized Gaussian in terms of utility-privacy trade-off in DP-SGD and PATE. To this end, the authors proposed $\\beta$-DP-SGD and GGNMax algorithms which are variants of DP-SGD and LNMax by replacing the noise distribution with the generalized Gaussian. The authors show empirically that choosing $\\beta=2$ is near-optimal in test accuracy."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "This paper is well-written and well-organized. I found that investigating the optimal parameter $\\beta$ of the generalized Gaussian mechanism for private ML is interesting and important in ML society. I found that $\\beta=2$ is near-optimal is very interesting, and I think it opens other research directions."
                },
                "weaknesses": {
                    "value": "Generally, I do not see much contribution in this paper. Several things I am concerned about are listed:\n- The proposed mechanisms ($\\beta$-DP-SGD and GGNMax) are a straightforward generalization of the existing mechanisms by replacing noise distribution. \n- The analysis using the PRV accountant is not novel.\n- I felt that there are not many analytical results in the generalized Gaussian mechanisms. Most of the results are empirical findings, and I doubt that the experiments are sufficient to claim the findings."
                },
                "questions": {
                    "value": "Main questions:\n1) Is Theorem 1 saying there exists $\\epsilon$ and $\\delta$ for $(\\epsilon,\\delta)$-DP? Isn't it obvious that every mechanism has $\\epsilon=1$ and $\\delta=1$ if I am not mistaken?\n2) For \"However, unlike the results ... larger than $\\beta>3$\" on page 8, is there any reason why this happens?\n3) If I am not mistaken, the comparisons regarding $\\beta$ are done after hyper-parameter optimization. If they are, I have some questions:\n- Is it reasonable to perform the comparison by fixing hyperparameters that are optimal in non-DP training? \n- For fixed hyperparameters, $\\beta=2$ is still near-optimal? or is it dependent on hyperparameters?\n\nSome minor questions are as follows:\n1) In the caption of Figure 4, it is written that the reported three epsilons are based on the minimum epsilon giving $0.98$ accuracy. Why then the accuracy is much worse than $0.98$ in the plots even for $\\epsilon^\\prime$?\n2) Renyi DP is defined in the main paper but is not used as a main part after that. Is there any reason for defining it in the main paper?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3644/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3644/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3644/Reviewer_QnfG"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3644/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698703759740,
            "cdate": 1698703759740,
            "tmdate": 1699636320227,
            "mdate": 1699636320227,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SGXAYe0f9E",
                "forum": "JG9PoF8o07",
                "replyto": "PPvLyuKNAz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3644/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3644/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their time and comments. We respond to questions and weaknesses, separately below, starting with the questions. (We respond in 2 parts)\n\n``Is Theorem 1 saying there exists eps  and delta  for (eps,delta)-DP? Isn't it obvious that every mechanism has eps=1 and delta = 1  if I am not mistaken? ``\n* You are correct that if delta is allowed to be 1, then all mechanisms are (epsilon, delta)-DP; however Theorem 1 states that there is an epsilon value for any choice of beta, sigma, and delta. While this seems intuitive in some cases it is certainly not true for all algorithms, and this precondition is a prerequisite to using the PRV Accountant. As an example, a mechanism that runs the \\epsilon-DP Laplace mechanism with probability 0.9, and with the remaining 0.1 probability returns the non-noisy answer is (\\epsilon, \\delta)-DP for some \\delta, but not for any delta < 0.1.\n\n``\"However, unlike the results\u2026. larger than beta> 3 \" on page 8, is there any reason why this happens?``\n* First, we emphasize that the label accuracy decline is on the order of ~0.1%, and so this is not a significant drop. The drop is most noticeable specifically because of how little variance there is in the label accuracy across values of \\beta. That said, we believe the drop is due to an artifact of how the mechanisms of equivalent DP guarantees are generated. To describe it in detail: first we add noise from an evenly distributed grid of \\beta \\in [1,4] and \\sigma \\in [0.01,7] values, and then we compute the privacy levels for those (\\beta,\\sigma) tuples and compute the corresponding mechanisms of approximately equal DP guarantees. Because of this, we overestimate \\epsilon when solving for mechanisms with equivalent DP guarantees; this is most noticeable for larger choices of \\beta, where the same difference in \\sigma contributes to a larger \\epsilon.\n\n``Is it reasonable to perform the comparison by fixing hyperparameters that are optimal in non-DP training? ``\n* Previous work has shown that hyperparameters which are optimal in non-DP training are not necessarily optimal for DP training. This was explored in this work https://arxiv.org/abs/2007.14191, and a later work https://arxiv.org/abs/2110.03620 produced a scheme for how to do privacy preserving hyperparameter tuning. \n\n``For fixed hyperparameters, beta=2  is still near-optimal? or is it dependent on hyperparameters?``\n* In general, it is near optimal, but it does depend on the hyperparameters, we provide plots for this in Appendix E.3.\n\n[1/2]"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3644/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700368709569,
                "cdate": 1700368709569,
                "tmdate": 1700368709569,
                "mdate": 1700368709569,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hHmyKyRCBn",
                "forum": "JG9PoF8o07",
                "replyto": "PPvLyuKNAz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3644/Reviewer_QnfG"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3644/Reviewer_QnfG"
                ],
                "content": {
                    "comment": {
                        "value": "Thank the authors for the detailed response to my questions. I have a better understanding of your work now. The motivation and investigating the optimized $\\beta$ in the GG mechanism are interesting and meaningful.\nNevertheless, I still doubt if this paper is an ICLR-quality paper. The main reason is the lack of theoretical or rigorous supporting evidence for the claim ($\\beta=2$ is near optimal). I understand that the analysis of the generalized GG mechanism on DP-SGD is quite problematic. However, even the empirical results in the paper are not sufficient in my opinion. For such a reason, I maintain my score."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3644/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700632052248,
                "cdate": 1700632052248,
                "tmdate": 1700632147814,
                "mdate": 1700632147814,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "try5J22OEa",
            "forum": "JG9PoF8o07",
            "replyto": "JG9PoF8o07",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3644/Reviewer_7vy3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3644/Reviewer_7vy3"
            ],
            "content": {
                "summary": {
                    "value": "This paper takes a deeper look at the generalized Gaussian mechanism.\nThe first contribution is to extend the privacy proof of the GGM to work with the PRV accountant to allow tighter analysis than previous bounds. \nThey then plug the mechanism into various ML applications and observe the effect of varying beta on accuracy.\nIn general, they find support for using the Gaussian mechanism, but also that more fine-tuned versions of beta (fractional values) can lead to slight improvements in accuracy."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Even though the results didn't yield significant changes while varying beta, I see great value in a study that supports the approximate optimality of the Gaussian mechanism. In general, there are so many hyperparameters to tune, so giving practitioners support in using the Gaussian mechanism as a default is useful.\n- Very well-written paper with clear descriptions."
                },
                "weaknesses": {
                    "value": "- Claiming STOA with three runs: The results on machine learning had quite a high variance due to limited runs. I think claiming STOA when the accuracy is better by such a small amount is not significant. Perhaps more runs and a hypothesis test/confidence interval would give more definitive results (although STOA is not the primary goal of the work).\n\n- One more hyperparameter: the very small gains in accuracy would surely be outweighed by the cost of tuning beta in practice. I see the main contribution of this work is showing that the beta doesn't have too much effect rather than improving the accuracy of current mechanisms. \n\n### Typos\n- End of Section 3.2, last paragraph \"change subsequently change\".\n- A.1 Proof of theorem 4 has a missing ref.\n\n### Note\nI did not verify the proofs in this paper as I do not have sufficient theoretical background. I apologize that I have to leave this task to my fellow reviewers."
                },
                "questions": {
                    "value": "- What would be the solution to fix the artifacts in Figure 3? Perhaps more values in the grid?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3644/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3644/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3644/Reviewer_7vy3"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3644/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698772999149,
            "cdate": 1698772999149,
            "tmdate": 1699636320135,
            "mdate": 1699636320135,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8WfdmYTfTM",
                "forum": "JG9PoF8o07",
                "replyto": "try5J22OEa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3644/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3644/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the thorough comments and the kind words. We address the weaknesses stated in the review below:\n\n* Regarding the state-of-the-art results: as you stated, achieving state-of-the-art was not the primary goal of the work, and rather only a baseline to compare against; given this goal, we found that 3 runs were sufficient because the resulting standard deviations in nearly every case was less than 0.3%. \n* We agree that this is one more hyperparameter to tune, and generally agree that \u201cI see the main contribution of this work is showing that the beta doesn't have too much effect rather than improving the accuracy of current mechanisms.\u201d We also agree, as you state, that \u201cthere are so many hyperparameters to tune, so giving practitioners support in using the Gaussian mechanism as a default is useful.\u201d\n\nWe have addressed the typos, thank you for pointing those out.\n\nThank you very much for your time and comments."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3644/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700368830720,
                "cdate": 1700368830720,
                "tmdate": 1700368830720,
                "mdate": 1700368830720,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "2CsRVJT5H4",
            "forum": "JG9PoF8o07",
            "replyto": "JG9PoF8o07",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3644/Reviewer_aH3Q"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3644/Reviewer_aH3Q"
            ],
            "content": {
                "summary": {
                    "value": "In differential privacy literature, most papers focus on either Laplace or Gaussian Mechanism due to the simplicity of analysis and proven effectiveness in practice. This paper studies the Generalized Gaussian Mechanism instead. It shows that the mechanism is differentially private and through experiments on common benchmarks, it also shows the effectiveness of the mechanism on deep learning tasks."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper provides some empirical evidence on why Gaussian Mechanism is popular. In their experiments, the model usually achieves the best accuracy when the noise added is roughly Gaussian.\n\n- The Generalized Gaussian Mechanism can be useful for tasks that require very high accuracy. By tuning the $\\beta$ carefully, it's possible that the model can achieve better results (as shown by some improvements on cifar10 tasks).\n\n- The paper is well-written overall."
                },
                "weaknesses": {
                    "value": "- The experiments are conducted on fairly small datasets and deep learning architectures so it's hard to get a grasp of how well the generalized gaussian mechanism works. \n\n- While the study is fairly interesting, I'm not sure if the technical contribution is enough. The main takeaway is Gaussian and Laplace are pretty much the best choices as expected. Generalized Gaussian Mechanism is fairly hard to analyze since it doesn't have a closed-form relationship between $\\beta$ and $\\epsilon, \\delta$. The experiment also requires the tuning of $\\beta$ which in the end ends up being Gaussian and Laplace mechanism anyway."
                },
                "questions": {
                    "value": "- In page 18, I think the RHS should be $(\\frac{\\alpha-1}{\\alpha})^{1/\\beta}$?\n\n- Also as $x<0$, shouldn't $\\frac{|x|}{|x-\\mu|}$ be $\\frac{-x}{\\mu-x}$ instead? Fortunately, I don't think it affects the argument."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3644/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698786810369,
            "cdate": 1698786810369,
            "tmdate": 1699636320055,
            "mdate": 1699636320055,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "nX2ZPL0uWz",
                "forum": "JG9PoF8o07",
                "replyto": "2CsRVJT5H4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3644/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3644/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their response. We appreciate your feedback. Below we respond to the weaknesses stated in the review. \n\n``The experiments are conducted on fairly small datasets and deep learning architectures so it's hard to get a grasp of how well the generalized gaussian mechanism works.``\n*  Unfortunately current research on private machine learning is still developing techniques for accurately training on larger datasets. The error contributed by differential privacy scales with dimension (https://arxiv.org/pdf/2106.00001.pdf), and larger datasets tend to require larger models to perform well. This is evidenced by the fact that the state-of-the-art results for CIFAR-10 are still below 70% accuracy for epsilon =1 (which is often considered an acceptable privacy risk).\n\n``While the study is fairly interesting, I'm not sure if the technical contribution is enough``\n* Prior to our work, very little research has explored alternative differential privacy techniques for private machine learning. One notable exception is the Cactus mechanism (https://arxiv.org/abs/2207.00420), however, it is not implementable for models with a large number of parameters (>40). As far as we are aware, no work exists even considering Laplace noise for DP-SGD. Yes, our work finds that the Gaussian mechanism is close-to-optimal for the family of privacy mechanisms we explore. However, we emphasize our other contributions:\n    * We provide the first exploration of DP mechanisms outside of the Gaussian Mechanism for DPSGD for private ML and provide a practical implementation of this mechanism for private ML.\n    * We provide a framework for comparing Laplace and Gaussian mechanisms, as well as how to use existing privacy accountants for arbitrary mechanisms.\n    * To us, the authors, it is exceedingly surprising that the Gaussian Mechanism performs close to optimally. It\u2019s hard to apply a historical rationale for why previous researchers only considered the Gaussian mechanism, but it seems likely that this is because they were familiar with it mathematically, and it has nice properties for computing integrals. However, neither of those two reasons are any reason why the Gaussian mechanism (out of the infinitely many other possible mechanisms) should perform optimally. As a field, we have explored very little of the space of potential DP mechanisms, and to find that one of the two original mechanisms were in fact near optimal, is at the very least surprising. \n    * In our exploration we provide a _mostly_ negative result, that researchers should mostly not explore other unimodal DP mechanisms for DPSGD. While positive results are easier to accept, a negative result (that Gaussian noise performs near-optimally) is nonetheless a significant step forward in our understanding of privacy-accuracy tradeoffs in machine learning.\n\nRegarding your questions - yes, we believe you are correct, and we have updated it accordingly. As you noted, we also find that this does not change the argument.\n\nThank you very much for your time and comments."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3644/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700369007623,
                "cdate": 1700369007623,
                "tmdate": 1700370205245,
                "mdate": 1700370205245,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]