[
    {
        "title": "Dream to Adapt: Meta Reinforcement Learning by Latent Context Imagination and MDP Imagination"
    },
    {
        "review": {
            "id": "FG8xUdgxQ5",
            "forum": "FLOaCQfZe9",
            "replyto": "FLOaCQfZe9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6079/Reviewer_Jvj1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6079/Reviewer_Jvj1"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes to augment meta-RL with task imagination. By learning a better task representation space and interpolating meta-training task encodings, the authors claim to improve over PEARL on several environments."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. Task imagination is an important topic in meta-RL.\n2. The idea of integrating Dreamer into meta-RL is interesting.\n3. The experiment results show that MetaDreamer is able to greatly outperform PEARL."
                },
                "weaknesses": {
                    "value": "Overall, the paper needs major revision in presentation. The novelty is not clearly presented, and its connection with Dreamer is confusing. Below are my detailed comments.\n\n1. Please use the right style for citations. As instructed in the style files, use \\citep to include the citations in parenthesis.\n2. Calling the method MetaDreamer is confusing. The major contribution of Dreamer to model-based RL is its ability to directly compute gradients through the dynamics model to optimize policies. However, MetaDreamer seems only to use the model to collect datasets, and does not pass gradients through the model. So it might not be appropriate to call it a meta-RL version of Dreamer.\n3. Novelty is not clear. Section 4.1 emphasizes that MetaDreamer uses \\beta-VAE. However, \\beta-VAE is a common trick used in PEARL, as it also adjusts \\beta as a hyper-parameter. Moreover, using GRU as task encoders and decoupling task encoding and policy learning by decoding task rewards and dynamics is also not novel. They are techniques used by VariBAD[1], another SOTA meta-RL algorithm.\n4. The presentation needs improvement. The \"Meta-imagination by sampling the latent context space\" paragraph in Section 4.2 is confusing. I roughly understand that the authors interpolate different dimensions of the task encodings, but Eq.2 is really confusing. I advise the authors to re-construct the math expressions, E.g. the notations $M,K,f(M)$ are not clearly defined.\n5. The clustering loss in Section 4.3 is not clearly explained. This clustering loss seems a bit novel, and I think the authors should emphasize this clustering loss in earlier sections like the introduction. There is also a lack of ablation studies to discuss the importance of this loss. Will simply adding this loss to PEARL improve performance?\n6. Experiment results are not convincing. Although MetaDreamer seems to outperform PEARL, it utilizes extra physics knowledge of the environment, which is not fair for PEARL and MAML. Also, there lack ablation studies to discuss the importance of MetaDreamer's components. I also expect to see results on more complex tasks like Meta-World.\n\n[1] Zintgraf, Luisa, et al. \"Varibad: A very good method for bayes-adaptive deep rl via meta-learning.\" arXiv preprint arXiv:1910.08348 (2019)."
                },
                "questions": {
                    "value": "Please refer to the weakness part. I think a re-organization of the paper, as well as more experimental results will significantly improve the paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6079/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6079/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6079/Reviewer_Jvj1"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6079/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697786796546,
            "cdate": 1697786796546,
            "tmdate": 1699636655082,
            "mdate": 1699636655082,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "M7Vh8HiWyb",
            "forum": "FLOaCQfZe9",
            "replyto": "FLOaCQfZe9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6079/Reviewer_xXsW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6079/Reviewer_xXsW"
            ],
            "content": {
                "summary": {
                    "value": "The study introduces a Meta-RL algorithm named MetaDreamer, that aims to enhance generalization to unseen tasks. This is achieved through the preliminary training of the agent, utilizing simulated tasks created by interpolating between acquired latent contexts. The performance of MetaDreamer is assessed through its application in scenarios such as a highway-merging task and various MuJoCo tasks. The results are presented with a comparison to baseline performances, indicating a relative improvement in the capabilities of MetaDreamer."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "**Strength 1.**\n\nThe primary innovation of this paper resides in its introduction of physics-guided generative models within the realm of reinforcement learning (RL). This approach necessitates a degree of pre-existing knowledge concerning the dynamics of the tasks at hand, yet it is a reasonable presumption that such information pertaining to physical dynamics is readily accessible for the majority of environments. The incorporation of relevant, physics-informed concepts into machine learning showcases a significant intertwining of these disciplines within the RL framework, highlighting both the novelty and the importance of this development."
                },
                "weaknesses": {
                    "value": "**Weakness 1: Need for Enhanced Clarity and Precision**\n\nThis paper would benefit significantly from improvements in clarity across several sections, necessitating comprehensive revision in certain areas.\n\n- The section concerning related work could be more effectively structured. Presently, it poses some challenges in interpretation due to the way the context and citations are presented. A clearer demarcation between different works cited, perhaps through the use of spaces or commas, would greatly enhance readability and comprehension.\n\n- Precision and consistency in the use of notations and equations need attention. Currently, there seems to be some inconsistency in symbols, evidenced by the interchangeable use of $\\phi$ and $\\theta$ in Equation 1, Equation 4, Figure 2, and the introductory portion of Section 4.3. Clarifying these notations would significantly improve the paper's technical precision.\n\n- Attention to detail could further be improved by rectifying typographical errors scattered throughout the text. An instance of this is the term 'MPD' found on page 8, presumed to be a typo. \n\n\n**Weakness 2: Clarification of Contribution Required**\n\nThe paper would benefit from a more precise delineation of the authors' contributions, particularly within Section 4, which is integral to understanding the novelty of the work presented.\n\nThe narrative regarding the unique contributions of this research becomes somewhat obscured, especially in the third paragraph of Section 4. Here, the incorporation of elements such as the GRU encoder and the dynamics decoder, recognized components from VariBAD, alongside the concept of imagined dynamics from LDM, are noteworthy. However, these inclusions call for a clearer distinction between what the present work originates and what it adapts from existing methodologies.\n\nThe elements of originality appear to concentrate on the introduction of the disentangled context in Section 4.1 and the physics-informed generative models in Section 4.2. These are indeed significant contributions; however, their impact and the extent of their innovation could be overshadowed by the lack of clear differentiation from prior works.\n\nTo strengthen the academic rigor and originality of the paper, it is highly recommended that the authors carefully revise the method section. A more distinct separation between the novel contributions of this paper and the methodologies and concepts borrowed from previous works would enhance the readers' comprehension of the value and innovation this study offers. This clarity is not just a matter of academic precision but also of intellectual honesty and contribution to the field.\n\n\n**Weakness 3: Areas for Improvement in Empirical Evaluation**\n\nThe empirical evaluation section of the paper presents several opportunities for enhancement that would substantially solidify the work's contributions.\n\nGreater emphasis on reproducibility is essential. The current manuscript could significantly benefit from a more detailed presentation of the experimental setup and, importantly, the inclusion of source code. These additions would greatly aid peers in replicating and verifying the results.\n\nThe breadth of comparative analysis could be expanded. While the work's assessment includes comparisons with certain methods, the selection seems somewhat narrow. For instance, in the highway merging task and the MuJoCo tasks, the analysis includes MAML and PEARL but would be enriched by considering other recent relevant baselines like VariBAD, which shares considerable similarities with the approach.\n\nThe robustness of empirical conclusions in reinforcement learning, and Meta-RL in particular, often hinges on the ability to replicate results across multiple trials. The current reliance on results from three random seeds may not suffice to construct a reliable empirical foundation. It would be highly advisable for the authors to expand this aspect by utilizing a broader range of seeds, perhaps 8 to 10, thereby enhancing the statistical reliability and validity of the conclusions, especially considering the empirical nature of this study."
                },
                "questions": {
                    "value": "Question 1: The autonomous driving experiment showcased in Section 5.1 is indeed inspiring, effectively illustrating an application for the physics-informed decoder. Could you suggest any other benchmarks or scenarios where the proposed method has the potential to be particularly advantageous?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6079/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6079/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6079/Reviewer_xXsW"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6079/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698219917272,
            "cdate": 1698219917272,
            "tmdate": 1699636654978,
            "mdate": 1699636654978,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "uoTI3Ltvzq",
            "forum": "FLOaCQfZe9",
            "replyto": "FLOaCQfZe9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6079/Reviewer_iZ95"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6079/Reviewer_iZ95"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a variant of the PEARL meta-RL algorithm that differs in three ways:\n(1) The context variable is computed using a VAE, i.e., a prior is imposed on the context variable, in the hopes that this produces a disentangled representation for the context variable.\n(2) Rollouts from the policy can be simulated by knowing the semantic meanings of each dimension of the state and then applying physical laws to get the next state from an application of an action. For example, knowing that certain dimensions of the state represent velocity or acceleration, physical laws are used to relate the two.\n(3) Contexts for \"imagined\" new tasks can be generated by interpolating the context variables computed on existing training tasks.\n\nThis work performs experiments on a Highway task and several MuJoCo tasks with the resulting algorithm. The proposed algorithm appears to perform favorably compared to PEARL and MAML."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "This work attempts to extend PEARL in directions that are quite natural: e.g., to better handle generalization to new tasks, and potentially obtain better context variables."
                },
                "weaknesses": {
                    "value": "This work could make significant improvements in the following areas:\n\n*Presentation*:\n- This work is difficult to read and reproduce due to its presentation.\n- From a high-level, there are two main issues with the presentation:\n- (a) This work does not outline the problems it aims to solve, and hence cannot show that these problems really exist and that the work indeed solves them. Instead, we must rely on results on tasks that have already been previously solved to evaluate the algorithm's contribution (more on this below).\n- (b) This work presents its ideas at both extremely high vague levels (e.g., see intro paragraph 1, 2; 4.1: disentangled latent context space; 4.2 first para of \"meta-imagination ...\") and extremely detailed levels, with nothing in between, leaving the reader to fill in the gaps for what these vague statements precisely mean. The high-level vague claims are often ungrounded or unsubstantiated. The detailed levels also often leave terms undefined or defined with insufficient precision (e.g., f_\\theta in Eq (1), Z_k in 4.2 [these seem to be \\tau-dim vectors?]; z_{i, j} in Eq (2)). They also appear to be ad-hoc or insufficiently justified. For example, why should interpolating context vectors in Eq (2) be sensible, and in what way do we expect it to be useful?\n\n*Technical rigor / precision / correctness*\n- Beyond the notational issues described above, there are also areas that appear to simply be incorrect or misleading.\n- In the experiments, why are there modifications to the Walker environment compared to the basic one? The original PEARL paper appears to report stronger results than what this work is reporting on Walker (though it appears to be modified). Additionally, VariBAD reports results that are even better than PEARL. It seems like the VariBAD paper is reporting results that are stronger than what are reported in this paper, though it would be good to see a direct head-to-head comparison.\n- Equation (1) appears to be incorrect. I believe that D^{ts} and D^{tr} have been swapped in the equation, where typically you do training on the meta-training dataset D^{tr}, followed by evaluation on the meta-testing dataset D^{ts}, and take your gradients w.r.t. that.\n- What is the justification behind making the context variables disentangled with a VAE? Using the context variables to predict the next state and rewards as in VariBAD seems much more principled, since this helps you obtain the sufficient statistics for solving the task. On the other hand, I don't clearly see why we should expect applying a VAE should help with better Thompson-Sampling under a PEARL-like approach.\n- Additionally, note that while hard-coding physical laws is a completely reasonable thing to do for generating new simulated trajectories, this seems to be identical to just supporting it under the simulator. This approach also does not nicely generalize to new domains, especially those with pixel inputs, where the dimensions of the state are less easily manipulatable."
                },
                "questions": {
                    "value": "See questions in previous section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6079/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698792246112,
            "cdate": 1698792246112,
            "tmdate": 1699636654869,
            "mdate": 1699636654869,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "vmEiIO8tp1",
            "forum": "FLOaCQfZe9",
            "replyto": "FLOaCQfZe9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6079/Reviewer_eJ5U"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6079/Reviewer_eJ5U"
            ],
            "content": {
                "summary": {
                    "value": "The submission proposes a meta-RL framework, MetaDreamer, designed to improve generalization and sample efficiency compared to previous works.  \nMetaDreamer learns disentangled task latent space and generative models of trajectories, then uses them to augment new tasks and trajectory data for each task.  \nPhysics-related inductive bias is imployed to improve the training of the task encoder and decoder models.  \nExperimental results suggest that MetaDreamer demonstrates better sample efficiency and generalization performance than previous meta-RL methods in Highway-merging and Mujoco control domains."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The idea of augmenting both tasks and trajectory data has not been explored in previous works and is technically challenging.\n- Experimental results demonstrate promising sample efficiency and generalization capabilities compared to existing meta-RL methods."
                },
                "weaknesses": {
                    "value": "**Essential baselines are missing**  \nThe provided set of experiments only presents evaluation results for PEARL and MAML without task interpolation or physics-informed encoder-decoder structure.\nWhile the potential benefits of the proposed model over existing works involving task interpolation (ex. LDM [1]) or task encoding using inductive bias (ex. VariBad [2] + physics-informed encoder-decoder structure) are intuitively understandable, there is a lack of empirical comparisons.\nFurthermore, as the proposed method incorporates several incremental modification from previous works (beta-VAE, task interpolation, data augmentation, and physics-based inductive bias), it remains unclear which specific modification or combination thereof contributes to the observed improvement over meta-RL methods without those modifications.\n\n**Presentation has room for improvement**  \nSome flaws of writings make hard to understand their approach:\n- Figures 2 lacks explanations for indicators 1 to 3.\n- Section 4.2 notations lack critical details, thus hard to follow. For examples :\n  - $Z_i$ is not defined.\n  - Notation in $z_{f(k), i-1}$ is not explained.\n- The approach to the physics-informed generative model is not sufficiently explained in any part of the paper. Section 4.2 provides limited detail and focuses on one specific domain.\n- Section 1 - \"... without additional test-time adaptation...\" - seems to be inaccurate on my understanding. The proposed work has a same test-time adaptation procedure as PEARL, and the imagination is done during meta-training.\n- In Figure 7,\n  - the final performance does not align with actual final value of each graph\n  - it is not clear how many runs were averaged for each graph\n- Citation formatting substantially harms readability\n\n[1] Improving Generalization in Meta-RL with Imaginary Tasks from Latent Dynamics Mixture. Lee and Chung. NeurIPS 2021.  \n[2] VariBAD: A Very Good Method for Bayes-Adaptive Deep RL via Meta-Learning. Zintgraf at al. ICLR 2020."
                },
                "questions": {
                    "value": "It appears that the Walker-2D domain may be susceptible to compounding errors when generating 300-timestep length rollouts from initial states. Would it be possible to provide a qualitative visualization of the generated observations from the Walker-2D domain to show whether the generated observations align with provided tasks?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6079/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6079/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6079/Reviewer_eJ5U"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6079/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699360158891,
            "cdate": 1699360158891,
            "tmdate": 1699636654769,
            "mdate": 1699636654769,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]