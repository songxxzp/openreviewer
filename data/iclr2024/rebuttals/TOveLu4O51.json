[
    {
        "title": "Parameter-Efficient Detoxification with Contrastive Decoding"
    },
    {
        "review": {
            "id": "fAikYWnfQI",
            "forum": "TOveLu4O51",
            "replyto": "TOveLu4O51",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3044/Reviewer_qHFk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3044/Reviewer_qHFk"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a parameter efficient decoding time detoxification algorithm. The use a detoxifier, which is another generator that is finetuned on toxic data, to detect the toxic tokens and discount those generations by modifying the probability distribution of the generator. They show good detoxification results on the RealToxicityPrompts benchmark."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper is well written and it is easy to follow.\n- The detoxification results on RealToxocityPrompts is very good.\n- Ablation studies on the model size is interesting."
                },
                "weaknesses": {
                    "value": "- The authors claim that they  \"are the first to apply parameter-efficient learning to controllable text generation for detoxification\". However, there has been other work (such as \"\"Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models\" by Wang et al) that use PEFT.\n- One of the disadvantages of the proposed method is the cost as it needs both the generator as well as the detoxifier to do inference. The authors do not address this fact when they compare to other methods.\n- The effect on fluency, measured by perplexity has been evaluated only on the RealToxicityPrompt dataset. A more diverse set will show boarder impact. \n- The effect of the proposed approach on downstream tasks is not studied and it is not clear how the performance is affected."
                },
                "questions": {
                    "value": "- In Table 1, what are the perplexity for the original model (alpha = 0)?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3044/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3044/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3044/Reviewer_qHFk"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3044/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699221695319,
            "cdate": 1699221695319,
            "tmdate": 1699636249876,
            "mdate": 1699636249876,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8oSR3oweI1",
                "forum": "TOveLu4O51",
                "replyto": "fAikYWnfQI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3044/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3044/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer qHFk"
                    },
                    "comment": {
                        "value": "We thank the reviewer for considering our paper well-written and the model performance very good.  We also appreciate the reviewer for noting that our ablation study on model size is interesting.\n\n\n* By using both the generator and the detoxifier during inference, the cost is higher as compared to other methods\n\nWe respectfully disagree. In fact, cost is our approach\u2019s strength rather than a weakness. Here we will compare our GPU memory usage and inference latency with the two top-performing baselines, namely GeDi or DExperts:\n(1) Our GPU memory usage is only around a third of the baselines because our detoxifier is trained with a parameter-efficient method and shares exactly the same backbone parameters as the generator (i.e., the LLM). This is different from the baselines which need to train an expert and an anti-expert LM of opposing attributes with full finetuning.\n\n(2) Our inference latency is only two-thirds of the baselines because our detoxifier only needs to rely on the toxic part of the training data. Hence instead of running the LLM three times for each prompt during inference (one for the LLM itself, one for the expert LM, and one for the anti-expert LM), our method only runs twice because there is no anti-expert involved.\n\nWe sincerely hope that this detailed explanation alleviates the cost concern that may have negatively and greatly impacted our score.\n\n\n* In Table 1, what is the perplexity for the original model (alpha = 0)?\n\nThat would be column 1 in Tables 6 and 7, where we present results with the vanilla generator (i.e., without the detoxifier).\n\n\n* Previous work has applied parameter-efficient learning to detoxification\n\nThank you for pointing this out. Indeed Wang et al. (2022) applied parameter-efficient tuning to detoxification. We have toned down our claim in the revision. We do note a key difference though that their work assumes access to the Perspective API during training, while our work and the baselines we compare with do not, making the results not comparable to each other. \n\n\n* Evaluate the framework on more benchmark datasets and downstream tasks\n\nWe selected the current evaluation benchmark because it makes it easier to compare with previous work that also focused on the same dataset. That said, we do agree that more benchmarks and downstream tasks can shed more light on the effectiveness of our approach."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700618488703,
                "cdate": 1700618488703,
                "tmdate": 1700618488703,
                "mdate": 1700618488703,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "0926zyyUVt",
            "forum": "TOveLu4O51",
            "replyto": "TOveLu4O51",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3044/Reviewer_EV4t"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3044/Reviewer_EV4t"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new way to detoxify language models using contrastive decoding, where the output probabilities of the base language model are negated by the probabilities of a language model trained on toxic data. The authors show that their techniques outperform a number of detoxification baselines for both toxicity reduction and fluency."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The authors show that their technique enables toxicity reduction at many model sizes and for both GPT-2/LLaMA model families\n* The technique is relatively straightforward and efficient"
                },
                "weaknesses": {
                    "value": "* The method seems like a pretty minor change from Liu et al 2021's DEXPERTS. As the authors note, their technique operate on the probabilities space, while the DEXPERTS technique operates in logits. Other than that, I can't find much difference. Their technique provides what looks like small gains over the DEXPERTS technique under their metrics. I would appreciate more analysis for why their formulation is preferable over DEXPERTS, and in which cases DEXPERTS might fail that their method would not.\n* I would appreciate more qualitative examples of detoxification in the paper.\n* I do not see mention of code release.\n* Is perplexity the best measure of fluency? I would expect to see some human evaluations of generated text to confirm. \n* I am not sure if most readers are familiar with the \"Distinct-2/3\" metrics of diversity, I would appreciate a brief explanation of this metric in the paper."
                },
                "questions": {
                    "value": "Please see weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3044/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699565856339,
            "cdate": 1699565856339,
            "tmdate": 1699636249779,
            "mdate": 1699636249779,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "yrJnk9UcCW",
                "forum": "TOveLu4O51",
                "replyto": "0926zyyUVt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3044/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3044/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer EV4t"
                    },
                    "comment": {
                        "value": "We thank the reviewer for agreeing that our work leverages straightforward and efficient techniques and outperforms previous baselines.\n\n\n* DetoxiGen is the same as DExperts other than operating on the probability space\n\nWe respectfully disagree. Operating on the probability space is only the difference between DetoxiGen and DExperts during inference. As summarized in the last paragraph of the Introduction section, there are two more major differences: (1) training efficiency: DetoxiGen adopts parameter-efficient training of the detoxifier while DExperts requires a full-finetuning of the language model; (2) data efficiency: DetoxiGen only requires training on the toxic data alone, where DExperts necessitates the use of non-toxic data as well.\n\nWe sincerely hope that this detailed explanation alleviates the novelty concern that may have negatively and greatly impacted our score.\n\n\n* The approach overperforms previous work by a small margin\n\nWe respectfully disagree. As Reviewer FrfU and qHFk both noted, our approach achieved superior performance over baselines. In terms of Avgerage Maximum Toxicity, we brought previous state-of-the-art from 0.314 all the way down to 0.254 with the same backbone model and data. This is an even bigger gap than that between GeDi and DExperts, not to mention that the lower the toxicity baseline, the harder it is to make any improvements.\n\n\n* No mention of a code release\n\nWe thank the reviewer for bringing this up. We promised code release on Page 4 Footnote 1, and we have initiated the application process to open-source this project through our institution. We have migrated this footnote to page 1 in the revision to make it more salient.\n\n\n* Qualitative examples of detoxification\n\nWe thank the reviewer for the suggestion. We did not include the qualitative examples due to ethical concerns as the outputs without detoxification could seem very offensive to the readers. In our code release, we plan to provide some sample toxicity-inducing prompts and include instructions for researchers and practitioners to compare the difference in outputs.\n \n\n* Effectiveness of perplexity as a measure of fluency\n\nWe agree that perplexity alone may favor models that output generic, dull continuations that lead to low perplexity. That is the motivation that our work and previous baselines add the diversity metrics as a sanity check.\n\n\n* A detailed explanation of Distinct-N metrics\n\nWe thank the reviewer for the suggestion. We did not elaborate on the Distinct-N metrics due to space constraints. We have added the details in the revision."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700618073789,
                "cdate": 1700618073789,
                "tmdate": 1700618073789,
                "mdate": 1700618073789,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "4jqF6hxRgM",
            "forum": "TOveLu4O51",
            "replyto": "TOveLu4O51",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3044/Reviewer_9Tow"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3044/Reviewer_9Tow"
            ],
            "content": {
                "summary": {
                    "value": "The authors use a variant of contrastive decoding to generate non-toxic text. They do this by contrasting the outputs of the *generator* model with the *detoxifier* model which is soft-prompted to produce toxic text."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Originality: though this paper is not particularly original in its methods: it uses established NLP methods (contrastive decoding, soft-prompt tuning), it does apply them to non-toxic text generation which is fairly original.\nQuality: The experiments and idea are straightforward and simple. I view this as a strength, since anything more elaborate would only muddy the waters.\nClarity: the paper itself is quite clearly presented, and I did not find any parts confusing.\nSignificance: Since the methods used are simple and general and the application useful, I think the proposed method has the potential to have significant impact."
                },
                "weaknesses": {
                    "value": "While I respect the author's choice of sticking to a small set of reasonably chosen design decisions, I would have liked to trade some of the comprehensiveness on the model-size experiments for a broader look at some other hyperparameters, such as the method for creating the *detox* model (there are both more effective efficient fine-tuning methods like LoRA, and cheaper, more straightforward non-fine-tuning methods like plain-old prompting)."
                },
                "questions": {
                    "value": "No major questions."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3044/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699587681682,
            "cdate": 1699587681682,
            "tmdate": 1699636249698,
            "mdate": 1699636249698,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mgD2Lp5mDM",
                "forum": "TOveLu4O51",
                "replyto": "4jqF6hxRgM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3044/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3044/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 9Tow"
                    },
                    "comment": {
                        "value": "We thank the reviewer for considering our work to have the potential to have a significant impact by introducing a straightforward and simple approach in a well-presented paper.\n\n* Explore other parameter-efficient tuning methods such as LoRa\n\nWe went with Prompt Tuning as it is a more straightforward parameter-efficient approach that requires no change in model architecture (other than the few additional parameters from the soft token embeddings). That said, we agree that LoRa would be a nice baseline to compare with as part of the ablation studies. As the reviewer mentioned, due to space constraints, there is a trade-off on what studies to focus on \u2014 we figured that the experiments on model sizes would be very helpful for the audience to make design choices when applying our work."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700618024432,
                "cdate": 1700618024432,
                "tmdate": 1700618024432,
                "mdate": 1700618024432,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RTiRp9uZpm",
                "forum": "TOveLu4O51",
                "replyto": "mgD2Lp5mDM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3044/Reviewer_9Tow"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3044/Reviewer_9Tow"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your reply. I don't see any need to change my evaluation."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700678666905,
                "cdate": 1700678666905,
                "tmdate": 1700678666905,
                "mdate": 1700678666905,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "R6zdMSYKCQ",
            "forum": "TOveLu4O51",
            "replyto": "TOveLu4O51",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3044/Reviewer_FrfU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3044/Reviewer_FrfU"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduce a contrastive decoding methods with prompt tuning, which requires less parameters and performs better than a lot of works in the filed based on the result from realtoxicityprompts benchmark. The approach only requires toxic examples to train the detoxifier, without needing non-toxic contrastive data, making it more transferable. The framework could also steer generation towards desired attributes by flipping the probability manipulation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "the strengths:\n- a lightweight framework that only requires toxic data for prompt tuning\n- superior performance among six baselines."
                },
                "weaknesses": {
                    "value": "- I am not sure how much I appreciate the technical contribution of this work, it seems to me that both of the findings from the generator and the detoxifier part are using an existing method, so it is hard to convince myself the novelty. However, it indeed proves how the framework works in the detoxification field, this is definitely valuable.\n- the authors should show some qualitative examples to further back up table 2.\n- Only one benchmark dataset is used."
                },
                "questions": {
                    "value": "Please see the weakness parts."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3044/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3044/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3044/Reviewer_FrfU"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3044/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699590747627,
            "cdate": 1699590747627,
            "tmdate": 1699636249631,
            "mdate": 1699636249631,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2DNU7hXBiR",
                "forum": "TOveLu4O51",
                "replyto": "R6zdMSYKCQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3044/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3044/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer FrfU"
                    },
                    "comment": {
                        "value": "We thank the reviewer for noticing that our proposed method is lightweight and valuable as it leads to superior performance over previous baselines!\n\n* Justification of novelty\n\nAs Reviewer 9Tow mentioned: although the components of our framework (contrastive decoding, parameter-efficient tuning) are already established methods, combining and applying them toward Detoxification is novel. As discussed in the last paragraph of the Introduction section, our approach makes the data curation much easier than previous work because it only requires toxic data, and parameter-efficient tuning also makes the amount of data required much smaller than full finetuning. This improved transferability (as described in Section 1, last paragraph) is also a significant part of the novelty. We sincerely hope that this explanation alleviates the novelty concern that may have adversely impacted our score.\n\n* Provide qualitative examples\n\nWe thank the reviewer for the suggestion. We did not include the qualitative examples due to ethical concerns as the outputs without detoxification could seem very offensive to the readers. In our code release, we plan to provide some sample toxicity-inducing prompts and include instructions for researchers and practitioners to compare the difference in outputs.\n\n* Evaluate the framework on more benchmark datasets\n\nWe selected the current evaluation benchmark because it makes it easier to compare with previous work that also focused on the same dataset. That said, we do agree that more benchmarks and downstream tasks can shed more light on the effectiveness of our approach."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700617965580,
                "cdate": 1700617965580,
                "tmdate": 1700617965580,
                "mdate": 1700617965580,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]