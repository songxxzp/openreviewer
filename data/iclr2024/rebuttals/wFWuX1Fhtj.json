[
    {
        "title": "On the Hardness of Constrained Cooperative Multi-Agent Reinforcement Learning"
    },
    {
        "review": {
            "id": "32orOKi2H0",
            "forum": "wFWuX1Fhtj",
            "replyto": "wFWuX1Fhtj",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4041/Reviewer_fuRV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4041/Reviewer_fuRV"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies a constrained MARL problem, where a group of agents operate independently in an MDP and jointly optimize a reward function. There are safty constraints that must be satisfied by their joint policy as well. The first focus of the paper is on the hardness of the problem, where the authors showed that strong duality does not hold. The authors then propose a decentralized primal approach to solve the problem. Via examples, it is illustrated either the decentralized primal algorithm or the primal-dual algorithm outperform the other in all cases."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The problem studied is interesting and relevant to the topics of ICLR. The authors made efforts to derive rigorous analyses of the problem."
                },
                "weaknesses": {
                    "value": "From a computational perspective, the statements regarding the hardness of the studied problem are rather loose. Theorem 1 shows that the problem can be reduced to an optimization problem with quadratic constraints, which is in general hard. But nevertheless this doesn't imply the constrained MARL problem is also hard (for that requires a reduction in the other direction, i.e., quadratic optimization can be reduced to the studied MARL problem). Statements such as \"some studies argued that it is **probably** an NP-complete problem\" and  \"Thus, constrained cooperative MARL is a hard problem due to the presence of safety and product policy constraints\" are very loose. It also unclear whether the hardness comes from the safety constraints or the product constraints. Results in the subsequent sections do not seem to provide any clear message regarding the computational complexity of the problem, nor the time complexity of the algorithms discussed. Overall, the insights provided are a bit limited."
                },
                "questions": {
                    "value": "Is the problem known to be hard without the safety constraints (with only the product constraints)? How much is known about this in the literature?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4041/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698595170089,
            "cdate": 1698595170089,
            "tmdate": 1699636367309,
            "mdate": 1699636367309,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tIDLOnEqGZ",
                "forum": "wFWuX1Fhtj",
                "replyto": "32orOKi2H0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4041/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4041/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' reply to Reviewer fuRV"
                    },
                    "comment": {
                        "value": "Thank you very much for reviewing our manuscript and providing valuable feedback. Below is a response to the review comments. We have submitted a revised version with all revisions marked in **\"red\"**. Please let us know if further clarifications are needed.\n\n**Q1:** The hardness results are loose.\n\n**A:** Thanks for pointing this out. \nWe realize that our statement of hardness is not consistent with the actual contributions of the paper, as also pointed out by Reviewer WbB4. Therefore, in the revised paper, we follow the reviewers' suggestions and have changed the emphasis of our claim. Specifically, we changed \"hardness\" to \"duality gap\" in the title, and changed it to \"challenging\" or \"challenges\" throughout the paper. We also changed the emphasis of our main contribution, focusing on the nonzero duality gap and development of algorithms and their convergence results. \nWe agree that it is challenging to figure out the specific complexity class of such a problem, and we think this is an interesting and fundamental problem deserving future research. \n\n**Q2:** Does the hardness come from the safety constraints or the product constraints? Is the problem known to be hard without the safety constraints (with only the product constraints)? How much is known about this in the literature?\n\n**A:** Great question. The hardness comes from both safety constraints and the product constraints. This is because if we remove either the safety constraints or the product constraints, the constrained cooperative MARL reduces to either cooperative MARL or single-agent constrained RL, both having polynomial time algorithms. We have clarified this in the second paragraph of Section 1.1 and at the end of Section 2. \n\n**Q3:** Computational complexity and time complexity of the algorithms are not discussed. \n\n**A:** Thanks for the great suggestion. We have added the complexity results to Theorems 3 and 4 in the revised paper. In these results we derive sample complexity (the total number of required samples), as it is a standard metric used in finite-time analysis of RL algorithms and is also proportional to computation and time complexities. We sketch the derivation as follows.\n\nThe sample complexity of Algorithm 1 (Primal-Dual algorithm) is $\\mathcal{O}(\\epsilon^{-5}\\ln\\epsilon^{-1})$. To elaborate, based on Theoren 3, Algorithm 1 takes $T=\\mathcal{O}(\\epsilon^{-2})$ iterations, and each iteration requires $\\mathcal{O}(\\epsilon_1^{-3}\\ln\\epsilon_1^{-1})$ and $\\mathcal{O}(\\epsilon_2^{-2})$ samples to obtain $\\pi_t$ and $\\widehat{V}_k(\\pi_t)$ with precisions $\\epsilon_1=\\mathcal{O}(T^{-1/2})=\\mathcal{O}(\\epsilon)$ and $\\epsilon_2=\\mathcal{O}(T^{-1/2})=\\mathcal{O}(\\epsilon)$ respectively [1,2]. Therefore, the sample complexity of Algorithm 1 is\n$$\nT\\mathcal{O}(\\epsilon_1^{-3}\\ln\\epsilon_1^{-1}+\\epsilon_2^{-2})=\\mathcal{O}(\\epsilon^{-2})\\mathcal{O}(\\epsilon^{-3}\\ln\\epsilon^{-1}+\\epsilon^{-2})=\\mathcal{O}(\\epsilon^{-5}\\ln\\epsilon^{-1}).\n$$\n\nThe sample complexity of Algorithm 2 (Primal algorithm) is $\\mathcal{O}[T(\\epsilon_2^{-2}+\\epsilon_3^{-2})]=\\mathcal{O}(\\epsilon^{-4})$. To elaborate, based on Theorem 4, Algorithm 2 takes $T=\\mathcal{O}(\\epsilon^{-2})$ iterations, and each iteration requires $\\mathcal{O}(\\epsilon_2^{-2})$ and $\\mathcal{O}(\\epsilon_3^{-2})$ samples to obtain $\\widehat{V} _ k(\\pi_t)$ and $\\widehat{Q } _{k_t}^{(m)}(\\pi_t;s,a^{(m)})$ with precisions $\\epsilon_2=\\mathcal{O}(T^{-1/2})=\\mathcal{O}(\\epsilon)$ and $\\epsilon_3=\\mathcal{O}(T^{-1/2})=\\mathcal{O}(\\epsilon)$ respectively [2]. Therefore,  the sample complexity of Algorithm 2 is\n$$\nT\\mathcal{O}(\\epsilon_2^{-2}+\\epsilon_3^{-2})=\\mathcal{O}(\\epsilon^{-2})\\mathcal{O}(\\epsilon^{-2}+\\epsilon^{-2})=\\mathcal{O}(\\epsilon^{-4}).\n$$\n\n[1] Chen, Z., Zhou, Y., Chen, R. R., \\& Zou, S. (2022). Sample and communication-efficient decentralized actor-critic algorithms with finite-time analysis. In International Conference on Machine Learning (pp. 3794-3834). PMLR.\n\n[2] Li, G., Wei, Y., Chi, Y., Gu, Y., \\& Chen, Y. (2020). Breaking the sample size barrier in model-based reinforcement learning with a generative model. Advances in neural information processing systems, 33, 12861-12872."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4041/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700344602259,
                "cdate": 1700344602259,
                "tmdate": 1700344602259,
                "mdate": 1700344602259,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "OzPI0PhgOM",
                "forum": "wFWuX1Fhtj",
                "replyto": "tIDLOnEqGZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4041/Reviewer_fuRV"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4041/Reviewer_fuRV"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your feedback"
                    },
                    "comment": {
                        "value": "Thank you for your clarification. I agree that it's better to change \"hardness\" to \"duality gap\" in the title."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4041/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700673959560,
                "cdate": 1700673959560,
                "tmdate": 1700673959560,
                "mdate": 1700673959560,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5wBH0Kqb73",
            "forum": "wFWuX1Fhtj",
            "replyto": "wFWuX1Fhtj",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4041/Reviewer_2Wr4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4041/Reviewer_2Wr4"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the hardness of constrained cooperative multi-agent reinforcement learning. In particular, it argues that there is a strictly positive duality gap. In addition, neither primal-dual or primal algorithms are strictly better than the other one."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "+ The paper addresses an important question. \n+ The paper is well-written. \n+ The results seem correct and the explanations and theorems make intuitive sense."
                },
                "weaknesses": {
                    "value": "- The bound $\\Delta$ seems to be trivial? It just comes from the geometric sum and assuming that the risk at each step is less than 1?\n- I'm not sure I see the only if part of Theorem 7. \n- It would be good to offer some advice on when to use which type of algorithm. \n- Some simulation would be helpful to illustrate the results."
                },
                "questions": {
                    "value": "The paper seems to want to say that the problem is NP-hard but stops short. It seems that the quadratic equality is more of an analogy rather than equivalence to standard optimization problems. It would be good to make this more precise."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4041/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4041/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4041/Reviewer_2Wr4"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4041/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698688061878,
            "cdate": 1698688061878,
            "tmdate": 1699636367236,
            "mdate": 1699636367236,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6x3mpWC3ph",
                "forum": "wFWuX1Fhtj",
                "replyto": "5wBH0Kqb73",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4041/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4041/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' reply to Reviewer 2Wr4"
                    },
                    "comment": {
                        "value": "Thank you very much for reviewing our manuscript and providing valuable feedback. Below is a response to the review comments. We have submitted a revised version with all revisions marked in **\"red\"**. Please let us know if further clarifications are needed.\n\n**Q1:** The bound seems to be trivial? It just comes from the geometric sum and assuming that the risk at each step is less than 1? \n\n**A:** Yes, the simple bound $\\Delta\\le \\frac{1}{1-\\gamma}$ directly comes from the geometric sum and the assumption that the risk at each step is less than 1. In the revision, we have moved this result to the remark after Theorem 2. The main result of Theorem 2 is to prove the non-zero duality gap. \n\n**Q2:** I'm not sure I see the only if part of Theorem 7.\n\n**A:** Thanks for pointing this out. In the revised paper, we have added multiple bold subtitles to highlight the parts of \"if\" and \"only if\" in the proof of Theorem 7.\n\n**Q3:** It would be good to offer some advice on when to use which type of algorithm. \n\n**A:** Thanks for the suggestion. When the Q function can be approximated by a factorized form, the primal algorithm is preferred since the advantage gaps $\\zeta_k$ in the convergence rate are small. Otherwise, there is no significant difference between these two algorithms based on our current understanding. \n\n**Q4:** Some simulation would be helpful to illustrate the results. \n\n**A:** Thanks for the suggestion. We are currently conducting MARL experiments in a real world environment and will keep the reviewer posted once the results are available. \n\n**Q5:** The paper seems to want to say that the problem is NP-hard but stops short. It seems that the quadratic equality is more of an analogy rather than equivalence to standard optimization problems. It would be good to make this more precise.\n\n**A:** Thanks for the great suggestion. We agree that it is challenging to figure out the specific complexity class of such a problem, and we think this is an interesting and fundamental problem deserving future research. We also realize that our statement of hardness does not reflect the actual contribution of the paper, as also pointed out by Reviewer WbB4. Therefore, in the revised paper, we have changed the emphasis\nof our claim. Specifically, we changed \"hardness\" to \"duality gap\" in the title, and changed it to \"challenging\" or \"challenges\" throughout the paper. We also changed the emphasis of our main contribution, focusing on the nonzero duality gap and development of algorithms and their convergence results.\n\nRegarding the quadratic equality, our Theorem 1 strictly proved that the original RL problem (1) on the policy $\\pi$ is equivalent to the optimization problem (4) on the occupation measure $\\nu$. So this is not an analogy."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4041/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700344471423,
                "cdate": 1700344471423,
                "tmdate": 1700344471423,
                "mdate": 1700344471423,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "tcBbqFcVUV",
            "forum": "wFWuX1Fhtj",
            "replyto": "wFWuX1Fhtj",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4041/Reviewer_MmRm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4041/Reviewer_MmRm"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies cooperative multi-agent RL problems in which all agents aim to maximize the average reward value function subject to a constraint on the average safety value functions. The authors provide a counter-example to show that the strong duality fails. Nevertheless, the authors extend two existing constrained policy search methods in the single-agent setting to cooperative multi-agent RL under constraints and prove their non-asymptotic optimality gap and constrained violation error bounds. The authors also investigate the pros and cons of the two methods in numerical examples."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper is well written, and statements are supported by justifications. \n\n- The authors show the existence of a strict duality gap in a simple example of cooperative constrained MDPs. This structural property reveals the limitations of methods in the single-agent case, which is useful for developing new algorithms.\n\n- The authors present a primal-dual algorithm and investigate its limitation by revealing the dependence of error bounds on the duality gap.      \n\n- The authors also present a primal algorithm that works in a decentralized way, and provide finite-time error bounds on the optimality gap and constraint violation. \n\n- Numerical examples are provided to show that either one can perform better than the other."
                },
                "weaknesses": {
                    "value": "- For the duality, the authors didn't discuss the connection to the duality of constrained Markov potential games: Provably Learning Nash Policies in Constrained Markov Potential Games. Since constrained cooperative Markov games are a particular case, a non-zero duality gap directly follows. \n\n- Due to the non-zero duality gap, the proposed two algorithms suffer some gaps caused by the multi-agent and constraint coupling. It is more expected that the primal-dual algorithm suffers a duality gap. The primal algorithm has a dependence on an advantage gap that is less expected. It is not clear if these gaps are necessary and which one is better. \n\n- It is interesting to check the policy iterate convergence of two algorithms in simple examples. If this can be proved for the algorithms under certain conditions, it would be more beneficial to guide the practice.\n\n- Experiments are done with artificial examples. It is favorable to check the performance of the two actor-critic algorithms for solving real constrained tasks, and compare it with existing methods as mentioned."
                },
                "questions": {
                    "value": "- Is the non-product form of optimal policy the only reason for the duality gap? Does there exist a more fundamental metric that can characterize the cause of the duality gap?   \n\n- As shown in convergence analysis, the effect of the duality gap in different algorithms can be different. Does this suggest a better way to design algorithms? Is it possible to remove such gap dependence?  \n\n- The advantages of the two algorithms are discussed in terms of policy iterates, which are stronger than the output policy in algorithms. Is it possible to show them in convergence theory?  \n\n- As mentioned, prior works also studied constrained cooperative Markov games and the authors have improved the analysis. Can the authors illustrate the analysis differences due to the lack of zero duality gap? It is useful if the authors could compare assumptions and results with them in a table."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4041/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4041/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4041/Reviewer_MmRm"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4041/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698967782205,
            "cdate": 1698967782205,
            "tmdate": 1699636367168,
            "mdate": 1699636367168,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4fXU0Xxfwa",
                "forum": "wFWuX1Fhtj",
                "replyto": "tcBbqFcVUV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4041/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4041/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' reply to Reviewer MmRm (Q1-Q4)"
                    },
                    "comment": {
                        "value": "Thank you very much for reviewing our manuscript and providing valuable feedback. Below is a response to the review comments. We have submitted a revised version with all revisions marked in **\"red\"**. Please let us know if further clarifications are needed. \n\n**Q1:** For the duality, the authors didn't discuss the connection to the duality of constrained Markov potential games: Provably Learning Nash Policies in Constrained Markov Potential Games. Since constrained cooperative Markov games are a particular case, a non-zero duality gap directly follows. \n\n**A:** Thank you very much for pointing out this related work [1], which studies constrained Markov potential game with competing agents.\nIn the case where all the agents share the same reward function $r_0$, the potential function $\\Phi$ of the constrained Markov potential game reduces to the value function $V_0$ associated with $r_0$. Thus, we agree that the non-zero duality gap result in their Proposition 3 also applies to our case. In the revision, we have cited this work and added a remark after Theorem 2 to mention the related results.  \n\nWe also want to highlight the differences between our work and this related work [1]. To elaborate, their work focuses on Nash equilibrium of constrained Markov potential game, which is very different from the optimal product policy of constrained cooperative MARL studied in our work. More specifically, in the special case where all the agents share the same reward (i.e., cooperative case), their Nash equilibrium \ncorresponds to a feasible product policy $\\pi$ where each agent's policy $\\pi^{(m)}$ is optimal fixing all the other agents' policies $\\pi^{(\\backslash m)}$. Such a notion of agent-wise optimal product policy is weaker than the global optimal product policy studied in our work. \n\n[1] Alatur, P., Ramponi, G., He, N., \\& Krause, A. (2023). Provably Learning Nash Policies in Constrained Markov Potential Games. ArXiv:2306.07749.\n\n**Q2:** Experiments are done with artificial examples. It is favorable to check the performance of the two actor-critic algorithms for solving real constrained tasks, and compare it with existing methods as mentioned. \n\n**A:** Thanks for the suggestion. We are currently conducting MARL experiments in a real constrained task  \nand will keep the reviewer posted once the results are available. \n\n**Q3:** Is the product form of optimal policy the only reason for the nonzero duality gap? Does there exist a more fundamental metric that can characterize the cause of the nonzero duality gap?\n\n**A:** Yes. In fact, even partially product form of optimal policy (e.g., only one agent is independent from all the other agents) can lead to nonzero duality gap. For example, the policy $\\pi(a|s)=\\pi^{(1,2)}(a^{(1,2)}|s)\\pi^{(3)}(a^{(3)}|s)$ is a partially product policy for three agents, where agents 1 and 2 take joint action $a^{(1,2)}$ that is independent from the action $a^{(3)}$ taken by agent 3. Such a (partial) product form of the policy is the only reason that causes the nonzero duality gap. \n\n**Q4:** Is it possible to remove such gap dependence? Which gap is better, duality gap and advantage gap? As shown in convergence analysis, the effect of the duality gap in different algorithms can be different. Does this suggest a better way to design algorithms? \n\n**A:** Great questions. Our current analysis cannot avoid the duality gap for the primal-dual algorithm and the advantage gap for the primal algorithm. We think the dependence of the primal-dual algorithm on the duality gap is unavoidable due to the nature of primal-dual updates. In general, we believe this is a challenging problem that deserves future research. \n\nOn the other hand, we find that it is possible to remove the advantage gap for the primal algorithm by carefully selecting the initialization point. Specifically, in Example 1, all the advantage gaps $\\zeta_0, \\zeta_1, \\zeta_2>0$, but the primal algorithm can still converge to the optimal solution under certain choices of initialization. Hence, the primal algorithm can be very sensitive to the initialization, indicating that the dependence of the convergence on the advantage gap $\\zeta_k$ may not necessarily be tight. This indicates the possibility to address this issue by carefully selecting the initialization, which we leave for future study.\n\nIt is unclear whether the duality gap or the advantage gap is better, as neither of the primal-dual and primal algorithms strictly outperform the other one."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4041/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700344367454,
                "cdate": 1700344367454,
                "tmdate": 1700344367454,
                "mdate": 1700344367454,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tgzccha56A",
                "forum": "wFWuX1Fhtj",
                "replyto": "tcBbqFcVUV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4041/Reviewer_MmRm"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4041/Reviewer_MmRm"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the response. I have a few more questions.  \n\nFor Q1, the difference with the work [1] is a bit vague to me. As I see, [1] also considers the product policy, and illustrates non-zero duality in a constrained QP problem. \n\nFor Q3, do partially product policies also introduce certain quadratic constraints in the occupancy measure?"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4041/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700671304083,
                "cdate": 1700671304083,
                "tmdate": 1700672143518,
                "mdate": 1700672143518,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5jmnselbOg",
                "forum": "wFWuX1Fhtj",
                "replyto": "b593QNS3dV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4041/Reviewer_MmRm"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4041/Reviewer_MmRm"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for adding an illustrating experiment. It looks the nonzero duality gap of optimal product policy doesn't make difference between two algorithms. Is this also characterized in their convergence rates?"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4041/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700672072195,
                "cdate": 1700672072195,
                "tmdate": 1700672072195,
                "mdate": 1700672072195,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "NAWglhvJjg",
            "forum": "wFWuX1Fhtj",
            "replyto": "wFWuX1Fhtj",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4041/Reviewer_Ycbe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4041/Reviewer_Ycbe"
            ],
            "content": {
                "summary": {
                    "value": "The paper provides a comprehensive analysis of the strong duality condition in constrained cooperative Multi-Agent Reinforcement Learning (MARL), (for the first time) revealing its failure to hold and its impact on convergence rates of primal-dual algorithms. Then the authors presents/proposes a new decentralized primal algorithm to avoid the duality gap in constrained cooperative MARL. But their analysis shows that the convergence of this new algorithm is hindered by another gap induced by the advantage functions.The authors contribute to the understanding of the complexity of the constrained cooperative MARL problem by comparing it to cooperative MARL and single-agent constrained RL, and It is rigorously showed in this paper that constrained cooperative MARL is fundamentally harder than its special cases of cooperative MARL and constrained RL. Note that, before this work, strong duality has not been formally validated in constrained cooperative MARL, and therefore leaving convergence of the existing primal-dual type algorithms obscure."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Strengths:\n\nThe problem studied in this paper is important and interesting, and the valuable findings here could be beneficial to MARL research community.\n\nThe paper provides a comprehensive analysis of the strong duality condition in constrained cooperative Multi-Agent Reinforcement Learning (MARL), (for the first time) revealing its failure to hold and its impact on convergence rates of primal-dual algorithms.And then the authors present/propose a new decentralized primal algorithm to avoid the duality gap in constrained cooperative MARL.\n\nThe authors compare the primal-dual algorithm with the primal algorithm and show that neither of them always outperforms the other in constrained cooperative MARL, both theoretically and experimentally. Such theoretical and empirical  analysis are valuable to better understand hardness of constrained cooperative MARL and the performances of different algorithms.\n\nThe authors contribute to better understanding of the complexity of the constrained cooperative MARL problem by comparing it to cooperative MARL and single-agent constrained RL."
                },
                "weaknesses": {
                    "value": "The authors identify and reveal the issue about the previous primal-dual algorithms for constrained cooperative MARL, which is valuable, but the contribution would be much more significant if the authors could also propose a solution to successfully solve this identified problem . \n\nThe authors did attempt to propose a new decentralized primal algorithm to resolve the detected issue/challenge, but it seems no much success of the proposed solution. The proposed decentralized primal algorithm's convergence is hindered by a gap induced by the advantage functions, which can be seen as a major limitation. The comparison of the proposed decentralized primal-dual algorithm with the existing primal-dual algorithm doesn't seem to clearly indicate that the proposed new approach is a consistently superior approach, which makes the paper's contribution less significant.\n\nThe paper is highly theoretical, and comprehensive empirical validation/comparison of the proposed solutions are mostly missing. It would be great to also see some more comprehensive empirical experiment analysis on broad representative tasks (rather than just some very limited extreme case examples in current manuscript).\n\n(Though I have to admit that, although the authors are not able to successfully propose a solution to solve the issue, (for the first time) identifying this important problem/issue about  primal-dual algorithms for constrained cooperative MARL itself might be already quite valuable, and its contribution might possibly enough for publication on ICLR. Though if they are able to also provide a successful solution (in addition to identifying the problem), it would be a much stronger paper.)"
                },
                "questions": {
                    "value": "see weakness section comments."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4041/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699248000603,
            "cdate": 1699248000603,
            "tmdate": 1699636367099,
            "mdate": 1699636367099,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "A9W9QEkx4J",
                "forum": "wFWuX1Fhtj",
                "replyto": "NAWglhvJjg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4041/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4041/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' reply to Reviewer Ycbe"
                    },
                    "comment": {
                        "value": "Thank you very much for reviewing our manuscript and providing valuable feedback. Below is a response to the review comments. We have submitted a revised version with all revisions marked in **\"red\"**. Please let us know if further clarifications are needed.\n\n**Q1:** The contribution would be much more significant if the authors could also propose a solution to successfully solve this identified problem about the previous primal-dual algorithms for constrained cooperative MARL. \n\nThe proposed decentralized primal algorithm's convergence is hindered by a gap induced by the advantage functions, which can be seen as a major limitation. The comparison of the proposed decentralized primal-dual algorithm with the existing primal-dual algorithm doesn't seem to clearly indicate that the proposed new approach is a consistently superior approach, which makes the paper's contribution less significant. \n\n**A:** Great comment. We agree that our current analysis cannot avoid the duality gap for the primal-dual algorithm and the advantage gap for the primal algorithm. This is a challenging problem that deserves future research. On the other hand, it is possible to address this issue by carefully selecting the initialization point. Specifically, in Example 1, all the advantage gaps $\\zeta_0, \\zeta_1, \\zeta_2>0$, but the primal algorithm can still converge to the optimal solution under certain choices of initialization. Hence, the primal algorithm can be very sensitive to the initialization, indicating that the dependence of the convergence on the advantage gap $\\zeta_k$ may not necessarily be tight. This indicates the possibility to address this issue by selecting the initialization, which we leave for future study.\n\n**Q2:** The paper is highly theoretical, and comprehensive empirical validation/comparison of the proposed solutions are mostly missing. It would be great to also see some more comprehensive empirical experiment analysis on broad representative tasks (rather than just some very limited extreme case examples in current manuscript). \n\n**A:** Thanks for the suggestion. We are currently conducting MARL experiments in a real constrained task and will keep the reviewer posted once the results are available."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4041/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700344199396,
                "cdate": 1700344199396,
                "tmdate": 1700344199396,
                "mdate": 1700344199396,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kENJMnp2dH",
                "forum": "wFWuX1Fhtj",
                "replyto": "A9W9QEkx4J",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4041/Reviewer_Ycbe"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4041/Reviewer_Ycbe"
                ],
                "content": {
                    "title": {
                        "value": "I've checked out all comments and keep my rating unchanged"
                    },
                    "comment": {
                        "value": "I've checked out the authors' response as well as all the comments from other reviewers. I still think this is a border line paper in terms of contribution significance, and I've kept my rating unchanged."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4041/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700702663263,
                "cdate": 1700702663263,
                "tmdate": 1700702663263,
                "mdate": 1700702663263,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "uo2OA59fta",
            "forum": "wFWuX1Fhtj",
            "replyto": "wFWuX1Fhtj",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4041/Reviewer_WbB4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4041/Reviewer_WbB4"
            ],
            "content": {
                "summary": {
                    "value": "This work concerns a problem of MARL known as Constrained Cooperative MARL (CC-MARL). In such a setting, multiple agents share a common reward function that depends on joint action and the transitions of the underlying MDP depend on that joint action as well; further, apart from striving to maximize the expected discounted cumulative rewards they will get, the agents attempt to minimize a set of constraints. Those constraints in fact concern the expected discounted cumulative costs.\n\nExisting literature has offered results for correlated policies -- rather than product ones. The authors demonstrate that the problem of CC-MARL admits a formulation as a mathematical program with nonconvex (bilinear) constraints which is known to be NP-hard, in the general case. In general, in such a case, a solution of the CC-MARL is a product policy that will have an approximately zero single-agent optimality gap and constraint violation. The optimality gap is just the gain a single agent can have by unilaterally deviating from the joint output policy and the constraint violation is the amount by which a constraint is violated.\n\nThen, the authors demonstrate how the existing primal-dual algorithmic framework only manages to provide a bound on the constraint violation that depends on the *duality gap* of the underlying lagrangian function. This means that existing art can only offer solutions that could potentially have a constraint violation as large as the maximum possible discounted cumulative reward.\n\nFinally, the authors design an algorithm based on the single-agent RL CRPO algorithm. Convergence is proven using a potential/Lyapunov function argument. The optimality and constraint violation bounds depend on a quantity known as the *advantage gap*. The advantage gap in turn is zero if and only if the q-functions can be decomposed in a sum of functions that only depends on single-agent actions."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The authors extend previous work that existed only for the case of correlated policy optimization to a product policy setting. They even improve single-agent RL bounds for the CRPO algorithm.\n\nThe paper offers a rather rich exposition of previous theoretical results in the literature of (constrained) cooperative RL."
                },
                "weaknesses": {
                    "value": "A weakness of the authors' result is the lack of a definitive answer as to the hardness of the problem of Constrained Cooperative MARL. Indeed, the fact that the optimization program corresponds to a mathematical program with bilinear constraint functions is an indication of its potential hardness, yet there is a multitude of refined computational complexity classes that it could belong to. Is the problem *total*, i.e., is the problem guaranteed to have a solution? If so, it will belong to the TFNP complexity class. Then, does it belong to some known classes such as PPAD, PPA, CLS, PLS?\n\nI believe the paper has merit in extending previous results that considered correlated policies to quantifying the effect of being restricted to product policies. That being said, the narrative and even the title of the introductory text could benefit by stressing this fact rather than putting the focus on the hardness, since there is no definitive answer of the computational complexity."
                },
                "questions": {
                    "value": "What were the main challenges you faced in proving a definitive refined hardness result?\n\nWhat would be the advantage gap if the reward functions admitted a network-separable structure and the transitions were additive?\n\nDo you think that the dependence on the advantage gap is tight? Can it be improved, or is it yet another indication of the hardness of approximation of solutions of constrained cooperative MARL problem solutions?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4041/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4041/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4041/Reviewer_WbB4"
                    ]
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4041/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699400445167,
            "cdate": 1699400445167,
            "tmdate": 1699636367027,
            "mdate": 1699636367027,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "k3o0KaQqf4",
                "forum": "wFWuX1Fhtj",
                "replyto": "uo2OA59fta",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4041/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4041/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' reply to reviewer WbB4"
                    },
                    "comment": {
                        "value": "Thank you very much for reviewing our manuscript and providing valuable feedback. Below is a response to the review comments. We have submitted a revised version with all revisions marked in **\"red\"**. Please let us know if further clarifications are needed. \n\n**Q1:** Is the problem guaranteed to have a solution?  Does it belong to PPAD, PPA, CLS, PLS? Change the emphasis of the paper to the main contribution rather than the hardness, since there is no definitive answer of the computational complexity.. \n\n**A:** Good question. The optimization problem in Theorem 1 has a solution since the feasible set is compact and the objective function is continuous. However, we do agree that it is challenging to figure out the complexity class of such a problem, and we think this is an interesting and fundamental problem deserving future research. \n\nWe really appreciate the reviewer's great suggestion on changing the emphasis of our claim. We do agree that our statement of hardness does not reflect the actual contribution of the paper. In the revised paper, we have \nchanged \"hardness\" to \"duality gap\" in the title, and changed it to \"challenging\" or \"challenges\" throughout the paper. We also changed the emphasis of our main contribution, focusing on the nonzero duality gap and development of algorithms and their convergence results.\n\n**Q2:** What were the main challenges you faced in proving a definitive refined hardness result? \n\n**A:** The main challenge is to transform a known hard problem, e.g., NP-hard, into the optimization problem presented in Theorem 1, which has specific and complicated forms. This is necessary to prove that our problem is NP-hard (or belongs to some other complexity classes).\n\n**Q3:** What would be the advantage gap if the reward functions admitted a network-separable structure and the transitions were additive?\n\n**A:** Great question. For example, in the case where the reward functions and transition kernel are separable, i.e.,\n\n$\\overline{r}_k(s,a)=\\frac{1}{M}\\sum _ {m=1}^M r_k^{(m)}(s,a^{(m)})$\n\nand \n\n$\\mathcal{P}(s'|s,a)=\\sum _ {m=1}^M \\theta_m \\mathcal{P} _ m(s'|s,a^{(m)}),$ \n\nwhere $\\theta_m\\ge 0$ and $\\sum _ {m=1}^M\\theta_m=1$, the Q function is decomposable as follows.\n$$\nQ_k(\\pi;s,a)=\\overline{r}_k(s,a)+\\gamma \\sum _ {s'}\\mathcal{P}(s'|s,a) V_k(\\pi;s')=\\sum _ {m=1}^M \\widetilde{Q}_k^{(m)}(\\pi;s,a^{(m)})\n$$\nwhere $\\widetilde{Q}_k^{(m)}(\\pi;s,a^{(m)}):=\\frac{1}{M}r_k^{(m)}(s,a^{(m)})+\\gamma\\sum _ {s'}\\theta_m \\mathcal{P} _ m(s'|s,a^{(m)})V_k(\\pi;s')$. Therefore, the advantage gap vanishes.\n\n**Q4:** Do you think that the dependence on the advantage gap is tight? Can it be improved, or is it yet another indication of the hardness of approximation of solutions of constrained cooperative MARL problem solutions? \n\n**A:** Great question. We think the dependence on the advantage gap is not tight and may be improved by carefully tuning the initialization. To explain, in Example 1, all the advantage gaps $\\zeta_0, \\zeta_1, \\zeta_2>0$, but the primal algorithm can still converge to the optimal solution under certain choices of initialization. This indicates that the primal algorithm can be very sensitive to initialization and that the constrained cooperative MARL problem is challenging. We believe this is an interesting problem for future research."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4041/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700344139689,
                "cdate": 1700344139689,
                "tmdate": 1700344139689,
                "mdate": 1700344139689,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "IAeIWq4btR",
            "forum": "wFWuX1Fhtj",
            "replyto": "wFWuX1Fhtj",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4041/Reviewer_ditR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4041/Reviewer_ditR"
            ],
            "content": {
                "summary": {
                    "value": "The paper first examines whether strong duality holds for the constrained cooperative MARL setting (a problem which has been studied in previous works). In contrast to the constrained single agent case where strong duality holds, the authors reformulate the constrained cooperative MARL problem as a constrained optimization problem on the occupation measure associated with the agents\u2019 product policy, and prove that strong duality does not hold for constrained MARL case, because of the existence of non convex constraints (related to the product joint policy). They establish the first convergence rate result that characterizes the impact of duality gap on the constraint violation and optimality of the output policy of the Primal-Dual algorithm. In particular, both the optimality gap and the constraint violation converge at a similar sub-linear rate, but the latter up to a convergence error that depends on the duality gap of the problem. Furthermore, the paper proposes a primal-based algorithm for constrained cooperative MARL with the convergence not involving the duality gap, based on decentralized NPG policy updates. In particular, the authors show that both the optimality gap and the constraint violation converge at the sublinear rate, up to certain convergence errors that depend on defined advantage gaps. The authors also show that these advantage gaps vanish if and only if the Q-function has a certain factorization scheme. Last but not least, the paper explicitly compares the two algorithms and proves that each of the two algorithms can be better than the other in certain scenarios."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper is well-motivated, since strong duality has not been validated in previous constrained cooperative MARL works and the duality gap is crucial for the convergence of the Primal-Dual Algorithm.\n- The paper is very well-written and easy-to-follow with concrete examples and good intuition of the examined algorithms.\n- The paper introduces some novel technical elements, such as the upper bounds in inequalities (17) and (19) on page 8."
                },
                "weaknesses": {
                    "value": "- The assumption of the decomposition schema of the Q-function, that the advantage gaps depend on, seems limiting. Is the assumption necessary to ensure the computational tractability of the problem? Moreover, in practice, similar assumptions (on the linear decomposition of the Q-function) can harm performance, even in the unconstrained setting (e.g. see the comparison between VDN and QMIX (Rashid et al. 2020)).\n- It is not clear by the authors if the paper can be compared with other state-of-the-art algorithms (if exist) in terms of the optimality gap (in the constrained cooperative MARL setting)."
                },
                "questions": {
                    "value": "I have the following questions regarding some technical details of the paper:\n- In the proof of Theorem 3, the authors have assigned $\\lambda_k$ with a value larger than $\\lambda_{k,{max}}$ (page 19). Can the authors be more explicit about why they are able to assign $\\lambda_k$ with such a value?\n- In the proof of Theorem 7, can the authors be more explicit about the proof steps and explain what $\\pi_{\\omega}$ and $\\omega$ are?\n- In the proof of Lemma 3, can the authors be more explicit about the last inequality of page 33?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4041/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4041/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4041/Reviewer_ditR"
                    ]
                }
            },
            "number": 6,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4041/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699548386072,
            "cdate": 1699548386072,
            "tmdate": 1699636366943,
            "mdate": 1699636366943,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "WJn3G9NIju",
                "forum": "wFWuX1Fhtj",
                "replyto": "IAeIWq4btR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4041/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4041/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' reply to Reviewer ditR"
                    },
                    "comment": {
                        "value": "Thank you very much for reviewing our manuscript and providing valuable feedback. Below is a response to the review comments. We have submitted a revised version with all revisions marked in **\"red\"**. Please let us know if further clarifications are needed. \n\n**Q1:** The assumption of the decomposition scheme of the Q-function, that the advantage gaps depend on, seems limiting. Is the assumption necessary to ensure the computational tractability of the problem? Moreover, in practice, similar assumptions (on the linear decomposition of the Q-function) can harm performance, even in the unconstrained setting (e.g. see the comparison between VDN and QMIX (Rashid et al. 2020)). \n\n**A:** Great question. Note that the convergence result in Theorem 4 does not rely on this assumption. Moreover, we showed in Appendix H that this assumption is necessary and sufficient to ensure a vanishing advantage gap $\\zeta_k$. We agree with the reviewer that this assumption is restricted and may fail to hold in practical scenarios, and this echos our key point that constrained cooperative MARL problems can be challenging to solve.\n\n**Q2:** It is not clear by the authors if the paper can be compared with other state-of-the-art algorithms (if exist) in terms of the optimality gap (in the constrained cooperative MARL setting). \n\n**A:** Good question. To the best of our knowledge, no existing approaches for constrained cooperative MARL has convergence guarantee on the optimality gap. Specifically, as we discussed after Q1 in the introduction, the existing works only obtained  either convergence of gradient norm (weaker than the optimality gap), or convergence of only part of the policy instead of the full algorithm. In the revision, we have added Table 1 to summarize this comparison.  \n\n**Q3:** In the proof of Theorem 3, why can we assign $\\widetilde{\\lambda} _ k$ to a larger value $2\\lambda _ {k,\\max}$ in the primal-dual algorithm. \n\n**A:** Thank you very much for pointing out this and we have fixed it in the revised paper. Specifically, we changed the value of $\\widetilde{\\lambda} _ k$ from $2\\lambda _ {k,\\max}I\\{V_k(\\pi_t)\\le \\xi_k\\}$ to $\\lambda_{k,\\max}I\\{V_k(\\pi_t)\\le \\xi_k\\}$. Accordingly, we have doubled the value of $\\lambda _ {k,\\max}$ in Lemma 1 and showed that the optimal dual variable $\\lambda_k^*\\le \\frac{1}{2}\\lambda_{k,\\max}$ (not $\\lambda _ {k,\\max}$).\n\n**Q4:** In the proof of Theorem 7, can the authors be more explicit about the proof steps and explain what $\\pi_{\\omega}$ and $\\omega$ are? \n\n**A:** Thanks for checking our proof so carefully. In our revised paper, we have added bold subtitles to highlight the proofs of \"if\" and \"only if\" parts. We also added more intermediate steps and explanations to the proof of ``if'' part (i.e. the Q-function decomposition implies $\\zeta_k=0$). We have also changed $\\pi_{\\omega}$ and $\\omega$ to $\\pi$. Thanks for pointing out this inconsistent notation.\n\n**Q5:** In the proof of Lemma 3, can the authors be more explicit about the last inequality of page 33?\n\n**A:** Thanks for checking our proof so carefully. We think the reviewer was referring to the following inequality.\n$$\\sum_a \\Big|\\prod_{m=1}^M\\pi_{t+1}^{(m)}(a^{(m)}|s)-\\prod_{m=1}^M \\pi_t^{(m)}(a^{(m)}|s)\\Big|$$\n$$\\le\\sum_a \\sum_{m'=1}^M\\Big|\\prod_{m=1}^{m'}\\pi_{t+1}^{(m)}(a^{(m)}|s)\\prod_{m=m'+1}^{M}\\pi_t^{(m)}(a^{(m)}|s)-\\prod_{m=1}^{m'-1}\\pi_{t+1}^{(m)}(a^{(m)}|s)\\prod_{m=m'}^{M}\\pi_t^{(m)}(a^{(m)}|s)\\Big|$$\nTo exlain, for any fixed action $a$, denote $C_{m'}(a):=\\prod_{m=1}^{m'}\\pi_{t+1}^{(m)}(a^{(m)}|s)\\prod_{m=m'+1}^{M}\\pi_t^{(m)}(a^{(m)}|s)$ and then the above inequality can be obtained by the following triangle inequality\n$$|C_M(a)-C_0(a)|=\\Big|\\sum_{m'=1}^M [C_{m'}(a)-C_{m'-1}(a)]\\Big|\\le \\sum_{m'=1}^M |C_{m'}(a)-C_{m'-1}(a)|.$$ \nWe have added this clarification to the revised paper."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4041/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700343937918,
                "cdate": 1700343937918,
                "tmdate": 1700344649106,
                "mdate": 1700344649106,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]