[
    {
        "title": "A Unified Approach for Online Continuous DR-Submodular Maximization"
    },
    {
        "review": {
            "id": "qAw8MmMjjd",
            "forum": "H4A9e8HvIn",
            "replyto": "H4A9e8HvIn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8364/Reviewer_EVLt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8364/Reviewer_EVLt"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents unified projection-free Frank-Wolfe algorithms for online continuous adversarial DR-submodular optimization. It covers various scenarios such as full-information and (semi-)bandit feedback, monotone and non-monotone functions, different constraints, and types of stochastic queries. The algorithms achieve state-of-the-art or improved regret bounds compared to existing methods. The paper also addresses semi-bandit and bandit feedback for adversarial DR-submodular optimization."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper presents a unified approach for online continuous adversarial DR-submodular optimization, covering a broad spectrum of scenarios. This comprehensive investigation is novel and expands the understanding of the field beyond previous research. The authors introduce technical novelties, such as the combination of meta-actions and random permutations, contributing to the originality of the research.\n\nThe paper is well-structured and clearly presents the problem formulation, algorithms, and theoretical analysis. The inclusion of tables and figures enhances the clarity of the presentation.\n\nIn summary, the research addresses a significant problem in the field of continuous adversarial DR-submodular optimization with numerous real-world applications. The proposed algorithms demonstrate practical relevance and significance, contributing to the development of efficient optimization techniques for DR-submodular functions."
                },
                "weaknesses": {
                    "value": "While the paper mentions the applications of continuous adversarial DR-submodular optimization, it lacks a thorough empirical evaluation of the proposed algorithms on real-world applications. Including experiments that demonstrate the performance of the algorithms in practical scenarios would strengthen the paper's claims and provide empirical evidence of their effectiveness\n\nI guess that the authors have adopted a text-wrapping layout around the pseudocode due to space constraints. However, the limited space allocated to the pseudocode has resulted in somewhat disorganized format. I would suggest that the authors consider using algorithm2e to reduce the space occupied by the pseudocode, thereby enhancing its readability. Just a friendly suggestion."
                },
                "questions": {
                    "value": "Please refer to weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8364/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8364/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8364/Reviewer_EVLt"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8364/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698483628912,
            "cdate": 1698483628912,
            "tmdate": 1699637039974,
            "mdate": 1699637039974,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "zh0j5S9A4f",
                "forum": "H4A9e8HvIn",
                "replyto": "qAw8MmMjjd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8364/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8364/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks a lot for your time and the great comments. \n\nRegarding experiments, we note that the focus of the paper is on the theoretical results.\nWe have provided evaluations on non-convex/non-concave quadratic maximization which has also been used in the prior works.\nWe note that we consider a unified approach for 16 cases in this paper. \nIn 9 of these cases, ours is the first algorithm, and thus there are no baselines to compare.\nFurthermore, one would need to find different real world examples for different settings, since each real-world example often matches the assumption of only a few of the 16 cases. \nWhile practically important, we chose a case where the assumptions are satisfied to demonstrate the benefits of our approach and where we had relevant baselines to perform the comparison. \nThus, we leave this comparison to the experts in different domains (e.g., profit maximization in social networks, advertising, experimental design, resource allocation, mean-field inference in probabilistic models, MAP inference in determinantal point processes, etc) where such algorithms could be used in realistic setups. \n\nRegarding the text-wrapping layout, that is indeed due to the space constraint. \nWe have followed your advice and have used the algorithm2e package in the revision to enhance readability."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8364/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700458336066,
                "cdate": 1700458336066,
                "tmdate": 1700458336066,
                "mdate": 1700458336066,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ip7iqejjd7",
            "forum": "H4A9e8HvIn",
            "replyto": "H4A9e8HvIn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8364/Reviewer_5yTK"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8364/Reviewer_5yTK"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigates online adversarial continuous DR-submodular optimization. The authors propose unified projection-free Frank-Wolfe type algorithms under many settings, e.g., full information and (semi-)bandit feedback, monotone and non-monotone functions, different constraints, and types of stochastic queries. Compared with the related works, most of the proposed algorithms achieve state-of-the-art $\\alpha$-regret bound."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* This paper conducts a detailed investigation on online adversarial continuous DR-submodular optimization and proposes effective algorithms for various settings. \n* Compared with existing studies, the proposed algorithms achieves state-of-the-art $\\alpha$-regret bound in most settings."
                },
                "weaknesses": {
                    "value": "The presentation of technical contributions and motivation in this paper requires further improvement. See **Questions** below."
                },
                "questions": {
                    "value": "I have the following questions to ask the authors:\n\n* Could you elaborate on the technical challenges of this paper? The proposed algorithms seem to combine existing techniques without introducing novel technical tools. \n* This paper proposes two unified projection-free Frank-Wolfe type algorithms for the full-information and bandit settings. Could you provide the reasons why previous algorithms couldn't achieve a unified framework? \n* Compared with Zhang et al. (2023) for non-monotone functions, the proposed algorithms achieve only a slight improvement in terms of $\\alpha$-regret guarantee. Can you explain the reasons for this, and the differences between two algorithms? \n* Could the authors provide a discussion on the technical contributions of this paper regarding online adversarial continuous DR-submodular optimization?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8364/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8364/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8364/Reviewer_5yTK"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8364/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698504133189,
            "cdate": 1698504133189,
            "tmdate": 1699637039844,
            "mdate": 1699637039844,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "huPcxg9DF0",
                "forum": "H4A9e8HvIn",
                "replyto": "ip7iqejjd7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8364/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8364/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your time in reviewing our paper.\n\n**Q1**: As we  mentioned in the introduction and elaborated on in Sections 3.1-3.2 and Appendix A.2, our main technical novelties include:\n**(i)** a novel combination of the idea of meta-actions and random permutations to obtain a new algorithm in the full-information setting; \n**(ii)** handling stochastic (gradient/value) feedback *without* using variance reduction techniques like momentum, which in turn leads to state of the art regret bounds; and **(iii)** a unified approach that specializes to multiple scenarios considered in this paper.  \n(In our submission, we described novelties (ii) and (iii) together; for clarity, we now describe them separately.) \n\n**(i)**\nExcept for the full-information algorithm of (Niazadeh et al., 2021) which uses a completely different approach,\nall of the referenced algorithms in prior works designed for the full-information setting with $T^\\beta > 1$ gradient samples available for each function $F_t$ used meta-actions, specifically with $K=T^\\beta$ online linear optimization (OLO) oracles.\nSo the number of oracles $K$ used was set equal to the number of samples $T^\\beta$ available as feedback.\nWe prove that using $K = T^\\beta$ OLO oracles is sub-optimal. \nWe do so by designing and analyzing the first random permutations plus meta-action based procedure for this setting.\nUsing random permutations, we add a degree of freedom where we can choose the number $K$ of OLO oracles separately from the number of queries $T^\\beta$.\nThis results in significant improvements in regret bounds.\nFor example, in the limit of the number of gradient queries per function $T^\\beta$ tending to one, for monotone functions over convex sets containing the origin (Meta-Frank-Wolfe in (Chen et al., 2018a)) and for non-monotone functions over downward closed sets (Meta-MFW in (Zhang et al., 2023)), \nour novel approach using random permutations results in an improvement of $O(T^{1/5})$.\n(Note that this is the improvement due solely from combining random permutations with meta-actions, without considering the effect of removing momentum, which also reduces regret and which we will describe in detail below. \nIn the aforementioned settings, when the number of gradient queries per function $T^\\beta$ is more than one, our final result improves the state of the art by a factor of $O(T^{1/3})$.)\n\nIntuitively, our approach harmonizes \"Meta\" algorithms (designed for $T^\\beta > 1$ gradient samples per function $F_t$) with \"Mono\" algorithms (designed for a single, $T^\\beta = 1$, gradient sample per function $F_t$), which have never been combined before. \nWe strove for our methods to be as simple as possible---the simplicity in combining these ideas is only evident in hindsight and is not evident from the prior works, \ndespite the regret bounds for Meta-algorithms as $T^\\beta\\to 1$ being clearly sub-optimal.\nEven in the most recent work with both types of algorithms,\n(Zhang et al., 2023), separate Meta and Mono algorithms were proposed and they were also  analyzed separately, despite a regret bound gap for $\\beta=0$ (see Figure 1 in our paper with $\\beta=0$ for a visual depiction of (Zhang et al., 2023)'s Meta-MFW algorithm's regret bound gap compared to that of their Mono-MFW algorithm).\n\nIn regards to **(ii)**, one of our main technical novelties is to handle stochastic feedback without relying on variance reduction techniques.\nIn particular, not only do we show for all cases that noisy feedback (gradients/values) can be handled without momentum, but more so for a fixed number of queries (fixed $T^\\beta$), using momentum leads to higher regret.\n\nAlmost all previous Frank-Wolfe type algorithms in online DR-submodular maximization that handle stochastic feedback employ some form of momentum (a common variance reduction method).\nWe believe this was largely due to a misinterpretation of the counter-example described in (Hassani et al., 2017) where they show that in the offline setting, directly replacing the exact gradient with an unbiased estimator of the gradient could result in arbitrarily bad outputs of the algorithm.\nThis is mentioned in Section 3.2 of (Chen et al., 2018b) as the reason why their version of Meta-Frank-Wolfe may not be used with a stochastic gradient and is later solved in (Chen et al., 2018a) by using momentum which results in considerable loss in performance.  \nThe version of Meta-Frank-Wolfe described in (Mualem et al., 2023), for non-monotone functions over general convex, works with stochastic gradient oracles without using momentum, which partially inspired this technical novelty of our work.\nHowever, we note that their work focused only on regret bounds, not query complexity, and if query complexity is ignored it does not matter whether momentum is used-- $O(T^{1/2})$ can be achieved."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8364/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700162737289,
                "cdate": 1700162737289,
                "tmdate": 1700162737289,
                "mdate": 1700162737289,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CefZ8Ckq5J",
                "forum": "H4A9e8HvIn",
                "replyto": "ip7iqejjd7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8364/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8364/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "(The fact that their algorithm obtains $O(T^{1-\\beta})$ regret for $T^{\\beta}$ queries per function follows from the first part of Theorem 4.1 together with the last sentence of Section 4 and the first paragraph of the proof Theorem 3.1 in their paper.)\nWhile they state their algorithm and proof for an arbitrary number of queries per function, they have no analysis or discussion on query complexity, nor on the possibility of extending that approach to other settings.\nTo the best of our knowledge, our paper is the first to realize that removing momentum could result in improved regret bound for a fixed query complexity.\n\nWe prove that for online DR-submodular optimization, in all cases, even when the feedback is stochastic, using meta-actions alone (i.e., without momentum) is *sufficient* to obtain sublinear $\\alpha$-regret bounds and using momentum decreases the performance.\nWe extend this analysis to Mono-Frank-Wolfe, where we improve the state of the art by $O(T^{2/15})$.\nIf the idea of random permutations is used as we have described in (i), together with momentum, the regret will likely be bounded from above by $O(T^{4/5 - \\beta/5})$.\nBy removing momentum, we achieve $O(T^{2/3 - \\beta/3})$ regret, i.e. a likely improvement of $O(T^{2(1 - \\beta)/15})$ over the result one would obtain by using (i) with momentum.\n\nFor **(iii)**, we note that many papers and results add more complexity to the field of research, but our result tries to move in the opposite direction. Algorithm 1 (for full-information feedback) generalizes, simplifies and improves 8 previous algorithms, while Algorithm 2 (for semi-bandit feedback) does this for 3 previous algorithms.\nWe developed a unified analysis which is more modular and simpler than analyses in prior works.\nThis modularity allows us to *(a)* obtain better insight for how elements of the algorithm design and problem setting interact in bringing about the $\\alpha$ approximation ratio separately from the $\\alpha$-regret bounds; and as consequence, results in *(b)* proof for regret guarantees for 16 algorithms in shorter space than other papers proved regret guarantees for just one or two algorithms.\n\nRegarding *(iii).(a)* on how the modularity of the analysis yields clearer insight, \nin Appendix E we show an essential lemma (Lemma 8) that makes explicit why the update rules and the step sizes should be the way they are. \nLemma 8 only considers a single DR-submodular function and captures how certain update rules result in certain approximation coefficients.\nIn fact, besides the two algorithms in this paper, Lemma 8 may be directly used in the proof of at least 18 algorithms in the literature as the part of the proof which derives the approximation coefficients: (Chen et al., 2018b) (Chen et al., 2018a) (Zhang et al., 2019) (Niazadeh et al., 2021) (Thang et al., 2021) (Zhang et al., 2023) (Mualem et al., 2023) (Bian et al., 2017b) (Mokhtari et al,. 2020) (Bian et al., 2017a) (Du et al., 2022) (Pedramfar et al., 2023)\n\nRegarding *(iii).(b)*, as an example of how much the modularity of our analysis leads to brevity, in the paper (Zhang et al., 2019), where the idea of random permutations is first used for DR-submodular maximization with full-information single sample gradient $T^\\beta=1$ feedback, the proof of their result for the full-information setting \nis 8.5 pages (Appendix B in their paper).  \nThat proof only covers the  (simpler) case of monotone functions over convex sets containing the origin, with  a single evaluation of gradient oracle.\nThey use another 9 pages to prove their result for monotone functions over downward closed convex sets in the bandit setting.\n(We are only considering the proofs that involve the ideas of meta-actions and random permutations, not general statements about convex sets or DR-submodular functions.)\nIn contrast, the only part of our proofs that deals explicitly with the online setting are in Appendix F and G, a total of 4 pages, which, together with Lemma 9, prove the regret bounds for 16 problem variations listed in Table 1.\n\n**Q2**: We cannot speak for authors of other papers on why they did not propose a unified framework. \nInstead, we partly address a related question -- in what way is this work unified and what more work would some authors have needed to do in order to unify their separately described and analyzed algorithms.\nIn general, that would depend on how one defined the notion of \"unification\".\nThere are several different forms of unification appearing in our work:\n\n**(a)** Unification of value/gradient oracle settings:  \nAlgorithm 1 is the first algorithm for adversarial DR-submodular maximization with full information feedback given a value oracle.\nExcept for (Chen et al., 2018b) which uses a projection-based method, Algorithm 2 is the first algorithm for adversarial DR-submodular maximization with semi-bandit feedback given a gradient oracle.\nThis is arguably the simplest form of unification present in our work."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8364/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700163041309,
                "cdate": 1700163041309,
                "tmdate": 1700164071563,
                "mdate": 1700164071563,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gGaRVsGkiH",
                "forum": "H4A9e8HvIn",
                "replyto": "wJJ5qeO8Rh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8364/Reviewer_5yTK"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8364/Reviewer_5yTK"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the detailed responses."
                    },
                    "comment": {
                        "value": "The thorough discussions have resolved the issues I raised in Q2 and Q3. However, I am still confused about the technical challenges in this paper. First, I believe that a \"novel combination\" in online learning cannot be considered a technical contribution. Second, the paper primarily uses existing techniques, i.e., random permutations to achieve a series of improved bounds, as the authors have mentioned in rebuttal. Finally, technical novelties (ii) and (iii) also do not introduce any novel technical tool but simply combine existing techniques and provide corresponding analysis. In this review round, I will maintain my score, reflecting my uncertainty about the technical contributions of this paper."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8364/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700401521229,
                "cdate": 1700401521229,
                "tmdate": 1700401521229,
                "mdate": 1700401521229,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "SWOHLvhCa2",
            "forum": "H4A9e8HvIn",
            "replyto": "H4A9e8HvIn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8364/Reviewer_ZRDt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8364/Reviewer_ZRDt"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes an expedient and highly generalized projection-free Frank-Wolfe type algorithms for adversarial and continuous DR-submodular maximization problems. The settings they consider can be a full information or a (semi-) bandit feedback, with monotone or non-monotone functions, having different constraints, and types of stochastic queries. Notably, for every problem they consider in the non-monotone setting, they either provide the first algorithm with proven sub-linear $\\alpha$-regret bounds or they improve the already existing $\\alpha$-regret bounds. They also report obtaining the state-of-the-art sub-linear $\\alpha$-regret bounds among projection-free algorithms in the majority of the monotone settings they consider. In the remaining monotone setting, they match their result to the existing one."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "The paper's efforts to present unified projection-free algorithms is convenient and worthy of exploration. The main technical contributions of the paper, a.k.a. combining the ideas of meta-actions and random permutations and providing a refined analysis that does not rely on variance reduction techniques, are original. The ideas, contributions, and techniques are expressed clearly. I especially enjoyed the level of detail in Table 1 and Appendices A.2 and C."
                },
                "weaknesses": {
                    "value": "I have not noticed particular weaknesses so far."
                },
                "questions": {
                    "value": "I do not have any clarifying questions on my mind at the moment."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "10: strong accept, should be highlighted at the conference"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8364/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8364/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8364/Reviewer_ZRDt"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8364/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698856459611,
            "cdate": 1698856459611,
            "tmdate": 1699637039740,
            "mdate": 1699637039740,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tl77MRWWBo",
                "forum": "H4A9e8HvIn",
                "replyto": "SWOHLvhCa2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8364/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8364/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We genuinely appreciate your time and effort in reviewing our work. Thank you very much for your valuable feedback and support."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8364/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700164113073,
                "cdate": 1700164113073,
                "tmdate": 1700164113073,
                "mdate": 1700164113073,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]