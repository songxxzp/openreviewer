[
    {
        "title": "ZOOPFL: EXPLORING BLACK-BOX FOUNDATION MODELS FOR PERSONALIZED FEDERATED LEARNING"
    },
    {
        "review": {
            "id": "Nnhw0DRMWw",
            "forum": "U2ZIgcrg7Z",
            "replyto": "U2ZIgcrg7Z",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7431/Reviewer_RdGi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7431/Reviewer_RdGi"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses challenges in personalized federated learning with large foundation models and limited resources, including data, computation, and model access. The proposed method, ZOOPFL (Zeroth-Order Optimization for Personalized Federated Learning), adapts inputs through zeroth-order optimization and uses linear projections for personalization. Input surgery is introduced to reduce computation costs and enhance personalization."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The experiments are comprehensive, covering multiple datasets in both computer vision (CV) and natural language processing (NLP) applications.\n- The paper's focus on federated learning settings that address both data privacy and model privacy is intriguing."
                },
                "weaknesses": {
                    "value": "My main concerns are the validity and privacy risks of this FL setting. \n- First, the black-box FL setting lacks practicality. The paper assumes the existence of large foundation models on clients in the form of encrypted assets, and it does not require the uploading of transformed inputs. However, this does not align with the most common scenarios in machine learning model services, such as the access of various black-box large language models like ChatGPT. In practical scenarios, local data needs to be uploaded to the model service provider.  \n- Second, the motivation for deploying zeroth-order optimization methods based on the local encrypted black-box model setup is not well-motivated. This setting implies that it is entirely possible to train an white-box emulator [1] as a proxy for the black-box model and directly perform first-order optimization based on the white-box emulator. However, the authors do not provide relevant discussions and experimental comparisons.\n- In terms of model privacy, the privacy leakage of a black-box model is closely related to the number of queries [2], but the authors do not provide theoretical or empirical studies on this. \n- The experimental section lacks ablation experiments with varying levels of noise added on the transformed data and visualizations of transformed data.\n\n[1] Xiao, Guangxuan, Ji Lin, and Song Han. \"Offsite-tuning: Transfer learning without full model.\" arXiv preprint arXiv:2302.04870 (2023).  \n[2] Tsai, Yun-Yun, Pin-Yu Chen, and Tsung-Yi Ho. \"Transfer learning without knowing: Reprogramming black-box machine learning models with scarce data and limited resources.\" International Conference on Machine Learning. PMLR, 2020."
                },
                "questions": {
                    "value": "see weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7431/Reviewer_RdGi"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7431/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698701788892,
            "cdate": 1698701788892,
            "tmdate": 1699636892383,
            "mdate": 1699636892383,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "i2z6ia6Nkj",
                "forum": "U2ZIgcrg7Z",
                "replyto": "Nnhw0DRMWw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer RdGi"
                    },
                    "comment": {
                        "value": "Thanks for your acknowledgment in our *comprehensive experiments* and *intriguing*! We see that your main concerns are on details of *practicality*, *motivation*, *model privacy*, and *more experimental analysis*. Now we answer them here.\n\n1. The black-box FL setting lacks practicality. \n\nPlease refer to the general response for the problem setting.\n\n2.  The motivation for deploying zeroth-order optimization methods based on the local encrypted black-box model setup is not well-motivated. This setting implies that it is entirely possible to train an white-box emulator [1] as a proxy for the black-box model and directly perform first-order optimization based on the white-box emulator. However, the authors do not provide relevant discussions and experimental comparisons.\n\nIt is important to note that we are in a black-box setting while [1] uses a white-box setting. Thus, *the comparison with [1] is neither fair nor meaningful.* But we will cite [1] in the future.\n\nSpecifically, [1] involves compressing or substituting large models, requiring a deeper understanding, which differs from our current framework. We make the assumption that *the internals of large models are entirely unknown*. While training substitute models through obtaining outputs based on given inputs could be another avenue, as mentioned in our future work, 'Foundation models in ZOOPFL can be enhanced by other ways, e.g., auxiliary models, to serve as a complement to foundation models.' Currently, no one in the field has pursued this direction. Additionally, in our setup, each client has a limited amount of training data, potentially challenging the construction of robust substitute models ('For COVID-19, each client only has about 50 samples.').\n\n[1] Xiao, Guangxuan, Ji Lin, and Song Han. \"Offsite-tuning: Transfer learning without full model.\" arXiv preprint arXiv:2302.04870 (2023).\n\n3. In terms of model privacy, the privacy leakage of a black-box model is closely related to the number of queries [2], but the authors do not provide theoretical or empirical studies on this.\n\nA good question! However, our paper *does not* have such an issue. Why? The black-box models are in each client, and there is no data exchange between clients and servers, or between clients. \n\nRegarding the privacy protection of the model, it's not within the scope of consideration for our current paper. Our focus lies in exploring how to better leverage a black-box model provided by the model suppliers\u2014enhancing the alignment between local task inputs and outputs with the model. \n\n4. The experimental section lacks ablation experiments with varying levels of noise added on the transformed data and visualizations of transformed data.\n\n- First, we do have the experiments on varying levels of noise, as illustrated in Figure 6(b).\n- As for visualization, we add such extra experiments in the revised version, as illustrated in Appendix F.5. \n\nWe hope your concerns will be resolved and the rating of the paper can be increased accordingly. Thank you!"
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700384816309,
                "cdate": 1700384816309,
                "tmdate": 1700384816309,
                "mdate": 1700384816309,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9beNi98vOi",
            "forum": "U2ZIgcrg7Z",
            "replyto": "U2ZIgcrg7Z",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7431/Reviewer_hxrH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7431/Reviewer_hxrH"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed ZOOPFL, a zeroth-order optimization system for the black-box local model under a federated learning setup. Instead of directly fine-tune the black-box foundational model, ZOOPFL learns input surgery and semantic re-mapping for black-box large foundation models in federated learning. ZOOPFL aims to adapt inputs to models and project outputs to meaningful semantic space. The experiment shows that ZOOPFL performs better than the ZS setup in both NLP and CV benchmark datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. In the current foundational model era, the black-box foundational model is becoming popular. It is important to propose some ideas to efficiently personalize the foundational model without direct interference with it. Compared to other existing works related to foundational model with FL, the proposed ZOOPFL is the first to achieve federated learning with large black-box models, which is very relative to the current challenges.\n\n2. The paper is well-written and clearly structured. The author selects two different data modalities to validate the soundness of the proposed ZooPFL."
                },
                "weaknesses": {
                    "value": "1. The idea seems very similar to the soft-prompt training [1], which is also working on the input surgery without directly inference the foundational model. What is the benefit of the auto-encoder pre-training in your paper?\n\n2. What are the benefits of personalization? In the experiment part, it mainly focused on the overall accuracy boost compared to ZS, which does not reflect anything regarding to personalization.\n\n3. I suggest the paper should be more clear about the only baseline ZS. I checked several times in the paper, and I could not understand what ZS stands for and why it is a suitable baseline for ZooPFL.\n\n\n[1]. Wang, Zifeng et al. \u201cLearning to Prompt for Continual Learning.\u201d 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2021): 139-149."
                },
                "questions": {
                    "value": "1. What does ZS stand for in the paper? Does it stand for zero-shot training?\n\n2. I am curious why the author selected the personalized FL as a topic to discuss. Even without step 3, this paper still makes its point regarding how to efficiently use the black-box model under FL setup.\n\n3. I am not very clear why ZooPFL needs Semantic re-mapping. Could the author elaborate more on this?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7431/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698707536510,
            "cdate": 1698707536510,
            "tmdate": 1699636892238,
            "mdate": 1699636892238,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tFXoLKvn3u",
                "forum": "U2ZIgcrg7Z",
                "replyto": "9beNi98vOi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response To Reviewer hxrH"
                    },
                    "comment": {
                        "value": "Thanks for your acknowledgment in our paper: *the first to achieve federated learning with large black-box models* and *well-written and clearly structured*! We see that your main concerns are on details of *novelty*, *personalization*, *module functions*, and *concepts*. Now we answer them here.\n\n1. The idea seems very similar to the soft-prompt training [1], which is also working on the input surgery without directly inference the foundational model. What is the benefit of the auto-encoder pre-training in your paper?\n\nWe appreciate your recognition of the significance of [1] and we have cited this work in the revision. Where is the benefits of auto-encoder pre-training?\n\nWe use auto-encoders to alleviate the computational complexity associated with zeroth-order optimization. The rationale behind pre-training the auto-encoder stems from the need to adapt it to samples and tasks effectively. The pre-training step, as depicted in Figure 4 of the original manuscript, serves as a crucial aspect of our methodology, as illustrated by the ablation experiments.\n\nIn summary, we agree with your assessment and appreciate the opportunity to clarify the unique contributions of our work in addressing the where, how, and why aspects of input manipulation, particularly in the context of personalized federated learning with large black-box models. We will certainly emphasize the distinctions and innovations of our approach in the revised manuscript, giving due credit to the relevant literature, including Reference [1].\n\n[1] Wang, Zifeng et al. \u201cLearning to Prompt for Continual Learning.\u201d 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2021): 139-149.\n\n2. What are the benefits of personalization? In the experiment part, it mainly focused on the overall accuracy boost compared to ZS, which does not reflect anything regarding to personalization. Even without step 3, this paper still makes its point regarding how to efficiently use the black-box model under FL setup.\n\nIndeed, personalized learning stands out as one of the **most crucial and practical challenges** in FL [2], and our approach naturally tackles this issue. While we do furnish personalized outcomes for each client (as depicted in Figure 3 in the main text and Tables 4-6 in the appendix), constraints posed by page limitations compel us to emphasize average results in our report. It's worth noting that we explicitly stated in the original text, '**Our method achieves the best accuracy in most clients.**' \n\nWithout Step 3 or implementing Step 3 via FedAVG, our method seamlessly adapts to the common federated learning (FL) setting. However, the incorporation of Step 3 not only **enhances semantic matching** but also leads to **superior overall outcomes and personalized effects**.\n\n[2] Jian Xu, Xinyi Tong, and Shao-Lun Huang. Personalized federated learning with feature alignment and classifier collaboration. In The Eleventh International Conference on Learning Representations, 2023\n\n3. What does ZS stand for in the paper? Does it stand for zero-shot training?\n\nThe meaning of ZS is introduced in the paper: ZS denotes \"zero-shot pre-trained models\", i.e., zero-shot inference using the pre-trained models. And with all due respect, the term \"zero-shot training\" in your question is incorrect since we cannot \"zero-shot\" train a model if there is no sample available.\n\n4. I am not very clear why ZooPFL needs Semantic re-mapping. Could the author elaborate more on this?\n\nThe benefit of semantic remapping is introduced in the main paper. Here we explain it more. Short answer: the model outputs do not match the target task, so a re-mapping is needed.\n\nLong answer: As highlighted in our main text, \"Some popular language models such as BERT and GPT-2 in Huggingface utilize a random projection between extracted features and logits,\" and \"This step endeavors to re-map logits into meaningful semantic spaces with a simple linear projection.\" The intentional inclusion of a random mapping followed by a specific semantic mapping is justified in practical terms. Moreover, when meeting data not covered by foundation models, foundation models can be able to extract meaningful features but be unable to map it to expected target labels. Semantic re-mapping eliminates these gaps. The ablation experiments further substantiate the significance of this component.\n\n- - -\n\nWe hope your concerns will be resolved and the rating of the paper can be increased accordingly. Thank you!"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699965839338,
                "cdate": 1699965839338,
                "tmdate": 1699965839338,
                "mdate": 1699965839338,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JIU40s5HLK",
                "forum": "U2ZIgcrg7Z",
                "replyto": "tFXoLKvn3u",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_hxrH"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_hxrH"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the rebuttal, which clarifies most of my concerns. \n\nHowever, I agree with the Reviewer MDQp that most of the black-box models are hosted in the cloud, and transmitting data to the cloud indeed violates the privacy promise of FL. As a result, your application scenario is now limited to the locally-inference models, which means ZOOPFL is another novel way to efficiently fine-tune the large models without modifying the weights. If my understanding is correct, then PROMPTFL could also be used to fine-tune the black-box models, as it only appends a prompt learner in front of the large foundational model. Please let me know if my understanding is not correct."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700258455273,
                "cdate": 1700258455273,
                "tmdate": 1700258455273,
                "mdate": 1700258455273,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Czb6kdRAln",
                "forum": "U2ZIgcrg7Z",
                "replyto": "9beNi98vOi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the response. But we are upset that reviewer still cannot understand our situation.\n\nFirst of all, we are not dealing with cloud-hosted models but local ones on each client. The privacy concern makes this setting even more primary. Your understanding about this is correct. But this is not a minor setting.\n\nSecond, promptfl requires gradient to tune the prompt, which is not possible in the blackbox setting. As we discussed extensively in the related work part, prompt tuning is not possible.\n\nWe are glad that you read other review. But please also read other response to get a better understanding especially our general response."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700263087188,
                "cdate": 1700263087188,
                "tmdate": 1700263427479,
                "mdate": 1700263427479,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Vsb4g6PFuN",
            "forum": "U2ZIgcrg7Z",
            "replyto": "U2ZIgcrg7Z",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7431/Reviewer_1Crz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7431/Reviewer_1Crz"
            ],
            "content": {
                "summary": {
                    "value": "The authors designed a method that treats foundation models as black boxes. The idea is to use zeoth-order optimisation to  make sure that fine-tuning can be done efficiently on-device (e.g., to train through federated learning)"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Being able to fine-tune Foundation Models (FM) in a privacy-preserving way is an important problem\n- Overall this paper helps us understand the scenario of incorporating FM in FL settings. \n- The use of zeroth-order optimization, input surgery and semantic re-mapping are interesting contributions here"
                },
                "weaknesses": {
                    "value": "Some areas to improve:\n\n- While the idea of using FM as black box is interesting, there might be some privacy implications. It is unclear if the input to the FM reveals any information about the private input that is used both for training and during inference. I assume that the FM --being a black box and too big to be hosted on-device-- is run externally). As a result, this method might limit the ability of FL to offer privacy-preserving training. \nIn other words,  If we assume that the \"black box\" in figure 2.b runs externally, what are the privacy implications wrt to its input and output crossing the device boundary. If it runs on-device then what are the assumptions wrt to its size and the fact that it is a black box. \n\n- The authors assume that the FM is a black box. With more and more FM being open-sourced, it would be great if the authors can further motivate their approach and what might be the main advantages of incorporating a black box. \n\n- The evaluation is mostly done on rather simple benchmarks. I was wondering if the proposed approach (to train just parts of the model) would carry enough capacity to tackle larger tasks. Maybe some discussion or even evaluation on a more complex task would be great. \n\n- The paper might benefit from some understanding of the memory footprint and computation complexity of this method. Overall, the main target of this method is to make FM training possible with FL (on-device). As a result, we should have a good understanding on the memory/computation overhead."
                },
                "questions": {
                    "value": "See above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7431/Reviewer_1Crz"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7431/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698772952418,
            "cdate": 1698772952418,
            "tmdate": 1699636892116,
            "mdate": 1699636892116,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Nx2BbFKPhE",
                "forum": "U2ZIgcrg7Z",
                "replyto": "Vsb4g6PFuN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response To Reviewer 1Crz"
                    },
                    "comment": {
                        "value": "Thanks for your acknowledgment of the paper: *an important problem*, *helps us understand the scenario of incorporating FM in FL settings*, and *interesting contributions*! We see that your main concerns are on details of *privacy implication*, *more FM*, *larger task*, and *the memory footprint and computation complexity*. Now we answer them here.\n\n1. If we assume that the \"black box\" in figure 2.b runs externally, what are the privacy implications wrt to its input and output crossing the device boundary. If it runs on-device then what are the assumptions wrt to its size and the fact that it is a black box.\n\n- First, we currently do not assume cross-device data exchange following existing work on PFL. So, the privacy issue does not exist.\n- Second, for on-device training of our model, the sizes of models and data highly depend on the local computation hardware, but not our algorithm. By design, our algorithm supports all kinds of models and datasets.\n\n2. The authors assume that the FM is a black box. With more and more FM being open-sourced, it would be great if the authors can further motivate their approach and what might be the main advantages of incorporating a black box.\n\nPlease refer to the general response for the detailed answer.\n\nShort answer: even if you can have full access to the model locally, it is still expensive to actually train them. \"Black-box\" does not equal to close-source, even open-source models are expensive to train on ordinary devices. \n\n3. The evaluation is mostly done on rather simple benchmarks. I was wondering if the proposed approach (to train just parts of the model) would carry enough capacity to tackle larger tasks. Maybe some discussion or even evaluation on a more complex task would be great.\n\nIn actuality, our study encompassed extensive experimentation across **eight** datasets that include **two modalities**: COVID-19, APTOS, Terra100, Terra46, SST2, COLA, Financial-phrasebank (Financial), and Flipkart. The results from these experiments underline the superiority of the framework proposed in our study. \n\nPlease be aware that the tasks we have selected are currently **not adequately addressed or poorly performed** by large models. Our aim is to align these large models with specific tasks, **rather than undergoing retraining**. Consequently, we do not require an abundance of data or a larger dataset.\n\n4. The paper might benefit from some understanding of the memory footprint and computation complexity of this method. Overall, the main target of this method is to make FM training possible with FL (on-device). As a result, we should have a good understanding on the memory/computation overhead.\n\nThe answer is simple: we only introduce *negligible* memory and computation burden to the foundation models.\n\nAs depicted in Figure 4(d) of the original paper, it's evident that the parameters adjusted by our method are significantly smaller in scale compared to the large foundation models. This aspect reinforces the notion that our approach hones in on a smaller subset, effectively **tailoring the model's adjustments**, rather than necessitating the manipulation or direct handling of the entire foundation model. Our emphasis remains on the utilization of these large models as protected tools within federated learning, ensuring their functionality while mitigating the challenges associated with their training costs.\n\n- - -\n\nWe hope your concerns will be resolved and the rating of the paper can be increased accordingly. Thank you!"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699965764862,
                "cdate": 1699965764862,
                "tmdate": 1699965764862,
                "mdate": 1699965764862,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "RSKdKdiypw",
            "forum": "U2ZIgcrg7Z",
            "replyto": "U2ZIgcrg7Z",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a method for personalized federated learning (FL) while relying on the existence of foundation models at clients. The main idea is to train some additional components (auto-encoder and semantic re-mapping) that are applied before or after the foundation model. Zeroth-order optimization has been applied due to the assumption that the foundation model cannot be accessed for purposes other than inference. Experimental results confirm the advantage of the proposed method compared to some baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The consideration of foundation models in FL is an important research direction."
                },
                "weaknesses": {
                    "value": "- The paper assumes that foundation models are located at FL clients, but the clients cannot perform back-propagation on these models. It is not clear in what practical scenario such an assumption would hold. It is worth noting that most large language models (LLMs) nowadays are hosted in the cloud. Obviously, transmitting data to the cloud, even for inference, violates the privacy promise provided by FL. It seems that the authors of this paper try to overcome this privacy violation by assuming that the foundation model is hosted on each client. However, this has several issues. First, many types of LLMs are not feasible to run on mobile devices, which means that the proposed approach may only be possible in the case of cross-silo FL but not cross-device FL. Second, and more importantly, if the foundation model is hosted at the client, it is unclear why gradients cannot be computed, since each client has full access to its model in this case. \n- Overall, the proposed approach is a combination of several known techniques, including zeroth-order optimization, so the novelty seems limited. \n- The method requires additional components to be added to an existing foundation model, which appears to be a patch instead of a long-term solution. These additional components will cause additional computational overhead, which has not been studied in the paper."
                },
                "questions": {
                    "value": "My questions are related to the weaknesses mentioned above, which are summarized as follows:\n- In what practical scenario would a FL client host a foundation model, but does not have full access to it?\n- What are the key technical challenges and novel solution in this work?\n- What is the additional computational overhead of the additional components (auto-encoder and semantic re-mapping) in the proposed method, when the full combined model is used for inference? It would be helpful to measure and compare the inference time with and without these additional components on a real device."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7431/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699233190023,
            "cdate": 1699233190023,
            "tmdate": 1700584671956,
            "mdate": 1700584671956,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "f9fsbqQPEI",
                "forum": "U2ZIgcrg7Z",
                "replyto": "RSKdKdiypw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response To Reviewer MDQp"
                    },
                    "comment": {
                        "value": "Thanks for your acknowledgment in our *research direction*! We see that your main concerns are on details of *practical scenario*, *novelty*, and *computational overhead*. Now we answer them here.\n\n1. In what practical scenario would a FL client host a foundation model, but does not have full access to it?\n\nPlease refer to the general response for a better understanding of our problem setting.\n\nShort answer: *The understanding of the word \"black-box\" could be broad.* Black-box does not only deal with the case where one has no full access to the model; even if you have the model access, it is still extremely expensive to run model updates (Backpropagation) on the local devices given the increasing larger sizes of the models. As an example used in the paper, 'training GPT-2-small (Radford et al., 2019) requires at least two A100 GPUs for 16 hours, a resource unavailable to many'. We are a solution of using inference for BP to save computation and communication costs.\n\n2. What are the key technical challenges and novel solution in this work?\n\nKey technical challenges:\n- efficiently update the foundation models locally\n- distribution divergence in different clients\n\nOur innovations to deal with them:\n- A first pioneering exploration of the problem where models become too large to update, while FL clients still want to preserve privacy by not sharing data with the central server.\n- A new framework to handle the problem using zeroth order optimization.\n- We offer theoretical analysis along with extensive experiments to show the effectiveness of our work.\n\n3. What is the additional computational overhead of the additional components (auto-encoder and semantic re-mapping) in the proposed method, when the full combined model is used for inference? \n\nSimple: the additional computation costs are *negligible* compared to the huge cost of the foundation models. Quantitatively speaking, as depicted in Figure 4(d), the parameter volume of the head-tail adjustment module is **several orders of magnitude smaller** compared to the foundation model.\n\nIf you think these responses address your concerns, please consider increasing your score. Thank you!"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699965607636,
                "cdate": 1699965607636,
                "tmdate": 1699965607636,
                "mdate": 1699965607636,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lUAoSwUP1O",
                "forum": "U2ZIgcrg7Z",
                "replyto": "Czb6kdRAln",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "content": {
                    "comment": {
                        "value": "I guess the question (at least to me) is: since zeroth order optimization is a known algorithm, can it be applied to prompt tuning as well? As long as a zeroth order algorithm is used, there is no need to compute the gradients. How would applying zeroth order optimization to prompt tuning compare to applying it in your current approach?"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700267858350,
                "cdate": 1700267858350,
                "tmdate": 1700267858350,
                "mdate": 1700267858350,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Rr2XSYuVVD",
                "forum": "U2ZIgcrg7Z",
                "replyto": "UglEF4QqhU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "content": {
                    "comment": {
                        "value": "Initial explorations should be submitted to workshops. Conference papers (at least in the field of machine learning) should generally be a piece of established work."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700276828906,
                "cdate": 1700276828906,
                "tmdate": 1700276828906,
                "mdate": 1700276828906,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IKf7ND1db8",
                "forum": "U2ZIgcrg7Z",
                "replyto": "nPeSy7ZXbP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the response. The authors claim that their proposed black-box FL has \"low cost\". However, I do not see anywhere in the experiments that measures this cost compared to baselines. \n\nFurthermore, the writing of the paper needs substantial improvement. For example:\n- The experiments use \"ZS\" as a baseline, but it is not clear what ZS stands for (I couldn't find it from the paper). \n- In Theorem 1, I cannot find the definitions of the quantities $\\Delta_\\mathbf{u}$ and $\\Delta_\\mathbf{v}$. \n- In Algorithm 1 (in Appendix C), $s_i$ and $r_i$ are part of the output, but the algorithm does not seem to include any step for computing $s_i$ and $r_i$. How are they computed?\n\nUnfortunately, the more carefully I read the paper, the more I find the paper to be lacking scientific rigor. Even cleaning up all the definitions and other details requires a thorough and careful revision, besides other issues. It is clearly not ready for publication in its current form."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700281962934,
                "cdate": 1700281962934,
                "tmdate": 1700281962934,
                "mdate": 1700281962934,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "e61wNpnwNu",
                "forum": "U2ZIgcrg7Z",
                "replyto": "2kfaNiH644",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks. Regarding \u201cIn Figure 4(c), we mentioned the number of parameters, stating that fewer parameters imply lower cost under similar conditions,\u201d the number of parameters cannot capture the difference in cost between forward propagation only and forward+backward propagation, which is the key difference between zeroth order optimization and existing first-order based approaches. Some other metric, such as FLOPs, memory consumption, or running time, would be needed for a meaningful comparison between the two types of approaches."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700286926018,
                "cdate": 1700286926018,
                "tmdate": 1700286926018,
                "mdate": 1700286926018,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8ITomW7opX",
                "forum": "U2ZIgcrg7Z",
                "replyto": "sSvkIyNMlF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks. If the authors can make the edits as discussed, to improve the clarity and rigor of the paper, I would be happy to raise my score. \n\nIn general, the main paper should be self-contained with all the variables properly defined. Having variables appearing in the main theorem defined in the appendix is not appropriate in my opinion, since reviewers and other readers are not expected to read the appendix in order to understand the main conclusions in the paper."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700319122048,
                "cdate": 1700319122048,
                "tmdate": 1700319122048,
                "mdate": 1700319122048,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kdg94tx7Ds",
                "forum": "U2ZIgcrg7Z",
                "replyto": "CTmwuBZ7Z4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "content": {
                    "comment": {
                        "value": "I see that an author of this paper has posted on social media that I\u2019m an emotional reviewer and would like to reject this paper due to this comment. That\u2019s not my point. My main point in the comment about \u201cinitial exploration\u201d is that all full papers should be rigorous with the claims being sufficiently validated, either theoretically or empirically. The paper should make a contribution that is new and interesting to the research community. It is fine to have limitations, but they should be acknowledged. As I mentioned in the comments at the top, this paper in its current form lacks rigor and there is clearly space for improvement. I\u2019m happy to raise the score if such improvements can be made. \n\nI shall also say that I am disappointed that the authors seem to be trying to \u201cbypass\u201d the comment about prompt tuning in this thread, by saying that their framework is general enough and can include \u201ceverything\u201d, but they do not consider it due to \u201cinitial exploration\u201d. In my opinion, this is neither a meaningful argument nor a rigorous way of thinking. Instead, I would expect the authors to explain **why** they use their current method in this study and do not consider alternatives like prompt tuning. \n\nI am also a bit disappointed that the authors use emotional words like \u201cupset\u201d in their response. While I can understand the frustration, such words are not helpful for a meaningful discussion. To be honest, I rarely (if ever) see such kind of wording or attitude in other discussions. \n\nPlease do not post emotional comments on social media. As a reviewer, my main goal is to make a proper evaluation for every paper to my best effort, for the fairness of both the authors and everyone in the community. I also try to help the authors improve their paper whenever possible. However, if the author says in their social media post themself that I should reject the paper, I am not sure what I should do, but I will still try my best to make a professional judgement and not be biased by such non-technical factors."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322517103,
                "cdate": 1700322517103,
                "tmdate": 1700322517103,
                "mdate": 1700322517103,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UiUsGm9R1w",
                "forum": "U2ZIgcrg7Z",
                "replyto": "01wHb0rt61",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the update. It may be good to add this result to the paper as well, unless the authors think otherwise."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700580573870,
                "cdate": 1700580573870,
                "tmdate": 1700580573870,
                "mdate": 1700580573870,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LXnUVd40wM",
                "forum": "U2ZIgcrg7Z",
                "replyto": "rcYGEwnYFp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the updates. For Table 3 containing the new results, could you explain why your method consumes less GPU memory although it includes additional processing? Do you use more CPU instead of GPU?\n\nIn addition, as mentioned in my [earlier comment](https://openreview.net/forum?id=U2ZIgcrg7Z&noteId=e61wNpnwNu), it would be nice to compare the difference in cost between forward propagation only and forward+backward propagation, which is the key difference between zeroth order optimization and existing first-order based approaches. The current results do not seem to include this comparison. In other words, it would be nice to include some empirical evidence showing the advantage of zeroth-order optimization in terms of computational efficiency."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700581348024,
                "cdate": 1700581348024,
                "tmdate": 1700581348024,
                "mdate": 1700581348024,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "L0jYp7AGcW",
                "forum": "U2ZIgcrg7Z",
                "replyto": "PuKtaPtulo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "content": {
                    "comment": {
                        "value": "Sounds good to me. No problem."
                    }
                },
                "number": 27,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700584200502,
                "cdate": 1700584200502,
                "tmdate": 1700584200502,
                "mdate": 1700584200502,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yvpz7tY5nE",
                "forum": "U2ZIgcrg7Z",
                "replyto": "QcXii5qhyG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission7431/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7431/Reviewer_MDQp"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the explanation. Could you perhaps list the cost of training and cost of inference in separate tables (or subtables), and add a bit more explanation to each of them? I think even the fact that ZOO saves GPU memory during training is a nice characteristic of it, which is worth highlighting. \n\nI'll raise my score to 6."
                    }
                },
                "number": 28,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700584631258,
                "cdate": 1700584631258,
                "tmdate": 1700584631258,
                "mdate": 1700584631258,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]