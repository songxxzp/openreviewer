[
    {
        "title": "Certainty In, Certainty Out: REVQCs for Quantum Machine Learning"
    },
    {
        "review": {
            "id": "MJzu1MBjll",
            "forum": "6cDEcJsE1Y",
            "replyto": "6cDEcJsE1Y",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1985/Reviewer_eDnW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1985/Reviewer_eDnW"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses the fundamental issue of statistical uncertainty in QML. It tries to solve this problem by training algorithms that achieve high single sample accuracy. The paper claims to have an algorithm that can optimize for this goal. Some numerical results are presented that show improvements in  dimension-reduced  datasets."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Tries to address a fundamental issue in QML. Statistical uncertainty due to shot noise is fundamental in all QML methods. Overcoming this barrier is necessary to make QML scalable in the future."
                },
                "weaknesses": {
                    "value": "1. What is the exact definition REVQC? How exactly is the model trained so as to reduce single sample uncertainty? The authors claim to define this in Section 3. But Section 3 does not contain anything concrete on what this new training method is.\n\n2. The authors repeat the fact that quantum circuits are unitary and hence reversible and this somehow helps in reducing the uncertanity in the output. This is connection is not well explained in the text. Overall, the paper needs substantial rewriting with a lot more mathematical detail.\n\n3. The method is tested on datasets that are projected onto a smaller space using PCA. I understand that this is necessary  for  QML as we don't have actual quantum systems. But results on such small datasets is not enough justification for the claim that these methods are somehow interesting. This makes these types of works very unsuitable for a venue like ICLR. A specialized venue for QML would be more suitable. This work would be suitable for ICLR  If the authors can give some stronger theoretical results regarding their method. \n\nWhile there might be some interesting in this work, overall the paper does not explain the main contribution well. A significant rewrite is required before peer-review."
                },
                "questions": {
                    "value": "1. Can you show how REVQC is different from standard training of parametrized circuits?\n\n2. Can you clarify how the unitarity of these circuits are useful in reducing uncertainty in the output?\n\n3. In the caption of  Figure 1. How does one train a VQC using back propagation?  The authors rightly claim in the beginning of the paper that this is not possible."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1985/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1985/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1985/Reviewer_eDnW"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1985/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697840240791,
            "cdate": 1697840240791,
            "tmdate": 1699636130179,
            "mdate": 1699636130179,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "7ZHEgINePg",
            "forum": "6cDEcJsE1Y",
            "replyto": "6cDEcJsE1Y",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1985/Reviewer_Udj4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1985/Reviewer_Udj4"
            ],
            "content": {
                "summary": {
                    "value": "Quantum machine learning models typically identify expectation values of observables as predictions. This increases uncertainty and requires many shots to estimate the prediction accurately. In this paper, the author propose a new method to train a variational quantum circuit: by fixing the labels as inputs of the reverse circuits and train the model to reconstruct the inputs. Experiments are proposed to validate the idea that this procedure leads to single sample accuracy higher than expectation value accuracy."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- Identify challenges of VQC training and discuss uncertainty in QML \n- Analysis trying to explain why REVQC is better than std VQC"
                },
                "weaknesses": {
                    "value": "- Choice of architecture: a QCNN model from [Hur et al] is used for benchmarking VQC. The model is deemed highly expressive, however in table 1-4 this leads to accuracy of about 50% for a binary classification problem (equal to random guessing). In contrast, simple ansatz like [https://www.tensorflow.org/quantum/tutorials/mnist] achieve 85% test set accuracy for a similar task. Also, I do not understand why a CNN structure is used, since the data is produced via PCA I would not expect the label to be invariant under shifts of the inputs.\n- Choice of benchmark: the experimental setting of using 8 qubits and MNIST and Fashion MNIST makes it difficult to learn general lessons about the behaviour of ML models. I think that more experiments should be done to assess the soundness of the method.\n\nMinor:\n- Section 2: \"they do not pertain to discrete outputs\". I find this confusing since QAOA aims to converge the quantum state to the bit string that solve the classical optimisation problem.\n- Section 3: \"(complex angle-preserving)\" should be \"(norm-preserving)\"?\n- Section 5: \"the model can be represented as a mixed-state\". I find this and the discussion around it confusing since it's an operator not a state. Did you mean a completely positive map?\n- Section 5: \"Quantum models are not universal function approximators\". I think that this depends on what space of functions one looks at. In the space of Boolean functions they are - since they generalize reversible computation which is universal. So a clarification might be helpful.\n- Duplicate [Hur et al] reference"
                },
                "questions": {
                    "value": "- What happens if you use a different architecture for the VQC that achieves higher accuracy than 50%?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1985/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698740863590,
            "cdate": 1698740863590,
            "tmdate": 1699636130087,
            "mdate": 1699636130087,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "ReaVLubdO3",
            "forum": "6cDEcJsE1Y",
            "replyto": "6cDEcJsE1Y",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1985/Reviewer_2wYu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1985/Reviewer_2wYu"
            ],
            "content": {
                "summary": {
                    "value": "In this work, the authors put forth effective training methods to improve the optimization performance of variational quantum circuit-based machine learning tasks. In particular, the proposed approach demonstrates an outstanding performance in single-sample inference tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The idea of improving the VQC training efficiency, especially on NISQ devices, is interesting. \n\n2. The authors conduct comprehensive experiments to demonstrate the effectiveness of the proposed methods."
                },
                "weaknesses": {
                    "value": "There are so many weaknesses in this paper, hinging it from being accepted. \n\n1. Some technical claims are not correct. \n\n    (a)  In the Introduction part, the sentence \"QML models still cannot be back-propagated from samples\" is not correctly claimed. The parameters of QML models like quantum neural networks can be well-adjusted using a back-propagation approach when simulating on a classical CPU/GPU, and a parameter-shift rule can be employed to estimate the gradients for back-propagation. \n  \n   (b) In Backgrounds of Methods, the description of \"Quantum gates are the quantum equivalent of classical (reversible) gates\" is incorrect. The quantum gates can be described as unitary matrices and can be classically simulated on classical computers, but they can be taken as some equivalent classical gates like \"And\" & \"Or\" gates. \n\n2. As shown in Figure 2, it is very confusing to use CNN representing a quantum gate. CNN denotes a classical convolutional neural network, but the authors intend to showcase a quantum convolutional neural network. \n\n3. The use of multi-quit CNN can make it difficult to be well-trained on NISQ devices. In particular, they have to suffer from very serious Barren plateau problems. Besides, since multi-qubit can be decomposed as the combination of single-qubit gates, the circuit diagram in Figure can be further optimized. \n\n4. The MSE loss function is not optimal for VQC-based regression, as the MAE loss is a better choice than the MAE. The authors can refer to the theoretical work as:\n\nRef. Qi, J., Yang, C.H.H., Chen, P.Y. and Hsieh, M.H., 2023. Theoretical error performance analysis for variational quantum circuit based functional regression. npj Quantum Information, 9(1), p.4.\n\n5. In the experimental part, the baseline results of VQC on the MNIST datasets are extremely low, which is not correct. Many works of VQC for classification demonstrate that a VQC can attain much higher accuracy. \n\nRef. Chen, S.Y.C., Huang, C.M., Hsing, C.W. and Kao, Y.J., 2021. An end-to-end trainable hybrid classical-quantum classifier. Machine Learning: Science and Technology, 2(4), p.045021.\n\n6. The paper devotes much content to the background introduction of quantum technologies, but it does not highlight the main contribution of the proposed methods."
                },
                "questions": {
                    "value": "1. Why are the baseline results of VQC so low? \n\n2. Is a non-linear activation method used for the VQC? If not, how does  the VQC approximate a complicated target function when conducting regression?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1985/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698792250077,
            "cdate": 1698792250077,
            "tmdate": 1699636129991,
            "mdate": 1699636129991,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]