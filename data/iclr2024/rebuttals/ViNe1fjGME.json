[
    {
        "title": "Deep Temporal Graph Clustering"
    },
    {
        "review": {
            "id": "O5uowPKcjD",
            "forum": "ViNe1fjGME",
            "replyto": "ViNe1fjGME",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6696/Reviewer_PosK"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6696/Reviewer_PosK"
            ],
            "content": {
                "summary": {
                    "value": "This paper expands deep graph clustering to temporal graphs from four aspects, including problem, algorithm, dataset, and evaluation. A generalized framework named TGC is proposed for temporal graph clustering. The authors demonstrate the superiority of TGC and provide sound insights via extensive experiments."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "+ The motivation is clear. It is meaningful to expand deep clustering to temporal graphs. The presentation is excellent. \n\n+ The core idea is novel and easy to follow. The temporal loss mines graph temporal information and the clustering loss is improved with node-level distribution and batch-level reconstruction. \n\n+ The experiments are comprehensive. The analyses provide many significant insights for temporal graph clustering."
                },
                "weaknesses": {
                    "value": "- The authors just conduct the clustering algorithms one run. However, most clustering algorithms are not robust and are sensitive to random seeds.\n\n- The performance of TGC on the Brain dataset is not promising. Please provide the explanation and analyses. \n\n- The related work section is limited. The authors need to survey and compare more papers published in 2022 and 2023. \n\n- Missing middle-scale datasets. The authors should explore the dataset size boundaries of the statics deep graph clustering methods.\n\n- The chronological order training is a strong restriction. I\u2019m concerned that such as this strong strict will limit the performance on some datasets. As I know, some methods can disrupt the graph structure for training. \n\n- In Figure 11, point out which sub-figure represents the result on which dataset. Besides, ablation studies should be provided in the main text. Figure 2 is too small. In addition, there seems to be something wrong with the commas.\n\n- Have you considered explaining the relationship between the number of nodes in the static graph and the number of edges in the temporal graph further? This is an exciting topic, i.e., what is the difference in the way of thinking about a problem when the focus shifts from nodes to edges?"
                },
                "questions": {
                    "value": "See Strengths and Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6696/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697771601004,
            "cdate": 1697771601004,
            "tmdate": 1699636768597,
            "mdate": 1699636768597,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "aVCoenijaU",
                "forum": "ViNe1fjGME",
                "replyto": "O5uowPKcjD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6696/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6696/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer PosK [1/2]"
                    },
                    "comment": {
                        "value": "We thank the Reviewer PosK for the detailed and constructive review. We greatly appreciate the valuable insights and extensive expertise reflected in your comments. Irrespective of the final acceptance of the article, we extend our sincerest gratitude for your suggestions, which have significantly enhanced the overall quality of our work. We respond to the comments one by one.\n\n> Due to space constraints, we have added the needed figures and tables to the last subsection (Page 21) of the appendix for your review. The rest of the text will be added after a subsequent reorganization of the article layout.\n\n## **Experimental Repeatability**\n\n+ This is an oversight in our presentation; our results are averaged over three experiments performed, not just one run. It is only due to restricted table space that we do not report the margin of error for each result.\n\n## **Performance on Brain**\n\n+ This can actually support our assertion that depth map clustering and temporal graph clustering are complementary and that they are applicable in different situations, rather than who is to replace whom. \n\n+ For temporal graph data, when the number of nodes and edges is small, i.e., the graph scale is small, it is perfectly possible to learn by means of deep graph clustering. As in the case of the Brain dataset, deep graph clustering is able to obtain a more complete neighborhood structure, which is advantageous for clustering. In this case, temporal graph clustering may not be more effective than depth graph clustering.\n\n+ However, when executed on large-scale datasets (e.g., arXIvCS), these depth graph clustering methods can suffer from OOM problems due to their inability to handle large-scale neighbor matrices. In this case, temporal graph clustering has its place.\n\n## **Related Work**\n\n+ Thanks to your reminder, we will introduce some relevant papers published in 2022 and 2023 in the Related Work Section [1-5]. Due to page constraints, we may consider including this section in detail in the appendix.\n\n> [1] Wang, Tianchun, et al. DyExplainer: Explainable Dynamic Graph Neural Networks. WSDM 2024.\n\n> [2] Feng, Kaituo, et al. Towards Open Temporal Graph Neural Networks. ICLR 2023.\n\n> [3] Liu, Meng, et al. TMac: Temporal Multi-Modal Graph Learning for Acoustic Event Classification. ACM MM 2023.\n\n> [4] Zheng, Yanping, et al. Decoupled Graph Neural Networks for Large Dynamic Graphs. VLDB 2023.\n\n> [5] Luo, Yuhong, et al. Neighborhood-aware Scalable Temporal Network Representation Learning. LOG 2022 Best Paper.\n\n## **About Middle-Scale Datasets**\n\n+ We should recognize that we have not consider the middle-scale datasets.  This is because it is already difficult to find public datasets suitable for temporal graph clustering, and even more difficult to satisfy the scale requirements. As shown in Table 4, we summarize some common public datasets, and we can see that these datasets can generally be classified into three categories.\n\n+ The first category is datasets without usable labels (e.g., CollegeMsg), and in fact most of the common temporal graph datasets are of this type. The second category is those with untrustworthy labels (e.g., Bitcoin), and we have conducted experiments on datasets in this category, and their experimental results are often lower than 5\\% or even 1\\%, which means that it is difficult to measure the clustering performance with such node labels. The third category, i.e., the datasets we selected, may have some datasets with smaller sizes and some datasets with fewer timestamps, but these are already as suitable as possible for temporal graph clustering.\n\n+ Therefore, in this case, it is difficult to find all the datasets that fulfill the different scales. In the future, we will consider designing and developing more temporal graph clustering datasets with different scales."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6696/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700116004508,
                "cdate": 1700116004508,
                "tmdate": 1700187132424,
                "mdate": 1700187132424,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PazHfWkRAF",
                "forum": "ViNe1fjGME",
                "replyto": "O5uowPKcjD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6696/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6696/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer PosK [2/2]"
                    },
                    "comment": {
                        "value": "## **Training Order**\n\n+ This is exactly the problem we wanted to point out, namely that the destruction of the graph structure has the potential to cause a loss of information about the graph structure. As we mentioned in the article: Suppose there is an interaction between two nodes in a subgraph occurs in 2023, while an edge between a subgraph and another So how do we reverse time the information from 2023 and pass it on in 2020?\n\n+ In some scenarios where temporal information is more important, the destruction of the graph structure and thus the reverse propagation of information can instead negatively affect the clustering effect. Therefore, in our opinion, this strict time entry order is instead one of the advantages of temporal graph clustering, i.e., this guarantees a strict order of information transfer.\n\n## **Figures and Ablation Study**\n\n+ Regarding the ablation experiments of TGC node-level modules and batch-level modules, we provide the relevant experimental results in the Appendix section, as shown in Fig. 11. They are, in order, DBLP, Brain, Patent, School, arXivAI and arXivCS.\n\n+ In addition, parameter sensitivity experiments on different datasets are provided in Fig. 5-Fig. 10. Due to space constraints, we did not put these experiments in the main text, after which we will consider adjusting the layout of the article. For the other issues you mentioned, we will amend them one by one, thank you for your correction.\n\n## **Discussion from Node to Interaction**\n\n+ You ask a very insightful question, which provokes us to think deeper: what exactly are we focusing on once the center of attention has shifted from nodes to edges?\n\n+ First of all, the treatment of data becomes different, which is of course obvious, and we discuss this throughout. The fact that temporal graphs record data as a sequence of interactions and can thus be trained in batches brings more flexibility to the temporal graph approach, but at the same time many opportunities to use classical techniques are lost. Therefore we would like to emphasize that temporal graph clustering is not proposed to replace depth graph clustering on temporal graphs, it is proposed to provide more possibilities for researchers in. When researchers feel that static graph clustering is not very suitable, they can have one more option of temporal graph clustering.\n\n+ In addition, the perspective of measuring the size of the dataset has changed. Static graphs judge the size of the graph by the number of nodes, while temporal graphs judge it by the number of interactions. This means that the two types of methods refer to different sizes when faced with large-scale problems. Although the number of nodes and the number of interactions tend to grow together, there are differences. For example, in several of the datasets we have given, the Brain dataset is clearly a large-scale temporal graph dataset.\n\n+ Finally, we would like to point out to the readers that for temporal graph clustering, which is full of countless expandable spaces, this is still a near-new field. There are many classical techniques that need to be adapted to be applicable to temporal graphs, and this process of adaptation is the way to fully exploit temporal graph data."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6696/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700116128644,
                "cdate": 1700116128644,
                "tmdate": 1700183865054,
                "mdate": 1700183865054,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ozV4gwfmmZ",
                "forum": "ViNe1fjGME",
                "replyto": "O5uowPKcjD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6696/Reviewer_PosK"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6696/Reviewer_PosK"
                ],
                "content": {
                    "comment": {
                        "value": "The authors have addressed most of my concerns well. I think this is an innovative work in temporal graph clustering that can inspire other researchers in the community, so I recommend accepting this paper."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6696/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700446042671,
                "cdate": 1700446042671,
                "tmdate": 1700446042671,
                "mdate": 1700446042671,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "J81DytcBEk",
            "forum": "ViNe1fjGME",
            "replyto": "ViNe1fjGME",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6696/Reviewer_Euq6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6696/Reviewer_Euq6"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies temporal graph clustering via graph neural networks. Temporal graphs have been widely investigated in the graph community. However, the topic of temporal graph clustering is less explored. The authors argue that this is because of lacking datasets suitable for clustering, thus several datasets are carefully selected by the authors for experiments. Moreover, the authors also introduce two tricks (i.e., clustering assignment distribution and adjacency matrix reconstruction) to improve existing models\u2019 performance on temporal graph clustering task. Experimental results on 6 public datasets demonstrate that the proposed general framework TGC can outperform recent baselines with different gains."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1)\tThis paper investigates temporal graph clustering, which is less explored in the graph community.\n2)\tBoth large and small datasets are used in the experimental sections and the results demonstrate the proposed model achieve really good performance.\n3)\tMemory consumption and running time are reported to show the efficiency of the proposed framework.\n4)\tAblation studies are given to show the effectiveness of the proposed components."
                },
                "weaknesses": {
                    "value": "1)\tThe technical contribution of this paper is very limited. The two introduced tricks (i.e., clustering assignment distribution and adjacency matrix reconstruction) have been widely used by existing works. Eq. 6 and Eq. 7 are commonly utilized in existing static graph clustering models. No new models are proposed in this paper.\n\n[1] Bo D, Wang X, Shi C, et al. Structural deep clustering network[C]//Proceedings of the web conference 2020. 2020: 1400-1410.\n\n[2] Xie J, Girshick R, Farhadi A. Unsupervised deep embedding for clustering analysis[C]//International conference on machine learning. PMLR, 2016: 478-487.\n\n2)\tThis paper studies continuous-time dynamic graphs. The authors argue that their selected datasets are more suitable for temporal graph clustering tasks. However, it seems that it is not true. As we can see in Table 1, most of the selected datasets have very limited timestamps, which is not consistent with their claimed continuous-time dynamic graphs. They are more like discrete-time dynamic graphs. For example, the DBLP, arXivAI and arXivCS datasets usually contain publication year only. \n3)\tThe comparisons of GPU memory usage are not fair in Figure 2. The authors only compare their TGC with static deep clustering baselines that feed whole graphs. The authors should compare their TGC with existing temporal graph clustering baselines like HTNE, TGAT, JODIE, etc. The low consumption of TGC largely depend on its backbone model HTNE, thus it is hardly to say this is the advantage of TGC. This comment can also be applied to Figure 3. The running time should also compare with other temporal baselines.\n4)\tIn Figure 4, it is not clear what is TGN + TGC? Since TGC is based on HTNE, I guess what you mean is applying clustering assignment distribution and adjacency matrix reconstruction to TGN. If so, please give the ablation studies on each component.\n\nThere are lots of typos in the paper. Some of them are listed as follows:\n\n\u201cA sample general framework\u201d should be \u201cA simple general framework\u2026\u201d\n\n\u201cwhich we do not discuss here\u201d should be \u201cthat we do not discuss here\u201d\n\n\u201cThen We conduct\u201d should be \u201cThen, we conduct\u201d"
                },
                "questions": {
                    "value": "1)\tThe comparisons of GPU memory usage are not fair in Figure 2. The authors only compare their TGC with static deep clustering baselines that feed whole graphs.\n2)\tThe running time should also compare with other temporal baselines.\n3)\tIt is not clear how clustering assignment distribution and adjacency matrix reconstruction will individually impact the model's performance."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No ethics review needed"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6696/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6696/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6696/Reviewer_Euq6"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6696/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698567326527,
            "cdate": 1698567326527,
            "tmdate": 1700629887424,
            "mdate": 1700629887424,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4hL2UNIjq4",
                "forum": "ViNe1fjGME",
                "replyto": "J81DytcBEk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6696/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6696/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Euq6 [1/3]"
                    },
                    "comment": {
                        "value": "We thank the Reviewer Euq6 for the detailed and constructive review. We greatly appreciate the valuable insights and extensive expertise reflected in your comments. Irrespective of the final acceptance of the article, we extend our sincerest gratitude for your suggestions, which have significantly enhanced the overall quality of our work. We respond to the comments one by one.\n\n> Due to space constraints, we have added the needed figures and tables to the last subsection (Page 21) of the appendix for your review. The rest of the text will be added after a subsequent reorganization of the article layout.\n\n## **Technical Contribution**\n\nThank you for your comment. Before discussing this issue, we would like to reiterate our contributions.\n\n+ (1) Our contributions can be divided into four parts. For **Problem**, We discuss the differences between temporal graph clustering and existing works on an intuitive level. For **Algorithm**, we design a general framework TGC, and analysis the computational complexity of temporal methods and static methods. For **Dataset**, we collate several suitable datasets and also develop two new datasets. For **Evaluation**, we conduct multiple experiments to elucidate the characteristics of temporal graph clustering.\n\n+ (2) Then we would like to emphasize the point that model design is far from being the whole story of this article, and in terms of contributions it is only a quarter of the story. Moreover, even if we simply improve and apply these classical techniques, it is already the first time that they have been considered in temporal graph learning.\n\n+ (3) This comes down to the reality that deep temporal graph clustering is a field that gets very little attention. In this case, much of the work we do is exploring uncharted territory. Within the paper, we expound upon deep temporal graph clustering, encompassing aspects such as intuition, modeling, complexity, datasets, and experiments. The deliberate selection of a simple model was intended to prevent an excessive focus on the model itself, allowing readers to grasp the broader concepts.\n\n+ (4) Undoubtedly, we could have introduced various novel technical ideas, such as spiking Neural Network [1], parameter-free learning [2], coupled memory networks [3], open-world scenarios [4], and graph connectivity discussions [5]. These additions would certainly make our model appear to be sufficiently work-intensive and innovative, but we select not to do so, these techniques are beyond the focus of this paper. In the case of a nascent field, the employment of simple and easily comprehensible models is more conducive to its development. Subsequent researchers will naturally refine and enhance their models.\n\n+ (5) For a paper about exploring a new field, too much technical detail can cloud the readers' judgment and attract too much attention, thus ignoring many details that we would like to discuss in other chapters. In our view, these details pertaining to the concept of temporal graph clustering hold greater significance than the model complex design. In other words, we constructed the model with the primary purpose of conducting experiments that further elucidate the characteristics of temporal graph clustering.\n\nBuilding upon this foundation, we have devised improvements to two classical techniques to render them adaptable to temporal graph data. Furthermore, we hope that the reviewers comprehend that, when exploring a new field, the majority of the workload lies not in the design of the model, but rather in problem definition, dataset selection, and experimental presentation.\n\n> [1] Li, Jintang, et al. Scaling Up Dynamic Graph Representation Learning via Spiking Neural Networks. AAAI 2023.\n\n> [2] Liu, Jiahao, et al. Parameter-free Dynamic Graph Embedding for Link Prediction. NeurIPS 2022.\n\n> [3] Zhang, Zhen, et al. Learning Temporal Interaction Graph Embedding via Coupled Memory Networks. WWW 2020.\n\n> [4] Feng, Kaituo, et al. Towards Open Temporal Graph Neural Networks. ICLR 2023.\n\n> [5] Zhang, Bohang, et al. Rethinking the Expressive Power of GNNs via Graph Biconnectivity. ICLR 2023 Outstanding Paper."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6696/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700116536861,
                "cdate": 1700116536861,
                "tmdate": 1700186373100,
                "mdate": 1700186373100,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Pn07GF0H4j",
                "forum": "ViNe1fjGME",
                "replyto": "J81DytcBEk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6696/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6696/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Euq6 [2/3]"
                    },
                    "comment": {
                        "value": "## **Timestamps in Datasets**\n\nWe should recognize that these datasets have fewer timestamps. But they are already relatively suitable for temporal graph clustering in many public datasets. As shown in Table 4, we summarize some common public datasets, and we can see that these datasets can generally be classified into three categories.\n\n+ (1) The first category is datasets without usable labels (e.g., CollegeMsg), and in fact most of the common temporal graph datasets are of this type. The second category is those with untrustworthy labels (e.g., Bitcoin), and we have conducted experiments on datasets in this category, and their experimental results are often lower than 5\\% or even 1\\%, which means that it is difficult to measure the clustering performance with such node labels. The third category, i.e., the datasets we selected, may have some datasets with smaller sizes and some datasets with fewer timestamps, but these are already as suitable as possible for temporal graph clustering.\n\n+ (2) In addition, we would like to point out that many continuous-time dynamic graph (i.e., temporal graph) methods are also experimenting with these datasets with fewer timestamps [1-6], which may be unhelpful, but it does not affect the unfolding of the experiments on these datasets either. Since these methods focus on the mode of processing timestamps, and whatever the number of timestamps is, it does not affect the difference between the modes of processing of the continuous-time dynamic graphs and the discrete-time dynamic graphs.\n\n+ (3) Going back to our dataset, we actually provide optional datasets for different scenarios. In terms of timestamp scale, there's Brain, which has fewer timestamps, Patent, which is medium-sized, and School, which has a lot of timestamps. These datasets can handle different situations, even those datasets with fewer timestamps. As we said, discrete dynamic graph methods usually use static graph clustering, which can cause OOM problems. If we converting discrete graphs to timestamped graphs for clustering, this can provides researchers with more ideas, and Brain can be seen as just such an example.\n\nFinally, in the future, we will aim to explore datasets with more timestamps.\n\n> [1] Feng, Kaituo, et al. Towards Open Temporal Graph Neural Networks. ICLR 2023.\n\n> [2] Xu, Da, et al. Inductive Representation Learning on Temporal Graphs. ICLR 2020.\n\n> [3] Rossi, Emanuele, et al. Temporal graph networks for deep learning on dynamic graphs. ICML Workshop 2020.\n\n> [4] Zhang, Zhen, et al. Learning temporal interaction graph embedding via coupled memory networks. WWW 2020.\n\n> [5] Kumar, Srijan, et al. Predicting dynamic embedding trajectory in temporal interaction networks. KDD 2019.\n\n> [6] Zuo, Yuan, et al. Embedding temporal network via neighborhood formation. KDD 2018."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6696/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700116674545,
                "cdate": 1700116674545,
                "tmdate": 1700185204479,
                "mdate": 1700185204479,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ZMNU00hd6s",
                "forum": "ViNe1fjGME",
                "replyto": "J81DytcBEk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6696/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6696/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Euq6 [3/3]"
                    },
                    "comment": {
                        "value": "## **Comparison with Temporal Baseline**\n\nThanks to your reminder, we have added more comparison methods to both experiments on dataset size and batch size. We have placed the updated experimental plots on the last page of the Appendix (Figures 13 and 14) for your review.\n\n+ (1) Specifically, HTNE has less GPU requirements due to its simplicity and flexibility, which is why we chose HTNE as the baseline model. In addition, JODIE and TREND will have a bit more GPU requirements, but still have a lot of upside compared to static graph clustering methods. Therefore, we believe that the batchwise temporal graph method is more suitable for large-scale temporal graph data. Moreover, as the data size increases, the temporal graph method can avoid the OOM problem by increasing the memory or shrinking the batch.\n\n+ (2) This is exactly what we are going to discuss in the next experiment, i.e., memory and runtime changes due to batch changes. As we can see in Figure 14, the runtime and memory footprint are basically inversely proportional on different timing diagram methods. This can also prove our conclusion that temporal graph clustering is able to find a balance between space requirements and time requirements. The only problem that occurs is the running time of TREND when the batch size is 10000, which increases rather than decreases. This is because the TREND model is designed to search for higher-order neighbors, a process that is done by the CPU. When the batch is larger, the number of nodes that have to wait for the CPU search result is also larger. Therefore, the increase in TREND's runtime on large batches is actually due to the increased computation by the CPU, rather than the GPU problem we usually consider.\n\n+ (3) In conjunction with the above, we should note that traditional graph clustering models tend to suffer from large-scale problems. And our proposed temporal graph clustering can bring new ideas to researchers, i.e., using the flexibility of temporal graphs to solve the scale problem of clustering, which is exactly what we want to emphasize.\n\n## **Ablation Study**\n\nThanks for the correction, here TGC refers to a clustering framework that can be flexibly adapted to other temporal graph methods and does not include HTNE. this is our mistake and we will correct this in the main text.\n\n+ Regarding the ablation experiments of TGC node-level modules and batch-level modules, we provide the relevant experimental results in the Appendix section, as shown in Fig. 11. They are, in order, DBLP, Brain, Patent, School, arXivAI and arXivCS.\n\n+ In addition, parameter sensitivity experiments on different datasets are provided in Fig. 5-Fig. 10. Due to space constraints, we did not put these experiments in the main text, after which we will consider adjusting the layout of the article.\n\n## **Typos**\n\nThank you for the corrections, we will correct these errors and recheck the full article. For example, some changes are given below:\n\n> (1) Change \u201cA sample...\u201d to \u201cA simple...\u201d.\n\n> (2) Change \u201cwhich we do not...\u201d to \u201cthat we do not...\u201d.\n\n> (3) Change \u201cThen We conduct\u201d to \u201cThen, we conduct\u201d.\n\n> (4) Change \u201cnode embeding\u201d to \u201cnode embeddings\u201d.\n\n> (5) Corrected the mistake with the top quote.\n\nThank you again for your professional comments and insights, which have helped us to improve the quality of our article."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6696/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700116778895,
                "cdate": 1700116778895,
                "tmdate": 1700185750278,
                "mdate": 1700185750278,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VDPxAwWhZy",
                "forum": "ViNe1fjGME",
                "replyto": "ZMNU00hd6s",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6696/Reviewer_Euq6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6696/Reviewer_Euq6"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your rebuttal!"
                    },
                    "comment": {
                        "value": "I have read the authors' rebuttal. It almost addresses my concerns, thus I increase the score."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6696/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700629837935,
                "cdate": 1700629837935,
                "tmdate": 1700629837935,
                "mdate": 1700629837935,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "mVlxXSiZoK",
            "forum": "ViNe1fjGME",
            "replyto": "ViNe1fjGME",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6696/Reviewer_8jHD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6696/Reviewer_8jHD"
            ],
            "content": {
                "summary": {
                    "value": "This work focuses on deep temporal graph clustering and proposes a general framework for deep Temporal Graph Clustering called TGC, which introduces deep clustering techniques to suit the interaction sequence-based batch-processing pattern of temporal graphs. The experimental results are impressive and demonstrate the effectiveness of the proposed framework."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1 The paper is well-written, structured and easy to follow. The authors provide sufficient implementation and experimental details in the Appendix.\u00a0\n2 The authors' focus and exploration of temporal graph clustering may shed new light on the graph learning community.\n3 The experiments are extensive and the results are presented in a clear and concise manner."
                },
                "weaknesses": {
                    "value": "1 The authors mention that datasets are processed by batches, so for each batch does that mean it is a subgraph structure obtained by sampling? Or what is the difference between this way of processing the data in batches, compared to the way of training according to subgraphs?\n\n2 I would like the authors to further discuss the practical application of temporal graph clustering in real-world scenarios to demonstrate the significance of this \u2018new\u2019 task.\n\n3 The authors need to check the paper for grammatical and spelling errors, such as the wrong quotation marks above the Eq (7)."
                },
                "questions": {
                    "value": "Why isn't there more discussion about the two new datasets that you developed yourself in the paper? It doesn't seem to be presented very well in the appendix section either."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6696/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698651697637,
            "cdate": 1698651697637,
            "tmdate": 1699636768355,
            "mdate": 1699636768355,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pwLZgGANNt",
                "forum": "ViNe1fjGME",
                "replyto": "mVlxXSiZoK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6696/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6696/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 8jHD [1/2]"
                    },
                    "comment": {
                        "value": "We thank the Reviewer 8jHD for the detailed and constructive review. We greatly appreciate the valuable insights and extensive expertise reflected in your comments. Irrespective of the final acceptance of the article, we extend our sincerest gratitude for your suggestions, which have significantly enhanced the overall quality of our work. We respond to the comments one by one.\n\n> Due to space constraints, we have added the needed figures and tables to the last subsection (Page 21) of the appendix for your review. The rest of the text will be added after a subsequent reorganization of the article layout.\n\n\n## **Batch Data**\nThanks for the reviewer's comment, it was a good one and very insightful. It helped us reorganize our thinking and we take the opportunity to discuss it further here. \n\n\n+ The temporal graph data is read in batches, and each batch holds the node interactions, i.e., each row considers only two nodes interacting at some moment. This means that different rows (i.e., different interactions) within the same batch may be completely unconnected to each other. Therefore, from this perspective, the interaction data of a single batch does not necessarily constitute a subgraph.\n\n+ Further, it is precisely because a single batch cannot constitute a subgraph that the focus is on a single interaction and an attempt is made to obtain information about its neighbors for the nodes in the interaction, i.e., to construct a limited subgraph for a single node. This point is the biggest difference from those schemes based on batch subgraphs. This in turn leads to the fact that the temporal graph learning is not affected by the batch size in training, because even if there is only one interaction, the sequence of neighbors of a node is still constructed normally, and the batch size only affects the computational efficiency. \n+ Subgraph-based methods, on the other hand, will have requirements on the batch size; when the batch is small, the subgraph structure that can be accessed lacks important information, and when the batch is too large, it will bring computational problems.\n\nBased on the above, we would like to reiterate once again that the batch processing mode based on interaction sequences for temporal graphs is not a replacement for any other algorithms (e.g., adjacency matrices, subgraphs, etc.), but rather it provides a new way of thinking outside of these algorithms, allowing for one more possibility of problem solving solutions.\n\n\n## **Practical Application**\nTemporal graph clustering has a wide range of application scenarios. As the extension of graph clustering, theoretically all the real-life scenarios to which graph clustering applies, temporal graph clustering is applicable. Specifically, it can be divided into two categories, one is the application scenarios directly oriented to graph clustering, and the other is the application scenarios enhanced by graph clustering.\n\n+ The first class of scenarios refers to the scenarios to which graph clustering tasks are naturally adapted, such as community discovery, anomaly detection, etc. The purpose of such scenarios is to mine latent relationships within the same cluster (community discovery) or anomalies that stray from the majority of clusters (anomaly detection) by categorizing the samples into different clusters, so the essence of these scenarios is precisely graph clustering.\n\n+ In the second class of scenarios, the results of graph clustering cannot be directly applied to the target needs, but can be assisted to enhance their effects, e.g., interest recommendation, drug discovery, knowledge graph reasoning, etc. There has been quite a bit of work on enhancing the model's ability to learn the main task by introducing additional clustering tasks, which can bring additional valid information to the main task.\n\nIn summary, temporal graph clustering has rich application scenarios and can realize the effect of data enhancement and mining with richer temporal information on the basis of the original graph clustering.\n\n\n## **Typos**\n\n+ Thank you for the corrections, we will correct these errors and recheck the full article. For example, some changes are given below:\n\n> (1) Change \u201cA sample...\u201d to \u201cA simple...\u201d.\n\n> (2) Change \u201cwhich we do not...\u201d to \u201cthat we do not...\u201d.\n\n> (3) Change \u201cThen We conduct\u201d to \u201cThen, we conduct\u201d.\n\n> (4) Change \u201cnode embeding\u201d to \u201cnode embeddings\u201d.\n\n> (5) Corrected the mistake with the top quote."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6696/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700115653755,
                "cdate": 1700115653755,
                "tmdate": 1700187122426,
                "mdate": 1700187122426,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "l9rphFaH4U",
                "forum": "ViNe1fjGME",
                "replyto": "mVlxXSiZoK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6696/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6696/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 8jHD [2/2]"
                    },
                    "comment": {
                        "value": "## **Discussion on New Datasets**\n\nThanks to your reminder, we discuss and analyze both datasets further here. As shown in Table 4, we summarize some common public datasets, and we can see that these datasets can generally be classified into three categories.\n\n+ The first category is datasets without usable labels (e.g., CollegeMsg), and in fact most of the common temporal graph datasets are of this type. \n\n+ The second category is those with untrustworthy labels (e.g., Bitcoin), and we have conducted experiments on datasets in this category, and their experimental results are often lower than 5\\% or even 1\\%, which means that it is difficult to measure the clustering performance with such node labels. \n\n+ The third category, i.e., the datasets we selected, may have some datasets with smaller sizes and some datasets with fewer timestamps, but these are already as suitable as possible for temporal graph clustering.\n\n\nHowever, except for our two newly developed datasets, the remaining four datasets are very limited in size, and thus the superiority of temporal graph clustering on large-scale datasets could not be verified. To address this issue, we extracted two datasets belonging to the AI domain and the CS domain from the existing OGB dataset and re-labeled these data. Combined with the experimental results on large-scale datasets in the paper, it can be found that the inclusion of these two large-scale datasets points out the limitation of depth graph clustering, i.e., the difficulty of applying the clustering method based on adjacency matrices to large-scale datasets, whereas the temporal graph method, regardless of whether it works well or poorly, can be successfully executed on these datasets.\n\nThank you again for your professional comments and insights, which have helped us to improve the quality of our article."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6696/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700115788566,
                "cdate": 1700115788566,
                "tmdate": 1700148823627,
                "mdate": 1700148823627,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "p76aV0KWj2",
                "forum": "ViNe1fjGME",
                "replyto": "l9rphFaH4U",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6696/Reviewer_8jHD"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6696/Reviewer_8jHD"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the responses!"
                    },
                    "comment": {
                        "value": "Thanks for the responses. My concerns have been addressed."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6696/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700580276215,
                "cdate": 1700580276215,
                "tmdate": 1700580276215,
                "mdate": 1700580276215,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]