[
    {
        "title": "Are We in (A)Sync?: Guidance for Efficient Federated Learning"
    },
    {
        "review": {
            "id": "kvsJXZXjq7",
            "forum": "wilJbPvRYv",
            "replyto": "wilJbPvRYv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3178/Reviewer_eseE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3178/Reviewer_eseE"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a model to formulate the time consumption and resource usage in asynchronous FL methods and tries to use this model to understand the advantage of the asynchronous FL method compared to the synchronous FL method. The idea is interesting and promising, and the topic is meaningful."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The idea is interesting and promising, and the topic is meaningful. The experiment results show that the proposed formulation well approximates the actual time consumption and resource allocation. Overall, I like the idea of this paper, but wish the authors could clarify my concerns regarding the technical results. I'm willing to improve my score if the authors can address some of my concerns."
                },
                "weaknesses": {
                    "value": "The technical part of this paper is not well-written and difficult to understand to the reviewer.\n\n1. It's difficult for me to understand the real meaning of $f(T, c, i)$. The authors claimed that $f(T, c, i)$ is the portion of time client $i$ participated in AsyncFL. If the training process takes time $A$ and during the $A$ time interval, client $i$ participated in the training process for $B_i$ time units, then I would think that $f(T,c, i)=B_i/A$. However, with this definition, I cannot understand why in Appendix A, $f(T,2,1)=f(T,2,2)=1$ when $T=$\\{$ t_1,t_2$ \\}. Moreover, I also don't understand why $f(T,c, i)$ is irrelevant with $k$.\n\n2. The expression of some terminologies is not accurate. For example, the number of updates given by other clients during the training and communication of node $i$ is not precisely the quantity in Eq (4), and the quantity in Eq (4) only tells the of updates given by other clients during the $0$th update and the $1$th update of node $i$.\n\n3. I understand that for simplicity, the authors treat delays or the number of updates as continuous variables, rather than discrete variables. However, since these quantities themselves are discrete, the authors should at least mention this in the paper."
                },
                "questions": {
                    "value": "The authors also provide a formula for delay prediction (above Eq (5)), which is of interest to many researchers. Therefore, can the authors compare the actual delay distribution with the predicted one by experiments? It would be great if you could provide such a comparison even after the rebuttal and in the final version."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3178/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3178/Reviewer_eseE",
                        "ICLR.cc/2024/Conference/Submission3178/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3178/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698504433317,
            "cdate": 1698504433317,
            "tmdate": 1700495005219,
            "mdate": 1700495005219,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "R4GQrcXydI",
                "forum": "wilJbPvRYv",
                "replyto": "kvsJXZXjq7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3178/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3178/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer eseE"
                    },
                    "comment": {
                        "value": "We truly appreciate your thoughtful comments and valuable suggestions. Our responses are as follows:\n\n---\n\n**Comment 1: Meaning of $f(T,c,i)$ and its relevance with respect to $k$**\n\nThank you very much for your detailed question on our formulation. Your understanding is correct: if the client $i$ participated in asyncFL for $B_i$ time while the whole training process takes time $A$, then $f(T,c,i) = \\frac{B_i}{A}$.\n\nWe would like to confirm that when $T = \\{t_1, t_2\\}$, $f(T,2,1) = f(T,2,2) = 1$ is correct, $f(T,2,1)$ and $f(T,2,2)$ indicates the portion of time which client 1 and client 2 each participated in asyncFL when concurrency value $c = 2$. As concurrency $= 2$ when the total number of clients $= 2$, client 1 and client 2 should continuously participate in asyncFL during the whole process to satisfy the concurrency parameter, which makes $f(T,2,1) = f(T,2,2) = 1$. We assume the time required for the server to aggregate updates and to sample new clients are zero for simplicity.\n\nMoreover, $f(T,c,i)$ might depend on $k$ if a client is restricted to contributing more than once to the global model updates, a situation that occurs when $k$ client updates are buffered. However, our formulation is constructed without such restriction, making $k$ irrelevant to $f(T,c,i)$.\n\nWe will ensure to present the above in our revised manuscript, providing more details on the assumptions we made and clarifying the explanation of our formulation.\n\n---\n\n**Comment 2: Inaccurate expression of terminologies**\n\nThank you for pointing out this oversight. You are correct in noting that Eq. (4) does not precisely calculate the expected number of updates by other clients while client i is training and communicating. However, it offers a close approximation, as evidenced by our formulation based on Eq. (4), which closely predicts the actual time and resource usage observed in FL experiments. This is further supported by our delay prediction results directly derived from Eq. (4), as mentioned below in comment 4. We recognize the need to clarify this in our manuscript and either plan to revise Eq. (4) or explicitly state its approximate nature in the updated version.\n\n---\n\n**Comment 3: Treating discrete variables as continuous variables**\n\nThank you for bringing this to our attention. The number of updates and the delays (staleness) we mentioned in Section 3 are all expected values. We will ensure to update our inaccurate notations regarding the continuous or discrete nature of variables in our updated manuscript.\n\n---\n\n**Comment 4 (Question): Comparison on formulated delay prediction and actual value**\n\nThank you for your suggestion. We conducted a delay prediction based on the equation above Eq. (5), by comparing it with the actual delay values from the experiment on the FEMNIST dataset as follows:\n\n| concurrencies       | 10    | 25    | 50    | 100    | 200    | 500    | 1000    |\n|---------------------|-------|-------|-------|--------|--------|--------|---------|\n| FEMNIST-Formulation | 0.901 | 2.406 | 4.929 | 10.022 | 20.402 | 53.115 | 113.129 |\n| FEMNIST-Experiment  | 0.900 | 2.399 | 4.896 | 9.885  | 19.845 | 49.546 | 98.503  |\n\nThe results indicate that our formulation aligns closely with the actual delay values observed in the FL experiment. However, we observed an increasing discrepancy at higher concurrency levels, likely stemming from the errors in Eq. (4) addressed in comment 2. We expect such an error to decrease as we suggest an accurate formulation for Eq. (4). In our revised manuscript, we plan to include results on delay prediction across all datasets used in our study."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3178/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700360260720,
                "cdate": 1700360260720,
                "tmdate": 1700360260720,
                "mdate": 1700360260720,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vHoH7eaQQD",
                "forum": "wilJbPvRYv",
                "replyto": "R4GQrcXydI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3178/Reviewer_eseE"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3178/Reviewer_eseE"
                ],
                "content": {
                    "title": {
                        "value": "I agree to raise my score because the authors addressed some of my issues."
                    },
                    "comment": {
                        "value": "I agree to raise my score because the authors addressed some of my issues. Specifically, they demonstrate that the delay formula (4) they derived is relatively tight."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3178/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700494972318,
                "cdate": 1700494972318,
                "tmdate": 1700494972318,
                "mdate": 1700494972318,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qyWwD9fxUi",
            "forum": "wilJbPvRYv",
            "replyto": "wilJbPvRYv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3178/Reviewer_F9nE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3178/Reviewer_F9nE"
            ],
            "content": {
                "summary": {
                    "value": "AsyncFL allows the server to exchange models with available clients continuously, enhancing the resource utilization. Given the training and communication speed of participating clients, this paper presents a formulation of time and resource usage on syncFL and asyncFL. The proposed formulation weights asyncFL against its inefficiencies stemming from stale model updates, enabling more accurate comparison to syncFL. This paper reveals that no single approach always works better than the other regarding time and resource usage."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The finding that \"neither syncFL nor asyncFL universally outperforms the other in terms of time and resource usage\" is interesting.\n2. The studied problem is timely and may have practical influences."
                },
                "weaknesses": {
                    "value": "1. Lemma 1, Corollary 1, 2 and Proposition 1 consider the participating time and resource usage. However, they do not consider the model training, loss functions, data heterogeneity, etc. Thus, it is hard to say the proposition can be utilized into FL.\n2. Non-IID data distribution widely exists in FL. However, experiments only consider IID data distribution.\n3. The presentation of experiment results is not clear. What does the proposed formulation mean when compared with other FL algorithms?"
                },
                "questions": {
                    "value": "See weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3178/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698599089666,
            "cdate": 1698599089666,
            "tmdate": 1699636265328,
            "mdate": 1699636265328,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YX1WnUgT5E",
                "forum": "wilJbPvRYv",
                "replyto": "qyWwD9fxUi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3178/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3178/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer F9nE"
                    },
                    "comment": {
                        "value": "We greatly appreciate your thoughtful comments and feedback. Our replies are as follows:\n\n---\n\n**Comment 1: Formulation not considering training, loss functions, or data heterogeneity**\n\nThank you for highlighting an important aspect to consider regarding our formulation. Incorporating model convergence, training specific, and data characteristics would yield more theoretically precise results. However, we instead approached formulating with an assumption that syncFL and asyncFL achieve the target accuracy after p global model updates. Our empirical results in Section 6 demonstrate that this simplified formulation also effectively predicts the actual values observed in FL runs across five datasets spanning vision and NLP domains that involve up to 21,876 clients. We plan to improve our theoretical formulation based on the elements you mentioned as a future work. \n\n---\n\n**Comment 2: Experiments considering IID data distribution only**\n\nThank you for emphasizing the importance of non-IID data distribution in federated learning. In our experiments, while we allocated IID data to clients within the CIFAR-10 dataset, the other four datasets (FEMNIST, CelebA, Shakespeare, Sent140) employed were distinctly non-IID. We utilized these four datasets in their original form, as provided by the LEAF federated learning framework [1], where they inherently exhibit non-IID characteristics with heterogeneous data quantity and class distributions.\n\nIn our revised manuscript, we will include details on non-IID characteristics of experimented datasets.\n\n---\n\n**Comment 3: Meaning of proposed formulation compared to other algorithms**\n\nWe interpreted your comment (item 3 under weaknesses) as about the experimental results shown in Figures 3c and 3d and have responded accordingly below. If your comment was about a different aspect, please inform us.\n\nWe built our formulation on the prevalent syncFL and asyncFL algorithms (FedAvg and FedBuff). In experiments on Figures 3c and 3d, we aimed to assess whether our formulation provides insight into the time and resource usage when other widely used FL optimization algorithms are applied, such as FedProx, FedYogi, and FedAdagrad. Our results indicate that employing our formulation with these algorithms may increase the prediction error. Still, the general trend in time and resource usage over different concurrency parameters remains consistent between the formulation and other FL algorithms.\n\nWe empirically showed our formulation\u2019s applicability in predicting time and resource usage trends over different concurrency parameters. This could potentially assist FL practitioners in choosing the most suitable approach (asyncFL / syncFL) or parameter for different FL algorithms.\n\n---\n\n[1] Caldas, Sebastian, et al. \"Leaf: A benchmark for federated settings.\" arXiv preprint arXiv:1812.01097 (2018)."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3178/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700359944005,
                "cdate": 1700359944005,
                "tmdate": 1700359944005,
                "mdate": 1700359944005,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zAdKi0BhuE",
                "forum": "wilJbPvRYv",
                "replyto": "qyWwD9fxUi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3178/Reviewer_F9nE"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3178/Reviewer_F9nE"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your respones"
                    },
                    "comment": {
                        "value": "Thanks for your respones, I decide to keep my scores based on following comments:\n1. The analysis considering training, loss functions, or data heterogeneity is important.\n2. I checked the revision, the details of the dataset partition are not provided."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3178/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700450434285,
                "cdate": 1700450434285,
                "tmdate": 1700450434285,
                "mdate": 1700450434285,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gcfGvVI2tD",
                "forum": "wilJbPvRYv",
                "replyto": "qyWwD9fxUi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3178/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3178/Authors"
                ],
                "content": {
                    "title": {
                        "value": "To reviewer F9nE"
                    },
                    "comment": {
                        "value": "Thank you very much again for your valuable feedback.\n\nWe fully acknowledge the importance of considering training, loss functions, and data heterogeneity in our research. While we regret not including these in the current discussion due to time constraints, we would like to stress that our simplified formulation accurately predicts the actual values observed in FL executions.\n\nIn the paper, we added an explanation that four out of five used datasets were non-IID as originally provided by LEAF. We opted not to include extensive details of the dataset in our paper, as the datasets we used are well-established in the field and the details are covered in prior literature."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3178/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700650214282,
                "cdate": 1700650214282,
                "tmdate": 1700650280322,
                "mdate": 1700650280322,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "SyDZalTcDb",
            "forum": "wilJbPvRYv",
            "replyto": "wilJbPvRYv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3178/Reviewer_pJDG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3178/Reviewer_pJDG"
            ],
            "content": {
                "summary": {
                    "value": "This paper aims to show that neither synchronous (syncFL) nor asynchronous (asyncFL) Federated Learning (FL) approaches can be deemed to be definitively superior over the other in regards to reducing time and resource consumption, thus invalidating the previous findings which showed one's superiority over the other."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "++ The paper makes a novel observation: the current works that compare syncFL and asyncFL concerning their time and resource consumption contradict each other\u2013\u2013some works claim that asyncFL is better than syncFL, and others claim the opposite. The authors settle this argument by making a novel statement that there is no definitive winner among the two. \n\n++ The authors have thoroughly examined the related works, and identified flaws and contradictions among those works.\n\n++ It introduces novel formulations to determine the time and resource usage till the target accuracy is achieved. The formulation accounts for stale model updates in asyncFL which allows it to outperform baseline models."
                },
                "weaknesses": {
                    "value": "-- Lack of comparison with state-of-the-art approaches for time & resource measurement and estimation. The paper only compares with the Updates-N baseline methods. \n\n-- The abstraction of resource usage in FL is over-simplified since real-world FL systems rely on multiple types of resources with heterogeneous characteristics. \n\n-- The authors' formulations for time and resource consumption make strong assumptions.  The formulations for time and resource consumption assume that the syncFL and asyncFL reach the target accuracy after p rounds. How do we determine the number (p) of updates until target accuracy is achieved? In addition, the authors' formulation assumes that the time (T = {t_1,t_2,...,t_n}) required by the clients to download, train and upload the model weights are constant across training rounds. The assumption of T being constant across rounds may not reflect reality because a client model can be faster in certain rounds and slower in others. \n\n-- In section 4, the authors conclude that, based on their formulations, neither syncFL nor asyncFL can be deemed to be definitively superior to the other. The authors have used their formulation to demonstrate that neither syncFL nor asyncFL can be deemed to be definitively superior to the other. They should verify this using actual time and resource usage values."
                },
                "questions": {
                    "value": "1. In section 5, under \"Reflecting the Impact of Bias\", the authors claim that $10*CV(U)+1$ at $p$ yields an accurate prediction. The authors should justify this in the paper.\n\n2. How do the experiments support the authors' argument\u2013\u2013\u2013neither syncFL nor asyncFL can be deemed to be definitively superior to the other? The authors have shown that their approach of determining resource and time utilization for asyncFL closely approximates the actual values, however since this does not establish a connection with previous works that have opposing views, it does not invalidate the previous authors' works which determines that either asyncFL is better than syncFL, or vice versa. Figures 3c and 3d do not justify that the authors' formulations are also accurate when predicting time and resource usage for other aggregation schemes. Those figures do not compare the formulations' predictions of time and resource usage to real ones, instead, they simply show the predictions when using the authors' formulations.\n\nWriting Issues:\n\n* Figure 1 has missing legends, making it incomprehensible to the readers. The figure is critical to the paper as it intends to show that neither syncFL nor asyncFL approaches can be deemed to be definitively superior to the other in regards to reducing time and resource consumption. The authors mention that Figure 1 is a comparison of asyncFL and syncFL in terms of their resource and time utilization, however, it appears that the figure is incomplete and does not compare the two approaches.\n\n* What is D-bar in section 5, under \"Contribution Scaling on a Client Dataset\"?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3178/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3178/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3178/Reviewer_pJDG"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3178/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698935461567,
            "cdate": 1698935461567,
            "tmdate": 1699636265246,
            "mdate": 1699636265246,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "noLxemdTSM",
                "forum": "wilJbPvRYv",
                "replyto": "SyDZalTcDb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3178/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3178/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer pJDG (Part 1)"
                    },
                    "comment": {
                        "value": "We are deeply grateful for your thoughtful comments and feedback. In our revised manuscript, we intend to address these points as follows:\n\n---\n\n**Comment 1: Lack of comparison with state-of-the-art approaches**\n\nWe appreciate your question regarding the comparison with state-of-the-art approaches. To our knowledge, no existing literature proposes to predict the relative time or resource usage between syncFL and asyncFL. Thus, we could only compare with a basic baseline, \u201cUpdates-$N$,\u201d which predicts after observing the metrics for $N$ rounds. In our revised manuscript, we plan to introduce an additional baseline that predicts based on the observed metrics from initial FL runs reaching a low target accuracy (e.g., 10%). Please note that these baseline methods require sample FL runs for each configuration to make predictions, whereas our formulation uniquely predicts the metrics without requiring any FL runs.\n\n---\n\n**Comment 2: Resource usage in FL is over-simplified**\n\nThank you for questioning our abstraction of resource usage as the cumulative time for on-device training and model weight communication. We acknowledge the variety of resources in real-world FL systems and the value of examining each type separately. Although capable of presenting our resource usage formulation for each type, we opted for a time-based abstraction to simplify our prediction experiments on actual values. The time units metric is proportional to various resource types such as energy consumption [1]. It allows us to avoid fine-grained measurements (e.g., power measurements), which are challenging to accurately simulate at scale. Our choice of a time-based abstraction is based on Abdelmoniem et al. [2], who explored the resource efficiency of federated learning systems.\n\nWe will ensure to explain our choice of resource usage abstraction in our revised manuscript.\n\n---\n\n**Comment 3: Assumption in time and resource usage formulations**\n\nWe acknowledge that our formulation was built on an assumption that syncFL and asyncFL achieve the target accuracy after p global model updates. However, we would like to note that in actual FL runs, the number of required global model updates observed in both approaches is similar while having different time and resource usage, as shown below:\n\n| Datasets | SyncFL | AsyncFL c:10 | AsyncFL c:25 | AsyncFL c:50 | AsyncFL c:100 |\n|----------|--------|--------------|--------------|--------------|---------------|\n| FEMNIST  | 131    | 115          | 116          | 124          | 164           |\n| Celeba   | 518    | 649          | 574          | 569          | 567           |\n\nThe numbers of asyncFL global model updates in the table are adjusted with the staleness penalty as proposed in Section 3. We observed that the required global model updates for asyncFL are generally comparable to those needed for syncFL. This suggests that our formulation could be leveraged to predict time and resource usage of actual FL runs, as we evidenced in our experiments in Section 6. \n\nAddressing your question on client times varying over time, we conducted an additional experiment to compare the prediction errors in scenarios where client times are either changing or remaining constant. To simulate dynamically changing client times, we employed a methodology from a previous study [3] that simulated client training and communication times based on real-world user traces from 136,000 smartphones. In this method, each client is assigned a mean and standard deviation for its time, with the client's time being sampled from a normal distribution each time it is selected. For experiments where client times are constant, the mean value was always used. Our experiments on the FEMNIST dataset, using the same hyperparameters as in Section 6, generated the following results:\n\n| Methods              | Time RMSE  | Resource usage RMSE |\n|----------------------|------------|---------------------|\n| Static client times  | 0.07+-0.01 | 0.50+-0.09          |\n| Dynamic client times | 0.06+-0.01 | 0.50+-0.17          |\n\nThese results show that the prediction accuracy is remarkably similar in both scenarios. We surmise that the minimal difference arises as the variations in client times in the dynamic case tend to average out over numerous global model updates in FL. This finding implies that our formulation would be effective in real-world conditions. We intend to incorporate these findings on dynamic client times in our revised manuscript, extending the experiment across all datasets used in our study.\n\n---\n\n[1] Li, Li, et al. \"SmartPC: Hierarchical pace control in real-time federated learning system.\" IEEE Real-Time Systems Symposium, 2019.\n\n[2] Abdelmoniem, Ahmed M., et al. \"REFL: Resource-Efficient Federated Learning.\" The Eighteenth European Conference on Computer Systems, 2023.\n\n[3] Yang, Chengxu, et al. \"Characterizing impacts of heterogeneity in federated learning upon large-scale smartphone data.\" The Web Conference, 2021."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3178/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700359530768,
                "cdate": 1700359530768,
                "tmdate": 1700359530768,
                "mdate": 1700359530768,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]