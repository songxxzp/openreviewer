[
    {
        "title": "Understanding deep neural networks through the lens of their non-linearity"
    },
    {
        "review": {
            "id": "dyrQc6uf3P",
            "forum": "NFaFvyKKbX",
            "replyto": "NFaFvyKKbX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission134/Reviewer_Hcf9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission134/Reviewer_Hcf9"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new metric to measure the non-linearity of activation functions in deep neural networks. Extensive comparative studies have been done for the analysis of different network architectures. The proposed metric is also somehow relevant to the performance of a DNN."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ The topic of analyzing the non-linearity of DNNs is interesting.\n+ It seems novel (to me, not an expert) to leverage OT to measure the extent of non-linearity."
                },
                "weaknesses": {
                    "value": "- Def 3.1 only focuses on pointwise non-linear activation functions to measure non-linearity. However, many functions other than the ACT family also introduces non-linearity to the DNN, such as max pooling. How to measure the non-linearity of these functions?\n- Def 3.1 considers each activation function independently. How about combining two or more activation functions? Intuitively, by stacking the non-linearities, the overall non-linearity will grow exponentially.\n- How to interpret Figure 1? It seems that the non-linearity of sigmoid and gelu are better than relu. Then why does relu become the most widely used activation function?\n- About the result in Figure 9. How to interpret the negative correlation between the maximum affinity score and accuracy. It seems contradict with the NAS models results in Figure 20.\n- Could the proposed metric bring any new insights (or serve as a regularization term) to help us build better DNNs or design better activation functions?"
                },
                "questions": {
                    "value": "see above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission134/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698675223711,
            "cdate": 1698675223711,
            "tmdate": 1699635938873,
            "mdate": 1699635938873,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vayhxlR571",
                "forum": "NFaFvyKKbX",
                "replyto": "dyrQc6uf3P",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission134/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission134/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Clearing out misunderstandings"
                    },
                    "comment": {
                        "value": "> 1. Def 3.1 only focuses on pointwise non-linear activation functions to measure non-linearity. However, many functions other than the ACT family also introduces non-linearity to the DNN, such as max pooling. How to measure the non-linearity of these functions?\n\nWe can measure the non-linearity of any function, point-wise or not, activation or pooling. However, we have chosen the activation functions as they are present in all studied models, often repeatedly. We can include pooling layers as well if we were to extend this work. However, we believe that activation functions, often appearing after conv and pool layers are more interesting in this regard as they effectively capture the non-linearity of what precedes them. \n\n> 2. Def 3.1 considers each activation function independently. How about combining two or more activation functions? Intuitively, by stacking the non-linearities, the overall non-linearity will grow exponentially.\n\nThis intuition is actually incorrect as stacking the non-linearity makes them more linear. To see this, we remember that ReLU zeros out all negative elements so that another ReLU on top of its output will become perfectly linear. Nevertheless, we could easily compute affinity scores for combinations of activation functions by considering the combination of functions as a single activation function, but it never happens in practice since there are always other operations between activation functions in neural networks.  \n\n> 3. How to interpret Figure 1? It seems that the non-linearity of sigmoid and gelu are better than relu. Then why does relu become the most widely used activation function?\n\nWe believe that there is no such a notion as better non-linearity. What it shows is that sigmoid is more linear, and ReLU is highly non-linear only in a very restricted subdomain (interval of the input values). GELU is as non-linear as ReLU but in a larger subdomain making it more stable optimization-wise. We believe that it explains why it is largely used now.\n\n> 4. About the result in Figure 9. How to interpret the negative correlation between the maximum affinity score and accuracy. It seems contradict with the NAS models results in Figure 20.\n\nA negative correlation with the maximum affinity score (maximum over layers) means that a lower maximum affinity score in the efficient model translates to a higher Imagenet top@1 accuracy. NAS models are different from efficient models: it seems that NAS privileges more linear models, while manually designed efficient models are penalized for having too linear activations. \n\n> 5. Could the proposed metric bring any new insights (or serve as a regularization term) to help us build better DNNs or design better activation functions?\n\nWe experimenting with this. So far, we managed to successfully generate networks with a predefined non-linearity signature but didn't do any large-scale tests on popular benchmarks."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission134/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700126582648,
                "cdate": 1700126582648,
                "tmdate": 1700126582648,
                "mdate": 1700126582648,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ybmPRy7T1V",
            "forum": "NFaFvyKKbX",
            "replyto": "NFaFvyKKbX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission134/Reviewer_1uvv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission134/Reviewer_1uvv"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a theoretically sound solution to track non-linearity propagation in deep neural networks. Specifically, this method measures the nonlinearity of a given transformation using optimal transport (OT) theory. More critically, the authors investigate the practical utility of the proposed affinity score and apply the proposed affinity score to a wide range of popular DNNs."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This paper develops a new method to track non-linearity propagation in deep neural networks.\n2. This paper proposes the affinity score to evaluate the non-linearity and apply it to diverse architectures."
                },
                "weaknesses": {
                    "value": "1. The authors mention that \"consider transformer architectures with a\nspecific focus on the non-linearity present in their MLP blocks\". How about the non-linear operation inside the attention block, e.g., softmax?\n\n2. In Figure 2, the authors highlight the robustness of the affinity score. Nevertheless, it is still unclear why the robustness of this score is important.\n\n3. It is unclear how accurate the affinity score is to evalute the non-linearity. More details are required towards this.\n\n4. It seems that the non-linearity does not vecessarily correlate with the performance. From this point of view, how do we understand DNNs based on this metric?"
                },
                "questions": {
                    "value": "Please refer to the weakness part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission134/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698765010440,
            "cdate": 1698765010440,
            "tmdate": 1699635938802,
            "mdate": 1699635938802,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "J6ye4U6e0r",
                "forum": "NFaFvyKKbX",
                "replyto": "ybmPRy7T1V",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission134/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission134/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Clearing out misunderstandings"
                    },
                    "comment": {
                        "value": "> 1. The authors mention that they \"consider transformer architectures with a specific focus on the non-linearity present in their MLP blocks\". How about the non-linear operation inside the attention block, e.g., softmax?\n\nAs such, we can consider any transformation and measure its non-linearity. However, we have chosen the activation functions as they are present in all studied models, often repeatedly. We can include pooling layers as well if we were to extend this work. However, we believe that activation functions, often appearing after conv and pool layers are more interesting in this regard as they effectively capture the non-linearity of what precedes them. \n\nFinally, we note that pooling layers cannot be fully linear: it is not clear what an upper bound of the maxpooling operation may look like contrary to activation functions that, in theory, can all attain values between 0 and 1.\n\n> 2. In Figure 2, the authors highlight the robustness of the affinity score. Nevertheless, it is still unclear why the robustness of this score is important.\n\nNeural networks operate on 4th-order tensors. We represent them as 2D matrices and want to know whether such a transformation doesn't lose much information. Figure 2 gives an affirmative answer to this: affinity score is robust to this change of representation.\n\n> 3. It is unclear how accurate the affinity score is to evaluate the non-linearity. More details are required for this.\n\nOur work lays the theoretical foundation in this sense. Note that there are no theoretically sound competitors to our work that can be used as a baseline. Nevertheless, we refer the reviewer to our study of different activation functions (in Figure 1 and more detailed in Appendix B), where we can clearly see that the resulting affinity score is high in regions of the space where the function is linear and low otherwise. \n\n> 4. It seems that the non-linearity does not necessarily correlate with the performance. From this point of view, how do we understand DNNs based on this metric?\n\nThe results provided in Figure 9 and Appendix I tell us that for many models this is the case. Can the reviewer be more specific about what gave them this impression?"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission134/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700126470737,
                "cdate": 1700126470737,
                "tmdate": 1700126470737,
                "mdate": 1700126470737,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "zoM8ToGIfI",
            "forum": "NFaFvyKKbX",
            "replyto": "NFaFvyKKbX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission134/Reviewer_uebp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission134/Reviewer_uebp"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies various different NN architectures through a a unique metric of non-linearity. It shows how different networks throughout history have leveraged non-linearity and how they improved. It also shows some theoretical guarantees."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is quite interesting! I think it goes through various architectures and shows some compelling results."
                },
                "weaknesses": {
                    "value": "The presentation can be greatly improved in my opinion. The figures are not clear, colormaps are missing, many effects in the plots are not thoroughly explained (e.g. the effects in most figures except the ViTs are not very clear). I think this paper has the potential to be much better if the writing were to be improved, along with the presentation, and more thorough explanations."
                },
                "questions": {
                    "value": "Minor comments:\n1. Plots are not clear, they do not have a color bar, and the colors are not clear (e.g. Figure 4, 5, ...)\n\nQuestions:\n1. Have the authors tried to check how the non-linearity metric corresponds with intermediate layer performance (e.g. the linear eval on the layer)? This could be interesting to check to improve the paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission134/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698789160650,
            "cdate": 1698789160650,
            "tmdate": 1699635938731,
            "mdate": 1699635938731,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "eQL59SzQSi",
                "forum": "NFaFvyKKbX",
                "replyto": "zoM8ToGIfI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission134/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission134/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Clearing out misunderstandings"
                    },
                    "comment": {
                        "value": "> The presentation can be greatly improved in my opinion. The figures are not clear, colormaps are missing, and many effects in the plots are not thoroughly explained (e.g. the effects in most figures except the ViTs are not very clear). I think this paper has the potential to be much better if the writing were to be improved, along with the presentation, and more thorough explanations.\n\nWe would be grateful if the reviewer could provide us with anything specific regarding their last remark. We are wondering which effects in the figures the reviewer is referring to since we analyze each set of figures in the associated text. \n\nAlso, please note that this color palette was initially chosen to be friendly for color-blind people. We propose an alternative revised version taking into account your remark. \nWhen the colormaps are removed, it usually is because they are of no importance: as mentioned in the paper, each color simply is associated with each repeated activation function in the network. \n\n> Have the authors tried to check how the non-linearity metric corresponds with intermediate layer performance (e.g. the linear eval on the layer)? This could be interesting to check to improve the paper.\n\nThis is an interesting suggestion, although we do not immediately see what kind of link the reviewer expects to see here. Can they elaborate on their intuition?"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission134/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700126403831,
                "cdate": 1700126403831,
                "tmdate": 1700126403831,
                "mdate": 1700126403831,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rVczy1SxFT",
            "forum": "NFaFvyKKbX",
            "replyto": "NFaFvyKKbX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission134/Reviewer_K2zC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission134/Reviewer_K2zC"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a formulation, named 'affinity score,' to measure the non-linearity of deep neural networks. The authors then use the proposed affinity score to evaluate the non-linearity signatures of popular neural networks and illustrate the affinity scores for every layer within these networks. The authors claim that these non-linearity scores will bring insights into the understanding of neural networks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The topic of understanding non-linearity in DNNs is intriguing, and the author proposes a novel formulation to evaluate it.\n2. The writing style is engaging, and the presentation of the material is well-executed."
                },
                "weaknesses": {
                    "value": "1. In the computation of affinity scores, which are tied to the activations within a neural network, there is an inherent dependence on both the input data and the network's parameters. My understanding is that affinity scores are influenced by the architecture and the parameters (the trained weights) of the network. However, it seems that in the evaluation of their experiments, the authors have placed a predominant focus on the architecture while possibly overlooking the significance of the network parameters. It is important to consider that the parameters, which are shaped by the training process, are crucial for the network's performance and ultimately for the validity of the affinity scores. An in-depth analysis that includes the impact of these parameters could provide a more comprehensive understanding of the network's behavior and the experimental outcomes.\n2. The author claims \"Despite being almost 20 times smaller than VGG16, the accuracy of Googlenet on Imagenet remains comparable, suggesting that increasing and varying the linearity is a way to have high accuracy with a limited computational complexity compared to predecessors.\u201d\nHowever, this assertion seems to overlook the fact that a significant portion of VGG16's parameters are concentrated in the final fully connected layers, which consist of two 4096-dimensional layers. Empirical evidence suggests that reducing the parameter count of these fully connected layers does not drastically diminish performance. Thus, concluding that 'increasing and varying the linearity is a way to have high accuracy with a limited computational complexity' may not be entirely justified."
                },
                "questions": {
                    "value": "Please refer to the weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission134/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission134/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission134/Reviewer_K2zC"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission134/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698995137004,
            "cdate": 1698995137004,
            "tmdate": 1699635938673,
            "mdate": 1699635938673,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Dvrgm7h8ID",
                "forum": "NFaFvyKKbX",
                "replyto": "rVczy1SxFT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission134/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission134/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Clearing out misunderstandings"
                    },
                    "comment": {
                        "value": "> 1. In the computation of affinity scores, which are tied to the activations within a neural network, there is an inherent dependence on both the input data and the network's parameters. My understanding is that affinity scores are influenced by the architecture and the parameters (the trained weights) of the network. However, it seems that in the evaluation of their experiments, the authors have placed a predominant focus on the architecture while possibly overlooking the significance of the network parameters. It is important to consider that the parameters, which are shaped by the training process, are crucial for the network's performance and ultimately for the validity of the affinity scores. An in-depth analysis that includes the impact of these parameters could provide a more comprehensive understanding of the network's behavior and the experimental outcomes.\n\nThank you for pointing this out so that we can clarify this potential misunderstanding. We actually do not put any particular emphasis on the architecture when defining the non-linearity of the neural network vs. the weights (parameters) of the model. To understand this, one needs to remember that the non-linearity of the activation function reflects what happens in the layers that precede it. As such, ReLU, for instance, is parameterless but the layers preceding it make it more or less linear depending on how they transform the input of the ReLU. These transformations are done by the parameters of the preceeding layers and affinit score reflects this. \n\nAlso, please note that the experiments in our paper already cover models trained on several datasets (different sets of parameters, pre-trained or trained from scratch, Appendix F and E) and even different training approaches and learning tasks (see a comparison of self-supervised approaches in Appendix G). We also provide a comparison of models trained with 9 different random seeds (Appendix C). This totals a study over a very large ensemble of possible scenarios. \n\nAll in all, we have carried out a comprehensive set of comparisons; it does not seem straightforward what other in-depth analyses would help more. It would be kind of you to detail more in case you had some specific analyses in mind.\n\n> 2. The author claims \"Despite being almost 20 times smaller than VGG16, the accuracy of Googlenet on Imagenet remains comparable, suggesting that increasing and varying the linearity is a way to have high accuracy with a limited computational complexity compared to predecessors.\u201d However, this assertion seems to overlook the fact that a significant portion of VGG16's parameters are concentrated in the final fully connected layers, which consist of two 4096-dimensional layers. Empirical evidence suggests that reducing the parameter count of these fully connected layers does not drastically diminish performance. Thus, concluding that 'increasing and varying the linearity is a way to have high accuracy with a limited computational complexity' may not be entirely justified.\n\nWe thank the reviewer for pointing this out to us. However, we see a distinct pattern of GoogleNet that we describe as \"increasing and varying the linearity\" that VGG (with or without high-dimensional classification layers) doesn't have. We will remove the claim about the size though as the reviewer suggests."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission134/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700126280197,
                "cdate": 1700126280197,
                "tmdate": 1700126280197,
                "mdate": 1700126280197,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]