[
    {
        "title": "Multi-Objective Multi-Solution Transport"
    },
    {
        "review": {
            "id": "O8muXcgB6I",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8707/Reviewer_AiMo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8707/Reviewer_AiMo"
            ],
            "forum": "uXbqFnQfH4",
            "replyto": "uXbqFnQfH4",
            "content": {
                "summary": {
                    "value": "This paper proposed a new algorithm based on bilevel optimization. The inner level is an weighted MGDA and the upper level is OT make perference more alginable."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The proposed method is validated both on extensive experiments and theory."
                },
                "weaknesses": {
                    "value": "see questions."
                },
                "questions": {
                    "value": "1. Why we do not use a Pareto set learning (PSL) model, which is now a very mature techniques., (see COSMOS[1], Lin[2]) to solve the considered problems. Since PSL is now believed can run very fast and find the whole PS/PF for fairness problems. \n\n2. The considered simplex is m-1 not m. So you should use the notation $\\Delta^{m-1}$/$\\Delta^{n-1}$ in the paper. \n\n3. Why considered OT? Can a simple JS/KL/TV divergence also work?\n\n4. You claim EPO can not deal non-smooth and dis-continuous problem. But I think the proposed method also have such issues. When the solution is not smooth. It is actually impossible to apply any gradient-based method (to the best of my knowledge).\n\n5. As far as I have implemented, EPO works perfectly on ZDT1. The main problem EPO is it is slow. However, the EPO you have implemented only find a single solution. I suggest the author to re-implement EPO. \n\n6. According to my understanding, LS can work perfectly on MNIST/FMNIST problem since their PFs are almost convex. So I am skeptical to the results in Table 2. \n\n7. The Eq.4, using a weighted version of MGDA, do not have a direct meaning. It is hard to understand its result of Eq4 since the result of MGDA is unpredictable. So a weighted version of MGDA will not lead to very meaningful solutions (according to my try several month ago).  \n\n8. I am a curious about the distribution of final solutions (similar to 7).\n\n9. I am actually concerned about the design of the algorithm. I have to say, I think the algorithm is over-designed. Since MGDA does not have a guarantee to find a specific solution. I think COSMOS may be a better choice for the design in the inner loop.\n\n10. I have to say, many of the baselines are not what the author claims. Many of the baselines, (including 5 EPO) actually have much better performance than the author claims. \n\n11. For many-objective problems, MGDA is too slow since calculating m gradients seems not a main-stream method. In addition, how is the OT implement. As far as I know, sinkhorn alg for solving the OT is still slow. \n\n\n[1] Pareto Set Learning for Expensive Multi-Objective Optimization.\n\n[2] Scalable pareto front approximation for deep multi-objective learning."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8707/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8707/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8707/Reviewer_AiMo"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8707/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697172670991,
            "cdate": 1697172670991,
            "tmdate": 1700449958943,
            "mdate": 1700449958943,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PEyzI6Mt1f",
                "forum": "uXbqFnQfH4",
                "replyto": "O8muXcgB6I",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8707/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8707/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer AiMo"
                    },
                    "comment": {
                        "value": "Thank you for your review on MosT. We appreciate the opportunity to address your concerns and provide additional insights to enhance the understanding of our work.\n\n---\n\n> Q1. **Why not use a Pareto set learning (PSL) model?**\n   - We acknowledge the existence of techniques like PSL. However, MosT was designed with a focus on handling problems with a large number of objectives (i.e., $n\\ll m$, much more than the number of models), aiming for a comprehensive exploration of the Pareto front. We are open to discussing this further and would appreciate any specific objections or concerns you may have.\n\n> Q2. **Optimal Transport (OT) vs. Divergence Measures:**\n   - The choice of OT over other divergence measures was motivated by its ability to capture structural relationships between objectives, which cannot be provided by divergence measures.\n\n> Q3. **Issues on non-smooth solutions:**\n   - The weights assigned by Optimal Transport (OT) exhibit inherent smoothness properties. The optimization process guided by OT involves finding a transport plan that minimizes the loss while satisfying the marginal constraints. This characteristic ensures that the weights smoothly transition between different solutions, contributing to the overall smoothness of the optimization landscape. As a result, MosT benefits from the inherent smoothness of the OT weights, mitigating non-smooth and discontinuous behavior in the optimization process. This contributes to the algorithm's ability to handle a wide range of objective landscapes, promoting stability and reliability across diverse problem scenarios.\n\n> Q4. **EPO Implementation:**\n- We compare the algorithms using their original implementations and a consistent experimental setup, including the use of reference points and the number of solutions. The performance gap may come from the fact that EPO needs to sample an extensive number of preference vectors (\\~100) and SVGD needs diverse initializations (\\~50). Comparing their numbers with our limited number of solutions (5 for ZDT problems), these two algorithms cannot work as reported. These results show the efficiency of MosT, which does not rely on diverse sampling to achieve well-distributed solutions over the Pareto fronts. \n\n> Q5. **LS should perform well on MNIST/FMNIST because its PF is convex:**\n- Due to data heterogeneity and the large number of clients/objectives, it is unlikely that the Pareto front of FEMNIST (using the convolutional neural network) is convex.\n\n> Q6. **The intuition behind weighted MGDA (Eq.4):**\n   - By the definition of Pareto optimality, the Pareto optimal solutions identified for weighted objectives remain Pareto optimal for the original unweighted problem if all weights are positive. That being said, the weight vector for each model per step guides the MGDA to pursue solutions at a specific region of the Pareto front, similar to a reference/preference vector. Hence, different weight vectors lead to different solutions.\n   - OT-weighted MGDA leads to complementary and balanced solutions, due to the two marginal constraints in OT, which enforce the balance among the $m$ solutions and a fair coverage over all the $n$ objectives. A detailed explanation is provided in General Response #2. This controlled weighting achieves a delicate balance, uncovering solutions that uniquely contribute to a diverse and complementary Pareto front.\n\n\n> Q7. **Distribution of Final Solutions:**\n   - We have shown the distribution in Figure 1.\n\n> Q8. **Computational Efficiency and OT Implementation:**\n  - Optimal transport (OT) only costs a tiny fraction of the total runtime in MosT. Moreover, when compared to alternatives such as linearization and EPO, MosT remains more efficient overall. For comprehensive details and specific values of the runtime, please refer to General Response #3.\n\n---\n\nWe hope these clarifications address your concerns and contribute to an improved understanding of MosT. \n\nSincerely,  \nAuthors of Paper #8707"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8707/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700355109582,
                "cdate": 1700355109582,
                "tmdate": 1700355109582,
                "mdate": 1700355109582,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tAQVULMRAa",
                "forum": "uXbqFnQfH4",
                "replyto": "PEyzI6Mt1f",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8707/Reviewer_AiMo"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8707/Reviewer_AiMo"
                ],
                "content": {
                    "title": {
                        "value": "wrt epo"
                    },
                    "comment": {
                        "value": "I think EPO does not require the number of input. It can accept a single pref."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8707/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700364946661,
                "cdate": 1700364946661,
                "tmdate": 1700364946661,
                "mdate": 1700364946661,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dpcKZd3Oc4",
                "forum": "uXbqFnQfH4",
                "replyto": "PEyzI6Mt1f",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8707/Reviewer_AiMo"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8707/Reviewer_AiMo"
                ],
                "content": {
                    "title": {
                        "value": "what do you mean struture information"
                    },
                    "comment": {
                        "value": "does it help for the final performance?"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8707/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700364999443,
                "cdate": 1700364999443,
                "tmdate": 1700364999443,
                "mdate": 1700364999443,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iRE6XsZtVN",
                "forum": "uXbqFnQfH4",
                "replyto": "IZr7zZLzaB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8707/Reviewer_AiMo"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8707/Reviewer_AiMo"
                ],
                "content": {
                    "title": {
                        "value": "about epo"
                    },
                    "comment": {
                        "value": "Why on zdt1, epo can only find a single solution\uff1f \uff08Figure 6 in the main paper\uff09. I have just run this experiment several dates among. EPO work perfectly on ZDT1, do you use the same preference?"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8707/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700450073408,
                "cdate": 1700450073408,
                "tmdate": 1700450073408,
                "mdate": 1700450073408,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ECWNEoRMQW",
                "forum": "uXbqFnQfH4",
                "replyto": "O8muXcgB6I",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8707/Reviewer_AiMo"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8707/Reviewer_AiMo"
                ],
                "content": {
                    "title": {
                        "value": "Another missing work."
                    },
                    "comment": {
                        "value": "Another missing work is \"Multi-Objective Deep Learning with Adaptive Reference Vectors\", which use a similar bi-level optimization method by maximizing the hv. \nSince this paper seems that directly optimize the hv. This method should have better hv than Most. Since Most does not directly optimize hv."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8707/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700466036421,
                "cdate": 1700466036421,
                "tmdate": 1700466036421,
                "mdate": 1700466036421,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2aH6ISkver",
                "forum": "uXbqFnQfH4",
                "replyto": "O8muXcgB6I",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8707/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8707/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to \"Another missing work\""
                    },
                    "comment": {
                        "value": "Thanks for pointing out the work! We will look into it and discuss it in our paper. Since we cannot find the source code of the paper online, it might be hard to provide an empirical comparison with it within a short time. \n\nThat being said, most HV optimization methods only work for small-$n$ cases ($n$=2 or 3 objectives). They usually CANNOT scale to **large-$n$ and $n\\gg m$ cases** with hundreds to thousands of objectives, which are the main focus of this paper and the gap we aim to bridge. The computation of HV and its gradient may also suffer from the curse of dimensionality when $n$ is large.\n\n**In Table 4 of the paper you mentioned, they already claimed that their method is hard to scale to merely $n=15$ objectives**. Quoted from Table 4's caption, \"GMOOAR-HV cannot be run on 15 tasks as it takes more than a month on our machine.\" In contrast, in Section 5.3 of our paper, **MosT can easily scale to $n>200$ objectives**."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8707/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700471135058,
                "cdate": 1700471135058,
                "tmdate": 1700472127400,
                "mdate": 1700472127400,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gAqOCaN848",
                "forum": "uXbqFnQfH4",
                "replyto": "aMzksTrbMC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8707/Reviewer_AiMo"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8707/Reviewer_AiMo"
                ],
                "content": {
                    "title": {
                        "value": "a tricky thing about epo"
                    },
                    "comment": {
                        "value": "a tricky thing about epo is that, it is the exact solution w.r.t. the inverse of the preferences $1/\\lamba_1, ..., 1/\\lamba_m$. What the current chosen of preferences. A fair comparasion should be, the uniform preference distribution in this inverse preference space."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8707/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700481033167,
                "cdate": 1700481033167,
                "tmdate": 1700481033167,
                "mdate": 1700481033167,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UclV27Ax7V",
                "forum": "uXbqFnQfH4",
                "replyto": "2aH6ISkver",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8707/Reviewer_AiMo"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8707/Reviewer_AiMo"
                ],
                "content": {
                    "title": {
                        "value": "current concerns"
                    },
                    "comment": {
                        "value": "My current concern is mainly about the experiments. \n(1) When the number of  objective n is small. I think, it is actually pretty hard to improve the previous methods. Chen Wei Yu's NeurIPS work, considering the hv maximization should have the best hv, though hv may still not a satisfied indicator. \n\n(2) I agree with the author, that, the many objective issue is very important. However, the results shown in Figure 2(c) outperform other methods by such a great margin. I think this is impossible. Other methods may not get enough diverse objectives, but it seems that other solution is dominated by the proposed method on all objectives. The results seems too optimistic. \n\nWhat is the core reason, the proposed method win such a lot on Figure (a)? The considered different type MGDA or OT?"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8707/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700482835046,
                "cdate": 1700482835046,
                "tmdate": 1700482835046,
                "mdate": 1700482835046,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6dNU4e2Vny",
                "forum": "uXbqFnQfH4",
                "replyto": "O8muXcgB6I",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8707/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8707/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to \"a tricky thing about epo\" and \"current concerns\""
                    },
                    "comment": {
                        "value": "Q1. What are the current chosen preferences?\n\nThe preference vectors used for EPO are generated using the exact pipeline as outlined in the official implementation of EPO (https://github.com/dbmptr/EPOSearch/blob/master/mtc/epo_train.py). That is, we follow the same process described as the \"tricky way\" in your review. We are committed to providing the implementation details of MosT, as well as all baseline methods, upon publication.\n\nQ2. It seems that other solution is dominated by the proposed method on all objectives.\n\nIn Figure 2(c), we are not displaying the performance gap for each objective separately but rather for groups of objectives. So, the figure does not suggest that MosT dominates other solutions on all objectives. What it illustrates is that MosT outperforms the baselines by a larger margin for clients with worse performance. This underscores MosT's role in promoting fairness in federated learning by delivering superior results for those clients facing greater challenges.\n\nQ3. Why does MosT win a lot in federated learning?\n\nThis is because we keep optimizing the assignment of solutions (models) to objectives (clients) in the training stage (by OT), while other methods do not optimize the assignments at all."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8707/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700496217179,
                "cdate": 1700496217179,
                "tmdate": 1700497880985,
                "mdate": 1700497880985,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aC62aiLpPl",
                "forum": "uXbqFnQfH4",
                "replyto": "6dNU4e2Vny",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8707/Reviewer_AiMo"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8707/Reviewer_AiMo"
                ],
                "content": {
                    "comment": {
                        "value": "I do believe EPO can lead to perfect result on zdt1. I will conduct this experiment for you tomorrow."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8707/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700497688654,
                "cdate": 1700497688654,
                "tmdate": 1700497688654,
                "mdate": 1700497688654,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "NYxzyLD6Ea",
            "forum": "uXbqFnQfH4",
            "replyto": "uXbqFnQfH4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8707/Reviewer_EZcQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8707/Reviewer_EZcQ"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes a novel Multi-objective multi-solution Transport (MosT) method to find a small set of diverse Pareto solutions for problems with a large number of objectives. MosT is formulated as a bi-level optimization problem, where the upper-level problem is to determine different objective weights for each solution via optimal transport (OT) based on their current performance, while the lower-level problem is to find a Pareto solution for each subproblem with weighted objectives. MosT can also be generalized to tackle multi-objective optimization problems with few objectives via random objective interpolation.\n\nThis work also provides theoretical analysis to prove MosT can find a set of Pareto solutions via solving the bi-level optimization problem. Experiments show MosT can achieve promising performance on different synthetic and application problems."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ This work is well-organized and easy to follow.\n\n+ The *small solution set for a large number of objectives* setting is important for many real-world applications. This work is a timely contribution to an interesting yet under-explored research direction.\n\n+ The proposed MosT method can achieve promising performance on different synthetic and application problems."
                },
                "weaknesses": {
                    "value": "I enjoy reading this paper but also have many major concerns on the proposed MosT method, which makes it hard for me to vote for acceptance. My current rating is more like a weak reject (4). \n\n**1. Motivation**\n\nSome crucial design choices for MosT are not well motivated, and more clear discussions are needed.\n\n- **Weighted Objectives:** The key of MosT is to assign different weights to the objectives for different solutions. What is the relation of the Pareto sets for the problems with weighted objectives (1) with the Pareto set of the original unweighted problem? In addition, It is also unclear what makes the weighted problems good for diversity. On page 4, it mentions that the weighted problem can move a small gradient from the origin in Eq. (5). But the whole picture of how the (optimal) weighted problem can lead to a set of \"different but complementary and balanced\" solutions that best cover all objectives is not clear to me.\n\n- **Optimal Weights and OT:** If there is a set of optimal weights that can lead to a set of optimally distributed solutions, what properties such a set of weights should have? Is it unique? Why such optimal weights (if they exist) can be found by OT (e.g., eq.(2)) is also not clearly discussed.\n\n- **MGDA for Weighted Problems:** MosT uses MGDA to find a Pareto solution for each problem with different weighted objectives. However, MGDA can find any Pareto stationary solutions and the location is not controllable. For a non-trivial problem, the Pareto set could be a large $n-1$ dimensional manifold with a large $n$ for each weighted problem, where MGDA can lead to any possible solution on the manifold. Why the (uncontrollable) solutions found by MGDA for each weighted problem (1) can be guaranteed to be complementary and evenly distributed? \n\n**2. Gap between MosT and the Metrics**\n\nThere are different and not unique metrics to measure the quality of the obtained solution set. It is unclear why the solution set found by MosT could be optimal for a given criteria (e.g., hypervolume). \n\n- **Hypervolume for Few Objectives $(n << m)$:** For problem with few objectives (e.g., 2-3), if the goal is to maximize the hypervolume, why not directly use gradient-based hypervolume maximization to find the solution set [1,2]?\n\n- **Large Number of Objectives $(n >> m)$:** For problems with a large number of objectives, this work let each objective pick the best solution out of all $m$ obtained solution, and then calculate the overall performance. In this case, it seems that, at the end of optimization, the objectives covered by different optimal solutions should be mutually exclusive. For example, for a problem with 300 objectives and 3 solutions, solution 1 covers 95 objectives, solution 2 covers 103 objectives, and solution 3 covers 102 objectives, and hence each objective is covered by a single solution. In this case, the optimal solution should not cover other conflicted objectives that it does not work the best, since it might lower the solution's performance on the currently covered objectives.  Therefore, it is unclear why \"During later stages, ..., every objective has to be covered by sufficient models (solutions)\".\n\nIn addition, the final metric we care about is the mean(std) of average performance across all objectives (e.g., Table 2). Once the groups of objectives covered by different solutions are determined, why not just use simple uniform linear scalarization to optimize all objectives for each group?\n\n**3. Time Complexity**\n\n- MosT formulate the original multi-objective optimization as iterative bi-level optimization, which involves solving a OT problem and $m$ MGDA problems at each iteration. What is the time complexity of MosT? Will the OT solver has high computational overhead?\n\n- For MGDA with large $n$ (e.g., 205), even with the Frank-Wolfe algorithm, will the run time be very long for solving eq. (5)? Will it be very hard to find a valid gradient direction to optimize all 205 objectives at the same time?  \n\n**4. Extension to Few Objective Case ($n << m$)**\n\nFor problems with few objectives (e.g., 2 or 3), this work uses $n^{\\prime}$ dense interpolations among original objectives to create a large number of objectives, and then applies MosT to find a set of diverse solutions.\n\n- If $n^{\\prime}$ is large, will this approach lead to high computational overhead for problems with few objectives?\n\n- The weights of interpolation are uniformly drawn from a Dirichlet distribution over the simplex. However, uniform weights usually do not represent uniform solutions on the Pareto front. If $n^{\\prime}$ is small, will it hurt the performance? \n\n**5. Experiment**\n\n- **Toy Problems:** To my understanding, the algorithms considered in Section 5.1 are all for unconstrained multi-objective optimization problems. However, the ZDT problems have box constraints ($\\theta \\in [0,1]^d$), and their Pareto sets are all on the boundary (the constraints are activated). Will these algorithm's performances be significantly affected by the constraints? In addition, according to [3], EPO (if with a suitable reference point) and SVGD have much better performance on ZDT1-3. What is the reason for the poorer performance reported in this paper?\n\n- **More Problem with Large Number of Objectives:** The main motivation of this work is to tackle the *small solution set for a large number of objectives* problem. However, the experiment only has a single real-world application with many objectives on the federated learning application with FEMNIST. The other experiments are on synthetic problems or problems with few objectives. It is important to know MosT's performance on more realistic application problems with a large number of objectives, especially those other than federated learning.  \n\n- **Runtime Comparison:** Please report the runtime for different algorithms on all experiments."
                },
                "questions": {
                    "value": "- Please address the concerns raised in the above weaknesses.\n\n- When citing multiple papers, it is better to put them in chronological order.\n\n**Reference**\n\n[1] Hypervolume indicator gradient ascent multi-objective optimization. International Conference on Evolutionary Multi-Criterion Optimization 2017.\n\n[2] Multi-Objective Learning to Predict Pareto Fronts Using Hypervolume Maximization. arXiv:2102.04523.\n\n[3] Profiling Pareto Front With Multi-Objective Stein Variational Gradient Descent. NeurIPS 2021."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8707/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698760178930,
            "cdate": 1698760178930,
            "tmdate": 1699637091791,
            "mdate": 1699637091791,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HVdt4wSMcJ",
                "forum": "uXbqFnQfH4",
                "replyto": "NYxzyLD6Ea",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8707/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8707/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer EZcQ (part 1)"
                    },
                    "comment": {
                        "value": "### 1. Motivation\n> Q1.1  **What is the relation of the Pareto sets for the problems with weighted objectives (1) with the Pareto set of the original unweighted problem? How the (optimal) weighted problem can lead to a set of \"different but complementary and balanced\" solutions that best cover all objectives?**\n\nBy the definition of Pareto optimality, the Pareto optimal solutions identified for weighted objectives remain Pareto optimal for the original unweighted problem if all weights are positive. That being said, the weight vector for each model per step guides the MGDA to pursue solutions at a specific region of the Pareto front, similar to a reference/preference vector. Hence, different weight vectors lead to different solutions.\n\n\nThe complementary and balanced solutions are enforced through the weights achieved by OT and they are mainly due to the two marginal constraints in OT, which enforces the balance among the $m$ solutions and a fair coverage over all the $n$ objectives. \nThis controlled weighting achieves a delicate balance, uncovering solutions that uniquely contribute to a diverse and complementary Pareto front.\n\n> Q1.2  **If there is a set of optimal weights that can lead to a set of optimally distributed solutions, what properties such a set of weights should have? Is it unique? Why such optimal weights (if they exist) can be found by OT (e.g., eq.(2)) is also not clearly discussed.**\n\nOptimal weights in MosT are expected to achieve diverse and complementary assignments from solutions to objectives. The solution to entropic optimal transport, as employed in MosT, is unique [1]. OT seeks a transportation plan that minimizes loss (complementary) while meeting the marginal constraint (diversity) [2]. This offers a clear connection between the principles of OT and the optimal weights needed in MosT.\n\n> Q1.3  **Why the (uncontrollable) solutions found by MGDA for each weighted problem (1) can be guaranteed to be complementary and evenly distributed?**\n\nMosT combines MGDA with strategic weight assignment for a balanced exploration of the Pareto front. While MGDA itself may not guarantee the location of solutions, the reweighted objective (with weights 'controlled' by OT) ensures that the algorithm converges to solutions that cover different regions of the Pareto front. The weights assigned to objectives are derived through Optimal Transport (OT), introducing a controlled and strategic weighting mechanism. This weighting process ensures that the solutions found by MGDA are not arbitrary but guided by a deliberate assignment of weights."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8707/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700362096245,
                "cdate": 1700362096245,
                "tmdate": 1700362320640,
                "mdate": 1700362320640,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oSTCJpUgeO",
                "forum": "uXbqFnQfH4",
                "replyto": "NYxzyLD6Ea",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8707/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8707/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer EZcQ (part 2)"
                    },
                    "comment": {
                        "value": "### 2. Gap between MosT and the Metrics\n\n\n> Q2.1  **Why not directly use gradient-based hypervolume maximization to find the solution set?**\n\nWhile gradient-based hypervolume maximization is effective for a small number of objectives, MosT is effective in both less-dimensional and high-dimensional scenarios. Combining multi-gradient descent algorithms with optimal transport, MosT navigates high-dimention Pareto front efficiently. \n\n\nAdditional, we want to highlight challenges with direct hypervolume maximization [3], facing issues such as dependence on reference points and susceptibility to bad local minima [4,5].\n\n> Q2.2  **It is unclear why \"During later stages, ..., every objective has to be covered by sufficient models (solutions).\"**\n\nDuring later stages, the uniformity of objective marginals, coupled with performance-based solution marginals, enables each objective to select its best-performing solution(s).\n\nWe acknowledge that objectives may be covered by different optimal solutions, raising concerns about potential mutual exclusivity. However, MosT aims to harmonize these contributions rather than enforce exclusivity. MosT strategically balances marginal distributions in later stages as described. This design ensures that even if a solution excels on specific objectives, the overall objective coverage remains diverse and robust.\n\n> Q2.3 **In addition, the final metric we care about is the mean(std) of average performance across all objectives (e.g., Table 2). Once the groups of objectives covered by different solutions are determined, why not just use simple uniform linear scalarization to optimize all objectives for each group?**\n\n\nOur main interest is in achieving diverse and complementary assignments from solutions to objectives, not just in terms of average accuracy. We want to make sure our solutions cover various objectives effectively. \n\nNote that, even within the same group you mentioned, objectives may exhibit varying characteristics and trade-offs. Consequently, a one-size-fits-all approach, such as simple uniform linear scalarization, might not capture the intricacies of each objective grouping. In addition, such alternative approaches require additional design, such as stopping criteria, which can increase the complexity of the algorithm. In contrast, MGDA tailors the optimization process to the specific characteristics of each group. This fine-grained optimization approach ensures that each objective's contribution is considered with the attention it deserves.\n\n\n### 3. Time Complexity\n\nWe acknowledge the importance of this aspect and have provided a detailed analysis in General Response #3. In summary, optimal transport constitutes only a small fraction of the total runtime in MosT. Moreover, when compared to alternatives such as linearization and EPO, MosT remains more efficient overall. For comprehensive details and specific values, please refer to General Response #3.\n\n### 4. Extension to Few Objective Case (n<<m)\n\nWe empirically show that a relatively small $n'$ for interpolations of a few (i.e., $n$) original objectives is sufficient to achieve adequate performance. In the accuracy-fairness tradeoff ($n=2$), we conducted experiments sweeping over $n'\\in \\{10, 20, 30, 40, 50\\}$. Our results indicate that utilizing $n' = 10$ yields comparable performance to those larger $n'$, as clarified in Appendix D.3. Consequently, we adopted the smaller $n' = 10$ in our experiments, obtaining the final results reported in Table 3."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8707/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700362272666,
                "cdate": 1700362272666,
                "tmdate": 1700362272666,
                "mdate": 1700362272666,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Z4RKVbPB7a",
                "forum": "uXbqFnQfH4",
                "replyto": "NYxzyLD6Ea",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8707/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8707/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer EZcQ (part 3)"
                    },
                    "comment": {
                        "value": "### 5. Experiment\n\n> Q5.1 **Constraints in ZDT Problems and performance of EPO and SVGD:**\n   - All algorithms in the experiments, including MosT, are originally designed to handle unconstrained multi-objective optimization problems. To enforce the constraints in the ZDT problem, all algorithms perform projected gradient descent, i.e., by clipping the variables back to [0,1] in every step if necessary. This operation ensures the fairness of the comparison and the constraints.\n   \n\n   - We compare algorithms with their original implementations and consistent settings, including the same reference point and the same number of solutions. The performance gap may come from the fact that EPO needs to sample an extensive number of preference vectors (\\~100) and SVGD needs diverse initializations (\\~50). Comparing their numbers with our limited number of solutions (5 for ZDT problems), these two algorithms cannot work as reported. These results show the efficiency of MosT, which does not rely on diverse sampling to achieve well-distributed solutions over the Pareto fronts.  \n\n> Q5.2 **Realistic Application Problems with a Large Number of Objectives:**\n   - **Expansion to Multi-Task Learning Scenarios:** We appreciate your suggestion to include more realistic application scenarios with a higher number of objectives. In response, we have expanded our experiments to include multi-task learning scenarios with two real datasets (n = 4 and 6, resp) and showed promising results. This addition aims to provide a more diverse and comprehensive evaluation of MosT's performance across different application domains. Detailed results and analysis are available in Appendix E and General Response #4.1.\n\n> Q5.3 **Runtime Comparison:**\n   \n   - In response to your feedback, we have included detailed runtime metrics for MosT and other algorithms over two real datasets, detailed in General Response #3. The results show that MosT is more efficient compared to linearization and EPO, and comparable to MGDA.\n\nSincerely,  \nAuthors of Paper #8707\n\n---\n\nReferences:\\\n[1] Xie Y, Wang X, Wang R, et al. A fast proximal point method for computing exact wasserstein distance. Uncertainty in artificial intelligence. PMLR, 2020: 433-453.\\\n[2] Cuturi M. Sinkhorn distances: Lightspeed computation of optimal transport. Advances in neural information processing systems, 2013, 26.\\\n[3] Liu X, Tong X, Liu Q. Profiling pareto front with multi-objective stein variational gradient descent. Advances in Neural Information Processing Systems, 2021, 34: 14721-14733.\\\n[4] Wang H, Deutz A, B\u00e4ck T, et al. Hypervolume indicator gradient ascent multi-objective optimization. Evolutionary Multi-Criterion Optimization: 9th International Conference, EMO 2017, M\u00fcnster, Germany, March 19-22, 2017, Proceedings 9. Springer International Publishing, 2017: 654-669.\\\n[5] Deist T M, Grewal M, Dankers F J W M, et al. Multi-objective learning to predict pareto fronts using hypervolume maximization. arXiv preprint arXiv:2102.04523, 2021."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8707/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700362362857,
                "cdate": 1700362362857,
                "tmdate": 1700362362857,
                "mdate": 1700362362857,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pDGifCGuxH",
                "forum": "uXbqFnQfH4",
                "replyto": "NYxzyLD6Ea",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8707/Reviewer_EZcQ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8707/Reviewer_EZcQ"
                ],
                "content": {
                    "title": {
                        "value": "Follow-up Comment"
                    },
                    "comment": {
                        "value": "Thank you for your detailed response and additional experiments. However, many of my concerns remain.\n\n**1. Motivation:**  Many claims are not solid and not well-supported, such as \"the weight vector for each model per step guides the MGDA to pursue solutions at a specific region of the Pareto front, similar to a reference/preference vector\" and \"this weighting process ensures that the solutions found by MGDA are not arbitrary but guided by a deliberate assignment of weights\".\n\nIn MosT, the MGDAs can reach any Pareto optimal solution of each weighted problem, which is exactly the same Pareto optimal set of the original problem. In other words, the current theoretical guarantee of MosT is not stronger than the original MGDA. The reason why MosT can be ensured to find a set of diverse Pareto solutions does not have proper theoretical support.\n\n**2. Metrics:** My main concern here is to clearly show why the solution set found by MosT can outperform other algorithms on different criteria for both the (n<<m) and (n>>m) cases with *theoretical analysis*.\n\n\n**3. Time Complexity:** It is counter-intuitive to see linear scalarization require more runtime than MGDA. What is the computational overhead of linear scalarization over MGDA? In addition, since the main motivation for MosT is to address the problem with a much larger number of objectives (n >> m), the runtime comparison under this setting (e.g., with n = 205) is much more important. \n\n**5.1 Toy Problems:** An immediate follow-up question is why compare all unconstrained multi-objective optimization algorithms on a set of constrained problems?\n\nIn addition, to my understanding, EPO is an exact preference-based optimization method, and the quality of each solution is agnostic to the number of preference vectors. Even only given a single preference vector, under a set of reasonable assumptions, EPO can also successfully find the Pareto solution with the specific trade-off. Therefore, EPO should work fine with 5 given preference vectors. The claim \"EPO needs to sample an extensive number of preference vectors (~100)\" is questionable.\n\n**5.2 More Problem with Large Number of Objectives:** The main motivation for MosT is to handle the problem with a large number of objectives (e.g., m << n = 200). The added experiments with a small number of objectives (e.g., n = 4 and 6) are still far from the main motivation. Is it very hard to find a practical application for the n >> m setting?\n\nIn addition, recent works on MTL and multi-domain learning have shown that simple linear scalarization with proper regularization can perform comparably with advanced methods such as MGDA [4,5,6]. The linear scalarization is also fast and will not suffer from a large computational overhead for problems with many tasks (e.g., a large n) as considered in this work. Why is the performance of linear scalarization much worse than MGDA in the new experiments with a large gap? \n\n[1] In Defense of the Unitary Scalarization for Deep Multi-Task Learning. NeurIPS 2022.\n\n[2] Do current multi-task optimization methods in deep learning even help. NeurIPS 2022.\n\n[3] Scalarization for Multi-Task and  Multi-Domain Learning at Scale. NeurIPS 2023.\n\n**5.3 Runtime Comparison:** Please report the runtime for the n >> m setting (e.g., n = 200)."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8707/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700533546885,
                "cdate": 1700533546885,
                "tmdate": 1700534533543,
                "mdate": 1700534533543,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "GRvZOPyQ8R",
            "forum": "uXbqFnQfH4",
            "replyto": "uXbqFnQfH4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8707/Reviewer_SZEd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8707/Reviewer_SZEd"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a method to generate $m$ solutions over the Pareto Set of a MOO to maximize diversity among the solutions, especially in the case where the number $n$ of objectives are much larger than $m$. \n\nTo enforce diverse solutions, this paper uses an Optimal Transport(OT)-based approach to learn the weights of different objectives towards evaluating different solutions such that the solutions are diverse and then uses MGDA to solve the MOO.\n\nThe advantages of the method have been illustrated over several experiments involving toy and real datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The main strength of the method is summarized nicely after eq (6) in the paper. Incorporating the optimal transport between uniform distribution over $1$ to $n$, and $1$ to $m$ effectively reweights the objectives before running vanilla MGDA. Because of OT, these weights $\\Gamma_{i,j}$ are larger where $L_i(\\theta_j)$ are small, that is, when two objectives $i$, and $j$ are similar ($L_i(\\theta_j)$ small), large $\\Gamma_{i,j}$ decreases the influence of the gradients of such objectives over MGDA compared to objectives which are different from each other. In the absence of $\\Gamma_{i,j}$ the solution of MGDA gets biased towards the objectives with small gradients and may lead to smaller diversity. \n\n2. This nice intuition works well over several applications. The effect of incorporating OT is nicely demonstrated in Figure 4 which shows the diversity in the selected objectives."
                },
                "weaknesses": {
                    "value": "The main weakness of the paper is the lack of theoretical support. **While the main claim of the paper is that it learns diverse solutions over Pareto set when the number of objectives is large, Theorem 1 and 2 only show convergence of the methods to any $m$ Pareto solutions which sheds no light on the diversity of the solutions.** The authors acknowledge this in the line just before Theorem 2. \n\nThe convergence results follow straightforwardly from existing literature as it just combines the proof of convergence of IPOT and MGDA. Moreover, it just characterizes the complexity of the outer loop whereas the inner loop (especially IPOT) can be quite computationally expensive. \n\nWithout proper theoretical justification, the claimed advantages of MosT, diverse solutions, and computationally cheaper, over other methods seem weak."
                },
                "questions": {
                    "value": "1. Why is $\\epsilon$ needed in Algorithm 1?\n\n2. I would expect the hypervolume of the solutions to be higher if one runs MGDA with diverse weight vectors $m$ times instead of random seeds. Could you compare MosT with such a version of MGDA?\n\n3. While comparing to previous work it is stated in Page 2 that the number of preference vectors required to profile the Pareto set can be exponential in the problem parameters which might be discouraging when the number of objectives $n$ is large. When $m$ and/or $n$ are large, IPOT (Line 4 in Algorithm 1) needs to be solved for high dimensions which can still be computationally large. How does this paper compare with the previous literature on this aspect?\n\nMinor Points (do not affect my score):\n1. Typo in Page 6: MDGA --> MGDA\n2. The full form of the abbreviations should be written where they are first introduced. \n3. ``which gives higher priority to models selecting objectives at\nthe earlier stages and then transits to a higher priority of objectives selecting the best models.\" - Why is this desirable?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8707/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698892040090,
            "cdate": 1698892040090,
            "tmdate": 1699637091686,
            "mdate": 1699637091686,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "csCkwL6VNN",
                "forum": "uXbqFnQfH4",
                "replyto": "GRvZOPyQ8R",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8707/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8707/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer SZEd"
                    },
                    "comment": {
                        "value": "Thanks to Reviewer SZEd for the insightful comments, and we provide our response below.\n\n> **Q1. Why is $\\epsilon$ needed in Algorithm 1?**\n\n\nSetting $\\epsilon$ to be a small non-zero constant guarantees that any Pareto solutions for the re-weighted objective in Eq.(5) are also Pareto solutions for the original unweighted problem. Empirically, we found that it also provides numerical stability during the optimization process. Its effectiveness is also supported by our convergence, which incorporates a non-zero $\\epsilon$. We will add more details in the revision.\n\n\n> **Q2. Comparison with MGDA using diverse weight vectors $m$ times.**\n   \nFollowing your suggestion, we conduct an ablation study in the context of federated learning with $n\\gg m$, in order to compare MosT and MGDA with $m$ different weight vectors for $n$ objectives. Our ablation study shows MosT with OT-generated weights achieves higher accuracy averaged across all objectives than the MGDA alternative. This indicates the importance of optimal transport in simultaneously balancing multiple solutions and multiple objectives. Comprehensive details and results are available in Appendix C.3 and General Response #4.2.\n\n> **Q3. Comparison with Previous Literature on Computational Aspects.**\n\nIn our method, the number of solution $m$ is a predefined constant, while MosT aims to maximize their usage and fully exploit their capacity by the optimal transport assignment to the $n$ objectives. This leads to better model efficiency, for example, when $n\\gg m$. In contrast, previous work usually requires the number of models $m$ to grow linearly or exponentially with $n$, without explicit optimization of their matching. Hence, our design aligns well with the practical need of computational efficiency and model efficiency. It also leads to scalability and computational tractability in scenarios with a large number of objectives ($n\\gg m$). In General Response #3, we provide the end-to-end running time of our method and the baselines under the same $m$, showing that MosT is able to result in better solutions more quickly.\n\n---\n\nWe hope these responses address your concerns and provide further clarity on the contributions of our work. \n\nSincerely,  \nAuthors of Paper #8707"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8707/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700328316067,
                "cdate": 1700328316067,
                "tmdate": 1700328316067,
                "mdate": 1700328316067,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "GFsZcOPHtX",
            "forum": "uXbqFnQfH4",
            "replyto": "uXbqFnQfH4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8707/Reviewer_bAug"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8707/Reviewer_bAug"
            ],
            "content": {
                "summary": {
                    "value": "The authors introduced a multi-objective multi-solution transport approach to optimizing multiple objectives using multiple solutions, which aims to achieve diverse trade-offs among objectives by treating each solution as a domain expert. The authors stated that the approach addresses cases where the number of objectives greatly exceeds the number of solutions and demonstrates superior performance in applications like federated learning, fairness-accuracy trade-offs, and standard multi-objective optimization benchmarks, providing high-quality, diverse solutions that cover the entire Pareto frontier. Moreover, the authors stated that the approach \u201caims to find m Pareto solutions (models) that achieve diverse trade-offs among n optimization objectives\u201d."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "NA"
                },
                "weaknesses": {
                    "value": "The literature review does not provide a cohesive and structured presentation, and fails to accurately acknowledge established approaches and terminology within Evolutionary Computation (EC). This indicates a potential oversight in acknowledging state-of-the-art methods in EC such as the author do not properly reference existing work on this topic from EC. The approach lacks novelty and has been previously explored in the literature. The description of the approach and the literature review is not presented in a clear and understandable manner. The authors do not provide any new insights into the method, key experimental setup is missing (see section 5.1 Experimental setting). The solutions produced in Section 5 \u201cMOST APPLICATIONS\u201d are not clearly described and it is not clear that there is any significance to the results taking into account the benchmarks are insufficiently small and inadequate for comprehensive evaluation. The paper's contributions lack substantial significance and originality, and primarily represent incremental progress."
                },
                "questions": {
                    "value": "How does this approach contribute to achieving diverse trade-offs among objectives? Can you provide more details about the theoretical foundation?\nCan you provide a more detailed comparison between the MosT approach and existing state-of-the-art methods in multi-objective optimization?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8707/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699513812625,
            "cdate": 1699513812625,
            "tmdate": 1699637091580,
            "mdate": 1699637091580,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fgHijxCowD",
                "forum": "uXbqFnQfH4",
                "replyto": "GFsZcOPHtX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8707/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8707/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer bAug"
                    },
                    "comment": {
                        "value": "We express gratitude to Reviewer bAug for the evaluation of our submission. While we respect your perspective, we aim to address concerns and provide clarifications.\n\n---\n\n> Q1. **Literature Review:**\n   - Our literature review in Section 2 did include discussions on Evolutionary Computation (EC) methods. We also compared MosT with SVGD [1], a recent approach that evolutionarily updates particles towards the Pareto front. Specifically, EC methods can be inefficient in practical MOO problems due to the absence of gradient information [1-3] and the poor exploration in high-dimensional spaces (when the number of objectives is large). This distinction positions our approach, which leverages gradient-based techniques, as a more suitable and efficient alternative. \n   \n   - **Question: Could you please specify which literature is missing?**\n\n> Q2. **Novelty and Significance:**\n   - Our primary contributions and novelty: (1) the novel task and problem formulation of multi-objective multi-solution transport; (2) addressing a unexplored class of challenging problems when $n\\gg m$ (but also appliable to cases when $n\\ll m$); (3) intuitive and effective MosT algorithm; (4) thorough empirical evaluation on a diverse set of machine learning problems. Specifically, the marginal constraints in Optimal Transport (OT) are essential to achieve a balanced solution-objective matching, leading to a diverse and complementary ensemble of solutions.\n    \n    \n  - **Question: Could you please specify which literature has explored our method?** \n   \n\n> Q3. **Experimental Setup:**\n   - The details of the experimental setup are introduced in Section 5.1, and additional information is provided in Appendix D for a more comprehensive understanding.\n\n   - **Question: Could you please specify which part of the experimental setup is considered missing?**\n\n> Q4. **Results Significance:**\n   \n   MosT proves its application across federated learning, fairness-accuracy trade-offs, and multi-task learning (new to rebuttal) with multiple real datasets and also synthetic datasets. \n   - Our dataset selection aligns with established practices from previous papers in federated learning [4] and multi-objective optimization [1]. \n   - In the new version, we have expanded our experiments to real-world datasets for multi-task learning, providing a more comprehensive evaluation for $2\\leq n\\ll m$ cases. Detailed results and analysis are available in Appendix E. We will discuss this in the manuscript to underscore the significance of our findings.\n\nIn conclusion, we appreciate the opportunity to address these concerns and are committed to enhancing the clarity and completeness of our manuscript based on your valuable feedback.\n\nSincerely,  \nAuthors of Paper #8707\n\n---\n\nReferences:\\\n[1] Liu X, Tong X, Liu Q. Profiling pareto front with multi-objective stein variational gradient descent. Advances in Neural Information Processing Systems, 2021, 34: 14721-14733.\\\n[2] Mahapatra D, Rajan V. Multi-task learning with user preferences: Gradient descent with controlled ascent in pareto optimization. International Conference on Machine Learning. PMLR, 2020: 6597-6607.\\\n[3] Momma M, Dong C, Liu J. A multi-objective/multi-task learning framework induced by pareto stationarity. International Conference on Machine Learning. PMLR, 2022: 15895-15907.\\\n[4] Li T, Sahu A K, Zaheer M, et al. Federated optimization in heterogeneous networks[J]. Proceedings of Machine learning and systems, 2020, 2: 429-450."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8707/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700238314150,
                "cdate": 1700238314150,
                "tmdate": 1700238314150,
                "mdate": 1700238314150,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "V47Mg3W3nD",
            "forum": "uXbqFnQfH4",
            "replyto": "uXbqFnQfH4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8707/Reviewer_YDRF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8707/Reviewer_YDRF"
            ],
            "content": {
                "summary": {
                    "value": "This articled presented a multi-objective multi-solution transport framework aiming to find the solutions that achieve diverse trade-offs among n optimization."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This article explored the feasibility of exploring a high dimensional Pareto frontier where there needs significant contribution is needed.\nThe authors framework had theoretically converges to a number of solution by optimizing the objectives and optimal transport.\nApplied the framework to some of the ML problems such as federated learning, fairness-accuracy trade-offs, some other multi-objective optimization benchmark problems.\nEmpirical articulation of convergence analysis"
                },
                "weaknesses": {
                    "value": "Improvements and contributions towards federated learning would ensemble this article to a different altitude"
                },
                "questions": {
                    "value": "Interesting analysis on n<<m in section 5.4. But the number of objectives is set as 2. Are there experiments conducted with more than 2 objectives? Did the solution converge when n increased to 3 or 5?\nWhat type of solver used to run needs to be detailed out\nKeen to understand federated learning in detail, how does the clients receive training as it is very diverse and also what's the effect of number of local sample (vi) in such scenario?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8707/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699586422483,
            "cdate": 1699586422483,
            "tmdate": 1699637091467,
            "mdate": 1699637091467,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "eM0wobFI5B",
                "forum": "uXbqFnQfH4",
                "replyto": "V47Mg3W3nD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8707/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8707/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer YDRF"
                    },
                    "comment": {
                        "value": "We extend our sincere thanks to Reviewer YDRF for the insightful evaluation of our submission. We are encouraged by your recognition of the significance of our work in exploring a high-dimensional Pareto frontier. We hope the following replies resolve the concerns raised in your review.\n\n---\n\n> Q1. **\"Are there experiments conducted with more than 2 objectives? Did the solution converge when n increased to 3 or 5?\"**\n\nFollowing your suggestion, we've **expanded our experiments to include multi-task learning scenarios with `n << m` and varying numbers of objectives beyond two ($n=4 \\text{ and } 6$)**. Results show that MosT achieves promising performance over baselines, supporting the versatility of our proposed framework as `n` increases. Detailed results and analysis are available in Appendix E of the revised manuscript and also in General Response #4.1.\n\n> Q2. **\"What type of solver used to run needs to be detailed out.\"**\n\nWe utilize IPOT [1] as an off-the-shelf OT solver for Eq.(2) and a min-norm solver (based on a Frank-Wolfe algorithm) used by the vanilla MGDA [2] for optimizing Eq.(1), as mentioned in Section 3. We found that these solvers are effective in handling the complexities of our proposed optimization tasks.\n\n> Q3. **(also mentioned in `[Weakness]`) \"Keen to understand federated learning in detail, how do clients receive training, and what's the effect of the number of local samples (vi)?\"**\n\nThanks for your question. Clients perform training by running local SGD updates, similar to standard federated optimization methods. \n\nIn response to your suggestion, we conducted experiments that involved varying numbers of local samples per client\u2014specifically, 50, 75, and 100\u2014utilizing the synthetic federated learning dataset. Experiments consistently demonstrated MosT's superior performance compared to all baseline methods, as shown in the table below. Notably, **MosT exhibited greater efficacy, particularly with smaller local sample sizes**, outperforming the best baseline (MGDA).\n\n|     |  MGDA | Linearization | FedAvg | FedProx | FedMGDA+ | MosT  | over MGDA (%) |\n|:---:|:-----:|:-------------:|:------:|:-------:|----------|-------|-------|\n|  50 | 82.44 |     81.56     |  81.63 |  81.85  | 79.33    | 85.33 | 3.51% |\n|  75 | 83.89 |     81.33     |  82.56 |  82.67  | 77.44    | 86.56 | 3.18% |\n| 100 | 87.50 |     85.00     |  84.11 |  84.56  | 84.08    | 89.06 | 1.78% |\n\n\nSincerely,  \nAuthors of Paper #8707\n\n---\n\nReferences:\n\n[1] Xie Y, Wang X, Wang R, et al. A fast proximal point method for computing the exact Wasserstein distance. Uncertainty in artificial intelligence. PMLR, 2020: 433-453. \\\n[2] D\u00e9sid\u00e9ri J A. Multiple-gradient descent algorithm (MGDA) for multiobjective optimization. Comptes Rendus Mathematique, 2012, 350(5-6): 313-318."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8707/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700335190506,
                "cdate": 1700335190506,
                "tmdate": 1700335190506,
                "mdate": 1700335190506,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]