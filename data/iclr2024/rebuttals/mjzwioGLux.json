[
    {
        "title": "ROBUST SPARSE AND DENSE MATCHING"
    },
    {
        "review": {
            "id": "EHabSuV2gY",
            "forum": "mjzwioGLux",
            "replyto": "mjzwioGLux",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2298/Reviewer_Bj1C"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2298/Reviewer_Bj1C"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a generalized dense matching network, capable of tackling both the optical flow and feature matching tasks simultaneously.  To do this, the authors propose a new model architecture that decouples the uncertainty estimation and investigate how to jointly train on a diverse set of flow and matching datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The authors provide a sound approach to matching, overcoming issues with confidence masks having different interpretations depending on the task by completely decoupling the certainty estimation as a posthoc step. The decoupling is also done in previous work (see PDCNet for example), but they do not detach gradients. What would have perhaps been even more interesting to see would be decoupling of the flow depending on the task. For example, small baseline tasks imply different priors on the types of flow that are likely. There is future potential in this type of approach.\n\n* The paper, except for some minor mistakes, is easy to follow and well written. \n\n* The task is important and a method unifying small and large baseline matching would be of great interest to the community. (See UniMatch)"
                },
                "weaknesses": {
                    "value": "* The model architecture is not well motivated. It seems similar to previous optical flow and dense feature matching works. It is not clear why the authors do not start from an established baseline like, e.g., PDCNet or GMFlow.\n\n* The performance on pose estimation is significantly below previous work. The MegaDepth benchmark, which is commonly used, is only shown briefly in the ablation, but no state of the art comparison is provided. The performance is about 5% lower than DKM. On ScanNet the performance is about 3% lower. Also on optical flow the relation to state of the art methods is not documented.\n\n* The ablation on the data is inconclusive. Adding optical flow datasets seem to lower results on pose estimation (Table 1). In the data ablation (Table 2) those results are no longer shown, why? Since those results are not shown, it must be assumed that adding more optical flow datasets further degrade performance.\n\n* Overall message. The manuscript fails in convincing that, with the currently available datasets, unifying wide and small baseline stereo is a good idea. The authors make a good attempt, and their model performs well at both tasks, but worse than the specialized counterparts. Showing that it is possible to do both tasks has been previously shown (GLUnet), so what remains to be shown is that the joint paradigm is superior."
                },
                "questions": {
                    "value": "1. What is the motivation of the architecture choice (see first weakness)?\n\n2. Why does adding optical flow datasets reduce performance (see third weakness)?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2298/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698657718094,
            "cdate": 1698657718094,
            "tmdate": 1699636162465,
            "mdate": 1699636162465,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "q9tLPIXjWV",
                "forum": "mjzwioGLux",
                "replyto": "EHabSuV2gY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2298/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2298/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your instructive suggestions on our paper. In this work, we aim to improve the generalization performance of the matching problem by collecting large-scale datasets covering optical flow, and geometry estimation datasets. We also propose a generalist model, capable of both optical flow estimation and geometry estimation. Our method achieves the best zero-shot evaluations across all datasets for matching and pose estimation tasks, strongly validating the effectiveness of our proposed method. To mitigate the degeneration of specialized datasets caused by training on data of diverse distributions, we propose a decoupled training strategy by learning matching and uncertainty estimation in a two-stage manner. Overall, we have taken into full consideration both the specificity and generality. The best zero-shot generalization performance compared with prior generalist and specialized models as well as the competitive performance compared with specialized methods can strongly demonstrate the contributions of our work. We also report the performance of optical flow following the standard setting as specialized models. The comparison is illustrated in Tab.6. We provide the updated results by adopting the tile mechanism proposed in FlowFormer. The results are shown below:\n\n| Methods       | Sintel-C &darr; | Sintel-F &darr;  | KITTI EPE &darr; | KITTI F1 &darr; |\n| ------------- | --------------- | ---------- | -------- | ---------- |\n|PWCNet| 2.6 | 3.9 | 10.4 | 33.7 |\n|DKM| 2.6 | 4.4 | 13.1 | 37.7 |\n|MS-RAFT| 1.4 | 2.7 | - | - |\n|FlowFormer| **1.0** | **2.4** | 4.1 | 14.7 |\n|GMFlow| 1.1 | 2.5 | 7.8 | 23.4 |\n|RAFT| 1.4 | 2.7 | 5.0 | 17.4 |\n|Ours| **1.0** | **2.4** | **3.9** | **12.6** |\n\nThis comparison strongly validates that if training on specific datasets under the same setting as specialized models, our method can also obtain superior performance. We will provide detailed explanations to your problems below:\n\n## Network architecture:\nThanks for pointing out this problem. We provide a detailed explanation for this problem in our first official comment. The primary reasons are twofold. First of all, the iterative optimization mechanism provides an explicit and efficient approach for exploiting geometric similarity, which can be employed in geometry estimation methods for further improvement. Moreover, conducting matching at a higher resolution can empirically introduce additional improvement for downstream pose estimation as in DKM, PATS, etc. However, popular optical flow estimation works like RAFT, FlowFormer, and GMFlow end up with the refinement at a relatively low resolution(1/4 at most). To mitigate this problem, we elaborately construct the model architecture to perform refinement at 1/2 resolution. In future work, we will conduct more comprehensive experiments and utilize your mentioned models(GMFlow, PDCNet+) for generalization evaluations with our training data.\n\n## Degeneration with optical flow \nCurrently, widely used datasets for training optical flow, such as FlyingThings3D, FlyingChairs, Sintel, and TartanAir, are synthesized datasets with relatively small displacements. In contrast, real-world datasets for geometry estimation often exhibit substantial changes in viewpoint. The integration of a diverse set of datasets with varying distributions, as opposed to training on specific datasets tailored for specialized tasks, may introduce inevitable interference, which accounts for the degeneration. The ablation studies in Table 1 are primarily conducted to reveal this phenomenon and demonstrate the effectiveness of our proposed decoupled training strategy in mitigating this decline. A more straightforward table for downstream pose estimation is presented below:\n\n|Methods|Datasets|Megadepth AUC@5|YFCC AUC@5|\n|---|----|----|----|\n|Joint|M|55.3|48.2|\n|Joint|M+TS|51.9|47.8|\n|Decoupled|M|55.7|48.5|\n|Decoupled|M+TS|54.0|48.2|\n\nLeveraging our decoupled training strategy efficiently enhances the performance when the optical flow dataset is used. In Tab.2, we utilize our decoupled training strategy in default to explore the effectiveness of scaling up the diversity of training for generalization performance. The uncertainty estimation module is not involved at this matching stage so only generalization evaluations on matching tasks are reported."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2298/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700718378425,
                "cdate": 1700718378425,
                "tmdate": 1700721863596,
                "mdate": 1700721863596,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cfNFTksAL0",
                "forum": "mjzwioGLux",
                "replyto": "q9tLPIXjWV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2298/Reviewer_Bj1C"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2298/Reviewer_Bj1C"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their rebuttal and will check my assessment after reading the responses to all reviews."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2298/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700723586032,
                "cdate": 1700723586032,
                "tmdate": 1700723586032,
                "mdate": 1700723586032,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "muzzVCfPKU",
                "forum": "mjzwioGLux",
                "replyto": "EHabSuV2gY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2298/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2298/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We greatly appreciate your immediate correspondence. We sincerely hope that in your reassessment, you can kindly take our primary contributions to the generalized matching task for both matching and pose estimation as well as our explorations to alleviate the degeneration when training on the mixed data of diverse distributions into consideration. Thanks for your instructive and academic suggestions on our work again!"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2298/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700726292137,
                "cdate": 1700726292137,
                "tmdate": 1700726335600,
                "mdate": 1700726335600,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7h8bHseifa",
            "forum": "mjzwioGLux",
            "replyto": "mjzwioGLux",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2298/Reviewer_Sn8S"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2298/Reviewer_Sn8S"
            ],
            "content": {
                "summary": {
                    "value": "This paper propose a robust sparse and dense matching network termed RSDM which can generalize well to unseen scenarios with our proposed cascaded GRU refinement for dense correspondence estimation and an uncertainty estimation module for sparsification.  The authors explore the effectiveness of scaling up the training data by mixing up multiple datasets. A comprehensive analysis is conducted to explore a more reasonable training strategy for enhanced robustness. The RSDM achieves state-of-the-art generalization performance in zero-shot evaluations for both matching and geometry estimation across multiple datasets, outperforming previous generalist and specialized models by an obvious margin"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper propose a robust sparse and dense matching network termed RSDM incorporating the proposed cascaded GRU refinement module along with an uncertainty estimation module for sparsification. The decoupled training mechanism as well as the increasing diversity of the numerous training data contributes to the superior generalization performance in zero-shot evaluations for both matching and pose estimation.\nThe strengths are as follows:\n1. The proposed RSDM can deal with both  sparse and dense matching task \n2. The proposed method mix up various dense and sparse matching datasets which significantly improves the training diversity.\n3. Superior performance is achieved for zero-shot matching as well as downstream geometry estimation across multiple datasets, outperforming the previous methods by a large margin"
                },
                "weaknesses": {
                    "value": "The weakness are as follows:\n1. The proposed model use high-weight parameters, swin-transformer, RAFT. It doesn't present the comparison with other methods.\n2. The \"Warping Error Map\" is not detailed in paper, but it's important \n3. How to use \"Uncertainty Map\" in ransac filter, it should be given in detail.\n4. In the experiments, the proposed method achieves good performance on zero-shot matching evaluations. but for Downstream pose estimation, it works not very well. Compared with DKM, its result is not very good. but the authors has no explanation.\n5. There is no model size and runtime cost comparison with other methods."
                },
                "questions": {
                    "value": "No questions"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "no"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2298/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698741679986,
            "cdate": 1698741679986,
            "tmdate": 1699636162380,
            "mdate": 1699636162380,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TxBjshI6sU",
                "forum": "mjzwioGLux",
                "replyto": "7h8bHseifa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2298/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2298/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Correspondence to reviewer2"
                    },
                    "comment": {
                        "value": "Thanks for pointing out the weakness of our work and we apologize for the unclear writing in this component. We will provide more comprehensive experiments in our revised supplementary materials.\n\n## Comparison with other methods:\nIn our work, we utilize the shifted-window strategy to perform self-attention and cross-attention for feature enhancement. The compared methods like GMFlow and FlowFormer also adopt the high-weight parameters. It's worth mentioning that FlowFlower utilizes the Twins-L model as its backbone for feature extraction.\n\n## Warping error computation\nAs briefly introduced in Sec.3.2, we warp the target frame to the reference frame according to the estimated optical flow with bilinear sampling. Given the input reference and target images $I_r, I_t,$ as well as the estimated optical flow $f$ at the grid $x$, the warped reference image can be computed as:\n$$\nI_{warped}(x) = I_r(x+f(x)),\n$$\nand the warped RGB error can be computed as:\n$$\nE_{RGB} = |I_r - I_{warped}|\n$$\nWe also compute the feature error $E_{feat}$ in the same way with reference and target features $F_r, F_t$:\n$$\nE_{feat}(x) = |F_r(x) - F_t(x+f(x))|\n$$\n\nThe final warping error is defined as the concatenation of both warped RGB error and warped feature error. We will add detailed introduction about the implementation of warping error in our revised paper.\n\n## Uncertainty map for ransac filter\nThe uncertainty map serves as a manifestation of the effectiveness of sparse correspondence matching. A higher degree of effectiveness in the sparse matching outcomes for a specific point is associated with an increased magnitude of its corresponding uncertainty. The cumulative uncertainties of all points within an image collectively contribute to the formation of its corresponding uncertainty map. We conduct a point selection procedure involving the uncertainty map and its corresponding matching outcomes, subsequently directing the selected points into a RANSAC filter. Our point selection process comprises two sequential steps. The initial step involves the selection of points using uncertainty as a screening criterion. The second step, based on the distribution among these selected points, constitutes a secondary selection aimed at ensuring diversity in the chosen points. In the specific context of the secondary point screening step, it entails the initial computation of Euclidean distances among the points selected during the initial screening. Euclidean distances are subsequently employed as a reference to establish weights for the secondary point selection, where greater distances correspond to augmented weights. As a preventive measure against the introduction of noise data, weights for points with distances exceeding a predefined threshold are reset to the minimum value of 1e-7.\n\n## Comparison with other optical flow methods:\nSorry for the shortage of this comparison with other optical flow methods in the main text which is placed in the supplementary materials as can be found in Tab.6. In our later research, we find that additional improvement can be obtained by adopting the tile technique mentioned in FlowFormer for alleviating the influence of position embedding at different resolutions. We provide the updated results in the following table:\n\n| Methods       | Sintel-C &darr; | Sintel-F &darr;  | KITTI EPE &darr; | KITTI F1 &darr; |\n| ------------- | --------------- | ---------- | -------- | ---------- |\n|PWCNet| 2.6 | 3.9 | 10.4 | 33.7 |\n|DKM| 2.6 | 4.4 | 13.1 | 37.7 |\n|MS-RAFT| 1.4 | 2.7 | - | - |\n|FlowFormer| **1.0** | **2.4** | 4.1 | 14.7 |\n|GMFlow| 1.1 | 2.5 | 7.8 | 23.4 |\n|RAFT| 1.4 | 2.7 | 5.0 | 17.4 |\n|Ours| **1.0** | **2.4** | **3.9** | **12.6** |\n\nThis comparison strongly validates that when training on specific datasets for specialized tasks, our model still obtains outstanding performance, achieving the best results on both Sintel and KITTI datasets. We will provide comprehensive comparisons with other specialized models under the same setting of specific tasks to validate the effectiveness of the proposed method. Moreover, we will place the aforementioned comparison on optical flow estimation in our main text in the revised version.\n\n## Computation cost and inference speed\nThanks for pointing out the absence of this experiment. We select state-of-the-art methods and make comparisons with them in terms of computation costs and inference speed. The result is shown below:\n\n|Methods|Computation Costs(GFLOPs)|Inference Speed(s)|\n|---|----|----|\n|FlowFormer|695.0|0.23|\n|GMFlow|202.8|0.06|\n|RAFT|505.8|0.15|\n|Ours|940.7|0.19|\n\nWe will explore to construct a more efficient model in our future work."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2298/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700723117557,
                "cdate": 1700723117557,
                "tmdate": 1700724129098,
                "mdate": 1700724129098,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "2QbXiIAQRs",
            "forum": "mjzwioGLux",
            "replyto": "mjzwioGLux",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2298/Reviewer_gGcr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2298/Reviewer_gGcr"
            ],
            "content": {
                "summary": {
                    "value": "This work proposed the robust network suitable for both sparse and dense matching tasks called RSDM. In this work, simlarity matrix/cost volume of three scales are generated with feature level refinement and GRU based correlation volume level refinement. Context level information is also used to guide the GRU refinemnet block for the first scale.  For sparsification, warp error based on predicted dense matching results are used to estimate the uncertainty while balanced sampling strategy are use. This work also generate a dataset based on TartanAir with optical flows generated. Experiments are hold based on several banchmarks outperforming the previous methods by a large margin however several experimental results have to be provided."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1) Using flow to achieve cross-scale transfer of matching relationships is an efficient solution.\n2) The ability to scale to diverse downstream tasks makes this approach attractive."
                },
                "weaknesses": {
                    "value": "1. The problem statement of  \"robust for sparse and dense matching\":\n\n   What are the main differences between the RSDM and the methods only fit for sparse or dense matching task? The RSDM seems designed based on original dense metching pipelines such as GMFlow with uncertainty estimation(from DKM) for sparsifiy the dense matching result. Can this setting be used in other dense matching works to make it suitable for sparse matching tasks?\n\n2. The effectiveness of multi-scale design:\n\n   The method used the FPN and  generate simlarity matrix in three scales. However, in the following three GRU Refinement Blocks only one  matrix seemes to be used. How about the matrixes in other two scales. Besides, further ablations on the multi-scale design should be provided.\n\n3. The design of dataset:\n\n   The proposed dataset seems like a subset of TartanAir dataset with a improved optical flow rendering method. What is the main problem solved by building this data set? What are the advantages over previous datasets besides better optical flow supervision? More experimental results based on this dataset need to be given.\n\n4. Several results in ablation study is not clear:\n\n   The data in the experimental table cannot clearly reflect the effectiveness of each module. For example, Table 1, what is the setting of RSDM? Is it the last row?"
                },
                "questions": {
                    "value": "See the Weakness part"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2298/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698812799574,
            "cdate": 1698812799574,
            "tmdate": 1699636162283,
            "mdate": 1699636162283,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JA4Pl6W1JF",
                "forum": "mjzwioGLux",
                "replyto": "2QbXiIAQRs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2298/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2298/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Correspondence to Reviewer1"
                    },
                    "comment": {
                        "value": "Thanks for pointing out the problems of our work. Here are our explanations.\n## Model architecture\nAs mentioned in the introduction, the model design is not our primary contribution in this work. We think any dense matching framework coupled with an uncertainty estimation module can serve as a generalist model. However, currently available models have their limitations. The iterative optimization mechanism provides an explicit and efficient approach for exploiting geometric similarity, which can be employed for geometry estimation. Emperiaclly, conducting matching at a higher resolution can introduce additional improvement for downstream pose estimation as in DKM, PATS, etc. However, popular optical flow estimation works like RAFT, FlowFormer, and GMFlow end up with the refinement at a relatively low resolution(1/4 at most), which is the main reason we elaborately construct the model architecture to perform refinement at 1/2 resolution.\n\n## Advantage of our organized dataset:\nThanks for pointing out this question. The re-organized of the TartanAir dataset is an important exploration in our work. Notably, the magnitude of displacement varies substantially across different datasets and scenarios. We list the displacement distribution of different datasets as well as our organized data below which can also be found in Tab.5 in our paper. It's worth noticing that our generated optical flow dataset obtains a different distribution compared to the original TartanAir dataset.\n\n|Datasets|Task|s0-10|s10-40|s40+|\n|----|----|-----|-----|--------|\n|KITTI|Optical Flow|30.3|36.5|33.2|\n|HPatches|Geometry Estimation|0.9|4.5|94.6|\n|FlyingThings3D|Optical Flow|25.2|45.7|29.1|\n|TartanAir|Optical Flow|46.2|47.2|6.6|\n|Sintel|Optical Flow|69.0|21.3|9.7|\n|ScanNet|Geometry Estimation|0.0|0.6|99.4|\n|Megadepth|Geometry Estimation|1.1|10.9|88.0|\n|Ours|Optical Flow|0.9|9.2|89.9|\n\nWe re-organize the dataset by increasing the sampling interval to obtain a closer distribution of other real-world datasets. The computation of optical flow ground truth is illustrated in our appendix A.1. The effectiveness of our proposed dataset is obvious as shown in Tab.1 and Tab.2. We simplify Tab.2 as below to show the effectiveness of our organized TartanAir sampled(TS) dataset.\n\n| With TS dataset       | HPatches PCK-1 &uarr; | KITTI AEPE&darr;  | KITTI F1 &darr; | ETH3D AEPE &darr; | ETH3D PCK-1 &uarr; |\n| ------------- | --------------- | ---------- | -------- | ---------- | ----------- |\n| &#10060;   | 44.3            | 4.1        | 10.8     | **2.0**    | 55.9        |\n| &#10004; | **46.3**        | **3.5**    | **9.6**  | **2.0**    | **56.3**     |\n\nThe adoption of our organized TartanAir dataset efficiently improves the generalization performance across multiple datasets, demonstrating the advantages of our organized dataset.\n\n## Ablations on multi-scale design\nWe are sorry for the confusion caused by the absence of this experiment. We provide the following ablation studies by inferring at previous scales for a quick validation of our multiscale design. The results are shown below and scale 3 corresponds to the refinement of 1/2 resolution utilized in our final model while scale 1 indicates the refinement of 1/8 resolution:\n\n| Output Scale       | HPatches PCK-1 &uarr; | KITTI AEPE&darr;  | KITTI F1 &darr; | ETH3D AEPE &darr; | ETH3D PCK-1 &uarr; |\n| ------------- | --------------- | ---------- | -------- | ---------- | ----------- |\n| 1   | 40.4 | 4.9 | 15.1 | 11.3 | 40.4 |\n| 2 | 46.5 | 4.5 | 11.1 | 10.1 | 46.5 |\n| 3 | **47.3** | **4.4** | **10.9** | **9.9** | **47.3** |\n\nFurthermore, we also utilize the matching at the previous scale for pose estimation, and the performance is shown below:\n|Output Scale| ScanNet AUC@5 | YFCC@5 | TUM@5 |\n|-------|-------|-------|-------|\n|1| 22.9 |39.4|15.0|\n|2| 25.3 |47.0|16.0|\n|3| **26.0** |**48.3**|**16.3**|\n\nThe above-listed results across matching and pose estimation tasks validate the effectiveness of the multi-scale design and the necessity of applying refinement at a higher resolution. We will place this comparison in the supplementary materials and conduct more comprehensive ablation experiments in our revised paper.\n\n## Ablation Study Setting:\nWe apologize for the ambiguity caused by our experiment settings and paper writing. In Tab.1, we illustrate the effectiveness of the decoupled training strategy by learning matching and uncertainty in a two-stage manner. In our final experiment, we adopt this decoupled training strategy. At the matching stage, we first train the dense matching model on the mixture of datasets as shown in Tab.2 to improve the generalization performance, and the effectiveness is validated. In the second stage, we freeze the parameters of the matching model and train the uncertainty estimation model based on the warping error according to the matching model. At this stage, only Megadepth and ScanNet are utilized. The detailed training settings are mentioned in Sec.4.1."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2298/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700722415600,
                "cdate": 1700722415600,
                "tmdate": 1700722415600,
                "mdate": 1700722415600,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]