[
    {
        "title": "Eliciting Human Preferences with Language Models"
    },
    {
        "review": {
            "id": "PT3McypGDx",
            "forum": "tqiAfRT1Lq",
            "replyto": "tqiAfRT1Lq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2818/Reviewer_j3g4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2818/Reviewer_j3g4"
            ],
            "content": {
                "summary": {
                    "value": "This paper formalizes the task elicitation problem, under which existing learning paradigms are applicable. The authors also introduce GATE, a learning framework that uses language models to interact with users and elicit their preferences. The authors compare GATE to multiple other elicitation methods across three tasks and find that their proposed approach is comparable or sometimes better than baselines but at comparable or less mental demand for users."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper introduces a nice framing to think about task elicitation and proposes a simple, but potentially effective method leveraging language models.\n- I appreciated that the authors conducted a user study to evaluate users on multiple tasks, rather than simply using language models as a proxy for human users, and considered a number of relevant real-world metrics (e.g., mental load)."
                },
                "weaknesses": {
                    "value": "- While the paper introduces three different domains, two of the three baselines were not available for two of the three tasks. Since GATE shows promising results for content recommendations, it is hard to assess the validity and generalizability of the results without similar comparisons to baseline elicitation approaches for the other two tasks.\n- It is unclear the extent to which the results found in this paper hinge on the choice of GPT-4 as both the LM that is used to elicit user preferences and the model that is used to predict user preferences. For the latter, prior work tends to train a reward model on the human data, rather than use the collected data as prompt input.\n- It seems like elicitation using generative open-ended questions is the best of the three generative variants studied in this work (according to Figure 2), however, it also seems to be the most mentally demanding for the users (according to Figure 3) and seemed to be comparable to baselines. It would be nice to see a proposed modification to that approach that would maintain the *same* score in Figure 2 but would decrease the reported mental load, particularly given that the generative approaches that were tried in this work were all relatively simple (as stated by the authors themselves)."
                },
                "questions": {
                    "value": "Other clarification questions\n- How is the framework in Section 2 connected to Section 3? The two sections felt a bit disconnected.\n- Incorrect reference in Area under the p(correct)-time curve paragraph?\n- In Figure 2, what does the * signify?\n- What do 6/10 and 7/10 settings refer to?\n- Does the term \u201ctime limit\u201d refer to the 5-minute interaction period?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2818/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2818/Reviewer_j3g4",
                        "ICLR.cc/2024/Conference/Submission2818/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2818/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698527802197,
            "cdate": 1698527802197,
            "tmdate": 1700603383871,
            "mdate": 1700603383871,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "DtlLT4sYF4",
                "forum": "tqiAfRT1Lq",
                "replyto": "PT3McypGDx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2818/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2818/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Baselines**\n\nThanks for raising this point, as we could clarify better in the main text. The two primary baselines we consider are 1) No interaction (this is 0 on our graphs) and 2) Detailed prompts, where we have the participant write out their preferences. For the content preferences domain only, we also have access to a dataset of example news articles. We can use this to present two additional baselines: supervised learning and active learning. Unfortunately, in many domains, we do not have access to a large dataset of examples from the target domain; for example, there is no \u201cnatural distribution\u201d over moral dilemmas or invalid email addresses. Thus, our experiments attempt to capture the performance of GATE in both settings. \n\nIn fact we see that as an advantage of our method: lots of domains do not have large, pre-existing corpuses of data which allow for supervised learning and/or active learning. Our method opens the possibility of learning preferences in those domains without pre-collecting a labeled dataset.\n\n**Why not train a reward model?**\n\nWe agree that reward models are a useful way to model preferences. Unfortunately, reward models require a large amount of data; for example, [1] collected a dataset of over 64,000 examples. By contrast, in our setting we consider interactions with a human that last less than 5 minutes long, which would leave us with far too little data to train a reward model. Furthermore, another advantage of using language models is their ability to comprehend free-form text data, rather than needing to learn from examples. As our transcripts are mostly free-form text (particularly in the two generative questions cases), it is impossible to train a reward model with traditional supervised learning.\n\n**Mediating generative open-ended questions**\n\nBroadly speaking, there is a tradeoff between interaction time/effort and the degree to which an approach can elicit human preferences. As the reviewer has noted, open-ended questions tend to be on one end of the tradeoff, requiring slightly higher mental demand (although equivalent mental demand to 2 of the 3 baselines), but being the best performing out of the three. Yes-or-no questions, while worse than open-ended questions at eliciting preferences, still beats out all baseline approaches, while being much equivalent or less mentally demanding to all three baselines. We agree that it would be great if there were some approach that could push the Pareto frontier, which we leave to future work.\n\n**How is the framework in Section 2 connected to Section 3?**\n\nIn short, the framework of Section 2 motivates a gap in the literature which we fill in Section 3. \n\nSection 2 describes how existing learning paradigms can be described as task elicitation methods along two axes. First, methods can elicit information passively (as in supervised learning) or actively (as in active learning). Next, they can elicit information with examples (again as in traditional supervised learning) or by rich free-form inputs (such as prompting). However, no present method actively elicits free-form inputs. Section 3 describes our proposal of GATE, a framework for actively eliciting free-form task specifications, and we describe how we operationalize this framework for investigation in our paper. Section 4 then describes the concrete experiments we do given this operationalization.\n\n**In Figure 2, what does the * signify?**\n\nThe asterisk signifies statistical significance at the 0.05 level. We have added this information to the caption in our newest revision.\n\n**What do 6/10 and 7/10 settings refer to?**\n\nGreat catch \u2013 There were actually only 9 settings and GATE improves in 7 of them. Specifically, we examined the following 9 (domain, elicitation method) pairs from Figure 2 and counted in how many settings that GATE improves over user-written prompts, ignoring significance:\n(Content domain, generative open-ended questions): Yes\n(Content domain, generative yes-or-no questions): Yes\n(Content domain, generative active learning): No\n(Moral domain, generative open-ended questions): No\n(Moral domain, generative yes-or-no questions): Yes\n(Moral domain, generative active learning): Yes\n(Email domain, generative open-ended questions): Yes\n(Email domain, generative yes-or-no questions): Yes\n(Email domain, generative active learning): Yes\n\n6/10 referred to a metric we had in a previous version of the paper, apologies for the confusion. We have taken this out in our newest revision and fixed the denominator to 7/9.\n\n\n**Does the term \u201ctime limit\u201d refer to the 5-minute interaction period?**\n\nYes, we have edited this in our newest revision to clarify.\n\n\n[1] https://arxiv.org/pdf/2009.01325.pdf"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2818/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700160054797,
                "cdate": 1700160054797,
                "tmdate": 1700160054797,
                "mdate": 1700160054797,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MAsbUTInbd",
                "forum": "tqiAfRT1Lq",
                "replyto": "PT3McypGDx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2818/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2818/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer j3g4,\n\nThank you for your review and feedback. As the discussion period is coming to a close, please let us know if our response has adequately addressed your concerns, or if you have any remaining questions and concerns. If not, we would appreciate if you could raise your score. We appreciate your hard work!"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2818/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700503961635,
                "cdate": 1700503961635,
                "tmdate": 1700503971784,
                "mdate": 1700503971784,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "B3YTH8gXZM",
                "forum": "tqiAfRT1Lq",
                "replyto": "MAsbUTInbd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2818/Reviewer_j3g4"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2818/Reviewer_j3g4"
                ],
                "content": {
                    "title": {
                        "value": "Follow-up question"
                    },
                    "comment": {
                        "value": "Thank you authors for clarifying the scope of the paper. Could the authors discuss \"the extent to which the results found in this paper hinge on the choice of GPT-4 as the LM that is used to elicit user preferences\"?"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2818/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700512578510,
                "cdate": 1700512578510,
                "tmdate": 1700512578510,
                "mdate": 1700512578510,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GACPtDDPJh",
                "forum": "tqiAfRT1Lq",
                "replyto": "To1dTRk5I2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2818/Reviewer_j3g4"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2818/Reviewer_j3g4"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks to the authors for their continued efforts to improve this submission. I have raised my score from a 3 to a 5 as a result of the author's clarifications. I still believe that this work has limitations that I hope the authors could address in the future in terms of more precisely defining the scope of when GATE should be used and a thorough evaluation in comparison to relevant baselines in both settings that the authors mentioned in their first response."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2818/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700603687962,
                "cdate": 1700603687962,
                "tmdate": 1700603687962,
                "mdate": 1700603687962,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "6WG9xgLG4K",
            "forum": "tqiAfRT1Lq",
            "replyto": "tqiAfRT1Lq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2818/Reviewer_d4UR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2818/Reviewer_d4UR"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes an approach for an interactive recommeder system on the basis of LLMs, here GPT4. The authors suggest three methods- \"Generative active learning\", \"Generating yes-or-no questions, \"Generating open-ended questions\" - for which the propose respective LLM prompts. The evaluation is conducted for three domains, namely content recommendation, moral reasoning, email verification by means of a user study including in total 388 participants. The system is compared to standard supervised learning trained on Microsoft News Dataset (only for content rec.), a pool-based active learner and user-made prompts for preferences. The results show that the three proposed methods are either on par or even outperforming the baseline approaches for the domains. In addition, the felt mental demand of the participants was mostly lower for the proposed methods, with open-ended questions being the most demanding among the three proposed approaches."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The research direction is fruitful for LLMs, as their capability to continuously, autonomously interact with end-users is crucial. To this end, the three proposed methods are sensible. It is therefore insighful and value adding to evaluate the performance of the respective prompts.\n\nThe paper clarity is quite high, showing detailled evaluation results, method descriptions and related works. \n\nThe empirical results are promising, showing that LLMs can guide the user towards the correct goal. In addition, the chosen baselines are quite well-chosen, making the results significant. The conducted user study is well-structured and a important part for the contribution of the paper. Here, the results are very insightful and can support future prompt design or fine-tunings. It is informative and very relevant to see that the different proposed prompts have different advantages in the respective domains and felt mental loads."
                },
                "weaknesses": {
                    "value": "It is unclear where other known preference elicitation approaches such as pairwise comparisons / choice-based preference elicitation / ... fit into the stated related work. They might be situated in example-based/interactive, but especially there are other studied interaction mechanisms in this field which might have overlaps to free-form. It should be part of the related work coverage.\n\nPart of the investigated methods (generative active learning and generating yes-or-no questions) might be too rigid, as a interests/preferences might not be black and white. I understand that the user can give any response to any of the methods, thereby giving more refined answers than yes/no, but handling arbitrary relative answers might become difficult to handle. The paper does not analyse the availability of such a problem / rule it out based on the results of the conducted user study. Here, ablations of possible user answers or prompt changes might be insightful\n\nAs mentioned in the reproducibility section, the authors used closed-source GPT4 for their experiments, which makes exact replication difficult."
                },
                "questions": {
                    "value": "Did you test implications of answer diversity on the success of your methods? Taking yes/no questions, a user might still answer with any fuzzy statement which might be quite ambiguous. It would be intersting to know if limiting the answers to potentially some selected \"in-between\" categories would help or not. Along this, did you analyse how often a user answered with such an ambiguous statement?\n\nWould it be possible to combine the proposed prompts to improve performance / reduce mental load? Did you experiment with such prompts? The open-ended version could, of course, do so by design - did you conduct analyses if this happens?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2818/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698834096742,
            "cdate": 1698834096742,
            "tmdate": 1699636225288,
            "mdate": 1699636225288,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "DCrELU0JT6",
                "forum": "tqiAfRT1Lq",
                "replyto": "6WG9xgLG4K",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2818/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2818/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their review!\n\n**Other preference elicitation formats**\n\nThis is a great point! This is indeed relevant literature which we will discuss in related work. We believe that GATE is complementary to pairwise comparisons / choice-based elicitation, and we can definitely do them within the GATE framework (i.e. prompt the LM to generate pairwise queries, choices to select among), which would be a good topic for future work. We don't mean to claim that this paper has exhaustively characterized the space of possible GATE policies.\n\n**Some answer types are less flexible**\n\nWe agree\u2014generative active learning and generative yes/no questions both assume a binary set of responses.  This might be limiting in real-world settings where the true answer might be \u201cit depends,\u201d or something more subtle. Interestingly, however, we do see some evidence that participants use the open-endedness of the chat interface to provide more details in these settings, rather than always replying with a single \u201cyes\u201d or \u201cno.\u201d And in general we believe that the advantage of our work is that it opens up the possibility for open-ended dialogue and answers that can more fully capture the space of nebulous human preferences, as we explore in the open-ended response settings we study.\n\n**Choice of models**\n\nWe thank the reviewer for this note. While we consider the GATE framework in our paper to be the main contribution of the work, we agree that closed-source models are limited. We hope to revisit these experiments with open-source models in future work, especially as more able models are released.\n\n**Answer diversity vs. success of GATE**\n\nThis is a great question! We did a preliminary investigation of whether we could correlating the **% of answers that aren\u2019t \u201cyes\u201d or \u201cno\u201d** in a transcript (for the \u201cyes-or-no questions\u201d elicitation setting) vs. the **delta p(correct)** after the transcript. Unfortunately, we could not find a strong correlation in our preliminary investigation (p-values $0.4$, $0.5$, $0.9$ respectively for the email, moral, and content domains). Note that writing an explanation takes additional time, so transcripts with more explanations tend to also have less turns overall. This preliminary result suggests that directly answering the questions asked by GATE may be more useful than whatever explanation a user may decide to provide. However, more fine-grained analyses may be necessary to break down the nature of the additional explanation / fuzzy answer, and the direct contribution of that answer to the accuracy. \n\n**Combine proposed prompts to improve performance & reduce mental load**\n\nThis is a good question. We believe that combining question types would be an interesting direction for future work, and could be better able to navigate tradeoffs between performance vs. mental load. We will add this discussion to future versions of our paper. We also found that the open-ended case does indeed sometimes ask yes-or-no questions."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2818/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700159959695,
                "cdate": 1700159959695,
                "tmdate": 1700159998342,
                "mdate": 1700159998342,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Fcne7FYqjZ",
                "forum": "tqiAfRT1Lq",
                "replyto": "sIa6tOkpOR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2818/Reviewer_d4UR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2818/Reviewer_d4UR"
                ],
                "content": {
                    "title": {
                        "value": "Thank your for your clarifications!"
                    },
                    "comment": {
                        "value": "Thanks for your answers! Yes, I think it would be important to add the mentioned works to the related work section, as they can be seen as alternative or extension to active learning in your problem setting.\n\nI believe your conducted evaluation nicely analyses/discusses the relative merits of the selected approaches. I was additinally wondering how to interpret the results \"absolutely\" - would a user with reached AUC results (for your approaches) be already using the system or rather search residing to manual search?"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2818/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700550537111,
                "cdate": 1700550537111,
                "tmdate": 1700550537111,
                "mdate": 1700550537111,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9i4IxzA1qh",
            "forum": "tqiAfRT1Lq",
            "replyto": "tqiAfRT1Lq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2818/Reviewer_Nhj6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2818/Reviewer_Nhj6"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses the issue of training LLMs to perform complex task such as personalized website recommendations via interaction with the users in an active learning mode."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "+ comprehensive and well written paper\n+ introduction of a novel method GATE for generative open-ended questions and model improvement with active learning \n+ ethical considerations and limitations are well thought\n+ code availability"
                },
                "weaknesses": {
                    "value": "- the testing is well-thought but quite limited. Such models require an extensive testing to ensure they are not overfitting, especially when for systems like this one which may eventually foster polarization as an effect of extreme self-centred recommendations.\n- the concept of morality is underdefined. What is the notion of morality employed here? There is quite some literature on the moral foundations theory and their detection from text which should be used as a benchmark for the model"
                },
                "questions": {
                    "value": "- the testing is well-thought but quite limited. Such models require an extensive testing to ensure they are not overfitting, especially when for systems like this one which may eventually foster polarization as an effect of extreme self-centred recommendations.\n- the concept of morality is underdefined. What is the notion of morality employed here? There is quite some literature on the moral foundations theory and their detection from text which should be used as a benchmark for the model"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2818/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698840953243,
            "cdate": 1698840953243,
            "tmdate": 1699636225225,
            "mdate": 1699636225225,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "rlPn5rw3p7",
                "forum": "tqiAfRT1Lq",
                "replyto": "9i4IxzA1qh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2818/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2818/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their review!\n\n**Overfitting and polarization**\n\nWe agree it is crucial to prevent overfitting to people's preferences. Our work makes efforts to guard against two potential sources of overfitting. First, we guard against statistical overfitting of our classifiers by ensuring that models are always evaluated on how well they can predict preferences on held-out data from another distribution. The strong performance of our models in this setting indicates they are not overfitting to the training data. Second, we check that the model does not cause the humans to \u201coverfit\u201d by strengthening or modifying their own preferences (e.g. via echo chamber effects). Notably, Figure 3, right, demonstrates that people's preferences do not change after using GATE. That said, we agree that longer-term use of personalized recommender systems warrants caution and further study, and have included discussion of this in our ethical considerations section.\n\n**Morality**\n\nWe completely agree that there is no single objective framework for moral reasoning. The point of these experiments in our paper was to see whether GATE could enable a language model to elicit information about an individual\u2019s subjective, personal moral preferences. Interestingly, we do find that many of the questions asked by the language model align with the axes explored by moral foundations theory (e.g. exploring the tension between care and fairness), and have added discussion and citations to that effect in the newest revision."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2818/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700159909386,
                "cdate": 1700159909386,
                "tmdate": 1700159909386,
                "mdate": 1700159909386,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "BmNLe1sAyC",
            "forum": "tqiAfRT1Lq",
            "replyto": "tqiAfRT1Lq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2818/Reviewer_djQq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2818/Reviewer_djQq"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose using LLMs to elicit or derive from the user what their preferences are based on a new method called GATE. Here the LLM asks the user either yes or no, or open ended questions to find out what their preferences are for recommendations. The research experiment shows improvement in novel recommendation considerations."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "I am afraid I cant see any strength."
                },
                "weaknesses": {
                    "value": "The authors of this research project have not considered the ethical aspects of having LLMs ( they already have their own bias and hallucination issues) probe humans to spill their preferences. Interacting with a chatbot an/or  AI systems have shown to be psychologically endearing to humans and yet the researchers seem to be intent on making recommendations more accurate than the population's psychological impact. \nNo in depth assessment of conversation based interactions of this nature and their strength of cognitive processes in gathering accruate recommendations outside of this field was provided."
                },
                "questions": {
                    "value": "Please provide any ethical assessments done during or prior to IRB approval of how such a system can impact humans over the long term use of a GATE based recommendation system? Please provide more depth to this \" A fundamental challenge across many fields is how to obtain information about people\u2019s nebulous\nthoughts, preferences, and goals. In psychology and cognitive science, protocol analysis describes\nmethods for how to obtaining and analyze verbal reports from subjects about cognitive processes\nincluding via think-aloud protocols (Ericsson & Simon, 1980; Ericsson, 2017)\""
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2818/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2818/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2818/Reviewer_djQq"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2818/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699339150450,
            "cdate": 1699339150450,
            "tmdate": 1699636225136,
            "mdate": 1699636225136,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CWAQRJqDCK",
                "forum": "tqiAfRT1Lq",
                "replyto": "BmNLe1sAyC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2818/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2818/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their review!\n\n**Long-term use of GATE**\n\nAs the reviewer noted, our research received IRB approval for the experiments we carried out in our paper. These experiments involved short-term interactions with GATE; specifically, participants interacted with the model for five minutes. However, we did consider whether interacting with a language model would have an impact on user preferences (Figure 3, right). There, we found that participants did not have significantly different preferences before vs after interacting with the model; that is, using GATE did not materially alter the user\u2019s preferences. We agree that the long-term use of language model assistants is worth caution and further study. In our ethical considerations section we will expand on our discussion of \u201cthin slicing\u201d and other harms to include discussion of potential attachments people may form with language models and how to avoid dependence and over-sharing. We will also caution against widespread long-term use of LM companions prior to these risks being better understood.\n\n**Discussion of work in other fields**\n\nWe are happy to elaborate on these sentences. Many fields are concerned with understanding people\u2019s cognitive processes, inner states, or personal preferences. For example, in cognitive psychology one might attempt to understand what strategies people use when attempting to solve math problems, and in user experience research one might attempt to understand how users understand an interface. However, these inner experiences are often hard to verbalize because people are not always skilled at introspecting and discussing what factors guide their preferences and actions. Thus, many fields study how to better elicit and measure these inner cognitive states, including by interviewing and asking questions of people, as we study in our work"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2818/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700159894470,
                "cdate": 1700159894470,
                "tmdate": 1700159894470,
                "mdate": 1700159894470,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ha6A3VyOfM",
                "forum": "tqiAfRT1Lq",
                "replyto": "BmNLe1sAyC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2818/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2818/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer djQq,\n\nThank you for your review and feedback. As the discussion period is coming to a close, please let us know if our response has adequately addressed your concerns, or if you have any remaining questions and concerns. If not, we would appreciate if you could raise your score. We appreciate your hard work!"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2818/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700504060195,
                "cdate": 1700504060195,
                "tmdate": 1700504060195,
                "mdate": 1700504060195,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IXX3nUmmzJ",
                "forum": "tqiAfRT1Lq",
                "replyto": "ha6A3VyOfM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2818/Reviewer_djQq"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2818/Reviewer_djQq"
                ],
                "content": {
                    "title": {
                        "value": "Followup"
                    },
                    "comment": {
                        "value": "Thanks for responding to the review. Can you please elaborate or share more references that you have found in your research about conversation based interactions in any field of study and their validity in extracting accurate preference knowledge other than what is listed in the paper? It appears to me that your entire premise of the GATE stands on that assumption that such interactions are worthwhile. From my awareness, the more you ask, the more you probe, the less useful the information is. Based on cognitive and market studies. But you may have found evidence to the contrary which I don't see listed in your references - do send us one or two such studies on which your foundation is built on."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2818/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700518633023,
                "cdate": 1700518633023,
                "tmdate": 1700518633023,
                "mdate": 1700518633023,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]