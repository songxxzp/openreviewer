[
    {
        "title": "Rethinking the Noise Schedule of Diffusion-Based Generative Models"
    },
    {
        "review": {
            "id": "lKJDKs87js",
            "forum": "ylHLVq0psd",
            "replyto": "ylHLVq0psd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5772/Reviewer_nhAz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5772/Reviewer_nhAz"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors investigate the training/sampling noise schedule through the lens of power spectrum and introduce the weighted signal-noise ratio (WSNR). The authors show that adjusting the noise schedule according to WSNR is able to improve the performance of high-resolution image generation and ODE-based sampling."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1) Although the importance of noise schedule has been studied in previous papers, most of previous methods adjusting the schedule intuitively. The authors proposed a numerical metric and validated the effectiveness of the proposed metric.\n2) The motivation of this paper is clear and the organization and presentation of this paper is good.\n3) The experimental results validated the advantage of adjusting noise schedule for high-resolution image generation and ODE-based sampling."
                },
                "weaknesses": {
                    "value": "1) The authors proposed the WSNR metric and adjusting the noise schedule of high-resolution image generation to align the WSNR schedule with low-resolution image, although the authors show that such adjustment is beneficial for high-resolution image generation, a more important question is whether the proposed metric could shed light on optimal schedule for image generation. Since the schedule for 64\\times 64 image generation is also intuitively setted, why should we align the schedule of high-resolution image generation to 64 \\times 64?\n2) The idea of data-driven ODE noise schedule is interesting, and the authors show that the proposed method is able to improve the sampling quality. Is the newly proposed sampling strategy highly related to the WSNR metric, can we adjust the sampling schedule based on other metrics such as PSNR? The improvement is mainly due to the data-driven framework or the newly proposed metric."
                },
                "questions": {
                    "value": "Please refer to the weakness part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5772/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698657965141,
            "cdate": 1698657965141,
            "tmdate": 1699636606581,
            "mdate": 1699636606581,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lzGiT7xuxz",
                "forum": "ylHLVq0psd",
                "replyto": "lKJDKs87js",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the positive and comprehensive feedback. We are encouraged that the reviewer found our WSNR noise schedule is beyond adjusting noise schedule intuitively. In the following, we provide a response to the questions in the review. \n\n\nQ1: Why should we align the schedule of high-resolution image generation to 64 x 64? Whether the proposed metric could shed light on optimal schedule for image generation?\n\nA1:  We appreciate the reviewer\u2019s query regarding our anchor noise schedule choice. \n\nWe chose the 64x64 noise schedule as our anchor training noise schedule because the diffusion model is well-trained at this resolution. However, the choice of resolution for alignment is flexible.\n\nOur WSNR metric lays the foundation for finding the optimal schedule for image generation, reducing our exploration to just one set of hyperparameters. This is because the WSNR-Equivalent Training Noise Schedule consistently achieves superior results with a single set of hyperparameters. In contrast, other noise schedules fail to consistently achieve desired performance across multiple resolutions in both RGB and latent spaces under a single hyperparameter set.\n\nFurthermore, we believe that our proposed data-driven sampling schedule can aid in exploring the design of training noise schedules. Since probabilistic generative models are essentially fitting data distributions, we hold that the optimal noise schedule should be data-driven. We leave this exploration to our future work.\n\nQ2: Is the newly proposed sampling strategy highly related to the WSNR metric? Can we adjust the sampling schedule based on other metrics such as PSNR? \n \nA2: We are very grateful to the reviewer for raising such insightful questions, which have sparked our thinking about how to use WSNR to uniformly design both training and sampling noise schedules.\n\nOur proposed WSNR metric can be used to uniformly represent noise levels across different scales, meaning that a data-driven sampling schedule can be designed and expressed through WSNR. We found that for the FFHQ-64 and FFHQ-256 datasets, the ODE integration intervals should be [0.002, 98.96] and [0.008, 394.62], respectively. When represented in terms of WSNR, these intervals become [117166875, 0.0478] and [117166875, 0.0481], showing that FFHQ 64 and 256 are similar in terms of the WSNR metric.\n\nWe have not explored replacing WSNR with PSNR, because WSNR is a promising metric. We will leave the exploration regarding PSNR for future work.\n\n------------------------------------------------------------------------\n\nWe would greatly appreciate it if you could confirm whether the revisions made align with your expectations and satisfactorily resolve the issues previously highlighted. \n\nYour further guidance and feedback will be important to us and we are committed to making any additional improvements as needed.\n\nThank you very much for your time and consideration. We look forward to your response."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700579203951,
                "cdate": 1700579203951,
                "tmdate": 1700579203951,
                "mdate": 1700579203951,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "YAFpcwgQRg",
            "forum": "ylHLVq0psd",
            "replyto": "ylHLVq0psd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5772/Reviewer_pugY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5772/Reviewer_pugY"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigates noise scheduling strategies within the scope of denoising diffusion generative models. They investigate the training noise schedule through the lens of power spectrum and introduce a novel metric, weighted signal-noise-ratio, to uniformly represent the noise level in both RGB and latent spaces, enhancing the performance of high-resolution models in these spaces with WSNR-Equivalent training noise schedules. \nThey explore the correlation between the number of evaluation points and the generation quality to optimize the acceleration of the ODE solver in the diffusion model. Based on practical considerations of evaluation point effects, we propose an adaptive scheme to choose numerical methods within computational constraints, balancing efficacy and efficiency."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This paper views the noise scheduling problem from the perspective of power spectra of various frequency components and discover that the average power spectra of isotropic Gaussian noise are consistent across all components.\n\n2. The proposed metric, WSNR, quantifies the noise level of the training data in both the RGB space and latent space.\n\n3. It empirically explores the relationship between the number of evaluation points and the generation quality."
                },
                "weaknesses": {
                    "value": "1. The noise scheduling is discussed in previous works from different perspectives. The concurrent work [1] also discusses the noise schedule from the spectra view. The authors are encouraged to discuss the differences.\n[1] Relay diffusion: Unifying diffusion process across resolutions for image synthesis\n\n2. This paper aims to solve the terrible performance of existing noise scheduling in high resolutions. But the experiments are all conducted on small resolutions, with the highest resolutions being 256x256.  Experiments with a higher resolution are highly recommended."
                },
                "questions": {
                    "value": "Please refer to the weaknesses and questions."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5772/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699065327998,
            "cdate": 1699065327998,
            "tmdate": 1699636606450,
            "mdate": 1699636606450,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KDjmt3JxSN",
                "forum": "ylHLVq0psd",
                "replyto": "YAFpcwgQRg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Q1: The concurrent work [1] also discusses the noise schedule from the spectra view. The authors are encouraged to discuss the differences. \n\nA1:   Thank you for bringing concurrent work [1] to our attention. We acknowledge that [1] also explores the noise level from a spectral perspective in RGB space. \n\n**However, our work and [1] have several distinct differences**:\n1. **Different Approaches**: Our work is dedicated to designing a robust training noise schedule applicable across different resolutions and latent spaces. [1] mainly focuses on the relay connection within their proposed RDM, enabling a cascading sampling process from 64x64 to 256x256 in a single pass. It seems that they do not contribute to the training noise schedule. If my understanding of [1] is incorrect, please kindly correct me.\n2. **Different Analysis Metrics**: We propose WSNR as a consistent quantization metric, ensuring consistent quantization results at the same noise level across different resolutions. In contrast, [1] uses the SNR quantization metric, which is not consistent in different resolutions.\n3. **Different Analytical Perspectives**: We analyze the average power of images and Gaussian noise from a power spectrum perspective, highlighting that the average power of Gaussian noise is uniform across all frequency components. This conclusion is not stated in their work.\n\nAdditionally, it's worth noting that we have conducted theoretical analysis on the sampling noise schedule and proposed improvements.\nMoreover, [1] is also a submission to ICRL 2024. We believe these are two independent pieces of research work, and this should not be considered a weakness or even a reason for rejection.\n\n\n\nQ2: The noise schedule is discussed in previous works from different perspectives. \n\nA2:  We appreciate the reviewer's comment regarding the discussion of noise scheduling in prior works. \nSince our work is titled \"Rethinking the Noise Schedule of Diffusion-Based Generative Models\", we have acknowledged that some previous works have explored noise schedule design. However, our paper has **unique contributions**:\n- We propose a novel WSNR metric to consistently quantify the noise level across multiple resolutions in **RGB space and latent space** for the forward process of diffusion models.\n- We significantly improve the performance of diffusion models, via our novel WSNR-Equivalent training noise scheduler. Specifically, our method decreases the FID score by 3.6 on FFHQ-256x256 dataset, and achieves the same FID scores on ImageNet-256 and 512 for UViT-M (#Params: 287M)  as those of UViT-L (#Params: 287M).  \n- We analyze that the **ODE sampling noise schedule** should be data-driven. Consequently, we propose estimating the integration interval based on the average data distance.\n- We explore the relationship between the number of evaluation points and generation quality. Our findings lead us to develop a **NFE-guided sampling noise schedule**.\n- Our sampling schedule refines the FID of pre-trained CIFAR-10 and FFHQ-64 models from 1.92 and 2.45 to 1.89 and 2.25, respectively, utilizing 35 network evaluations per image.\n\n\nAs the reviewer did not provide further explanation and references about the \"previous works\" and \"different perspectives\", we will discuss the recent representative research works [2,3,4,5,6], which proposed handcrafted training noise schedules to improve the performance of diffusion models. However, the proposed schedules are based on the SNR metric, which is neither consistent in different resolutions, nor consistent in latent space. \n\nThat means their schedules **fail to** achieve desired performance consistently on various across multiple resolutions in RGB space and latent space under a single set of hyperparameters. In contrast, **ours can achieve superior results** consistently with just one set of hyperparameters.\n\nBesides, our analysis and improvement on ODE sampling noise schedule, an aspect not addressed by the other methods. This unique focus not only demonstrates our method's innovative approach but also highlights its ability to fill a critical gap in the current research landscape. By delving into areas previously unexplored, our work contributes significantly more to the advancement of the field, offering novel insights and practical improvements that set a new standard for future research in this area."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700551976488,
                "cdate": 1700551976488,
                "tmdate": 1700551976488,
                "mdate": 1700551976488,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ceB2Z54vjk",
                "forum": "ylHLVq0psd",
                "replyto": "YAFpcwgQRg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Q3: The highest resolution is 256x256. Experiments with a higher resolution are highly recommended.\n\n\nA3: We thank the reviewer for highlighting the importance of conducting experiments at higher resolutions, especially given our paper's focus on improving noise scheduling in high-resolution contexts. \n\nDue to the limited time for rebuttal and our computational resources, we trained a network on ImageNet 512x512 to demonstrate the effectiveness of our training schedule. Specifically, we use UViT-M as network architecture, similar to the experiment in our draft on ImageNet 256x256, keeping the hyperparameters unchanged. The results, as shown in the table below, indicate that UViT-M, utilizing our WSNR-Equivalent noise schedule, achieves a superior FID score compared to the UViT-L model, which has more than double the parameter count of UViT-M.\n\n| Network | #Param | FID |\n| --- | --- | --- |\n| UViT-M, p(WSNR) | **131M** | **4.55** |\n| UViT-L, p($\\sigma$) | 287M | 4.67 |\n\n\n\nWe understand the importance of ensuring that our paper meets the high standards of ICLR and would greatly appreciate it if you could confirm whether the revisions made align with your expectations and satisfactorily resolve the issues previously highlighted.\n\nYour further guidance and feedback will be important to us and we are committed to making any additional improvements as needed.\n\nThank you very much for your time and consideration. We look forward to your response.\n\n\n\n[1] Teng, Jiayan, et al. \"Relay diffusion: Unifying diffusion process across resolutions for image synthesis.\" arXiv preprint arXiv:2309.03350 (2023).\n\n[2] Nichol, Alexander Quinn, and Prafulla Dhariwal. \"Improved denoising diffusion probabilistic models.\" International Conference on Machine Learning. PMLR, 2021.\n\n[3] Kingma, Diederik, et al. \"Variational diffusion models.\" Advances in neural information processing systems 34 (2021): 21696-21707.\n\n[4] Choi, Jooyoung, et al. \"Perception prioritized training of diffusion models.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.\n\n[5] Chen, Ting. \"On the importance of noise scheduling for diffusion models.\" arXiv preprint arXiv:2301.10972 (2023).\n\n[6] Hang, Tiankai, et al. \"Efficient diffusion training via min-snr weighting strategy.\" arXiv preprint arXiv:2303.09556 (2023)."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700552090001,
                "cdate": 1700552090001,
                "tmdate": 1700552147734,
                "mdate": 1700552147734,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zS2gKRJMF8",
                "forum": "ylHLVq0psd",
                "replyto": "YAFpcwgQRg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer pugY,\n\nWe appreciate the diligent efforts put into reviewing our work.\n\nWe have compared our novel training and sampling noise schedule with both previous and concurrent works. Besides, we conducted experiments on a higher resolution.  Furthermore, we improved the writing quality in our revised manuscript.\n\nWe would greatly appreciate it if you could confirm whether the revisions made align with your expectations and satisfactorily resolve the issues previously highlighted.\n\nWe sincerely look forward to your response and would happily address any other questions.\n\nThank you,\n\nThe authors"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700662667317,
                "cdate": 1700662667317,
                "tmdate": 1700662667317,
                "mdate": 1700662667317,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lkLVANZvRO",
                "forum": "ylHLVq0psd",
                "replyto": "YAFpcwgQRg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer pugY,\n\nJust a reminder, there are only 4 hours left for the rebuttal.\n\nAfter this time, we will not be able to participate in the discussion any further.\n\nWe are waiting for your response. We would happily address any other questions.\n\nBest Regards,\n\nThe Authors"
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700727061909,
                "cdate": 1700727061909,
                "tmdate": 1700727061909,
                "mdate": 1700727061909,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ZnagaGKL5R",
                "forum": "ylHLVq0psd",
                "replyto": "YAFpcwgQRg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer pugY,\n\nJust a reminder, there are only **3 hours** left for the rebuttal.\n\nAfter this time, we will not be able to participate in the discussion any further.\n\nWe are waiting for your response. We would happily address any other questions.\n\nBest Regards,\n\nThe Authors"
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700730870365,
                "cdate": 1700730870365,
                "tmdate": 1700730870365,
                "mdate": 1700730870365,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ISJDSjU4rU",
                "forum": "ylHLVq0psd",
                "replyto": "YAFpcwgQRg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nJust a reminder, there are only **2 hours** left for the rebuttal.\n\nAfter this time, we will not be able to participate in the discussion any further.\n\nWe are waiting for your response. We would happily address any other questions.\n\nBest Regards,\n\nThe Authors"
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700733989413,
                "cdate": 1700733989413,
                "tmdate": 1700733989413,
                "mdate": 1700733989413,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "JsGrGT25zX",
            "forum": "ylHLVq0psd",
            "replyto": "ylHLVq0psd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5772/Reviewer_9Ms4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5772/Reviewer_9Ms4"
            ],
            "content": {
                "summary": {
                    "value": "This paper provides a theoretical and empirical analysis of the noise schedule strategy in denoising diffusion generative models. The authors investigate training noise schedules from the perspective of power spectra and introduce a new metric called Weighted Signal-to-Noise Ratio (WSNR) to uniformly represent noise levels in both RGB space and latent space, improving the performance of high-resolution models. They also explore the inverse sampling process using the framework of Ordinary Differential Equations (ODEs), revealing the concept of optimal denoisers and providing insights into data-driven sampling noise schedules. Additionally, they explore the correlation between the number of evaluation points and the quality of generated samples, and propose optimizations for accelerating ODE solvers. The proposed method improves the FID of CIFAR-10 and FFHQ-64 models without requiring additional training."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The authors propose a novel metric, weighted signal-noise-ratio (WSNR), to quantify the noise level in both RGB and latent spaces.\n  - WSNR is an intuitive metric. Figure 2 helps to understand the motivation.\n- They explore the correlation between the number of evaluation points and the generation quality, and propose a strategy to dynamically select numerical methods for better generation quality.\n- They achieve improved performance in high-resolution RGB and latent spaces without additional training.\n- They contribute to the field by quantifying the noise level of the forward process of the diffusion model and extending it to the latent space.\n- They present empirical results on CIFAR-10, FFHQ-64, ImageNet-64, and FFHQ-256 datasets, demonstrating the effectiveness of the proposed methods.\n- They discuss the probability of the synthesized data and the importance of a broad variety in generated samples.\n- They introduce a data-driven sampling noise schedule to ensure the diversity of generated data.\n- They identify the trade-off between the quality of generated data and the number of neural function evaluations (NFE) and proposes an appropriate value for the integration range."
                },
                "weaknesses": {
                    "value": "- The motivation or justification for rethinking the noise schedule of diffusion-based generative models is not clearly explained in the introduction.\n  - I could not understand how Figure 1 is related to the main motivation of the paper. Figure 2 was more intuitive.\n- From Eq. (1), it seems to implicitly assume the variance exploding (VE) case, but it is not clear what happens in the variance preserving (VP) case.\n- Overall, writing should be improved. In the current form, motivation is not clearly explained in the introduction, and it is not until Figure 2 in Section 4 that the motivation is understood."
                },
                "questions": {
                    "value": "As I described in the weakness section, Eq. (1) seems to implicitly assume the VE case, but how abound the VP case?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5772/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699077257634,
            "cdate": 1699077257634,
            "tmdate": 1699636606340,
            "mdate": 1699636606340,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SdeW3cFwWX",
                "forum": "ylHLVq0psd",
                "replyto": "JsGrGT25zX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are grateful to the reviewer for the comprehensive feedback. We are encouraged by the recognition that our WSNR metric is both novel and well-motivated, and that the proposed sampling schedule is efficient and effective. Below, we respond to the questions raised in the review.\n\n\nQ1: The motivation or justification for rethinking the noise schedule of diffusion-based generative models is not clearly explained in the introduction. How Figure 1 is related to the main motivation of the paper?\n\nA1: We appreciate the reviewer\u2019s feedback regarding the clarity of our paper\u2019s motivation and the role of Fig 1. We acknowledge an error in our initial submission regarding the referencing of figures. This analysis is actually presented in Fig 2. We apologize for any confusion this may have caused and have corrected this reference in our revised manuscript. Fig 1 is intended to illustrate the training noise schedule and sampling noise schedule.\n\nWe have revised the introduction section to explain the motivation clearly.\nHere, we summarize our motivation briefly:\n\n1. As shown in Fig. 2, significant variation in noise levels across images of different resolutions when exposed to Gaussian noise with identical standard deviations, leads to a discrepancy in the noise levels focused on by manually designed training noise schedules in different RGB space resolutions and latent space. Motivated by this observation, we propose a novel metric WSNR to quantify the noise level consistently across multiple resolutions in RGB space and latent space. We further propose a novel training noise schedule based on the WSNR metric.\n\n2. As illustrated in Fig. 4 and elaborately explained in Sec. 5, the diversity of the generated data is jointly influenced by the initial Gaussian distribution at the start point and the Euclidean distance from the data points in the dataset. Therefore, we propose a data-driven sampling noise schedule to determine the integration interval of the diffusion ODE.\n\n3. As demonstrated in Tab. 4, an increased number of evaluation points (the unique time steps at which model makes predictions) leads to better results when the step size is relatively large. Conversely, with smaller step sizes, the advantage of adding more evaluation points becomes less significant. Drawing on these findings, we propose a strategy for dynamically selecting numerical methods according to computational constraints, aiming to optimize generation quality.\n\n\n\nQ2: From Eq. (1), it seems to implicitly assume the variance exploding (VE) case, but it is not clear what happens in the variance preserving (VP) case.\n\nA2: Our proposed methods are applicable to VP case. As shown in Tab.3, our data-driven sampling noise schedule works when it is applied to DPM-Solver, which is based on VP ODE.\n\nBesides, we conduct experiments on VP cases to evaluate our WSNR-Equivalent training noise schedule. The FID score on FFHQ dataset in the following table show that our method further improves performance on VP cases.\n\n| FFHQ | 64 | 128 | 256 |\n| --- | --- | --- | --- |\n| $p(\\text{WSNR})$ | 3.80 | 6.23 | 7.99 |\n| $p(\\sigma)$ | 3.80 | 7.41 | 11.78 |\n\n\nActually, the denoiser D_theta (x) in Eq. 1 can be used to explain VP, VE and EDM cases. \nAs shown in Eq. 7 in [1], we can write the $D_\\theta(x; \\sigma)$ in the following form:\n\n$$D_\\theta(x; \\sigma) = c_{\\text{skip}}(\\sigma) x + c_{\\text{out}}(\\sigma) F_\\theta(c_{\\text{in}}(\\sigma) x; c_{\\text{noise}}(\\sigma))$$\nFor VP, $c_{\\text{skip}}(\\sigma)=1,\u00a0c_{\\text{out}}(\\sigma)=-\\sigma,\u00a0c_{\\text{in}}(\\sigma)=\\frac{1}{\\sqrt{\\sigma^2 + 1}},\u00a0c_{\\text{noise}}(\\sigma)\u00a0=\u00a0(M-1)\\sigma^{-1}(\\sigma)$. \nThis implies that our Eq.1 is compatible with the VP case and our sampling noise schedule can be evaluated with  the pre-trained VP model.\n\n\nAs for the training process, we follow the training loss in [1], setting the training target as:\n\n$E_{\\sigma, y, n} \\left[ \\overbrace{\\lambda(\\sigma) c_{\\text{out}}(\\sigma)^2}^{\\text{effective weight}} \\left\\| \\overbrace{F_\\theta \\left( c_{\\text{in}}(\\sigma) \\cdot (y + n); c_{\\text{noise}}(\\sigma) \\right)}^{\\text{network output}} - \\overbrace{\\frac{1}{c_{\\text{out}}(\\sigma)} (y - c_{\\text{skip}}(\\sigma) \\cdot (y + n))}^{\\text{effective training target}} \\right\\|^2 \\right]$\n\nTherefore, we believe that our training process is compatible with interpreting the VP case.\n\n[1] Karras, Tero, et al. \"Elucidating the design space of diffusion-based generative models.\" Advances in Neural Information Processing Systems 35 (2022).\n\n\nWe understand the importance of ensuring that our paper meets the high standards of ICLR and would greatly appreciate it if you could confirm whether the revisions made align with your expectations and satisfactorily resolve the issues previously highlighted.\n\nYour further guidance and feedback will be important to us and we are committed to making any additional improvements as needed.\n\nThank you very much for your time and consideration. We look forward to your response."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700544370070,
                "cdate": 1700544370070,
                "tmdate": 1700573721976,
                "mdate": 1700573721976,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HxpBRtoHB4",
                "forum": "ylHLVq0psd",
                "replyto": "JsGrGT25zX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer 9Ms4,\n\nWe appreciate the diligent efforts put into reviewing our work.\n\nWe have tried to answer all your question about the Eq.1 and would greatly appreciate it if you could confirm whether the revisions made align with your expectations and satisfactorily resolve the issues previously highlighted.\n\nAs you recognize so many strengths of our work, we sincerely look forward to your response.\n\nWe would happily address any other questions.\n\nThank you, \n\nThe authors"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700657786307,
                "cdate": 1700657786307,
                "tmdate": 1700657786307,
                "mdate": 1700657786307,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YxGVDAfX07",
                "forum": "ylHLVq0psd",
                "replyto": "JsGrGT25zX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer 9Ms4,\n\nJust a reminder, there are only 4 hours left for the rebuttal. \n\nAfter this time, we will not be able to participate in the discussion any further. \n\nWe are waiting for your response. We would happily address any other questions.\n\nBest Regards,\n\nThe Authors"
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700727010936,
                "cdate": 1700727010936,
                "tmdate": 1700727010936,
                "mdate": 1700727010936,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ZkYdOK95vO",
                "forum": "ylHLVq0psd",
                "replyto": "JsGrGT25zX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer 9Ms4,\n\nJust a reminder, there are only **3 hours** left for the rebuttal.\n\nAfter this time, we will not be able to participate in the discussion any further.\n\nWe are waiting for your response. We would happily address any other questions.\n\nBest Regards,\n\nThe Authors"
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700730844570,
                "cdate": 1700730844570,
                "tmdate": 1700730844570,
                "mdate": 1700730844570,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "f9hS4F05W2",
                "forum": "ylHLVq0psd",
                "replyto": "JsGrGT25zX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nJust a reminder, there are only **2 hours** left for the rebuttal.\n\nAfter this time, we will not be able to participate in the discussion any further.\n\nWe are waiting for your response. We would happily address any other questions.\n\nBest Regards,\n\nThe Authors"
                    }
                },
                "number": 25,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700733954302,
                "cdate": 1700733954302,
                "tmdate": 1700733954302,
                "mdate": 1700733954302,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "JszdnqAlMu",
            "forum": "ylHLVq0psd",
            "replyto": "ylHLVq0psd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5772/Reviewer_jyko"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5772/Reviewer_jyko"
            ],
            "content": {
                "summary": {
                    "value": "This research study identifies substantial disparities  in noise levels across images of different resolutions, \nsignificantly affecting the performance of the diffusion model. The manuscript then investigates the training of \ndiffusion models using a weighted signal-to-noise-ratio (WSNR) metric. This metric does not depend on the image \nresolution. WSNR is shown to be a better metric to quantize the noise level in the forward diffusion process.\nThe manuscript provides the analysis of the diffusion model from the point of view of the ordinary differential equations\nprobability flows in Section 5"
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The manuscript propose a weighted signal-to-noise-ration (WSNR) metric for training diffusion models which does not depend on the image  resolution.\n- WSNR is shown to be a better metric to quantize the noise level in the forward diffusion process.\n- Experimental results show that WSNR represents a valid metric to illustrate noise levels in the latent space."
                },
                "weaknesses": {
                    "value": "-"
                },
                "questions": {
                    "value": "- How would the metric depend on the local properties of the image, such as the presence of flat regions or textures?\nFor example in Figure 2 the noise is evident in the background but it is masked in the region of the main object which is highly textured."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5772/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5772/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5772/Reviewer_jyko"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5772/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699105534535,
            "cdate": 1699105534535,
            "tmdate": 1699636606213,
            "mdate": 1699636606213,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "WUFRQDpbB4",
                "forum": "ylHLVq0psd",
                "replyto": "JszdnqAlMu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are thankful to the reviewer for their very positive and comprehensive feedback. We feel encouraged by their acknowledgment that our WSNR metric effectively quantifies the noise level, independent of image resolution, and is also applicable to latent space.\n\nQ1: How would the metric depend on the local properties of the image, such as the presence of flat regions or textures?\n\nA1: We are very grateful to the reviewer for raising such insightful questions, which is an important property for both neural networks and image processing. \n\nThe WSNR metric, designed based on power spectrum analysis, quantifies noise levels at the image level. The frequency characteristics of local areas influence the overall power spectrum, thereby affecting the WSNR. \n\nLocal properties are a common and crucial property for neural networks. We can further use Short-Time Fourier Transform (STFT) to analyze the power spectrum of local areas more directly and likewise use WSNR to represent the noise level in these areas. We plan to include this analysis in the final version of our work.\n\n\nThank you very much for your time, consideration and support."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700580646863,
                "cdate": 1700580646863,
                "tmdate": 1700580646863,
                "mdate": 1700580646863,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "eBvzfuHGxv",
            "forum": "ylHLVq0psd",
            "replyto": "ylHLVq0psd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5772/Reviewer_QVZ8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5772/Reviewer_QVZ8"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigates the training noise schedule of diffusion models from the perspective of the spectrum. It introduces the weighted signal-noise ratio (WSNR) to better represent the noise level of latent variables of diffusion models. This paper also proposes an adaptive sampling scheme that better balances efficacy and efficiency."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed WSNR can better measure the noise level of diffusion latent variables across various resolutions. Models trained with a WSNR-oriented schedule can generalize better to more resolutions.\n\n2. The proposed adaptive sampling strategy better balances the efficacy and efficiency of diffusion models. It improves the performance of diffusion models without additional training."
                },
                "weaknesses": {
                    "value": "1. The proposed WSNR-Equivalent training noise schedule and data-driven sampling noise schedule seem to be independent of each other\uff0c which weakns the focus of this paper.\n\n2. Experiments in Table 1 and Table 2 compare with only EDM training noise schedule. The authors are suggested to compare with more training noise schedules to further verify the effectiveness of training noise schedule."
                },
                "questions": {
                    "value": "See the weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5772/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699256644683,
            "cdate": 1699256644683,
            "tmdate": 1699636606092,
            "mdate": 1699636606092,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SsTj2T99xz",
                "forum": "ylHLVq0psd",
                "replyto": "eBvzfuHGxv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the positive and comprehensive feedback. We are encouraged that the reviewer found our WSNR metric represents noise level well and our adaptive sampling scheme balances efficacy and efficiency well. In the following, we provide a response to the questions in the review. \n\n\nQ1: The proposed WSNR-Equivalent training noise schedule and data-driven sampling noise schedule seem to be independent of each other, which weakens the focus of this paper.\n\nA1: We respectively disagree with this viewpoint.  \nFirstly, the training and sampling processes of diffusion models are strongly interrelated. Diffusion models are trained independently for each noise level. The inference stage can be seen as refining the generated images multiple times at various timesteps using the network. We believe that optimizing both the training and sampling stages simultaneously **highlights our contribution**.\n\nSecondly, exploring the training and sampling processes of diffusion models within a single work is **not a weakness**. In the **NIPS 2022 Outstanding Paper** [1], the authors **similarly improved the training and sampling processes of diffusion models**, which was not considered a weakness by the reviewers, area chairs, or senior area chairs.\n\nFinally, combining our methods will **further enhance the performance**.  We evaluate our trained model on FFHQ-256 using our proposed sampling method. The table shows that our sampling method consistently lowers the FID score of the trained model, indicating improved performance since a lower FID score is desirable.\n\n|  | Heun (NFE=35) | Ours (NFE=35) |\n| --- | --- | --- |\n| p(WSNR) | 7.89 | **7.40** |\n| p($\\sigma$) | 11.49 | **11.02** |\n\n\n[1] Karras, Tero, et al. \"Elucidating the design space of diffusion-based generative models.\" Advances in Neural Information Processing Systems 35 (2022): 26565-26577.\n\n\nQ2: Experiments in Table 1 and Table 2 compare with only EDM training noise schedule. The authors are suggested to compare with more training noise schedules to further verify the effectiveness of training noise schedules.\n\nA2:  We appreciate your suggestion to include comparisons with more training noise schedules to further validate the effectiveness of our approach. \n\nDue to the limited time for rebuttal and our computational resources, we conduct experiments on VP cases to evaluate our WSNR-Equivalent training noise schedule. The results in the following table show that our method further improves performance on VP cases.\n\n| FFHQ | 64 | 128 | 256 |\n| --- | --- | --- | --- |\n| p(WSNR) | 3.80 | **6.23** | **7.99** |\n| p($\\sigma$) | 3.80 | 7.41 | 11.78 |\n\n\n\nWe understand the importance of ensuring that our paper meets the high standards of ICLR and would greatly appreciate it if you could confirm whether the revisions made align with your expectations and satisfactorily resolve the issues previously highlighted.\n\nYour further guidance and feedback will be important to us and we are committed to making any additional improvements as needed.\n\nThank you very much for your time and consideration. We look forward to your response."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700573229737,
                "cdate": 1700573229737,
                "tmdate": 1700573258702,
                "mdate": 1700573258702,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "PzBP6xZdWX",
            "forum": "ylHLVq0psd",
            "replyto": "ylHLVq0psd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5772/Reviewer_d8X8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5772/Reviewer_d8X8"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigates the noise schedule of diffusion models.\n* The authors introduce a training noise schedule according to a metric \"weighted signal-to-noise-ratio (WSNR)\". It improves FID of latent diffusion models on FFHQ-128/-256 and ImageNet-256.\n* The authors propose a sampling noise schedule which slightly improves FID on CIFAR-10 and FFHQ-64 with 35 network evaluations per image."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The proposed training noise schedule improves FIDs.\n\nThe proposed sampling noise schedule improves FIDs."
                },
                "weaknesses": {
                    "value": "> As illustrated in Fig. 1, we observed substantial disparities in noise levels across images of varying resolutions under the same noise schedule. \n\nFigure 1 has nothing to do with resolutions.\n\n> To the best of our knowledge, we are the first to quantify the noise level of the forward process of the diffusion model, and have successfully extended it to the latent space. \n\nThis paper is not the first to quantify the noise level of the forward process of the diffusion model.\n* Choi et al., Perception Prioritized Training of Diffusion Models, CVPR2022 \n* What is the contribution of this paper compared to the above one?\n\n> P\u00b7,c(u,v) is the power of the frequency component at (u,v) within the c-th channel.\n\n* Are u and v in the frequency domain?\n* What technique is used to convert the images into frequency domain?\n\nSection 4 before 4.1 should be more self-contained.\n\n> Given a finite dataset, an ideal solution for the denoiser D(xt) can be found as the weighted sum of all clean data in the dataset. \n\n* This statement does not have support.\n* Eq. 4 describes it but it is not proved.\n\nThe proposed method is hardly reproducible.\n\nWriting should be improved. It is hard to follow due to poor connection between consecutive sentences. Especially in Introduction.\n\nTypos:\n* > ... in advancing the performance ? diffusion models.\n* > Eq. 7 implies that the proportion of data points whose square distance exceeds \u03b1 times the standard deviation from the mean is? no more than 1/\u03b1^2.\n\nPlease use one-letter variables in the algorithms for readability.\n\nPlease put titles on the axes in the figures for readability."
                },
                "questions": {
                    "value": "This paper proposes a training method and a sampling method. How do they affect the performance when applied together?\n\nWhat is the number of evaluation points?\n\nHow much is the difference in wall clock between 35 network evaluations with the proposed method and typical number of network evaluations with other methods?\n\nPlease consult Weaknesses for improving the paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 6,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5772/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699455240708,
            "cdate": 1699455240708,
            "tmdate": 1699636605973,
            "mdate": 1699636605973,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ISoDhv91nU",
                "forum": "ylHLVq0psd",
                "replyto": "PzBP6xZdWX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Q1: Figure 1 has nothing to do with resolutions.\n\nA1: Thanks for pointing it out, we acknowledge an error in our initial submission regarding the referencing of figures. Specifically, the discussion of resolutions is visualized in Fig 2 instead of Fig 1. We apologize for any confusion this may have caused and have corrected this reference in our revised manuscript. We appreciate the reviewers bringing this to our attention and ensuring the accuracy of our work.\n\n\n\nQ2: This paper is not the first to quantify the noise level of the forward process of the diffusion model. What is the contribution of this paper compared to [1]?\n\nA2: We have revised the relevant claim in the introduction section. Thanks for your suggestion. \nWe note that prior work, P2 [1], proposed a simple heuristic partition of noise levels based on SNR metric:  coarse (SNR 0 ~ 1e^-2), content (1e^-2 ~ 1), clean-up (1 ~ 1e^4). \n\nUnlike our WSNR metric, SNR is neither consistent in different resolutions, nor consistent in latent space. **Our WSNR is the first power spectrum based metric**, **which is consistent for noise level across multiple resolutions in RGB space and latent space**.\n\nHowever, our quantization metric is different from P2. We summarize the difference as follows:\n|  | Quantitative Metric | Quantitative Method | Consistent on Multiple Resolutions | Consistent in Latent Space |\n| --- | --- | --- | --- | --- |\n| Our | WSNR   | Power spectrum   | Consistent  | Consistent  |\n| P2 [1] | SNR  | Heuristic Discretization  | Not consistent  | Not consistent  |\n \nBesides the WSNR metric, **our paper contributes uniquely by**:\n- We significantly improve the performance of diffusion models, via our novel WSNR-Equivalent training noise scheduler. Specifically, our method decreases the FID score by **3.6** on FFHQ-256x256 dataset, and achieves the **same FID scores** on ImageNet-256 and 512 for UViT-M (#Params: 287M)  as those of UViT-L (#Params: 287M).  \n- We analyze that the **ODE sampling noise schedule** should be data-driven. Consequently, we propose estimating the integration interval based on the average data distance.\n- We explore the relationship between the number of evaluation points and generation quality. Our findings lead us to develop a **NFE-guided sampling noise schedule**.\n- Our sampling schedule refines the FID of pre-trained CIFAR-10 and FFHQ-64 models from **1.92 and 2.45 to 1.89 and 2.25**, respectively, utilizing 35 network evaluations per image.\n\nThus, our paper offers new insights and advancements in the study of the noise schedule of diffusion models.\n\n[1] Choi et al., Perception Prioritized Training of Diffusion Models, CVPR2022"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700555398156,
                "cdate": 1700555398156,
                "tmdate": 1700555398156,
                "mdate": 1700555398156,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ON0HMwYpih",
                "forum": "ylHLVq0psd",
                "replyto": "PzBP6xZdWX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Q3: Are u and v in the frequency domain?  What technique is used to convert images into frequency domain?\n\nA3:  Yes, u and v are in the frequency domain. Because $P$ represents the power spectrum.\nThe power spectrum is defined as \n$$P(u,v) = |F(u,v)|^2 $$\nwhere $F(u,v)$ is the 2D discrete Fourier transform (DFT). Please check the Eq. (4-67) and (4-89) in [2], which is a textbook widely adopted by university computer vision courses. \n\n[2] Gonzalez, Rafael C. Digital image processing 4th Edition.\n\n\nQ4:  Given a finite dataset, an ideal solution for the denoiser D(xt) can be found as the weighted sum of all clean data in the dataset. The ideal solution is not proved.\n\n\nA4:  We appreciate the reviewer's point regarding the lack of a formal proof for our assertion that an ideal solution for the denoiser can be represented as a weighted sum of all clean data in the dataset. \n\nHere, we provide proof to make it clear:\nGiven the standard deviation of Gaussian noise $\\sigma$ and the clean data probability distribution $p_{\\text{data}}(x) = \\frac{1}{Y} \\sum_{i=1}^{Y} \\delta(x - y_i)$, the probability of the noisy data $p(x; \\sigma)$ can be expressed as: \n\n$$\n\\begin{align}\np(x; \\sigma) & = p_{\\text{data}} * \\mathcal{N}(0, \\sigma^2 \\mathbf{I}) \\\\\n& = \\int_{\\mathbb{R}^d} p_{\\text{data}}(x_0) \\mathcal{N}(x; x_0, \\sigma^2 \\mathbf{I}) dx_0 \\\\\n& = \\int_{\\mathbb{R}^d} \\left[ \\frac{1}{Y} \\sum_{i=1}^{Y} \\delta(x_0 - y_i) \\right] \\mathcal{N}(x; x_0, \\sigma^2 \\mathbf{I}) dx_0 \\\\\n& = \\frac{1}{Y} \\sum_{i=1}^{Y} \\int_{\\mathbb{R}^d} \\mathcal{N}(x; x_0, \\sigma^2 \\mathbf{I}) \\delta(x_0 - y_i) dx_0 \\\\\n& = \\frac{1}{Y} \\sum_{i=1}^{Y} \\mathcal{N}(x; y_i, \\sigma^2 \\mathbf{I}) \\\\\n\\end{align}\n$$\n\n\nThe loss of the Denoiser is:\n\n$$\n\\mathcal{L}(D; \\sigma) = E_{y \\sim p_\\text{data}} \\mathbb{E}_{x \\sim p(x, \\sigma)}  \\| D(x; \\sigma) - y \\|_2^2\n$$\n\n$$\\mathcal{L}(D; \\sigma) = \\int_{\\mathbb{R}^d} \\frac{1}{Y} \\sum_{i=1}^Y \\mathcal{N}(x; y_i, \\sigma^2 \\mathrm{I}) \\| D(x; \\sigma) - y_i \\|_2^2  dx$$\n\nThe solution is obtained by setting the gradient w.r.t $D(x; \\sigma)$ to zero:\n\n$$\n0 = \\nabla_{D(x;\\sigma)} \\mathcal{L}(D; x, \\sigma)\u00a0\n$$\n\n$$\n0 = \\nabla_{D(x;\\sigma)} \\left[ \\frac{1}{Y} \\sum_{i=1}^Y \\mathcal{N}(x; y_i, \\sigma^2 \\mathrm{I}) \\| D(x; \\sigma) - y_i \\|_2^2 \\right]\n$$\n\n$$\n0 = \\sum_{i=1}^Y \\mathcal{N}(x; y_i, \\sigma^2 \\mathrm{I}) \\nabla_{D(x;\\sigma)} \\left[ \\| D(x; \\sigma) - y_i \\|_2^2 \\right]\n$$\n\n\n$$\n0  = \\sum_{i=1}^Y \\mathcal{N}(x; y_i, \\sigma^2 \\mathrm{I}) \\left[ 2 D(x; \\sigma) - 2 y_i \\right]\u00a0\n$$\n\n$$\n0 = \\left[ \\sum_{i=1}^Y \\mathcal{N}(x; y_i, \\sigma^2 \\mathrm{I}) D(x; \\sigma) \\right] - \\left[ \\sum_{i=1}^Y \\mathcal{N}(x; y_i, \\sigma^2 \\mathrm{I}) y_i \\right]\u00a0\n$$\n\n$$\nD(x; \\sigma) = \\frac{\\sum_{i=1}^Y \\mathcal{N}(x; y_i, \\sigma^2 \\mathrm{I}) y_i}{\\sum_{i=1}^Y \\mathcal{N}(x; y_i, \\sigma^2 \\mathrm{I})}\u00a0\n$$\n\n$$\nD(x; \\sigma) = \\frac{\\sum_{i=1}^Y\u00a0\\mathrm{exp}(\\frac{||x-y_i||^2}{-2\\sigma^2})  y_i}{\\sum_{i=1}^Y \\mathrm{exp}(\\frac{||x-y_i||^2}{-2\\sigma^2})}\n$$\n\n$$\nD(x; \\sigma) = \\sum_{i=1}^Y \\mathrm{softmax}(\\frac{||x-y_i||^2}{-2\\sigma^2})\u00a0y_i\n$$\n\nAs shown in the last Equation in this comment, the ideal solution for the denoiser $D(x)$ can be found as the weighted sum of all clean data in the dataset."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700557760909,
                "cdate": 1700557760909,
                "tmdate": 1700640568612,
                "mdate": 1700640568612,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Ibl5wxm8fi",
                "forum": "ylHLVq0psd",
                "replyto": "PzBP6xZdWX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Q5: The proposed method is hardly reproducible.\n\nA5: We will release code to reproduce the results.\n\nQ6: Typos and connection.  Use one-letter variables in algorithms for readability. Put titles on the axes in the figures for readability.\n\nA6: In the revised version of the draft, we fix typos and improve the connection between sentences. Besides, we  make the algorithm and figures more readable. We will keep polishing our draft for the final version. Thanks for your suggestion.\n\nQ7: What is the number of evaluation points?\n\nA7: Evaluation points are the **unique timesteps** at which the diffusion model makes predictions. The 2nd Heun's adopts the start point and end point to estimate the 2nd derivative. Therefore, the end point of the current timestep is identical to the start point of the next timestep. For example, when employing the 2nd Heun method for sampling, which uses 18 timesteps, the Number of Function Evaluations (NFE) is calculated as 2x18 - 1 = 35. Please refer to [this code segment](https://github.com/NVlabs/edm/blob/main/generate.py#L25) for more details.  However, the model actually performs evaluations at only 18 unique timesteps. We refer to these 18 points as evaluation points.  In the case of the midpoint method, all NFEs are performed at unique timesteps, so NFE equals the Number of Evaluation Points (NEP).\n\n\nQ8: How much is the difference in wall clock between 35 network evaluations with the proposed method and typical number of network evaluations with other methods?\n\nA8: There is no difference in wall clock between 35 network evaluations with the proposed method and typical number of network evaluations with other methods.  \n\nFor a UNet with a base channel of 128 and channels per resolution set to 1-2-2-2, having 4 ResNet blocks at each resolution, the computational cost for each neural network evaluation is **41.72 GFlops** when the output shape is (1, 3, 64, 64). The remaining computational cost involves less than 100 instances of element-wise addition or multiplication operations, amounting to less than **0.0012288 GFlops**. \n\nTherefore, our wall clock time is the same as other methods under the identical NFE.\n\nQ9: This paper proposes a training method and a sampling method.  How do they affect performance when applied together?\n\nA9: To prove the compatibility of our training and sampling methods, we evaluate our trained model on FFHQ-256 using our proposed sampling method. The table shows that our sampling method consistently lowers the FID score of the trained model, indicating improved performance since a lower FID score is desirable.\n\n|  | Heun (NFE=35) | Ours (NFE=35) |\n| --- | --- | --- |\n| p(WSNR) | 7.89 | **7.40** |\n| p($\\sigma$) | 11.49 | **11.02** |\n\nWe understand the importance of ensuring that our paper meets the high standards of ICLR and would greatly appreciate it if you could confirm whether the revisions made align with your expectations and satisfactorily resolve the issues previously highlighted.\n\nYour further guidance and feedback will be important to us and we are committed to making any additional improvements as needed.\n\nThank you very much for your time and consideration. We look forward to your response."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700561268064,
                "cdate": 1700561268064,
                "tmdate": 1700563490637,
                "mdate": 1700563490637,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XiqMKwdObg",
                "forum": "ylHLVq0psd",
                "replyto": "PzBP6xZdWX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer d8X8,\n\nJust a reminder, there are only 4 hours left for the rebuttal. \n\nAfter this time, we will not be able to participate in the discussion any further. \n\nWe are waiting for your response. We would happily address any other questions.\n\nBest Regards,\n\nThe Authors"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700726977814,
                "cdate": 1700726977814,
                "tmdate": 1700726977814,
                "mdate": 1700726977814,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WkOn0ZKt6m",
                "forum": "ylHLVq0psd",
                "replyto": "PzBP6xZdWX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5772/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer d8X8,\n\nJust a reminder, there are **only 2 hours** left for the rebuttal.\n\nAfter this time, we will not be able to participate in the discussion any further.\n\nWe are waiting for your response. We would happily address any other questions.\n\nBest Regards,\n\nThe Authors"
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5772/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700733871632,
                "cdate": 1700733871632,
                "tmdate": 1700733871632,
                "mdate": 1700733871632,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]