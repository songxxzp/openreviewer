[
    {
        "title": "Flag Aggregator: Scalable Distributed Training under Failures and Augmented Losses using Convex Optimization"
    },
    {
        "review": {
            "id": "ubcIodcuS7",
            "forum": "7avlrpzWqo",
            "replyto": "7avlrpzWqo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6879/Reviewer_Es7u"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6879/Reviewer_Es7u"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes a novel robust aggregator, i.e., Flag Aggregator (FA), to deal with Byzantine faults in distributed computation. FA is an optimization-based subspace estimator that formulates aggregation as a maximum likelihood estimation procedure using Beta densities. In distributed training setups where vanilla mean aggregators are replaced by robust aggregators without additional tricks, FA consistently outperforms many other existing robust aggregators in extensive experiments with various batch sizes, fractions of Byzantine nodes, and number of nodes."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed FA is novel in the distributed optimization literature. FA makes use of dependence among distributed gradients, while most existing aggregators only exploit the pairwise distance or moment conditions. This is beneficial in that if one can design aggregator that utilizes the data dependence, this aggregator is actually adaptive to this specific problem automatically, and thus one can improve performance. The authors provide insights on the intuitions, formulations, and approximate solutions to FA.\n3. Consistent empirical performance improvement against many existing aggregators is achieved, among extensive experiments that investigate many facets of the Byzantine distribution optimization problem."
                },
                "weaknesses": {
                    "value": "1. There are no specific examples that can show FA is theoretically better than existing methods, and thus makes the claim not persuasive to some audience. It can be, possibly, FA only performs well in the specific datasets, models, the way of distributing datasets among compute nodes in the experiments presented in this work. Even a naive toy example would help people understand why FA is theoretically better. \n2. There are no comparisons between FA and existing aggregators in terms of computation complexity. It can be that, FA is too expensive to use in every iteration. \n3. The intuition behind the development of FA is not clear enough to me, this goes to the first bullet, can the authors provide an example or a simple problem model to illustrate this? And why is FA optimal as claimed in line 83? Can the authors elaborate on this point?"
                },
                "questions": {
                    "value": "1. In line 22, the description of quadratic function is not clear to me, can the authors put it simpler? \n2. How will the augmented data and stable diffusion influence the mutual dependence of distributed data, can the authors comment on that?\n3. In line 72, what does it mean for noise to be nonlinear? \n4. In line 73 & 74, how does the discrete hyper parameters hamper convergence of the overall training procedure, can you elaborate on that?\n5. In line 76, the authors mention 'sparse', does that correspond to the choice of the second dimension of $Y$, i.e., $m$, how is $m$ chosen? \n6. In line 115, it seems that $g$ should $g_i$, and there is no need to use trace on a scalar right? \n7. In figure 3, I don't understand what is optimal subspace, do you mean optimality in the sense of formulation (5)?\n8. Why is beta distribution used in the formulation of FA? \n9. In the experiment starting from line 300, what attacks are being used?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6879/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6879/Reviewer_Es7u",
                        "ICLR.cc/2024/Conference/Submission6879/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6879/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698797729392,
            "cdate": 1698797729392,
            "tmdate": 1700712825349,
            "mdate": 1700712825349,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3t0Wv2A4kX",
                "forum": "7avlrpzWqo",
                "replyto": "ubcIodcuS7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6879/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6879/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q.** There are no specific examples that can show FA is theoretically better than existing methods, and thus makes the claim not persuasive to some audience. It can be, possibly, FA only performs well in the specific datasets, models, the way of distributing datasets among compute nodes in the experiments presented in this work. Even a naive toy example would help people understand why FA is theoretically better.\n\n**Ans.** Please see Figure 3 for a specific example. Here, we extracted gradients of parameters of ResNet-18 at $p=15$ workers, of which $f=2$ produce uniformly random gradients for 1000 iterations. At each iteration, we compute the mean of gradients and use it to calculate the values of workers. We also compute the optimal subspace provided by FA and calculate the values of workers using that at each iteration. The histogram of values computed using the mean gradient is much lower since most values are close to zero whereas when the optimal subspace provided by FA aggregation is used, the value is enhanced. We observed this phenomenon on many datasets, and architectures at various training stages, and we are happy to give more details with exact checkpoints in the Appendix for scientific replication purposes. In summary, we believe that this decreased value while using average gradients is due to the high dimensional phenomenon and can be easily replicated. \n\n\nWe used the standard data-parallel training setup used in practice. First, we shuffle the data to randomize it, using a seed for consistency. Then, we create partitions proportional to the number of workers, ensuring each chunk is a different part of the dataset. These partitions are lists of indexes, representing how the data is divided. This setup allows distributing different data chunks to multiple workers in a training process, ensuring each worker gets a unique, random subset of the data for independent and identically distributed gradients.\n\nWe assure the reviewer that the way of distributing datasets did not have any effect on our experiments. We consider the reproducibility aspects of our experiments seriously, so we will release all the datasets, along with code, model, a blog post, as well as a tutorial to reproduce all the figures in our submission on acceptance. \n\n**Q.** There are no comparisons between FA and existing aggregators in terms of computation complexity. It can be that, FA is too expensive to use in every iteration.\n\n**Ans.** Please refer to the potential limitation in the appendix and the corresponding Figure~18. Please note that although the iteration complexity of FA is higher, the utility of each iteration is higher, which is reflected in the time-to-accuracy comparison. The figure shows two main points: 1) FA converges to a higher accuracy, and more importantly, 2) it reaches to that level in less (wall-clock) time. In this sense, we think that FA's somewhat higher per-iteration complexity is well justified. In the future, we plan on evaluating eigenvalue solvers to further accelerate training time. We have provided a more detailed explanation, along with preliminary evaluation of per-iteration complexity in Section G in the Appendix. In essence, we believe that this gap in per-iteration time can be further reduced using modern fast eigenvalue solvers.\n\n**Q.** The intuition behind the development of FA is not clear enough to me, this goes to the first bullet, can the authors provide an example or a simple problem model to illustrate this? And why is FA optimal as claimed in line 83? Can the authors elaborate on this point?\n\n**Ans.** FA is optimal in the sense that it seeks to find an approximate solution to the optimization problem formulation given in Equation (5). Our derivation using MLE in Sec 2.2 shows that problem (5) can be used whenever the value of the gradients needs to be maximized or in other words, when we want to maximize the values provided by gradients from workers in a distributed training pipeline. Finally, to see that FA aggregation guarantees convergence, please notice that our update is given by $YY^{\\top}G{\\bf 1}$ where $G{\\bf 1}$ simply denotes the sum of gradients from workers. Now since $YY^{\\top}$ is a symmetric positive semidefinite matrix, it is guaranteed to have an eigenbasis. Intuitively, this means that the update rule itself simply rotates the gradients, scales them in specific coordinates, and rotates them back to their original basis. This is our main intuition in proposing subspace based aggregation that is currently not explored in distributed training pipelines used in practice."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6879/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700631583797,
                "cdate": 1700631583797,
                "tmdate": 1700631583797,
                "mdate": 1700631583797,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "si8sxL89oF",
                "forum": "7avlrpzWqo",
                "replyto": "3t0Wv2A4kX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6879/Reviewer_Es7u"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6879/Reviewer_Es7u"
                ],
                "content": {
                    "comment": {
                        "value": "I express my gratitude to the reviewers for providing thorough responses to my inquiries. While I acknowledge that the suggested aggregator consistently demonstrates strong performance across diverse datasets and under various attacks, my initial concern remains regarding the absence of a theoretical toy example. This example would serve to illustrate: 1) the modeling process, elucidating the rationale behind determining the appropriate value for $m$; and 2) a comparison of computational complexity with other methods, including the intricacies of solving FA. I understand that this may not be deemed necessary if the primary emphasis of the contribution is on practical effectiveness, and raised my scores accordingly."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6879/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700712802569,
                "cdate": 1700712802569,
                "tmdate": 1700712802569,
                "mdate": 1700712802569,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "jrGqwvxsPw",
            "forum": "7avlrpzWqo",
            "replyto": "7avlrpzWqo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6879/Reviewer_PqPx"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6879/Reviewer_PqPx"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes an aggregation function based on low-rank projection. In particular, for a given matrix $G$, this work proposes to perform the aggregation by projecting it to a low-dimensional space, $YY^TG1$, where $Y$ is the subspace chosen based on low-rank factorization of $G$. The connection between the algorithm and the Maximum Likelihood Estimation procedure using Beta densities is presented. Experimental results show improvements in communication efficiency and accuracy compared to previous works."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The proposed method is simple yet effective. Theoretical analysis is also provided to backup the algorithm.\n\n2. Detailed experimental results are provided, and better accuracy has been shown compared to the previous works."
                },
                "weaknesses": {
                    "value": "Here are a few comments regarding the experimental section:\n\n1. The choice of setting the subspace rank $m$ to $(p+1)/2$ in all experiments raises a question. Is this decision rooted in theoretical analysis or other considerations?\n\n2. The paper introduces a general framework in Section 2, considering a general norm and suggesting SDP for solving the system. However, the focus shifts to $\\ell_1$ regularization later due to its ease of optimization. An experimental comparison of different regularization terms could bridge the apparent gap between Sections 2 and 3.\n\n3. It would be useful to explore whether the proposed algorithm offers advantages even when $f=0$."
                },
                "questions": {
                    "value": "n/a"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6879/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6879/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6879/Reviewer_PqPx"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6879/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698819694123,
            "cdate": 1698819694123,
            "tmdate": 1699636799809,
            "mdate": 1699636799809,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GuJMj7b1Vf",
                "forum": "7avlrpzWqo",
                "replyto": "jrGqwvxsPw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6879/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6879/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q.** Is the choice of setting the subspace rank $m$ to $(p+1)/2$ in all experiments rooted in theoretical analysis or other considerations?\n\n**Ans.** Great question! We decided to use $m$ to be $(p+1)/2$ since it corresponds to a naive prior that each worker may provide noisy gradient with probability $1/2$. In this case, the expected number of clean gradients will be the integer greater than or equal to  $p/2$.  Our choice also corresponds to a realistic setting in most use cases -- that the majority (i.e., more than half) of workers provide correct gradients. \n\n**Q.** The paper introduces a general framework in Section 2, considering a general norm and suggesting SDP for solving the system. However, the focus shifts to regularization later due to its ease of optimization. An experimental comparison of different regularization terms could bridge the apparent gap between Sections 2 and 3.\n\n**Ans.** We use the SDP relaxation of the MLE in Equation (4) to argue that solving FA problem may be tractable since SDPs can be solved efficiently from the theoretical standpoint. We provided the regularized version with two specific regularization functions $\\mathcal{R}$ that our tractability analysis using SDP can handle since these two choices of $\\mathcal{R}$ are convex functions with respect to $Y$. We provided preliminary experiments with pairwise data dependent regularizer in Sec F.2, Figure 10. We plan to do a detailed study on different regularizers with FA in the near future. We will definitely clarify this in the camera-ready. \n\n**Q.** It would be useful to explore whether the proposed algorithm offers advantages even when $f=0$\n\n\n**Ans.** We agree, thank you for pointing this out!  Our update rule is given by $YY^{\\top}G{\\bf 1}$ where $G{\\bf 1}$ simply denotes the sum of gradients from workers. Reviewer will be able to see that since $YY^{\\top}$ is a symmetric positive semidefinite matrix, it is guaranteed to have an eigenbasis. Intuitively, this means that the update rule itself simply rotates the gradients, scales them in specific coordinates, and rotates them back to their original basis. So, we may think of $YY^{\\top}$ as an adaptive preconditioner and can be used whenever the loss landscape is ill-conditioned. In the Appendix, we have added a convergence plot in Figure 11 for the noiseless setting i,e, $f=0$. In this setting, a robust aggregator should be as good as the standard distributed SGD with Mean as the aggregator, which we can clearly observe here.  In Figure 11 we can see that FA, performs better than mean, which is consistent with the findings in [Mankovich et al. 2022]. \n\n[Mankovich et al. 2022] The Flag Median and FlagIRLS, CVPR 2022."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6879/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700631379255,
                "cdate": 1700631379255,
                "tmdate": 1700631379255,
                "mdate": 1700631379255,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "YADMInOQuX",
            "forum": "7avlrpzWqo",
            "replyto": "7avlrpzWqo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6879/Reviewer_YEpb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6879/Reviewer_YEpb"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes Flag Aggregator, a simple Maximum Likelihood Based estimation procedure for aggregation purposes. They show that any procedure used to solve Flag Optimization can be directly used to obtain the optimal summary statistic $Y^*$.The authors also show the approach is resilient against Byzantine attacks for gradient aggregation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Gradient aggregation is a critical design choice in many of the distributed training applications, and is ubiquitous. The proposed method seems promising and useful for this space."
                },
                "weaknesses": {
                    "value": "- I am not sure how much overhead the SVD might bring in practice, could you provide some real-world measurement? So far all the empirical results are epoch-wise measuring.\n- Most of the baseline compared in the experiments seem to be from at least five years ago (2018); I wonder if the authors can compare their approach with latest algorithms? For instance  Allouah et al. (2023a;b); Farhadkhani et al. (2022) as mentioned in the related work."
                },
                "questions": {
                    "value": "I'll increase my rating if comparison to more recent algorithms is provided."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6879/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699212856124,
            "cdate": 1699212856124,
            "tmdate": 1699636799685,
            "mdate": 1699636799685,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MlNCzTqHIf",
                "forum": "7avlrpzWqo",
                "replyto": "YADMInOQuX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6879/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6879/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q.** How much overhead the SVD might bring in practice, could you provide some real-world measurement?\n\n**Ans.** Yes, please refer to the potential limitation in Section G in the appendix. Indeed, there is nontrivial overhead to execute FA in each training iteration. Fortunately, this overhead is compensated by reduction in total number of training iterations in all our experiments, thus providing significantly lesser wall clock time. We have provided more explanations and suggestions for potentially accelerating training time by using approximate eigenvalue calculation. When using exact eigenvalue calculations, the overheads per iteration can be seen in Figure 18.\n\n**Q.** Most of the baseline compared in the experiments seem to be from at least five years ago (2018). Can the authors compare their approach with latest algorithms? For instance Allouah et al. (2023a;b); Farhadkhani et al. (2022)\n\n**Ans.** Thank you for the suggestion. We compared FA to RESAM [Farhadkhani et al. (2022)] which adapts the concept of gradient momentum to distributed architectures. RESAM involves each honest worker computing and storing the momentums of their stochastic gradients as well as the gradients, and sending the momentum to the server which increases computational complexity per iteration. Similar to [Allouah et al. (2023a;b)], RESAM still relies on resilient aggregation similar to our baselines at the server, so we complement it with the existing baselines including CGE [Gupta et al. (2021)]. Nevertheless, we show the comparison in Figure~13 of the updated submission while ignoring the overheads of RESAM. The figure shows FA's advantage under three different scenarios. In addition, FA is designed as a robust standalone aggregator that needs no extra computation or space for calculating gradient momentums and storing them on the worker side.\n\n[Gupta et al. (2021)] Byzantine Fault-Tolerant Distributed Machine Learning Using Stochastic Gradient Descent (SGD) and Norm-Based Comparative Gradient Elimination (CGE)\n\n[Farhadkhani et al. (2022)] Byzantine machine learning made easy by resilient averaging of momentum\n\n[Allouah et al. (2023a)] Distributed Learning with Curious and Adversarial Machines\n\n[Allouah et al. (2023b)] Fixing by Mixing: A Recipe for Optimal Byzantine ML under Heterogeneity"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6879/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700630975711,
                "cdate": 1700630975711,
                "tmdate": 1700630975711,
                "mdate": 1700630975711,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]