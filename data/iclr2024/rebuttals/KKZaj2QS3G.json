[
    {
        "title": "Enriching Time Series Representation: Integrating a Noise-Resilient Sampling Strategy with an Efficient Encoder Architecture"
    },
    {
        "review": {
            "id": "58uH4bvTW7",
            "forum": "KKZaj2QS3G",
            "replyto": "KKZaj2QS3G",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3667/Reviewer_sJ4A"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3667/Reviewer_sJ4A"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a self-supervised learning framework that explicitly considers noise and ensures consistent representation given noisy input data. The proposed architecture is also lightweight and efficient. Experiments across three tasks (forecasting, classification, anomaly detection) verify the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed representation learning framework explicitly takes noise into consideration, and enables consistent representation despite noise in the original data.\n2. The proposed model architecture with Inception blocks is lightweight and efficient.\n3. Extensive experiments on three time-series related downstream datasets demonstrate promising performance."
                },
                "weaknesses": {
                    "value": "1. The direct forecasting baselines compared in the paper are no longer the state of the art. Including more recent baselines like PatchTST and DLinear could better showcase the effectiveness of the proposed method in comparative analysis.\n2. The diversity of forecasting datasets seems limited, focusing only on the electricity domain. \n3. How to quantify the performance improvement with respect to the noise levels in the original datasets? For example, do higher noise levels in the original datasets correspond to larger performance improvement after adopting the proposed noise-resilient approach?\n4. The choice of Discrete Wavelet Transform (DWT) for denoising, as opposed to other frequency-domain denoising techniques like high-frequency component filtering post-Fast Fourier Transform (FFT), needs further clarification.\n5. The paper could benefit from clarifying any underlying assumptions about the noise characteristics, such as whether the noise needs to be additive rather than multiplicative in relation to the original time series."
                },
                "questions": {
                    "value": "See Weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3667/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3667/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3667/Reviewer_sJ4A"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3667/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698790891450,
            "cdate": 1698790891450,
            "tmdate": 1699636323445,
            "mdate": 1699636323445,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AnggbvCQSi",
                "forum": "KKZaj2QS3G",
                "replyto": "58uH4bvTW7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3667/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3667/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer sJ4A"
                    },
                    "comment": {
                        "value": "Thank you for dedicating your time to reviewing our paper and providing detailed, informative comments. Besides the responses, we have uploaded our revised manuscript and appendix, with all the revisions and additional details made based on your constructive feedback. Below are our responses to your specific questions:\n\n*1. Regarding forecasting baselines*\n\nThank you for sharing the interesting studies, and we have completed the reading of these remarkably interesting works. We cite these references in our revised manuscript in the literature reviews section. We are working to add these methods into our experiments. However, due to the short rebuttal time and extensive experiments, we can not guarantee that such comparisons appear within the time period. Nevertheless, we will do our best to add the references to the experiments in the next version of our manuscript. \n\n*2. The diversity of forecasting datasets seems limited, focusing only on the electricity domain.*\n\nAbout the use of 4 datasets for forecasting task, there are several reasons for us to do so:\n- They are widely used to assess performance of time series frameworks when predicting long future sequences.\n- We incorporate these datasets in line with earlier research [1,2], and we follow the specific configurations outlined in those studies. This procedure is taken to minimize potential biases arising from varying experimental conditions, ensuring a fair comparison of our method with existing research.\n- Three of four datasets come from the same repository (ETT datasets), and one from UCI repository. These 2 repositories have the distinguished target variables: For ETT datasets, the target variable is Oil Temperature (OT), while the variable of Electricity dataset is electrical consumption in kWh. This diversity enhances the overall Forecasting section, rendering it more comprehensive and universally applicable.\n\n*3. How to quantify the performance improvement with respect to the noise levels in the original datasets? For example, do higher noise levels in the original datasets correspond to larger performance improvement after adopting the proposed noise-resilient approach?*\n\nWe thank the Reviewer for this insightful comment. Following this suggestion, we plan to further design and conduct an experiment investigating the relationship between noise levels and models\u2019 performance. We are working to add experimental result in the next version of our manuscript.  However, due to the short rebuttal time and extensive experiments, we can not guarantee that such comparisons appear within the time period. \n\n*4. Clarification on the choice of Discrete Wavelet Transform (DWT)*\n\nOur initial preference for the Discrete Wavelet Transform (DWT)-based low-pass filter is grounded in several considerations outlined below:\n- DWT, as opposed to another commonly used method in frequency analysis, FFT, offers a distinct advantage that aligns with our objectives in the low-pass filter. While FFT provides a decomposition without temporal information, DWT deconstructs series into multiple frequency sub-bands with reduced time resolutions. Opting for DWT grants us more flexibility in determining which frequency bands to diminish at specific time ranges, allowing targeted reduction without completely eliminating entire frequency spectra from the series of interest.\n- This filter operates as an independent module and requires no training parameters, making it decoupled from other modules in the CoInception framework. This modular design opens space for potential replacements that may be better suited to specific datasets or tasks.\n\nIt's crucial to underscore that our primary contribution lies not in the low-pass filter itself but in the objective of generating noise-resilient representations. Consequently, our current selection of the DWT low-pass filter may not be universally optimal for all datasets or tasks. For particular datasets, we believe spending extra effort to carefully choose the suitable low-pass filter could enhance the CoInception pipeline\u2019s performance even further."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3667/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699987434999,
                "cdate": 1699987434999,
                "tmdate": 1699987434999,
                "mdate": 1699987434999,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "dKdP6aBLXr",
            "forum": "KKZaj2QS3G",
            "replyto": "KKZaj2QS3G",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3667/Reviewer_TahQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3667/Reviewer_TahQ"
            ],
            "content": {
                "summary": {
                    "value": "Ths paper proposes three improvements to learn a better representation of time series data, especially under noise situation. The three parts  are a novel sampling strategy, an enhanced dilated convolutional encoder, and a new triplet loss. The experiments on different domains of time series dataset, show consistent improvement over the state-of-the-art TS2VEC model."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The authors provide ablation study on how effective of each proposed components, and show all of them contributes to the final improvement.\n2. The testing dataset is ocmprehensive, including popular UCR, UEA, Yahoo, etc. The results are evaluated on most of the subset in each repository.\n3. The domain of experiments is also comprehensive, including forecasting, classification, abnormaly detection, etc. A consistent improvement on all the domain and all the dataset make the contribution very solid."
                },
                "weaknesses": {
                    "value": "1. It might be better to see an additional ablation study on the encoder architecture, as the authors also proposes 3 changes on the original encoder.\n2. The noise reduction is demonstrated in Figure 2, but it is hard to tell what to expect from the figure. I would suggest using some statistics to show the closeness between the embeddings of original time series and the perturbed ones."
                },
                "questions": {
                    "value": "The noise reduction effect is mainly attributes to which of the three proposed compoenents?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3667/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698812104408,
            "cdate": 1698812104408,
            "tmdate": 1699636323352,
            "mdate": 1699636323352,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AGG0JeGhdQ",
                "forum": "KKZaj2QS3G",
                "replyto": "dKdP6aBLXr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3667/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3667/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer TahQ"
                    },
                    "comment": {
                        "value": "Thank you for your time and the positive evaluations of our paper. We also express gratitude for your constructive comments and suggestions. Besides the responses, we have uploaded our revised manuscript and appendix, with all the revisions and additional details made based on your constructive feedback. We hope that our responses below sufficiently address all of your questions:\n\n*1. An additional ablation study on the encoder architecture*\n\nWe thank you for these great constructive comments. We find this experiment can be directly addressed, given that it is related to our framework and worth investigating. We plan to update these results together with our revised manuscript in the next few days.\n\n*2. The noise reduction is demonstrated in Figure 2, but it is hard to tell what to expect from the figure.*\n\nThank you for pointing out this. We have made our motivation clearer with Figure 2, including quantitative correlation calculation measured by cosine similarity to show the proximity between the representations of original time series and the perturbed ones.\n\n*3. The noise reduction effect is mainly attributes to which of the three proposed compoenents?*\n\nThe initiation of the noise reduction effect occurs during the sampling stage for training data samples, where segments of both raw and disturbed series are selected. Subsequently, the actual realization of this effect is guided by our alignment loss and stabilized by the Triplet Loss regularization term through the training process. \n\nNevertheless, while the CoInception Encoder does not directly support the noise reduction effect, its contribution is also crucial in the whole pipeline. It balances efficiency and effectiveness, contributing significantly to the enhanced performance of CoInception, as demonstrated in Table 4 of the ablation experiment. Moreover, owing to the independent nature of these two modules, future studies might be benefited from different aspects of the CoInception pipeline, such as the reutilization of the CoInception architecture, without necessitating modifications or assumptions about other modules.\n\nOnce again, thank you for your positive evaluations of our paper. Please leave us with other responses if you have any further concerns. When all your concerns are resolved, we sincerely hope that you could consider increasing your score and support us."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3667/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699987154061,
                "cdate": 1699987154061,
                "tmdate": 1699987154061,
                "mdate": 1699987154061,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "f6FUuzqmI0",
                "forum": "KKZaj2QS3G",
                "replyto": "I7Rq2ugZvY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3667/Reviewer_TahQ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3667/Reviewer_TahQ"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your response"
                    },
                    "comment": {
                        "value": "I acknowledge that I have read authors' responses and I appreciate the additional ablation studies by the authors. I will stick to my positive score."
                    }
                },
                "number": 27,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3667/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700713417588,
                "cdate": 1700713417588,
                "tmdate": 1700713417588,
                "mdate": 1700713417588,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hnlnaw78TL",
            "forum": "KKZaj2QS3G",
            "replyto": "KKZaj2QS3G",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3667/Reviewer_CP3P"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3667/Reviewer_CP3P"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a new time-series representation learning strategy with contrastive learning, which highlights the importance of handling noise. Specifically, they propose the noise-resilient sampling strategy to find the positive and negative pairs where different views of the data samples are created from the spectral domain instead of the temporal domain. They present a new time-series encoder that leverages Inception and Dilation to achieve efficiency and wide receptive field at the same time."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Their proposed new encoder architecture is both lightweight and able to look at a wide receptive field.\n2. They\u2019ve conducted extensive experiments to show the advantages of their proposed methods in time-series representation learning in the tasks of forecasting, classification, and anomaly detection."
                },
                "weaknesses": {
                    "value": "1. One of the key assumptions that the authors make is that noise is usually in high frequency, citing two reference papers (Lanting et al., 2011 and Oohashi et al., 2000). But I highly doubt whether this is the case in general. The 1st reference paper (Lanting et al., 2011) focuses on a very niche case (Macroscopic Resonant Tunneling), while the key insight of the 2nd one (Oohashi et al., 2000) is not even related based on my glimpse at the abstract of that paper. Thus, I would doubt the usefulness of the proposed method.\n2. Writing and English need to be improved. I\u2019ll give 3 examples but there are more scattering around the entire paper. (1) for Figure 2, it is very confusing which part I should be looking at when reading the corresponding text in Section 2.2. (2) On page 4, it is confusing what level $j$ refers to without further explanation (I could sort of infer it means the $j$-th dimension of $\\mathbf{x}$). (3) The long paragraph on Page 5 should be better structured and many sentences in it are informal and unprofessional. I would suggest the authors read through the paper before submitting it."
                },
                "questions": {
                    "value": "I have included some of the questions in the part of Weakness. Other than that:\n- What are the characteristics of datasets that you expect your proposed method to work better on? For example, do they tend to have noise in distinct frequencies or require longer sequence dependence?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3667/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3667/Reviewer_CP3P",
                        "ICLR.cc/2024/Conference/Submission3667/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3667/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698819724435,
            "cdate": 1698819724435,
            "tmdate": 1700369383575,
            "mdate": 1700369383575,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "zedYA0ct2f",
                "forum": "KKZaj2QS3G",
                "replyto": "hnlnaw78TL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3667/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3667/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer CP3P"
                    },
                    "comment": {
                        "value": "We appreciate your time and effort spent on reviewing our manuscript. We are glad to receive your acknowledgment of our encoder design and our efforts in conducting experiments. Besides the responses, we have uploaded our revised manuscript and appendix, with all the revisions and additional details made based on your constructive feedback. We address and clarify these concerns point-by-point below:\n\n*1. Regarding high frequency noise*\n\nThank you for this insightful comment. We are sorry that our sentences gave a false impression that we assume high frequency in noise. We agree with you about the two references and we remove them since they potentially lead to a misunderstanding of our intended idea. We hope to discuss this in detail and clarify our work better with you. \n\nWhile we focus on addressing high-frequency noise, we do not necessarily assume that noise is inherently high frequency. However, we have motivations to consider this setting, which is the observation that high-frequency noisy components often correspond to short-term variations or bursts that may not significantly contribute to the overall structure of the time series. The contextual information derived from these short-term fluctuations can be misleading and may not accurately represent the underlying series of interest. Therefore, our objective is to make the CoInception framework insensitive to these high-frequency noise. By doing so, we aim to ensure that the output representations are more robust to variations and disturbances in the input. In addition, this approach aligns well with various studies [1,2,3,4] emphasizing the utilization of disentangled components of raw series, such as seasonality or trends, which exhibit persistence in a long-term context.\n\nFor the above reasons, we argue that the study of this setting is useful and beneficial in practice, and this fact is proven by our extensive experiments. In the revision, we clearly explain why we are specifically addressing high-frequency noise and update our references accordingly.\n\n*2. Regarding our writing*\n\nThank you for this straight and constructive feedback. As mentioned, we have refined our writing in this revision (taking into account all three examples you mentioned), carefully with our choices of words to avoid any potential misunderstandings and concerns. If you see any other examples, please let us know and we will work with you promptly to make sure our manuscript is clear and concise.\n\n*3. What are the characteristics of datasets that you expect your proposed method to work better on? For example, do they tend to have noise in distinct frequencies or require longer sequence dependence?*\n\nWe thank you for an insightful question on the further analysis of our methods. While our primary focus is on making the CoInception framework robust to high-frequency noise, it's important to note that we don't presume superior performance on specific datasets. This intentional lack of expectation ensures the versatility of our design, allowing it to be applicable across a broad spectrum of datasets and tasks.\nSpecifically, when defining the 'high-frequency' spectrum in our framework, we don't restrict it to a fixed range of frequency bands. Instead, it is calculated based on the characteristics of the datasets to which the CoInception framework is applied. This adaptability feature allows the CoInception network to flexibly adjust to various datasets and tasks.\nIt's worth mentioning another potential concern, constructively mentioned by Reviewer CkvB: the risk of over-smoothing effect in CoInception when high-frequency components are informative for representing the original series. We efficiently address it with our Triplet loss regularization term by prioritizing alignment between two raw overlapped series. Further details on this matter can be found in our original response to the first question posed by Reviewer CkvB. \n\nWith these responses, we hope that we have addressed all of your current concerns. Should you need any other clarification, please leave a comment and we are happy to further discuss with you. Given your appreciation for the CoInception encoder design and our comprehensive experiments, we sincerely hope that once all your concerns are resolved, you may reconsider the paper, potentially increasing your score and supporting our approach. Thank you for your time and consideration."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3667/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699986994658,
                "cdate": 1699986994658,
                "tmdate": 1699986994658,
                "mdate": 1699986994658,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CpQ8T2YRAn",
                "forum": "KKZaj2QS3G",
                "replyto": "9m0UYlOBYC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3667/Reviewer_CP3P"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3667/Reviewer_CP3P"
                ],
                "content": {
                    "comment": {
                        "value": "Dear authors, \n\nThanks for your response and the revisions made to the manuscript.\n\nI can see you removed the previous two references for \"the noise-like elements, which appear in high frequency spectrum of the original series\". I understand that your paper specifically addresses the challenge posed by noise induced by high-frequency components, and this seems to be a general issue in many time series data. But without legitimate citations or empirical evidence regarding high-frequency noise, I still cannot fully understand the source of performance gain of your proposed method.\n\nThe writing of the revised version seems to be improved.\n\nRegarding my inquiry about the characteristics of datasets where your proposed method might work well, I was hoping to gain more insights into the circumstances under which your approach outperforms others. Acknowledging that there is no universally \"best\" model applicable to all datasets, discussing scenarios or types of data where your method is particularly advantageous would be valuable. This information would guide potential users in making informed decisions about when to employ your method.\n\nI have updated my score.\n\nBest,"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3667/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700369452447,
                "cdate": 1700369452447,
                "tmdate": 1700369452447,
                "mdate": 1700369452447,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "xHXYO0MD83",
            "forum": "KKZaj2QS3G",
            "replyto": "KKZaj2QS3G",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3667/Reviewer_UsRW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3667/Reviewer_UsRW"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents \"CoInception,\" a framework for time series representation learning that is both noise-resilient and efficient. Recognizing the challenges in time series analysis such as the presence of noise and the need for lightweight yet robust encoders, the authors present a novel sampling strategy alongside an encoder architecture designed to enhance noise resilience and task performance. Their sampling strategy utilizes a spectral low-pass filter to generate noise-invariant representations, ensuring that key time series features are preserved while reducing the influence of noise. For encoding, they combine Inception blocks with dilated convolutions to capture long-range dependencies within a scalable network architecture that remains computationally efficient.\nThe proposed framework is validated through experiments, showing superior performance in forecasting, classification, and anomaly detection tasks compared to existing methods. CoInception achieves this with fewer parameters, highlighting its efficiency."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper certainly represents a significant amount of work by the authors, especially in the experimental section. The related work section is also extensive."
                },
                "weaknesses": {
                    "value": "The paper does not do a good job positioning itself in the vast literature of timeseries modeling. It is not clear how the paper extends the state of the art in this area, and whether/how the proposed method is new compared to some fairly basic signal processing concepts, such as low-pass filtering to reduce noise."
                },
                "questions": {
                    "value": "The paper does not do a good job positioning itself in the vast literature of timeseries modeling. Some key statements in the paper show this issue more clearly. For example:\n\n\"A common shortcoming emerges in existing methods: none explicitly address noise in time series data alongside an appropriate strategy for handling this unwanted signal. Unlike other data types, real-world time series often harbor substantial noise, severely impacting task accuracy\"\n\nThis statement is hard to accept. Of course all or most prior work in this area considers that the time series will be noisy. This is one of the main reasons we use neural networks, as opposed to other models that are much less capable to deal with noisy data. \n\nThen, there are some sentences that are hard to understand. For example: \n\n\"we devise a sampling strategy based on the insight that the noisy signal combined with the original series shouldn\u2019t disrupt time series frameworks. In essence, frameworks should produce consistent representations given noise-free or raw series (noise-resiliency characteristics).\"\n\nWhat \"Frameworks\" are the authors talking about? \n\nAdditionally, there are some aspects of the model, or claims about the model, that are very basic but they are presented as an important technical contribution. For example:\n\n\"To achieve this, we shift our focus from the temporal domain to the spectral domain. Here, we employ a spectrum-based low-pass filter to create correlated yet distinct views of each input time series. These augmented views serve as positive samples of the raw series, effectively capturing the desired noise invariance. The advantages of this low-pass filter-based augmentation are twofold: (1) the filter preserves key characteristics such as trend and seasonality, ensuring deterministic and interpretable representations; (2) it eliminates noise-prone high-frequency components, improving noise resilience and enhancing downstream task performance by aligning the raw signal representation with the augmented view\"\n\nOf course there is nothing particularly new in the previous paragraph. Working in the spectral domain and performing LPF to remove high-frequency noise are elementary operations that are typically taught at the level of undergraduate signal processing courses. \n \nConsidering the previous weaknesses, it is hard to provide specific technical comments to the authors, given that (at least to this reviewer) it is not clear if the paper has something really new to contribute in the area of timeseries modeling."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3667/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3667/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3667/Reviewer_UsRW"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3667/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699018487379,
            "cdate": 1699018487379,
            "tmdate": 1699636323179,
            "mdate": 1699636323179,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Jp8nPttCQi",
                "forum": "KKZaj2QS3G",
                "replyto": "xHXYO0MD83",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3667/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3667/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer UsRW"
                    },
                    "comment": {
                        "value": "Thank you for dedicating your time and effort to reviewing our paper. We appreciate your understanding of the work amount we invested in this study. At the same time, we are sorry that you found our claims being vague in this version. Here, we aim to address and clarify these concerns in our subsequent responses to specific questions and points you made. Besides the responses, we have uploaded our revised manuscript and appendix, with all the revisions and additional details made based on your constructive feedback. If further clarification is required, please feel free to leave a comment, and we would be delighted to engage in a discussion with you.\n\nRegarding our position in time series modeling literature, we kindly direct you to our common response to all Reviewers, where we offer a concise summary of all the contributions presented in our work. Furthermore, we assure you that in the revised version, we will exercise our utmost care to mitigate any potential ambiguity or misunderstanding arising from the choice of words.\n\n*1. Regarding how to deal with noises in time series data*\n\nWhile we agree with you that the intentional use of Neural Networks is partially attributed to their ability to cope with noise, we want to emphasize that this effort may not be sufficient to effectively diminish the impact of noise, especially when our goal is to produce robust and resilient time series representations. \nWe visually highlight this point through Figure 2 in the manuscript. Considering the visually negligible impact of noise on the original series in this figure, we expect the fundamental characteristics in the learned representation to remain intact. However, we acknowledge the inconsistent representations generated by an existing State of The Art framework when presented with raw and noise-added series. This experiment is one of our motivations for explicitly considering noise resilience as a crucial characteristic of learned representations in the design of the CoInception framework.\n\n\n*2. What \"Frameworks\" are the authors talking about?*\n\nIn these specific sentences, our intention is to underscore that the presence of noise in raw series should not impact the representations learned for the true underlying series under investigation. The term \"frameworks\" encompasses generic models aimed at producing robust time series representations for various downstream tasks.\nTo enhance clarity, we revise the sentences as follows, and will accordingly update them in the revised manuscript:\n\"we devise a sampling strategy guided by the principle that the presence of noise in the series should not hinder the functionality of our framework. Ideally, it should generate consistent representations whether provided with noise-free or raw series, highlighting noise-resiliency characteristics\"\n\n*3. Regarding the basic aspects of the model but are presented as technical contributions*\n\nWe apologize if you have the impression that these basic aspects are the technical contributions of our paper. However, we think this is just a misunderstanding and we have revised our writing to make sure there would be no confusion. As you rightly noted, this Low Pass Filter is well-established and extensively studied over its long history. Instead, we highlight its advantageous applications in the context of time series representation learning, aligning well with our initial goal: ensuring noise resilience characteristics. Furthermore, our current implementation of the LPF in the sampling stage effectively isolates it from other modules within the CoInception framework. Thus, the LPF serves as a tool assisting in achieving the ultimate goal of learning noise resiliency, and it can be replaced by any filters or modules that function to reduce potential noise in the given raw series, while other CoInception modules remain intact.\n\nFinally, we hope our answers address all of your questions. Given your acknowledgment of the effort invested in this study, we hope that once all your concerns are resolved, you may reconsider the paper, potentially increasing your score and supporting our approach. Thank you for your time and consideration."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3667/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699986846750,
                "cdate": 1699986846750,
                "tmdate": 1699986846750,
                "mdate": 1699986846750,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UINfbJjs7v",
                "forum": "KKZaj2QS3G",
                "replyto": "5Pmb3gdWF8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3667/Reviewer_UsRW"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3667/Reviewer_UsRW"
                ],
                "content": {
                    "title": {
                        "value": "My initial concerns remain."
                    },
                    "comment": {
                        "value": "Dear Authors, \n\nOn one hand, I appreciate that you have put a large effort in trying to address the reviewers' concerns (including mine) by providing lengthy explanations, additional experiments, etc. \n\nMy main concerns about the paper, namely that it does not make a significant contribution in the vast literature of representation learning for time series, remains as that cannot be addressed with some more explanations or few additional experiments."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3667/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700636086752,
                "cdate": 1700636086752,
                "tmdate": 1700636086752,
                "mdate": 1700636086752,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "SXhf5YuTlv",
            "forum": "KKZaj2QS3G",
            "replyto": "KKZaj2QS3G",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3667/Reviewer_CkvB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3667/Reviewer_CkvB"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a novel framework called CoInception for time series representation learning. It addresses the challenges of noise and lack of efficient encoder architectures in time series tasks. The framework utilizes a noise-resilient sampling strategy and an encoder architecture with dilated convolution within the Inception block. Experimental results show that CoInception outperforms state-of-the-art methods in forecasting, classification, and anomaly detection tasks. The authors investigates the existence and impacts of noise in time series representation learning and introduces a noise-resilient sampling strategy to learn consistent representations despite the noise."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Originality: The paper introduces a novel noise-resilient sampling strategy and an efficient encoder architecture, which are not explicitly considered in previous works. It investigates the existence and impacts of noise in time series representation learning, addressing a critical factor that affects the efficacy of time series tasks.\n\nQuality: The authors provide empirical validation of the proposed CoInception framework and compares it with recent state-of-the-art methods, demonstrating consistent outperformance in forecasting, classification, and anomaly detection tasks. The experiments highlight the effectiveness of the framework in learning informative representations robust to various downstream tasks.\n\nClarity: The paper clearly presents the motivation, challenges, and contributions of the research, as well as the design principles of the framework. It also provides a comprehensive evaluation of the proposed method, highlighting the best results for better comparison.\n\nSignificance: The authors address the gap in existing works by exploring the potential of unsupervised representation learning in time series data. The proposed framework offers a solution for learning informative representations without the need for costly and difficult labeling, particularly in privacy-sensitive fields like healthcare and finance. The experimental results demonstrate the superiority of the proposed method over state-of-the-art approaches, indicating its significance in advancing time series analysis."
                },
                "weaknesses": {
                    "value": "1.This paper appears to be making modifications on top of TS2Vec, incorporating a denoising module and enhancing the encoder, which limits the novelty of this paper.\n\n2.The authors do not provide a detailed analysis of the limitations and potential drawbacks of the proposed noise-resilient sampling strategy and encoder architecture. This could hinder a deeper understanding of the trade-offs and potential challenges in implementing and applying the CoInception framework in real-world scenarios.\n\n3.Lack of comparison with more recent and diverse state-of-the-art methods in time series representation learning, beyond the ones mentioned in the paper. This could limit the comprehensive evaluation of the proposed CoInception framework and its performance against a wider range of approaches."
                },
                "questions": {
                    "value": "1. In real-world time series data, there may be some high-frequency components. As mentioned by the authors, the DWT method in this paper is capable of filtering out high-frequency noise. How can useful high-frequency data be preserved and what trade-offs are made in addressing this issue?\n\n2. Could you provide a clearer explanation of the Inception Block in the Method section, including an explanation of the meanings of variables like $b$ and $h$ in Figure 3 (a), as well as the significance of the numbers in brackets? This would help in better understanding this paper.\n\n3. The comparison with baselines could be more comprehensive. I believe it would be more convincing if the authors could compare their method to recent approaches from the past two years, such as TimesNet [1].\n\n[1] Wu, Haixu, et al. \"TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis.\" The Eleventh International Conference on Learning Representations. 2022."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3667/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699066265411,
            "cdate": 1699066265411,
            "tmdate": 1699636323115,
            "mdate": 1699636323115,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PwCIHP3lMO",
                "forum": "KKZaj2QS3G",
                "replyto": "SXhf5YuTlv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3667/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3667/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer CkvB"
                    },
                    "comment": {
                        "value": "We appreciate your precious comments and thank you for your recognition of our work on multiple aspects. We hope that our responses below answer all of your questions. Besides the responses, we have uploaded our revised manuscript and appendix, with all the revisions and additional details made based on your constructive feedback. Should you need any other clarification, please leave a comment and we are happy to discuss with you. \n\n*1. Regarding the novelty of this paper.*\n\nWe agree that there are some alignments of our proposal with the previous work - TS2Vec, and understand your concern. However, we want to make further clarifications that those alignments are not overlapping with our contributions. \n- First, our novel noise-resilience sampling strategy is driven by its distinguished motivations. Concurrently, we ensure context-invariant characteristics through a modified version of the technique introduced with TS2Vec. The rationale behind this modification is well-founded, addressing potential collapses in certain scenarios, with detailed explanations provided in our Appendix A.1.\n- Second, it is important to note that the stacked Dilated Convolutional network itself is not a new concept and has been employed in prior works (e.g. [1]). We leverage and build upon this existing framework, as it aligns with our stated objective of achieving both robustness and efficiency.\n\n*2. Detailed analysis of the limitations and potential drawbacks of the proposed approach*\n\nThank you for this suggestion. We hope to discuss this with you. We do rely on some assumptions as well as make some considerations upon designing the CoInception framework, which might be its limitations and potentially lead to drawbacks in some scenarios, listed below:\n- Regarding the DWT-based sampling strategy, our focus on high-frequency noise implicitly confines the type of noise being targeted in this study. By removing the high-frequency components, the filter helps to smooth out the signal and eliminate rapid fluctuations caused by noise, while better revealing the underlying trends or slow-varying patterns in the time series. However, this strategy does not guarantee to create an ideal noise-free signal of the series.\n- Regarding the encoder architecture, our current design, while making a positive step toward balancing efficiency and effectiveness, only partially attains this objective. Despite the automation of scaling dilation factors with the Inception idea, the challenge of optimizing the number of layers remains unanswered. This issue is inherent in the efficiency-effectiveness trade-off, indicating that we have not fully realized our goal. Presently constrained to a 3-layer encoder, we make no claim about the optimal number of layers to be used, recognizing the need for fine-tuning based on specific tasks or datasets.\n\nGiven these insights, we will certainly take these factors into account for future work. Due to space limitations, we plan to incorporate these reflections in a dedicated section titled \"Discussion\" within the Appendix of the modified manuscript.\n\n\n*3. Regarding comparison with other state-of-the-art methods*\n\nWe thank you for your suggestion, and we cite more references in our revised manuscript in the literature reviews section. We are working to add these methods into our experiments. However, due to the short rebuttal time and extensive experiments, we can not guarantee that such comparisons appear within the time period. Nevertheless, we will do our best to add the empirical comparisons (including TimesNet) in the next version of our manuscript. \n\n*4. Regarding high-frequency noise and trade-offs in addressing this issue*\n\nWe account for this scenario in the design of the CoInception framework and address it implicitly through the introduction of a Triplet loss regularization term, detailed in Section 2.3 of the revised manuscript. Specifically, if the vital information of the original series is predominantly in the high-frequency spectrum, solely aligning raw samples' representations with disturbed ones could result in substantial information loss. The Triplet loss regularization term mitigates this effect by giving more priority to the alignment between two raw overlapped samples, thus alleviating the loss of essential information. Empirical results presented in Table 4 highlight the detrimental impact of ablating this Triplet term."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3667/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699986615591,
                "cdate": 1699986615591,
                "tmdate": 1699986615591,
                "mdate": 1699986615591,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "AJDS4f9wU6",
            "forum": "KKZaj2QS3G",
            "replyto": "KKZaj2QS3G",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3667/Reviewer_sMvT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3667/Reviewer_sMvT"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new approach to time series analysis called CoInception, which integrates a noise-resilient sampling strategy with an efficient encoder architecture. The proposed method outperforms state-of-the-art methods in forecasting, classification, and abnormality detection tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed method outperforms the baselines in forecasting, classification, and abnormality detection tasks. This demonstrates the effectiveness of the proposed approach. \n\n2.  The paper conducts comprehensive experiments to evaluate the efficacy of CoInception and analyze its behavior. This provides a thorough understanding of the proposed method and its strengths and weaknesses of each components.\n\n3. The paper introduces a new approach to time series analysis that integrates a noise-resilient sampling strategy with an efficient encoder architecture. This approach has not been explored before."
                },
                "weaknesses": {
                    "value": "1. The paper may not compare the proposed method with other state-of-the-art methods, making it difficult to assess its effectiveness. PatchTST, DLinear, TimesNet, all these SOTA methods are recommended to be included in the forecasting task.\n\n2. The method section lacks originality, as it comprises three components from existing methods, and it lacks a coherent rationale for the integration of these three modules."
                },
                "questions": {
                    "value": "1. Add PatchTST and DLinear baselines\n2. The design of CoInception is not based on downstream tasks, why it works well on all three tasks? any insights?\n3. What is the reason for using Inception as the backbone model?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 6,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3667/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699242469262,
            "cdate": 1699242469262,
            "tmdate": 1699636323025,
            "mdate": 1699636323025,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "rPnx94mmoC",
                "forum": "KKZaj2QS3G",
                "replyto": "AJDS4f9wU6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3667/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3667/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer sMvT"
                    },
                    "comment": {
                        "value": "Thank you so much for your time and your evaluations of our paper. We are glad that you think our empirical studies are comprehensive and provide thorough understanding. Besides the responses, we have uploaded our revised manuscript and appendix, with all the revisions and additional details made based on your constructive feedback. We hope to discuss about the originality and novelty of our work which we try to clarify in the following responses to specific questions and concerns:\n\n*1. Regarding comparison with other state-of-the-art methods*\n\nWe express our gratitude to you for sharing the three interesting studies, and we have completed the reading of these remarkably interesting works. We cite these references in our revised manuscript in the literature reviews section. We are working to add these methods into our experiments. However, due to the short rebuttal time and extensive experiments, we can not guarantee that such comparisons appear within the time period. Nevertheless, we will do our best to add the references to the experiments in the next version of our manuscript. \n\n*2. Regarding our CoInception backbone model and originality*\n\nOur sampling strategy is intentionally decoupled from the encoder architecture, and there are several benefits of making them modular.\n- For the sampling strategy, as you mentioned, we use an existing method - DWT low pass filter, hence it is not our main focus in this work. With the independent nature of this module, a different noise-canceling methodology, which is more suitable for particular tasks or datasets, can be installed in a plug-and-play manner, without affecting the function of the Encoder.\n- For the Encoder architecture, with this modular design, it carries no assumption about the data as well as the task being dealt. This nature, together with its design in accordance with our intention of balancing out between effectiveness and efficiency, explain for its robustness in both three tasks and various datasets discussed in our Experiment section. In addition, owing to the modular nature, any future studies can refer to our work and be benefited from our Encoder architecture without tied assumptions.\n\nThat being said, inside each of these modules, there are strict connections between sub-components.\n- Regarding the sampling strategy, it should not be viewed in isolation within our framework. Instead, it should be integrated with our objectives, as represented by the loss functions. In addition to temporal-wise and instance-wise loss functions, which align samples from raw and disturbed series, we introduce an additional term acting as a regularization factor. This serves to stabilize the training process and mitigate the over-smoothing effect. The combination of the sampling stage and loss functions guides the CoInception framework in learning noise-resilient representations.\n\n- Concerning the Inception and Dilated Convolution architecture, their interaction ensures enhanced efficiency and effectiveness. The stacked Dilated Convolutional architecture has a notable weakness related to the selection of dilation factors. When these factors are too small, the parameter-efficient gain from dilation diminishes, and if they are too large, the framework overly focuses on a broad range of contextual information, potentially neglecting local details due to skipped spatial locations and limitations on the number of kernel filters used.\nTo address this challenge, we incorporate the Inception idea into our Encoder. The Inception design naturally serves as a solution to automate the incorporation of various dilation factors in a single layer. By introducing different dilation factors of varying sizes into a single layer, our aim is to capture both local and global context without going too deep vertically into the number of network layers, while also reaching a large receptive field.\n\nIn conclusion, we hope that our responses have sufficiently addressed all of your questions. We appreciate your favorable evaluations of our paper. Once all your concerns have been resolved, we sincerely hope for your consideration in increasing your score and offering your support. Thank you again for your time and consideration."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3667/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699986344458,
                "cdate": 1699986344458,
                "tmdate": 1699986344458,
                "mdate": 1699986344458,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]