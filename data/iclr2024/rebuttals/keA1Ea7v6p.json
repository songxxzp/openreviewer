[
    {
        "title": "Federated Learning Empowered by Generative Content"
    },
    {
        "review": {
            "id": "738Dz1090c",
            "forum": "keA1Ea7v6p",
            "replyto": "keA1Ea7v6p",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1145/Reviewer_kS7r"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1145/Reviewer_kS7r"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes an idea of adding generated data to local client datasets in federated learning to improve local model performances. Coined under the name FedGC but the framework is basically the standard federated learning framework plus data generation for local clients. In data generation, the paper focuses on 4 aspects: budget allocation, prompt design, generation guidance an training strategy. For each aspects, the authors propose 3 simple approaches. \n\nTo show the superiority of FedGC experimentally, they created a dataset with synthesized heretogeneity by merging from a few existing datasets: CIFAR-10, EuroSAT, PACS, VLCS, Sentiment140 from LEAF benchmark and Yahoo! Answers. They tested with a few federated learning frameworks including FedAvg, FedProx and SCAFFOLD and showed that with data generation, the models performed better."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The flow of the paper is clear, straightforward and easy to read. The motivation of the problem is exciting."
                },
                "weaknesses": {
                    "value": "There are a few issues in the paper.\n\n1. Other than considerations regarding generating data locally for each client (i.e. the four aspects at generating the data above), there is no significant theoretical contribution. There is no theorem, no proposal. Not a single equation is found in the paper.\n\n2. The paper solely focuses on data generation for local training. However, there is nothing in the communication among the clients that carries any information about data generation from one client to another, other than the number of samples to be generated for each client. In other words, the use of federated learning and data generation appear to be unrelated. I wonder if the whole work could have been better presented in a non-federated setting. \n\n3. In terms of data generation for each client itself, the proposed approaches for each of the 4 aspects above are simple and straightforward. I think this part of the paper is good from a practical point of view. However, it appear to be dominantly engineering contributions, which does not seem suitable for ICLR, a conference about learning representations.\n\n4. The dataset for experimenting was made up by merging from a few existing known datasets which were not designed for federated learning. Heterogeneity in the dataset was synthesized using Dirichlet distribution. This is probably one major weakness of the paper. It is questionable whether the dataset reflects real world. Results in this dataset are therefore not very convincing. I reckon the authors to use real-world datasets, or if that task is not feasible, at least use the same datasets that other federated learning approaches have used, rather than creating one of your own."
                },
                "questions": {
                    "value": "FedGC seems to be a straightforward idea of using existing generative models to generate data for learning. Doesn't that mean a related generative model has to exist for a given problem? What if no generative model exists for a given problem?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1145/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1145/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1145/Reviewer_kS7r"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1145/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698061898382,
            "cdate": 1698061898382,
            "tmdate": 1700680502185,
            "mdate": 1700680502185,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4cYVmrXo7L",
                "forum": "keA1Ea7v6p",
                "replyto": "738Dz1090c",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1145/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1145/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your time and comments.\n\n\n**General Response:** We think that the main reason of the reviewer's rejection is the seemingly simplicity of our method. However, we would like to justify for ourselves.\n\n1. We effectively mitigate the issue of one of the most critical issuses in FL: data heterogeneity. Our method is simple yet effective as verified by the **consistent and significant performance improvement**, which should not be overlooked.\n\n2. Simplicity does not equal no novelty. Our proposed FedGC framework for the **first time** training private heterogeneous data mixed with synthetic data generated by the powerful advanced generative models. Our work points out its potential and we believe that it could inspire more explorations in this topic to better address or even fully address the issue of data heterogeneity.\n\n3. We intentionally to make our framework simple and general. As the first exploration on this topic, rather than designing seemingly complicated algorithm, we decided to implement a general framework to conduct a **systematic empirical study** to provide more fundamental insights. Besides, thanks to this simplicity, our method is naturally compatible with conventional FL communication protocols such as secure aggregation and differential privacy.\n\n---\n\n**W2:** The paper solely focuses on data generation for local training. However, there is nothing in the communication among the clients that carries any information about data generation from one client to another, other than the number of samples to be generated for each client. In other words, the use of federated learning and data generation appear to be unrelated. I wonder if the whole work could have been better presented in a non-federated setting.\n\n**Response:** Focusing on data heterogeneity, we propose a new method that can effectively alleviate its negative effects. The generative data can significantlly mitigate the level of data heterogeneity and the issue of overfitting, promoting the performance of FL. Thus, it is not 'unrelated'.\n\nData heterogeneity is a representative and common issue in federated setting while in a non-federated setting there is no defination of data heterogeneity. Thus, the idea of using generative content to address data heterogeneity is quite **unique and suited for FL** but not non-FL setting. From the following table, we can see that local training (without FL) with generative content performs significantly worse.\n\n[**Table R1.** Performance comparison between local training with generative content and our FedGC.]\n| Method | CIFAR-High | CIFAR-Low | EuroSAT-High | EuroSAT-Low |\n|:--------:|:----------:|:---------:|:------------:|:-----------:|\n| Local+GC |   46.89    |   50.47   |    24.87     |    35.48    |\n|  FedGC   | **74.50**  | **79.93** |  **74.83**   |  **84.46**  | \n\n\nTo make the design 'more like' FL, there could be many methods following FedGC framework. For example, to mitigate the potential negative effects of dissimilarity between generative and real data, we can use soft-label supervision to train local model on generative data uwhile hard-label supervision for real data, where the soft labels come from the FL global model. We leave such methods to future works.\n\n---\n\n**W1/W3:** There is no theorem, no proposal. Not a single equation is found in the paper. I think this part of the paper is good from a practical point of view. However, it appear to be dominantly engineering contributions, which does not seem suitable for ICLR, a conference about learning representations.\n\n**Response:** \n\nFirst, federated learning itself is a practical setting and we propose a practical solution, which naturally fits the overall objective.\n\nSecond, this judgment varies from person to person. We kindly request the reviewer to refer to the following ICLR papers, where they might seem to be 'unrelated' and 'engineering' for the reviewer.\n\n[1] Chen, Hong-You, et al. \"On the importance and applicability of pre-training for federated learning.\" The Eleventh International Conference on Learning Representations. 2023.\n\n[2] Nguyen, John, et al. \"Where to Begin? On the Impact of Pre-Training and Initialization in Federated Learning.\" The Eleventh International Conference on Learning Representations. 2023.\n\n[3] Oh, Jaehoon, SangMook Kim, and Se-Young Yun. \"FedBABU: Toward Enhanced Representation for Federated Image Classification.\" International Conference on Learning Representations. 2022."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1145/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700583870567,
                "cdate": 1700583870567,
                "tmdate": 1700584127985,
                "mdate": 1700584127985,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qKw4Q8mmTo",
                "forum": "keA1Ea7v6p",
                "replyto": "738Dz1090c",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1145/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1145/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**W4:** The dataset for experimenting was made up by merging from a few existing known datasets which were not designed for federated learning?\n\n**Response:** \n\nPlease note that most of the used datasets are **quite common in federated learning literature and we follow exactly the same setting. Here are some examples.**\n\n- Sentiment140, which is from FL LEAF benchmark [1] (1052 citations).\n- CIFAR10, which is commonly used in most of FL papers [2,3,4].\n- HAM10000 [5,6,7], PACS[8,9,10].\n\n[1] Caldas, Sebastian, et al. \"Leaf: A benchmark for federated settings.\" arXiv preprint arXiv:1812.01097 (2018).\n\n[2] Chen, Hong-You, et al. \"On the importance and applicability of pre-training for federated learning.\" The Eleventh International Conference on Learning Representations. 2023.\n\n[3] Nguyen, John, et al. \"Where to Begin? On the Impact of Pre-Training and Initialization in Federated Learning.\" The Eleventh International Conference on Learning Representations. 2023.\n\n[4] Oh, Jaehoon, SangMook Kim, and Se-Young Yun. \"FedBABU: Toward Enhanced Representation for Federated Image Classification.\" International Conference on Learning Representations. 2022.\n\n[5] Thapa, Chandra, et al. \"Splitfed: When federated learning meets split learning.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 36. No. 8. 2022.\n\n[6] Yang, Fu-En, Chien-Yi Wang, and Yu-Chiang Frank Wang. \"Efficient model personalization in federated learning via client-specific prompt generation.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023.\n\n[7] Pennisi, Matteo, et al. \"Experience Replay as an Effective Strategy for Optimizing Decentralized Federated Learning.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023.\n\n[8] Zhang, Ruipeng, et al. \"Federated domain generalization with generalization adjustment.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n\n[9] Nguyen, A. Tuan, Philip Torr, and Ser Nam Lim. \"Fedsr: A simple and effective domain generalization method for federated learning.\" Advances in Neural Information Processing Systems 35 (2022): 38831-38843.\n\n[10] Chen, Haokun, et al. \"Fraug: Tackling federated learning with non-iid features via representation augmentation.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023.\n\n---\n\n**Q:** Doesn't that mean a related generative model has to exist for a given problem? What if no generative model exists for a given problem?\n\n**Response:** \n\nCurrently, there has been many generative models for many domains, which is why we think it is interesting and timely to explore this topic. \n\nBesides, the generative model does not neccessarily need to fully resemble real data. Here are our evidence.\n\n1. The experiments on **medical dataset HAM10000 in Table 4**. Since stable diffusion can not generate medical with good quality, we choose this experiment to alleviate the concern of contamination. Please note that the generated images are completely different from the real iamges and we decided not to posting them to avoid causing discomfort. Here, we put the results below for convinience. **Despite the dissimilarity, our method still brings significant gain.**\n\n[**Table R2.** Results on medical dataset.]\n| Baseline | Without FedGC | With FedGC |\n| :------: | :-----------: | :--------: |\n| FedAvg   | 48.57         | **56.67**      |\n| FedProx  | 49.52         | **56.19**      |\n| SCAFFOLD | 54.76         | **58.57**      | \n\n2. The experiments of training on **generated data only in Table 6.** Here, we put the results below for convinience. From the table, we see that **merely using generative data to train a model fail to perform well**, indicating that there is a huge gap between generative data and real data. Generated data can only exhibit its effectiveness when used in conjunction with real data in our proposed FedGC.\n\n[**Table R3.** Comparisons with training on genrative data only. Training on generative data only achieves low performance.]\n| Baseline | Real Data | Generative Data | FedGC (ours) |\n|:--------:|:---------:|:---------------:|:------------:|\n|  FedAvg  |   60.77   |      41.85      |  **73.99**   |\n| FedProx  |   63.62   |      40.93      |  **73.69**   |\n| SCAFFOLD |   65.00   |      43.45      |  **75.79**   |\n\n3. We compare real data and generative data in Figure 8 via visualization, where we see that there is a large amount of generative data with incorrect concept and can not fully represent real data.\n\n\n---\n\nOverall, we thank the reviewer for the time for reviewing. We hope that our responses can fully address your concerns. We also kindly request the reviewer for reconsideration and look forward to your feedback to improve our work."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1145/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700583930437,
                "cdate": 1700583930437,
                "tmdate": 1700583930437,
                "mdate": 1700583930437,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xS3nGVWvB9",
                "forum": "keA1Ea7v6p",
                "replyto": "738Dz1090c",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1145/Reviewer_kS7r"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1145/Reviewer_kS7r"
                ],
                "content": {
                    "title": {
                        "value": "Response to W2"
                    },
                    "comment": {
                        "value": "I thank the authors for their comments. They largely address my concerns. Unfortunately due to time constraints I will not be able to discuss all points at once. I will try to tackle one by one.\n\nRegarding your response to W2, maybe I was not clear in explaining my concern. The problem of data heterogeneity is very unique to FL. This is a major problem. I am aware of that. But it is not what I was concerned. I was concerned with the proposed solution where the data generation process is almost independent from one client to another. I was hoping that FedGC would do something smarter than existing FL approaches such that it can somehow pass some knowledge related to its local data distribution or the knowledge of how the local generated data were generated to other clients in the hope that they can use that knowledge to learn their own classification problem better. But it would not. Hence, it appears the federated setting here is unnecessary to the idea that the paper is promoting, which is to use generative models to generated data, other than to bring the data heterogeneity problem into the context.\n\nIn the new Table R1 you provided, do you have a row representing the results of local training without using generated content? How do they compare to Local+GC results? I suspect Local+GC should outperform Local (without GC). Going from Local to Local+GC can tell us how much the gain comes from generated content alone, and then from Local+GC to FedGC can tell us further how much we get when the gradients are communicated."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1145/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700669246384,
                "cdate": 1700669246384,
                "tmdate": 1700669246384,
                "mdate": 1700669246384,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YuknobI3ok",
                "forum": "keA1Ea7v6p",
                "replyto": "738Dz1090c",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1145/Reviewer_kS7r"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1145/Reviewer_kS7r"
                ],
                "content": {
                    "title": {
                        "value": "Response to W1/W3"
                    },
                    "comment": {
                        "value": "W1: I am glad that you acknowledge that federated learning itself is a practical setting. While you have shown that in your datasets, the experimental results when additional generated content was used increase the accuracy, the problem I see is that it only says that for these datasets FedGC works. Without some sort of theoretical statements about the generalisation of FedGC to other datasets, it is hard to understand how well FedGC would work in a new setting.\n\nW3: You are right. I have overlooked. I will increase my rating."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1145/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700669885023,
                "cdate": 1700669885023,
                "tmdate": 1700670065581,
                "mdate": 1700670065581,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TwMtKXeytp",
                "forum": "keA1Ea7v6p",
                "replyto": "f5FAafkwm4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1145/Reviewer_kS7r"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1145/Reviewer_kS7r"
                ],
                "content": {
                    "title": {
                        "value": "Thank you. I've updated my ratings."
                    },
                    "comment": {
                        "value": "Thank you for your very prompt but detailed comments. All my concerns are properly addressed.\n\nI would like to thank the authors for having been patient with me throughout the rebuttal period and politely corrected me where I was wrong. All your comments are very helpful. I clearly overlooked this good paper during the review period. No excuse for that. I have updated my overall rating to 8. Good paper."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1145/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700680786876,
                "cdate": 1700680786876,
                "tmdate": 1700680786876,
                "mdate": 1700680786876,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7ViRqM6mdx",
            "forum": "keA1Ea7v6p",
            "replyto": "keA1Ea7v6p",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1145/Reviewer_c8uL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1145/Reviewer_c8uL"
            ],
            "content": {
                "summary": {
                    "value": "The paper explores whether the data heterogeneity issues in federated learning (that limits its performance) could be mitigated by adding synthetic data generated via generative models. The authors first conduct experiments on two image datasets (CIFAR-10 and EuroSAT) and two language datasets (PACS and VLCS) to show that the performance of federated learning significantly improves after combining the private training data with new data that are generated based on the guidance of prompts and private data simultaneously. Interestingly, the authors also observe reduced privacy risk in FL after adding generated data, where the privacy risk means the average success of simple loss-based membership inference attacks over different clients. Algorithmically, the authors conduct extensive experiments and attributed the success of the method to four critical choices: amount of generative contents, the same amount of generative contents for each user, using multiple prompts to guide data generation; and simultaneously use text prompts and real private data for generation. \n\nTo further understand the reason for the performance gain, the authors additionally conduct several interesting ablation studies, where the central conclusions are:\n- The performance improvement exists even when the generated data is not similar to the private data.\n- Adding generative contents reduced data heterogeneity, and under a higher amount of generative contents, the performance of FedAvg becomes better or on par with other algorithms that are designed to tackle data heterogeneity (such as FedProx and SCAFFOLD).\n- Adding generative contents reduces the client drift effect in FL."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Thorough experiments that investigate the algorithmic choices and how federated learning is affected under new generative data.\n- Mitigating the issues due to data heterogeneity in FL is an important question, and exploring how large generative models could alleviate such issues is a timely and vital direction."
                },
                "weaknesses": {
                    "value": "- On the one hand, the authors show that increasing the amount of generative data always increases the learning performance (Table 2 and Figure 2). On the other hand, the authors also show that FL on only generative contents (no private data) performs poorly in Table 5. This seems counterintuitive. Could the authors explain why? \n\n- If we allow each user to train a local model on its private data combined with generative contents, would the performance be comparable to FL training on private data combined with newly generated data? If so, there would not be any incentive for clients to perform FL when they have access to additional generative content, thus deeming the problem setting as insignificant."
                },
                "questions": {
                    "value": "- See weakness for two questions.\n\n- Additionally, could authors discuss the possible dataset contamination? That is, whether the benchmark dataset is already used in training dataset for the generative model."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1145/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1145/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1145/Reviewer_c8uL"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1145/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698510068519,
            "cdate": 1698510068519,
            "tmdate": 1700722294747,
            "mdate": 1700722294747,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6yvheaJCsD",
                "forum": "keA1Ea7v6p",
                "replyto": "7ViRqM6mdx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1145/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1145/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your time for reviewing and your comments. Here are our detailed responses.\n\n---\n\n**W1:** On the one hand, the authors show that increasing the amount of generative data always increases the learning performance. On the other hand, the authors also show that FL on only generative contents performs poorly in Table 5. This seems counterintuitive. Could the authors explain why?\n\n**Response:** \n\nThat is a good point. Acturally, **they are not counterintuitive. Please note that in Table 2, the performance of using 50000 samples is worse than performance of using 20000 samples.**\n\nHere is the rationale. (1) First, the results showing that only generative contents performs poorly indicates that the generative data cannot fully represent real data. (2) Second, when generative data is combined with real heterogeneous data, the generative data serves to mitigate data heterogeneity and overfitting issue. Therefore, the performance is increased after adding generative data.\n\nHowever, when the number of generative samples is too large, the issue of dissimilarity between generative and real data tends to bring negative effects.\n\n\n[**Table R1.** Performance under different number of generative samples.]\n| Baseline |   0   | 1000  | 10000 |   20000   | 50000 |\n|:--------:|:-----:|:-----:|:-----:|:---------:|:-----:|\n|  FedAvg  | 61.25 | 66.98 | 74.50 | **76.93** | 76.39 |\n| FedProx  | 64.02 | 68.55 | 74.36 | **76.81** | 76.73 |\n| SCAFFOLD | 63.98 | 71.33 | 73.96 | **74.88** | 73.98 |\n\n---\n\n**W2:** If we allow each user to train a local model on its private data combined with generative contents, would the performance be comparable to FL training on private data combined with newly generated data?\n\n**Response:** \n\nThanks for this insightful comment. Following your advice, we have conducted the following experiments. From the table, we see that there is still a **huge gap between local training and FedGC**, thus incentivizing clients to participate federated learning.\n\n[**Table R2.** Performance comparison between local training with generative content and our FedGC.]\n| Method | CIFAR-High | CIFAR-Low | EuroSAT-High | EuroSAT-Low |\n|:--------:|:----------:|:---------:|:------------:|:-----------:|\n| Local+GC |   46.89   |   50.47   |    24.87     |    35.48    |\n|  FedGC   | **74.50**  | **79.93** |  **74.83**   |  **84.46**  | \n\n---\n\n**Q:** Additionally, could authors discuss the possible dataset contamination? That is, whether the benchmark dataset is already used in training dataset for the generative model.\n\n**Response:** Sure, we also take this factor seriously and that is why we have shown the following results in the submission.\n\n\n1. The experiments on **medical dataset HAM10000 in Table 4**. Since stable diffusion can not generate medical with good quality, we choose this experiment to alleviate the concern of contamination. Please note that the generated images are completely different from the real iamges and we decided not to posting them to avoid causing discomfort. Here, we put the results below for convinience. **Despite the dissimilarity, our method still brings significant gain.**\n\n[**Table R1.** Results on medical dataset.]\n| Baseline | Without FedGC | With FedGC |\n| :------: | :-----------: | :--------: |\n| FedAvg   | 48.57         | **56.67**      |\n| FedProx  | 49.52         | **56.19**      |\n| SCAFFOLD | 54.76         | **58.57**      | \n\n2. The experiments of training on **generated data only in Table 6.** Here, we put the results below for convinience. From the table, we see that **merely using generative data to train a model fail to perform well**, indicating that there is a huge gap between generative data and real data. Generated data can only exhibit its effectiveness when used in conjunction with real data in our proposed FedGC.\n\n[**Table R2.** Comparisons with training on genrative data only. Training on generative data only achieves low performance.]\n| Baseline | Real Data | Generative Data | FedGC (ours) |\n|:--------:|:---------:|:---------------:|:------------:|\n|  FedAvg  |   60.77   |      41.85      |  **73.99**   |\n| FedProx  |   63.62   |      40.93      |  **73.69**   |\n| SCAFFOLD |   65.00   |      43.45      |  **75.79**   |\n\n3. We compare real data and generative data in Figure 8 via visualization, where we see that there is a large amount of generative data with incorrect concept and can not fully represent real data.\n\n---\n\nOverall, we hope that our responses can fully address your concerns and will be grateful for any feedback."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1145/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700583834699,
                "cdate": 1700583834699,
                "tmdate": 1700583998039,
                "mdate": 1700583998039,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jT6VD00uqX",
                "forum": "keA1Ea7v6p",
                "replyto": "7ViRqM6mdx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1145/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1145/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We sincerely anticipate your feedback as the Discussion phase will conclude in 16 hours."
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nWe have carefully considered your comments and provided further clarifications and explanations in detail. We have:\n\n- Shown clear evidence that the results in Table 2 and Table 6 are not counterintuitive.\n- Provided experimental results to verify sufficient incentive for clients to participate FL.\n- Provided our detailed discussion on dataset contamination.\n\n As Discussion phase will end in 16 hours, we would be grateful if you could check our responses and reconsider your rating.\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1145/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700683542739,
                "cdate": 1700683542739,
                "tmdate": 1700683542739,
                "mdate": 1700683542739,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4MqsGEMer4",
                "forum": "keA1Ea7v6p",
                "replyto": "jT6VD00uqX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1145/Reviewer_c8uL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1145/Reviewer_c8uL"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the response. Most of my concerns are addressed. I've increased the score. Minor comments about the comparison between local training + generative data versus FL + generative data, it would be good to know whether the total number of generative data is kept the same for each client."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1145/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700722250491,
                "cdate": 1700722250491,
                "tmdate": 1700722250491,
                "mdate": 1700722250491,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rfngCHBeWU",
            "forum": "keA1Ea7v6p",
            "replyto": "keA1Ea7v6p",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1145/Reviewer_kHC9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1145/Reviewer_kHC9"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed FedGC, a synthetic-data-based federated learning system. In high-level speaking, FedGC utilized the foundational model on the local side to generate synthetic data, and mixed the synthetic data with real private data for local training. The experiments with both language and computer vision benchmark datasets show the effectiveness of FedGC."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. It is interesting to utilize the power of foundational models to assist federated learning.\n\n2. The experiment and ablation study are detailed."
                },
                "weaknesses": {
                    "value": "1. The author does not consider the generation cost in the paper. The Stable Diffusion model needs at least 4.2GB space to deploy locally, and the memory consumption of generation is huge for the IoT or cross-device FL setup. For the black-box foundational models such as ChatGPT, the prompts directly leak the data privacy to the server of ChatGPT. As a result, both methods do not fit the FL setups.\n\n2. The mixed-up training of synthetic and real private data directly increases the computational burden for the local devices. \n\n3. I am concerned about the in-domain generation problem. As the Stable Diffusion is trained with the LAION-5B dataset, we cannot guarantee that the Stable Diffusion does not meet with the test data, such as the CIFAR dataset, during the training. As a result, we could not distinguish whether the performance boost-up is coming from the FedGC or the in-domain generation of the foundational models."
                },
                "questions": {
                    "value": "1. How many synthetic data samples does the local client generate for the experiment in Table 1?\n\n2. During local data generation, does the local client only generate the data for the label it holds or generate the data for the whole label space among all participants?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1145/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698739187132,
            "cdate": 1698739187132,
            "tmdate": 1699636040626,
            "mdate": 1699636040626,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "iA8oJFgjZT",
                "forum": "keA1Ea7v6p",
                "replyto": "rfngCHBeWU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1145/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1145/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your time and comments. Here are our responses in detail.\n\n---\n\n**W1:** The author does not consider the generation cost in the paper. The Stable Diffusion model needs at least 4.2GB space to deploy locally, and the memory consumption of generation is huge for the IoT or cross-device FL setup. For the black-box foundational models such as ChatGPT, the prompts directly leak the data privacy to the server of ChatGPT. The method does not fit the FL setups?\n\n**Response:** \n\nForemost, we want to reiterate the emphasis of our paper: (1) the **idea** of leveraging advanced generative models to assist training on private data, and (2) the **general framework** with diverse solutions for each sub-step.\n\nRegarding the concern of generation cost, it can be easily alleviated by generating data using **online interfaces (rather than generating locally)**, which are commonly available right now (e.g., huggingface) [1]. And we can generate generate data without real-data guidance for such cases since our proposed FedGC provides diverse solutions for each generation step. In this case, **both the issues of generation burden and privacy issue are alleviated.**\n\nBesides, we acturally have recognized such potential concern so that we **do not use real-data-guidance for all the experiments except Table 4**. However, since our focus is to propose a general and multifunctional framework, we still decided to include this because such strategy can bring additional benefit if the computational resource is available.\n\n[1] https://huggingface.co/runwayml/stable-diffusion-v1-5\n\n---\n\n**W2:** The mixed-up training of synthetic and real private data directly increases the computational burden for the local devices?\n\n**Response:** There could be some misunderstanding. **Mixed training does not increase the computational burden.**\n\nPlease note that throughout our experiments, for each round, we are running with **the sample number of SGD iterations** for all clients and methods. That is, after mixing data, the used batch size and the number of SGD iterations are exactly the sample as baselines. \n\n---\n\n**W3:** I am concerned about the in-domain generation problem. We could not distinguish whether the performance boost-up is coming from the FedGC or the in-domain generation of the foundational models.\n\n**Response:** Acturally, we have put efforts to alleviate such concerns from three aspects.\n\n1. The experiments on **medical dataset HAM10000 in Table 4**. Since stable diffusion can not generate medical with good quality, we choose this experiment to alleviate the concern of in-domain generation. Please note that the generated images are completely different from the real iamges and we decided not to posting them to avoid causing discomfort. Here, we put the results below for convinience. **Despite the dissimilarity, our method still brings significant gain.**\n\n[**Table R1.** Results on medical dataset.]\n| Baseline | Without FedGC | With FedGC |\n| :------: | :------: | :------: |\n| FedAvg   | 48.57         | **56.67**      |\n| FedProx  | 49.52         | **56.19**      |\n| SCAFFOLD | 54.76         | **58.57**      | \n\n2. The experiments of training on **generated data only in Table 6.** Here, we put the results below for convinience. From the table, we see that **merely using generative data to train a model fail to perform well**, indicating that there is a huge gap between generative data and real data. Generated data can only exhibit its effectiveness when used in conjunction with real data in our proposed FedGC.\n\n[**Table R2.** Comparisons with training on genrative data only. Training on generative data only achieves low performance.]\n| Baseline | Real Data | Generative Data | FedGC (ours) |\n|:---:|:---:|:---:|:---:|\n|  FedAvg  |   60.77   |      41.85      |  **73.99**   |\n| FedProx  |   63.62   |      40.93      |  **73.69**   |\n| SCAFFOLD |   65.00   |      43.45      |  **75.79**   |\n\n3. We compare real data and generative data in Figure 8 via visualization, where we see that there is a large amount of generative data with incorrect concept and can not fully represent real data.\n\n---\n\n**Q1:** How many synthetic data samples does the local client generate for the experiment in Table 1?\n\n**Response:** The total amount for all clients is 20% of the original dataset. For example, CIFAR-10 has 50000 samples and then we will generate 10000 samples in total. Since there is 10 clients, each client will have 1000 samples.\n\n---\n\n**Q2:** During local data generation, does the local client only generate the data for the label it holds or generate the data for the whole label space among all participants?\n\n**Response:** Local client generates data for the whole label space.\n\n---\n\nOverall, we are so regret to see that the reviewer gave such a rating for our new exploration in federated learning. We hope that our responses can fully address the reviewer's concerns and would be grateful to get any useful feedback to improve our work."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1145/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700583759787,
                "cdate": 1700583759787,
                "tmdate": 1700583759787,
                "mdate": 1700583759787,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fI1mE0e44P",
                "forum": "keA1Ea7v6p",
                "replyto": "rfngCHBeWU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1145/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1145/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We sincerely anticipate your feedback as the Discussion phase will conclude in 16 hours."
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nWe have carefully considered your comments and provided further clarifications and explanations in detail. We hope that we have well address them through the provided methodological and empirical evidence. As Discussion phase will end in 16 hours, we would be grateful if you could check our responses and reconsider your rating.\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1145/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700683210443,
                "cdate": 1700683210443,
                "tmdate": 1700683210443,
                "mdate": 1700683210443,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "35xSPO8xKk",
                "forum": "keA1Ea7v6p",
                "replyto": "fI1mE0e44P",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1145/Reviewer_kHC9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1145/Reviewer_kHC9"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response. I still have concerns about the paper.\n\nW1: If the generation could be done on the cloud side, the communication cost would be very high for the client for transmitting the synthetic data. As a result, it is still unfeasible for cross-device FL setups due to the large communication burden.\n\nQ2: How would the local client know the whole label space? To be specific, under the non-iid distribution, each client has a skewed label distribution for the local data. How would the local client know the labels that it does not hold locally? If the client wants to hold whole label space information, some client-wise communication is needed and some privacy issues may be raised as well.\n\nAs a result, I prefer not to change my score."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1145/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700694010740,
                "cdate": 1700694010740,
                "tmdate": 1700694010740,
                "mdate": 1700694010740,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "47bOyCKi7t",
                "forum": "keA1Ea7v6p",
                "replyto": "rfngCHBeWU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1145/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1145/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the feedback."
                    },
                    "comment": {
                        "value": "Thanks for the further comments and here are our responses.\n\n---\n\n**W1:** If the generation could be done on the cloud side, the communication cost would be very high for the client?\n\n**Response:** Even in such cases, the communication cost is **not HIGH** as stated by the reviewer. On the contrary, the communication cost is **quite LOW**.\n\n1. Even in such cases, the additional communication cost is acturally minor and the the enhanced performance is significant. Here, we provide a detailed example on launching FedGC on SCAFFOLD on CIFAR10 in the following table. From the table, we can see that FedGC can achieve significantly higher performance than the baseline while introducing minor additional communication cost. Besides, please note that we only introduce some downlink cost rather than uplink cost, and it is commonly known that the uplink is slower at least five times than the downlink [1,2]. Specifically, **FedGC can achieve 5.07% absolute accuracy improvement while only introducing 0.007% additional communication cost!**\n\n&emsp;\n\n[**Table R3.** Communication cost per client and accuracy in cases where we use cloud generation.]\n|      Method       |  SCAFFOLD   | FedGC-100 | FedGC-200 | FedGC-1000 | FedGC-10000 |\n|:-----------------:|:-----------:|:---------:|:---------:|:----------:|:-----------:|\n| Downlink Cost (B) | 215,777,600 |  +30,720  |  +61,400  |  +307,200  | +3,072,000  |\n|  Uplink Cost (B)  | 215,777,600 |    +0     |    +0     |     +0     |     +0      |\n|  Total Cost (B)  | 431,555,200 |  +30,720  |  +61,400  |  +307,200  | +3,072,000  |\n|  Additional Cost (%)  | - |  +0.007%  |  +0.014%  |  +0.071%  | +0.712%  |\n|     Accuracy      |    63.98    |  **+5.07%**   |  **+7.35%**   |   **+7.35%**   |   **+9.98%**    |\n\n&emsp;\n\n2. To further alleviate the reviewer's concern, we provide the following table where we keep the communication cost less than baselines by reducing the communication rounds (i.e., 1-2 rounds reduction) for FedGC. From the table, **we see that even with less communication cost, FedGC still significantly outperforms the baseline!**\n\n&emsp;\n\n[**Table R4.** Accuracy comparison between FedGC and SCAFFOLD when keeping FedGC with less communication cost.]\n| Method   | SCAFFOLD | FedGC-100 | FedGC-200 | FedGC-1000 | FedGC-10000 |\n| :------: | :------: | :----: | :-------: | :---: | :----: |\n|  Total Cost (B)  | 431,555,200 |  427,270,368  |  427,301,048  |  427,546,848  | 430,311,648  |\n| Accuracy | 63.98    | **69.05%**    | **71.33%**    | **71.33%**     | **73.96%**            |\n\n&emsp;\n\n[1] Yi, Liping, Wang Gang, and Liu Xiaoguang. \"QSFL: A two-level uplink communication optimization framework for federated learning.\" ICML 2022.\n\n[2] Kone\u010dn\u00fd, Jakub, et al. \"Federated learning: Strategies for improving communication efficiency.\" arXiv preprint arXiv:1610.05492 (2016)."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1145/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700710944321,
                "cdate": 1700710944321,
                "tmdate": 1700718698353,
                "mdate": 1700718698353,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]