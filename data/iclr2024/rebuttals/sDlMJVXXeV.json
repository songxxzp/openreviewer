[
    {
        "title": "Neural varifolds: an aggregate representation for quantifying geometry of point clouds"
    },
    {
        "review": {
            "id": "eRw6XGmqRQ",
            "forum": "sDlMJVXXeV",
            "replyto": "sDlMJVXXeV",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3927/Reviewer_vDG7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3927/Reviewer_vDG7"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes neural varifold representations to characterize the geometry of point clouds. The neural varifolds combine point positions and tangent spaces to quantify surface geometry. Two algorithms are presented to compute neural varifold norms between point clouds using neural tangent kernels. The neural varifold is evaluated on shape classification, reconstruction, and matching tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The motivation for neural varifolds is well-articulated based on relevant literature from geometric measure theory and deep learning.  \n- The two proposed algorithms (PointNet-NTKI and PointNet-NTK2) to compute neural varifold are reasonable extensions of related work.\n- Experiments are conducted on standard benchmarks to evaluate different tasks, with ablation studies and comparisons to baseline methods."
                },
                "weaknesses": {
                    "value": "- The theoretical underpinnings of PointNet-NTK2 are less clear than PointNet-NTKI.\n- The performance of neural varifolds is not state-of-the-art on most tasks. \n- The network design in the manisript is relatively simple, which I am nore sure mainly results in the relatively poor performance. If so, could authors provide the design principle or experiments (if applicable) of the combination with more advanced networks to demonstrate the promising value of the proposed representation.\n- More visualizations are favorble to highlight the characteristics and advantages of the proposed approach, which could be included in the supplementary file."
                },
                "questions": {
                    "value": "- Can you elaborate more on the limitations of PointNet-NTK2 compared to PointNet-NTKI from a theoretical standpoint?   \n- How do you think the performance of neural varifolds can be further improved?\n- What are possible directions to extend this work for future research?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3927/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3927/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3927/Reviewer_vDG7"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3927/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698635067688,
            "cdate": 1698635067688,
            "tmdate": 1699636353239,
            "mdate": 1699636353239,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5H9Sw07Kgh",
                "forum": "sDlMJVXXeV",
                "replyto": "eRw6XGmqRQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer vDG7's Weakness 2"
                    },
                    "comment": {
                        "value": "##  \u2022 The performance of neural varifolds is not state-of-the-art on most tasks.\n\nWe appreciate the reviewer's remark on the manuscript. To clear some misunderstanding regarding the computational complexity and methods' performance, we would also like to refer the reviewer to our reply to reviewer wzuY and reviewer 6p7s particularly for their first question. Please see below for our further response. \n\n\nOnly for shape classification with all data, the performance of the neural varifold is not as comparable as the existing baselines like PointNet, DGCNN or more advanced methods, indicating the potential current limitation of the proposed methods in this specific case.  We would like to highlight that the performances of the proposed approaches on shape classification with  limited data, shape reconstruction and shape matching are either  better in many cases or at least comparable with other methods.\n\nIn the limited data scenario, the proposed methods are actually not computationally heavier than neural networks with respect to the training time. For example, the computational time for 5-sample training on ModelNet10 is respectively 47 and 18 seconds for PointNet-NTK1 and PointNet-NTK2, while it takes 254 and 502 seconds for training PointNet and DGCNN with a single NVIDIA 3090 GPU, respectively. Although the inference time for the standard neural network could be cheaper after training completed, considering the performance gap and computational cost for our proposed methods, it is still within acceptable range and is worth improving further.  \n\nIn the case of shape reconstruction, Table 3 in the manuscript shows that none of the baseline methods are dominating the task and that the proposed method is competitive to the baseline methods. Note that we have also included a SOTA method -- neural kernel surface reconstruction (NKSR) -- into baseline in Table 3 in our revised manuscript. In addition, we have added more visualisation of the shape reconstruction results from all baseline methods as well as our proposed method.\n\nOur proposed method can also be used to train and evaluate the similarity between two shapes. As shown in the experiment of shape matching, our proposed method can achieve competitive results with respect to all baseline metrics including popular ones (e.g., Chamfer distance and Earth Mover's distance). Moreover, we have incorporated three additional shape matching results (i.e.,  1. two hippocampi, 2. sphere to Stanford Bunny, and 3. two airplanes) into the Appendix of the revised manuscript. In all three instances, both NTK1 and NTK2 exhibit excellent results; please also refer to our response to reviewer 6p7s's second question, in which new quantitative results are provided."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700528820287,
                "cdate": 1700528820287,
                "tmdate": 1700528820287,
                "mdate": 1700528820287,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "J5JAqXcCw5",
                "forum": "sDlMJVXXeV",
                "replyto": "eRw6XGmqRQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer vDG7's Weakness 3"
                    },
                    "comment": {
                        "value": "##  \u2022 The network design in the manuscript is relatively simple, which I am not sure mainly results in the relatively poor performance. If so, could authors provide the design principle or experiments (if applicable) of the combination with more advanced networks to demonstrate the promising value of the proposed representation.\n\nThe current network designs (NTK1 and NTK2) are based on one of the most popular neural networks, PointNet, for 3D point clouds.\nThey are heavily influenced by the PointNet architecture where the neural networks consist of a series of permutation invariant operations (e.g., MLP layers, Conv1D with 1-width convolution kernel, average pooling, etc.). Therefore, the performance of the neural network might be limited by the current design of the  PointNet architecture, where local variations are hard to capture. \n\nPointNet can be viewed as a graph convolution without edge connections (i.e., isolated nodes). Neural tangent kernels on graph convolution may improve the performance on shape classification and/or shape reconstruction [2]. However, computation and memory requirement of graph neural tangent computation are currently much more expensive than that of PointNet-like architectures. Although sparse representation of graphs as well as efficient graph parallelism can resolve the computation as well as memory requirement bottleneck, it is an active area of research. In our experience, computational cost for graph convolutions is too heavy, while the performance benefits at the expense of high computational cost are limited. \n\nWe have tested a simple vanilla GNN architecture by adding an additional graph aggregation (message passing) layer on top of each layer of MLP on both PointNet-NTK1 and PointNet-NTK2. We refer these two algorithms as vanilla graph neural tangent kernel1 (vanilla-GNTK1) and  vanilla graph neural tangent kernel2 (vanilla-GNTK2), respectively.  The table below shows the performance comparison between the proposed PointNet NTKs and vanilla GNTKs. Note that PointNet-NTK1 and PointNet-NTK2 respectively take 47 and 18 seconds, while vanilla-GNTK1 and vanilla-GNTK2 respectively take 391 and 193 seconds on 5-sample ModelNet10 classification tasks. Given the computational time and performance comparisons, merely translating advanced architectures in a naive manner may not necessarily enhance performance. Consequently, further in-depth research is imperative to achieve performance improvement. We will leave it for the future work. \n\n| Model Architecture | ModelNet10 (5-sample) |\n|--------------------|-----------------------|\n| PointNet-NTK1      | 81.34 $\\pm$ 2.78      |\n| Vanilla-GNTK1      | 81.91 $\\pm$ 2.95      |\n| PointNet-NTK2      | 81.74 $\\pm$ 3.16      |\n| Vanilla-GNTK2      | 81.67 $\\pm$ 3.20      |"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700529022093,
                "cdate": 1700529022093,
                "tmdate": 1700529022093,
                "mdate": 1700529022093,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nnoqV9raq3",
                "forum": "sDlMJVXXeV",
                "replyto": "eRw6XGmqRQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer vDG7's Weakness 4"
                    },
                    "comment": {
                        "value": "##  \u2022 More visualizations are favorble to highlight the characteristics and advantages of the proposed approach, whichcould be included in the supplementary file.\n\nThanks for the reviewer's suggestion. More visualisation regarding shape matching as well as shape reconstruction will be added into the Appendix of the revised manuscript, which will be uploaded to OpenReview before the authors-reviewers discussion deadline."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700529083934,
                "cdate": 1700529083934,
                "tmdate": 1700529083934,
                "mdate": 1700529083934,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mBC6J5swjG",
                "forum": "sDlMJVXXeV",
                "replyto": "eRw6XGmqRQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer vDG7's Question 2 & 3"
                    },
                    "comment": {
                        "value": "##  \u2022 How do you think the performance of neural varifolds can be further improved? \n\n##  \u2022 What are possible directions to extend this work for future research?\n\nThanks for the reviewer's open questions. In order to minimise the performance gap, feature augmentation techniques can be explored. In the case of CIFAR10 classification, the work in [1] augmented the CIFAR dataset by a factor of 20, and then used highly parallelised conjugate gradient method to solve the linear system and achieved 91.2\\% accuracy, which is the current SOTA amongst kernel based methods. Although its performance is not as good as the SOTA neural networks, it could be further improved in the context of few-shot learning.  \n\nOur architecture is based on a simple PointNet architecture. Even though its performance is quite impressive already, it shares the drawback of the PointNet architecture and thus local variations cannot be able to be captured very efficiently as local neighbourhood is not considered in the architecture. It might be worth investigating graph neural tangent kernel and its variants [2] to take into account subtle variations within the local neighbourhood.  With the potential improvement of the computational complexity [3,4], it might be able to achieve better performance on few-shot learning, shape reconstruction and shape matching. Furthermore, various SOTA architectures like Point Transformer can be exploited for the improvement of the architecture side. This is of great interest to investigate in future study. \n\nFrom the varifold theory point of view, the multiplicity function $\\theta$ in  Definition 1 can also be used to differentiate the local density or second-order variations of the point clouds. In the current study, the multiplicity $\\theta$ is defined as constant 1 for simplicity, it might be worth investigating whether the multiplicity term can be learned by data-driven approaches like [5] to boost the performance. Furthermore, varifold framework is flexible such that it can take into account additional information on the surface. For example, Equation (32) in [6] defines the functional varifold, which can take into account texture information as a function. By doing so, the varifold framework can take advantage of the shape with texture information for various tasks, e.g. texture analysis, shape registration, shape reconstruction with texture, etc.  We believe these are just some of the many possible directions to extend this work for future research."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700529239020,
                "cdate": 1700529239020,
                "tmdate": 1700529239020,
                "mdate": 1700529239020,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PFzRC5Lreg",
                "forum": "sDlMJVXXeV",
                "replyto": "eRw6XGmqRQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "References"
                    },
                    "comment": {
                        "value": "[1] Adlam, Ben, et al. \"Kernel Regression with Infinite-Width Neural Networks on Millions of Examples.\" arXiv preprint arXiv:2303.05420 (2023).\n\n[2] Du, Simon S., et al. \"Graph neural tangent kernel: Fusing graph neural networks with graph kernels.\" Advances in neural information processing systems 32 (2019).\n\n[3] Zandieh, Amir, et al. \"Scaling neural tangent kernels via sketching and random features.\" Advances in Neural Information Processing Systems 34 (2021): 1062-1073.\n\n[4] Han, Insu, et al. \"Fast neural kernel embeddings for general activations.\" Advances in neural information processing systems 35 (2022): 35657-35671.\n\n[5] Huang, Jiahui, et al. \"Neural Kernel Surface Reconstruction.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n\n[6] Charlier, Benjamin, Nicolas Charon, and Alain Trouv\u00e9. \"The fshape framework for the variability analysis of functional shapes.\" Foundations of Computational Mathematics 17 (2017): 287-357.\n\n[7] Shankar, Vaishaal, et al. \"Neural kernels without tangents.\" International conference on machine learning. PMLR, 2020."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700529283965,
                "cdate": 1700529283965,
                "tmdate": 1700529283965,
                "mdate": 1700529283965,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aX5rJ31MS7",
                "forum": "sDlMJVXXeV",
                "replyto": "eRw6XGmqRQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer vDG7's Weakness 1 & Question 1"
                    },
                    "comment": {
                        "value": "## \u2022 The theoretical underpinnings of PointNet-NTK2 are less clear than PointNet-NTKI.\n## \u2022 Can you elaborate more on the limitations of PointNet-NTK2 compared to PointNet-NTKI from a theoretical standpoint?\n\nWe appreciate the reviewer's  remark on the manuscript. The paragraph following Equation (13) in the original manuscript about the theoretical underpinnings of PointNet-NTK2 was not clear so we rewrote it in the revised manuscript. Here is the new version: ***\"[PointNet-NTK2] cannot be associated in the limit with a Charon-Trouv\\'e type kernel, in contrast with PointNet-NTK1, but it remains theoretically well grounded because the explicit coupling of positions and normals is a key aspect of the theory of varifolds that provides strong theoretical guarantees (convergence, compactness, weak regularity, second-order information, etc.). Furthermore, PointNet-NTK2 falls into the category of neural networks proposed for point clouds that treat point positions and surface normals as 6-feature vectors, and thus PointNet-NTK2 is a natural extension of current neural networks practices for point clouds.\"*** We hope that this new version clarifies the theoretical underpinnings of PointNet-NTK2."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700738008421,
                "cdate": 1700738008421,
                "tmdate": 1700739728837,
                "mdate": 1700739728837,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "aIBKDCfcvd",
            "forum": "sDlMJVXXeV",
            "replyto": "sDlMJVXXeV",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3927/Reviewer_6p7s"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3927/Reviewer_6p7s"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors propose to consider a novel representation, varifolds for neural point cloud analysis. They first familiarizes the readers with the idea of varifolds consisting of a positional and Grassmannian component, which can be viewed as the joint representation consisting of points and normals. Then, the concept of neural tangent kernels is introduced to link the kernel theory and neural networks.  The NTK determines the distance between varifolds using neural networks. The authors then propose to represent point clouds using NTK to allow comparison in the varifold representation for conducting downstream tasks.  To demonstrate the effectiveness of the proposal, the authors conduct experiments on point cloud classification, surface reconstruction and shape matching. Especially in tasks where the data is limited, the results demonstrate that the proposed representation is able to capture the characteristics of the underlying shape, showing promise for further analysis."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The authors carefully introduces the idea of varifolds and how it can be used to represent the point clouds consisting of points and normals. They extensively explain how metrics can be introduced in this representation space.  \n\n- The authors thoroughly explain how neural tangent kernel can be used to introduce kernels into the domain of neural networks and how point cloud represented as varifolds can be compared. The representation as well as the derivation is  theoretically solid.\n\n- They propose two variants of the varifold representation using neural networks: NTK-1 and 2. The first separates the positional mass and the normal elements computes them separately, while the second jointly handles points and normals, as conventional point cloud neural network models do.\n\n- The task of using different metrics to conduct non-rigid registration is very interesting. As the proposed metric performs well in both cases of dolphin and cup, it seems to be a promising metric to compare different point cloud data and its underlying shapes."
                },
                "weaknesses": {
                    "value": "- Despite the very interesting theoretical approach of using varifolds, its practicality remains questionable. The interesting results can be found in small-sample shape classification tasks, where the proposed method and representation outperformed other conventional methods. However in most other tasks, the method had been outperformed by conventional methods with presumably more expensive computation. Despite the authors\u2019 claim that the representation is able to extract both global and local shape similarities, the experiments demonstrate otherwise. It would have been better if the authors proposed a specific network structure that is able to take better advantage of the NTK representation. In order to compensate for the practical disadvantages, the authors could have introduced theoretical advantages over the conventional approaches. Such seems to be missing in the paper.\n\n- The non-rigid registration results are very interesting, however, only two samples were provided for the experiments. It would be more convincing to apply the method on various shapes to analyze the tendencies of the proposal. Therefore, I believe the experiments are incomplete.\n\n- Some ablation study had been conducted in the supplementary material by changing the number of layers of the target network. However, as the neural tangent kernel is derived from the study that links kernels to over-parameterized neural networks, it would have also been better to present results from neural network with different layer widths."
                },
                "questions": {
                    "value": "- Are there other tasks that the method can play an important part? For example, change/defect detection within point cloud data may be one direction of possibilities, but as the method requires taking the mean of all the elements, I am presuming it is rather difficult.\n\n- What are the relationship between the proposed kernel and the network layers? Does the metric become more accurate as the width and number of layers increase? The authors do conduct analysis by changing the layers and comparing the final output, but I am curious about how relationship among shapes change according to the network structure. \n\n- As the method states, the NTK would be identical if the network tends to infinity, but as this is unrealistic, I believe there needs to be some practical solution to the network design. What justifies the selection of the current architecture?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "I believe there is little concern in terms of ethics, therefore I believe no further ethics review is necessary."
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3927/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698653436598,
            "cdate": 1698653436598,
            "tmdate": 1699636353128,
            "mdate": 1699636353128,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bHK7Kf7JWc",
                "forum": "sDlMJVXXeV",
                "replyto": "aIBKDCfcvd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer 6p7s's Weakness 1"
                    },
                    "comment": {
                        "value": "##  \u2022  Despite the very interesting theoretical approach of using varifolds, its practicality remains questionable. The interesting results can be found in small-sample shape classification tasks, where the proposed method and representation outperformed other conventional methods. However in most other tasks, the method had been outperformed by conventional methods with presumably more expensive computation. Despite the authors\u2019 claim that the representation is able to extract both global and local shape similarities, the experiments demonstrate otherwise. It would have been better if the authors proposed a specific network structure that is able to take better advantage of the NTK representation. In order to compensate for the practical disadvantages, the authors could have introduced theoretical advantages over the conventional approaches. Such seems to be missing in the paper.\n\nWe appreciate the reviewer's remark on the manuscript. To clear some misunderstanding regarding the computational complexity and methods' performance (and avoid redundant response), we would also like to refer the reviewer to our reply to reviewer wzuY. Please see below for our further response.\n\nOnly for shape classification with all data, the performance of the neural varifold is not as comparable as the existing baselines like PointNet, DGCNN or more advanced methods, indicating the potential current limitation of the proposed methods in this specific case.  We would like to highlight that the performances of the proposed approaches on shape classification with  limited data, shape reconstruction and shape matching are either  better in many cases or at least comparable with other methods.\n\nIn the limited data scenario, the proposed methods are actually not computationally heavier than neural networks with respect to the training time. For example, the computational time for 5-sample training on ModelNet10 is respectively 47 and 18 seconds for PointNet-NTK1 and PointNet-NTK2, while it takes 254 and 502 seconds for training PointNet and DGCNN with a single NVIDIA 3090 GPU, respectively. Although the inference time for the standard neural network could be cheaper after training completed, considering the performance gap and computational cost for our proposed methods, it is still within acceptable range and is worth improving further.  \n\nIn the case of shape reconstruction, Table 3 in the manuscript shows that none of the baseline methods are dominating the task and that the proposed method is competitive to the baseline methods. Note that we have also included a SOTA method -- neural kernel surface reconstruction (NKSR) -- into baseline in Table 3 in our revised manuscript. In addition, we have added more visualisation of the shape reconstruction results from all baseline methods as well as our proposed method. In the case of shape matching, we will explain in more detail in our response to your Weakness 2 below."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700510560409,
                "cdate": 1700510560409,
                "tmdate": 1700510950443,
                "mdate": 1700510950443,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BZpC1MyItP",
                "forum": "sDlMJVXXeV",
                "replyto": "aIBKDCfcvd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer 6p7s's Weakness 2"
                    },
                    "comment": {
                        "value": "## \u2022 The non-rigid registration results are very interesting, however, only two samples were provided for the experiments. It would be more convincing to apply the method on various shapes to analyze the tendencies of the proposal. Therefore, I believe the experiments are incomplete.\n\nIn our revised manuscript (which will be uploaded to OpenReview before the deadline), we have incorporated three additional shape matching results (i.e., 1. two hippocampi, 2. sphere to Stanford Bunny, and 3. two airplanes) into the Appendix, outlined in the table below  as a showcase firstly. \n\n|             | Metric  | Chamfer | EMD     | CT                | NTK1             | NTK2             |\n|-------------|---------|---------|---------|-------------------|------------------|------------------|\n| Hippocampus | Chamfer | 3.49E-1 | 3.2E-1  | **2.43E-1**  | 2.67E-1          | 2.65-1           |\n|             | EMD     | 2.80E5  | 2.10E5  | 2.25E5            | 2.09E5           | **1.96E5**  |\n|             | CT      | 2.27E3  | 2.92E5  | 2.32E3            | 2.19E3           | **2.15E3**  |\n|             | NTK1    | 1.84E5  | 1.01E9  | 59.7E5            | **4.93E3**  | 9.98E3           |\n|             | NTK2    | 6.37E4  | 3.09E9  | 1.56E6            | **1.54E3**  | **1.54E3**  |\n| Bunny       | Chamfer | 9.32E-3 | 5.12E-3 | **3.60E-3**  | 4.40E-3          | 4.32E-3          |\n|             | EMD     | 2.31E4  | 4.74E3  | 3.72E3            | **3.13E3**  | 3.52E3           |\n|             | CT      | 2.40E-1 | 1.25E0  | **7.51E-2**  | 1.28E-1          | 1.23E-1          |\n|             | NTK1    | 2.57E-2 | 1.32E-2 | 1.83E-3           | **2.22E-4** | 2.94E-4          |\n|             | NTK2    | 3.85E-2 | 2.68E-2 | 3.33E-3           | 8.85E-4          | **6.43E-4** |\n| Airplane    | Chamfer | 1.36E-3 | 4.07E-4 | **3.72 E-3** | 3.81E-3          | 5.90E-3          |\n|             | EMD     | 1.16E4  | 4.12E2  | **3.38E2**   | 3.43E2           | 7.50E2           |\n|             | CT      | 8.71E-2 | 3.62E0  | **-3.58E-4** | 1.67E-3          | 3.68E-3          |\n|             | NTK1    | 2.27E-3 | 1.80E-1 | 0.41E-6           | **0.31E-6** | 0.72E-6          |\n|             | NTK2    | 6.14E-2 | 5.13E0  | 8.69E-6           | 3.17E-6          | **2.42E-6** |\n\nIn all three instances, both NTK1 and NTK2 exhibit excellent results. In the case of shape matching between two hippocampi, NTK2 demonstrates superior results in terms of EMD, CT, and NTK2 metrics; for shape matching with NTK1, the best results are observed with respect to NTK1 and NTK2 metrics. For the Stanford Bunny, NTK1 yields the best outcomes in terms of EMD and NTK1 metrics; and the shape matching with NTK2 achieves optimal results with respect to the NTK2 metric. For shape matching between two airplanes, CT achieves the best results in terms of Chamfer, EMD and CT metrics, while both NTK1 and NTK2  achieve the best outcomes with respect to themselves. In particular, the visualisation of the airplane matching results shows that none of the methods match the target shape perfectly; and qualitatively, the shape matching results between airplanes are in favour of our methods NTK1 and NTK2 with respect to wings and fuselage. The detailed  visualisation of the additional experimental results has been added into the Appendix in the revised manuscript, which will be uploaded to OpenReview before the authors-reviewers discussion deadline."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700510904432,
                "cdate": 1700510904432,
                "tmdate": 1700516040173,
                "mdate": 1700516040173,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TG1pIXNQQt",
                "forum": "sDlMJVXXeV",
                "replyto": "aIBKDCfcvd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer 6p7s's Weakness 3"
                    },
                    "comment": {
                        "value": "## \u2022   Some ablation study had been conducted in the supplementary material by changing the number of layers of the target network. However, as the neural tangent kernel is derived from the study that links kernels to over-parameterized neural networks, it would have also been better to present results from neural network with different layer widths.\n\n\nWe appreciate the reviewer's suggestion. In response to this suggestion, we have conducted experiments on the 9-layer MLP-based PointNet-NTK2, varying the width settings to include 128, 512, 1024, 2048, and infinite-width configurations. The new experiments will be added to the Appendix of the revised manuscript. We trained the model on 5 randomly sampled point clouds per class from the ModelNet10 training set. The evaluation was carried out on the ModelNet10 validation sets. This process was repeated five times with different random seeds, and the average shape classification accuracy was computed. Notably, PointNet-NTK1 was excluded from this experiment due to the absence of a finite-width neural network layer corresponding to the elementwise product between two neural tangent kernels of infinite-width neural networks. The results presented in the table below demonstrate that the analytical NTK (infinite-width NTK) outperforms the empirical NTK computed from the corresponding finite-width neural network with fixed layer width sizes. \n\n| Number of width for each layer | PointNet-NTK2 (5-sample) |\n|--------------------------------|--------------------------|\n| 128-width                      | 78.74 $\\pm$ 3.30         |\n| 512-width                      | 80.08 $\\pm$ 3.02         |\n| 1024-width                     | 79.97 $\\pm$ 3.24         |\n| 2048-width                     | 80.46 $\\pm$ 3.13         |\n| infinite-width                  | 81.74 $\\pm$ 3.16  |\n\n\nFurthermore, computing empirical neural tangent kernels with respect to different length of width is known to be expensive since the empirical NTK is expressed as the outer product of the Jacobians of the output of the neural network with respect to its parameters. The details of the computational complexity and potential acceleration have been studied in [1]. However, if the finite-width neural networks are trained with the standard way instead of using empirical NTKs on the CIFAR10 dataset (containing 60,000 images), then finite-width neural networks outperform the neural tangent regime with performance significant margins [2,3]. In other words, there is still a large gap understanding about training dynamics of the finite-width nueral networks and their empirical neural kernel representations."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700511115408,
                "cdate": 1700511115408,
                "tmdate": 1700511115408,
                "mdate": 1700511115408,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ebpiBOqNZs",
                "forum": "sDlMJVXXeV",
                "replyto": "aIBKDCfcvd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer 6p7s's Question 1"
                    },
                    "comment": {
                        "value": "## \u2022 Are there other tasks that the method can play an important part? For example, change/defect detection within point cloud data may be one direction of possibilities, but as the method requires taking the mean of all the elements, I am presuming it is rather difficult.\n\nLet us firstly clear a misunderstanding. Taking the mean of all elements in varifold kernels between two shapes is necessary for some applications (e.g. shape classification and shape matching), but this is not always the case (e.g. shape reconstruction). In the case of shape reconstruction, we generate off surface points by adding or deducting a constant $\\delta$, and then assign labels per point. If points are on the surface, we then assign the label zero. If points are outside of the surface, we then assign either $\\delta$ or $-\\delta$ depending on the direction of the off surface points. Afterwards, we do the standard implicit surface reconstruction using the kernel regression. The changes of the shape/defect detection in theory is possible. However, it might not be scalable as it requires a prohibitively large kernel when the number of shapes increases. \n\nThe varifold framework is flexible enough to integrate additional information on the surface, in addition to positions and normals. Thanks to the measure-theoretic structure, this can be done very easily using tensor product of measures. For example, Equation (32) in [5] defines functional varifolds that can take into account texture information as a function. In our context, this opens the way to the use of the varifold structure for handling shapes with texture information for various tasks, e.g., texture analysis, shape registration, shape reconstruction with texture, etc."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700511219833,
                "cdate": 1700511219833,
                "tmdate": 1700511219833,
                "mdate": 1700511219833,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NlE8HrBwWi",
                "forum": "sDlMJVXXeV",
                "replyto": "aIBKDCfcvd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer 6p7s's Question 2"
                    },
                    "comment": {
                        "value": "## \u2022 What are the relationship between the proposed kernel and the network layers? Does the metric become more accurate as the width and number of layers increase? The authors do conduct analysis by changing the layers and comparing the final output, but I am curious about how relationship among shapes change according to the network structure.\n\n As the reviewer requested, the behavior of the NTK pseudo-metrics with respect to the number of layers has been evaluated and will be added to the Appendix of the revised manuscript. Note that the width is not considered as all pseudo-metrics are computed analytically (i.e., infinite-width) here; please refer to our response to your previous question regarding the property of the proposed method with different layer width. In this study, simple shape matching networks were trained solely by NTK psuedo-metrics with different number of layers.\n\nThe table  below showcases that the shape matching network trained with 5-layer NTK1 metric achieved the best score with respect to Chamfer, EMD, CT and NTK2 metrics, while the one with 9-layer NTK1 metric achieved the best score with respect to CT and NTK1 metrics. This is in accordance with the ablation analysis for shape classification, where 5-layer NTK1 achieved the best classification accuracy in the ModelNet10 dataset.  NTK2, on the other hand, shows a mixed signal. The shape matching network trained with the 1-layer NTK2 metric achieved the best outcome with respect to Chamfer, CT and NTK2 metrics, while the one trained with 9-layer NTK2 achieved the best results with respect to EMD and CT metrics. The network trained with 5-layer NTK2 only showed the best result with respect to NTK1 metric. This is not exactly in accordance with respect to shape classification with NTK2 metric, where the shape classification accuracy improves as the number of layers increases.  However, training a neural network always involves some non-deterministic nature; therefore, it is yet difficult to conclude whether the number of neural network layers is important for improving the shape quality or not. \n\n| Metric  | NTK1 (1)         | NTK1(5)          | NTK1(9)         |\n|---------|------------------|------------------|-----------------|\n| Chamfer | 2.82E-1          |  **2.67E-1** | 2.99E-1         |\n| EMD     | 2.43E5           | **2.09E5**  | 2.46E5          |\n| CT      | 2.19E3           | **2.17E3**  | **2.17E3** |\n| NTK1    | 7.74E3           | 4.93E3           | **4.90E3** |\n| NTK2    | 2.56E3           | **1.54E3**  | 1.92E3          |\n| **Metric**  | **NTK2 (1)**         | **NTK2 (5)**         | **NTK2 (9)**        |\n| Chamfer | **2.59E-1** | 2.61E-1          | 2.64E-1         |\n| EMD     | 2.14E5           | 2.32E5           | **1.93E5** |\n| CT      | **2.15E3**  | 2.17E3           | **2.15E3** |\n| NTK1    | 9.57E3           | **8.70E3**  | 9.98E3          |\n| NTK2    | **1.28E3**  | 1.41E3           | 1.53E3          |"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700511440849,
                "cdate": 1700511440849,
                "tmdate": 1700516178508,
                "mdate": 1700516178508,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "OQEyEXoMz4",
                "forum": "sDlMJVXXeV",
                "replyto": "aIBKDCfcvd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer 6p7s's Question 3"
                    },
                    "comment": {
                        "value": "## \u2022 As the method states, the NTK would be identical if the network tends to infinity, but as this is unrealistic, I believe there needs to be some practical solution to the network design. What justifies the selection of the current architecture?\n\nThe current architecture is based on one of the most popular neural network PointNet for 3D point clouds. The main idea is that the given network needs to be permutation invariant (e.g., fully connected layer, 1D convolution with 1-width convolution window, and average pooling). Even though our proposed methods have achieved excellent results in several important tasks for 3D point clouds, the proposed design shared the drawback from the adopted PointNet architecture and thus local variations cannot be able to be captured very efficiently as local neighbourhood is not considered in the architecture. The extension of the current work on graph neural tangent kernel is promising to address this case. We will try to see if we could add experiments in this regard within the limited authors-reviewers discussion period (note that we have added a significant number of new experiments in the revised manuscript); otherwise, we will leave it for future study since it is worth being investigated separately and deeply."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700511541610,
                "cdate": 1700511541610,
                "tmdate": 1700511541610,
                "mdate": 1700511541610,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RLMctdDCPi",
                "forum": "sDlMJVXXeV",
                "replyto": "aIBKDCfcvd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "References"
                    },
                    "comment": {
                        "value": "[1] Novak, Roman, Jascha Sohl-Dickstein, and Samuel S. Schoenholz. \"Fast finite width neural tangent kernel.\" International Conference on Machine Learning. PMLR, 2022.\n\n[2] Arora, Sanjeev, et al. \"On exact computation with an infinitely wide neural net.\" Advances in neural information processing systems 32 (2019).\n\n[3] Lee, Jaehoon, et al. \"Finite versus infinite neural networks: an empirical study.\" Advances in Neural Information Processing Systems 33 (2020): 15156-15172.\n\n[4] Du, Simon S., et al. \"Graph neural tangent kernel: Fusing graph neural networks with graph kernels.\" Advances in neural information processing systems 32 (2019).\n\n[5] Charlier, Benjamin, Nicolas Charon, and Alain Trouv\u00e9. \"The fshape framework for the variability analysis of functional shapes.\" Foundations of Computational Mathematics 17 (2017): 287-357."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700511566370,
                "cdate": 1700511566370,
                "tmdate": 1700511566370,
                "mdate": 1700511566370,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qVXx1dWAYe",
                "forum": "sDlMJVXXeV",
                "replyto": "aIBKDCfcvd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Reviewer_6p7s"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Reviewer_6p7s"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "Thank you for thoroughly addressing the questions and concerns.\nAs shape classification may not be the strength of this proposal, (as this led to every reviewer in believing that the overall performance was rather subpar), I think the paper could be reformatted by allocating more space for the experiments added during rebuttal on the main manuscript."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700701356539,
                "cdate": 1700701356539,
                "tmdate": 1700701356539,
                "mdate": 1700701356539,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hyqBchiPHh",
            "forum": "sDlMJVXXeV",
            "replyto": "sDlMJVXXeV",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3927/Reviewer_wzuY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3927/Reviewer_wzuY"
            ],
            "content": {
                "summary": {
                    "value": "The paper combines the concepts of varifolds from geometric measure theory defined for point clouds with neural tangent kernels (NTK) for infinite-width MLPs. Since the initial point cloud neural network architecture PointNet is an MLP, the main results of NTK directly translate to it. The authors propose to consider two variants of neural varifolds for point clouds constructed with: (1) product of separate NTKs for point coordinates and surface normals; (2) a single NTK for extended R^6 space of point and normal coordinates.\n\nUsing the resulting kernel methods, the authors specify how to use kernel ridge regression to solve shape classification and shape reconstruction, and also perform shape matching between point cloud pairs by minimization of a pseudo-metric for varifolds.\n\nIn the experiments, the authors evaluate the proposed methods and show that: 1) classification quality can not reach the performance of a standard PointNet network, although it can be competitive in a few-shot training setup; 2) shape reconstruction is competitive to some baselines; 3) shape matching experiment through varifold metric minimization shows promising results."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "I am not a specialist on this topic, but to my knowledge, it is the first work to view PointNet-like architectures for point clouds as NTK approach. Additional connection to varifolds looks novel and promising as it is possible that some further results from the geometric measure theory could be explored in the context of 3D shape analysis."
                },
                "weaknesses": {
                    "value": "1. Given that the complexity of the approach is higher compared to regular trainable networks and that the performance in the applications is lacking it is hard to find arguments in favour of using the proposed approach in practice.\n\n2. Few-shot 3D point cloud classification is an established task and it would be much more relevant to compare to approaches designed to few-shot setup instead of regular classification methods: A Closer Look at Few-Shot 3D Point Cloud Classification.\n\n3. Comparisons and proper positioning with respect to at least a couple of more recent baselines are missing: Neural Fields as Learnable Kernels for 3D Reconstruction, Neural Kernel Surface Reconstruction.\n\n4. Additional visualizations of qualitative comparisons would be much appreciated."
                },
                "questions": {
                    "value": "I am willing to improve my rating, but to be convinced I\u2019d like to at least hear a couple of ideas of how the proposed method can be improved to close at least the performance gap or complexity gap (both, if possible)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3927/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698806219221,
            "cdate": 1698806219221,
            "tmdate": 1699636353052,
            "mdate": 1699636353052,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "d5NKZKQZP9",
                "forum": "sDlMJVXXeV",
                "replyto": "hyqBchiPHh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer wzuY's Weakness 1 & Question (Part1)"
                    },
                    "comment": {
                        "value": "## \u2022 Given that the complexity of the approach is higher compared to regular trainable networks and that theperformance in the applications is lacking it is hard to find arguments in favour of using the proposed approach in practice.\n\n## \u2022 a couple of ideas of how the proposed method can be improved to close at least the performance gap or complexity gap (both, if possible)\n\nThe computational complexity of the neural kernels (e.g., the neural tangent kernel and neural Gaussian process) has been a well known problem. A number of studies have been investigated to accelerate the kernel computation speed in terms of parallelisation as well as kernel approximations. The framework used in this study ``neural tangents'' [1] provides a powerful GPU parallelism with batch processing. Similarly, KeOps [2] also provides similar features such that it can accelerate kernel computation with GPU parallelism. However, it is still not able to solve the fundamental problem about its quadratic complexity. Recent studies have more focused on reducing the computational complexity by approximating neural kernels. For example, the neural kernels with ReLU activation can be approximated by a variant of linear sketch algorithms [3]. Table 1 in [3] shows that the computation of the convolutional neural tangent kernel (CNTK) for 3-layer 2D convolutional network with the proposed method (5,160 seconds) is around 200 times faster than the exact computation of CNTK ($>$1,000,000 seconds) on the CIFAR10 dataset. Further generalisation of the neural kernel approximation with various nonlinear activation functions has been introduced in [4]. In [4], the proposed kernel computation method (1.4 GPU hours) achieved also 106 times faster than the exact computation (151 GPU hours) of CNTK for Myrtle-5 on the CIFAR dataset. Furthermore, the performance of the approximated neural kernel is indeed similar or even better than the performance of the exact neural kernel [3,4]. The proposed approaches [3] and [4] can be directly translated and modified to both PointNet-NTK1 and PointNet-NTK2 representations, which may accelerate the kernel computation speed without loss of performance. We will leave it for future study. \n\nIn the empirical point of view, the computational complexity of the PointNet-NTK1 and -NTK2 computation is actually not a significant bottleneck for some applications. For example, the few-shot scenario shown in Table 2 in the manuscript, the computational cost for 5-sample training on ModelNet10 is respectively 47 and 18 seconds for PointNet-NTK1 and PointNet-NTK2, while it takes 254 and 502 for training PointNet and DGCNN epochs with a single 3090 GPU, respectively. The performance and time complexity  are comparable to the standard neural networks in the case of the limited data scenario. To clear any confusion regrading the computational complexity, we have added a revised paragraph (i.e., the last paragraph) in Section 4.1 in our revision.  In the case of shape reconstruction, most of the shape reconstruction can be completed within 5 seconds. Furthermore, it can be potentially further optimised by introducing KeOps framework like Neural Splines. In the case of shape matching, the computation of the neural varifold kernels is not a significant computational bottleneck in terms of shape evaluation purpose. However, if one needs to use the metric as a loss function to train the network, then it is slower than other metrics; therefore further optimisation is required for better scalability."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700492138250,
                "cdate": 1700492138250,
                "tmdate": 1700511815572,
                "mdate": 1700511815572,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Hz0tNThjqJ",
                "forum": "sDlMJVXXeV",
                "replyto": "hyqBchiPHh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer wzuY's Weakness 1 & Question (Part2)"
                    },
                    "comment": {
                        "value": "In order to miminise the performance gap, feature augmentation techniques can be explored. In the case of CIFAR10 classification, the work in [7] augmented the data by a factor of 20, and then used highly parallelised conjugate gradient method to solve the linear system and achieved 91.2\\% accuracy, which is the current SOTA amongst kernel based methods. Although its performance is not as good as the SOTA neural networks, it can be further improved in the context of few-shot learning.  \n\nOur architecture is based on a simple PointNet architecture. Therefore, it shares the drawback of the PointNet architecture that local variations cannot be able to be captured very efficiently as local neighbourhood is not considered in the architecture. It might be worth investigating graph neural tangent kernel and its variants [8] to take into account subtle variations within the local neighbourhood.  With the potential improvement of the computational complexity [3,4], it might be able to achieve better performance on few-shot learning, shape reconstruction and  shape matching. It is worth highlighting that the performance of the proposed methods PointNet-NTK1 and PointNet-NTK2 is actually quite promising (i.e., they perform either better or comparably with the SOTA methods) rather than lacking. Furthermore, various SOTA architectures like Point Transformer can be exploited for the improvement of the architecture side. We will leave it for future study. \n\nThe general definition of a rectifiable varifold (see Definition 1) involves a multiplicity function $\\theta$ that carries concentration/density information. In the current study, the multiplicity $\\theta$ is defined as constant 1 for simplicity, but we consider future work investigating whether the multiplicity term can be learned by data-driven approaches like [6] to boost the performance. Furthermore, the varifold framework is flexible enough to integrate additional information on the surface, in addition to positions and normals. Thanks to the measure-theoretic structure, this can be done very easily using tensor product of measures. For example, Equation (32) in [9] defines functional varifolds that can take into account texture information as a function. In our context, this opens the way to the use of the varifold structure for handling shapes with texture information for various tasks (e.g. texture analysis, shape registration, shape reconstruction with texture, etc.)."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700492168226,
                "cdate": 1700492168226,
                "tmdate": 1700492168226,
                "mdate": 1700492168226,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YXRbWfRExM",
                "forum": "sDlMJVXXeV",
                "replyto": "hyqBchiPHh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer wzuY's Weakness 2"
                    },
                    "comment": {
                        "value": "## \u2022 Few-shot 3D point cloud classifi cation is an established task and it would be much more relevant to compare to approaches designed to few-shot setup instead of regular classification methods: A Closer Look at Few-Shot 3DPoint Cloud Classifi cation.\n\nWe appreciate the reviewer's insightful remarks on few-shot learning. In the current experiment setting in the manuscript, it is difficult to directly apply the standard few-shot learning approaches. This is because the few-shot learning approaches in [5]  you suggest require pre-training on existing dataset. In the main experiment in [5], the backbone network was trained with 30 classes of the ModelNet40 dataset, and then few-shot algorithms were applied and evaluated on 10 classes of ModelNet40. Our current experiment, on the other hand, assumes that all 40 classes have limited samples (1, 5, 10 or 50 samples).  Since the code base of [5] is public, we have been trying hard to investigate whether more results with experimental setup in [5] (i.e., pretraining on 30 class and few-shot learning on 10 class) can be added within this authors-reviewers discussion time frame. However, it is an interesting direction for the expansion of the current work."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700492269904,
                "cdate": 1700492269904,
                "tmdate": 1700511721923,
                "mdate": 1700511721923,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EZChxS5KgQ",
                "forum": "sDlMJVXXeV",
                "replyto": "hyqBchiPHh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer wzuY's Weakness 3 & 4 (Part1)"
                    },
                    "comment": {
                        "value": "## \u2022 Comparisons and proper positioning with respect to at least a couple of more recent baselines are missing: NeuralFields as Learnable Kernels for 3D Reconstruction, Neural Kernel Surface Reconstruction.\n## \u2022 Additional visualizations of qualitative comparisons would be much appreciated.\n\n| Metric       | Method         | Airplane       | Bench          | Cabinet        | Car            | Chair          | Display        | Lamp            | Speaker        | Rifle          | Sofa           | Table          | Phone          | Vessel         |\n|--------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|-----------------|----------------|----------------|----------------|----------------|----------------|----------------|\n| CD (mean)    | SIREN          | 1.501          | 1.624          | 2.430          | 2.725          | **1.556** | **2.193** | 1.392           | 7.906          | 1.212          | 1.734          | 1.856          | **1.478** | 2.557          |\n|              | Neural Splines | 4.145          | **1.304** | 1.969          | 2.131          | 1.828          | 4.577          | **1.062**  | **2.798** | **0.400** | **1.650** | **1.576** | 10.058         | 2.210          |\n|              | NKSR           | 1.141          | 2.000          | 2.423          | 2.198          | 2.520          | 17.720         | 5.477           | 3.622          | 0.414          | 1.848          | 2.493          | 1.547          | 1.093          |\n|              | NTK1           | **0.644** | 1.314          | **1.991** | **2.107** | 1.734          | 4.666          | 1.134           | 2.806          | 0.425          | 1.654          | 1.586          | 10.397         | **1.079** |\n| CD (Median)  | SIREN          | 0.733          | 1.384          | 2.153          | 2.134          | 1.230          | 1.469          | 0.661           | 3.304          | 0.581          | 1.706          | 1.670          | 1.424          | 1.112          |\n|              | Neural Splines | 0.947          | 1.289          | 1.799          | **1.640** | **1.160** | **1.413** | **0.479**  | **2.749** | 0.347          | 1.586          | 1.372          | 1.600          | **0.788** |\n|              | NKSR           | 1.205          | 1.426          |**1.797** | 1.830          | 1.236          | 1.565          | 1.579           | 2.945          | **0.326** | 1.638          | 1.637          | **1.305** | 0.894          |\n|              | NTK1           | **0.621** | **1.259** | 1.828          | 1.836          | 1.237          | 1.499          | 0.566           | 2.794          | 0.352          | **1.578** | **1.350** | 1.558          | 0.797          |\n| EMD (mean)   | SIREN          | **2.990** | 3.763          | 4.983          | 5.208          | **4.649** | **4.658** | 24.068          | 13.292         | 2.418          | **3.688** | 8.745          | **3.237** | 4.500          |\n|              | Neural Splines | 22.004         | **3.571** | **4.420** | **4.694** | 7.916          | 9.205          | **16.786** | **5.857** | **1.503** | 3.706          | **4.194** | 17.846         | 5.957          |\n|              | NKSR           | 7.153          | 8.456          | 8.018          | 8.190          | 16.824         | 31.182         | 21.182          | 9.984          | 2.329          | 5.871          | 13.658         | 4.152          | 4.581          |\n|              | NTK1           | 3.120          | 4.153          | **4.420** | 4.767          | 7.350          | 9.653          | 23.381          | 6.236          | 1.592          | 3.888          | 5.259          | 24.101         | **3.534** |\n| EMD (median) | SIREN          | **2.690** | 2.938          | 4.520          | **3.803** | **4.411** | **3.314** | **2.279**  | 6.240          | 1.605          | 3.653          | 3.782          | **3.060** | 2.576          |\n|              | Neural Splines | 6.873          | **3.068** | **4.154** | 3.999          | 4.740          | 4.053          | 3.802           | **5.123** | **1.216** | **3.543** | **3.695** | 3.838          | 2.210          |\n|              | NKSR           | 5.732          | 5.119          | 4.440          | 5.313          | 5.683          | 3.777          | 4.927           | 5.975          | 1.227          | 3.641          | 6.375          | 3.088          | 2.771          |\n|              | NTK1           | 2.864          | 3.319          | 4.284          | 3.947          | 5.293          | 3.875          | 3.288           | 5.795          | 1.271          | 3.738          | 3.980          | 3.380          | **2.074** |"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700493014470,
                "cdate": 1700493014470,
                "tmdate": 1700515869492,
                "mdate": 1700515869492,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ExJjb4gijr",
                "forum": "sDlMJVXXeV",
                "replyto": "hyqBchiPHh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer wzuY's Weakness 3 & 4 (Part2)"
                    },
                    "comment": {
                        "value": "As the reviewer recommended, we added another baseline -- Neural Kernel Surface Reconstruction (NKSR) [6] -- for comparison. We used the NVIDIA's pre-trained model available on the official GitHub repository of NKSR. The results are updated accordingly on figures and tables (e.g. see the table above a showcase of the comparison to NKSR) in the revised manuscript, which will be uploaded to  OpenReview before the deadline. As shown in the table above, NKSR only outperforms other methods with median Chamfer distance of the classes: Cabinet, Rifle and Phone. In the case of Neural Fields as Learnable Kernel for 3D reconstruction (NFLK), there is no public code base that is currently available. Due to the limited time frame for authors-reviewers discussion, it is not easily included into the baseline for comparison. However, since NKSR is indeed an extension of NFLK as stated in the Neural Kernel Surface Reconstruction [6], we hope you also agree adding NKSR for comparison is already sufficient and convincing. \n\nFurthermore, we will update the appendix of our manuscript to include more visualisation regarding the shape reconstruction results."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700493127402,
                "cdate": 1700493127402,
                "tmdate": 1700493127402,
                "mdate": 1700493127402,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lft0vap8IN",
                "forum": "sDlMJVXXeV",
                "replyto": "hyqBchiPHh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "References"
                    },
                    "comment": {
                        "value": "[1] Novak, Roman, et al. \"Neural tangents: Fast and easy infinite neural networks in python.\" arXiv preprint arXiv:1912.02803 (2019).\n\n[2] Charlier, Benjamin, et al. \"Kernel operations on the gpu, with autodiff, without memory overflows.\" The Journal of Machine Learning Research 22.1 (2021): 3457-3462.\n\n[3] Zandieh, Amir, et al. \"Scaling neural tangent kernels via sketching and random features.\" Advances in Neural Information Processing Systems 34 (2021): 1062-1073.\n\n[4] Han, Insu, et al. \"Fast neural kernel embeddings for general activations.\" Advances in neural information processing systems 35 (2022): 35657-35671.\n\n[5] Ye, Chuangguan, et al. \"A Closer Look at Few-Shot 3D Point Cloud Classification.\" International Journal of Computer Vision 131.3 (2023): 772-795. \n\n[6] Huang, Jiahui, et al. \"Neural Kernel Surface Reconstruction.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n\n[7] Adlam, Ben, et al. \"Kernel Regression with Infinite-Width Neural Networks on Millions of Examples.\" arXiv preprint arXiv:2303.05420 (2023).\n\n[8] Du, Simon S., et al. \"Graph neural tangent kernel: Fusing graph neural networks with graph kernels.\" Advances in neural information processing systems 32 (2019).\n\n[9] Charlier, Benjamin, Nicolas Charon, and Alain Trouv\u00e9. \"The fshape framework for the variability analysis of functional shapes.\" Foundations of Computational Mathematics 17 (2017): 287-357."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700493155984,
                "cdate": 1700493155984,
                "tmdate": 1700493155984,
                "mdate": 1700493155984,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]