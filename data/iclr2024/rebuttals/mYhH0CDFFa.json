[
    {
        "title": "Rethinking CNN\u2019s Generalization to Backdoor Attack from Frequency Domain"
    },
    {
        "review": {
            "id": "uOSCcnJ7hW",
            "forum": "mYhH0CDFFa",
            "replyto": "mYhH0CDFFa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission912/Reviewer_6jrw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission912/Reviewer_6jrw"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on the mechanism of CNN memorize poisoned samples in the frequency domain, and finds that CNN generate generalization to poisoned samples by memorizing the frequency domain distribution of trigger changes. It proposes a universal invisible strategy for visible triggers, which can achieve trigger invisibility while maintaining raw attack performance. It also designs a novel frequency domain backdoor attack method based on low-frequency semantic information. The main contributions of this paper are:\n- It explores the mechanism of CNN memorization for poisoned images from a frequency domain perspective, investigating the generalization of CNN with respect to perturbations in different frequency domains. \n- It explores the generalization of CNN for visible and invisible triggers, demonstrating that high-frequency features are more susceptible to perturbations than low-frequency features. \n- It proposes a generalized strategy for rendering visible backdoor attacks invisible while maintaining algorithmic performance. \n- It proposes a backdoor attack algorithm based on low-frequency semantic information for target classes, achieving high success rates across diverse datasets and models."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The main strengths of the paper are:\n- The paper is well-organized and clearly written, which is easy to follow.\n- This paper provides novel perspectives for backdoor attacks on CNN.\n- Experimental results are promising and can validate the effectiveness of the proposed method."
                },
                "weaknesses": {
                    "value": "The weaknesses of the paper are:\n- The motivation of this paper is unclear. The authors mention some related work about CNN and backdoor attacks, and they put forward their findings and the proposed methods. However, the necessity and urgency of the proposed method are still unclear. The authors should further clarify the motivation of the paper.\n- The dataset used in the paper is relatively small, which is not sufficient to reflect the generalization of the experiment. The author should conduct experimental observations on more generalized datasets such as ImageNet.\n\n------------------------------------After Rebuttal-----------------------------------------\n\nI thank the authors for their response. The response addressed most of my concerns. After reading other reviewers' comments, I think this paper is marginally above the acceptance threshold, thus I keep my score."
                },
                "questions": {
                    "value": "- Q1. The motivation of this paper is unclear. The authors mention some related work about CNN and backdoor attacks, and they put forward their findings and the proposed methods. However, the necessity and urgency of the proposed method are still unclear. The authors should further clarify the motivation of the paper.\n- Q2. The dataset used in the paper is relatively small, which is not sufficient to reflect the generalization of the experiment. The author should conduct experimental observations on more generalized datasets such as ImageNet."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission912/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission912/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission912/Reviewer_6jrw"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission912/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698288466316,
            "cdate": 1698288466316,
            "tmdate": 1700718230943,
            "mdate": 1700718230943,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gDndHyEhdA",
                "forum": "mYhH0CDFFa",
                "replyto": "uOSCcnJ7hW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 6jrw (Part 1)"
                    },
                    "comment": {
                        "value": "Thank you very much for your time and insightful comments. We are encouraged that our work is recognized. We hope the following new clarifications and results can address your concerns. We are happy to answer more questions and conduct more experiments if needed.\n\nQ1: The motivation of this paper is unclear. The authors mention some related work about CNN and backdoor attacks, and they put forward their findings and the proposed methods. However, the necessity and urgency of the proposed method are still unclear. The authors should further clarify the motivation of the paper.\n\nA1: Most current studies only study the impact of changing specific trigger features in the spatial domain on model generalization. The limitations of the spatial domain make it difficult for us to understand how CNN generalizes to poisoned samples. Frequency domain analysis is a good idea for analyzing the training process of neural networks. [1] provides a good idea for understanding the problem of how well deep neural networks can generalize. At the same time, [2] explained the high-frequency components from the perspective of the frequency domain to help CNN generalize. This study has given us some inspiration. Let us try to explain the mechanism of CNN's generalization on backdoor samples from the perspective of frequency domain. So we took visible and invisible triggers as examples to explore CNN's memory mechanism for poisoned images from the frequency domain perspective. We prove that successful triggers change the frequency domain distribution of samples, and CNN can generalize to a small number of poisoned samples by memorizing the frequency domain distribution changed by triggers. Our experiments also prove that the frequency domain distribution changed by the trigger is not always effective. For some triggers, only a part of it is effective. For some triggers, only a part of the perturbation can be used to achieve an efficient attack. Moreover, different frequency domain distributions of samples have different vulnerabilities to disturbances, and high-frequency components are more susceptible to disturbance than low-frequency components. In addition, after CNN establishes the association between feature distribution and labels, even if the triggering factors are diverse or unstable, backdoor attacks can be implemented as long as the frequency domain distribution is the same.\n\nVisible backdoor attacks exhibit a higher success rate, but their applicability is limited in scenarios that demand a higher level of concealment due to the visibility of their triggers. Therefore, combined with our theory, we extract the high-frequency component generated by the trigger that has less perturbation on the spectrum energy, and use the perturbation of the high-frequency component to inject a backdoor into the model. The spectral transformation of high-frequency perturbations into the spatial domain achieves the invisibility of triggers, thereby ensuring the efficiency of visible triggers in attacks. This expands the scenarios in which visible triggers can be effectively employed. Our proposed backdoor attack method, based on frequency-domain principles, capitalizes on the theoretical framework we introduced. This method harnesses the CNN's memory mechanisms for backdoor samples more effectively, enabling a highly efficient implementation of backdoor attacks. As demonstrated in Section 5, the attack accuracy of this method reaches 100% across multiple datasets and models.\n\nWe added the necessity of our proposed method in section 1 of the paper.\n\n[1] Zhang Y, Xu Z Q J, Luo T, et al. Explicitizing an implicit bias of the frequency principle in two-layer neural networks[J]. arXiv preprint arXiv:1905.10264, 2019.\n\n[2] Haohan Wang, Xindi Wu, Zeyi Huang, and Eric P Xing. High-frequency component helps explain the generalization of convolutional neural networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 8684\u20138694, 2020."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700278162781,
                "cdate": 1700278162781,
                "tmdate": 1700278162781,
                "mdate": 1700278162781,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aLUl43fgNb",
                "forum": "mYhH0CDFFa",
                "replyto": "VrgEsilQKY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission912/Reviewer_6jrw"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission912/Reviewer_6jrw"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "I thank the authors for their response. The response addressed most of my concerns. After reading other reviewers' comments, I think this paper is marginally above the acceptance threshold, thus I keep my score."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700718165151,
                "cdate": 1700718165151,
                "tmdate": 1700718165151,
                "mdate": 1700718165151,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "FX8eQgeTGL",
            "forum": "mYhH0CDFFa",
            "replyto": "mYhH0CDFFa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission912/Reviewer_2gr1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission912/Reviewer_2gr1"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigate CNN's generalization to backdoor attack in the frequency domain. Based on the fact that high frequencies are more easily perturbed and have higher attack efficiency. They designed an algorithm to convert visible triggers into invisible triggers and also a backdoor attack in the frequency domain."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This paper is well organized.\n\n2. The both proposed algorithms are well-motivated."
                },
                "weaknesses": {
                    "value": "1. The authors claimed that \"backdoor attack and defense from a frequency domain perspective is\nstill insufficient\", but IMHO, their literature review is insufficient. Recently, there are many researches about backdoor attacks in the frequency domain. The authors only mentioned one work [1], please discuss more related works such as [2,3,4]. By the way, adversarial attack (aka evasion attack) is closely related to backdoor attack, and there are even more adversarial attacks [5,6] in the frequency domain, and I noticed that the proposed algorithms shown in Figure 5(b) share some similarities with f-mixup in [6].\n\n2. [7,8] has already provided comprehensive analyses about CNN's generalization in the frequency domain, I think most conclusions reached in Section 3 may also be derived from the previous work. In other words, this paper does not provide enough new insights as the authors claimed.\n\n3. The proposed attack is motivated by frequency domain analysis for CNNs , but ViT has different bias in the frequency domain [9], which means that the proposed method may not generalize to ViT. IMHO, this is a great limitation.\n\n4. The authors conducted experiments on MNIST, CIFAR-10 and Celeba, it is necessary to validate the proposed algorithms on ImageNet. In my experience, CNNs trained on ImageNet is far less sensitive to high frequencies than CNNs trained on the above datasets.\n\nOverall, although I think this work is interesting, the current manuscript seems to not achieve the bar of ICLR in 2024.\n\n\nReference\n\n[1]  An invisible black-box backdoor attack through frequency domain, ECCV 2022.\n\n[2] FIBA: Frequency-Injection based Backdoor Attack in Medical Image Analysis, CVPR 2022.\n\n[3] Check Your Other Door! Creating Backdoor Attacks in the Frequency Domain, BMVC 2022.\n\n[4] Rethinking the Backdoor Attacks\u2019 Triggers: A Frequency Perspective, ICCV 2021.\n\n[5] Surfree: a fast surrogate-free black-box attack, CVPR 2021.\n\n[6] Decision-based adversarial attack with frequency mixup, IEEE TIFS 2022.\n\n[7] A Fourier perspective on model robustness in computer vision, NeurIPS 2019.\n\n[8] High-frequency component helps explain the generalization of convolutional neural networks, CVPR 2020.\n\n[9] How Do Vision Transformers Work? ICLR 2022\n\n------------------------------------After Rebuttal-----------------------------------------\n\nThe authors' rebuttal has addressed most of my concerns. However, the insufficient literature review still heavily weakens the motivation and novelty of this work. Specifically, the authors claimed that \"the research on backdoor attack and defense from a frequency domain perspective is still insufficient\", but actually, there exist many works in this direction. Besides, although the proposed algorithms shown in Figure 5(b) differs from f-mixup in some details, I still think the high-level ideas are similar, since both of inject misleading features into middle-and-high frequency domain. Therefore, although I have raised my score to 5, I think it is okay to reject this paper."
                },
                "questions": {
                    "value": "Please see weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission912/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission912/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission912/Reviewer_2gr1"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission912/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698415667937,
            "cdate": 1698415667937,
            "tmdate": 1700548250943,
            "mdate": 1700548250943,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oABUuzadXi",
                "forum": "mYhH0CDFFa",
                "replyto": "FX8eQgeTGL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 2gr1 (Part 1)"
                    },
                    "comment": {
                        "value": "Thank you very much for your time and insightful comments. We are encouraged that our work is recognized. We hope the following new clarifications and results can address your concerns. We are happy to answer more questions and conduct more experiments if needed.\n\nQ1: Insufficient review and some similarities with f-mixup in literature [1]\n\nA1: Thanks for pointing this out. In fact, we previously included a review of frequency domain backdoor attacks, but due to space reasons we had to reduce the introduction to this aspect, which we admit is insufficient. We have now supplemented the related work with a review of other backdoor attack methods (section 2.2).\n\nRegarding the work you mentioned in the field of adversarial attacks [1], we found this article and read it carefully. We will clearly and in detail explain the differences in working with them.\n\n1) First, our approach is different. In fact, the f-mixup mentioned in [1] is similar to ours in that they both use the frequency domain to add disturbance information. But our process of generating triggers (adversarial instances in adversarial attacks) and the raw materials of triggers used are completely different. F-mixup generates candidates by replacing part of the mid- and high-frequency components of the clean examples with the corresponding frequency components of the reference image. That is to say, f-mixup first uses DFT to transform the image into the frequency domain, then uses a band-pass filter to extract part of the high-frequency components of the reference image, and then uses a band-stop filter to filter out the frequency components of the same part of the clean image. Then add part of the high-frequency components of the reference image to the spectrum of the clean image, and finally use IDFT to transform to the spatial domain to obtain the adversarial sample. Our frequency-based backdoor attack method selects part of the low-frequency components of the target category image as the raw material of the trigger, and then adds the trigger to the mid- and high-frequency components of the clean image through upsampling and other operations to generate a poisoned image. And in order to improve the generalization of CNN to poisoned images whose label is set as the target category, we randomly select the low-frequency components of the image from the target category as raw materials when generating each poisoned image.\n\n2) Second, our purposes are different. The f-mixup in [1] is to destroy useful features in the image and introduce misleading information to perturb model prediction, thereby achieving adversarial attacks. Our attack method uses the low-frequency semantic information of the target category to inject the backdoor into the high-frequency component of the backdoor image in order to make the model better generalize to the trigger, thereby realizing the backdoor attack.\n\n[1] Li X C, Zhang X Y, Yin F, et al. Decision-based adversarial attack with frequency mixup[J]. IEEE Transactions on Information Forensics and Security, 2022, 17: 1038-1052."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700276238545,
                "cdate": 1700276238545,
                "tmdate": 1700276238545,
                "mdate": 1700276238545,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "s0PxLeIEGE",
                "forum": "mYhH0CDFFa",
                "replyto": "FX8eQgeTGL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Further responses to your comments"
                    },
                    "comment": {
                        "value": "Thank you for your reply. We have further clarified your question. We hope the new clarifications and results resolve your concerns. If you have any further questions, please ask and we'll be happy to continue answering your questions.\n\nQ1\uff1athe insufficient literature review still heavily weakens the motivation and novelty of this work.\n\nA1\uff1aThank you sincerely for your suggestions. In fact, when you first asked the question, we had already conducted a relevant literature review in section 2.2 and listed some of the current frequency domain-based backdoor attack methods. The expression of these methods did not demonstrate our motivation very well. We are sorry that it did not meet your expectations, so we revised the deficiencies in section 1 and section 2.2 again to supplement the motivation and novelty of our theories and methods.\n\n1) First of all, the current exploration of the mechanism of memorizing backdoor samples from the perspective of frequency domain is still lacking. Most frequency-based backdoor attack methods directly learn the CNN's memory ability of spectrum based on existing literature and make relevant assumptions, and then inject triggers based on this assumption. But they don\u2019t know why setting the trigger in this way makes CNN generalize, and they don\u2019t know the sensitivity of CNN to changes in the frequency components of each part. But we explored it. That is, we try to explain and explore the mechanism of CNN's memory of backdoor samples from the perspective of frequency domain. We further studied how the perturbations produced by visible and invisible triggers at different frequency components help the generalization ability of CNN.\n\n2) Secondly, in order to make the backdoor attack in frequency more efficient and bypass the backdoor defense algorithm based on the spatial domain, and can effectively implement the backdoor attack on the target category while minimizing the destruction of the original image energy. We use the research conclusions obtained in section 3 to propose the backdoor attack algorithm shown in Figure 5(b). At the same time, it is considered that visible backdoor attacks have a high attack success rate, but because of the visibility of the trigger, their use is limited in scenarios that require high concealment. Therefore, combined with our theory, we propose a general invisible algorithm shown in Figure 5(a), which realizes the invisible of visible triggers, ensures the attack efficiency of visible triggers, and expands the usage scenarios of visible triggers.\n\nQ2\uff1aThe algorithm shown in Figure 5(b) is similar to f-mixup in high-level ideas.\n\nA2:  As we replied before. The method we show in Figure 5(b) is completely different from the f-mixup method in terms of purpose and ideas. This also involves the purpose and difficulty of backdoor attack and adversarial attack tasks. Before comparing our two methods, it is necessary to correctly understand the difference between backdoor attacks and adversarial attacks. Moreover, just operating in the frequency domain does not mean that our high-level ideas are the same. Our purposes and methods are different, and the results we bring are also different. We will further explain the differences in methods to allay your concerns.\n\n\n1) f-mixup destroys useful features in images and introduces misleading information to perturb model predictions, thereby achieving adversarial attacks. This purpose means that it does not need to consider outputting specific results, but only perturbs the output results of the model. At the same time, f-mixup is generated in a way that generates adversarial examples by replacing parts of the mid- and high-frequency components of the clean examples with the corresponding parts of the reference image. The images referenced in the generation of adversarial samples do not need to consider fixed categories, and the trigger raw materials are medium and high frequency components.\n\n\n2) Our attack method utilizes the low-frequency semantic information of the target category and implants the backdoor in the high-frequency component of the backdoor image. This operation makes use of the CNN's memory mechanism for backdoor samples, so that the model can better generalize the triggers, thereby achieving backdoor attacks. And in order to improve the generalization of CNN to poisoned images whose label is the target category, we randomly select the low-frequency components of the image from the target category as raw materials when generating each poisoned image."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700567014047,
                "cdate": 1700567014047,
                "tmdate": 1700567014047,
                "mdate": 1700567014047,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "r7oc6LUIfo",
            "forum": "mYhH0CDFFa",
            "replyto": "mYhH0CDFFa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission912/Reviewer_F6E6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission912/Reviewer_F6E6"
            ],
            "content": {
                "summary": {
                    "value": "The study examines how triggers affect CNNs by looking at the frequency domain. The authors found that these triggers change the way images are distributed in this domain, which in turn affects CNN performance. They noted that higher frequencies are more vulnerable to attacks than lower ones. Based on these insights, they developed strategies to hide visible triggers and introduced a new backdoor attack method using low-frequency information. This method was effective against many defenses. The authors also provided ideas for future work, like using different triggers during training and testing. They hope their research encourages more exploration in the area of backdoor attacks and defenses."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.  This paper adopt a novel perspective of learning the backdoor effect through the lens of frequency domain. Specifically, it is interesting to see how different frequency component affect the attack success rate of in current backdoor attack methods. This research provides an insightful understanding into the intricate dynamics between frequency components and the effectiveness of backdoor attacks.\n2. The paper provides detailed experiments that comes with insightful conclusion, which is considered a good contribution to the backdoor community."
                },
                "weaknesses": {
                    "value": "Two important works on frequency-based backdoor attack are missed: \n[1] Zeng, Y., Park, W., Mao, Z.M. and Jia, R., 2021. Rethinking the backdoor attacks' triggers: A frequency perspective. In Proceedings of the IEEE/CVF international conference on computer vision (pp. 16473-16481).\n[2] Feng, Y., Ma, B., Zhang, J., Zhao, S., Xia, Y. and Tao, D., FIBA: Frequency-Injection based Backdoor Attack in Medical Image Analysis Supplementary Material.\nThe paper should clearly state the differences between the current work and these previous works."
                },
                "questions": {
                    "value": "Please refer to the weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Privacy, security and safety"
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission912/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission912/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission912/Reviewer_F6E6"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission912/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698441639558,
            "cdate": 1698441639558,
            "tmdate": 1699636017993,
            "mdate": 1699636017993,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pGHZ04Zxct",
                "forum": "mYhH0CDFFa",
                "replyto": "r7oc6LUIfo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer F6E6 (Part 1)"
                    },
                    "comment": {
                        "value": "Thank you so much for your thoughtful comments and recognition of the significance of our work. We hope the following results and explanations address your concerns.\n\nWe have carefully read the two important tasks you listed and we are very sorry for their omission. So below we will first introduce our contributions, and then clearly and in detail explain the differences from their work. A discussion of our work and their work has been added to Appendix A.8.\n\nOur work mainly explores the mechanism of CNN memory poisoning samples from the perspective of frequency domain. We analyze the changes in different frequency components of existing visible and invisible triggers with good performance. We found that CNN can generalize to poisoned samples by remembering the frequency domain distribution changed by triggers. We also explore the impact of triggering perturbations with different frequency domain components on the generalization of poisoning models for visible and invisible backdoor attacks, and demonstrate that high-frequency components are more susceptible to perturbations compared to low-frequency components. In addition, in order to improve the concealment of visible triggers in specific scenarios, we propose a general strategy to hide visible triggers. We also propose a backdoor attack algorithm based on low-frequency semantic information, which is proven to be effective and can bypass multiple backdoor defense methods.\n\nLiterature [1] also adds triggers in the frequency domain. What we have in common is that we all use the low-frequency information of the target category image to introduce the semantics of the target category into the poisoned image. But our methods of generating triggers and specific training are completely different.\n\nLiterature [1] uses FFT to transform the image from the spatial domain to the frequency domain, and then linearly adds the low-frequency component of the clean image and the low-frequency component of the target image through a certain ratio as the low-frequency component of the poisoned image, thereby achieving frequency injection of the trigger. Literature [1] uses FFT to transform the image from the spatial domain to the frequency domain, and then linearly adds the low-frequency component of the clean image and the target image through a certain ratio as the low-frequency component of the poisoned image, thereby achieving frequency injection of the trigger. And their training process introduced noise images similar to those in the literature [2] to enhance the uniqueness of the trigger. However, our frequency-based backdoor attack method selects part of the low-frequency components of the target category image as the raw material of the trigger. The poisoned image is then generated by adding triggers to the mid- and high-frequency components of the clean image through operations such as upsampling. And in order to improve the generalization of CNN to poisoned images whose label is the target category, we randomly select the low-frequency components of the image from the target category as raw materials when generating each poisoned image, and do not use noise images.\n\n\n[1] Feng, Y., Ma, B., Zhang, J., Zhao, S., Xia, Y. and Tao, D., FIBA: Frequency-Injection based Backdoor Attack in Medical Image Analysis Supplementary Material. The paper should clearly state the differences between the current work and these previous works.\n\n[2] Tuan Anh Nguyen and Anh Tuan Tran. Wanet - imperceptible warping-based backdoor attack. In ICLR, 2021."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700275813734,
                "cdate": 1700275813734,
                "tmdate": 1700275813734,
                "mdate": 1700275813734,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "oKtYixRB1F",
            "forum": "mYhH0CDFFa",
            "replyto": "mYhH0CDFFa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission912/Reviewer_Uoqj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission912/Reviewer_Uoqj"
            ],
            "content": {
                "summary": {
                    "value": "This paper propose to study the backdoor attack on CNN in frequency domain. It shows that high frequency component are more susceptible to perturbations. It further proposes a strategy for rendering visible backdoor attack invisible and proposes a backdoor attack algorithm based on low-frequency component from target class."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1). It is interesting and novel to study the backdoor attack on CNN in frequency domain. The proposed algorithm utilizing low-frequency component from target class is also interesting. \n\n2). Overall, the paper is clear and well-written."
                },
                "weaknesses": {
                    "value": "1). The experiments is not enough to show the effectiveness of the proposed method against defense. For backdoor attacks, it is easy to achieve high ASR with no defense. Though empirical evidences have been provided in Fig.6, I still have doubts on the effectiveness of the propsoed method against defense. It would be more convincing to report the result against some defense methods e.g. the defense methods supported by backdoorbench [1].\n\n2). For the strategy rendering visible backdoor attack invisible, it lacks comparison with other invisible backdoor attacks. Since invisible backdoor attacks mainly rely on the perturbation on high frequency components, what is the relation or difference between visible backdoor attack and invisible backdoor attack after masking the low-frequency perturbation?\n\n3). Fig.4 shows that it requires smaller perturbation on high frequency than on low frequency to achieve high attack success rate. However, when comparing to the original image, since most mass concentrate in low-frequency components, the small perturbation on high frequency might be relatively large comparing to the original image. It might require more results to show that high frequency components are more susceptible to backdoor attack\n\nOverall, I think the experiments in this paper is not sufficient to support the analysis in this paper and verify the effectiveness of the proposed method.\n\n[1] Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Chao Shen. BackdoorBench: A Comprehensive Benchmark of Backdoor Learning. NeurIPS 2022."
                },
                "questions": {
                    "value": "As mentioned in the weakness section, I have several questions regarding the experiments in this paper.\n\n1). When rendering visible backdoor attack invisible, what is the relation between the visible backdoor attacks and invisible backdoor attacks?\n\n2). For both the rendering strategy and the proposed backdoor attack algorithm, are they still be effective facing conventional defence methods?\n\n3). It has already been observed that high frequency components are more susceptible to attacks such as adversarial attacks. Is there any new takeaways regarding the backdoor attack?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission912/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission912/Reviewer_Uoqj",
                        "ICLR.cc/2024/Conference/Submission912/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission912/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698571371649,
            "cdate": 1698571371649,
            "tmdate": 1700558645691,
            "mdate": 1700558645691,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Ke7d9SZOjo",
                "forum": "mYhH0CDFFa",
                "replyto": "oKtYixRB1F",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission912/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission912/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Uoqj (Part 1)"
                    },
                    "comment": {
                        "value": "Thank you very much for your time and insightful comments. We are encouraged that our work is recognized. We hope the following new clarifications and results can address your concerns. We are happy to answer more questions and conduct more experiments if needed.\n\nQ1\uff1aWhen rendering visible backdoor attack invisible, what is the relation between the visible backdoor attacks and invisible backdoor attacks?\n\nA1: In this work, we achieve the invisibility of visible backdoor attacks from the frequency domain. In fact, we modify the visible trigger in the frequency domain to make it invisible and still maintain good offensiveness. It can be said that the generated invisible trigger uses a visible trigger with good performance as raw material, and uses the high-frequency disturbance of the visible trigger to implement a backdoor attack. The attack performance of the visible trigger will also affect the attack performance of the generated invisible trigger to a certain extent.\n\tThe invisible strategy we propose makes up for the shortcomings of most existing visible backdoor attacks, that is, most visible backdoor attacks [1, 2, 3] have good attack performance but poor stealth, making them Application scenarios are limited. Using the invisible strategy we proposed can help visible triggers be applied in scenarios with high stealth requirements.\n\nQ2\uff1aFor  the proposed backdoor attack algorithm, are they still be effective facing conventional defence methods?\n\nA2\uff1aThanks for pointing this out. We used GradCam, Fine-Pruning and STRIP to evaluate backdoor defense in our original paper submission, and the results proved that our frequency domain-based backdoor attack algorithm is effective in combating backdoor defense (Figure 6). Now we have added three new backdoor defense methods, NC [4], DBD [5] and CLP [6], to further evaluate the frequency domain-based attack algorithm we proposed respectively. The experimental results are shown in Tables 1 and 2 as below. Experimental results show that although the performance of our attack algorithm is slightly degraded on some defense algorithms, it is still effective. We have added this part to Appendix A.7.\n  \nTable 1: Mitigation results of backdoor defense methods DBD and NC on our algorithm\n\n|                                    | **DBD-BA** | **DBD-ASR** | **NC-BA** | **NC-ASR** |\n|------------------------------------|------------|-------------|-----------|------------|\n| BadNet [1]                  | 89.65      | 1.28        | 89.05     | 1.27       |\n| Blended[7]                | 69.91      | 99.68       | 93.47     | 99.92      |\n| WaNet[8]                    | 80.9       | 6.61        | 91.80     | 7.53       |\n| ISSBA[9]                  | 63.5       | 99.51       | 90.99     | 0.58       |\n| Ours($\\rho=0.4$,$\\varepsilon=\\frac{1}{3}$) | 70.29  | 100.00      | 94.26     | 91.80      |\n\nTable 2 Mitigation results of our algorithm by backdoor defense method CLP\n\n|                                    | **CLP-BA** | **CLP-ASR** |\n|------------------------------------|------------|-------------|\n| IAD[2]                     | 90.3       | 2.17        |\n| Blended[7]                 | 91.32      | 99.74       |\n| WaNet[8]                    | 81.91      | 78.42       |\n| ISSBA[9]                   | 91.38      | 68.13       |\n| Ours($\\rho=0.4$,$\\varepsilon=\\frac{1}{3}$) | 94.55 | 98.41       |\n\n[1] Gu T, Dolan-Gavitt B, Garg S. Badnets: Identifying vulnerabilities in the machine learning model supply chain[J]. arXiv preprint arXiv:1708.06733, 2017.\n\n[2] Nguyen T A, Tran A. Input-aware dynamic backdoor attack[J]. Advances in Neural Information Processing Systems, 2020, 33: 3454-3464.\n\n[3] Bagdasaryan E, Shmatikov V. Blind backdoors in deep learning models[C]//30th USENIX Security Symposium (USENIX Security 21). 2021: 1505-1521.\n\n[4] Wang B, Yao Y, Shan S, et al. Neural cleanse: Identifying and mitigating backdoor attacks in neural networks[C]//2019 IEEE Symposium on Security and Privacy (SP). IEEE, 2019: 707-723.\n\n[5] Huang K, Li Y, Wu B, et al. Backdoor defense via decoupling the training process[J]. arXiv preprint arXiv:2202.03423, 2022.\n\n[6] Zheng R, Tang R, Li J, et al. Data-free backdoor removal based on channel lipschitzness[C]//European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2022: 175-191.\n\n[7] Chen X, Liu C, Li B, et al. Targeted backdoor attacks on deep learning systems using data poisoning[J]. arXiv preprint arXiv:1712.05526, 2017.\n\n[8]Nguyen A, Tran A. Wanet--imperceptible warping-based backdoor attack[J]. arXiv preprint arXiv:2102.10369, 2021.\n\n[9]Li Y, Li Y, Wu B, et al. Invisible backdoor attack with sample-specific triggers[C]//Proceedings of the IEEE/CVF international conference on computer vision. 2021: 16463-16472."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700275260775,
                "cdate": 1700275260775,
                "tmdate": 1700275260775,
                "mdate": 1700275260775,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Ws4parqF2g",
                "forum": "mYhH0CDFFa",
                "replyto": "oKtYixRB1F",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission912/Reviewer_Uoqj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission912/Reviewer_Uoqj"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "I thank author for the detailed response. The experimental results against defense methods have addressed my concerns over the effectiveness of the proposed methods. Therefore I am rising my rating to 6."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission912/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700558615798,
                "cdate": 1700558615798,
                "tmdate": 1700558615798,
                "mdate": 1700558615798,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]