[
    {
        "title": "Efficient Diversified Attack: Multiple Diversification Strategies Lead to the Efficient Adversarial Attacks"
    },
    {
        "review": {
            "id": "g9YkrJ89Cv",
            "forum": "qpuxHL9X3d",
            "replyto": "qpuxHL9X3d",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1746/Reviewer_pdmN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1746/Reviewer_pdmN"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents an approach to improving adversarial attacks on deep learning models. The paper emphasizes the importance of diversification and intensification in constructing strong attacks. It introduces the multi-directions/objectives (MDO) strategy, employing multiple search directions and objective functions for diversification. The strategy results in more diverse and potent attacks. Furthermore, the Efficient Diversified Attack (EDA), combining the MDO and multi-target strategies, outperforms existing attacks in terms of diversification and efficiency."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Research on adversarial examples is an important research topic. \n- The paper is overall well-written and provides extensive supplementary material. \n- While relatively intuitive, the discoveries in this work are novel to the best of my knowledge. \n\t- Diversification Strategy: Introduces the multi-directions/objectives (MDO) strategy, a unique approach using multiple search directions and objective functions to enhance diversification in adversarial attacks.\n\t- Efficient Diversified Attack (EDA), combines the MDO and multi-target strategies resulting in a fast and potent attack"
                },
                "weaknesses": {
                    "value": "- Overall the performance improvements are only marginal compared to previous results. \n- Previous works are concerned with the transferability of adversarial attacks. A transferability evaluation is missing. \n- The work mainly evaluates ResNet architectures. These days, the trend moves to the usage of transformer architectures. Hence an evaluation against transformer architectures would be beneficial and more timely. \n- The paper uses many abbreviations, making it difficult to comprehend at times."
                },
                "questions": {
                    "value": "Please address the points in my weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1746/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1746/Reviewer_pdmN",
                        "ICLR.cc/2024/Conference/Submission1746/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1746/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698131385380,
            "cdate": 1698131385380,
            "tmdate": 1700631041652,
            "mdate": 1700631041652,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TLTPIM72Zj",
                "forum": "qpuxHL9X3d",
                "replyto": "g9YkrJ89Cv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1746/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1746/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate the reviewer's comment on our paper. We respond to each comment in turn.\n\n**Weakness 1**\n\n> Overall the performance improvements are only marginal compared to previous results.\n\nWe have responded as a Global comment. Please refer to it.\n\n**Weakness 2**\n\n> Previous works are concerned with the transferability of adversarial attacks. A transferability evaluation is missing.\n\nWe have tested the transferability of EDA for several models.\nThe results show that EDA can generate more transferable adversarial examples than A$^3$ and other baselines, regardless of the data set. The performance improvement is about 5 to 10% for CIFAR10, 2 to 7% for CIFAR100, and 1.6 to 4% for ImageNet. Please take a look at Appendix L, p. 43 in the revised paper for details.\n\n**Weakness 3**\n\n> The work mainly evaluates ResNet architectures. These days, the trend moves to the usage of transformer architectures. Hence an evaluation against transformer architectures would be beneficial and more timely.\n\nWe agree that the evaluations against transformer-based architectures are beneficial and more timely. In Appendix I (p.41-42 in the revised paper), we examined the performance of EDA for several models with transformer-based architectures. The experimental results in Table 21 show that EDA consistently outperforms AA and A$^3$ in terms of both computational efficiency and attack performance.\n\n**Weakness 4**\n\n> The paper uses many abbreviations, making it difficult to comprehend at times.\n\nA table summary of the abbreviations was added at the beginning of the appendix to reduce reading difficulty caused by the large number of abbreviations. (Table 3, p.15)\n\n\nWe look forward to hearing from you regarding our submission. We would be glad to respond to any further questions and comments that you may have."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1746/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700129412905,
                "cdate": 1700129412905,
                "tmdate": 1700129412905,
                "mdate": 1700129412905,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rKyPSfzmgt",
                "forum": "qpuxHL9X3d",
                "replyto": "TLTPIM72Zj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1746/Reviewer_pdmN"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1746/Reviewer_pdmN"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the rebuttal"
                    },
                    "comment": {
                        "value": "Hello authors, thank you for the detailed answers. My concerns were mainly addressed. From my side, I am increasing my score for now."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1746/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700631071808,
                "cdate": 1700631071808,
                "tmdate": 1700631071808,
                "mdate": 1700631071808,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "z0BxYYvoAW",
            "forum": "qpuxHL9X3d",
            "replyto": "qpuxHL9X3d",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1746/Reviewer_hF3e"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1746/Reviewer_hF3e"
            ],
            "content": {
                "summary": {
                    "value": "The paper shows the ability to diversify the adversarial attck based on multi-restart is limited. The authors propose the multi-directions/objectives (MDO) strategy which shows higher diversification performance and attack performance. A combination of MDO and multi-target strategies is also provided. The experimental results show a relationship between attack and diversification performances."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The idea is neat.\n- The experimental results are plentiful."
                },
                "weaknesses": {
                    "value": "- The proposed approach is a white-box attack.\n- Comparison with ACG attack (Yamamura et al., 2022) is not provided in Table 1.\n- From Table 1 and 6, EDA is not better than GS+LS (ADS). The authors should give more analysis on that.\n- Too much mathematics.\n- It is hard to follow the paper. What is PAS? What does the graph $G(X,\\Theta)$ mean?"
                },
                "questions": {
                    "value": "- What does the total distortion of the proposed method under $l_\\infty$ attack.\n- What is the motivation of generalized-DLR (G-DLR) loss, $L_{G-DLR, q}$.\n- Does the initial point selection method $\\phi$ and the step size update rule $\\psi$ matter? The authors do not provide details on these.\n- What does \"the highest objective values found by an attack $a$ from $R$ initial points\" mean?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Privacy, security and safety"
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1746/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1746/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1746/Reviewer_hF3e"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1746/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698748421357,
            "cdate": 1698748421357,
            "tmdate": 1699636103720,
            "mdate": 1699636103720,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LiF5Z6UdtL",
                "forum": "qpuxHL9X3d",
                "replyto": "z0BxYYvoAW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1746/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1746/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response (1/2)"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer's comment on our paper. We respond to each comment in turn.\n\n**Weakness 1**\n\n> The proposed approach is a white-box attack.\n\nWe focus on white-box attacks because the security of deep learning models can be significantly improved by accurate robustness evaluations and the development of robust models based on stronger attacks.\n\nWhite-box and black-box attacks have different advantages and disadvantages from each other.\nIt is known that the white-box setting can create a more potent attack than the black-box case. Therefore, developing white-box attacks helps develop robust models and evaluate robustness. However, from an attacker's point of view, a white-box setting is unrealistic.\n\nThe black-box setting assumes the attacker can access the model's output alone. Therefore, the development of black-box attacks has the advantage of leading to more realistic threat assumptions. However, the black-box attacks tend to show lower attack performance than the white-box attacks and require many queries.\n\n**Weakness 2**\n\n> Comparison with ACG attack (Yamamura et al., 2022) is not provided in Table 1.\n\nWe added the experimental results for ACG to Table 1. The proposed methods consistently showed higher performance than ACG.\n\n**Weakness 3**\n\n> From Tables 1 and 6, EDA is not better than GS+LS (ADS). The authors should give more analysis on that.\n\nWe believe the reviewer is mistaken on this point. We carefully checked the experimental results, but the results showed that EDA consistently performed better than GS+LS (ADS). To make this comparison easier to understand, a table comparing the robust accuracy of EDA and GS+LS (ADS) was added to the Appendix as Table 19 (p.40 in the revised paper).\n\n**Weakness 4**\n\n> Too much mathematics.\n\nA table summary of mathematical symbols was added to the appendix to reduce reading difficulty caused by the large number of mathematical symbols. (Table 4, p.16)\n\n**Weakness 5**\n\n> It is hard to follow the paper. What is PAS? What does the graph $G(X,\\theta)$ mean?\n\nPAS stands for Prediction Aware Sampling. We have changed the title of Appendix E (p.35) from Prediction Aware Sampling to Prediction Aware Sampling (PAS). In addition, the definition of $G(X, \\theta)$ was revised (p.20, after the equation (10)). \n$G(X,\\theta)$ is a graph with nodes $X$ and edges between nodes whose Euclidean distance is less than a given threshold $\\theta$."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1746/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700129240771,
                "cdate": 1700129240771,
                "tmdate": 1700129383764,
                "mdate": 1700129383764,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "G1BSNwrdFi",
            "forum": "qpuxHL9X3d",
            "replyto": "qpuxHL9X3d",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1746/Reviewer_GZwH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1746/Reviewer_GZwH"
            ],
            "content": {
                "summary": {
                    "value": "This paper contributes a white-box adversarial attack framework of Efficient Diversified Attack (EDA) with a new multi-directions/objectives (MDO) strategy. This method focuses on the diversification of adversarial examples (AE) by utilizing multiple attack methods and objective or loss function. The effectiveness of MDO depends on appropriate search directions (\u03b4) and objective functions (L). Thus, the authors propose an Automated Diversified Selection (ADS) algorithm to select the combinations of \u03b4 and L. The MDO strategy consists of two phases: the diversification phase (global search, GS) and the intensification phase (local search, LS). The authors conduct experiments to demonstrate the effectiveness of ADS and the GS+LS, and the efficiency of MDO in comparison to baselines."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThe paper is demonstrated well. The procedure figure and most diagrams are easy to understand. The presentation is easy to follow.\n\n2.\tThe authors test their methods on 41 models and 21 different defenses, covering typical datasets of CIFAR-10/100 and ImageNet.\n\n3.\tThe method reduces the number of queries and time spent to 86.9% on average, according to Table 2."
                },
                "weaknesses": {
                    "value": "1.\tEven though this method saves time, the increase in attack success rate is little.\nIn Table 2, the delta of accuracy is very small. In Table 6 in the appendix, the delta of accuracy is less than 0.1% in most cases.\n\t\n2.\tThe diversification of EDA is not good enough.\nIn Figure 5, the Diversity Index (DI) of MT_cos exceeds that of the authors' methods. \n\n3.\tThe authors\u2019 methods are not consistently effective.\nIn Table 6, there are some cases that the authors\u2019 method even takes longer time than the baseline. Considering the weakness in lack of improvement in diversification and effectiveness, could the authors discuss the tradeoff between efficiency and diversification?\n\n4.\tThis paper does not evaluate the effectiveness of combining these methods with their method.\nThere are many existing methods for improving the success rate of adversarial attacks, such as [1] and [2]. Can EDA and MDO be combined with them? If so, what will the diversification and effectiveness of the authors\u2019 method and baselines be?\n\n5.\tThere is a contradiction between the text and the figure.\nIn section 4.1, the paper claims that \u201cFigure 6 indicates that GS+LS found AEs in fewer queries than MT_cos\u201d. However, in Figure 6, it seems GS+LS and MT_cos have similar numbers of queries, and there are more cases in which MT_cos takes fewer queries. Could the authors explain the reason? What do the average lines represent?\n\n[1] Xie, C., Zhang, Z., Zhou, Y., Bai, S., Wang, J., Ren, Z., & Yuille, A. L. (2019). Improving transferability of adversarial examples with input diversity. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 2730-2739).\n\n[2] Dong, Y., Pang, T., Su, H., & Zhu, J. (2019). Evading defenses to transferable adversarial examples by translation-invariant attacks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 4312-4321)."
                },
                "questions": {
                    "value": "1.\tCan EDA and MDO be combined with other augmentation methods mentioned above? If so, what will the diversification and effectiveness of the authors\u2019 method and baselines be?\n\n2.\tCould the authors explain the data in Figure 6? What do the average lines represent?\n\n3.\tConsidering the weakness in lack of improvement in diversification and effectiveness, could the authors discuss the tradeoff between efficiency and diversification?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1746/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698828948878,
            "cdate": 1698828948878,
            "tmdate": 1699636103651,
            "mdate": 1699636103651,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9jek4NewiB",
                "forum": "qpuxHL9X3d",
                "replyto": "G1BSNwrdFi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1746/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1746/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response (1/3)"
                    },
                    "comment": {
                        "value": "> Considering the weakness in lack of improvement in diversification and effectiveness, could the authors discuss the tradeoff between efficiency and diversification?\n\nThe reviewer has raised an important question. Before answering the question directly, let me explain the relationship between attack performance, diversification, and intensification.\n\n### For weakness 1 (The increase in attack success rate is little.)\n\nAs discussed in detail in the global comment, the performance gains from the proposed method are large enough compared to the improvement in recent attacks.\n\n### For weakness 2 (Not enough improvement in diversification)\n\nAs Weakness 2, the reviewer pointed out that EDA is not diversified enough because the Diversity Index of EDA is smaller than that of MTcos. However, higher diversification is not always better. What is important in improving search performance is to strike a balance between diversification and intensification [1]. An example is step size control. Searching with a large step size promotes diversification, but it is difficult to further improve the objective value by continuing the search at the same step size. However, gradually decreasing the step size can adjust the balance between diversification and intensification. As a result, as existing studies have shown, the control of gradually decreasing step size contributes to performance improvement. Given that EDA showed higher attack performance than MTcos, Figure 5 just shows that EDA has a more appropriate balance of diversification and intensification than MTcos.\n\nIn addition, there is no general definition of diversification. In the main text, we evaluated diversification based on the Diversity Index to check whether the search points form any cluster. However, different definitions of diversification may lead to different analysis results. In Appendix D.6 (p.31 in the revised paper), we quantified the degree of diversification using a measure based on the Euclidean distance. This analysis enables us to understand the diversification of EDA from a perspective that cannot be considered in the Diversity Index. Figure 14 (p.32 in the revised paper) shows the difference in the degree of diversification measured by the Euclidean distance-based measure. In this case, the difference in the degree of diversification between EDA and MT$_{cos}$ is smaller than those measured by the Diversity Index. \n\nThe analysis results using the two diversification indices suggest that EDA and MT$_{cos}$ diversify their search differently.  Based on the above description, we discuss the tradeoff between diversification and efficiency.\n\n### Trade off between efficiency and diversification.\n\nDiversification and computational efficiency are not necessarily trade-offs. If diversification and intensification are appropriately balanced, it is possible to enumerate different local solutions faster. In other words, appropriate diversification and intensification may improve both computational efficiency and search performance at the same time. The experimental results in Table 8 in our revised paper show that EDA shows higher attack performance in less computation time than Adaptive Auto Attack for many models. Therefore, Table 8 and Figure 5 in our revised paper support our contention that EDA balances diversification and intensification well.\n\nIn addition, differences in attack performance should be considered when comparing computational efficiency. Table 8 in the revised paper shows that EDA showed higher attack performance than Adaptive Auto Attack for all models where EDA spent relatively more computation time.\nAdaptive Auto Attack terminates its search with a different number of queries per model depending on its search progress. Therefore, the potential reason for the difference in efficiency is that Adaptive Auto Attack terminates its search, leaving room for performance improvement, resulting in a shorter time than EDA.\n\n[1] Crepins\u030cekMatej, LiuShih-Hsi, and MernikMarjan. Exploration and exploitation in evolutionary algorithms. ACM Computing Surveys (CSUR), 45(3):33, jul 2013. doi: 10.1145/2480741.2480752."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1746/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700129018197,
                "cdate": 1700129018197,
                "tmdate": 1700129153385,
                "mdate": 1700129153385,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Sq6Awesy7C",
                "forum": "qpuxHL9X3d",
                "replyto": "9jek4NewiB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1746/Reviewer_GZwH"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1746/Reviewer_GZwH"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your response. If higher diversification is not always better, why do we need to compare different methods in terms of their diversification? Even when using the new Euclidean distance-based measure, the proposed method does not perform significant better."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1746/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700742139082,
                "cdate": 1700742139082,
                "tmdate": 1700742139082,
                "mdate": 1700742139082,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "EjziqIpCj0",
            "forum": "qpuxHL9X3d",
            "replyto": "qpuxHL9X3d",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1746/Reviewer_C5Ls"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1746/Reviewer_C5Ls"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors propose techniques to enhance the adversarial attack suite in terms of effectiveness and efficiency against robust models. Specifically, they start with a given search space containing possible gradient directions $\\delta$ and losses $L$, and identify the top combinations of search direction $\\delta$ and objective functions $L through Automated diversification search (ADS). They then proceed with a two-stage approach, 1 initial coarse-grained attack (GS) followed by a  2. localized attack within the region found by the best point in stage 1.  Furthermore, they combine the proposed approach with MultiTarget (MT) to obtain an Efficient diversified Attack."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The authors present a unified formulation of an adversarial attack, encompassing aspects such as initialization, step size updates, search directions, and loss functions. This lets us to study each factor in a fine-grained manner and ultimately improve the attack performance\n\n- The empirical evaluation is conducted on 41 models, which unquestionably provides a clear and comprehensive perspective and establishes robust baselines for future research endeavors."
                },
                "weaknesses": {
                    "value": "**Presentation:**\n\n- In my initial reading, I found the paper's notation to be confusing. Moreover, all the crucial algorithms (ADS, GS, LS, EDA) are deferred to the Appendix, making for a less-than-smooth reading experience. Within the Appendix itself, these algorithms are distributed at different places in the 38-page paper, further complicating the reading process. I would request to consider moving a few of them (ADS, GS, LS, EDA, Target selection) to the main draft\n\n- As also suggested by Reviewer pdmN, this paper had many abbreviations and particularly difficult to follow sometimes. I request the authors to simplify the paper presentation and notations.\n\n**Technical:**\n\n- In my view, the proposed ADS for selecting the most effective search direction ($\\delta$) and loss function ($L$) based on the diversity measures at both input and output, appears quite straightforward. Additionally, the Diversity Index (DI) has been widely studied in Yamamura et al. 2021, thereby paper's technical contribution may be somewhat limited as it just picks the combinations based on this measure and $P_i^e$.\n\n- The GS and LS techniques introduced within the search framework are, to some extent, heuristic in nature. Although ablation studies have been carried out with respect to N1, N2, and N3, the current framework's configuration, comprising GS with N1 and N2 iterations, followed by LS with N3 iterations, strikes me as somewhat heuristic.\n\n- Upon closer examination, the differences in performance between ADS and Random appear negligible in Table 1, and the variation between GS+LS (ADS) and GS+LS (Random) seems relatively small. On average, across nine models, this difference stands at less than approximately 0.05% (please correct me if I'm wrong).\n\n- Notably, there exists a substantial number of hyperparameters tied to ADS, GS, LS, and the target selection schemes. While the paper presents ablation studies, I anticipate that the widespread adoption of the proposed method as a robust alternative to the AutoAttack suite might pose a considerable challenge. \n\n- ADS requires access to the dataset. The authors perform ADS on 1% of the data, while AutoAttack and other baseline attacks operate on a per-datapoint basis without depending on additional datapoints."
                },
                "questions": {
                    "value": "- Why are the step sizes set to 2*$\\epsilon$ for $N_1$ iterations, $N_2$ iterations with $\\epsilon$, and $N_3$ iterations with $\\epsilon/2$?\n\n- What is the individual influence of the two terms $P_i^e$ and DI(.) in the overall ADS search performance?\n\n- What combinations were discovered by ADS for the different models? Are there any insights into the top $n_a$ combinations found by ADS for different models?\n\n- Why is ADS performed in the LS stage? What are the benefits of conducting it before LS? While I understand that the initial points are different at these two stages, could the authors provide an empirical analysis of employing ADS in the LS stage?\n\n- Are top combinations {$\\delta_{a_j^*}, L_{a_j^*}$} found at GS, LS stages correlated? \n\n- Can you report the average performance over  9 models in Table 1 for all methods \n\n- In the absence of a dataset to perform ADS, is the combinations found by ADS transferable in the cross-domain setting?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1746/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1746/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1746/Reviewer_C5Ls"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1746/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698835321893,
            "cdate": 1698835321893,
            "tmdate": 1699879963335,
            "mdate": 1699879963335,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6x7yVO7wfL",
                "forum": "qpuxHL9X3d",
                "replyto": "EjziqIpCj0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1746/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1746/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response (1/3)"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer's comments on our paper. The order of comments has been changed in order to provide a concise and clear response.\n\n### Technical weakness 1\n\n> In my view, the proposed ADS for selecting the most effective search direction and loss function based on the diversity measures at both input and output, appears quite straightforward. Additionally, the Diversity Index (DI) has been widely studied in Yamamura et al. 2021, thereby paper's technical contribution may be somewhat limited as it just picks the combinations based on this measure and $P_i^e$.\n\nWe acknowledge that ADS has a clear and simple approach. However, the major contribution of ADS is its ability to determine the combination of objective function and update direction at low computational cost.\n\nAlthough various objective functions and update formulas have been proposed, no method has been proposed to make good use of them. The related research is those for finding ensembles of attacks, such as CAA [1] and AutoAE [2]. These methods determine the ensemble based on the attack success rate or the best objective function value of the candidate attack methods.\nTherefore, they are computationally expensive because the candidate attack methods must be executed in advance. Due to the many combinations of objective functions and search directions, it is impractical to select a pair of objective functions and search directions using these methods from a computational cost perspective.\n\nOn the contrary, by focusing on the degree of search diversification, ADS has dramatically reduced the computational cost of combination decisions. ADS allows for better utilization of existing objective functions and update formulas, which may encourage the development of adversarial robustness research. In addition, ADS could facilitate the automation of the robustness evaluation process. For example, we can construct an ensemble of attacks from automatically generated candidates of the ensemble using ADS, CAA, and AutoAE. Thus, ADS is considered to be a versatile and valuable algorithm.\n\n[1] Xiaofeng Mao, Yuefeng Chen, Shuhui Wang, Hang Su, Yuan He, and Hui Xue. Composite adversarial attacks. AAAI 2021.\n\n[2] Shengcai Liu, Fu Peng, and Ke Tang. Reliable Robustness Evaluation via Automatically Constructed Attack Ensembles. AAAI 2023.\n\n### Technical weakness 2 and question1\n\n> The GS and LS techniques introduced within the search framework are, to some extent, heuristic in nature. Although ablation studies have been carried out with respect to N1, N2, and N3, the current framework's configuration, comprising GS with N1 and N2 iterations, followed by LS with N3 iterations, strikes me as somewhat heuristic.\n\n> Why are the step sizes set to 2$\\epsilon$ for $N_1$ iterations, $N_2$ iterations with $\\epsilon$, and  $N_3$ iterations with $\\epsilon/2$?\n\nWe determined the step size inspired by the APGD heuristic, which is widely used and works well. The APGD heuristic has eight checkpoints. The checkpoints are written down as $w_1=\\lceil0.22N\\rceil, w_2=\\lceil0.41N\\rceil, w3=\\lceil0.57\\rceil,...,w_8=\\lceil0.99N\\rceil$, where $N$ is the total iterations.\nOur framework's $N_1$, $N_2$, and $N_3$ iterations correspond to the search from checkpoint $w_1$, $w_1$ to $w_2$, and $w_2$ and beyond in the APGD heuristic, respectively.\n\nAPGD has an initial step size of $2\\varepsilon$ and halves the step size if the condition is satisfied at each checkpoint. If the condition is satisfied at all checkpoints, the step size is $2\\varepsilon$ up to $w_1$, $\\varepsilon$ between $w_1$ and $w_2$, and $\\varepsilon/2$ after $w_2$. Based on this, we set the step size in the proposed framework to $2\\varepsilon$, $\\varepsilon$, and $\\varepsilon/2$ for $N_1$, $N_2$, and $N_3$ iterations, respectively.\n\n### Technical weakness 4\n\n> Notably, there exists a substantial number of hyperparameters tied to ADS, GS, LS, and the target selection schemes. While the paper presents ablation studies, I anticipate that the widespread adoption of the proposed method as a robust alternative to the AutoAttack suite might pose a considerable challenge.\n\nEDA can be used without hyperparameter tuning in practice, similar to AutoAttack.\n\nAutoAttack's components, APGD, FAB, and Square attack, have explicitly given hyperparameters and magic numbers heuristically determined by the authors. While AutoAttack is not inherently parameter-free, their default parameters are carefully determined.\n\nOur ablation study suggests that EDA is robust to hyperparameter settings. In addition, the particularly influential parameter, step size, is determined based on the APGD heuristic, which is widely used and effective. Therefore, EDA can be used without hyperparameter tuning in practice."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1746/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700128616979,
                "cdate": 1700128616979,
                "tmdate": 1700128616979,
                "mdate": 1700128616979,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IBqcyMWFsc",
                "forum": "qpuxHL9X3d",
                "replyto": "EjziqIpCj0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1746/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1746/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author response (2/3)"
                    },
                    "comment": {
                        "value": "### Technical weakness 3\n\n> Upon closer examination, the differences in performance between ADS and Random appear negligible in Table 1, and the variation between GS+LS (ADS) and GS+LS (Random) seems relatively small. On average, across nine models, this difference stands at less than approximately 0.05% (please correct me if I'm wrong).\n\nAs mentioned in the global comment, based on the existing research, even an improvement in attack performance from AutoAttack of less than 0.1% is considered sufficient. Considering that GS+LS(ADS) showed competitive attack performance as AutoAttack, the difference between GS+LS(ADS) and GS+LS(random) is large enough.\n\nIn addition, the performance of GS+LS(random) is expected to be unstable because GS+LS(random) is completely dependent on random numbers for selection. On the contrary, GS+LS(ADS) are expected to show stable and high performance.\n\n\n### Questions 2 and 5\n\n> Question 5: Are top combinations $\\{(\\delta_a, L_a)\\}$ found at GS, LS stages correlated?\n\nThe brief answer is No. The potential reasons are: 1. $P_i^e$ and DI play different roles from each other, 2. the ACG's search direction may be similar to the steepest for small step sizes, and 3. the difference between Nesterov's acceleration gradient direction and gradient direction. Appendix D.8 (p. 33 in revised paper) provides further information.\n\nWe explain the role of $P_i^e$ and DI as the answer to the question 2.\n\n> Question 2: What is the individual influence of the two terms $P_i^e$ and DI(.) in the overall ADS search performance?\n\nThe $P_i^e$ measures the degree of diversification in the output space during the search. Therefore, a pair with the largest $P_i^e$ is expected to search for a high diversity in the output space. In addition, from Yamamura et al. (2022), it can be assumed that the ACG direction increases $P_i^e$, while the steepest-like direction does not. From the above, it is considered that the pair with the maximum $P_i^e$ is likely to include the ACG direction.\n\nIn our use case, DI measures the diversity of the best point set obtained by the search. In other words, DI represents the dissimilarity between the best points. That is, we expect that pairs with the largest DI are more likely to enumerate dissimilar solutions. Intuitively, updates in diverse directions contribute to the enumeration of dissimilar solutions. Given that the search direction is gradient-dependent, the pair with the largest DI is likely to include a variety of objective functions and update formulas.\n\n### Question 4\n\n> Why is ADS performed in the LS stage? What are the benefits of conducting it before LS? While I understand that the initial points are different at these two stages, could the authors provide an empirical analysis of employing ADS in the LS stage?\n\nThe advantage of performing ADS in LS is that it reduces the possibility of redundant searches. The search direction of ACG is likely to be selected in GS, and the direction of ACG is more likely to be similar to the steepest direction for small step sizes. Therefore, an efficient search may not be possible if the search is continued using the pair selected in GS. In addition, given the multimodal nature of the objective function, searching in Nesterov's accelerated gradient direction and the gradient direction may help to find different local solutions.\n\n### Question 3\n\n> What combinations were discovered by ADS for the different models? Are there any insights into the top $n_a$ combinations found by ADS for different models?\n\nThere are slight differences in the pairs selected for each model. However, the trend is consistent: the ACG's direction is more likely to be selected for GS, and the Nesterov's accelerated gradient direction is more likely to be selected for LS.\nIn addition, experimental results on EDA's transferability suggest that EDA can generate highly transferable adversarial examples.\nThese experimental results suggest that different models may have some common features."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1746/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700128651815,
                "cdate": 1700128651815,
                "tmdate": 1700129182071,
                "mdate": 1700129182071,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]