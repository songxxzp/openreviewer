[
    {
        "title": "Welfare Diplomacy: Benchmarking Language Model Cooperation"
    },
    {
        "review": {
            "id": "fzBCK4HvEN",
            "forum": "AKJLnDgzkm",
            "replyto": "AKJLnDgzkm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission413/Reviewer_A4aM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission413/Reviewer_A4aM"
            ],
            "content": {
                "summary": {
                    "value": "The authors aim to promote societal safety by assisting researchers in developing and assessing multi-agent AI systems. They propose a new benchmark called Welfare Diplomacy for measuring the cooperative capabilities of AI systems., and introduce a general-sum variant of the zero-sum board game Diplomacy, where players must balance military conquest and domestic welfare. They implement the rules of Welfare Diplomacy using an open-source Diplomacy engine and construct baseline agents using zero-shot prompted language models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.\tThe authors introduce Welfare Diplomacy (WD) and provide an implementation in an open-source Diplomacy library.\n2.\tThis paper provides theoretical and empirical evidence highlighting the benefits of WD compared to the existing benchmark, Zero-Sum Diplomacy (SD).\n3.\tThe authors develop a language model (LM) scaffolding system to create competent zero-shot baseline agents for WD."
                },
                "weaknesses": {
                    "value": "1. Pareto-efficient equilibria are often not stable\uff0cand there may be various factors that can lead to deviations from the equilibrium, such as imperfect information, externalities, or strategic behavior. These deviations can disrupt the equilibrium and lead to a new outcome that is not Pareto-efficient.\n2. It is challenging to attain Pareto-efficient equilibria, and how to achieve optimal Nash welfare remains unclear."
                },
                "questions": {
                    "value": "1.\tAs this paper aims to enhance societal safety by aiding researchers in the development and evaluation of multi-agent AI systems, could you please provide examples that illustrate the potential benefits of using benchmarks in real-world scenarios?\n2.\tDespite the existence of multiple Pareto-efficient Nash Equilibria (NEs), they often display instability, particularly in complex or realistic scenarios. How can we effectively tackle this challenge?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission413/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698309260553,
            "cdate": 1698309260553,
            "tmdate": 1699635968022,
            "mdate": 1699635968022,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "rktGHmW55R",
                "forum": "AKJLnDgzkm",
                "replyto": "fzBCK4HvEN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission413/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission413/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer A4aM"
                    },
                    "comment": {
                        "value": "Dear Reviewer A4aM, we appreciate your constructive feedback and your recognition of our contribution to the field with the introduction of Welfare Diplomacy. Your acknowledgment of the theoretical grounding and empirical evidence supporting our work is very encouraging to us. We have made the following revisions and comments in response to your review:\n\n1.  \u201cPareto-efficient equilibria are often not stable, and there may be various factors that can lead to deviations from the equilibrium, such as imperfect information, externalities, or strategic behavior. These deviations can disrupt the equilibrium and lead to a new outcome that is not Pareto-efficient.\u201d, \u201cIt is challenging to attain Pareto-efficient equilibria, and how to achieve optimal Nash welfare remains unclear.\u201d, \u201cDespite the existence of multiple Pareto-efficient Nash Equilibria (NEs), they often display instability, particularly in complex or realistic scenarios. How can we effectively tackle this challenge?\u201d \u2192 We fully agree with the remarks about the instability of Pareto optimal NE, and the difficulty of attaining such profiles. There are a few things to note about this:\n    1.  One hope is that having benchmarks like ours will facilitate research that makes it more likely that we can construct agents that do play Pareto optimal Nash equilibria.\n    2.  We believe there is a need for both more robust solution concepts (e.g., performance against diverse distributions of agents) and the development of environments that are more realistic among the dimensions you mention (e.g., exhibiting noise and private information). We\u2019ve added some remarks about this to our Conclusion, in red.\n    3.  Pareto-optimal Nash equilibrium is a standard operationalization of rational cooperation, and so this is a limitation shared by much of the literature on game theory and multi-agent systems.\n2.  \u201cAs this paper aims to enhance societal safety by aiding researchers in the development and evaluation of multi-agent AI systems, could you please provide examples that illustrate the potential benefits of using benchmarks in real-world scenarios?\u201d \u2192 It is true that there are often gaps between benchmarks and real-world applications (e.g., https://aclanthology.org/2021.acl-long.81/). At the same time, it is difficult to improve systems if we do not know what to measure. We aim to push forward the work of measuring cooperative capabilities; we do not think that our Welfare Diplomacy benchmark in itself will inform a particular real-world application. That said, here are some examples of benchmarks that inform real-world scenarios: Claude 2\u2019s system card includes evaluations on benchmarks (e.g., BBQA) which informed deployment (https://www-files.anthropic.com/production/images/Model-Card-Claude-2.pdf); Anthropic\u2019s \u201cresponsible scaling policy\u201d requires evaluations for safety (https://www.anthropic.com/index/anthropics-responsible-scaling-policy); OpenAI spent six months after the training of GPT-4 to assess safety concerns, partially informed by benchmarks (https://cdn.openai.com/papers/gpt-4-system-card.pdf).\n\nMany thanks,\n\nThe Authors"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission413/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700043005684,
                "cdate": 1700043005684,
                "tmdate": 1700043114410,
                "mdate": 1700043114410,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "uy57XuI8LQ",
            "forum": "AKJLnDgzkm",
            "replyto": "AKJLnDgzkm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission413/Reviewer_zuKK"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission413/Reviewer_zuKK"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces Welfare Diplomacy, a variant of the game of Diplomacy that incorporates the balancing of military conquest and domestic welfare. The authors evaluate the proposed variant by developing language model-based agents and comparing different state-of-the-art language models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The game of diplomacy is an important challenge in multi-agent research, and the concept of welfare diplomacy is interesting. \n2.  The paper effectively explains the differences between the proposed game and existing benchmarks. By making two modifications to the game rules, the nature of the game has been altered, incentivizing players to pursue peace and promoting cooperation.\n3. The proposed game and prompts are open-sourced, and experimental results are extensive."
                },
                "weaknesses": {
                    "value": "1. Some arguments regarding the motivations of welfare diplomacy lack rigor and may be questionable. It has been repeatedly claimed in the paper that \"While Standard Diplomacy (SD) has features that make it interesting as an environment for cooperative AI research, it is zero-sum and incentivizes the development of cooperation-undermining capabilities\" and `In contrast to SD, WD is general-sum'.  However, it has been pointed out in [1] that \"In Diplomacy, seven players... coordinate their actions to both cooperate and compete with each other,\" suggesting that standard diplomacy is not necessarily a zero-sum game. If standard diplomacy were indeed zero-sum, cooperation would not be involved, similar to chess and heads-up poker.\n\n2. The theoretical results are hard to interpret. It would be helpful to clarify the meaning of $\\pi^k$ as a NE and how Theorem 1 relates to the main claim.\n\n3. Some important technical details lack clarity. The terms \"zero-shot prompted language model\", \"zero-shot baseline\" and \"zero-shot evaluations\" are used throughout the paper without any specific explanation. Additionally, it would be helpful to provide justification for constructing the exploiter in the paper. Does there exist any agent that has better exploitative power?\n\n[1] \"Human-level play in the game of Diplomacy by combining language models with strategic reasoning\", Science 2022."
                },
                "questions": {
                    "value": "I would like to see responses to the aforementioned weaknesses.\n\nIn addition, I have a question about the metric \"basic proficiency\". Currently, it is the mean of \"the rate of model outputs that are valid JSON and thus able to be parsed without error, the rate of submitted orders that are valid possible orders, and the fraction of global SCs owned by any player and not left neutral.\" While the first two are understandable, I don't understand why the fraction of global SCs should be considered as an aspect of 'basic proficiency'. To me, it is more like a metric about social welfare."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission413/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698375705193,
            "cdate": 1698375705193,
            "tmdate": 1699635967928,
            "mdate": 1699635967928,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ExwGF3eHGL",
                "forum": "AKJLnDgzkm",
                "replyto": "uy57XuI8LQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission413/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission413/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer zuKK"
                    },
                    "comment": {
                        "value": "Dear Reviewer zuKK, we are thankful for your comments on the significance of Diplomacy in multi-agent research and your interest in our Welfare Diplomacy variant. Your acknowledgment of our clear explanation of the game differences and the value of open-sourcing our code and results is greatly appreciated! We thank you for your insightful comments and have made several clarifications or revisions to address the points you raised:\n1. \u201csuggesting that standard diplomacy is not necessarily a zero-sum game. If standard diplomacy were indeed zero-sum, cooperation would not be involved, similar to chess and heads-up poker.\u201d \u2192 Yes, it is true that Standard Diplomacy also involves cooperation (between subsets of players). When we say that it is a \"zero-sum game\", we mean this in the technical sense: The sum of players' scores is the same for any policy profile (because a player's utility is the indicator of whether they won). Although SD can involve cooperation, the fact that there is a single winner means that it has a few limitations as a benchmark for cooperation. In particular, it does not exhibit opportunities for (global) rational cooperation (where \u201cglobal\u201d means between all players) and skilled play is not differentially (globally) cooperative, as we discuss in Section 2.1. \n2. \u201cThe theoretical results are hard to interpret. It would be helpful to clarify the meaning of  as a NE and how Theorem 1 relates to the main claim.\u201d \u2192 We agree that the relevance of Theorem 1 to our main claims should be clarified. We have now edited the paragraph directly after Theorem 1 (see red text), explicitly pointing out the connection to our criterion (A), that there should exist opportunities for global, rational cooperation. In particular, Theorem 1 shows that, in the toy environment, there are Nash equilibria that Pareto-dominate others, and that these Pareto-dominating equilibria require more cooperative capabilities. We also already discussed the connection to Theorem 1 in Section 2.2; we have now added a forward reference to Theorem 1 to make this clear.   \n3. \u201cThe terms \"zero-shot prompted language model\", \"zero-shot baseline\" and \"zero-shot evaluations\" are used throughout the paper without any specific explanation.\u201d \u2192 By zero-shot, we mean that no examples of gameplay are provided to the model. We have added this clarification to the beginning of Section 4 in red.\n4. \u201cAdditionally, it would be helpful to provide justification for constructing the exploiter in the paper. Does there exist any agent that has better exploitative power?\u201d \u2192 In addition to the details provided in the section \u201cexploitability reveals our agents don\u2019t deter deviators\u201d, we have additional details in Appendix B.3. In short, we designed our exploiters based on our intuitions in playing WD. There are likely to be better exploiters as we did not design for optimal exploitation. Our goals with the exploiter experiments were to (i) present a proof of concept for the measurement of exploitability, which is a key property to measure alongside social welfare, and (ii) get a sense for the exploitability of our models, for which these exploiters were sufficient (as they clearly demonstrate that our agents are highly exploitable).     \n5. \u201cI don't understand why the fraction of global SCs should be considered as an aspect of 'basic proficiency'. To me, it is more like a metric about social welfare.\u201d \u2192 This metric is about using all the available resources on the board. It\u2019s true that some partitions of the board might involve agreements to leave certain SCs neutral, but in practice, we observed that less capable or worse-prompted models would just not try much to capture free SCs. We wanted a component of the metric to check for this possibility.\n\nMany thanks,\n\nThe Authors"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission413/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700043263973,
                "cdate": 1700043263973,
                "tmdate": 1700043263973,
                "mdate": 1700043263973,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ByBonHORMI",
                "forum": "AKJLnDgzkm",
                "replyto": "ExwGF3eHGL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission413/Reviewer_zuKK"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission413/Reviewer_zuKK"
                ],
                "content": {
                    "comment": {
                        "value": "I suggest the author revise their arguments about standard Diplomacy in the paper. The current ones are misleading, as detailed in my review comment. While classifying standard Diplomacy as a zero-sum game may create a stark contrast with existing studies, this oversimplification does not provide an accurate basis for assessing the paper's originality and significance.\n\nRegarding other concerns, the response and the revision have addressed them appropriately."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission413/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700662557503,
                "cdate": 1700662557503,
                "tmdate": 1700662557503,
                "mdate": 1700662557503,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Vf4QGmWwkK",
            "forum": "AKJLnDgzkm",
            "replyto": "AKJLnDgzkm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission413/Reviewer_R7WR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission413/Reviewer_R7WR"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes Welfare Diplomacy (WD), a variant of Diplomacy that considers more about agent cooperation. The paper offers \n(1) Motivation and illustration of environment design \n(2) Nash equilibrium analysis of WD\n(3) Experiments that benchmark different LLM models' Nash Welfare and exploitability."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Overall I think this is a great paper, the strengths can be addressed as follows:\n(1) The paper is clearly written and easy to follow.\n(2) The paper proposes a new environment variant to benchmark the agent cooperation ability and clearly illustrate the motivation.\n(3) The paper offers a theoretical analysis of its proposed environment and verifies the reasonability of the proposed environment.\n(4) The experiments successfully help benchmark the agent cooperation ability."
                },
                "weaknesses": {
                    "value": "The weaknesses are summarized as follows:\n\n(1) The author can try to include more experiment results and ablation studies such as prompt sensitivity, hyperparameter effects, etc.\n(2) The author should try to incorporate human-LLM mixed experiments to see how human engagement can influence LLM performance.\n(3) Some human analysis of LLM's policy should be conducted to better understand LLM's performance."
                },
                "questions": {
                    "value": "I have the following questions and suggestions:\n1. There exist several typos in the paper, e.g. in the first line of section 3 certain NEs certain NEs.\n2. Can the authors elaborate more on how the theoretical analysis simplifies the real WD game in section 3.2.1 and theorem 1 and what is the gap between the theoretical analysis and the real WD game?\n3. I recommend the author slightly modify the title as the cooperation discussed in the paper is the cooperation in a general-sum game. It can help distinguish itself from the fully cooperative setting.\n4. From my perspective, what differentiates the current LLM agent from the previous agent is the ability of the agent to communicate with other agents using language. As shown in the paper, there exist some Pareto efficient policies theoretically. I am a little bit worried about, why bother LLM to do such thing if we can theoretically derive the optimal action (I understand this is a game of language so a language encoder is necessary, but you can also train a language-based RL agent to purely output action). What do the authors think the language communication here can help? My first thought is that communication here can be used during the bargain game and help the equilibrium selection. Can the language help in some other cases (like helping policies but it again fails in the case if you can theoretically derive some optimal action)?\n5. It seems most models, except advanced LLMs like GPT-4, cannot have policies that are significantly better than the random baseline, what could be the reasons?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission413/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission413/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission413/Reviewer_R7WR"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission413/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698793880081,
            "cdate": 1698793880081,
            "tmdate": 1699635967860,
            "mdate": 1699635967860,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qEEoexEdKv",
                "forum": "AKJLnDgzkm",
                "replyto": "Vf4QGmWwkK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission413/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission413/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer R7WR"
                    },
                    "comment": {
                        "value": "Dear Reviewer R7WR, thank you for your evaluation of our paper. Your appreciation for the clarity of our writing and the introduction of a new benchmark for agent cooperation has been encouraging! We also value your recognition of our efforts in providing a theoretical analysis and experimental validation for our environment. We have incorporated several changes in response to your comments:\n1. \u201cmore experiment results and ablation studies such as prompt sensitivity, hyperparameter effects, etc.\u201d \u2192 See Appendices B, C. We have also added a small prompt ablation experiment on GPT-4 in Figure 8 of section C.5 in addition to the existing larger prompt ablation on Claude 1.2 in Figure 7.\n2. \u201chuman-LLM mixed experiments to see how human engagement can influence LLM performance\u201d \u2192 The suggestion is interesting! We are excited about pursuing this direction in future work; for this work, we were financially constrained and had to narrow our focus.\n3. \u201cSome human analysis of LLM's policy\u201d \u2192 We have already included such analysis in Appendix D, E. We have now also added additional analysis of WDAgent(M) for each of the models M we looked at in Appendix C.4. \n4. \u201cThere exist several typos in the paper, e.g. in the first line of section 3 certain NEs certain NEs.\u201d \u2192 Thank you for pointing that out! We went through it once more and corrected typos.\n5. \u201cCan the authors elaborate more on how the theoretical analysis simplifies the real WD game in section 3.2.1 and theorem 1 and what is the gap between the theoretical analysis and the real WD game?\u201d \u2192 We added a description of how the toy version of WD differs from the real version (see new text at the beginning of Section G in red). In short, our toy version has fewer states and more symmetries between players - which makes it much more tractable to analyze - and is centered around a bargaining problem that captures the core challenge of WD.\n6. \u201cI recommend the author slightly modify the title\u201d \u2192 To our knowledge, 'cooperation' is commonly understood as applying to both purely cooperative and mixed-motive games. For example, this is how it is meant in 'cooperative AI' (https://arxiv.org/abs/2012.08630), a subfield we consider our paper to be a part of. In combination with the fact that making the title more precise might require making it too long, we currently think it's best to stick with the present title.\n7. \u201cI am a little bit worried about, why bother LLM to do such thing if we can theoretically derive the optimal action (I understand this is a game of language so a language encoder is necessary, but you can also train a language-based RL agent to purely output action). What do the authors think the language communication here can help?\u201d \u2192 Our interpretation of this question is, why bother to measure the behavior of LLMs If we can build systems to cooperate to begin with? Assuming this interpretation, we think that an increasingly likely world is one with different LM-based systems integrated into society and not built to coordinate with each other by default, as we discuss in the first paragraph of the introduction. We think it is valuable both to prepare for the world we describe and also to work to build another world, such as by building systems that can cooperate optimally. Please correct us if we have misinterpreted the question.\n8. \u201cMy first thought is that communication here can be used during the bargain game and help the equilibrium selection\u201d \u2192 Yes, precisely! Even setting aside whether you need language for strong performance, having this environment allows us to measure the properties of LMs that we're interested in.\n9. \u201cIt seems most models, except advanced LLMs like GPT-4, cannot have policies that are significantly better than the random baseline, what could be the reasons?\u201d \u2192 Thank you for prompting us to look at this more closely. As part of the newly added Appendix C.4 (in red), we have provided commentary on some of the qualitative features of LLM policies that determine their performance. (Briefly: Claude-1.2 gets very low root mean Nash welfare because in several games, some players hold their units throughout the game and therefore get 0 Welfare Points. GPT-3.5 and Llama-2 each tend not to acquire many more SCs, but do sometimes disband units and therefore acquire some WPs.)\n\nMany thanks,\n\nThe Authors"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission413/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700043364294,
                "cdate": 1700043364294,
                "tmdate": 1700043364294,
                "mdate": 1700043364294,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]