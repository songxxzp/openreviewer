[
    {
        "title": "Efficient Point Cloud Matching for 3D Geometric Shape Assembly"
    },
    {
        "review": {
            "id": "glhEEqqWAz",
            "forum": "6cGiRiExUd",
            "replyto": "6cGiRiExUd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8840/Reviewer_jjsW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8840/Reviewer_jjsW"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces Proxy Match Transform (PMT), which is a low-complexity high-order feature transform layer that reduces the computational complexity and memory occupancy. The proposed PMT, combined with a GeoTransformer (CVPR 2022) framework, is used in the task of object assembly, where its effectiveness has been proved by experiments."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The proposed PMT, at least from the theoretical analysis, could effectively reduce the computational complexity. I personally consider this design similar to KPConv (ICCV 2019), where they use several anchor points to compute their correlations to spatial points that represent the local geometry. This design is reasonable, intuitive, and valuable.\n\n2. The proposed method achieves the state-of-the-art in the benchmark for object assembly, although it is only a synthetic one and there lacks experiments on real data.\n\n3. The Theoretical analysis in the Appendix provides a better understanding of the advantages of the proposed module, which I really appreciate, although it is overly complex to understand throughly."
                },
                "weaknesses": {
                    "value": "1. The whole pipeline is developed upon GeoTransformer (CVPR 2022) and uses a majority of the previous design. The differences are the use of PMT to replace the Self- and Cross-Attention mechanisms in the coare level, as well as the use of PMT after each stage in decoder. I think this weakens the contribution and novelty of this paper.\n\n2. The methodology part is overly complex, and I do not this it is organized well and easy to follow. \n\n    2.1 For example, in Eq. (2) and the following equations, the calculation of attention matrix $\\mathbf{A}$ is unclear;\n\n    2.2 Moreover, it is also misleading that the proposed PMT is used to replace the attention mechanisms used in GeoTransformer, while in Fig.1 it is compared to the convolutions. And also in many other places concolutions are introduced, but all the computation of PMT seems like attention-based;\n\n    2.3 In Eq. (2), it seems the output of PMT is the enhaced features, while in Eq. (4), the output is some correlation scores. Do I make a mistake in understanding this?\n\n3. The experiments are only conducted on synthetic dataset, which makes me doubt its value in real applications. Therefore, it is better to include some real data. If there is no real data in this task, as this method is strongly based on GeoTransformer, simply running on GeoTransformer's benchmark also makes sense.\n\n4. As this paper mainly focuses on cutting the memory burden and reducing the complexity. Except for the theoretical analysis, it is also necessary to conduct experiments in terms of the memory occupancy and the running speed, to make comparisons to the state-of-the-art."
                },
                "questions": {
                    "value": "See weaknesses for the questions. I strongly suggest the authors to re-organize their methodology part and simplify their symbols. Fig. 1 does not help understand the main contributions. Also the real-data experiments as well as the comparisons in terms of memory occupancy and running speed are highly encouraged."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8840/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8840/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8840/Reviewer_jjsW"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8840/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698697393513,
            "cdate": 1698697393513,
            "tmdate": 1699637111872,
            "mdate": 1699637111872,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "RHCDWT7Iz2",
                "forum": "6cGiRiExUd",
                "replyto": "glhEEqqWAz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8840/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8840/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Comments to Reviewer jjsW (1/4)"
                    },
                    "comment": {
                        "value": "We appreciate Reviewer jjsW for their insightful comments and suggestions. In response, we have addressed your comments and incorporated revisions into our manuscript, as outlined in the general comments. We encourage the reviewer to check the updated version of our paper.\n\n**[W1] The whole pipeline is developed upon GeoTransformer (CVPR 2022) and uses a majority of the previous design.**  \n\n**Answer:** We recognize that the presentation of our method might raise questions about the uniqueness of our technical contribution. It's important to clarify that our approach is built upon the coarse-to-fine matching framework, which serves as a flexible and shared platform for efficient matching across diverse domains [1,2,3,4]. Each method tailors its approach to different matching tasks within this shared platform by designing specific matching layers and model-fitting algorithms. In this context, we underscore our contributions as follows:  \n\nFirstly, we introduce Proxy Match Transform, a low-complexity matching layer that effectively refines the matching of the feature pair. Combined with the prevalent coarse-to-fine matching framework, our method outperforms the state-of-the-art methods on the popular object assembly benchmarks while exhibiting order-of-magnitude smaller computational costs.  \n\nSecondly, with its substantial reduction in computational cost, the Proxy Match Transform enables its adoption as a fine-level matcher. To the best of our knowledge, this is the first attempt of its kind, refining matching at a granular level. This approach yields state-of-the-art results on recent 3D object assembly benchmarks, where intricate matching is paramount.  \n\nLastly, we theoretically analyze that the Proxy Match Transform layer can effectively approximate the high-order convolutional layers and introduce two sufficient conditions that need to hold.\n \n\n**References.**  \n[1] Zhou, Qunjie, Torsten Sattler, and Laura Leal-Taixe. \"Patch2pix: Epipolar-guided pixel-level correspondences.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2021.  \n[2] Sun, Jiaming, et al. \"LoFTR: Detector-free local feature matching with transformers.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2021.  \n[3] Yu, Hao, et al. \"Cofinet: Reliable coarse-to-fine correspondences for robust pointcloud registration.\" Advances in Neural Information Processing Systems 34 (2021): 23872-23884.  \n[4] Qin, Zheng, et al. \"GeoTransformer: Fast and Robust Point Cloud Registration With Geometric Transformer.\" IEEE Transactions on Pattern Analysis and Machine Intelligence (2023).\n\n---\n\n**[W2] The methodology part is overly complex, and I do not this it is organized well and easy to follow.**  \n\n**Answer:** We acknowledge our method section was not easy to follow, and the concerns raised about its complexity and organization. In response, we have revised Section 3 and added an overview in the early part of the section.\n\nThis revision is primarily focused on improving the clarity of notations and presenting the methods in a more structured and unambiguous manner. Additionally, we have revised the section to avoid some omissions in the equations and clarify some confused notations, ensuring that each step is clearly explained and logically follows from the previous one. The revised section also includes additional explanatory text to guide the reader through the methodology, aiming to make it more accessible and easy to follow.  \n\nNotably, we've adjusted the notations as follows: $\\mathbf{P}$ represents the proxy, same as before. The spatial resolution of the proxy is now denoted by $D_{\\text{proxy}}$ rather than $P$. Additionally, we've introduced $\\mathcal{X}$ as the notation for the source point cloud, and $\\mathcal{Y}$ for the target point cloud.  \n\nIn the final iteration, we will conduct a comprehensive revision, including any additional comments given during the author-reviewer discussion period."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8840/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700211599488,
                "cdate": 1700211599488,
                "tmdate": 1700211599488,
                "mdate": 1700211599488,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qCVXNQ2FBW",
                "forum": "6cGiRiExUd",
                "replyto": "glhEEqqWAz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8840/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8840/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reminder for Discussion"
                    },
                    "comment": {
                        "value": "Dear reviewer jjsW,\n\nWe would like to kindly remind you that the deadline for discussions is approaching. We highly appreciate all the time and effort the reviewers have dedicated to our manuscript, along with their insightful suggestions, and we have thoroughly reviewed and addressed each of the comments you've made. If there are any additional issues, we are ready and willing to continue discussions with the reviewers.\n\nBest regards, Submission 8840 Authors"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8840/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700539133130,
                "cdate": 1700539133130,
                "tmdate": 1700539133130,
                "mdate": 1700539133130,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tjR8BOO7Al",
                "forum": "6cGiRiExUd",
                "replyto": "stDD0laKRT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8840/Reviewer_jjsW"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8840/Reviewer_jjsW"
                ],
                "content": {
                    "title": {
                        "value": "Comment to the authors"
                    },
                    "comment": {
                        "value": "Dear Authors,\n\nThanks again for your detailed response to my questions. I highly appreciate the additional efforts you made expecially in the experiment part to make this manuscript much better and more clear. I think the answers have addressed most of my concerns. \n\nHowever, standing with Reviewer NyfY and jVVT, I also consider the novelty of this paper trivial and probably insufficient for a top-tier conference. It heavily depends on GeoTransformer but tries to optimize memory occupancy using a proxy \"trick\", which has been widely adopted in previous papers. Also, I have the same feeling as Reviewer jVVT that this paper is hard to follow. Please try to re-organize it and simplify the symbols for the revised version. \n\nAs a conclusion, I personally would give it a borderline, but it seems there is no such an option. I will consider other reviewrs' opinions and give my final rating.\n\nBest,\nReviewer jjsW"
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8840/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700646424319,
                "cdate": 1700646424319,
                "tmdate": 1700646424319,
                "mdate": 1700646424319,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jllYenG1mf",
                "forum": "6cGiRiExUd",
                "replyto": "glhEEqqWAz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8840/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8840/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Comments to Reviewer jjsW (2/2)"
                    },
                    "comment": {
                        "value": "> **\u201cbut tries to optimize memory occupancy using a proxy \"trick\", which has been widely adopted in previous papers.\u201d**   \n\nUnfortunately, we are not aware of the \"previous papers\" you mentioned about. If you specify the papers, we will discuss them compared to ours in revision. \n\nTo the best of our knowledge, our approach is unique in the sense that we approximate high-order convolution by introducing a proxy as **a new learnable tensor** that facilitates the exchange of information between two independent feature transforms. It serves as a key computational element within PMT, enabling efficient and effective feature matching in point cloud processing, particularly enhancing the assembly and analysis of 3D geometric shapes. We show both theoretical and empirical results supporting this idea. \n\nIn addition, we have enhanced our manuscript with an empirical analysis of proxy tensors and provided detailed descriptions of each element within the PMT layer through our revisions (Appendix A.1, Appendix A.2). We believe these additions will not only help readers better understand how PMT operates but also highlight its novelty by clearly distinguishing how it functions in comparison to other methods using proxies.  \n\n---\n\n> **\u201cAlso, I have the same feeling as Reviewer jVVT that this paper is hard to follow. Please try to re-organize it and simplify the symbols for the revised version.\u201d**\n\nWe appreciate pointing this out again. In response to the concerns, we have revised the method section in our manuscript to improve its readability. We have also made efforts to simplify the symbols and re-organize the content to make it more accessible to readers. Please refer to our revised manuscript for the changes we have implemented so far, and we will continue to work on further improvements to ensure that the final iteration of our paper is as clear and comprehensible as possible. If you have any specific suggestions for this, we will do our best to reflect them as well."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8840/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700700337382,
                "cdate": 1700700337382,
                "tmdate": 1700700363118,
                "mdate": 1700700363118,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "xi3fJBMExa",
            "forum": "6cGiRiExUd",
            "replyto": "6cGiRiExUd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8840/Reviewer_oLtM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8840/Reviewer_oLtM"
            ],
            "content": {
                "summary": {
                    "value": "High order feature transforms are used to lift features to a high dimensional space to simplify the correlation interpretation. However, this is a computational expensive process. This paper proposes a proxy feature transform(PMT) which transforms the high dimensional feature into an embedding of much smaller dimension while maintaining the feature correlation. As an application, this transform is applied to shape assembly problem in 3D using a coarse-to-fine registration strategy. Experiments show a significant improvement in the performance from existing methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "Strengths:\nthe paper is well-formalised. It proves the existence of a smaller space orthonormal embedding in the theorem 1, which preserves the convolution of high dimensional features. This can be seen as the PCA for dimension reduction.\nThe ablation study justifies the various components of the algorithm and the orthonormality condition.\nExperimental evaluation seems adequate and clearly indicates the strength of the algorithm."
                },
                "weaknesses": {
                    "value": "No major weakness."
                },
                "questions": {
                    "value": "Few comments\nPaper is too compact. More details are required in the proof of theorem 1.\nMLP and HDC in table 4 are never mentioned before.\nThe  transform is learnt on high amount of data. How does it perform with unseen data?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8840/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698772113391,
            "cdate": 1698772113391,
            "tmdate": 1699637111743,
            "mdate": 1699637111743,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XW5QW0qMf9",
                "forum": "6cGiRiExUd",
                "replyto": "xi3fJBMExa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8840/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8840/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Comments to Reviewer oLtM (1/2)"
                    },
                    "comment": {
                        "value": "We appreciate Reviewer oLtM for their positive comments. We have addressed the comments from reviewers and incorporated revisions into our manuscript, as outlined in the general comments. We encourage the reviewer to check the updated version of our paper. And, these are our answers to some of your questions.  \n\n**[Q1] Paper is too compact. More details are required in the proof of Theorem 1.**  \n\n**Answer:** We acknowledge our method section was not easy to follow, and the concerns raised about its complexity and organization. In response, we have revised Section 3 and added an overview in the early part of the section.\n\nThis revision is primarily focused on improving the clarity of notations and presenting the methods in a more structured and unambiguous manner. Additionally, we have revised the section to avoid some omissions in the equations and clarify some confused notations, ensuring that each step is clearly explained and logically follows from the previous one. The revised section also includes additional explanatory text to guide the reader through the methodology, aiming to make it more accessible and easy to follow.  \n\nNotably, we've adjusted the notations as follows: $\\mathbf{P}$ represents the proxy, same as before. The spatial resolution of the proxy is now denoted by $D_{\\text{proxy}}$ rather than $P$. Additionally, we've introduced $\\mathcal{X}$ as the notation for the source point cloud, and $\\mathcal{Y}$ for the target point cloud.  \n\nIn the final iteration, we will conduct a comprehensive revision, including any additional comments given during the author-reviewer discussion period.\n\n\n---\n\n**[Q2] MLP and HDC in Tab. 4 are never mentioned before.** \n\n**Answer:** In response to the reviewer's query about the MLP and HDC in Table 4, we acknowledge that these baselines were not previously introduced in the main text. We appreciate this opportunity to clarify their roles in our ablation studies, and we updated the revised paper's Appendix to provide a comprehensive explanation of these baselines.  \n\nIn our ablation studies, we evaluated our PMT model against four distinct baselines, demonstrating its effectiveness in both coarse- and fine-matching contexts. The first baseline, **Linear**, involves constructing two individual linear layers for features $\\mathbf{F}\\_{\\mathcal{X}}$ and $\\mathbf{F}\\_{\\mathcal{Y}}$, sharing a common weight matrix $\\mathbf{W} \\in \\mathbb{R}^{D\\_{\\text{emb}} \\times D\\_{\\text{emb}}}$. The second, **MLP**, employs two linear layers with weight matrices $\\mathbf{W}\\_{1} \\in \\mathbb{R}^{D\\_{\\text{emb}} \\times D\\_{\\text{emb}}/2}$ and $\\mathbf{W}\\_{2} \\in \\mathbb{R}^{D\\_{\\text{emb}}/2 \\times D\\_{\\text{emb}}}$, each followed by a Group Normalization and ReLU sequence. The third baseline, **HDC**, adheres to the center-pivot convolution approach as introduced by Min et al. (2021) [1]. Lastly, for **GeoTr**, we implemented the Geometric Transformer according to the method outlined by Qin et al. (2022) [2].  \n\n**References.**  \n[1] Juhong Min, Dahyun Kang, and Minsu Cho. Hypercorrelation squeeze for few-shot segmentation. In Proc. IEEE International Conference on Computer Vision (ICCV), 2021.  \n[2] Zheng Qin, Hao Yu, Changjian Wang, Yulan Guo, Yuxing Peng, and Kai Xu. Geometric transformer for fast and robust point cloud registration. In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8840/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700211270861,
                "cdate": 1700211270861,
                "tmdate": 1700211270861,
                "mdate": 1700211270861,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jChbXAZHsu",
                "forum": "6cGiRiExUd",
                "replyto": "xi3fJBMExa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8840/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8840/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reminder for Discussion"
                    },
                    "comment": {
                        "value": "Dear reviewer oLtM,\n\nWe would like to kindly remind you that the deadline for discussions is approaching. We highly appreciate all the time and effort the reviewers have dedicated to our manuscript, along with their insightful suggestions, and we have thoroughly reviewed and addressed each of the comments you've made. If there are any additional issues, we are ready and willing to continue discussions with the reviewers.\n\nBest regards, Submission 8840 Authors"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8840/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700539102760,
                "cdate": 1700539102760,
                "tmdate": 1700539102760,
                "mdate": 1700539102760,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NjmYtwj8GG",
                "forum": "6cGiRiExUd",
                "replyto": "jChbXAZHsu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8840/Reviewer_oLtM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8840/Reviewer_oLtM"
                ],
                "content": {
                    "comment": {
                        "value": "Dear authors,\n\nThank you for addressing most of my comments in detail. The revised manuscript is indeed more clear in terms of both theoretical formulations and experiments. According to me, the overall message of the paper is that the proposed PMT is interesting due to its computational simplicity and therefore, the ability to perform finer matching. \n\nI have also gone through comments from other reviewers. I understand the concerns about the incremental nature of the proposed method. The big question is: what is the significance/impact of the main contribution of the paper, PMT? From what I understand from the paper, the PMT is inspired from the proposed theorem (Cordonnier et al., 2020) relating self-attention to convolution. The authors use this argument to simplify a high-order convolution.\n\n I still think that the PMT has merits of its own to be considered as a novel contribution with significant impact on the performance of coarse-to fine matching (Table 4b) across various methods.  Table 4b also shows that PMT is not as efficient as GeoTransformer (the method it is primarily based on) for coarse matching. However, given its computational simplicity in Table 6, this slight dip in performance seems to be acceptable.\n\nOverall, I acknowledge the incremental nature of the proposed method but my opinion about the paper is still fairly positive due to merits of PMT. It is designed to be computationally simpler and the experiments demonstrate convincingly that it mostly outperforms the existing methodologies."
                    }
                },
                "number": 25,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8840/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737639040,
                "cdate": 1700737639040,
                "tmdate": 1700737639040,
                "mdate": 1700737639040,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "SwhV0f9ekf",
            "forum": "6cGiRiExUd",
            "replyto": "6cGiRiExUd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8840/Reviewer_jVVT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8840/Reviewer_jVVT"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new technique for efficiently aligning surfaces of fractured objects for re-assembly. Its principal insight is that a convolution on a bipartite graph formed from samples on the two object parts (with $N$ and $M$ points respectively) can be simplified (in terms of time/compute resources) by routing the messages that aggregate samples through a proxy transform layer. If the number of heads in this layer is $O(H)$ for some constant $H$, then the presence of the proxy layer changes the quadratic ($N \\times M$) complexity of the convolution to $O(H) \\times \\max{N, M}$ (correct?)"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The core of the method is a new technique to compute convolutions over the feature sets of the two fragments. The method is theoretically compelling and the authors do a good job of justifying it theoretically and practically. The experimental section seems thorough and validates the method vs several baselines."
                },
                "weaknesses": {
                    "value": "The paper is written in a way that is rather difficult to follow -- I would suggest doing another pass (maybe with feedback from some external readers) to make the language more simple and streamlined.\n\nI am also not entirely sure of the magnitude of the contribution. The proxy match transform is a clever trick that significantly enhances efficiency and accuracy in real-world training scenarios. But it sits inside a large pipeline that draws heavily upon previous work, and it is difficult to gauge its conceptual contribution. Is it a small tweak to make a big system better, or something so critical its impact goes beyond said big system?\n\nFor me, the second point puts the paper on the borderline, and the first point pushes it slightly below the threshold. I am open to revising the score based on the rebuttal and other reviewers' comments."
                },
                "questions": {
                    "value": "Exposition:\n\n- Since \"shape assembly\" is more commonly used to refer to assembling shapes from parts (e.g. a chair from seat, back and legs), it might be clearer to use \"shape re-assembly\" instead, or even \"fractured shape re-assembly\".\n\n- \"... two sets of features, $\\mathcal{F}_P$ and $\\mathcal{F}_Q$, associated with each point cloud\" --> this reads as: each point cloud has two sets of features. You might want to rephrase as \"... two sets of features $\\mathcal{F}_P$ and $\\mathcal{F}_Q$ associated with the two point clouds respectively\" or something like that.\n\n- Please don't use $P$, $\\mathbf{P}$ and $\\mathcal{P}$ to denote totally different things (near Eq. 3). It's super-confusing."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8840/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699065355995,
            "cdate": 1699065355995,
            "tmdate": 1699637111637,
            "mdate": 1699637111637,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gj52FjUTfe",
                "forum": "6cGiRiExUd",
                "replyto": "SwhV0f9ekf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8840/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8840/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Comments to Reviewer jVVT (1/2)"
                    },
                    "comment": {
                        "value": "We appreciate Reviewer jVVT for their insightful comments and suggestions. In response, we have addressed your comments and incorporated revisions into our manuscript, as outlined in the general comments. We encourage the reviewer to check the updated version of our paper.  \n\n**[W1] The paper is written in a way that is rather difficult to follow.**\n\n**Answer:** We acknowledge our method section was not easy to follow, and the concerns raised about its complexity and organization. In response, we have revised Section 3 and added an overview in the early part of the section.\n\nThis revision is primarily focused on improving the clarity of notations and presenting the methods in a more structured and unambiguous manner. Additionally, we have revised the section to avoid some omissions in the equations and clarify some confused notations, ensuring that each step is clearly explained and logically follows from the previous one. The revised section also includes additional explanatory text to guide the reader through the methodology, aiming to make it more accessible and easy to follow.  \n\nNotably, we've adjusted the notations as follows: $\\mathbf{P}$ represents the proxy, same as before. The spatial resolution of the proxy is now denoted by $D_{\\text{proxy}}$ rather than $P$. Additionally, we've introduced $\\mathcal{X}$ as the notation for the source point cloud, and $\\mathcal{Y}$ for the target point cloud.  \n\nIn the final iteration, we will conduct a comprehensive revision, including any additional comments given during the author-reviewer discussion period.\n\n---\n\n**[W2] I am also not entirely sure of the magnitude of the contribution.**\n\n**Answer:** We recognize that the presentation of our method might raise questions about the uniqueness of our technical contribution. It's important to clarify that our approach is built upon the coarse-to-fine matching framework, which serves as a flexible and shared platform for efficient matching across diverse domains [1,2,3,4]. Each method tailors its approach to different matching tasks within this shared platform by designing specific matching layers and model-fitting algorithms. In this context, we underscore our contributions as follows:  \n\nFirstly, we introduce Proxy Match Transform, a low-complexity matching layer that effectively refines the matching of the feature pair. Combined with the prevalent coarse-to-fine matching framework, our method outperforms the state-of-the-art methods on the popular object assembly benchmarks while exhibiting order-of-magnitude smaller computational costs.  \n\nSecondly, with its substantial reduction in computational cost, the Proxy Match Transform enables its adoption as a fine-level matcher. To the best of our knowledge, this is the first attempt of its kind, refining matching at a granular level. This approach yields state-of-the-art results on recent 3D object assembly benchmarks, where intricate matching is paramount.  \n\nLastly, we theoretically analyze that the Proxy Match Transform layer can effectively approximate the high-order convolutional layers and introduce two sufficient conditions that need to hold.  \n\n\n**References.**  \n[1] Zhou, Qunjie, Torsten Sattler, and Laura Leal-Taixe. \"Patch2pix: Epipolar-guided pixel-level correspondences.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2021.  \n[2] Sun, Jiaming, et al. \"LoFTR: Detector-free local feature matching with transformers.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2021.  \n[3] Yu, Hao, et al. \"Cofinet: Reliable coarse-to-fine correspondences for robust pointcloud registration.\" Advances in Neural Information Processing Systems 34 (2021): 23872-23884.  \n[4] Qin, Zheng, et al. \"GeoTransformer: Fast and Robust Point Cloud Registration With Geometric Transformer.\" IEEE Transactions on Pattern Analysis and Machine Intelligence (2023)."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8840/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700211019142,
                "cdate": 1700211019142,
                "tmdate": 1700211019142,
                "mdate": 1700211019142,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iyX8qBHZPk",
                "forum": "6cGiRiExUd",
                "replyto": "SwhV0f9ekf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8840/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8840/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reminder for Discussion"
                    },
                    "comment": {
                        "value": "Dear reviewer jVVT,\n \nWe would like to kindly remind you that the deadline for discussions is approaching. We highly appreciate all the time and effort the reviewers have dedicated to our manuscript, along with their insightful suggestions, and we have thoroughly reviewed and addressed each of the comments you've made. If there are any additional issues, we are ready and willing to continue discussions with the reviewers.\n \nBest regards,\nSubmission 8840 Authors"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8840/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700539017752,
                "cdate": 1700539017752,
                "tmdate": 1700539017752,
                "mdate": 1700539017752,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IG5UlzZWmn",
                "forum": "6cGiRiExUd",
                "replyto": "iyX8qBHZPk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8840/Reviewer_jVVT"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8840/Reviewer_jVVT"
                ],
                "content": {
                    "title": {
                        "value": "Borderline"
                    },
                    "comment": {
                        "value": "I thank the authors for the careful responses to our questions and for the textual revisions. Unfortunately, they don't fully resolve my concerns. The exposition is still rather unclear -- I still find it very difficult to get real insight into what the method is doing and why it works. And like other reviewers I remain unclear about the magnitude of the contribution. I remain on the borderline -- maybe a little more positive than I was earlier but not fully convinced the contribution is enough -- and clearly explained enough -- for acceptance."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8840/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700713744526,
                "cdate": 1700713744526,
                "tmdate": 1700713744526,
                "mdate": 1700713744526,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "WBdR4AoPZu",
            "forum": "6cGiRiExUd",
            "replyto": "6cGiRiExUd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8840/Reviewer_NyfY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8840/Reviewer_NyfY"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes Proxy Match transform a low complexity feature transform that can be used in extracting correspondences for shape assembly. This approach tries to solve the quadratic complexity issue of high-order convolution by substituting it with a convolution with a common small-support proxy tensor that captures the local similarities among the shape."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Strong experimental results. This paper does not offer a lot of theoretical insight, but if the results are reproducible it will prove useful to a lot of practitioners"
                },
                "weaknesses": {
                    "value": "- Lack of motivation: The role and derivation of the both the proxy tensor P and the learnable weight w should be better detailed.\n- Limited theoretical insight: the paper feel a bit ad hoc, in the sense of \"I have done this and it works.\" It is not clear how the architecture was derived."
                },
                "questions": {
                    "value": "See points above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8840/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699204437003,
            "cdate": 1699204437003,
            "tmdate": 1699637111530,
            "mdate": 1699637111530,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Zw5RIlrA85",
                "forum": "6cGiRiExUd",
                "replyto": "WBdR4AoPZu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8840/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8840/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Comments to Reviewer NyfY"
                    },
                    "comment": {
                        "value": "We appreciate Reviewer NyfY for their insightful comments and suggestions. In response, we have addressed your comments and incorporated revisions into our manuscript, as outlined in the general comments. We encourage the reviewer to check the updated version of our paper.  \n\n**[W1&2]. Lack of motivation & theoretical insight**\n\n**Answer:**\n\n**Motivation and derivation:** \nAs outlined in our paper's introduction, high-order feature transform methods have been known to excel in addressing matching problems by capturing structural patterns of correlations in high-dimensional spaces. It is more critical for geometric shape assembly, which requires a meticulous search for pairwise correlations to capture the fine local details of each shape fragment. Despite their efficacy, these methods encounter challenges due to quadratic complexity, limiting their applicability to coarse-grained matching with a restricted number of points. In response to this constraint and with the goal of leveraging a computationally efficient high-order feature transform, we introduce a novel layer termed Proxy Match Transform. We demonstrate its effectiveness and efficiency in the context of shape assembly tasks.\n\n**Role of proxy tensor $\\mathbf{P}$:**\nAs discussed in Section 3.1 of our paper, the proxy plays a crucial role in achieving the previously mentioned goal of designing an efficient high-order feature transform layer. Essentially, the Proxy Match Transform employs the proxy to reduce the quadratic computational cost of high-order convolution to a sub-quadratic level while effectively expressing the high-order convolution. We have dedicated efforts to analyze the role of the proxy both theoretically and empirically; In Section 3.1, we have discussed the derivation demonstrating how the Proxy Match Transform can express high-order convolution with only sub-quadratic complexity. In Section 3.2, we established sufficient conditions for its approximation. In Section A.1, we have put the extended theoretical analysis of the Proxy Match Transform. In Section A.2, we added the empirical analysis on the proxy and showed how the proxy helps in facilitating critical information exchange between two input point clouds.\n\n**Role of weight $w$:**\nWeight value w is a learnable parameter in Proxy Match Transform layer, serving to accumulate the computation results for each head of the Proxy Match Transform with an appropriate weight."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8840/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700210847885,
                "cdate": 1700210847885,
                "tmdate": 1700210847885,
                "mdate": 1700210847885,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Dv9w8hUszF",
                "forum": "6cGiRiExUd",
                "replyto": "WBdR4AoPZu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8840/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8840/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reminder for Discussion"
                    },
                    "comment": {
                        "value": "Dear reviewer NyfY,\n \nWe would like to kindly remind you that the deadline for discussions is approaching. We highly appreciate all the time and effort the reviewers have dedicated to our manuscript, along with their insightful suggestions, and we have thoroughly reviewed and addressed each of the comments you've made. If there are any additional issues, we are ready and willing to continue discussions with the reviewers.\n \nBest regards,\nSubmission 8840 Authors"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8840/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700538982007,
                "cdate": 1700538982007,
                "tmdate": 1700538982007,
                "mdate": 1700538982007,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]