[
    {
        "title": "BayOTIDE: Bayesian Online Multivariate Time series Imputation with functional decomposition"
    },
    {
        "review": {
            "id": "cWQZg3KQnp",
            "forum": "FGoq622oqY",
            "replyto": "FGoq622oqY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3080/Reviewer_XZJX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3080/Reviewer_XZJX"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces BayOTIDE (Bayesian Online Multivariate Time series Imputation with functional decomposition), a novel approach for handling missing data in multivariate time series. BayOTIDE views multivariate time series as a combination of various low-rank temporal factors with distinct patterns. A group of Gaussian Processes with different kernels is utilized as functional priors. To enhance computational efficiency, the GPs are transformed into a state-space prior using an equivalent stochastic differential equation, enabling the development of a scalable online inference algorithm. One of the key advantages of the proposed method is its ability to perform imputation over arbitrary time points in the time series."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The strengths include: \n1. Representing multivariate time series data through low-rank temporal factors with distinct patterns for improved insight. \n2. Robust handling of missing data using probabilistic reasoning and uncertainty quantification. \n3. Efficient online inference through a conversion of Gaussian Processes into a state-space prior. \n4. Suitable for imputing data at arbitrary time points."
                },
                "weaknesses": {
                    "value": "I am not an expert in the field of time series imputation, and therefore, I am unable to assess the novelty of this work within the imputation domain. However, I have a strong background in Bayesian frameworks and Gaussian processes. From a methodological perspective, key techniques employed in this work, such as the conversion of Gaussian Processes into a state-space model and the use of conditional Expectation Propagation for posterior approximation, are all existing methods. The methodological aspect of the paper does not introduce significant innovations. Nevertheless, it is possible that these methods could hold value within the imputation field. \n\nFurthermore, the notation used in this paper is not ideal. As a common practice, scalars are typically represented using lowercase letters, vectors using bold lowercase letters, and matrices using bold uppercase letters. The notation employed in the paper is confusing. For instance, in Equation (1), F (a matrix) and L (a vector) are presented in the same format. Additionally, $\\omega(t)$ (a scalar) in Equation (1) and $\\mathbf{y}_n^d$ (a scalar) in Equation (5) are both scalars but are denoted differently. Similar issues can be found with various other symbols such as $U$, $V$, and so forth. These concerns are not exhaustively listed here."
                },
                "questions": {
                    "value": "Why use Matern kernel to model the trend factors, not other kernels? Any explanation?\n\nI understand that the conversion of Gaussian Processes into a state-space model is a computationally efficient approach to bypass the costly kernel matrix computation and facilitates the derivation of subsequent online inference. There are also other techniques based on low-rank approximations to reduce the computational complexity of GPs. Is it possible to incorporate such methods into your framework?\n\nRecommendation: Move \"We highlight that all the parameters of the LTI-SDE....can be derived from the given stationary kernel function.\" under equation (2). This will help readers gain a clearer understanding of how the parameters of LTI-SDE are obtained."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3080/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698058799196,
            "cdate": 1698058799196,
            "tmdate": 1699636253735,
            "mdate": 1699636253735,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qJ3PjewIUG",
                "forum": "FGoq622oqY",
                "replyto": "cWQZg3KQnp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3080/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3080/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the careful review and constructive suggestions. We address the comments below:C: comments; R: response.\n\n> C1:Novelty in Bayesian learning side and time series imputation side\n\nR1: Good point! Please refer to sections **Novelty and contribution on time series imputation side** and  **Novelty and contribution on Bayesian learning side** in the response overview, which at the top-level post in this forum.\n\n> C2: Notation polish and remove inaccurate statements\n\nR2: We thank the reviewer for the careful reading and pointing out the inaccurate statements. We will polish the notation and remove the inaccurate statements in the revised version.\n\n> C3: Why matern kernel?\n\nR3: The state-space GP we used requires the kernel to be a stationary covariance function. The Matern kernel is a strong and well-known stationary covariance function, which is widely used in the GP literature and has an elegant closed form for the corresponding state-space representation(Sections 1.1 and 1.2 in the appendix). We can further adjust the smoothness parameter $\\nu$ to control the smoothness of the kernel to match the different series.\n It can be further reduced to the widely-used RBF kernel when the smoothness parameter $\\nu$ is set to $1/2$.  \n \n Thus, considering the capacity and flexibility of the Matern kernel, and the elegant closed form of the corresponding state-space representation\n we choose the Matern kernel to model the non-linear trend components in **BayOTIDE**. \n\n> C4: \"Is it possible to incorporate other low-rank GP methods into your framework?\"\n\nR4: Very good point! Utilizing other low-rank GP methods, like the classical sparse GP with inducing points, is feasible. We just need to run SVI to minimize the ELBO with respect to joint probability (eq 7). However, compared with state-space GP,\n we claim the sparse GP may not be ideal for the following reasons:\n\n - The space GP with inducing points actually is the low-rank approximation of the covariance matrix, which is could be low quality when the inducing points are not well-selected. On the contrary, the state-space GP is exactly equivalent to the original GP, which fully preserves the capacity of GPs.\n\n- The ELBO-based SVI for sparse GP is not able to handle online learning well. On the contrary, the state-space GP, formulated as a chain-structured prior, is able to handle the streaming inference with KF. It's a great advantage for the time series task."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3080/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700547549502,
                "cdate": 1700547549502,
                "tmdate": 1700547549502,
                "mdate": 1700547549502,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "sdZ47mEC2l",
            "forum": "FGoq622oqY",
            "replyto": "FGoq622oqY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3080/Reviewer_PJoe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3080/Reviewer_PJoe"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a Gaussian processes-based method for online multivariate time series imputation. By considering a Linear time-invariant stochastic differential equation, a solution to which is a Gaussian process, and representing it as a Markov process, the paper aims to impute missing values at arbitrary time stamps. Furthermore, the model decomposes time series into multiple channels to account for factors such as trend and seasonality. The resulting approach is capable of providing probabilistic missing data imputation in online streaming tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Overall, the idea of the paper is appealing; in particular, the continuous modelling with developing methods in Neural ODEs/GPs seems a natural direction to consider. From a methodological point of view, the method is able to provide missing data imputation ability in very relevant realistic scenarios (online, continuous setting) which is definitely a notable strength."
                },
                "weaknesses": {
                    "value": "The evaluation approach remains weak: I am not sure the considered data sets are not varied enough, as missing data patterns considered in the paper are quite limited. At this point, I cannot give a rating above 2 for contribution because of limited evaluation (i.e., it is unclear how well the proposed approach performs in a more general settings). The same holds for the general rating."
                },
                "questions": {
                    "value": "-- Only 50% and 70% of observed ratios are considered in the simulation results. To evaluate how the proposed method compares in more general to other benchmarks, it is important to consider various benchmarks: 90%, 80%, 70%, 60%, 50%. Is the approach beneficial at all levels of missing values or do the benefits come only at a certain level?\n\n-- Only missingness at random is considered. GP-VAE paper considers the following mechanisms: random, spatial, 2 temporal and missing, not at random.  While spatial would not be relevant here I presume, a more relevant multivariate time series mechanisms of missingness can be considered. \n\n-- The approach considers trend and seasonality explicitly. I am not sure any of the compared benchmarks explicitly consider these channels of the time series. Therefore, I would at least include a standard multi-output GP framework with linear + periodic kernels or a spectral kernel (the implementation of the latter should be available in gpytorch). In particular, on the example represented in Figure 1 I would expect these standard methods to perform well. \n\n-- Results in Table 2 appear over a single run; a more extensive Monte Carlo study should be considered with corresponding standard deviations in the results."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3080/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3080/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3080/Reviewer_PJoe"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3080/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698590944050,
            "cdate": 1698590944050,
            "tmdate": 1700688963648,
            "mdate": 1700688963648,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kklYsj5mAY",
                "forum": "FGoq622oqY",
                "replyto": "sdZ47mEC2l",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3080/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3080/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your comments. Here are our responses. C: comments; R: response.\n\n> C1: More missing rate setting\n\nR1: We agree that more missing rate settings will help to better evaluate the performance of the proposed method. However, we argue that the main contribution of **BayOTIDE**, the first Bayesian online imputation model, is mainly on the novel methodological and theoretical aspects, instead of the performance gain over large-scale datasets under different missing rate settings. Similar method-driven work in this area, like **CSDI** [ Tashiro, Neurips 2021],  **CSBI** [Chen, ICML 2022], and **TIDER** [Liu, ICRL 2023] all only evaluate the performance under no-more-three missing rate settings.  \n\nThus, we only evaluate the performance under two missing rate settings in the paper. We will add statements to clarify this point in the revised version.    \n\n> C2: \"Only missingness at random is considered.\"\n\nR2: Good point. We clarify that we actually evaluate the performance under **two** missing pattern settings. \n\n- The first setting is the **random missing pattern**, which is the most common missing pattern in real-world applications. Table 2 in the paper shows the performance under this missing setting.\n\n - The second setting is the **all-channel / block-wise missing**, which is similar to the *temporal missing* pattern in the **GP-VAE** paper. We actually use the setting at **Imputation with Irregular timestamps** parts(last section of section 5). During the training, the observations at the irregular timestamps are all masked out. The results are shown in the table 3 and 5.   \n\n\n>C3: Multi-output GP framework with linear + periodic kernels as baselines.\n\nR3: Good point. We do agree that the multi-output GP with linear + periodic kernels can work well in the simulation study. However, we argue that even with linear + periodic kernels,**multi-output GP can not handle the real-world long-time series. It's because the multi-output GP is a full GP, which has $O(T^2N^2)$ space cost and $O(T^3N^3)$ time cost**. where $T$ is channel number and $N$ is the number of timestamps. Thus, it's not scalable to the real-world long time series.\n\n To make the multi-output GP work on the real-world long time series, we have to **patch the long time series into short segments**, and then train the multi-output GP on each segment (**The segment size is $30 \\times 30$ in our experiments**). The patching makes the kernel can not capture any long-term dependency, like seasonal dependency, and the performance will be similar or worse than the multi-output GP with RBF kernels. To verify this, we compare the performance of multi-output GP with RBF kernels and multi-output GP with linear + periodic kernels on the *traffic-guangzhou* dataset. The results are shown in the following table:\n\n| Observed-ratio=70% | RMSE | MAE | CRPS |\n| ------ | ---- | --- | --- | \n| **BayOTIDE** | 3.724 | 2.611 |  0.053 | \n| **MT-GP-RBF** | 4.471 | 3.223 |  0.082  | \n| **MT-GP-linear+periodic** | 8.673 | 7.224 |  0.252 | \n\n> C4: MC-study on evaluation\n\nR4: We clarify that we actually use the MC-study on evaluation. We state at the end of the *Baseline and setting* paragraph in section 5.2 that \"We repeat all the experiments 5 times and report the average results.\". Due to the space limit, we do not report the variance of the results."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3080/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700547403995,
                "cdate": 1700547403995,
                "tmdate": 1700547435349,
                "mdate": 1700547435349,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hebzbxxAx6",
                "forum": "FGoq622oqY",
                "replyto": "kklYsj5mAY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3080/Reviewer_PJoe"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3080/Reviewer_PJoe"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for the reply and for addressing some of the raised points. I believe the method is promising but not yet well presented and evaluated. Based on the latest state of the paper (I believe no revision was uploaded) and replies of the authors, I am raising my score but cannot recommend acceptance."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3080/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700688930357,
                "cdate": 1700688930357,
                "tmdate": 1700688930357,
                "mdate": 1700688930357,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5gFs0NHC4W",
            "forum": "FGoq622oqY",
            "replyto": "FGoq622oqY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3080/Reviewer_SiJc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3080/Reviewer_SiJc"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes BAYOTIDE, a novel Bayesian model for online multivariate time series data imputation. BAYOTIDE models the data as a weighted sum of temporal factors governed by Gaussian processes. Here, the Gaussian processes can be discretized on a random collection of time steps as a Markov model with Gaussian transition. This enables the model to deal with irregularly sampled data. By viewing the model as a state-space model, an online inference procedure is derived using Kalman filtering. Thus, the model can handle missing data. Experiments on real and synthetic data show the competitiveness of the model."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper tackles the problem imputing missing values of an irregularly sampled time series data. The setting is very practical. A lot of existing methods only consider regularly sampled data, and it is non-trivial for them to handle irregular data.\n- This paper extends the idea of TIDER and put it in a novel framework combining Gaussian process and state-space model. This allows the model to perform 1. online imputation 2. uncertainty quantification on missing values and 3. handle irregular data\n- Analysis on the complexity of running cost is given\n- Experiments on real and synthetic data show the competitiveness of the proposed method"
                },
                "weaknesses": {
                    "value": "- There are typos and indentation issues in the paper\n- Although there are no existing online multivariate imputation model, the comparison with online univariate & probabilistic imputation models, e.g. state-space model with Kalman filtering, can be included in the experiment\n- RTS smoother is listed in Algorithm 1 as an option to compute the full posterior. However, it seems that the formula is not given in the paper or the appendix"
                },
                "questions": {
                    "value": "- The main advantage of considering multivariate time series is that the correlation between dimensions can be captured. It seems that all the evaluation metrics are univariate. I suggest the authors to also include multivariate metrics (e.g., energy score [1] and sum CRPS [2]) in the experiments to evaluate if the propose method can better capture the correlations than baselines\n- The model size (e.g., number of parameters) is not reported in the experimental results. It is recommended to also report model size. The proposed model seems to be outperforming, but could it be because that it is using a larger model?\n\n[1] Gneiting, T., & Raftery, A. E. (2007). Strictly proper scoring rules, prediction, and estimation. Journal of the American statistical Association, 102(477), 359-378.\n[2] Kan, K., Aubet, F. X., Januschowski, T., Park, Y., Benidis, K., Ruthotto, L., & Gasthaus, J. (2022, May). Multivariate quantile function forecaster. In International Conference on Artificial Intelligence and Statistics (pp. 10603-10621). PMLR."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3080/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698717752366,
            "cdate": 1698717752366,
            "tmdate": 1699636253587,
            "mdate": 1699636253587,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2pE0fpwskC",
                "forum": "FGoq622oqY",
                "replyto": "5gFs0NHC4W",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3080/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3080/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the careful review and constructive suggestions.We address the comments below:(C: comments; R: response.)\n\n> C1: Typos and presentation.\n\nR1: Thanks for the suggestion! We will polish the presentation quality in the revised version. \n\n> C2: Comparison with online univariate & probabilistic imputation models \uff08state-space model with Kalman filtering\uff09\n\nR2: Good suggestion! We add the comparison with a single state-space model (**single-SS**) with Kalman filtering on *traffic-guangzhou* The results are shown in the following table:\n\n| Observed-ratio=70% | RMSE | MAE | CRPS |\n| ------ | ---- | --- | --- | \n| **BayOTIDE** | 3.724 | 2.611 |  0.053 | \n| **single-SS** | 5.152 | 4.691 |  0.132 | \n\n| Observed-ratio=50% | RMSE | MAE | CRPS |\n| ------ | ---- | --- | --- | \n| **BayOTIDE** | 3.820 | 2.687 |  0.055 | \n| **single-SS**| 5.558 | 4.821 |  0.173 | \n\nIt's clear that the **single-SS** model is much worse than the proposed method. The reason is that the **single-SS** model is not able to capture the cross-channel dependency, which is crucial for multivariate time series imputation.\n\n> C3: Add multivariate metrics (e.g., energy score [1] and sum CRPS [2])\n\nR3: We do agree that the multivariate metrics are more informative than univariate metrics, but we clarify that the *energy score*[1] will reduce to the *CRPS* ($\\beta=m=1$) and *RMSE* ($\\beta=2$), which are already included in the paper. For the *sum CRPS* used in [2], it seems to be the sum over the CRPS overall evaluation points. As we report the mean of the CRPS overall evaluation points, the *sum CRPS* will have the same effect as the *CRPS* in our case. However, we do agree that multivariate metrics may help to better understand the performance under multivariate setting and will investigate it in future work. \n\n\n[1] Gneiting, Tilmann, and Adrian E. Raftery. \"Strictly proper scoring rules, prediction, and estimation.\" Journal of the American Statistical Association 102.477 (2007): 359-378.\n\n\n[2] Kan, K., Aubet, F. X., Januschowski, T., Park, Y., Benidis, K., Ruthotto, L., & Gasthaus, J. (2022, May). Multivariate quantile function forecaster. In International Conference on Artificial Intelligence and Statistics\uff0c 2022\n\n> C4: Add model size discussion\n\nR4: Good point! We take the *traffic-guangzhou* dataset(size: 213 channels, 500 timestamps) as an example, and show the model size comparison of *BayOTIDE* and *CSDI*[1]\u2014the state-of-the-art probabilistic imputation method.  \n\n As *BayOTIDE* is a factorization-based method, the model size is determined by the number of components. Corresponding to the hyper-parameter setting in Table 4, we set $D_r + D_s = 40$ components. Then the weights U's size is $40 \\times 213$, and the components V's size is $40 \\times 500 \\times 2$(the mean and diag var). Thus, the total model size is $40 \\times (213+500 + 500) = 48520$.\n\n*CSDI* is a diffusion-based method, the model size training memory is determined by the number of diffusion steps and the structure of the deep-based score estimator. The default structure *CSDI*'s(Figure 6 in CSDI paper) includes a spatial-temporal transformer with 5 layers and 8 heads and fully connected layes. The parameters also include the embedding(dim=128) of timestamps and features, and the diffusion step embedding. Thus, the total model size is at least $5 \\times 16 \\times 2 \\times (500\\times3+128\\times3) + 128 \\times (213 + 500) =  388224$. \n\nThus, the model size of *BayOTIDE* is much smaller than *CSDI*. The performance gain of *BayOTIDE* over *CSDI* is mainly due to the factorization-based formulation, not the model size. In the *TIDER* paper[2], which takes a similar factorization formulation with *BayOTIDE*, the authors reported the memory usage of TIDER and CSDI (Figure 4 in TIDER paper). The memory usage of TIDER is much smaller than CSDI.\n\n[1]: Tashiro, Yusuke, et al. \"Csdi: Conditional score-based diffusion models for probabilistic time series imputation.\" Advances in Neural Information Processing Systems 34 (2021): 24804-24816.\n\n[2]: LIU, SHUAI, et al. \"Multivariate Time-series Imputation with Disentangled Temporal Representations.\" The Eleventh International Conference on Learning Representations. 2022."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3080/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700547262272,
                "cdate": 1700547262272,
                "tmdate": 1700547262272,
                "mdate": 1700547262272,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "FDjvgNSazS",
            "forum": "FGoq622oqY",
            "replyto": "FGoq622oqY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3080/Reviewer_CYA1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3080/Reviewer_CYA1"
            ],
            "content": {
                "summary": {
                    "value": "This paper highlights the limitations of conventional time-series data imputation methods, which often disregard global trends, presume consistent sampling intervals, and are constrained to offline processing. To address these shortcomings, the authors introduce BayOTIDE, a groundbreaking imputation approach tailored for irregularly sampled data. Central to BayOTIDE's methodology is the interpretation of time series as amalgamations of low rank temporal factors, harnessing Gaussian Processes with varied kernels. By adeptly transitioning these processes into a state space model using stochastic differential equations, the method ensures computational efficiency and real time inference capabilities."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper tackles prevalent issues in time-series imputation, such as neglecting global trends, assumptions of regular sampling, and offline-only operation.\n\n2. The introduction of treating time series as combinations of low-rank temporal factors is a novel perspective.\n\n3. The transformation of Gaussian Processes into a state-space model using stochastic differential equations ensures the method is computationally efficient, which is crucial for real-world applications."
                },
                "weaknesses": {
                    "value": "1. My main concerns regard writing/presentation and theoretical results.\n\n2. The writing is rough, with some unclear and insufficient descriptions. \n\n3. Unclear theoretical support."
                },
                "questions": {
                    "value": "1. The paper requires improved structuring, particularly in terms of presenting the supporting theoretical guarantees."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3080/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3080/Reviewer_CYA1",
                        "ICLR.cc/2024/Conference/Submission3080/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3080/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698805841815,
            "cdate": 1698805841815,
            "tmdate": 1700707228527,
            "mdate": 1700707228527,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "h2GISvA5PL",
                "forum": "FGoq622oqY",
                "replyto": "FDjvgNSazS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3080/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3080/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your comments. Here are our responses. C: comments; R: response.\n\n> C1:\"unclear and insufficient descriptions\"\n\nR1: Could you please specify which part is unclear and insufficient? We will gladly add statements to clarify the unclear and insufficient parts.\n\n> C2:  \"Unclear theoretical support.\"\n\nR2: The factorization-based formulation of the proposed method is aligned with Bayesian PCA[1], which is a well-known and classical Bayesian method with theoretical support.  The state-space GP prior[2] is known to be highly flexible/expressive for function estimation and has been used in numerous applications, including time series modeling [3]. The EP-based inference[4] is also a well-known approximate inference method with theoretical gaurentees on provable convergence. Thus, the proposed method is well-supported by the theoretical results of the above methods.\n\nRef:\n\n[1] Bishop, Christopher. \"Bayesian PCA.\" Advances in neural information processing systems 11 (1998).\n\n\n[2] Rasmussen, Carl Edward. \"Gaussian processes in machine learning.\" Summer school on machine learning. Berlin, Heidelberg: Springer Berlin Heidelberg, 2003. 63-71.\n\n\n[3] Roberts, Stephen, et al. \"Gaussian processes for time-series modeling.\" Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 371.1984 (2013): 20110550.\n\n\n[4]:Minka, Thomas P. \"Expectation propagation for approximate Bayesian inference.\" arXiv preprint arXiv:1301.2294 (2013)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3080/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700546961184,
                "cdate": 1700546961184,
                "tmdate": 1700546961184,
                "mdate": 1700546961184,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2bJPOGcE8k",
                "forum": "FGoq622oqY",
                "replyto": "VJ1Lc7GXXw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3080/Reviewer_CYA1"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Submission3080/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3080/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3080/Reviewers",
                    "ICLR.cc/2024/Conference/Submission3080/Reviewers/Submitted"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3080/Reviewer_CYA1"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the authors' detailed response and their efforts to address the points raised in my initial review. Their clarifications have provided a clearer understanding of the novelty and methodology of the work, which is indeed promising. Consequently, I have decided to change my rating accordingly to \"marginally below the acceptance threshold\". \n\nI believe that the paper, as it currently stands, still falls short of the standards required for acceptance. While the method shows potential, it requires further refinement in presentation and evaluation. Therefore, at this stage, I cannot recommend acceptance."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3080/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700692198914,
                "cdate": 1700692198914,
                "tmdate": 1700692198914,
                "mdate": 1700692198914,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "lnRpy3vFZj",
            "forum": "FGoq622oqY",
            "replyto": "FGoq622oqY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3080/Reviewer_FPUc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3080/Reviewer_FPUc"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a data imputation framework of multivariate nonstationary time series. The framework follows the classical Bayesian PCA (BPCA)-like imputation technique with the exception that the prior distribution is designed so the trend and seasonal components are captured.\n \nSpecifically, the model assumes the observation at each time point to be a linear combination of a few static basis vectors, where the coefficients of the linear combination are time-dependent. To allow seasonal and trend decomposition, the authors introduce specific prior distributions in the form of the Gaussian process (GP), where the temporal correlation is represented with the kernel function.\n \nAlthough the inference procedure is analytically intractable, the authors leverage a variational Bayes approximation and derive a closed-form online updating equation."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Solid formulation.\n- Derivation of an analytic form of online updating equation for data imputation/model updates.\n- The capability of splitting the trend and seasonal components, which is actually not straight forward when nonlinear temporal correlations are considered.\n\n\nThis is a good work. To the best of my knowledge, the framework is new. The basic concept of the BPCA-based imputation approach has been known for decades, but the paper adds a few new elements. \n\nI vote for accepting the paper."
                },
                "weaknesses": {
                    "value": "- Section 3.2 does not seem to play any role. Perhaps this paper has been rejected before, and the authors just wanted to add a \"modern\"-looking section. I got it. But it looks hardly related.\n- Very poor proof-reading quality. Basic latex commands such as \\eqref, \\cite, etc. are not properly used. I know this might be re-re\u2026 submission, but PLEASE be respectful to the reviewers by meticulously proof-reading the manuscript before submission."
                },
                "questions": {
                    "value": "- How does the well-known non-identifiability with respect to the unitary transformation in the UV-factorization form (1) take effect on the result?\n- I am not clear how the almost linear trend could be separated in the result presented in Fig.1. How did the kernel expansion with the GPs produce the linear-looking trend component? What is the intuition behind it? \n- Although I support accepting this paper, I am not 100% sure about the novelty. Bayesian PCA-based imputation is well-established. I know the main novelty comes from the time-series part, but your paper was not very clear about the \"delta\" from the pre-deep learning imputation works. To defend your work, please elaborate on the novelty in light of existing works. I just want to help you --- I suspect many ICLR reviewers do not have a strong understanding of the machine learning basics such as Bayesian PCA, and hence, papers like this one tend to receive unfairly low ratings."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3080/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699082599801,
            "cdate": 1699082599801,
            "tmdate": 1699636253414,
            "mdate": 1699636253414,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NjZ0CXykcz",
                "forum": "FGoq622oqY",
                "replyto": "lnRpy3vFZj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3080/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3080/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the careful review and constructive suggestion\u2014especially the suggestion on highlighting and elaborating the novelty of the proposed method in theoretical and methodological aspects. \n\n**We follow your suggestion and make a response overview to highlight the novelty and contribution of the proposed method, which is the top-level post in this forum. We regularly refer to the response overview**. We address the comments below:(C: comments; R: response.)\n\n>C1:\" Section 3.2 does not seem to play any role. It looks hardly related.\"\n\nR1: The state-space GP we introduced in section 3.2  actually plays a key role in the proposed method. We use that state-space GP to model the trend and seasonal components in a continuous and functional manner with linear time cost. The chain structure of the state-space GP also enables online learning with KF. Specifically, we have to use the chain-structured prior (eq 2 in section 3.2) to replace the full GP prior (eq 7 in section 4.2) in the proposed method (the paragraph under eq7). We apologize for the unclear presentation and will add statements to highlight the role of the state-space GP in the proposed method.\n\n>C2: \"Improve presentation quality\"\n\nR2: Thanks for the suggestion! We will polish the presentation quality in the revised version. Actually, it's the first time we submit this paper to a peer-reviewed conference, so we are pretty grateful to get your valuable feedback and will continue to improve the presentation quality in the future :) \n\n\n>C3:  \"How does the well-known non-identifiability with respect to the unitary transformation in the UV-factorization form (1) take effect on the result?\"\n\nR3: Good point! We do acknowledge that the non-identifiability of unitary transformation will make learned components(V) and weights(U) lose the nice properties of uniqueness. However, we argue that the loss of non-identifiability is not a big issue in our case. The reason is that the components(V) is assigned with functional priors (GP), and are doomed to be non-linear and periodic. Then, even the non-identifiability effect takes place, saying the components(V) do not match the right \"scale\" but still have the right \"shape\", the weights(U) will be able to compensate for the \"scale\" effect. Actually, in our simulation study(Section 5.1), we do observe the non-identifiability effect, but when combining learned components(V) and weights(U), we could still get the right trend and seasonal components with the weights (Figure 1, (b)-(e)). We will add statements to clarify this point in the revised version.\n\n>C4: \"I am not clear how the almost linear trend could be separated in the result presented in Fig.1. How did the kernel expansion with the GPs produce the linear-looking trend component? What is the intuition behind it?\"\n\nR4: Good question! The short answer is that the separation of linear trend is not learned by the GP, but by the weights(U). Specifically, we set four GP components for $V(t)$ in the simulation study, and the first component is a Matern kernel, and the last three components are periodic kernels. Thus, the separated linear trends shown in Figure 1 (b)-(e) are actually from one GP kernel (Matern kernel), but with four different weights(U). The intuition behind it is that the different channels of dynamics may share similar trend components but with different weights. The message-passing algorithm in the proposed method is able to learn the channel-wise weight precisely with conditional moment-matching. \n\n>C5: \"Elaborate Bayesian PCA-based imputation and highlight novelty compared with existing methods.\"\n\nR5: Great point! We just follow your suggestion and add general statements to highlight the novelty of the proposed method in the response overview. Please refer to sections **Novelty and contribution on time series imputation side** and  **Novelty and contribution on Bayesian learning side** in the response overview."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3080/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700546859205,
                "cdate": 1700546859205,
                "tmdate": 1700546859205,
                "mdate": 1700546859205,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PehMzWecN7",
                "forum": "FGoq622oqY",
                "replyto": "lnRpy3vFZj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3080/Reviewer_FPUc"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3080/Reviewer_FPUc"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for clarifications."
                    },
                    "comment": {
                        "value": "\"Overview of Author's Response and Clarifications\" is well-structured and helped me a lot understand the overall picture of the novelty claimed. Although I'm still trying to internalize some aspects of the theory, I think the authors have provided enough clarifications for me to keep the original review and rating."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3080/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700598176278,
                "cdate": 1700598176278,
                "tmdate": 1700598214572,
                "mdate": 1700598214572,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]