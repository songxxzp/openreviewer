[
    {
        "title": "Quality-Diversity through AI Feedback"
    },
    {
        "review": {
            "id": "0Zvt3CAbtX",
            "forum": "owokKCrGYr",
            "replyto": "owokKCrGYr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6013/Reviewer_K2hJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6013/Reviewer_K2hJ"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces an novel approach that integrates AI-generated (LMs) feedback into quality-diversity search algorithms, aiming to enhance the capability of AI systems in independent searching, evaluating, and innovation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1. The authors have proposed a novel and effective quality-diversity algorithm that leverages the latest developments in AI feedback, demonstrating superior performance compared to existing alternatives.\n2. The paper features a comprehensive set of experiments focused on creative writing, supported by a thorough analysis of the results, showcasing the practical applicability of the proposed method."
                },
                "weaknesses": {
                    "value": "1. The presentation, particularly in the experimental section, could benefit from clarification and better organization to enhance readability and comprehension.  \n2. The paper occasionally employs exaggerated language and makes promising claims that seem to lack sufficient empirical backing. For example, the paper states \u201cproviding a recipe that seemingly generalizes to many domains and modalities\u201d and \u201cit is often easier for a model to evaluate the quality of a generation than to generate the same high-quality text.\u201d These claims would be more convincing if supported by concrete evidence or reference or discussion."
                },
                "questions": {
                    "value": "A separate conclusion section, summarizing the key findings and contributions, would be advantageous for providing clear takeaways for the readers."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6013/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698762559173,
            "cdate": 1698762559173,
            "tmdate": 1699636645261,
            "mdate": 1699636645261,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Ml5XeM4Dhq",
                "forum": "owokKCrGYr",
                "replyto": "0Zvt3CAbtX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6013/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6013/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you reviewer K2hJ"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their positive review and useful feedback! We address the weaknesses below:\n\n> The presentation, particularly in the experimental section, could benefit from clarification and better organization to enhance readability and comprehension.\n\nWe have uploaded a new draft of the paper which we hope greatly improves the readability and structure. In particular, Section 4.2 shows changes in blue text with improvements to clarity in the experimental setup, and a correction to a section reference in the baseline description of **Random-Search**\n\n> The paper occasionally employs exaggerated language and makes promising claims that seem to lack sufficient empirical backing. For example, the paper states \u201cproviding a recipe that seemingly generalizes to many domains and modalities\u201d and \u201cit is often easier for a model to evaluate the quality of a generation than to generate the same high-quality text.\u201d These claims would be more convincing if supported by concrete evidence or reference or discussion.\n\nWe take this concern seriously and take a moment to clarify on the two highlighted points to resolve the misunderstanding. On the quote \u201cproviding a recipe that seemingly generalizes to many domains and modalities\u201d, we highlight in the conclusion through reference that AI feedback can be done with any model that has been instruction-tuned such as the AI feedback model used in QDAIF. We cited in the conclusion Liu et al., 2023, a work that introduces instruction tuning for multimodal text-image understanding models. Instruction tuning enables this model to solve tasks in image and text domains, including solution evaluation - it is interesting future work for example to apply AI feedback to images with the visual instruction-tuned model (or another similar image-text model such as GPT-4+V) to evolve images and creative art, that can be described by AI feedback on the new domain of images, and generate refinements of images.\n\nOn the quote \u201cit is often easier for a model to evaluate the quality of a generation than to generate the same high-quality text\u201d, we cited Saunders et al., 2022, to refer to the generation-discrimination gap described by the quote. We also cited this part of their work in Section 4.4 in the original manuscript (now in A.18), but realized that we forgot to include page number 12 in the first mention of this reference (which we did in Section 4.4 originally), containing the reference to generation-discrimination gap which gives context to our results. The page number is added now to the first mention of the reference. We apologize for the lack of clarity, and hope the added detail will prevent future readers from sharing the same confusion.\n\n> A separate conclusion section, summarizing the key findings and contributions, would be advantageous for providing clear takeaways for the readers.\n\nThank you for sharing this suggestion and for thinking of ways to improve the presentation of QDAIF. We added to the first paragraph of the conclusion a brief statement on key takeaways from results for our draft revision, to support the communication of the contributions messaging in the final paragraph of the conclusion.\n\n### Conclusion:\nWe would be grateful for your thoughts on the quality of our manuscript and contributions of QDAIF following our response here as well as the general comment, and hope to get your support in realizing QDAIF as a valuable contribution to ICLR, during the remaining time of the discussion period.\n\nIf you feel that your comments have been adequately addressed, we would greatly appreciate it if you could update your score to reflect that.\n\nThank you for your encouraging statements on the strengths of the paper. We look forward to hearing more from you on ways to make this paper stronger."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6013/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700630604659,
                "cdate": 1700630604659,
                "tmdate": 1700630604659,
                "mdate": 1700630604659,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "msnZuALVUQ",
                "forum": "owokKCrGYr",
                "replyto": "0Zvt3CAbtX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6013/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6013/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow up"
                    },
                    "comment": {
                        "value": "We understand that the author discussion period is closing soon, but we are still open to coming back to you on any remaining questions you may have about the manuscript. We have gone deep into following up on your concerns, and have resolved them from our understanding of your points raised.\n\nWe would be happy to quickly answer any potential remaining questions from you. Thank you again for your work on improving the paper, and encouraging statements on the strengths of our work."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6013/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737644915,
                "cdate": 1700737644915,
                "tmdate": 1700737644915,
                "mdate": 1700737644915,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Nzfrx51xAO",
            "forum": "owokKCrGYr",
            "replyto": "owokKCrGYr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6013/Reviewer_3nT4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6013/Reviewer_3nT4"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed a pipeline combining a quality-diversity search algorithm and LLM as feedback for quality and diversity, aiming to improve the quality-diversity in the creativity domain, such as creative writing. The authors also conduct human evaluations to evaluate the output of the pipeline."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Strength: \n* The paper addresses an interesting problem in the creativity domain, namely, generating solutions that are both diverse and of high quality. The integration of AI feedback and the existing QD algorithm seems to be novel and interesting"
                },
                "weaknesses": {
                    "value": "Weakness\n* One key motivation of the paper using AI feedback seems to bypass the necessity to articulate a set of criteria. However, the prompt strategies still resort to specified diversity and quality criteria\n* The evaluation result seems to be a bit confusing; for example, in Table 1, one of the methods is LMX, Fitness-only, then in section 4.3 when it explains the method, there is LMX Quality-only. Is that the same method as LMX, fitness-only\n* It would be interesting to see ablation analysis to compare with the QD with and without AI feedback (not sure if LMX fitness-only or quality only serves the baseline) \n* QD metric is used throughout, which is the \u201csum of highest quality value found in each bin\u201d - it seems to only focus on quality rather than diversity. For readers not familiar with QD metrics, some explanation/justification of why QD measures Quality and Diversity will be helpful"
                },
                "questions": {
                    "value": "Table 1:  there is a lack of explanation of the quality metrics. For example, what is the difference between human QD score and quality rating? Is quality rating from humans? \n\n* On page 5, section quantifying performance and diversity, it is unclear where the probability comes from in the sentence \u201c the solutions\u2019 quality estimate is derived from the logarithm of the probability of the LM\u2019s answer\u201d \u2026  Please clarify\n\n* Figure 3 illustrates the differential performance of various methods on different generation tasks. Is there any qualitative difference in terms of the QD score difference of less than one point"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6013/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6013/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6013/Reviewer_3nT4"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6013/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698766125654,
            "cdate": 1698766125654,
            "tmdate": 1699636645158,
            "mdate": 1699636645158,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dn9Muygr0k",
                "forum": "owokKCrGYr",
                "replyto": "Nzfrx51xAO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6013/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6013/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you reviewer 3nT4 [1/3]"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their thoughtful review of the paper. We come back to the reviewer\u2019s questions and concerns below, starting off with some clarifications to aid in the understanding of our findings and explanations, and then in the second part of the reply clarifying on main concerns.\n\n> The evaluation result seems to be a bit confusing; for example, in Table 1, one of the methods is LMX, Fitness-only, then in section 4.3 when it explains the method, there is LMX Quality-only. Is that the same method as LMX, fitness-only\n\nThank you for highlighting this for correction! It was a typo on our part, \u201cLMX, fitness-only\u201d should be worded as \u201cLMX, Quality-Only\u201d. We corrected this in Table 1 in the revised draft, shown in blue text. The Quality-Diversity (QD) literature frequently uses the term \u201cfitness\u201d for the notion of quality as a metric, for general context.\n\n>QD metric is used throughout, which is the \u201csum of highest quality value found in each bin\u201d - it seems to only focus on quality rather than diversity. For readers not familiar with QD metrics, some explanation/justification of why QD measures Quality and Diversity will be helpful\n\nIn many domains you want to get a wide range of high-quality diverse artifacts (the motivating case as described in the introduction); the QD score [1] is one popular measure used in the literature. QD score increases are possible in two ways - by filling a previously empty bin with a solution of that kind (i.e. finding a novel solution, with improvement to the overall archive by the amount of quality improvement introduced from the addition of this new solution of a particular quality value), or by improving over an existing solution in a filled, non-empty bin with an evolved solution that is evaluated to be of this kind/bin, but has a higher quality score, as described in the method overview in Section 3 regarding the acceptance of evaluations to the archive. Coverage of the archive with new, diverse solutions, is, therefore, a key contributor to improvements in QD score (which we highlight in new additional stats including coverage in the added A.7 section, referenced in figure 3).\n\n> Table 1: there is a lack of explanation of the quality metrics. For example, what is the difference between human QD score and quality rating? Is quality rating from humans?\n\nYes, quality rating is from humans. Thank you for sharing your concern on readability here. We provide full details on the human evaluation study referenced in the Table 1 results in Appendix A.1 and reference it in the \u201cEvaluation\u201d paragraph of Section 4.1. We added minor clarification and further self-contained referencing of A.1 in the revision for improved clarity.\n\n> On page 5, section quantifying performance and diversity, it is unclear where the probability comes from in the sentence \u201c the solutions\u2019 quality estimate is derived from the logarithm of the probability of the LM\u2019s answer\u201d \u2026 Please clarify\n\nAs part of the standard AI feedback method, the quality and diversity prediction values are obtained from LM next-token-prediction log probabilities, where we assess the probability of the AI feedback LM in predicting for a given text/story one label/token(s) (e.g. \u201chorror\u201d) versus another label/token(s) (e.g. \u201cromance\u201d). We quote in the section referred here in the paper, \u201cThe log probability of these responses serves as our measure of solution diversity\u201d for context, applying the same approach to quality AI feedback. We slightly reworded a part of this sentence, highlighted in blue text. Thank for raising possible suggestions to improve the readability of the paper."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6013/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700630446598,
                "cdate": 1700630446598,
                "tmdate": 1700630446598,
                "mdate": 1700630446598,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NwxsoP7wCW",
                "forum": "owokKCrGYr",
                "replyto": "Nzfrx51xAO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6013/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6013/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow up"
                    },
                    "comment": {
                        "value": "We have added additional material in the v2 revision to further expand upon the topic of Automating QDAIF Search (Diversity Axes).\n\nWe hope that this gives you further insights into the strengths of QDAIF. We have followed up on all of your concerns, and see that we have resolved them from our understanding of your points.\n\nWe would be happy to quickly answer any potential remaining questions from you. Thank you again for your work on improving the paper."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6013/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737438567,
                "cdate": 1700737438567,
                "tmdate": 1700737438567,
                "mdate": 1700737438567,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qAhfpw7Kld",
            "forum": "owokKCrGYr",
            "replyto": "owokKCrGYr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6013/Reviewer_8ua9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6013/Reviewer_8ua9"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses the problem of generate a diverse range of high-quality outputs by using AI feedbacks, instead of traditional Quality-Diversity (QD) search algorithms. The authors propose a Quality-Diversity through AI feedback (QDAF) where an evolutionary algorithm applies LMs to both generate variation and evaluate the quality and diversity of candidate text. Experiments show that produced outputs have a reasonable agreement between AI and human evaluation.\n\nThe proposed approach QDAIF builds upon MAP-Elites [Mouret and Clune, 2015], which follows those steps: randomly select a solution, mutate it, evaluate the new solution in terms of quality and diversity. Finally, if the new solution is better, all previous cells are replaced. The improvement of QDAIF is significant and leverage the characteristics of LLMs. Instead of using a uniformly-separated grid, the authors split the grid by density. This makes a lot of sense because we output distributions generated by LLMs are skewed. The initialization and mutation are based on few-shot prompting. Finally, the quality and diversity evaluation is done via prompting the LLMs and observing whether the answer is \"yes\" or \"no\" and their log-probabilities.\nOverall, the method is a composition of simply ideas that make it easy to follow.\n\nThe experiments consists of creative text generation in the domains of opinions and stories. The domain in the former is about eating plant-based diets, and for the latter a short story containing a spy and a politician. Diversity is based on the sentiment towards a topic in case o opinions and genre and ending for the stories. The authors evaluate using QD score [Pugh et al. 2016] and human evaluation. In terms of baseline, they seem to be simple variations of the framework. It would be needed to have baselines cited in prior work. The results are significantly better for QDAIF, but it is unclear whether this is due because the baselines are bad or whether the model is really better. I appreciate the other experiments that the authors have conducted on scaling up the models and trying other mutation methods.\n\nOverall, the paper is well structured and written. The idea is simple but sounds effective. My only concern is the lack of more sophisticated baselines. I would ask the authors to evaluate their proposed approach on another task, such as control text generation (e.g., writing about specific topics and using a classifier to assess the topic being discussed)"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- A combination of simple ideas that allow to generate diverse high-quality outputs\n- Strong performance in the experiment section\n- The paper is well written"
                },
                "weaknesses": {
                    "value": "- The lack of strong baselines\n- More datasets for the experiments would be appreciated"
                },
                "questions": {
                    "value": "Could you add more baselines and tasks?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6013/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698768180772,
            "cdate": 1698768180772,
            "tmdate": 1699636645043,
            "mdate": 1699636645043,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "288GIXXLDl",
                "forum": "owokKCrGYr",
                "replyto": "qAhfpw7Kld",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6013/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6013/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you reviewer 8ua9"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their insightful review, and are encouraged by their comments on the strengths of the paper. We come back to the reviewer\u2019s concerns on experimental soundness below.\n\n> In terms of baseline, they seem to be simple variations of the framework. It would be needed to have baselines cited in prior work. The results are significantly better for QDAIF, but it is unclear whether this is due because the baselines are bad or whether the model is really better\u2026 My only concern is the lack of more sophisticated baselines.\n\nThank you for sharing your feedback on the importance of detailed and informative baseline comparisons. We agree with this statement, and revised the draft with additional baseline comparisons, introducing new baselines from prior works (on top of the LMX, Quality-Only baseline introduced in the original manuscript, and studied in the LMX, or Language Model Crossover paper [1]) and detailing performance comparison results with QDAIF in Appendix A.8, with detailed implementation details of added diversity-seeking baselines in A.9. In addition to further demonstrations of performance improvements by QDAIF compared to baselines, the new comparisons highlight the importance of each component of QDAIF in improving the QD score performance during search, with new insights on the value of diversity-seeking elements of relevant search algorithms, often outperforming the baseline which optimizes for quality in solutions only (LMX, Quality-Only).\n\nFurthermore, as highlighted in the general response, we introduced a new variant of QDAIF for Poetry, LMX-rewrite (in edited Section 4.4), which becomes a fair comparison to the Random-Poems baseline, where both methods do not request for solutions of specific genres and tones in poetry, but LMX-rewrite adds the rewriting mutation and evolution of archive bin solutions to improve over Random-Poems. This experiment improvement also enabled us to conduct an ablation with the method Fixed Seed Rewrite, which reveals that the element of evolving an improving population with QDAIF (in addition to rewriting mutation) is important for significant performance improvements with QDAIF. \n\nGiven the improvements to the experimental soundness with sophisticated baselines, and a showcasing of the strengths and weaknesses of baselines, we have shown performance gains from QDAIF to be meaningful (with improved insights on the contributions of components of QDAIF), in line with seminal works in the literature which also compare to baselines (such as Random-Search, as well as LMX, Quality-Only for single objective quality/fitness optimization), in the experiments of the Novelty Search [2] and MAP-Elites [3] papers.\n\n> I would ask the authors to evaluate their proposed approach on another task, such as control text generation (e.g., writing about specific topics and using a classifier to assess the topic being discussed)\n\nThank you for your interest in the applicability of QDAIF to other domains in addition to creative writing such as the existing **Opinions**, **Stories**, and **Poetry** domains.\n\nFirstly, the **Opinions** domain seems to be relevant to the idea of topic writing, which is highlighted in the review here in the paper explanation. The topic of eating vegetables and plant-based foods would likely be relevant here.\n\nStill, we take the suggestion on the value of studying QDAIF in different kinds of domains into account, and added results of QDAIF applied to a new (non-creative-writing) code-writing domain in Appendix A.20. We saw marked improvement in the diversity and quality of generated code from QDAIF (LMX-rewrite) for the task of implementing sorting algorithms to solve a specified problem, compared to the Random-Code baseline.\n\nWe believe that results here also demonstrate the flexibility and generality of QDAIF, in being helpful to creative search in another, more-technical domain.\n\n### Conclusion\nWe would be grateful for your thoughts on the quality of our manuscript and contributions of QDAIF following our response here as well as the general comment, and hope to get your support in realizing QDAIF as a valuable contribution to ICLR, during the remaining time of the discussion period.\n\nIf you feel that your comments have been adequately addressed, we would greatly appreciate it if you could update your score to reflect that.\n\nThank you again for your helpful feedback that further improved the paper\u2019s quality!\n\n[1] Language Model Crossover (LMX) - https://arxiv.org/abs/2302.12170\n\n[2] Novelty Search - https://stars.library.ucf.edu/facultybib2010/1530/\n\n[3] MAP-Elites - https://arxiv.org/abs/1504.04909"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6013/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700630378910,
                "cdate": 1700630378910,
                "tmdate": 1700630378910,
                "mdate": 1700630378910,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "B6NaA6Wfpy",
                "forum": "owokKCrGYr",
                "replyto": "qAhfpw7Kld",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6013/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6013/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow up"
                    },
                    "comment": {
                        "value": "We have added additional material in the v2 revision to further expand upon the topic of Additional Domain Beyond Creative Writing and an Additional Baselines.\n\nWe hope that this gives you further insights into the strengths of QDAIF. We have followed up on all of your concerns, and see that we have resolved them from our understanding of your points.\n\nWe would be happy to quickly answer any potential remaining questions from you. Thank you again for your work on improving the paper."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6013/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737366998,
                "cdate": 1700737366998,
                "tmdate": 1700737366998,
                "mdate": 1700737366998,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Fa6AiDZ4fz",
            "forum": "owokKCrGYr",
            "replyto": "owokKCrGYr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6013/Reviewer_gkKB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6013/Reviewer_gkKB"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces Quality-Diversity through AI Feedback (QDAIF), a novel method that leverages advances in foundation models to evaluate the quality and diversity of generated text in qualitative domains. QDAIF employs an evolutionary algorithm that uses language models to generate variation and evaluate the quality and diversity of candidate text. The results demonstrate that QDAIF covers more of a specified search space with high-quality samples compared to non-QD controls and aligns with human perception of quality and diversity."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. QDAIF presents a novel approach to discover diverse and high-quality solutions in qualitative domains by leveraging AI feedback, which contributes to the development of AI systems.\n2. The paper thoroughly discusses limitations and potential future work, offering some insights for further research in this area."
                },
                "weaknesses": {
                    "value": "1. QDAIF still requires researchers to define the axes of diversity they are most interested in, which may limit its autonomy in creative search.\n2. Could we have a detailed comparison with other AI feedback methods or discuss how QDAIF specifically addresses their limitations? \n3. The generalizability of QDAIF to other domains and tasks beyond creative writing is not extensively discussed."
                },
                "questions": {
                    "value": "1. Can you provide more insight into the scalability and computational efficiency of QDAIF in more complex and large-scale tasks?\n2. How does the proposed QDAIF approach perform in other domains and tasks beyond creative writing?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6013/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6013/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6013/Reviewer_gkKB"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6013/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698836780593,
            "cdate": 1698836780593,
            "tmdate": 1699636644939,
            "mdate": 1699636644939,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PX6CMUDA6j",
                "forum": "owokKCrGYr",
                "replyto": "Fa6AiDZ4fz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6013/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6013/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you reviewer gkKb [1/2]"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their insightful review and thoughtful comments on the strengths of the paper. We come back to the reviewer\u2019s questions and concerns below.\n\n> QDAIF still requires researchers to define the axes of diversity they are most interested in, which may limit its autonomy in creative search.\n\nThank you for raising this interesting discussion point following the presented statements on the limitations of QD methods in the final section of the manuscript. We added Appendix A.10 which investigates and tackles the concern raised here through additional experiments and literature review, and referenced A.10 in the conclusion section on the limitations discussion.\n\nFirstly, to give more context from prior works in the literature (as we described in the context of the discussion on limitations since the original manuscript), most existing algorithms since the first introduction of QD search have not yet studied approaches (if at all) to alleviate the need to define the axes of diversity, especially ones that would likely be most interesting to users in a creative search. In A.10, we added references for an existing possible direction of defining higher dimensions of diversity via unsupervised diversity representation learning. Here we noted limitations of this approach in the case where for our desired use cases, we *do* want to leverage the general knowledge of assessing all types of creative writing from foundation models to inspire creative QDAIF search; we can then exploit LM domain knowledge for expanding on possible output text solutions where the distinctions in diverse, high-quality texts can be subjectively appreciated and informatively cataloged.\n\nWe describe in A.10 an approach where such domain knowledge for automating the initialization or expansion of diversity axes can be explored for more diverse, high-quality texts. With recent advances in LM capabilities (e.g. GPT-4), we can specify the search problem or domain of interest, and ask it, for example, to directly generate ideas for plausible new diversity axes to explore, or even directly generate the AI feedback prompts which may be used in the existing QDAIF setups, maybe following the structure and format of say the feedback prompts we tested.\n\nThe question remains - how effectively would QD score performance (the measure of quality and diversity in archive solutions) improve if one tested such a pipeline, and continued search with the introduction of additional diversity axes over time.\n\nWe demonstrated in A.10 results that applying dimension expansion on the **Stories** domain as an example is effective in enabling the improvement of QD score in higher dimensions of diversity, surprisingly even providing gains in \u201cBest Solution Quality\u201d (mentioned in general response).\n\nOverall, new results that we found and added bring us closer to the potential of automatically defining diversity axes, proving practical performance gains to be had.\n\n> The generalizability of QDAIF to other domains and tasks beyond creative writing is not extensively discussed\u2026 How does the proposed QDAIF approach perform in other domains and tasks beyond creative writing?\n\nWe added Appendix A.20, referenced in Section 4.4, to show the results of QDAIF applied to coding problems, which is not focused on creative writing, and compared to the Random-Code baseline.\n\nWe are encouraged that you highlighted the importance of applying QDAIF to highly-subjective, qualitative domains, where no viable measures except for AI feedback (the alternative to expensive human feedback) exist, unlike the domains studied by QD works in prior work. Interestingly, we show in new results that AI feedback\u2019s ability to bring evaluation to qualitative domains is also effective for code-writing tasks, where QDAIF generated qualitatively more diverse sorting algorithms (from first principles) with higher quality scores obtained, and overall higher QD score than that of the baseline (that returned nearly always one particular type of sorting algorithm, 95% of the time).\n\nWe appreciate the interest of the reviewer in QDAIF when applied to domains beyond creative writing. We further highlight the generalizability of QDAIF with this finding."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6013/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700630258343,
                "cdate": 1700630258343,
                "tmdate": 1700630258343,
                "mdate": 1700630258343,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CrPj9NSfO5",
                "forum": "owokKCrGYr",
                "replyto": "Fa6AiDZ4fz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6013/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6013/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you reviewer gkKb [2/2]"
                    },
                    "comment": {
                        "value": "> Could we have a detailed comparison with other AI feedback methods or discuss how QDAIF specifically addresses their limitations?\nYes, we highlight the relevance of AI feedback (AIF) methods in the context of QDAIF in the original manuscript in Section 2.3, and added minor clarifications in this section in the revised draft, providing more clarity on how QDAIF leverages AIF in a new setting to introduce a new kind of QD algorithm, enabling other recent advancements in QD research studied in different domains to be applied on top of the high-level QDAIF approach.\n\nWe show with this clarification that QDAIF is a complementary direction of research that takes inspiration from works applying AIF such as Constitutional AI [1] and Self-Refine [2], and their proven results in utilizing AI feedback for qualitative text quality assessment (which led to LM refinements being able to improve text solutions), to apply AIF to a new context towards tackling QD problems (adding the diversity and evolution aspects for a new application in QD).\n\nWe hope that this brings a clearer picture of the differences between QDAIF and other AI feedback methods, where QDAIF enables QD approaches in new domains through qualitative AI feedback.\n\n> Can you provide more insight into the scalability and computational efficiency of QDAIF in more complex and large-scale tasks?\n\nThe scalability and computational efficiency of QDAIF both hinge on the capabilities and sizes of available existing LMs (which carry out both the mutation of texts, and the evaluation of text solutions defined by AI feedback prompts).\n\nWe refer to an additional analysis carried out and described since the original manuscript version to study the effect of the generator/mutator LM\u2019s model size in Section 4.3, on \u201cLMX Model Size\u201d. Results summarize likely gains in scalability, where discovered samples of creative writing solutions found by QDAIF (with larger model sizes as generator LMs) obtained higher human feedback scores for quality compared to their ratings of samples from smaller LMs.\n\nFurthermore, our additional analysis on the qualitative sample poems in the **Poetry** domain in the revised manuscript, Appendix A.18 (in particular, Figures 21 and 22) suggests potential improvements in meaningful mutations of texts towards more diverse, higher-quality texts when running QDAIF with larger, more capable models such as GPT-4 compared to GPT-3.5 Turbo. While QDAIF benefits from more search iterations (meaning more LM generation and evaluation calls via label/attribute prediction), it still shows QD score performance sample efficiency improvements over existing baselines, hinting at the potential scalability of QDAIF that can improve with advancements to available LMs. \n\n ### Conclusion:\nWe would be grateful for your thoughts on the quality of our manuscript and contributions of QDAIF following our response here as well as the general comment, and hope to get your support in realizing QDAIF as a valuable contribution to ICLR, during the remaining time of the discussion period.\n\nIf you feel that your comments have been adequately addressed, we would greatly appreciate it if you could update your score to reflect that.\n\nThank you again for your work on the review.\n\n[1] Constitutional AI - https://arxiv.org/abs/2212.08073\n\n[2] Self-Refine - https://arxiv.org/abs/2303.17651"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6013/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700630321521,
                "cdate": 1700630321521,
                "tmdate": 1700654742949,
                "mdate": 1700654742949,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yghZkbJDNb",
                "forum": "owokKCrGYr",
                "replyto": "Fa6AiDZ4fz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6013/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6013/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow up"
                    },
                    "comment": {
                        "value": "We have added additional material in the v2 revision to further expand upon the topic of Automating QDAIF Search (Diversity Axes) and an Additional Domain Beyond Creative Writing.\n\nWe hope that this gives you further insights into the strengths of QDAIF. We have followed up on all of your concerns, and see that we have resolved them from our understanding of your points.\n\nWe would be happy to quickly answer any potential remaining questions from you. Thank you again for your work on improving the paper."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6013/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737299168,
                "cdate": 1700737299168,
                "tmdate": 1700737299168,
                "mdate": 1700737299168,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]