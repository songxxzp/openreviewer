[
    {
        "title": "Learning interpretable control inputs and dynamics underlying animal locomotion"
    },
    {
        "review": {
            "id": "1iN8K6HZyB",
            "forum": "MFCjgEOLJT",
            "replyto": "MFCjgEOLJT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6347/Reviewer_j5DC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6347/Reviewer_j5DC"
            ],
            "content": {
                "summary": {
                    "value": "This manuscript provides a framework for modeling the behavior of the larval zebrafish using a control theoretic and dynamical systems framework. They model the behavior of a system as arising from a dynamical system driven by sparse inputs with a students-t distributed prior. They assume behavior is generated from the dynamical system by either a linear or RNN model, and use iQLR-VAE to infer model parameters and the sparse inputs. In each case they use a model truncation approach to reduce the number of dimensions considered. They begin by validating the approach on a double pendulum oscillator system, showing they could reproduce the number and values of eigenvalues. Then they analyze a dataset of larval zebrafish behavior, which is organized into discrete bouts and thus a natural test case for this approach. They find they need high capacity models (120 latent dimensions, 10 control inputs) to fit the behavior. They show that the resulting representation is useful, in that the dynamical representations provides a more disentangled input that can be better decoded from the top 5 PCs compared to the postural representation or even the full time series in some cases. By using model reduction, they show the dynamics underlying behavior can be decomposed  into separate modes."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The formulation is well described and I believe novel, and an addition to other methods fitting dynamical systems to neural and muscular systems, but here in the case of sparsely driven behavior. \n\n* The result about better disentangling of behavior is interesting, and the spatial decoding result as well. \n\n* The model reduction approach to achieve small models is interesting."
                },
                "weaknesses": {
                    "value": "* There is a lack of benchmarks comparisons to other techniques in the literature such as LFADs. Even though some suggest continuous inputs for their control scheme, could they be used to model the behavioral dynamics in Figure 3C for instance. \n\n* I found the applications a bit limited. It wasn\u2019t obvious from this analysis that there were fundamentally new types of experiments that were enabled by this approach. \n\n* Overall, I think the lack of benchmarks combined with the lack of novel applications was a major sticking point for me and I view this manuscript as very borderline. I would be happy to reconsider the manuscript (which was very well written) if these were added or addressed. I see this as just 1 compelling figure short of a reasonable submission."
                },
                "questions": {
                    "value": "* Does the number of control inputs match the number of bout types people have reported in the literature? \n\n* There is no ground truth in behavior for the driving inputs and thus there is no way to validate that they are correct, however with an appropriate experiment (e.g. applying a perturbation or stimulus at a specific time) perhaps they could be useful. \n\n* Generally, more concretely linking any of the observations to real neural or behavioral variables would improve the manuscript's impact."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6347/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6347/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6347/Reviewer_j5DC"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6347/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698755718926,
            "cdate": 1698755718926,
            "tmdate": 1700704321641,
            "mdate": 1700704321641,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "h4Oq2yV6Ee",
                "forum": "MFCjgEOLJT",
                "replyto": "1iN8K6HZyB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6347/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6347/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to j5DC"
                    },
                    "comment": {
                        "value": "Many thanks for your in-depth review and for the positive feedback! As described in the common reply, we have now updated the paper to reflect new results, which we believe should address the majority of your concerns. Below, we address the specific points/questions you raised. Of course, please let us know if anything is unclear or if you feel that we did not properly address your concerns.\n\n> There is a lack of benchmarks comparisons to other techniques in the literature such as LFADs. Even though some suggest continuous inputs for their control scheme, could they be used to model the behavioral dynamics in Figure 3C for instance.\n\nThat is a good point. We have now included a comparison to LFADS (where we used the standard LFADS implementation, with an autoregressive prior). In summary, we found that LFADS learns inputs throughout the whole time series that exhibit a strong correlation with the actual behavior (see **new Figure S6**). This is somewhat expected, as the autoregressive prior does not discourage the model from using inputs to fit the temporal structure in the data, that could alternatively be captured by the dynamics. To address the second part of your question, we found that such inputs allow us to accurately reconstruct the behavior, but lead to a representation in the LFADS model that is less predictive of the movement category than the iLQR-VAE MGU representation (see **updated Figure 2.C**). \n\n\n> I found the applications a bit limited. It wasn\u2019t obvious from this analysis that there were fundamentally new types of experiments that were enabled by this approach.\n\n> There is no ground truth in behavior for the driving inputs and thus there is no way to validate that they are correct, however with an appropriate experiment (e.g. applying a perturbation or stimulus at a specific time) perhaps they could be useful.\n\n> Generally, more concretely linking any of the observations to real neural or behavioral variables would improve the manuscript\u2019s impact.\n\nThank you for highlighting the concern regarding limited application. To address this, we implemented our framework on a C. elegans dataset, capitalizing on a significant advantage \u2014 the presence of controlled external stimuli in certain trials. We exploited this well-timed laser heat shock as a ground truth control input. In **new Figure 4.D**, we show a salient control is inferred at the moment of the laser pulse, a feature not readily apparent in the posture space. This outcome is particularly encouraging as it suggests the potential for the model to be employed in conjunction with perturbation experiments in the future. For instance, it could be used alongside optogenetic stimulation applied to a population of neurons. In such experiments, the timing would be controlled by the experimentalist, while the impact on the dynamical system, though unknown, could be inferred by our model.\n\n>`Q1.` Does the number of control inputs match the number of bout types people have reported in the literature?\n\nThis is an interesting point you raised. To clarify, we found that rather than controlling distinct movements, the different control inputs were combined in different ratios to generate different categories of movements. We added a figure illustrating this (**Figure S3**)."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6347/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700524512281,
                "cdate": 1700524512281,
                "tmdate": 1700524512281,
                "mdate": 1700524512281,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UPSAknTjiC",
                "forum": "MFCjgEOLJT",
                "replyto": "h4Oq2yV6Ee",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6347/Reviewer_j5DC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6347/Reviewer_j5DC"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the reply"
                    },
                    "comment": {
                        "value": "Thanks for the reply. I do think these substantive changes directly address my questions which were shared by some of the reviewers eg AsPq  and 9AdGwho note the need to do a proper model comparison and 9AdG who notes the limited scope of the results for application papers where it is common to demonstrate general applications in a few use cases. I will increase my score based on these results."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6347/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700704297206,
                "cdate": 1700704297206,
                "tmdate": 1700704297206,
                "mdate": 1700704297206,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "fZ03jhdEdY",
            "forum": "MFCjgEOLJT",
            "replyto": "MFCjgEOLJT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6347/Reviewer_325F"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6347/Reviewer_325F"
            ],
            "content": {
                "summary": {
                    "value": "In this paper the authors propose a control framework for estimating movement dynamics from behavioural/postural observations. Movements are considered as generated by an unknown dynamical system controlled through sparse input signals.\nThey employ two alternative methods to fit the latent dynamics: \n- One that uses the iLQR-VAE from Schimel et al., 2022 that approximates the observed dynamical system through an RNN.\n- And a linear model of \u201clarge dimensionality\u201d that is consequently reduced to a lower dimensional model using balanced truncation.\nThey demonstrate their method on a toy example of a linearly approximated system comprising two pendulums, and on a behavioural dataset of zerbafish movements. \nThey are able to further provide insights into the identified dynamics by dissecting the spectrum of the reduced linear model."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Applying balanced model reduction together with dynamical and control inference is an interesting contribution to the existing system identification literature.\n- The linear approximation through the model reduction allows for interesting insights into the approximated dynamics (like in Figure 4 for analysing the eigenmodes active during different movements), that would be otherwise more cumbersome to perform for an RNN."
                },
                "weaknesses": {
                    "value": "- The dissection of the identified dynamics through the reduced linear model requires the non-reduced linear system to already approximate accurately the observed system. I wonder whether the authors could provide a systematic analysis on the robustness of their framework when fit on the nonlinear toy model.\n- As the authors already mention in their discussion, the framework they propose requires the fitting of two dynamical systems: an RNN that captures accurately the observed behavioural trajectories, and an linear system that provides interpretability."
                },
                "questions": {
                    "value": "- In the toy example with the pendulum, as I understand, the authors created observations by simulating the linear approximation of the system (assuming small angles). I wonder how  the proposed framework would perform if the authors created the observations for the same system parameters with the nonlinear dynamics, and for parameter sets that result in increasingly larger angles. I think in this toy example it is interesting to demonstrate the robustness of the linear-reduced order framework.\n\n- In Figure 3 why does the classification accuracy decrease with time (observation time?)?\n\n- In Figure 4C and associated main text, the authors mention that the reduced model added eigenmodes with larger timescales, while it neglected the small timescale modes of the the non-reduced system. While the second part of the previous sentence is expected, I am not sure how should I understand the first one. Can you provide some intuition. Also related to this, when I first looked at Figure 4C I thought that the large the large time scale values of the reduced and non-reduced model overlap, therefore the light grey ones are not visible. Can you probably make the circles of the reduced system non-opaque or non-filled to make the plot clearer?\n\n- I think it would be helpful if the authors mention in the supplement how they fit the linear model of their framework, and provide a brief description of the iLQR-VAE framework that is a crucial component of the proposed approach.\n\n- Model Selection C.1. section is missing from the supplement.\n\n- There is a typo in the subscripts in Eq. 5."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6347/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6347/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6347/Reviewer_325F"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6347/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698839881836,
            "cdate": 1698839881836,
            "tmdate": 1699636699529,
            "mdate": 1699636699529,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "RkywgsZN7x",
                "forum": "MFCjgEOLJT",
                "replyto": "fZ03jhdEdY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6347/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6347/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to 325F (1/2)"
                    },
                    "comment": {
                        "value": "> Applying balanced model reduction together with dynamical and control inference is an interesting contribution to the existing system identification literature.\n\n>The linear approximation through the model reduction allows for interesting insights into the approximated dynamics (like in Figure 4 for analyzing the eigenmodes active during different movements), that would be otherwise more cumbersome to perform for an RNN.\n\nThank you for your positive feedback on the insights from the model reduction, we also believe that this is a promising method to facilitate interpretability. This method was also successful when applied to the new C. elegans dataset, with the first 3 modes of the reduced model corresponding to reverse crawls, omega-turn, and forward crawls (see **new Figure S8**).\n\n\n> In the toy example with the pendulum, as I understand, the authors created observations by simulating the linear approximation of the system (assuming small angles). I wonder how the proposed framework would perform if the authors created the observations for the same system parameters with the nonlinear dynamics, and for parameter sets that result in increasingly larger angles. I think in this toy example it is interesting to demonstrate the robustness of the linear-reduced order framework.\n\nThank you for raising this point! Indeed, we generated this toy example by assuming that the system was linear. The main point of this example was to illustrate how the model reduction works and act as a sanity check that iLQR-VAE + model reduction has the expected performance, in the case where ground truth is known.\n\nWhile we do agree that the example you propose is interesting, it is not obvious to us how it demonstrates the robustness of the framework: indeed, as we increase the angles, the model will not recover the linearized dynamical system, but the linearized system does not exactly capture the ground truth dynamics, so it is not obvious to us whether that is a failure of the model. \n\nIn general, as the behavioral time series we are analyzing are unlikely to have true underlying linear dynamics, we view the linear + model reduction approach as a way to extract interpretable modes from the model rather than as a way to recover the ground truth. Here, our examples hopefully illustrate this \u2013 even though we know we are modeling nonlinear systems, the linear approximation + model reduction allows us to extract novel insights that are less accessible otherwise. \n\nWe do however agree that the question of where the linear model may fail is interesting: in our view, this is better addressed by fitting both a nonlinear model and a linear model, and to evaluate which parts of the dynamics can be captured by the former but not the latter. \n\n\n> In Figure 3 why does the classification accuracy decrease with time (observation time?)?\n\nIn Figure 3, a distinct classifier is trained at each time point (excluding the dashed line that represents training from the complete time series of posture). Therefore as time advances toward the end of the movements, the classification gradually diminishes, approaching the chance level.\n\n> In Figure 4C and associated main text the authors mention that the reduced model added eigenmodes with larger timescales, while it neglected the small timescale modes of the non-reduced system. While the second part of the previous sentence is expected, I am not sure how should I understand the first one. Can you provide some intuition. Also related to this, when I first looked at Figure 4C I thought that the large time scale values of the reduced and non-reduced model overlap, therefore the light grey ones are not visible. Can you probably make the circles of the reduced system non-opaque or non-filled to make the plot clearer?\n\nThank you for this question. That is a good point, and indeed the behavior of the model reduction has interesting properties that are not all intuitive (which is another reason why we believe our example can be informative to other researchers in the area).\n\nThe reduced model learns modes that differ slightly from the top eigenmodes of the previous system, as it is a different linear system. In the original system, it is possible for multiple modes to combine with one another, leading to effectively longer timescales arising in the system. Since the reduced model looks for a minimal version of the dynamics, it might learn timescales that do not exist in the initial system (and that may be longer). Let us know if this clarifies things. We have, in addition, followed your advice and **updated Figure 3c** with open circles for the reduced model spectrum."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6347/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700524399036,
                "cdate": 1700524399036,
                "tmdate": 1700524399036,
                "mdate": 1700524399036,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "9GbgyC7P8a",
                "forum": "MFCjgEOLJT",
                "replyto": "fZ03jhdEdY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6347/Reviewer_325F"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6347/Reviewer_325F"
                ],
                "content": {
                    "comment": {
                        "value": "I would like to thank the authors for their responses.\nI have read the responses to my comments and to the comments of the other reviewers, and I think our concerns have been mostly addressed. \n\nI appreciate that the authors put in the effort to additionally compare their method to LFADs, and included the additional eigenworm decomposition of C. elegance posture dynamics. This seems to be a more suitable application for their framework compared to the zebrafish dataset, since the experimental setup includes externally delivered perturbations.\n\n>The reduced model learns modes that differ slightly from the top eigenmodes of the previous system, as it is a different linear system. In the original system, it is possible for multiple modes to combine with one another, leading to effectively longer timescales arising in the system. Since the reduced model looks for a minimal version of the dynamics, it might learn timescales that do not exist in the initial system (and that may be longer). Let us know if this clarifies things. We have, in addition, followed your advice and updated Figure 3c with open circles for the reduced model spectrum.\n\nThank you for the clarification. It makes sense that the reduced model might learn slightly different modes compared to the top eigenmodes of the high-dimensional linear system. However, I still have some concerns about the additional dominant modes introduced in the zebrafish experiment's reduction process.\n I would expect from the reduced model to capture the dominant behaviour of the system, thus more or less its spectrum to contain the top eigenvalues of the high-dimensional linear system (akin to the reduced spectrum in the C. elegance experiment [Figure S8]), without adding additional *dominant* ones. \nI would be curious to see what kind of behaviour these dominant modes of the reduced model represent, and whether they would disappear if you would change the order of the reduction. But I won't insist on this. \n\n\n\nMinor:\n- Figure 2C,  legend key for the whole posture time series should be a dashed line."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6347/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700668073537,
                "cdate": 1700668073537,
                "tmdate": 1700685100126,
                "mdate": 1700685100126,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jKoVwuOicI",
                "forum": "MFCjgEOLJT",
                "replyto": "fZ03jhdEdY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6347/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6347/Authors"
                ],
                "content": {
                    "title": {
                        "value": "2nd Response to 325F"
                    },
                    "comment": {
                        "value": "Thank you very much for your positive feedback and for engaging in the rebuttal process, we very much appreciate it!\n\n> Thank you for the clarification. It makes sense that the reduced model might learn slightly different modes compared to the top eigenmodes of the high-dimensional linear system. However, I still have some concerns about the additional dominant modes introduced in the zebrafish experiment's reduction process. I would expect from the reduced model to capture the dominant behaviour of the system, thus more or less its spectrum to contain the top eigenvalues of the high-dimensional linear system (akin to the reduced spectrum in the C. elegance experiment [Figure S8]), without adding additional dominant ones. I would be curious to see what kind of behaviour these dominant modes of the reduced model represent, and whether they would disappear if you would change the order of the reduction. But I won't insist on this.\n\nThis is a very interesting question, thank you for raising this point! \nOur hypothesis for this behavior was that the original linear dynamical system that the model learns is highly non-normal. This means that the connectivity contains hidden feedforward chains which can lead to the dynamics exhibiting timescales that are effectively longer than the slowest timescale in the eigenspectrum (see [`1`] for illustrations of such behaviors in recurrent neural networks). \n\nOur intuition was that the reduced models are less non-normal than the original dynamics matrix, and thus need to rely on slower eigenvalues to be able to generate the same slow timescales as the original system. \nWe have now confirmed this by computing the eigenvalue spectrum at different orders of the reduction (see **[link](https://anonymous.4open.science/r/iclr_rebuttal_figs-F77E/Figure1.png) to Figure 1**), as well as the degree of nonnormality of the reduced system (**see [link](https://anonymous.4open.science/r/iclr_rebuttal_figs-F77E/Figure2.png) to Figure 2**). We computed the nonnormality of $A$ here as,\n$$ 1 - { \\sqrt{ \\sum_{i=1}^{r} \\lambda_{i}^{2}} \\over \\vert\\vert{A^{(r)}}\\vert\\vert^{2}_{2}} $$\nwhich is equivalent to computing the norm of the upper Schur triangle of A, divided by the norm of A (there, a fully non-normal matrix would have a degree of non-normality of 1, and a fully normal matrix would have a degree of 0). \n\nThere indeed appears to be a very clear trend, with the reduced systems getting gradually more and more normal as we reduce the order of the system, and thus relying on slower timescales to approximate the dynamics of the original system. \nWhile there could also be other effects at play, we believe that this in large part explains why those slow eigenvalues arise in the reduced systems. \n\n\n> I have read the responses to my comments and to the comments of the other reviewers, and I think our concerns have been mostly addressed.\n\nWe are glad that you feel we have addressed the main points raised by all the reviewers. There were several very interesting questions raised and we hope you think, as we do, that the new data, together with this additional analysis have significantly improved the paper.\n\n[`1`] Mark S Goldman, 2009. Memory without Feedback in a Neural Network. Neuron."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6347/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700698027858,
                "cdate": 1700698027858,
                "tmdate": 1700698950186,
                "mdate": 1700698950186,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Yyt9I9gCUL",
            "forum": "MFCjgEOLJT",
            "replyto": "MFCjgEOLJT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6347/Reviewer_9AdG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6347/Reviewer_9AdG"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a framework to identify the latent control signals and the underlying dynamics that make up the natural behavior of zebrafish. It utilizes iLQR-VAE for learning the parameters and inferring the control signals. The paper trained recurrent neural network (RNN) models and linear dynamical systems (LDS) to reproduce the postural sequence with sparse control signals. The underlying dynamics of those models are explored and how they relate to the behaviors is studied. The paper further demonstrates the model order reduction on the LDS model and relates the reduced mode to the observed behaviors."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper looks at a new approach for studying naturalistic behaviors, and defines the problem in a clear way.\n\nThe model reduction on the LDS model gives new insights into modeling behavior."
                },
                "weaknesses": {
                    "value": "The paper utilizes iLQR-VAE for learning the parameters and inferring the control signals. It would be helpful if the authors stated clearly in the text what is the difference between the proposed model and the previous model. It seems like the differences are minimal if any, in which case, this is a good application paper, however, it doesn't introduce many novel elements from a modeling perspective. While the model reduction technique for linear models is not usually applied to this field of behavioral modeling, it is a very well-known concept and does not offer novelty from a methodological perspective. There are interesting takeaways from a neuroscience perspective, but these would have to be validated more thoroughly and may be more suitable for a different venue.\n\nThe kinematics of the zebrafish are somewhat simple; however, the naturalistic behaviors of other animals (mice and monkeys, for example) are much more complex. Will the model still be able to capture these dynamics? One real-world dataset may not be able to provide enough insight about the generalizability of the model for this question.\n\nThere is no comparison with other models presented.\n\n\nMinor:\n1. Section 4.1, mismatched figure labels. Figure 1C->Figure 1B; Figure 1D -> Figure 1C\n2. Figure 3 Caption: missing space: \u2018udriving\u2019 -> \u2018u driving\u2019\n3. More explanations on Figure 3D in the main text.\n4. Page 15: \u2018all states withing the LDS\u2019 -> \u2018all states within the LDS\u2019\n5. Page 15: \u2018cannot be reach via observations\u2019 -> \u2018cannot be reached via observations\u2019\n6. Page 16: \u2018Therefore, we can the compute the\u2019 -> \u2018Therefore, we can compute the\u2019"
                },
                "questions": {
                    "value": "Please see above weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6347/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6347/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6347/Reviewer_9AdG"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6347/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698877766239,
            "cdate": 1698877766239,
            "tmdate": 1700771858106,
            "mdate": 1700771858106,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MyyKGnBEPg",
                "forum": "MFCjgEOLJT",
                "replyto": "Yyt9I9gCUL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6347/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6347/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to 9AdG"
                    },
                    "comment": {
                        "value": "> The model reduction on the LDS model gives new insights into modeling behavior.\n\nThank you for noting this, we also think that the model reduction is an interesting framework for behavioral modeling. Our new C. elegans (see **new Figure 4**) results corroborate the fact that it can be a useful way to extract relevant modes of animal behavior. \n\n> It would be helpful if the authors stated clearly in the text what is the difference between the proposed model and the previous model. It seems like the differences are minimal if any, in which case, this is a good application paper, however, it doesn't introduce many novel elements from a modeling perspective.\n\n>  There are interesting takeaways from a neuroscience perspective, but these [...] may be more suitable for a different venue.\n\nThank you for your comment: indeed, our paper focuses on the application of iLQR-VAE to naturalistic animal behavior. We fine-tuned the model parameters to work on the datasets of interest to us, but we indeed did not change the existing method.\n\nWe would indeed describe our work as \u201c*an application paper*\u201d, more than proposing a new methodology. Note however that, **in the ICLR call for papers, \u201c*applications in audio, speech, robotics, neuroscience,  biology, or any other field*\u201d are considered and welcome. Therefore, we do not think that our focus on a neuroscience application should be ground for rejection.** \n\n>  While the model reduction technique for linear models is not usually applied to this field of behavioral modeling, it is a very well-known concept and does not offer novelty from a methodological perspective. \n\nWe agree that the model reduction (MOR) approach is certainly not new. However, we are not aware of other work applying it to behavioral modeling or neuroscience. We thus believe our paper would be very relevant to members of those communities, as a case study using MOR to extract insights from data. \n\nAdditionally, applying model reduction to an input-driven dynamical system whose parameters are learned from data is to the best of our knowledge a novel approach. Asides from iLQR-VAE and LFADS, no methods have focused on learning input-driven dynamics from data.  We believe that the combination of such approaches with MOR opens up very exciting avenues for the field of systems identification, and is a valuable contribution.\n\n> There is no comparison with other models presented.\n\nWe agree that the lack of comparison with other methods was a weakness of the paper. We have now included a comparison with LFADS on the zebrafish dataset. In summary, we found that LFADS (which assumes an autoregressive prior over the inputs), can fit the behavioral time series but does so using continuous inputs which are strongly correlated to the posture (see **new Figure S6**). Moreover, LFADS leads to latent trajectories which are less predictive of the behavioral category (see **updated Figure 2.C**). \n\n> The kinematics of the zebrafish are somewhat simple; however, the naturalistic behaviors of other animals (mice and monkeys, for example) are much more complex. Will the model still be able to capture these dynamics? One real-world dataset may not be able to provide enough insight about the generalizability of the model for this question.\n\nWe agree that providing only the zebrafish as an example application somewhat limited the scope of the paper. We have addressed this by including a new application (see **new Figure 4** and **Figure S8**) to behavioral recordings from crawling C. elegans (worm). While the posture is still low-dimensional, the movement dynamics are more complex than the zebrafish because of their continuous nature, and the fact that the worm is changing its behavior in response to unknown environmental stimuli at variable time intervals.\n\nWe found that the model performed well on this dataset. It reconstructed the behavior accurately, using inputs that strongly correlated to ground truth aversive heat stimuli (**new Figure 4.D**).\n\nAdditionally, after performing the model reduction on the learned dynamical system, the top 3 modes of the reduced system matched the previously identified behavioral modes of the worm [`1`]. We hope that these results will convince you of the general applicability of our method, and the insights it can yield!\n\n> There are interesting takeaways from a neuroscience perspective, but these would have to be validated more thoroughly\n\nAs we detail above, we believe that our new C. elegans results address this concern, both because of the ground truth input recovery, and the fact that the model reduction identifies modes that can be related to prior work.\n\n**Regarding Minor Changes**\nThank you for spotting the few typos and mislabelling of figures. We have made these amendments to the updated manuscript.\n\n[`1`] Costa, A.C., Ahamed, T. and Stephens, G.J., 2019. Adaptive, locally linear models of complex dynamics. Proceedings of the National Academy of Sciences, 116(5), pp.1501-1510."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6347/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700524283046,
                "cdate": 1700524283046,
                "tmdate": 1700618370742,
                "mdate": 1700618370742,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "R93l60qQLv",
            "forum": "MFCjgEOLJT",
            "replyto": "MFCjgEOLJT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6347/Reviewer_AsPq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6347/Reviewer_AsPq"
            ],
            "content": {
                "summary": {
                    "value": "This paper uses an unsupervised method of discovering latent control signals from behavioural sequences, to discover behavioural motifs. The main methodological contribution is using a model reduction technique to gain interpretability insights into the inferred models. Overall I think this is a good paper."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper analyses various behavioural sequences and infers intuitive behavioural motifs.\n\nWhile the core method is not new, the interpretability aspect is, and the insights are interesting.\n\nThe paper is well written, and clearly presented."
                },
                "weaknesses": {
                    "value": "The paper could do with a proper model comparison, i.e. vs moseq.\n\nThe Balanced truncation bit needs to be better explained with some intuition. \n\nEqn 5 should have $ \\tilde{W}_o = \\tilde{W}_c = \\dots$\n\nFig 1 A: what does blue and orange correspond to? Different sequences?\n\nSome of the Figures seem to be mis-referenced, e.g., \u201cAs shown in Figure 3B, the MGU could reconstruct bouts using a sparser control compared to the LDS. \"\n\nAll the figures could do with more explanations in their captions."
                },
                "questions": {
                    "value": "See weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6347/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6347/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6347/Reviewer_AsPq"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6347/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699246434542,
            "cdate": 1699246434542,
            "tmdate": 1699636699311,
            "mdate": 1699636699311,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bX6ILDWNe6",
                "forum": "MFCjgEOLJT",
                "replyto": "R93l60qQLv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6347/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6347/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to AsPq"
                    },
                    "comment": {
                        "value": "> This paper analyses various behavioral sequences and infers intuitive behavioral motifs. \n\n> While the core method is not new, the interpretability aspect is, and the insights are interesting. \n\n> The paper is well-written, and clearly presented.\n\nThank you for your positive feedback! We also think the insights that can be obtained by applying model reduction are interesting. We would like to point you to the C. elegans results that we have added in the updated version of the paper (see **new Figure 4 and S8**), that provide another example of the insights that model reduction applied to a learned dynamical system can yield. Indeed, we find that, in this more complex C.elegans dataset, our method recovers most important modes of the system that are consistent with previously identified behavioural patterns [`1`] \u2013 something we were very excited about.\n\n>  The paper could do with a proper model comparison, i.e. vs moseq.\n\nThank you for your comment. We agree that the original version of the paper was lacking a comparison with other methods. We have now added a comparison to LFADS (a method similar to iLQR-VAE, but with a different recognition model, and which typically uses an autoregressive input prior).  We found that LFADS can reconstruct the behavior, but using inputs that are highly correlated with the posture (see **new Figure S.6**). Additionally, it gives rise to latent trajectories that are a lot less predictive of the behavior than the MGU model (see **updated Figure 2.C**). \n\nNote that Moseq is indeed a widely used method in the field of behavioral modeling, but its principal use is for segmenting movements into motifs. Thus, since the zebrafish behavior is by nature already segmented in bouts, we did not think that MoSEQ would yield additional insights. However, if you had a specific comparison in mind that you would like us to do we would be happy to hear that!\n\n> The Balanced truncation bit needs to be better explained with some intuition.\n\nThank you for that suggestion \u2013 we have tried our best to make the balanced truncation as intuitive as possible (see for instance the intuition given regarding the observability or controllability Gramians, or the intuition for the Hankel singular values). \n\nWe have also moved the pendulum example to the Appendix, and included more details on how it illustrates an example case of the balanced truncation, hopefully providing further intuition for the behavior of the model.\n\nHowever, if you have any suggestions on how to further improve the clarity of this section (e.g. specific places that you find confusing) we would be happy to further amend the paper!\n\n> Fig 1 A: what does blue and orange correspond to? Different sequences?\n\nThat is a good point \u2013 blue and orange correspond to two different input / output channels of the pendulum. We have clarified this in the caption. \n\n> typos and captions and misreferences\n\nThank you very much for spotting those, we have amended the manuscript to fix them! \n\n[`1`] Costa, A.C., Ahamed, T. and Stephens, G.J., 2019. Adaptive, locally linear models of complex dynamics. Proceedings of the National Academy of Sciences, 116(5), pp.1501-1510"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6347/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700524217144,
                "cdate": 1700524217144,
                "tmdate": 1700524217144,
                "mdate": 1700524217144,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dvqdpST2Q2",
                "forum": "MFCjgEOLJT",
                "replyto": "bX6ILDWNe6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6347/Reviewer_AsPq"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6347/Reviewer_AsPq"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "Thanks for the response and the additional result. I still like the paper, but will stick with my original score."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6347/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700700590898,
                "cdate": 1700700590898,
                "tmdate": 1700700590898,
                "mdate": 1700700590898,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]