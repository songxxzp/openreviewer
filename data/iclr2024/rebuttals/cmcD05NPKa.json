[
    {
        "title": "Learning the greatest common divisor: explaining transformer predictions"
    },
    {
        "review": {
            "id": "ogEh4m0AIM",
            "forum": "cmcD05NPKa",
            "replyto": "cmcD05NPKa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission386/Reviewer_zrzn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission386/Reviewer_zrzn"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents an exploration of using small transformers to calculate the greatest common divisor (GCD) of two positive integers. A notable aspect is that the predictions made by these models are explainable. The authors focus on how models learn a list of divisors and predict the largest element that divides both inputs. They also investigate the impact of different training distributions on model performance, including uniform operands, log-uniform operands, and balanced distributions of GCDs. They also investigate with different inputs representations in different bases."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Studying learning GCD through transformers is a novel problem.\n- This work raises some observations about the deterministic behavior of the model in learning GCD, and the simple shortcut algorithm it learns.\n- A lot of experiments/examples supporting the claims are provided."
                },
                "weaknesses": {
                    "value": "My main concern is about the significance of studying computing GCD through transformers. The observations are all limited to this particular task and it is not clear how broadly applicable they are. Or, if there is anything to learn from these observations and apply it elsewhere. \n\nMoreover, the observations are also not robust. The authors point out that the algorithm learned is deterministic but then this observations breaks down when the input distribution is changed. This non-robust behavior of the observations weaken them a lot in my opinion. For example, explainability breaks down with the change in input distribution."
                },
                "questions": {
                    "value": "- Did the authors try to experiment with Chain-of-Thought and see if providing the explanation helps with the accuracy?\n- Can the authors please explain why does the model only learn divisors of the base B? And, if there is a way to promote learning of other divisors?\n- The authors mention that some non-divisible small primes are learned very late in the training stage. Did the authors see that if they continue training further, eventually other primes will be learned?\n- The authors mention that explainability of the model breaks down with the change in the input distribution. Do the authors have any thoughts on why this is the case?\n- Do few shot prompts improve the performance?\n- The authors mention they observe grokking phenomenon. Can the authors please provide more related work on grokking and transformers. And, if this is the first work observing grokking for transformers."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission386/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698726038673,
            "cdate": 1698726038673,
            "tmdate": 1699635965839,
            "mdate": 1699635965839,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qC2eFA02o9",
                "forum": "cmcD05NPKa",
                "replyto": "ogEh4m0AIM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission386/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission386/Authors"
                ],
                "content": {
                    "title": {
                        "value": "reply to reviewer zrzn"
                    },
                    "comment": {
                        "value": "Thank you for your comments, questions and suggestions. We will integrate our replies in the revised version (in a few days).\n\n*My main concern is about the significance of studying computing GCD through transformers.*\n\nThe broader context of our research can be summarized as follows :\n\n* This is a first step towards using mathematical tasks to understand and explain deep learning models, by investigating their predictions on selected tasks. This extends current approaches on explainability which mostly focus on mechanical interpretability - i.e. looking at the model weights and internal calculations. In this paper, we demonstrate the feasibility of such an approach on a non-trivial mathematical task. By leveraging our theoretical knowledge of the underlying problem, we can design train and test sets, and get a clear picture of how the model learns to solve the problem. We believe that running similar analyses on a larger set of mathematical problems would provide a lot of insight about the inner workings of deep learning models (not just transformers). \n* While tasks of pure mathematics are not the main focus of LLM practitioners, they play a central role for the development of foundational models for science: large language models pre-trained on mathematical equations, instead of natural language. Our results show how transformers can be trained to perform exact calculations involving integer divisibility, a central task in integer arithmetic and number theory.\n* Our results on training distributions, i.e. the fact that some distributions allow for faster learning and better out-of-distribution performance, may apply to other arithmetic tasks. In particular, log-uniform operands and outcomes could be used when fine tuning LLM, or training foundational models for physics.\n\n*Moreover, the observations are also not robust. The authors point out that the algorithm learned is deterministic but then this observations breaks down when the input distribution is changed.*\n\nOur observations on determinism and explainability, and in particular the three rules for explainability G1, G2, G3 (section 4), hold for uniform and log-uniform operands, and natural (inverse square) and log-uniform outcomes, together with the additional distributions discussed in appendix D1. They are also valid for other deep learning architectures (see our reply to reviewer 21KR). We believe this makes a strong case for their robustness. \n\nIn fact, explainability only breaks (partially) when training on uniformly distributed GCD (section 6). The G rules, then get replaced by the weaker U rules, which break again (but temporarily) as the model learns the very last GCD (appendix D3, and figure 15). We believe this limiting case actually sheds light on what the model is learning. The non-uniform distribution of outcomes is an inductive bias about the problem that the model learns to exploit (see also our reply to your question below).\n\n*Can the authors please explain why does the model only learn divisors of the base B? And, if there is a way to promote learning of other divisors?*\n\nThe divisors of B are learned because divisibility by these numbers can be checked by looking at the last digits of the integer representation in base B. For instance, in base 10, a number is divisible by 2 iff its representation ends with a 0, 2, 4, 6  or 8. It is divisible by 5 iff it ends in 5 or 0, and by 20 iff it ends in 00, 20, 40, 60 or 80. This means that the model can check whether both its operands are divisible by 20, by looking at their 2 last digits (the attention mechanism allows the transformer to point at specific digits in the sequences) and comparing them to a set of memorized values (the FFN layers in the transformer allow for such memorization). For other bases, such simple rules do not exist: all digits in the number representation must be taken into account when checking for divisibility. We believe this explains our results from section 3.\n\nIn section 4, we observe that other divisors: small primes and their multiples, can be learned (i.e. grokked) when the model is trained long enough. How this phenomenon happens is not clear, but it seems to happen for all large bases, and to be accelerated by training on log-uniform distributions of operands and outcomes (section 5). In our best results, all products of primes up to 53 are learned. Observations from appendix D1 suggest that these results can be improved. Our experiments in section 6 indicate that an imbalance distribution of outcomes is required for this phenomenon to take place."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission386/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700406554724,
                "cdate": 1700406554724,
                "tmdate": 1700406554724,
                "mdate": 1700406554724,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4QB34Ah2z4",
                "forum": "cmcD05NPKa",
                "replyto": "ogEh4m0AIM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission386/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission386/Authors"
                ],
                "content": {
                    "title": {
                        "value": "reply to reviewer zrzn (2/2)"
                    },
                    "comment": {
                        "value": "*The authors mention that some non-divisible small primes are learned very late in the training stage. Did the authors see that if they continue training further, eventually other primes will be learned?*\n\nYes. Our initial experiments with grokking, for B=1000, shows that whereas all divisors of B were learned after 84 epochs, it took 220 epochs to learn 3 and its multiples. The rightmost column in Table 4 shows, for models trained up to 1300 epochs, the number of epochs needed to learn each small divisor. For instance, for B=2023, 3 is learned after 101 epochs, 2 after 205 and 4 after 599. For B=2744, 3 is learned after 543 epochs, and 5 after 1315. We believe that longer training would help (but 1300 epochs takes over 2 weeks on the machines we used). This is suggested by our experiments with log-uniform operands, which accelerate grokking, and allow to learn all primes up to 23 with a \u201cnatural\u201d distribution of outcomes, and 53 with a log-uniform distribution of outcomes.\n\n*The authors mention that explainability of the model breaks down with the change in the input distribution. Do the authors have any thoughts on why this is the case?*\n\nExplainability does not break down when the input distribution, i.e. the distribution of operands, changes (in section 5). The three rules G1, G2 and G3 from section 4 still hold for models trained on log-uniform operands, and even log-uniform outcomes. The only difference, mentioned in the last paragraph of section 5 (bottom of page 6), is that the transitions between different phases \u2013 the moment when the model is learning a new divisor \u2013  now span several epochs, during which model predictions are split between the old and the new value. Out of these transient phases, model predictions remain deterministic and explainable. \n\nExplainability (partly) breaks when models are trained on uniform outcomes. This is described in section 6. Models trained on uniform outcomes still learn to cluster their input pairs into classes which correspond to products of divisors of the base. All elements in the class are usually predicted the same, and new classes of multiples of new primes are learned as training proceeds (see the correct GCD in figure 3). Yet, the model prediction for each class varies from epoch to epoch (Table 8): multiples of 4 are predicted sometimes as 4, sometimes as 44, but at a given time in training, all multiples are predicted the same. \n\nWe believe this is an effect of the uniform distribution of outcomes: in previous experiments, the model predicted the most common instance of each class, which turned to be its smallest member. As a result, all multiples of 4 would be predicted as 4, and 1 would be the default prediction for all \u201cnon predictable\u201d GCD. With uniform outcomes, the most common instance randomly varies over time, and this accounts for the fluctuations observed in table 8. In other words, the distribution of outcomes  in the training set provides the model with an inductive bias about divisibility, which disappears when outcomes are uniformly sampled.  \n\n*Did the authors try to experiment with Chain-of-Thought and see if providing the explanation helps with the accuracy?*\n\nChain-of-thought does not apply to this setting, as it requires a decoder-only architecture, and we use encoder-decoder. Besides, it would demand that we know in advance the algorithm that the model is going to use. In the case of GCD, providing the model with steps from the \u201chuman algorithm\u201d (i.e. Euclid\u2019s algorithm) would certainly not help the model learn the sieving technique it is implementing. \n\n*The authors mention they observe grokking phenomenon. Can the authors please provide more related work on grokking and transformers. And, if this is the first work observing grokking for transformers.*\n\nThe original paper on grokking (Power et al. 2022, arxiv 2201.02177 referenced in the paper), observed the phenomenon in a transformer learning modular arithmetic \u2013 i.e. arithmetic over a finite set. The follow-up papers by Liu et al. (https://arxiv.org/abs/2205.10343) and Gromov (https://arxiv.org/abs/2301.02679) mostly focus on fully connected networks (MLP). Nanda et al. (https://arxiv.org/abs/2301.05217) study grokking in one-layer transformers. All these works focus on arithmetic over finite sets: the model is tasked to learn, or complete, a finite \u201caddition table\u201d. To our knowledge, our work is the first observation of grokking on a different arithmetic task."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission386/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700406584294,
                "cdate": 1700406584294,
                "tmdate": 1700406779191,
                "mdate": 1700406779191,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "UqgkYSVbsJ",
            "forum": "cmcD05NPKa",
            "replyto": "cmcD05NPKa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission386/Reviewer_t8xf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission386/Reviewer_t8xf"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies Transformers capabilities on learning the task of computing greatest common divisor (GCD) for two numbers. First the two integers of input and the integer of the output are encoded in base $B$. Then, the model is trained with 300,000 new samples at each epoch. The authors have tried different distributions for the input/operands (uniform and log-uniform) and also the output. They have observed that in the majority of their experiments, model's output is deterministic, meaning that if $\\gcd(a,b)=k$, the output of the model is fixed depending on $k$. Further, for $k$'s that are a divisor of $B$ or small, the output is usually correct. Moreover, they show that by having a log-uniform distribution on the operands, the performance of the model is increased."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The particular attention to the distribution of the operands is important, and it's shown that by emphasizing on small numbers, the performance of the model can be increased (resembling curriculum learning). \n- Similarly, authors have considered the distribution of the output showing that large GCDs may be slow/hard to learn as they are rare. \n- Experiments are rather extensive in several axes (e.g., number of bases, size of the models, batch-size, ...)."
                },
                "weaknesses": {
                    "value": "- The claim that Transformer predictions are fully explainable does not seem to be accurate once log-uniform operands are used. \n- Although, the paper usually interprets the results of experiments, it does not put forward any explanation for such results (for example, defining and justifying the shortcuts Transformers may take). \n- Some of the report rules might be consequences of other factors (and they may not be robust as a result). For example, the smaller primes are learned (or grokked) faster as they are more common in the output or really easier to learn? Although these problems can be clarified.  \nSee the questions below for more details."
                },
                "questions": {
                    "value": "- Q1. It's said that composite bases allow one to check for divisibility by seeing the rightmost digits. This is true, for example for powers of the base, one needs to count the number of zeros. However, the picture seems to be more complex for divisors of the base. For example, consider $B=210$. Any number ($<10^6$), can be expressed using 3 digits in this base. Now for checking divisibility by 8, one has to check the pattern of all 3 digits (and it's not as simple as being 0). On the other hand, checking divisibility for any other number also requires checking the 3 digits together. Is there anything that is making checking for 8 simpler? (Similarly, assume that $B=350$, could we expect that checking for $3, 6$ would be easier than $8$?)\n- Q2. At the beginning of the paper there is the idea that divisors of $B$ are easily learned. Is this also the case when $B$ is for example, the product of two large primes, e.g., $B=2021=43\\times 47$? Is there a possiblility that smaller primes are learned faster than $43, 47, 43^2, \\ldots$ in this case?\n- Q3. Also given the list intuition, why 420 is performing better than 210 in Table 2?\n- Q4. Further, the list intuition does not seem to be applicable anymore in Table 6 (E.g., $2401=7^4$ is having the best performance). What could be the reason for this? \n\n\n- Q5. In claim U2, one can see that 21 is wrongly classified into $C_4$. As a result I wonder, for other bases that are product of larger primes, e.g., again, $2021=43\\times 47$, can this phenomenon still be observe? Or is having small primes such as 2 and 5 playing an important role here? \n- Q6. In the line before table 5, we see that for $B=30$, $B-1, B+1$ are learned faster than other primes. I guess this might be due to the fact that $(x_3x_2x_1)_B \\pmod{B-1} = x_3 \\times B^2 + x_2 \\times B + x_1 \\pmod{B-1} =  x_3 + x_2  + x_1 \\pmod{B-1}$ which may be easier to learn due to symmetry between $x_3, x_2, x_1$. Similar explanations can be given for any divisor of $B-1$ and $B+1$. If that's the case, this factor should also be considered when we see some primes are grokked. \n\n## Minor questions/remarks\n- Q7. What stopping criterion has been used? For example in Figure 4, the loss appears to be still decreasing. Maybe the combination of continued training and weight decay results in improved generalization as in grokking? \n- Q8. The addition and multiplication of rationals mentioned in the intro and studied in the appendix require the output to be simplified. So I wonder, is there any particular difference or additional complexity comparing to the simplification task itself?\n- Q9. What is the positional embedding used for the model?\n- R1. My understanding is that the samples at each batch are freshly generated. I think it would be beneficial if this is communicated more clearly and earlier to the reader. \n- R2. Table 5 is a bit misleading with the current format. For example, when we see than 9 is learned for $B=2017$ we have to guess that 3 was already learned. (Similar issue can be observed for other bases.) \n- R3. For Section 5 experiments in page 6, it would helpful if training loss plot is provided."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission386/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission386/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission386/Reviewer_t8xf"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission386/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698768475325,
            "cdate": 1698768475325,
            "tmdate": 1699635965745,
            "mdate": 1699635965745,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CaOk5dJTFT",
                "forum": "cmcD05NPKa",
                "replyto": "UqgkYSVbsJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission386/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission386/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to reviewer t8xf"
                    },
                    "comment": {
                        "value": "Thank you for your comments, questions and suggestions. We will integrate our replies in the revised version (in a few days).\n\n*The claim that Transformer predictions are fully explainable does not seem to be accurate once log-uniform operands are used.*\n\nThe three rules for explainability (G1, G2, G3) are hold over a large set of training distributions : uniform and log-uniform operands, natural and log-uniform outcomes (together with the additional distributions from appendix D1). We will try to clarify the last sentence in the abstract.\n\nIn fact, explainability only breaks (partially) when the training data uniformly samples GCD (section 6). The G rules, then get replaced by the weaker U rules, which break again (but temporarily) as the model learns the very last GCD (appendix D3, and figure 15). We see these last cases are limiting conditions. They suggest that an unbalanced distribution of outcomes is needed to explainability to happen.\n\n*Although, the paper usually interprets the results of experiments, it does not put forward any explanation for such results*\n\nA number of explanations are provided, but they are scattered through the paper. We will concentrate them in one subsection of the discussion. Summarizing: \n\nWe can explain the shortcuts we believe our models use to test divisibility by products of divisors of the base. When the base is a prime number, the model counts the rightmost zeroes in both of its operands, takes the minimum $k$, and predicts $B^k$. When the base is composite (or a power of a prime), the model exploits the following property: if a factor $f$ divides $B^n$, ie $B^n = kf$, an integer $m$ is divisible by $f$ if and only if its $n$ last digits in base $B$ take one of the $k$ values : $0, f, 2f, \u2026 (k-1)f$. For instance, in base 10, a number is divisible by 20 iff it ends in 0, 20, 40, 60 or 80. We believe the model memorizes those lists when k and n are small. For small bases ($B<500$), models learn all divisors of $B^2$ this way. \n\nWe also understand how the model leverages divisibility rules to predict GCD. This exploits the imbalance in the GCD distribution (i.e. the fact that, in the training set, small GCD are more common than large GCD). As training begins, the model predicts 1 (the most common value) for all input pairs $(a,b)$. When divisibility by $k$ is learned (via the shortcuts described above, or grokking), the model learns to distinguish all pairs of the form $(ka, kb)$, i.e. such that their GCD is a multiple of $k$. The model therefore predicts $k$ for all pairs of the form $(ka,kb)$, and $1$ for the others. Once a second divisor, $l$, is learned, both input classes (i.e. $(ka,kb)$ input predicted as $k$, and others, predicted as $1$), are split into four classes, predicted as $1$, $k$, $l$, and $kl$ (except if $l=k^2$, in which case we end up with 3 classes, predicted as $1$, $k$ and $k^2$). Every new prime divisor $p$, learned by the model, causes each previous class, predicted as $f$, to split into two new classes, predicted as $f$ and $pf$. This accounts for the steps observed in the training curves. \n\nFinally, we can explain how this process leads to a correct algorithm for predicting GCD, when outcomes are not uniformly distributed. Once the divisors of the base are learned, small primes are grokked in order (so far, we do not have an explanation for grokking), and new classes are created, that correspond to the products of the prime with previously learned factors. These classes are predicted as $pf$ ($p$ the prime, $f$ the previous factor), and contain all pairs $(pfa pfb)$, divisible by $pf$. Pairs with GCD $pf$ are now correctly predicted, and multiples of $pf$ will be learned once all their prime power divisors are learned or grokked.\n\nThe only part in the process that cannot be explained is the grokking process. We leave it to future work.\nWe will add these explanations to the discussion section.\n\n*the smaller primes are learned (or grokked) faster as they are more common in the output or really easier to learn?*\n\nThe experiments from section 6 shed light on this. Non-divisors are grokked in order, and each class is predicted as its smallest element (i.e. its largest common divisor) so long the distribution of outcomes in the training set in imbalanced.  This suggests that small primes are learned first, because small GCD are more common in the training sample. The distribution of outcomes provides the model with the inductive bias about what a \u201csmall number\u201d is.  \n\n*Q2. For B=2021=43\u00d747, is there a possibility that smaller primes are learned faster than 43,47,432,\u2026?*\n\nFor B=2021, the two divisors of the base, 43 and 47, are learned long before small primes are grokked. Over three different initializations of the model, 43 and 47 always get learned around epoch 20 and 22. 2 is learned at epochs 261, 442 and 125, and 3 at epochs 450, 182 and 226. Even with log-uniform outcomes, grokking always sets in after the divisors of the base are learned."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission386/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700405321971,
                "cdate": 1700405321971,
                "tmdate": 1700406375804,
                "mdate": 1700406375804,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "PRdiYIuI4b",
            "forum": "cmcD05NPKa",
            "replyto": "cmcD05NPKa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission386/Reviewer_QHKu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission386/Reviewer_QHKu"
            ],
            "content": {
                "summary": {
                    "value": "The paper focuses on training Transformers from scratch to predict the GCD of two numbers and explaining the algorithm used by the trained model.  It is observed that for almost all pairs of numbers for which the GCD is k, the model outputs a unique value f(k).  The model learns a set of numbers D, and for an input pair with gcd k, f(k) is the largest number in D that divides k. When numbers are represented in base B, set D contains all the products of primes dividing B. For large bases B, if training continues for very long, set D starts to include other prime numbers as well, usually learned in a monotonically increasing fashion. For example, in base 1000, set D would have numbers 1, 2, 4, 5, 10, 16, 20 and so on. If the training is continued for long, this set also starts to include 3 and its multiples with the numbers already in D. If the GCD k is one of the elements of this set, then the model output will be correct, otherwise, the model outputs the largest element of this set that divides k. The paper also investigates the role of training distribution."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "I really enjoyed reading this paper. In most cases, the algorithms learned by Transformers do not seem interpretable. I was surprised by how structured the encoded algorithm is in the case of GCD computation. This structure is very well explored in the paper through cleverly designed experiments and the intuition behind the results is also explained well."
                },
                "weaknesses": {
                    "value": "I don't see any substantial weakness. Perhaps one could say that the implications of these results for large language models are unclear. However,  we barely know anything about the internal workings of Transformer models (the architecture behind LLMs) and this paper makes a small (and interesting!) step in enhancing our understanding."
                },
                "questions": {
                    "value": "Minor suggestions/clarifications:\n\n1. On page 2, the term epochs is used for training, which suggested to me that there is a fixed training set over which the model is trained for multiple epochs. But in the last paragraph of the paper, it is mentioned that new training data is generated on the fly. Perhaps this should be clarified on page 2.\n\n2. In the abstract and introduction of the paper, there are lines of the form ``Models trained from uniform operands only learn a handful of GCD\n(up to 38 out of 100)''. This is confusing if the reader does not know that all numbers with the same GCD are mapped to the same output by the model. Without this information, it can be the case that two pairs of numbers have the same GCD but the model output is correct for only one of them. In that case, it is unclear what would it mean for the model to learn a handful of GCDs. This should be made clear in the abstract and intro."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission386/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699234359451,
            "cdate": 1699234359451,
            "tmdate": 1699635965663,
            "mdate": 1699635965663,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wGC67p04zo",
                "forum": "cmcD05NPKa",
                "replyto": "PRdiYIuI4b",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission386/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission386/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to reviewer QHKu"
                    },
                    "comment": {
                        "value": "Thanks you for your comments, and suggestions. We will integrate them in the revised version (updated in a few days).\n\n*Perhaps one could say that the implications of these results for large language models are unclear.*\n\nWe agree that immediate applications to LLM are not obvious. We believe that the log-uniform sampling of operands and outcomes could be of help when fine tuning LLM on mathematical tasks (in fact, this might already be the case, since numbers scraped from the Internet tend to follow a Zipf/Benford law).\n\nA more likely application of this research is for Foundational models for Science, large language models pre-trained on a large corpus of scientific facts (equations, calculations, scientific data), to be used in Mathematics, Physics or Chemistry. These models need to perform correct integer calculations, and our results show how they can be learned.\n \nFinally, our main research direction is model explainability. Most current approaches focus on mechanical interpretability (i.e. understanding model weights). We propose a different direction, which focuses on elucidating model predictions for specific tasks. We believe mathematical problems are a good playground for such studies, because we can leverage our theoretical understanding of the underlying problems. Extending our approach to a larger set of mathematical problems might provide interesting insight about the algorithms learned by transformers (and other deep learning architectures)."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission386/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700404101257,
                "cdate": 1700404101257,
                "tmdate": 1700404101257,
                "mdate": 1700404101257,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hMmkAzccar",
                "forum": "cmcD05NPKa",
                "replyto": "wGC67p04zo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission386/Reviewer_QHKu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission386/Reviewer_QHKu"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for further clarifying the main contribution of the paper. I will take this into account while engaging with other reviewers and deciding the final score for the paper."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission386/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700585504522,
                "cdate": 1700585504522,
                "tmdate": 1700585504522,
                "mdate": 1700585504522,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "v3Ef84iDDW",
            "forum": "cmcD05NPKa",
            "replyto": "cmcD05NPKa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission386/Reviewer_21KR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission386/Reviewer_21KR"
            ],
            "content": {
                "summary": {
                    "value": "This paper trains small transformer models (4 layers) to compute the GCD of a pair of numbers. This is framed as a sequence prediction task. The input is a pair of numbers (a, b) encoded as a sequence of numbers in a base B. The model predicts a sequence of numbers (in base B) which collectively represent the GCD of (a, b). Performance is measured by 2 metrics - accuracy in prediction GCD and number of integers between 1 to 100 which are a GCD prediction. The second metric is required according to the paper because for any given pair (a, b), the GCD is likely to be small and they also turn out to be harder to predict correctly. The authors perform a bunch of experiments in a variety of configurations which will be described below.\n\nFor the first set of experiments, the training dataset (pairs of numbers) is sampled uniformly between 1 to a million. Models trained on these datasets show pretty variable accuracy but the main trend seems to be that using larger bases of composite numbers to encode pairs work well. Models also exhibit the property of being able to predict GCDs equal to the (prime) divisor of their bases (and their small powers) pretty well. Other small prime numbers which are not divisors of the base are \u2018grokked\u2019 much later during training.\n\nNext, the authors decide to oversample pairs of small numbers to create a lop-sided training distribution (called log-uniform in the paper). Models trained on this kind of distribution show dramatically improved and consistent performance regardless choice of base.\nFinally, the authors modify the training distribution to also be uniform over the predicted GCD. This maintains good accuracy of these models but degrades the consistency with which model predictions could be explained.\n\nTo analyze the model predictions, the authors introduce \u2018rules\u2019 which they obtain after looking at the results after each stage of the above experiments. These rule help us explain model predictions in a uniform fashion."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The main idea is pretty straightforward and most of the concepts in the paper are well explained (see concerns discussed below).\n2. To my knowledge, computing and analyzing GCD prediction via transformers has not been done before. \n3. Very comprehensive suite of experiments and exhaustive analysis. I appreciate the authors performing such a wide range of experiments. I also really like the nice link between theoretical accuracy and practical accuracy provided in Appendix C.\n4. Claims made by the authors are clearly backed up the experiments in the paper (see some minor concerns below)."
                },
                "weaknesses": {
                    "value": "My main concern about this work lies with the significance of the results and observations made. The authors train a transformer to predict the GCD which seems to work fairly well with some tricks in picking the right dataset. However, I\u2019m not convinced about why this result would be of significant interest to the wider community and what it says about the representational power of transformer themselves beyond the narrow context of learning GCDs. Like I mentioned earlier, the experiments are thorough and the analysis is extensive but I\u2019m struggling to understand the value of this beyond this specific task. \n\nThe authors present \u20183 rules\u2019 which supposedly explain model predictions and while they seem technically correct, they do seem pretty specific to the task and don\u2019t seem to point to something specific about transformers themselves. For example, do we get these same rules if we swap the transformer architecture to something else? Is there something special about the architecture?\n\nHaving said all of that, I appreciate a good, rigorous experimental paper and I\u2019m open to being convinced by the authors and reading other reviewers comments about the value of this work.\n\nOther:\n1. The authors hypothesize on Page 3 \u201cFor prime bases, such as B = 2, the three rules suggest that the model learns to predicts GCD by counting the rightmost zeros in its inputs\u201d. Something like this seems like it should be fairly easy to confirm by visualizing the attention weights. I wonder if the authors have tried this.\n2. The authors mention that their model is \u2018fully explainable\u2019 (see abstract). I was expecting the model to output some kind of explanation for its prediction (say via attention) but what the authors actually meant was that the model predictions can be $\\textit{explained by}$ a human  because they follow certain rules. These rules keep on changing depending on the training configuration and can only be inferred after a thorough analysis of the results so I\u2019m not sure if we can call it explainability at least in the traditional sense used in XAI. However, the authors do say in the final section \u201cOur approach to explainability differs from most works on the subject. Instead of looking at model\nparameters, we engineer experiments that reveal the algorithms that the model is implementing\u201d. I think a statement of this sort at the start of the paper would help in clarifying the confusion. Regardless, I\u2019m not sure if I would call a model showing some consistent trends in the output as \u2018explainable\u2019.\n\nMinor:\n1. On page 2, when introducing the procedure to generate the stratified test set, the symbol \u2018M\u2019 is introduced without any explanation as follows \u201cSample a and b, uniformly between 1 and M/k , such\u201d. I\u2019m assuming M is the upper limit on the numbers a and b. This symbol is used throughout the paper and explained nowhere so it\u2019s confusing.\n2. The authors use two metrics to evaluate their models - accuracy on a test set and number of correctly predicted GCD below 100. At several points in the paper, terms like \u201c50 GCD\u201d or \u201c50 correct GCD\u201d are used. I now understand that they mean that the model predicts 50 GCDs out of a 100 between 1 to 100 correctly but it was definitely confusing to me initially. I think clarifying these terms at the start can be useful.\n3. Typo - Appendix C, first line, \u201cfor models from section 3 the follow the three rules\u201d should be \u201cfor models from section 3 that follow the three rules\u201d"
                },
                "questions": {
                    "value": "How is the choice of the base made? Are they also sampled from a distribution?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission386/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699603575910,
            "cdate": 1699603575910,
            "tmdate": 1699635965591,
            "mdate": 1699635965591,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3cyP8R0BWO",
                "forum": "cmcD05NPKa",
                "replyto": "v3Ef84iDDW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission386/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission386/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to reviewer 21KR"
                    },
                    "comment": {
                        "value": "Thank you for your comments, questions and suggestions. We will integrate our replies in the revised version (in a few days).\n\n*My main concern about this work lies with the significance of the results and observations made.*\n\nThe broader context of our research can be summarized as follows:\n\n* This is a first step towards using mathematical tasks to understand deep learning models, by investigating their predictions on selected tasks. We see this as a new approach to explainability, and demonstrate its feasibility on a non-trivial mathematical task. \n* While mathematical tasks are not the main focus of LLM practitioners, they play a central role for the development of Foundational Models for Science: large language models pre-trained on mathematical equations. Our results show how transformers can be trained to perform exact calculations involving integer divisibility, a central task in integer arithmetic and number theory.\n* Our results on training distributions, i.e. the fact that some distributions allow for faster learning and better out-of-distribution performance, may apply to other arithmetic tasks. In particular, log-uniform operands and outcomes could be used when fine tuning LLM, or training foundational models for physics.\n\n\n*Are the 3 rules task specific? Do they apply to other architectures?*\n\nWe agree that the 3 rules are specific to tasks involving integer divisibility. Still, they provide insight about what our models can learn. In section 3, the model only learns divisors of the base, that can be tested by looking at a small number of digits. Divisibility by 3 or 9 (in base 10), which can be tested by summing all digits in the representation, seem harder to learn. For a transformer, we believe this suggests that the attention mechanism helps learn properties that concentrate on a few tokens in the input sequence, but struggle with  non-local properties, such as the sum of all digits in an operand.\n\nThank you for suggesting additional experiments on architectures! We experimented with LSTM and GRU, with 1024 and 2048 dimensions, and 4 layers, for 10 different bases (from 10 to 2401). We will include our findings in the appendix of the revised paper, but initial results suggest that our observations extend to these recurrent networks.\n \nWhen training on uniform operands for 260 epochs, we observe that: \n* for B=420, 34 GCD below 100 are learned, products of {1,2,4,8,16},{1,3,9}, {1,5} and {1,7} (divisors of the base)\n* for B=210, 31 GCD are learned: products of {1,2,4,8}, {1,3,9}, {1,5}, {1,7}\n* for larger bases, grokking seems to happen as well: for B=2021, 2 and 3 are grokked, for B=2023 and 2025, 2 is grokked, for B=2401, 2 and 4 are grokked.\nWhen training on log-uniform operands, 37 GCD are learned after 150 epochs, with uniform outcomes 57 GCD under 100 are learned.\n\nOverall, this suggests that our results extend beyond the transformer architecture. \n\n*Whether the model counts rightmost zeroes should be fairly easy to confirm by visualizing the attention weights. I wonder if the authors have tried this.*\n\nWe did, and observed that some attention heads do focus on the low digits of the operands. We hesitate to jump to conclusions because: \n* input sequences are short, and different heads attend to almost all tokens in the sequence, \n* this pattern was observed in tasks that do not involve divisibility,\n* the same phenomenon is observed in architectures without attention (see above).\n\n*Regardless, I\u2019m not sure if I would call a model showing some consistent trends in the output as \u2018explainable\u2019.*\n\nWe believe ours is a valid alternative to mechanical interpretability. Even though the low level specifics of the model are not fully understood, the 3 rules account for more than 99.5% of model predictions. We believe this qualifies as a valid explanation. Such a situation is common in physical sciences. Many macroscopic phenomena, the relation between volume, pressure and temperature in a gas, or the transformation of an egg into a fully developed individual, can be explained, even though the low level processes, the trajectories of particles in the gas or the biochemical processes of embryogenesis, are not completely elucidated. We see our approach as a new direction in explainability.\n\n*How is the choice of the base made? Are they also sampled from a distribution?*\n\nIn section 3, we selected small bases (2,3,4,5,6,7), bases often used in practice (10, 100, 1000), bases with many small prime divisors (30, 60, 210, 420) and primes bases close to these values (31, 211, 997). \n\nFor section 4, we selected bases depending on their prime decomposition. In particular, we focused on bases not divisible by some small primes, in order to observe grokking. The first column of table 4 provides an explanation of sorts.\n\nIn section 5 and 6, we reused the bases from the previous sections, for the sake of comparability."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission386/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700403855246,
                "cdate": 1700403855246,
                "tmdate": 1700403855246,
                "mdate": 1700403855246,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LQLuxObMiO",
                "forum": "cmcD05NPKa",
                "replyto": "3cyP8R0BWO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission386/Reviewer_21KR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission386/Reviewer_21KR"
                ],
                "content": {
                    "title": {
                        "value": "Response to rebuttal"
                    },
                    "comment": {
                        "value": "I thank the authors for their response. \n\nHowever, while I appreciate the results in the paper, I am still not convinced by the significance of the results beyond the GCD context. I will maintain the score for now."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission386/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700728561913,
                "cdate": 1700728561913,
                "tmdate": 1700728561913,
                "mdate": 1700728561913,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]