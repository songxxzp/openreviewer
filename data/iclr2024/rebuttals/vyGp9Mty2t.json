[
    {
        "title": "Implicit Neural Representations for Joint Sparse-View CT Reconstruction"
    },
    {
        "review": {
            "id": "rhoJdK4iLO",
            "forum": "vyGp9Mty2t",
            "replyto": "vyGp9Mty2t",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5462/Reviewer_PdsV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5462/Reviewer_PdsV"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a novel approach to improve reconstruction quality in Sparse-view Computed Tomography (CT) using Implicit Neural Representations (INRs) with a Bayesian perspective. The method incorporates latent variables to capture inter-object relationships and sets a new standard in CT reconstruction. The authors utilize three CT datasets and a natural image dataset to evaluate the generalizability of their approach. The proposed INR-based Bayesian framework enhances individual reconstructions and shows notably better metrics compared to other methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Novel approach to improve reconstruction quality in sparse-view CT with INR, enhancing reconstructions.\n- Extensive experiments and comparisons with other methods, to evaluate various facets of reconstruction performance\n- Clear and detailed explanation of the methodology, including the EM algorithm and the alternating E and M steps used in the approach\n- Results are well explained, each demonstrating the efficiency of including Bayesian framework.\n- Well-designed and well-executed study that makes a significant contribution to the field of medical imaging."
                },
                "weaknesses": {
                    "value": "No significant weakness in the paper."
                },
                "questions": {
                    "value": "- For Figure 4b, there is a discussion that MAML might struggle to capture the shared features when many nodes are participating. Could you give bit detailed explanation? Also, which dataset are used for Figure 4? Was it 4DCT?\n- Why would MAML fail to learn meaningful prior in Supplementary Figure 10?\n- How does the proposed framework compare to other state-of-the-art methods in terms of computational efficiency?\n\nnitpicks:\n- Missing bold text in 5th row of Table 3."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5462/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5462/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5462/Reviewer_PdsV"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5462/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698568619840,
            "cdate": 1698568619840,
            "tmdate": 1699636556521,
            "mdate": 1699636556521,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CI64s0jmxF",
                "forum": "vyGp9Mty2t",
                "replyto": "rhoJdK4iLO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comments by Authors"
                    },
                    "comment": {
                        "value": "Thank you for the thorough review and insightful feedback. We value the time you've dedicated to reviewing our work. In response, we have carefully prepared a rebuttal and revised the paper accordingly. Below, we address your questions:\n\n> Q1: For Figure 4b, there is a discussion that MAML might struggle to capture the shared features when many nodes are participating. Could you give bit detailed explanation? Also, which dataset are used for Figure 4? Was it 4DCT? \n\nIn Figure 4b, we utilized an intra-person configuration on LungCT dataset from Decathlon. We have clarified this in the revision by clarifying it in the caption of Figure 4 \u201con intra-patient LungCT\u201d. This additional detail should help readers better contextualize our findings.\n\nFurthermore, we conducted new experiments that applied priors learned from different numbers of nodes to unseen data using an inter-person configuration on LungCT dataset. The results (E8 and Figure 19) exhibit a consistent trend with MAML's performance.\n\nMAML is designed to identify an initial model that can be quickly fine-tuned to specific objects using a minimal number of gradient updates. Our hypothesis is that when the objects involved in joint training are excessively diverse, this initial model may not effectively generalize. Furthermore, while the original work [1] has successfully applied MAML to multiple objects in an image regression context, our empirical findings suggest that MAML struggles to develop a robust meta-model from many nodes when the reconstruction depends on projection measurements and the sampling is sparse.\n\nWe appreciate the opportunity to delve deeper into these aspects of our research, as understanding the nuances of these methods is crucial for advancing the field. We believe these additional experiments and discussions will offer valuable insights to the readers and contribute to a more comprehensive understanding of the potential and limitations of various methodologies in the realm of CT reconstruction.\n\n> Q2: Why would MAML fail to learn meaningful prior in Supplementary Figure 10?\n\nIn the visualization presented in Figure 10, it's observed that the learned prior of MAML does not depict a pattern that is immediately recognizable as a face, unlike those produced by FedAvg and INR-Bayes. \n\nIt's important to clarify that this observation shouldn't necessarily be seen as an indication of MAML's inability to learn a meaningful prior. Firstly, the 'color lump' pattern associated with MAML is also discernible in the priors learned by our method, suggesting its potential relevance to the reconstruction process. \n\nSecondly, although FedAvg captures face-like prior, MAML's reconstruction results are quantitatively superior to those of FedAvg, as evidenced by the metrics presented alongside each image. This indicates that while the priors learned by MAML may not offer clear semantic interpretation visually, they contribute effectively to the task of reconstruction, which is the primary goal of these methods.\n\nWe appreciate this opportunity to delve deeper into the nuances of how different methods approach and learn priors. Our goal is not just to compare these methods quantitatively but also to offer insights into their qualitative aspects. \n\n\n> Q3: How does the proposed framework compare to other state-of-the-art methods in terms of computational efficiency? \n\nRecognizing the relevance of this aspect, we have dedicated a new section in the appendix (E.6 and Table 5) to specifically address computation costs. This addition has also been made in response to similar queries from other reviewers. For your convenience, we have included Table 5 below, summarizing the computational costs of our method compared to other state-of-the-art approaches.\n\n|                    | SingleINR | FedAvg | MAML  | INR-Bayes |\n|--------------------|-----------|--------|-------|-----------|\n| GPU Memory (MiB)   | 6338      | 6408   | 6344  | 6452      |\n| Time (hrs:mins)    | 09:03     | 09:07  | 09:07 | 09:53     |\n\nAs indicated in the table, the additional computational overhead of our INR-Bayes method, when compared to SingleINR and other methods, is relatively modest. The primary additional computational time in our method involves the calculation of the latent variable and one-time Monte Carlo sampling per iteration. Our approach is deliberately devised to keep the computational overhead minimal while still harnessing the benefits of our Bayesian framework.\n\nWe hope this information adequately addresses your query regarding computational efficiency.\n\n> Q4:  Missing bold text in 5th row of Table 3.\n\nThank you for highlighting this oversight. We have now corrected Table 1 in our manuscript to ensure consistency and accuracy. Your attention to detail is greatly appreciated.\n\n[1] Tanick et. al, Learned initializations for optimizing coordinate-based neural representations, CVPR 2021"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700249531507,
                "cdate": 1700249531507,
                "tmdate": 1700249531507,
                "mdate": 1700249531507,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "FEInGl4rqB",
            "forum": "vyGp9Mty2t",
            "replyto": "vyGp9Mty2t",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5462/Reviewer_R9JK"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5462/Reviewer_R9JK"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a new method for improving the reconstruction quality of sparse-view CT scans using implicit neural representations (INRs). Addressing the challenges posed by undersampled data in Sparse-view CTs, this paper advocates for joint reconstruction of multiple objects/subjects, capitalizing on the shared information (statical regularities in the paper) often found in similar subjects. Central to their approach is an INR-based Bayesian framework that incorporates latent variables to discern inter-object relationships. These variables serve as a dynamic reference during the optimization process, ensuring enhanced reconstruction quality. This work achieves good results and promises to open source the code."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Novelty. I like the proposed approach to modeling shared information in a \"nerf-in-the-wild\" setting. It effectively extracts maximal shared information across different subjects and demonstrates its utility. This setting is new, at least to me. While some works have applied INRs to sparse-view CT challenges, this paper slightly sets it apart by jointly reconstructing multiple objects. Also, the incorporation of multiple latent variables in the Bayesian framework is a thoughtful addition, further enhancing the originality of the approach.\n\n2. The paper is well-structured and offers an intuitive flow, making it easy to read and follow.\n\n3. The tackled problem, sparse view CT reconstruction, holds its own significance in \"AI+Med\". The paper provides some extra (toy) examples in the appendix, which is appreciated."
                },
                "weaknesses": {
                    "value": "1. Small improvement. While the proposed method is conceptually appealing, the performance improvement appears to be minimal. As illustrated in Table 1, the gains, though in the positive direction, are relatively slight. Such incremental progress might raise questions about the practical implications and advantages of adopting this new approach over existing methods.\n\n2. Non-principled static-transient decomposition. From what I understand now, the current model seems to hinge on a static branch that remains uniform across all subjects, irrespective of their position in the 3D volume. While this might be appropriate in a NeRF-in-the-wild setting, given the fixed positioning of structures like buildings in the real world, its direct application to varied anatomical structures in the abdominal region seems problematic. Every patient's anatomy, although structurally similar, is unlikely to occupy the same 3D space due to innate variations (rigid/deformable transformations). Hence, applying this method without a template registration step appears misguided. \n\nI think a more holistic solution might involve concurrently learning different deformation fields for individual subjects, and mapping each anatomical point to a unified canonical space. This would account for the inherent spatial variations between patients while ensuring a consistent reference frame for reconstructions."
                },
                "questions": {
                    "value": "1. Increasing the number of nodes doesn't help much for almost all methods. Do the authors have any insights into this?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5462/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698800546188,
            "cdate": 1698800546188,
            "tmdate": 1699636556373,
            "mdate": 1699636556373,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "DTl30SPZHK",
                "forum": "vyGp9Mty2t",
                "replyto": "FEInGl4rqB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comments by Authors"
                    },
                    "comment": {
                        "value": "Thank you for the thorough review and insightful feedback. We value the time you've dedicated to reviewing our work. In response, we have carefully prepared a rebuttal and revised the paper accordingly. Below, we address your questions:\n\n> Q1: Small improvement. While the proposed method is conceptually appealing, the performance improvement appears to be minimal. As illustrated in Table 1, the gains, though in the positive direction, are relatively slight. Such incremental progress might raise questions about the practical implications and advantages of adopting this new approach over existing methods. \n\nWe appreciate your perspective and would like to offer some additional context to highlight the significance of our results.\n\nFirstly, it's important to note that PSNR is a logarithmic metric, meaning that even seemingly small numerical improvements can reflect substantial enhancements in image quality. Specifically, our method shows an average improvement of around 1.5 dB over single INR and approximately 0.5 dB over MAML. In the context of PSNR measurements over 30 dB, these improvements are indeed noteworthy.\n\nFurthermore, in the \u201cApplying to Unseen Data using Learned Prior\u201d experiment, our method achieved an even more pronounced improvement \u2013 an increase of 0.9 dB over MAML and 1.4 dB over SingleINR. This further underscores the efficacy of our approach.\n\nAnother crucial aspect of our method is its robustness against overfitting, a prevalent issue in INR-based approaches. Typically, these methods experience a decline in reconstruction quality after reaching a peak performance, making it challenging to set an appropriate early stopping criterion in practical scenarios. In contrast, our method not only consistently achieves superior reconstruction quality but also maintains this level once reached. This stability is a significant practical advantage over existing methods, offering more reliable and consistent results.\n\nWe believe that these aspects collectively demonstrate the practical utility and advancements of our proposed method in the field of CT reconstruction.\n\n> Q2: Non-principled static-transient decomposition. From what I understand now, the current model seems to hinge on a static branch that remains uniform across all subjects, irrespective of their position in the 3D volume. While this might be appropriate in a NeRF-in-the-wild setting, given the fixed positioning of structures like buildings in the real world, its direct application to varied anatomical structures in the abdominal region seems problematic. Every patient's anatomy, although structurally similar, is unlikely to occupy the same 3D space due to innate variations (rigid/deformable transformations). Hence, applying this method without a template registration step appears misguided.\n\nThank you for your insightful comments regarding the static-transient decomposition in our work. We acknowledge the importance of your observation, particularly in the context of CT reconstruction where anatomical structures can vary significantly in positioning and orientation.\n\nYou are correct in noting that our implementation of INRWild, adapted directly from NeRFWild, treats the static branch uniformly across subjects. This approach, while effective in settings with fixed structural elements, may indeed present limitations when applied to anatomical structures that inherently exhibit spatial variations.\n\nWhile the datasets we used for our study do provide a basic level of standardization, with objects generally centered, there are certainly deviations. Interestingly, our method seems to mitigate these deviations to some extent, as the prior learning process inherently accounts for variations in the weight space when selecting patients randomly for joint reconstruction. Our experimental results suggest that this approach confers a degree of robustness against the deviations present in our datasets.\n\nHowever, your point about the potential benefits of incorporating a registration step is well taken. Indeed, integrating our method with a template registration step could further enhance the accuracy and applicability of our approach, especially in cases with significant anatomical variations. This is an interesting direction for future research, and we are excited to explore the potential improvements this could bring to our method.\n\nThank you again for your constructive feedback and for highlighting this important aspect of our work. We are eager to delve into this area in our future research endeavors."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700249823553,
                "cdate": 1700249823553,
                "tmdate": 1700249905876,
                "mdate": 1700249905876,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yp5UdnYGo9",
                "forum": "vyGp9Mty2t",
                "replyto": "FEInGl4rqB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comments by Authors"
                    },
                    "comment": {
                        "value": "> Q3: Increasing the number of nodes doesn't help much for almost all methods. Do the authors have any insights into this?\n\nThe experiment depicted in Figure 4b was conducted using an intra-patient setup. Our hypothesis is that the statistics of a single patient's data can be effectively captured with just a few slices, and that adding extra nodes does not significantly improve the estimation. This phenomenon is likely to be consistent across different methods that extract statistical information from the INR network.\n\nWe have included a new experiment in the Appendix (E8 and Figure 19), conducted in an inter-patient setup. In this scenario, extracting statistics from a larger number of nodes should more accurately converge to the population statistics. Consequently, we observed a slight improvement in our method's performance as the number of nodes increased."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700249843465,
                "cdate": 1700249843465,
                "tmdate": 1700249843465,
                "mdate": 1700249843465,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Hn7gZCIsqC",
            "forum": "vyGp9Mty2t",
            "replyto": "vyGp9Mty2t",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5462/Reviewer_WCTi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5462/Reviewer_WCTi"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a method to implicit neural representation learning (INR) for joint sparse-view CT reconstruction, which means that to reconstruct several CT images at the same time. The proposed method is evaluated on different CT image datasets and shows better performance compared with previous meta-learning based INR methods."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed method may investigate an interesting research question that how to incorporate population priors in INR learning. Although I do have quite a few concerns and questions about the proposed method as below, the proposed INR-Bayes method may be a potential way by introducing latent variables so that it may be possible to make it as a generative model from some prior distribution in some way..\n- The paper validates the proposed method on different CT image datasets with different CT configuration or settings, and compares them with different baselines. The experiments about adaptation on new patients using priors learned from other patients are an interesting setting, but may also be questionable as follows."
                },
                "weaknesses": {
                    "value": "- The motivation for conducting joint CT reconstruction. From the perspective of clinical applications, I do not see any reason why we want to do joint CT reconstruction. To my best knowledge, there are no such settings and needs from current clinical protocol. Can we imagine that in a scenario, after one patient is scanned, we do not do the reconstruction right after the scanning but wait until there are 5-10 patients\u2019 scans, then we want to do the reconstruction together? I cannot think about some applications that require such needs, maybe the author can explain more or give some specific examples.  \n- What is the physical meaning of the learned priors? This prior is learned from 10 slices (which mimics 10 different patients). From this setting, I guess the prior may be some \u201caverage\u201d CT image across these 10 images including mostly low-frequency signals. This guess is also supported by the illustration of learned prior in Figure 13 and 15, which is somewhat the general structure of the sliced anatomic structure. But why should this prior be helpful to reconstruct higher quality of CT for new patients? In the sparse-view CT reconstruction, due to the sparse sampling, what is always missing is the high-frequency signal in the detailed structure. Why does such an \u201caverage\u201d image should be helpful to improve the final reconstruction image quality to get sharper and fine structures?\n- How to choose these 10 patients to get the prior? If we consider a setting to use the learned prior for new patients\u2019 reconstruction, how shall we choose the 10 different patients to get the prior? Such as healthy patients or abnormal patients? For example, if there are some patients with tumors, does the learned prior also include such prior in the latent variables and indicate that in the new patients\u2019 reconstruction? Shall there be any relationship between the new patients and prior patients? How can we know if the new patient is normal or abnormal before we get the CT image reconstructed?\n- How does the method deal with registration problems in CT imaging? The validated datasets in the paper seem to be already registered. If we consider the real CT scanning in practice, for different patients, the patient\u2019s positions will always be different. How can this method deal with the position shift when learning the prior from different patients?\n- In the motivation as well as experiments, one important baseline that the paper compares with is MAML [1]. As the author also mentioned, [1] learned an initialization from multiple objects in order to speed up optimization process while cannot achieve better optimization results from the learned initialization. The proposed works share a lot of similarity with [1] while using a different way to formulate and parametrize the learned prior, why the proposed method would achieve better optimization results while [1] not. The results in Table 1 also support these where the scores for these two methods are quite comparable. Besides, does the INR-Bayes and MAML use the same encoding function, embedding size and backbone network structure in this comparison?\n- In the previous works, the paper mentioned \u201cLastly, while alternative joint CT reconstructions like (Shen et al., 2022) [2] use priors from pre-reconstructed images, and (Reed et al., 2021) [3] relies on finding a template image from 4DCT; their practical limitations led to their exclusion from our comparative analysis.\u201d First, to my understanding, these two works are not doing the joint CT reconstruction as claimed in this paper. [2] is doing the CT and MRi reconstruction through INR by using a full-sampled prior image of the same patient as prior embedding, which is a very common setting for patients\u2019 longitudinal study in clinics. [3] is doing dynamic CT reconstruction where different frames share some similarity while maintaining deformable motion, which is also very common in 4DCT setting with motion. Second, I do not see what is the \u201cpractical limitations led to their exclusion from our comparative analysis\u201d, since these two papers\u2019 setting may be more reasonable from practical applications. And their goal is to achieve better reconstruction results instead of fast convergence as [1], so I think these two papers may even be more important to be  compared with to demonstrate the superiority of the proposed method.\n- In the setting of \u201cApplying to Unseen Data using Learned Prior\u201d, how are the patients chosen to learn the prior? Would different prior patients influence the reconstruction for the same new patient? Would different number of prior patients influence the reconstruction for the same new patient? When adapt the new patients, will the latent variable also adapt to the new patient?\nComputational efficiency. Based on Algorithm 1, it seems that multiple networks are maintained and trained simultaneously for different patients. Also it needs to iterate through all patient, all time steps, with three loops interleaved. This algorithm looks very costly for memory and time efficiency. Can the paper report the memory and time used in training and testing with comparison of baseline methods?\n- Using some framework figure may be better to illustrate the whole framework.\n\n[1] Learned initializations for optimizing coordinate-based neural representations. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2846\u20132855, 2021.\n\n[2] Nerp: implicit neural representation learning with prior embedding for sparsely sampled image reconstruction. IEEE Transactions on Neural Networks and Learning Systems, 2022.\n\n[3] Dynamic ct reconstruction from limited views with implicit neural representa- tions and parametric motion fields. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 2258\u20132268, 2021."
                },
                "questions": {
                    "value": "Please see weakness for the details of questions."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5462/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698819471827,
            "cdate": 1698819471827,
            "tmdate": 1699636556283,
            "mdate": 1699636556283,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7n4cjuJXqC",
                "forum": "vyGp9Mty2t",
                "replyto": "Hn7gZCIsqC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the thorough review and insightful feedback. We value the time you've dedicated to reviewing our work. In response, we have carefully prepared a rebuttal and revised the paper accordingly. Below, we address your questions:\n\n> Q1:  Application examples of joint reconstruction?\n\nWe appreciate the opportunity to clarify the practical motivations behind our approach to joint CT reconstruction. To address this, we have now included the sentence 'Computed Tomography (CT) plays a crucial role in both medical diagnostics and industrial quality control.' as the first sentence in our abstract.\n\nOur study aims to explore the potential benefits of joint reconstruction in scenarios where multiple CT scans share similarities, either in a medical or industrial context. We have added the sentence, 'Computed Tomography (CT) plays a crucial role in both medical diagnostics and industrial quality control,' to the abstract for clearer emphasis on its significance. In medical settings, patients can sometimes undergo multiple CT scans over extended periods, particularly for conditions like evolving tumors. Joint reconstruction can significantly enhance the consistency and quality of these serial scans. This approach could be particularly beneficial in situations where the same anatomical regions are scanned repeatedly, allowing for improved image quality and potentially lower radiation doses by using sparse-view scans.\n\nIn addition, different hospitals or CT machines could potentially use scans for joint reconstruction. The concept of applying previously learned information to new, unseen data presents another practical use. In such cases, we can store and leverage past reconstruction data to enhance future scans. \n\nWhile our research primarily evaluates medical images, the principles of joint reconstruction are equally applicable in industrial CT settings. For example, in assembly lines where similar objects are scanned routinely, batch processing of scans can efficiently utilize joint reconstruction techniques. This approach can lead to improved quality and consistency in industrial quality control processes.\n\nWe acknowledge that the direct clinical application of joint reconstruction as described might not be a current standard practice. However, our research opens avenues for future exploration and potential implementation in medical, industrial, and scientific fields. We believe our findings contribute significantly to the advancement of CT imaging techniques and their potential applications."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700250157553,
                "cdate": 1700250157553,
                "tmdate": 1700250157553,
                "mdate": 1700250157553,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aL1kYQ78vJ",
                "forum": "vyGp9Mty2t",
                "replyto": "Hn7gZCIsqC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comments by Authors"
                    },
                    "comment": {
                        "value": "> Q2: Physical meaning of the learned prior? Why can such prior help to reconstruct higher quality of CT for new patients? In the sparse-view CT reconstruction, due to the sparse sampling, what is always missing is the high-frequency signal in the detailed structure.\n \nThe learned prior in our Bayesian method is modeled as a Gaussian distribution in the weight space of the INR. We use its mean to illustrate that the prior captures significant anatomical information in Figure 13 and 15. However, we emphasize that this is only one aspect of its role. The full potential of the prior encompasses the representation of uncertainty, distinguishing between universally observed patterns and those unique to fewer or individual subjects. This uncertainty allows for adaptive regularization during individual training, as each network autonomously determines which information to extract from the prior based on its own uncertainty and that of the prior. This process is facilitated by minimizing the KL divergence between the prior and the posterior distribution of the individual network. Such adaptability distinguishes the Bayesian framework from other methods and underpins its superior performance.\n\nIn sparse-view CT, the challenge predominantly arises from scanning at fewer angles compared to traditional CT. This often leads to the Nyquist-Shannon sampling theorem not being fully met, which can result in compromised reconstruction quality. Specifically, there's a perceived loss of high-frequency information in the reconstructed images. However, it's crucial to note that the high-frequency information isn't inherently lost during scanning; rather, it's the insufficiency of scans (or sampling) that impedes the accurate reconstruction of these high-frequency signals.\nTo demonstrate that sparse sampling doesn\u2019t cancel out high frequency information, and with help of knowledge about low-frequency information we can reconstruct the high-frequency information, we design the following toy example. Consider a signal in the form y = sin(px) + cos(qx), where the coefficients p and q satisfy p, q \\in [0, 1] and p < q. This inequality indicates that the signal comprises both high-frequency and low-frequency components. With sparse sampling, we obtain limited data, for instance, we know that when x = \\pi, y = -0.5. From this single measurement, we cannot independently reconstruct the values of p or q. However, if the value of p (representing the low-frequency component) is known, we can deduce the value of q (representing the high-frequency component) from the sparse sample. Assuming p = 1/6, the equation becomes:\nsin(\\pi) +cos(q\\pi) = -0.5.\nSince sin(\\pi/6) = 0.5, this equation simplifies to:\ncos(q\\pi) = -1,\nwhich leads to the solution q = 1. \n\nThis example illustrates how knowledge about low-frequency components can guide the reconstruction of high-frequency details, even with sparse sampling. Our method leverages this principle, utilizing the prior to fill in the missing information and thus enhance the overall reconstruction quality.\n\n> Q3: How to choose 10 patients to get the prior? Such as healthy patients or abnormal patients? For example, if there are some patients with tumors, does the learned prior also include such prior in the latent variables and indicate that in the new patients\u2019 reconstruction? Shall there be any relationship between the new patients and prior patients? How can we know if the new patient is normal or abnormal before we get the CT image reconstructed?\n\nIn our experiments, we don\u2019t make specific requirements on the prior patients. For 4DCT, it\u2019s natural to use all 10 phases to jointly reconstruct as they have the common changing trend. For intra-patient, we randomly select slices along the longitude, they also share the common changing trend as they are sampled from the same patient. For inter-patient experiments on Medical Segmentation Decathlon and Brain CT Hemorrhage Challenge, we randomly choose those prior slices. As they are representing the same area, lung or brain, they shall share some similarities which can be captured by the prior of our method. Specifically, the lungCT dataset of  Medical Segmentation Decathlon contains both images with tumor and without tumor, but we don\u2019t make use of that information and randomly select 10 patients from the dataset, so the learned prior shall work for both normal and abnormal cases. Results show that our method is robust to the variation of these factors, suggesting that our method can improve the reconstruction quality without making additional requirements in normal CT applications. \n\nWe added sentences \u201cThe dataset comprises scans both with and without tumors. For our experiments, we randomly selected patients and images without distinguishing between those containing tumors and those without, aiming for a diverse representation of lung CT images.\u201d in the Dataset details section (D) to better clarify this point."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700250207782,
                "cdate": 1700250207782,
                "tmdate": 1700250207782,
                "mdate": 1700250207782,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BsMWp01uud",
                "forum": "vyGp9Mty2t",
                "replyto": "Hn7gZCIsqC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> Q4: How does the method deal with registration problems in CT imaging? \u2026 How can this method deal with the position shift when learning the prior from different patients?\n\nOur Bayesian framework and meta learning baselines like FedAvg and MAML learn the prior in the parameter space of an INR network. The INR network architecture itself may provide the ability to mitigate the registration problem. Although the datasets we used indeed provide images that are reasonably centered, there are always deviations in terms of positions of different patients and their sizes. In our inter-person experiments, we randomly select patients for joint reconstruction, therefore the deviation emerges in the learning process. However, the results show that our method and some baselines are robust to this potential issue. A joint optimization with a registration method and our method may further improve performance. However, the study of registration methods is orthogonal to our research on our Bayesian framework. Combining with registration methods may be an important step further towards the practical usage, which can be explored in future work. \n\n> Q5: \u2026 why the proposed method would achieve better optimization results while [1] not. The results in Table 1 also support these where the scores for these two methods are quite comparable.\n\nMAML learns a meta-model for rapid adaptation to various objects. In our Bayesian framework, distributions are introduced to the network weights and the prior, with the latter acting as a regularizer in the optimization objective. By incorporating manually set early stopping criteria, MAML can be cast as conducting a Maximum A Posteriori (MAP) reconstruction [4]. In this respect, it bears some resemblance to our Bayesian framework. However, key distinctions exist between these two methods. Firstly, our Bayesian framework explicitly sets a Gaussian distribution for the network weights and prior, while the prior of MAML is induced by the early stopping in an implicit manner. A Gaussian distribution is a natural and effective choice for the weight distribution [5]. Secondly, to cast MAML as a Bayesian framework, the integration of individual network weights is assumed to be approximated by making use of a point estimate [4]. Lastly, setting good early stopping criteria is difficult in practice without access to the ground truth image, whereas our Bayesian framework does not require this hyperparameter.\n\nOur experimental results demonstrate that our method outperforms MAML, especially when applying the learned prior to unseen data (see Table 2 in the paper). Additionally, while INR methods commonly face overfitting issues as Figure 5 shows, and setting early stopping criteria is challenging without access to a ground-truth image, our method shows robustness to overfitting. The performance consistently reaches and maintains its peak after sufficient training, highlighting a critical practical advantage of the Bayesian approach.\n\n> Q6: Besides, do the INR-Bayes and MAML use the same encoding function, embedding size and backbone network structure in this comparison?\n\nFor all comparison methods in our paper, we used the same encoding function, embedding size, total number of optimization iterations, and backbone network structure, ensuring a fair comparison. We have revised Section 5 to make this aspect clearer."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700250276822,
                "cdate": 1700250276822,
                "tmdate": 1700250276822,
                "mdate": 1700250276822,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "40HkBpJyaZ",
                "forum": "vyGp9Mty2t",
                "replyto": "Hn7gZCIsqC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> Q7: Comparison with [2] and [3]\n\nThe works [2][3] also leverage information from (an)other object(s) to assist in the reconstruction of a single object. Classifying them as joint reconstruction methods may lead to some confusion, so we have updated the revision by changing the statement to \u201cLastly, while other INR-based CT reconstruction methods exist\u2026\u201d\n\nRegarding [2], you are right in noting its practical approach where a fully-sampled reconstructed image of the same patient is used as a prior. This method is indeed intuitive and aligns well with common clinical practice for longitudinal studies. However, the challenge arises when the prior image does not closely match the target image. To illustrate this, we conducted an additional experiment, the results of which are presented in Figure 17. This experiment demonstrates that when there is a mismatch between the prior and target images, the performance of [2] can be inferior even to SingleINR with random initialization. The table below compares [2] with our method in different scenarios, including matched and unmatched priors. [2] achieves better PSNR with matched prior, but its SSIM is still lower than our method. In addition, all experiments in our paper only access a set of sparse measurements. Providing a fully-sampled prior image to Nerp can therefore be considered an unfair comparison.\n\n|                | SingleINR             | Nerp match             | Nerp unmatch          | INR-Bayes              |\n|----------------|-----------------------|------------------------|-----------------------|------------------------|\n| PSNR           | 33.69 \u00b1 0.06          | **35.33**  \u00b1 0.10      | 32.83 \u00b1 0.07          | 34.31 \u00b1 0.07           |\n| SSIM           | 0.883 \u00b1 0.002         | 0.889 \u00b1 0.001          | 0.849 \u00b1 0.02          | **0.901** \u00b1 0.001      |\n\n\nAs for [3], its focus on dynamic CT and the use of deformable motion are indeed relevant to our 4DCT experiment. However, this specific approach may not be directly applicable to other experimental settings presented in our paper. Moreover, their codebase is prohibited from release by their sponsor [https://github.com/awreed/DynamicCTReconstruction]. Despite reaching out to the authors, we have not yet received any response that would enable us to conduct comparison experiments with their approach. We appreciate your comments which have helped us refine our paper and re-evaluate our comparison methods. We believe our additional experiments and the ensuing discussion better contextualize our method\u2019s advantages and limitations."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700250372661,
                "cdate": 1700250372661,
                "tmdate": 1700250372661,
                "mdate": 1700250372661,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Rucl1aBSKV",
                "forum": "vyGp9Mty2t",
                "replyto": "Hn7gZCIsqC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comments by Authors"
                    },
                    "comment": {
                        "value": "> Q8: In the setting of \u201cApplying to Unseen Data using Learned Prior\u201d, how are the patients chosen to learn the prior? Would different prior patients influence the reconstruction for the same new patient? Would different number of prior patients influence the reconstruction for the same new patient? When adapt the new patients, will the latent variable also adapt to the new patient? \n\nThank you for your insightful questions regarding the selection of patients for learning the prior and its influence on reconstructing new patients. We appreciate the opportunity to clarify these aspects and extend our analysis.\n\nFor the experiment mentioned in the main paper, we selected patients randomly, ensuring a consistent slice position across different patients by proportionally selecting slices relative to the total volume. This method accommodates the variation in the number of slices and volume sizes across patients, which can range from (112,512,512) to (636,512,512). In this particular experiment, the prior is not updated with data from the new patient. However, we acknowledge the potential for further enhancing the prior by including the new patient's data.\n\nAddressing your query on the influence of different prior patients on the reconstruction of the same new patient, we extended our experiments (Appendix F.8). In this new experiment, we trained the prior using 10 different groups of patients, each group consisting of 10 randomly selected patients. We then used these 10 different priors to guide the reconstruction of the same new patient. As illustrated in Figure 19, our method effectively utilized these diverse priors to reconstruct the new patient, demonstrating robustness against variability in the selected prior patients.\n\nRegarding your question about the impact of the number of prior patients, we conducted another experiment to investigate this. We trained our prior using varying numbers of patients, ranging from 5 to 40, and then applied these priors to the reconstruction of the same 5 new patients. The results, presented in Figure 18, indicate a gradual improvement in PSNR when employing priors learned from a larger pool of patients. This finding suggests that having priors from more patients can be beneficial for our method, enhancing the reconstruction quality.\n\nWe hope these additional experiments and their results comprehensively address your queries and provide further insights into the robustness and adaptability of our proposed method.\n\n> Q9: Computation cost.\n\nWe understand that the algorithm's complexity and its implications on memory and time efficiency are crucial considerations.\n\nWhile our methods iterate over multiple patients, SingleINR also needs to run on each of the patients in order to obtain their reconstructions. Figure 5 shows that all methods converge at a similar speed. In all experiments, we run all methods for 30000 iterations and compare their performance. While our method does incur additional computational complexity due to the optimization of the latent variables, we derive an efficient algorithm to achieve that (Line 6, 7 in Algorithm 1). The increase of the computational time of our method is therefore less than 10% compared to SingleINR. However, considering the enhanced reconstruction quality and robustness to overfitting achieved, this additional time investment can be justified.\n\nTo clarify the computational efficiency, we have expanded our appendix to include a detailed analysis of the computational cost. We've also included a comparative table (Table 5) in this discussion for easy reference. You can find this detailed comparison [here](https://openreview.net/forum?id=vyGp9Mty2t&noteId=CI64s0jmxF). \n\nWe hope this additional information adequately addresses your query and provides clarity on the computational aspects of our method.\n\n> Q10: Using some framework figure may be better to illustrate the whole framework.\n\nThank you for your feedback, we agree that a visual representation could enhance the clarity and understanding of our methodology.\n\nWhile we believe that Figure 1 in our paper already offers a direct insight into the technical aspects of our method, we understand the importance of a more comprehensive visual overview. To address this, we have added a more detailed version of the method overview as Figure 7 in the appendix.\n\nWe hope that this additional figure will provide readers with a clearer understanding of our framework, especially before they delve into the more technical details of our approach. We are also open to further modifying the overview figure to make it even more comprehensive, should you have specific suggestions or comments in this regard."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700250516670,
                "cdate": 1700250516670,
                "tmdate": 1700251948502,
                "mdate": 1700251948502,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mhiBeBlX7w",
                "forum": "vyGp9Mty2t",
                "replyto": "Hn7gZCIsqC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comments by Authors"
                    },
                    "comment": {
                        "value": "We appreciate your insightful feedback and have diligently addressed the concerns raised. We hope that our revisions and clarifications demonstrate the robustness and relevance of our work, and we respectfully invite you to re-evaluate our submission in light of these updates."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700250682585,
                "cdate": 1700250682585,
                "tmdate": 1700252015091,
                "mdate": 1700252015091,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lujBjJ72Gj",
                "forum": "vyGp9Mty2t",
                "replyto": "Hn7gZCIsqC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comments by Authors"
                    },
                    "comment": {
                        "value": "[4] Grant et al., Recasting Gradient-Based Meta-Learning as Hierarchical Bayes, ICLR, 2018.\n\n[5] Matthews et al., Gaussian Process Behaviour in Wide Deep Neural Networks, ICLR, 2018."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251998078,
                "cdate": 1700251998078,
                "tmdate": 1700251998078,
                "mdate": 1700251998078,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NscAHTr2Lk",
                "forum": "vyGp9Mty2t",
                "replyto": "Hn7gZCIsqC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal follow up"
                    },
                    "comment": {
                        "value": "As we are now approaching the end of the reviewer-author discussion\nperiod, we would like to follow up on our rebuttal response and gently\nremind you to provide your valuable feedback.\n\nWe are keen to know if our response and improvements address your\nconcerns and satisfy you. Furthermore, we would like to confirm if there\nare any further concerns or questions you may have regarding our work,\nwe are more than willing to engage in a productive discussion during the\nreviewer-author period.\n\nThank you for your valuable input and time."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700567156412,
                "cdate": 1700567156412,
                "tmdate": 1700567156412,
                "mdate": 1700567156412,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "AF8aidvvll",
                "forum": "vyGp9Mty2t",
                "replyto": "Hn7gZCIsqC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Reviewer_WCTi"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Reviewer_WCTi"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for author's efforts to answer my questions. I have read the author's response and other reviewer's comments. Some of my concerns are addressed while I am still not fully convinced with other questions including:\n\nQ1: It is still not clear in what kind of applications scenarios, we must and have to conduct joint reconstructions for 10 patients/samples altogether no matter in medical or industrial CT imaging.\n\nQ2: As mentioned, \"the prior is formulated as a Gaussian distribution in the weight space of the INR\", how reliable this distribution can be with only limited samples?\n\nQ3/Q8: Random selecting a few samples to build prior sounds quite empirical and sensitive, without a more systematic study to disclose the reliability of the prior.\n\nQ4: I would respectively disagree with the author that \"The INR network architecture itself may provide the ability to mitigate the registration problem\", since INR is coordinate-based network modeling. And this algorithm should be quite sensitive to registration issue among prior samples due to the sensitivity and small samples to build the prior.\n\nQ5: The essential difference between MAML and this method is still not very clear, especially regarding learning prior from population samples, even MAML gets prior from more samples. The learn initialization can also be treated as some kind of regularization?\n\nThus, I would keep my original score as it is. Thanks."
                    }
                },
                "number": 28,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700712464264,
                "cdate": 1700712464264,
                "tmdate": 1700712596817,
                "mdate": 1700712596817,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "W19PMobRwu",
            "forum": "vyGp9Mty2t",
            "replyto": "vyGp9Mty2t",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5462/Reviewer_ufhh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5462/Reviewer_ufhh"
            ],
            "content": {
                "summary": {
                    "value": "The paper deals with the reconstruction of sparse-view CT images. The authors propose a novel Bayesian framework to jointly reconstruct multiple objects using implicit neural representations. The authors evaluate their method against other methods including FBP, iterative, and some joint reconstruction techniques using INRs."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is generally well written, and the motivation is clear. Additionally, the literature review is exhaustive. The authors also provide some interesting ablation studies of their method."
                },
                "weaknesses": {
                    "value": "**Writing**\n\nWhile the paper is well written and easy to read, some statements by the authors are somewhat misleading:\n> Sparse-view Computed Tomography (CT) is favored over standard CT for its reduced [...] (Abstract)\n\nsuggests, that sparse-view CT would be common practice nowadays, which is -to the best of my knowledge- not the case.\n\n>  While dense measurements typically yield accurate reconstructions, measurements are often intentionally limited to reduce ionizing radiation or cost, resulting in sparse data. (Introduction)\n\nSee above, to the best of my knowledge, sparse-view CT is not common in clinical practice. Also, can the authors clarify, how reducing the number of angles may reduce cost?\n\n> While many approaches learn the mapping from sparse-view to dense-view images using supervised learning [...] they often necessitate extensive, domain-specific datasets which are difficult to obtain in practice. (Introduction)\n\nSince full-view acquisitions are the de-facto standard in clinical CT and sparse-view datasets can easily be simulated from these data, such datasets are abundant (e.g., the LDCT Image and Projection data [1] contains over 300 full-view, full-dose acquisitions)\n\n**Experiments**\n\nI have several concerns regarding the experiments:\n\n1. Comparison methods. Unfortunately, the authors do not compare their method against standard CNN-based methods (some of which are also mentioned in the introduction). In particular, the authors do not compare their method against approaches that implicitly (e.g., [2]), or explicitly (e.g., in the form of a DNN) incorporate prior knowledge. The authors also don't compare their method against other, previously proposed INR reconstructing techniques for sparse-view CT.\n2. Missing error bars in Fig. 4, 5, & 6. In Tab. 1, over what is the mean $\\pm$ standard deviation computed? Are the improvements statistically significant?\n3. It is well known, that metrics such as SSIM and PSNR are often not in agreement with quality assessment by clinicians [3,4]. While I recognize that a thorough evaluation involving a reader study is beyond the scope of this work, I don't think the results in Tab. 1 justify the authors claim that their method 'sets a new standard in CT reconstruction performance' (Abstract). Upon visual inspection of Fig. 2 & 3, I find that the proposed method removes many anatomical details and I highly doubt that a clinician would find that reconstructions produced by INR-Bayes are significantly better than those produced by e.g. SingleINR.\n\n**Computational complexity and real-world applicability**\n\nWhat is the computational complexity of the method? Are all reconstructions performed for the main paper on single $512\\times 512$ slices? The application to CBCT reconstructions shown in the appendix is on a much smaller (clinically unusable) image matrix. What would the computational cost for one full patient be compared to the other methods and a CNN-baseline?\n\n[1] https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=52758026\n\n[2] Chen GH, Tang J, Leng S (2008) Prior image constrained compressed sensing\n(piccs): a method to accurately reconstruct dynamic ct images from highly\nundersampled projection data sets. Med Phys 35: 660\u2013663.\n\n[3] Renieblas G P, del Castillo E G, G\u00f3mez-Leon N, Gonz\u00e1lez A M and Nogu\u00e9s A T 2017 Structural similarity index family for image quality assessment in radiological images J. Med. Imaging.\n\n[4] Verdun F R, Racine D, Ott J G, Tapiovaara M J, Toroi P, Bochud F O, Veldkamp W J, Schegerer A, Bouwman R W, Hernandez-Giron I, Marshall N W and Edyvean S 2015 Image quality in CT: from physical measurements to model observers Phys. Med. 31 823\u201343"
                },
                "questions": {
                    "value": "The experiment configurations intra-patient and 4DCT violate the conditional independence assumption. Does this influence reconstruction quality?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5462/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5462/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5462/Reviewer_ufhh"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5462/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698829302416,
            "cdate": 1698829302416,
            "tmdate": 1699636556189,
            "mdate": 1699636556189,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0qzgXZJJs3",
                "forum": "vyGp9Mty2t",
                "replyto": "W19PMobRwu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comments by Authors"
                    },
                    "comment": {
                        "value": "Thank you for the thorough review and insightful feedback. We value the time you all have dedicated to reviewing our work. In response, we have carefully prepared a rebuttal and revised the paper accordingly. Below, we address your questions:\n\n> Q1: While the paper is well written and easy to read, some statements by the authors are somewhat misleading.\n\nWe are glad to see that the reviewer finds our paper well written and easy to read. We have adjusted our statements in the revision to improve the clarity and the consistency with our empirical findings. The revision should be better aligned with the reviewer\u2019s feedback.\n\n> Q2: \u201cSparse-view Computed Tomography (CT) is favored over standard CT for its reduced ... (Abstract)\u201d suggests, that sparse-view CT would be common practice nowadays, which is -to the best of my knowledge- not the case.\n\nWe adjust the previous statement to \u201cSparse-view Computed Tomography (CT) has advantages over standard CT for its reduced \u2026\u201d\n\nWe realize our phrasing in the abstract may inadvertently suggest that sparse-view CT is widely practiced, which was not our intention. Our goal was to emphasize the potential benefits of sparse-view CT, especially in terms of reduced radiation exposure and increased througput, which are significant considerations in CT. We understand that while sparse-view CT has promising advantages, its widespread adoption is still evolving, often influenced by factors like regulatory approvals and clinical validation.  We note, however, that CT is widely applied to a range of industrial and scientific applications which are not subject to clinical regulatory constraints, and our method may find ready application in these non-clinical domains.\n\nOur work aims to address the critical challenge of image quality in sparse-view CT. By focusing on improving the reconstruction quality from sparse data, we hope to contribute to overcoming one of the key hurdles in its broader implementation. We believe that the current status of sparse-view CT represents a phase in the ongoing advancement and integration of new technologies in practice. Thus, our research seeks to offer solutions that could facilitate its future adoption and underline its relevance in the field.\n\n> Q3: \u201cWhile dense measurements typically yield accurate reconstructions, measurements are often intentionally limited to reduce ionizing radiation or cost, resulting in sparse data. (Introduction)\u201d\n> \n> See above, to the best of my knowledge, sparse-view CT is not common in clinical practice. Also, can the authors clarify, how reducing the number of angles may reduce cost?\n\nThank you for highlighting this aspect. We have revised our introduction to better articulate the context and potential advantages of sparse-view CT. Our new wording in the introduction is: \u201cIn specific situations, limiting the number of CT measurements can offer benefits such as reduced radiation exposure and cost management, which may lead to the use of sparse data.\u201d This refined statement more accurately reflects the targeted use of sparse-view CT, emphasizing its potential benefits without suggesting widespread current clinical adoption.\nIn the realm of medical CT imaging, reducing the number of scanning angles can decrease patient exposure to ionizing radiation, a crucial consideration in frequent or high-risk scanning scenarios. This approach can also expedite the scanning process, potentially reducing wait times and increasing patient throughput in busy clinical settings. It can also potentially reduce the cost by lowering operational costs associated with extended scanner usage.\nIn industrial applications, where CT scanners often operate continuously in production environments, reducing scanning angles can significantly enhance efficiency. Shorter scan times increase throughput and reduce operational delays, directly impacting productivity. Additionally, decreased scanner usage results in lower energy requirements, contributing to cost savings and reduced environmental impact.\nWe believe that emphasizing these specific contexts provides a clearer understanding of where sparse-view CT can offer substantial advantages in both medical and industrial settings. We appreciate your feedback and hope this revised explanation addresses your concerns."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700250741796,
                "cdate": 1700250741796,
                "tmdate": 1700250741796,
                "mdate": 1700250741796,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VvOYhP4CzT",
                "forum": "vyGp9Mty2t",
                "replyto": "W19PMobRwu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comments by Authors"
                    },
                    "comment": {
                        "value": "> Q4: \u201cWhile many approaches learn the mapping from sparse-view to dense-view images using supervised learning [...] they often necessitate extensive, domain-specific datasets which are difficult to obtain in practice. (Introduction)\u201d\n> \n>Since full-view acquisitions are the de-facto standard in clinical CT and sparse-view datasets can easily be simulated from these data, such datasets are abundant (e.g., the LDCT Image and Projection data [1] contains over 300 full-view, full-dose acquisitions)\n\nWhile it is true that full-view acquisitions are standard in clinical CT and sparse-view datasets can be easily simulated from these data, the challenge lies not merely in dataset availability. The primary difficulty is in obtaining domain-specific datasets that are sufficiently diverse and representative to train models effectively for a wide range of real-world applications. While simulated sparse-view datasets derived from full-view acquisitions provide a valuable resource, they may not fully capture the complexity and variability found in actual sparse-view scenarios. Secondly, in industrial contexts, new products frequently lack comprehensive full-view acquisitions. Our research focuses on methods that can generalize well from limited or sparse data. By using methods that do not solely rely on large, domain-specific datasets, we aim to improve the robustness and applicability of our models in diverse real-world scenarios, where obtaining such datasets might be impractical."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700250862680,
                "cdate": 1700250862680,
                "tmdate": 1700250862680,
                "mdate": 1700250862680,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "J6savExNGS",
                "forum": "vyGp9Mty2t",
                "replyto": "W19PMobRwu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comments by Authors"
                    },
                    "comment": {
                        "value": "> Q5: Comparison methods. Unfortunately, the authors do not compare their method against standard CNN-based methods (some of which are also mentioned in the introduction). In particular, the authors do not compare their method against approaches that implicitly (e.g., [2]), or explicitly (e.g., in the form of a DNN) incorporate prior knowledge. The authors also don't compare their method against other, previously proposed INR reconstructing techniques for sparse-view CT. \n\nOur study focuses on approaches that excel in sparse-data environments. We selected comparison methods aligned with this focus, aiming to demonstrate the effectiveness of our approach in scenarios where data is inherently limited or sparse. This includes avoiding comparisons with methods that rely heavily on full-view acquisitions, as these do not align with the primary objective of our research, which is to excel in limited data scenarios. We have added sentences to the introduction section for clearer elaboration: \u201cThere are also works that adopt heuristic image priors, e.g., Total Variation (TV) [4,5,6], or use dense view images as priors [2, 7] to assist in reconstruction. However, these methods often lack domain-specific enhancements or require information from dense-view images.\u201d\n\nWe acknowledge that our study did not include comparisons with standard CNN-based methods or approaches that implicitly or explicitly incorporate prior knowledge, such as the ones mentioned in [2]. The primary focus of our research was to explore the potential of Implicit Neural Representations (INRs) in utilizing the statistical regularities shared among different objects with similar representations to enhance CT reconstruction quality through joint reconstruction. Therefore, we primarily concentrated on comparing our method with other prior-embedding INR-based methods that align closely with our research question as stated in the introduction. We have revised the last sentence of the introduction to better reflect the scope of our work and the research question posed: \u201cOur results establish that our method either outperforms or is competitive with existing INR-based baselines.\u201d This aligns with our initial inquiry: \u201cCan INRs utilize the statistical regularities shared among different objects with similar representations to enhance reconstruction quality through joint reconstruction?\u201d\n\nRegarding [2], it proposes an intriguing method of incorporating prior information from a previous image within a compressed sensing framework for 4DCT. While this approach is practically feasible for 4DCT, where scanning angles of different phases can be interleaved to form a dense-view reconstruction, it does not necessarily translate to our intra-patient and inter-patient settings. In these scenarios, even if the scans are conducted with interleaved angles, the substantial differences between the images can make it challenging to construct a cohesive and informative dense-view prior. This difference in the nature of the data and the specificities of our research focus led us to prioritize comparisons within the scope of INR-based methods.\n\nOur study compares our method with a diverse range of techniques, including classical methods like FBP and SIRT, as well as advanced INR-based approaches like Single INR [8][9], FedAvg[11], MAML[10], and INRWild[12]. We also add a new baseline Nerp in Appendix F.7 in the revision. Our selection of comparison methods was driven by the desire to demonstrate the effectiveness of our approach across a spectrum of techniques, from classical to the latest INR-based methods. We thank the reviewer for also acknowledging our exhaustive literature review, as we believe this diverse comparison set provides a comprehensive assessment of our method's capabilities in handling sparse-view CT reconstruction challenges. If the reviewer thinks there is any relevant INR for sparse-view CT that we have missed, we would be very happy to receive this feedback for incorporation during the discussion period or later. Comparing our method against a broader range of techniques, including other prior incorporation methods, are interesting for us as future work."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700250925491,
                "cdate": 1700250925491,
                "tmdate": 1700250925491,
                "mdate": 1700250925491,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BrfNXU7yOt",
                "forum": "vyGp9Mty2t",
                "replyto": "W19PMobRwu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comments by Authors"
                    },
                    "comment": {
                        "value": "> Q6: Over what is the mean standard deviation computed?\n\nThe mean and standard error reported in our study are computed over all reconstructed images of our experiments, taking into account both random initializations and variations in image selections.\n\nFor instance, in the case of the 4DCT dataset, which has dimensions of 10x136x512x512, we perform joint reconstructions using groups of 10 images, each being 512x512 in size. To ensure a diverse set of data, we randomly select these images from indices ranging between 20 and 120 within the dataset. This approach yields a substantial sample size for each experiment, specifically, we calculate the mean and standard error across 1,000 images (10 images per group across 100 groups).\n\nWe appreciate your feedback as it highlighted the need for clearer explanation in our manuscript. To address this, we added the sentence \u201cWe calulate mean and standard error over all reconstructioned images in each experiment.\u201d in the metrics subsection of section 5 (Experiments), offering a more detailed account of how these statistical measures were derived.\n\n> Q7: Are the improvements statistically significant? \n\nTo rigorously evaluate the statistical significance of our method's improvements, we conducted a Wilcoxon signed-rank test comparing our results with those of the second-best method. The obtained p-values, being less than 0.05 in most cases, strongly suggest that these improvements are indeed statistically significant. For clarity and transparency, we present the detailed Wilcoxon signed-rank test results below:\n\n| Experiment | Sample Size | Second Best Method | W-statistic (PSNR) | P-value (PSNR) | W-statistic (SSIM) | P-value (SSIM) |\n|------------|-------------|--------------------|--------------------|----------------|--------------------|----------------|\n| Intra-patient | 950 | MAML | 13252 | 2.16e-139  | 1617 | 7.72e-155 |\n| Inter-patient Lung | 100 | MAML | 348 | 7.14e-14 | 67 | 2.88e-17 |\n| Inter-patient Brain| 50 | MAML | 614 | 0.83 | 597 | 0.70 |\n| 4DCT | 1000 | FedAvg | 186785 | 3.73e-12 | 4689 | 3.79e-159 |\n| Adapt to new patient | 50 | MAML | 21 | 7.94e-13 | 0 | 1.78e-15 |\n\nWe have now highlighted in bold the results of both MAML and our method in Table 1 row 5 (Inter-patient Brain)  to demonstrate their statistically significant improvement over other methods. We appreciate your valuable feedback and hope that this additional analysis provides the necessary clarification.\n\n\n> Q8: It is well known that metrics such as SSIM and PSNR are often not in agreement with quality assessment by clinicians [3,4]. While I recognize that a thorough evaluation involving a reader study is beyond the scope of this work, I don't think the results in Tab. 1 justify the authors claim that their method 'sets a new standard in CT reconstruction performance' (Abstract). Upon visual inspection of Fig. 2 & 3, I find that the proposed method removes many anatomical details and I highly doubt that a clinician would find that reconstructions produced by INR-Bayes are significantly better than those produced by e.g. SingleINR.\n\nWe concur that PSNR and SSIM metrics may not always align with practical clinical assessments and acknowledge that incorporating human evaluation falls outside the scope of this paper and the ICLR conference. In evaluating our framework, it was necessary to select certain metrics for numerical comparison with other methods. Therefore, we chose PSNR and SSIM, which remain widely accepted and standard in both the machine learning and medical imaging fields, as evidenced by references [13], [14], [15], [16]. While we recognize that these metrics are not flawless, we believe that their limitations should not be viewed as a fundamental weakness of our paper.\n\nTo address your concerns, we have introduced a new section on limitations in our conclusion, highlighting the potential discrepancies between numerical metrics and clinical evaluations. The new limitation section now is: \"We recognize that the metrics employed in our study may not always correlate with clinical evaluations [3][4]. If applied in a medical application, clinical verification of our method remains essential to understand its practical implications and efficacy in a given clinical setting.\" This addition aims to clarify the context and application of our findings. \n\nAdditionally, we have carefully revised the abstract to more accurately represent our study's results and scope. The updated abstract now is: \"Our results indicate marked advancements over baseline methods in standard numerical metrics, marking a progressive stride in CT reconstruction techniques.\" This revision aligns our claims with the evidence presented, while acknowledging the nuances of clinical applicability."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700250984202,
                "cdate": 1700250984202,
                "tmdate": 1700259053041,
                "mdate": 1700259053041,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QnlNSI2MDI",
                "forum": "vyGp9Mty2t",
                "replyto": "W19PMobRwu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comments by Authors"
                    },
                    "comment": {
                        "value": "> Q9: What is the computational complexity of the method?\n\nWe understand the importance of this aspect and have added a new section in the appendix that details the computation costs. For your convenience, we have replicated the information in Table 5 [here](https://openreview.net/forum?id=vyGp9Mty2t&noteId=CI64s0jmxF), which presents a comparative analysis of the computational requirements.\n\nDue to the increased model capacity and therefore higher optimization complexity, our method exhibits slightly higher computational costs compared to other methods, but the increase is relatively small (less than 10%). \n\n> Q10: Are all reconstructions performed for the main paper on single 512 \\times 512 slices? The application to CBCT reconstructions shown in the appendix is on a much smaller (clinically unusable) image matrix. What would the computational cost for one full patient be compared to the other methods and a CNN-baseline?\n\nRegarding the scope of our experiments, the main paper focuses primarily on slice-based analyses. For the 3D Cone-Beam Computed Tomography (CBCT) experiments presented in the appendix, we utilize volumes of size 128^3. This 3D experiment was designed as a proof-of-concept to demonstrate our method's applicability and effectiveness in a 3D context.\n\nWe acknowledge that the 128^3 volume size used in the 3D CBCT experiment is smaller than what is typically used in clinical settings. The choice of this size was primarily driven by computational constraints. For a comprehensive comparison, our experiments iterate over the whole dataset, which involves running hundreds of reconstructions across various methods. The total computational load is substantial. Thus, to manage these constraints effectively while still providing meaningful insights, we opted for smaller volume sizes for the 3D experiments. \n\nTo provide a clearer perspective on the computational aspects, we included a new section in the Appendix (E6) that compares the computational costs across various INR-based methods, including our own. We also copied the comparison table [here](https://openreview.net/forum?id=vyGp9Mty2t&noteId=CI64s0jmxF) for your easier reference. While this comparison uses slice-based experiments, it offers a framework to extrapolate potential computational costs for larger, clinically relevant volumes.  \n\nWe hope this information clarifies your queries regarding the computational complexity and the scope of our experiments. We are continually working towards optimizing the method to handle larger volumes more efficiently.\n\n> Q11: The experiment configurations intra-patient and 4DCT violate the conditional independence assumption. Does this influence reconstruction quality?\n\nThe conditional independence assumption allows us to decompose the variational inference problem related to the joint posterior distribution across objects. This assumption significantly simplifies the model and is instrumental in deriving an efficient algorithm for our Bayesian framework. Our experiments have shown that the INR-Bayes framework performs robustly in 4DCT and intra-patient configurations, producing high-quality reconstructions. This indicates that the framework\u2019s capability to learn complex representations effectively compensates for any limitations introduced by the conditional independence assumption."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251036798,
                "cdate": 1700251036798,
                "tmdate": 1700251036798,
                "mdate": 1700251036798,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tAJDfNUItu",
                "forum": "vyGp9Mty2t",
                "replyto": "W19PMobRwu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comments by Authors"
                    },
                    "comment": {
                        "value": "We appreciate your insightful feedback and have diligently addressed the concerns raised. We hope that our revisions and clarifications demonstrate the robustness and relevance of our work, and we respectfully invite you to re-evaluate our submission in light of these updates."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251117518,
                "cdate": 1700251117518,
                "tmdate": 1700251786406,
                "mdate": 1700251786406,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pTDCpWW5Zr",
                "forum": "vyGp9Mty2t",
                "replyto": "W19PMobRwu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comments by Authors"
                    },
                    "comment": {
                        "value": "[4] Sidky and Pan, Image reconstruction in circular cone-beam computed tomography by constrained, total-variation minimization, Physics in Medicine & Biology, 2008\n\n[5] Liu et. al, Total variation-stokes strategy for sparse-view x-ray ct image reconstruction, Trans. Medical Imaging, 2013\n\n[6] Zang et al, Super-resolution and sparse view ct reconstruction, ECCV 2018\n\n[7] Shen et. al, Nerp: implicit neural representation learning with prior embedding for sparsely sampled image reconstruction. Trans Neural Networks and Learning Systems, 2022.\n\n[8] Zha et. al, Intratomo: self- supervised learning-based tomography via sinogram synthesis and prediction, CVPR 2021\n\n[9] Zhang et. al, Naf: Neural attenuation fields for sparse-view cbct reconstruction, MICCAI 2022\n\n[10] Tanick et. al, Learned initializations for optimizing coordinate-based neural representations, CVPR 2021\n\n[11] Kundu et. al, Panoptic neural fields: A seman- tic object-aware neural scene representation, CVPR 2022\n\n[12] Martin-Brualla et. al, Nerf in the wild: Neural radiance fields for unconstrained photo collections, CVPR 2021\n\n[13] Song et. al, Solving Inverse Problems in Medical Imaging with Score-Based Generative Models, ICLR 2023\n\n[14] Wu et. al, Unsupervised Polychromatic Neural Representation for CT Metal Artifact Reduction, NIPS 2023\n\n[15] Zhou et. al, dudoufnet:  Dual-Domain  Under-to-Fully-Complete  Progressive  Restoration  Network  for  Simultaneous  Metal  Artifact  Reduction  and  Low-Dose  CT  Reconstruction, Trans. Medical Imaging, 2022\n\n[16] Hu et. al, dior:   Deep   Iterative   Optimization-Based   Residual-Learning   for   Limited-Angle   CT   Reconstruction, Trans. Medical Imaging, 2022"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251160552,
                "cdate": 1700251160552,
                "tmdate": 1700501383268,
                "mdate": 1700501383268,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8NMrBftqHH",
                "forum": "vyGp9Mty2t",
                "replyto": "W19PMobRwu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal follow up"
                    },
                    "comment": {
                        "value": "As we are now approaching the end of the reviewer-author discussion\nperiod, we would like to follow up on our rebuttal response and gently\nremind you to provide your valuable feedback.\n\nWe are keen to know if our response and improvements address your\nconcerns and satisfy you. Furthermore, we would like to confirm if there\nare any further concerns or questions you may have regarding our work,\nwe are more than willing to engage in a productive discussion during the\nreviewer-author period.\n\nThank you for your valuable input and time."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700567075805,
                "cdate": 1700567075805,
                "tmdate": 1700567075805,
                "mdate": 1700567075805,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "AqCMcGzg2A",
                "forum": "vyGp9Mty2t",
                "replyto": "8NMrBftqHH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5462/Reviewer_ufhh"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5462/Reviewer_ufhh"
                ],
                "content": {
                    "comment": {
                        "value": "I would like to thank the authors for providing such a detailed rebuttal which addresses some of my concerns. I still have some comments and questions:\n\nI still think that the authors use misleading writing also in the new paragraphs:\n> [...] This approach can also expedite the scanning process, potentially reducing wait times and increasing patient throughput in busy clinical settings. It can also potentially reduce the cost by lowering operational costs associated with extended scanner usage. In industrial applications, where CT scanners often operate continuously in production environments, reducing scanning angles can significantly enhance efficiency. Shorter scan times increase throughput and reduce operational delays, directly impacting productivity.\n\nCan the authors comment on why scanning from fewer angles reduces acquisition times in practice? The CT spins continously at over 100 rpm. The amount of projections acquired should not influence scan time at all (at least for clinical CT, for nondestructive testing this could make a difference). The only factor that can really reduce cost is reconstruction time. Is this faster for the authors method compared to an FBP from the full set of projections? Am I correct in assuming that the numbers in the newly added Table 5 refer to reconstruction of 10 images @ $512\\times 512$ each? If this really takes 10 hours with the proposed method it clearly is impractical and would in fact substantially increase cost. It would mean that reconstructing e.g. chest CTs (usually having about 200 slices each) from 10 patients would require approximately 83 days... Can the authors comment on the computation time of the iterative reconstruction? It should be on the order of few hours for the entire 3D scan and thus 2 orders of magnitude faster. And iterative reconstruction is considered to be too slow for many clinical settings (e.g. for use in ER). If the proposed method really is this slow, this needs to be mentioned as a **major** limitation in the discussion.\n\n> This less than 10% increase in time is attributed to the added model capacibility and the Gaussian noise sampling procedure in INR-Bayes. However, considering the enhanced reconstruction quality and robustness achieved, this additional time investment can be justified.\n\nIn light of the point above, I find this newly added statement in the appendix highly misleading. A reader could think that this is an adequate reconstruction time, when in fact it is not. Why didn't the authors add times for FBP and the iterative (SART, I don't know why the authors call it SIRT instead) algorithm? FBP should take < 1s and iterative <1min for a single slice, so several orders of magnitude faster than the proposed (and all INR) method.\n\n> While simulated sparse-view datasets derived from full-view acquisitions provide a valuable resource, they may not fully capture the complexity and variability found in actual sparse-view scenarios\n\nI don't quite understand what the authors mean with this point. Only using every $n^{\\text{th}}$ projection models the system perfectly.\n\n> We acknowledge that the 128^3 volume size used in the 3D CBCT experiment is smaller than what is typically used in clinical settings. The choice of this size was primarily driven by computational constraints. For a comprehensive comparison, our experiments iterate over the whole dataset, which involves running hundreds of reconstructions across various methods. The total computational load is substantial. Thus, to manage these constraints effectively while still providing meaningful insights, we opted for smaller volume sizes for the 3D experiments.\n\nI would like to thank the authors for this clarification. How many datasets were included in the 3D CBCT experiments (unfortunately, I couldn't find this information in the appendix)? I still don't think that evaluating SSIM or PSNR on such small volumes makes much sense since it is extremely far from clinical practice."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5462/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700582579920,
                "cdate": 1700582579920,
                "tmdate": 1700582579920,
                "mdate": 1700582579920,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]