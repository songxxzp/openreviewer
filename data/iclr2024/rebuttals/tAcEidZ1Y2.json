[
    {
        "title": "Self-supervision Meets Bootstrap Estimation: New Paradigm for Unsupervised Reconstruction with Uncertainty Quantification"
    },
    {
        "review": {
            "id": "yeAwAL4jaO",
            "forum": "tAcEidZ1Y2",
            "replyto": "tAcEidZ1Y2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7561/Reviewer_FBWg"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7561/Reviewer_FBWg"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a novel self-supervised MRI reconstruction paradigm in which the reconstruction process is modeled as parameter estimation, leveraging the idea of bootstrapping. To mitigate the high variance incurred by randomly generating a sample set, this paper proposes to get the distribution of the observations by mapping the observation to a virtual sample set. The authors conduct both theoretical and empirical analyses for the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The idea is novel and interesting. \n2. The demonstrated equivalence between the sample set bootstrapping and the re-undersampling is inspiring. \n3. The results are promising to an extent. \n4. The paper is well written."
                },
                "weaknesses": {
                    "value": "1. It is highly expected that the paper includes a comparison with other typical methods for MRI reconstruction, such as [1] and [2]. Although the authors argue that deep learning models may suffer from unreliability, as the fast growing of vision transformers, their appealing performance should not be ignored. Thus, a comparison with such methods will make the results more convincing. Although these methods may not focus on zero-shot, the testing performance can still be compared. \n\n2. I think the paper lacks a discussion of the differentiability of the aggregation function h. Although the classical MSE loss is differentiable, due to the use of the aggregation function in the MSE which is adopted to train a model, the authors are highly encouraged to discuss the differentiability of the aggregation function. \n\nReference\n\n[1] https://proceedings.mlr.press/v172/lin22a/lin22a.pdf\n[2] http://proceedings.mlr.press/v139/fabian21a/fabian21a.pdf"
                },
                "questions": {
                    "value": "1. Is the uncertainty in this paper partially from the resampling operation due to the use of bootstrap? More insights will be helpful. \n\n2. Although reconstruction is an important topic in MRI, are there any other reasons that make the proposed method tie to MRI reconstruction? In other words, whether the proposed method is suitable for potential reconstruction tasks in natural image domains?\n\n3. Is that possible to use the Monte Carlo method in this work?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7561/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7561/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7561/Reviewer_FBWg"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7561/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698338177834,
            "cdate": 1698338177834,
            "tmdate": 1700508260657,
            "mdate": 1700508260657,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1JmE7knYEl",
                "forum": "tAcEidZ1Y2",
                "replyto": "yeAwAL4jaO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7561/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7561/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are really grateful for your recognition of our work and contributions. Below, we address your suggestions and comments.\n\n**Reply to Weaknesses**\n- While we would love to add more comparison with other advanced MRI reconstruction methods, unfortunately, it requires substantial time and access to their original codes (some are not shared though) for an informed and detailed comparison. We add citations to these referred papers, and will further explore them in our future work.\n- The differentiability of the aggregation function becomes a main concern in our derivation but we found it operable for  backpropagation and thus it won\u2019t influence the optimization. For example:\n   - With or without the aggregation function, the gradients of the reconstruction model parameterized by $\\theta$ are always: \n$$\\frac{\\partial{\\mathcal{L}}}{\\partial{\\theta}}=\\frac{\\partial{\\mathcal{L}}}{\\partial{f_{AF}}}\\frac{\\partial{f_{AF}}}{\\partial{f}}\\frac{\\partial{f}}{\\partial{\\theta}}=\\frac{\\partial{\\mathcal{L}}}{\\partial{f}}\\frac{\\partial{f}}{\\partial{\\theta}}$$\n   - As for the gradients of $y$ and $U$, we add an explanation after Equation 7, that aggregation function results in a re-undersampling mask which may not influence the differentiability to $y$. The gradients of $U$, on the other hand, may be influenced, but they are not optimized for MRI reconstruction, thus it may not a problem.\n\n**Reply to Questions**\n- In the original version of our paper, uncertainty has been limited to the randomness of undersampling, while the Bootstrap resampling actually \u201csimulates\u201d it. It\u2019s true that for the reconstruction of re-undersampled images, Bootstrapping incorporates uncertainty, but in inference, no re-undersampling will be conducted.\n- We\u2019re extending our work as we discussed in Conclusion. There would be a trivial extension that applies virtual sample and pseudo resampling in similar tasks related to Compressed Sensing. Other image-to-image translation tasks like super-resolution and deblurring could also benefit from our work by defining virtual sample sets in particular domains. We\u2019re open to further comments. \n- At this stage, Mote Carlo method would not be appliable as it incorporates sequential sampling and requires extra control for the  re-undersampling purpose, etc. We will further explore this idea.\n\n\nThank you very much and please let us know if you have any further comments."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7561/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700434327315,
                "cdate": 1700434327315,
                "tmdate": 1700464730797,
                "mdate": 1700464730797,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2l2G9PN09Q",
                "forum": "tAcEidZ1Y2",
                "replyto": "1JmE7knYEl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7561/Reviewer_FBWg"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7561/Reviewer_FBWg"
                ],
                "content": {
                    "comment": {
                        "value": "The authors\u2019 response addresses most of my concerns. However, I still think it would be more convinced to include comparisons with other advanced MRI reconstruction methods. I know adding this would be extremely challenging due to the short rebuttal window, but I think it is very necessary to include them in the future revisions. Seems the authors also plan to do so."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7561/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700508243048,
                "cdate": 1700508243048,
                "tmdate": 1700508243048,
                "mdate": 1700508243048,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "03dJNYZMSQ",
            "forum": "tAcEidZ1Y2",
            "replyto": "tAcEidZ1Y2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7561/Reviewer_n9iq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7561/Reviewer_n9iq"
            ],
            "content": {
                "summary": {
                    "value": "This paper interprets a popular self-supervised MRI reconstruction approach: self-training with secondary undersampling [1,2], as bootstrapping. The repeated secondary undersamplings are modeled as a virtual sample set, and the secondary sampling masks are aggregated as a sampling distribution for bootstrapping. The authors then propose to use the bootstrapped error to estimate the true underlying reconstruction error. Qualitative results are shown on public MRI datasets and some correlations between estimated errors and the true underlying errors can be observed."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The problem of estimating the error in MRI reconstruction is of practical value. It links to the trustworthiness of deep learning based image reconstruction. \n \nThe authors link the secondary undersampling technique [1,2] to bootstrapping. This is a very interesting interpretation. \n\nCorrelations between estimated reconstruction errors and the true underlying reconstruction errors can be observed."
                },
                "weaknesses": {
                    "value": "An important prior work [3] for modeling aleatoric and epidemic uncertainties for deep learning MRI reconstruction is missing. \n \nThe detailed approach and its mathematical framework of the prior works: self-supervised MRI reconstruction using self-training on secondary undersampling [1,2], need to be introduced in Sec. 2, as they are the basis for the entire manuscript. \n \nThe manuscript in general lacks clarity: it is difficult to find the key arguments and the core take-home information from the abstract and the introduction. \n \nThe writing style is also sloppy with key concepts arbitrarily named, used, but left unexplained. E.g., the first paragraph of Sec. 3.2: the narration is quite casual. Also, what does the paragraph under Eq. 8 mean? What does the starting paragraph in Sec. 4.3 mean? This sloppy writing may make readers who are not familiar with secondary undersampling based MRI reconstruction, extremely difficult to follow. The writing does not meet the high standards of ICLR. \n \nDespite the interesting interpretation of bootstrapping, the manuscript does not make significant theoretical/methodological breakthroughs beyond the existing secondary undersampling based MRI reconstruction approaches [1,2], not to mention that secondary undersampling is not the only approach for unsupervised/zero-shot MRI reconstruction and/or error estimation. \n \nSec. 5.2: There is a lack of quantitative evaluation of the quality of error estimations. The authors also fail to compare with the well-established Bayesian deep learning based image reconstruction [3]. Notebly, unlike the proposed approach, Bayesian deep learning allows to explicitly separate aleatoric uncertainty and epistemic uncertainty. \n \n[1] https://arxiv.org/abs/2102.07737 \n \n[2] https://www.sciencedirect.com/science/article/abs/pii/S1361841522001852 \n \n[3] https://link.springer.com/chapter/10.1007/978-3-030-00129-2_8"
                },
                "questions": {
                    "value": "Is the most fundamental assumption mentioned at the starting of the manuscript: modeling U as independent Bernoulli\u2019s, unrealistic? In practice sampling patterns are subjects to the physical constraints of the gradient system of the scanners, and the resultant sampling patterns (both original and secondary) are by no means independent.  \n\nThe authors are suggested to improve the clarity of writings and illustrations."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "This study is mostly based on public datasets and the authors need to check the terms and conditions by the owners of the datasets."
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7561/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7561/Reviewer_n9iq",
                        "ICLR.cc/2024/Conference/Submission7561/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7561/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698444997016,
            "cdate": 1698444997016,
            "tmdate": 1700600818091,
            "mdate": 1700600818091,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "UAsUYx3bGb",
                "forum": "tAcEidZ1Y2",
                "replyto": "03dJNYZMSQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7561/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7561/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your detailed comments. In response, we provide explanations below.\n\n**Response to Weakness**\n- Thank you for pointing out the missing reference. In this revision, we add the discussions about it.\n- Figure 1 presents the pipeline, and we add math equations to Section 2. We further add brief introduction to some SSR methods to Appendix E.\n- The paper is substantially reorganized responding to the related comments, including enhancing clarity and explanations. For take-home information, we argue and evidence that self-supervised MRI reconstruction can be modeled as error-oriented parameter estimation, accordingly we introduce a novel method - Bootstrap estimation for SSR (BootRec). \n- We polish the paper per your related comments.\n\nAbout the contribution of our work:\n-  We emphasize the key attributes of our methodology in a new section - Section 4.3.\n-  As mentioned in the introduction and related work parts, the existing methods are mostly heuristic in their design. Our method makes a meaningful trial to answer the following questions with reasons beyond \"it just works\":\n- Why use **this re-undersampling mask** instead of others?\n- Why use **this loss function** instead of others?\n- The re-undersampling methods, though not the only methods in SSR, it outperforms other models in similar settings [1,2], and our methods are also compared with other types of unsupervised approaches like Deep Imaging Prior.\n\n- Thank you for providing useful information on MRI UQ. The uncertainty quantification part in our work is not the focused claim, we instead focus on the estimation of errors, so the notions become different from [3]. We instead compare our methods with error-oriented UQ in Appendix G, which shares the idea of training a separated network or module to predict uncertainty. Besides, although our methods do not include epistemic uncertainty in the design, it can cooperate with any such methods, including the Bayesian Neural Network in [3], and it is training-free. A detailed comparison and assessment in terms of UQ goes beyond this paper, thus we focus on reconstruction.\n\n**Response to Questions**\n- It\u2019s a very good question to challenge the distribution of U. While the assumption of Bernoulli is a common deed in MRI communities, like the diagonal covariance matrix assumption in UQ and other tasks, it\u2019s not satisfactory. Also, a 1D Cartesian mask may be ideal in the dimension of sampling, and in other cases, different points do have correlations. However, even if the sampling points are not independent, we may always find some \u201cnearly independent elements\u201d in the acquisition, such as the radial tracings in radial sampling or to conduct methods like whitening to reduce the correlation. As for the re-undersampling pattern, we believe we can guarantee independence.\n- The paper is reorganized according to the related comments.\n\n[1] Zero-shot self-supervised learning for mri reconstruction. In International Conference on Learning Representations, 2022.\n\n[2] Parcel: Physics-based unsupervised contrastive representation learning for multi-coil mr imaging. IEEE/ACM Transactions on Computational Biology and Bioinformatics, 14(8):1\u201312, oct 2022b. ISSN 1557-9964. doi: 10.1109/TCBB.2022.3213669.\n\n[3] Bayesian Deep Learning for Accelerated MR Image Reconstruction. MLMIR 2018\n\n[4] Uncertainty Quantification in Deep MRI Reconstruction"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7561/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700431815487,
                "cdate": 1700431815487,
                "tmdate": 1700461416082,
                "mdate": 1700461416082,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0UmDlTNWp4",
                "forum": "tAcEidZ1Y2",
                "replyto": "UAsUYx3bGb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7561/Reviewer_n9iq"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7561/Reviewer_n9iq"
                ],
                "content": {
                    "comment": {
                        "value": "I would like to thank the authors for the substantial revision of the paper. Some of my concerns are addressed but others remain:\n\n- Major contributions: resampling-based SSL reconstruction itself (by Yaman et al.) might not be counted as a major contribution of your work. Instead, if I interpreted correctly, the major contribution should be its bootstrapping interpretation, in together with its utility for error quantification.\n\n- I am not fully convinced about the reason why estimating MSE would bring more clinical benefit than estimating aleatoric and epistemic uncertainties? Given that these two uncertainties have straightforward real-world interpretations of different aspects/sources of uncertainty.\n\n- I am still not fully convinced why error quantification for a very specific algorithm (k-space re-sampling) for a very specific task (self-supervised learning for deep learning MRI reconstruction) would be of sufficient interest to most of the readers of ICLR, despite that re-sampling may be the state-of-the-art approach for that very specific task for now. What do the authors think to be the broader impact of the proposed work?\n\n- Appendix G should be put forward into the main text."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7561/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700600350836,
                "cdate": 1700600350836,
                "tmdate": 1700600350836,
                "mdate": 1700600350836,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bDtUWevG6b",
                "forum": "tAcEidZ1Y2",
                "replyto": "03dJNYZMSQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7561/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7561/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your kind response.\n\n- The interpretation is among the key aspects of our work. Indeed, we never claim the contribution of proposing re-undersampling or introducing self-supervision in MRI reconstruction.\n- The field of uncertainty quantification is not very familiar to us so I may not be qualified to judge different uncertainty notions in this paper. In our observation, the errors seem to be more explicit and easier to judge since we can get the GT values. Further studies will be beneficial and thanks to your valuable perspective.\n- Please be aware that our quantification leverages re-undersampling but is not limited to SSR tasks (Section 5.2 and Appendix G conduct estimations on arbitrary models). In fact, we observe minimal constraints associated with applying our methodology and find broader applications (see our discussion with reviewer FBWg) in self-supervised learning of image-regression tasks, though with limited space to extend the discussion.\n- We'd make a final revision of our paper if possible."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7561/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700631022915,
                "cdate": 1700631022915,
                "tmdate": 1700654269692,
                "mdate": 1700654269692,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qPNfVKkSWQ",
            "forum": "tAcEidZ1Y2",
            "replyto": "tAcEidZ1Y2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7561/Reviewer_4bq6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7561/Reviewer_4bq6"
            ],
            "content": {
                "summary": {
                    "value": "The paper titled: Self-supervision Meets BOOTSTRAP Estimation: New Paradigm for Unsupervised Reconstruction with Uncertainty quantification proposes a novel SSR methods with BootStraping for MRI reconstruction, with the ability of uncertainty estimation and quantification."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Uncertainty quantification for MRI reconstruction is an open problem, based on my knowledge, I think this paper is the first one to quantify MRI uncertainty in an unsupervised or self-supervised manner from under-sampled MRI.\n\n2. I like the idea of using BootStrap to resample the undersampling pattern, and from the Figure 7 plots, the results outperform SSDU and other SOTAs in terms of quantitative metrics.\n\n3. The algorithm is well-written and delivered."
                },
                "weaknesses": {
                    "value": "1. I think one of my biggest concerns is how the proposed method compared with other existing approaches for uncertainty quantification, there have been a wide range of works on this topic, they are either sampling based [Uncertainty Quantification in Deep MRI Reconstruction] or directly estimation the absolute residual error [Rigorous Uncertainty Estimation for MRI Reconstruction], this paper lack the comparisons with other approaches, please discuss/cite them. \n\n2. For the reconstruction results, the authors only showed an PSNR and SSIM plot (Figure 7) without any visual results to inspect on the details, the only visual results is Figure 5, which also doesn't deliver much information. I think this paper demonstrates a proof-of-concept, but lack evaluations.\n\n3. What is the purpose of estimating MSE, this can be generalized to an open question, how to use the uncertainty estimation results for diagnosis, I can imagine it would be useful if we compute uncertainty in latent space, but could you elaborate on how to use uncertainty estimation for down-stream task?\n\nOne inspiring paper of quantifying theoretical results of uncertainty estimation is: [https://arxiv.org/abs/2202.05265 Image-to-Image Regression with Distribution-Free Uncertainty Quantification and Applications in Imaging], you maybe able to get some insights from."
                },
                "questions": {
                    "value": "1. How to quantitatively evaluate the quality of your uncertainty estimation results."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7561/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7561/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7561/Reviewer_4bq6"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7561/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698704342303,
            "cdate": 1698704342303,
            "tmdate": 1699636914900,
            "mdate": 1699636914900,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "05uKxdqjZj",
                "forum": "tAcEidZ1Y2",
                "replyto": "qPNfVKkSWQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7561/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7561/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your recognition of the novelty of our work, as well as to your helpful suggestions. \n\nAs we clarify in the summary of changes to all reviewers, our focus of this work is not on the Uncertainty Quantification (UQ). In the revision, we reorganize the paper for more focus on proposing a novel reconstruction method. Below, we address your specific comments.\n\n**The evaluation of UQ**\n- We add more discussion on UQ in the section on Related Work while focusing our quantification on MSE estimation in UQ. We also discuss the work you referred to. The UQ in our work is specifically referred to error estimation.\n- We compare the estimation of MSE with residual magnitude regression of the recommended work [Image-to-Image Regression with Distribution-Free Uncertainty Quantification and Applications in Imaging] (which should cover the family of similar methods) and SURE estimation of [Uncertainty Quantification in Deep MRI Reconstruction] in Appendix F. Unfortunately we cannot compare our work with the method in [Rigorous Uncertainty Estimation for MRI Reconstruction] because we do not have access to that paper's materials. We are investigating the implementation of more methods and further analysis may also be added later.\n- For evaluation metrics, we find the correlation between the estimated and actual MSE serving as a good indicator for MSE-based UQ, since the ground truth is clear. Other existing evaluation measures mainly focus on variance and quantiles, so we are not able to use them.\n\n**Visual Presentation of Reconstruction Results**\n- Visual examples including the reconstruction results and error maps are added to Figure 8 in the revised paper.\n\n**The application of UQ**\n- Specifically for our work, the purpose of estimating MSE has a rather simple and special answer: that is to optimize it. That\u2019s the core idea of our proposed self-supervised MRI reconstruction method, please refer to Section 5.3. Please be noted, this may not be generalized to other UQ notions or methods since they may either need training itself or be not suitable for optimization.\n- The application of general UQ is worthy of discussion. We add a brief discussion at the beginning of Section 2.3a."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7561/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700430719436,
                "cdate": 1700430719436,
                "tmdate": 1700509095741,
                "mdate": 1700509095741,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9ypWbewnFJ",
            "forum": "tAcEidZ1Y2",
            "replyto": "tAcEidZ1Y2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7561/Reviewer_tf3c"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7561/Reviewer_tf3c"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a novel self-supervised approach for MRI reconstruction using bootstrap sampling. The method involves re-subsampling the undersampled k-space, reconstructing each resampled measurement, and formulating a loss function based on the reconstruction of the original measurement and the mean squared error of the resampled reconstruction."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The approach presents an innovative concept and demonstrates commendable performance. Notably, the training loss trajectory aligns consistently with that of training on self-supervised MSE, as shown in Figure 6."
                },
                "weaknesses": {
                    "value": "The primary challenge with this paper lies in its presentation, making it difficult for readers to follow. Some issues include:\n- Excessive Equations and Notations: The paper is overwhelmed with equations and notations, overshadowing the fundamental concept. The core idea appears to be sampling, but the multitude of equations adds unnecessary complexity without aiding comprehension.\n- Confusing Notations: Notations like the two 'U's in Equation (6) are ambiguous and visually similar, leading to confusion and hindering understanding.\n- Unexplained Figures: Figures, such as Figure 4, lack detailed explanations, leaving readers without essential context to interpret the visual data.\n- Lack of Explaining Prior Works: Assumptions about the reader's familiarity with existing work, especially (Yaman, 2022)'s zero-slot learning, create gaps in understanding. The absence of pertinent details hampers comprehension.\n\nI suggest the authors clean up the notation, reformat this paper, add more details, and make resubmission to another conference.\n\nAnother concerns the authors might take into consider for improving this paper:\n- Unclear Significance of Variance: The paper lacks clarification on why the variance (uncertainty) of bootstrap resampled reconstruction is important. Address the relevance of this aspect, especially in comparison to uncertainty quantification for raw measurement reconstruction.\n- Theoretical Foundation: While the paper claims to provide a \"theoretical foundation,\" it predominantly relies on equations without substantive theoretical analysis. A more comprehensive exploration of the theoretical underpinnings is essential to substantiate this claim."
                },
                "questions": {
                    "value": "See the weakness part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7561/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7561/Reviewer_tf3c",
                        "ICLR.cc/2024/Conference/Submission7561/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7561/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698714379543,
            "cdate": 1698714379543,
            "tmdate": 1700697074913,
            "mdate": 1700697074913,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9bsiHtxpqo",
                "forum": "tAcEidZ1Y2",
                "replyto": "9ypWbewnFJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7561/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7561/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate your comments. We made major revisions to address your comments and enhance the paper's readability. Here we provide the point-to-point responses.\n\n**Reply to Weaknesses**\n- We add a note to the Introduction section directing readers to the table of notations in the appendix. The equations in the main content are largely reduced as well (from 25 to 16).\n- Do you mean the Us in Equation(5)? The two $$U$s refer to the \u201crandom variable\u201d and \u201cvector value\u201d of the mask $U$ with display styles provided by the ICLR formatting instructions. Anyway, we remove the equations.\n- We add explanations to the figures. Specifically, for Figure 4 in the original submission (i.e., Figure 5 in this revision), it shows the correspondence of the estimated results v.s. the actual values.\n- We add a new figure - Figure 1 - to summarize the framework of MRI reconstruction, which may help explain our work better. The detailed settings of the previous methods are provided in Appendix F.\n\n**Further replies to the concerns:**\n- We agree and notice the inclusion of variance estimation becomes redundant and compromises the integrity of the article. Such discussion may be pertinent to another independent research.\n- We will work on more theoretical analysis. \n- The abstract is revised.\n\nWe would greatly appreciate if you could kindly revisit the entire manuscript at your convenience, in particular, check our significant revision. Please let us know if you have any further comments."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7561/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700430305201,
                "cdate": 1700430305201,
                "tmdate": 1700459488838,
                "mdate": 1700459488838,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MvozdZCzKv",
                "forum": "tAcEidZ1Y2",
                "replyto": "9bsiHtxpqo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7561/Reviewer_tf3c"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7561/Reviewer_tf3c"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the rebuttal"
                    },
                    "comment": {
                        "value": "I would like to thanks for the author's efforts to improve the manuscript.\n- **Presentation**: I think, after the revision, the presentation of this paper has been improved. Yet, I believe the authors could do a even better job if having more time than this discussion period. More suggestions: (a) In the new Figure 1, it is better to also include your own method; (b) It is easier for me to understand this paper by looking at the Appendix B and D, rather than the main paper. I think there is still room for the improvement of the presentation (in the main paper).\n- **Variance estimation**: Thanks for your response.\n- **Theoretical foundation**: When I wrote this comments, I did not mean that this paper must having a theoretical analysis. Many good papers do not have theoretical analysis. I just wanted to highlight that, if you don't provide valuable theoretical results, don't over-claim it in the paper.\n\nI will raise my score to reflect the authors' effort in this rebuttal. Thank you!"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7561/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700697041080,
                "cdate": 1700697041080,
                "tmdate": 1700697041080,
                "mdate": 1700697041080,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]