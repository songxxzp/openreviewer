[
    {
        "title": "ReweightOOD: Loss Reweighting for Distance-based OOD Detection"
    },
    {
        "review": {
            "id": "V84mzRSDQ4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission226/Reviewer_8LLh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission226/Reviewer_8LLh"
            ],
            "forum": "OJoMzslBIa",
            "replyto": "OJoMzslBIa",
            "content": {
                "summary": {
                    "value": "Out-of-distribution (OOD) detection has been widely studied. This paper focuses on the distance-based OOD detection with contrastive optimization methods. It points out that assigning equal significance to all similar pairs is not efficient in reducing the MES for each class and achieving higher inter-class dispersion. Therefore, this paper proposes ReweightOOD, a weight mapping function based on similarity, to prioritize hard positives and hard negatives. Experiments and visualization results show the proposed ReweightOOD surpasses the baseline and SOTAs by a large margin on FPR and AUROC."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "Based on the distance-based methods in OOD detection, this paper may first combine reweighting the hard samples with contrastive optimization.\n\nThe paper conducts explicit experiments on the influence the ReweightOOD brings to MES and inter-class dispersion. The results on CIFAR and ImageNet also verify its effectiveness."
                },
                "weaknesses": {
                    "value": "The novelty of this idea is quite limited. Designing different weights for hard samples has been widely applied in many fields including classification, detection, etc., and yields success. It can be directly accustomed to nearly all methods and will not result in depreciation at least.\n\nThe baseline chosen in this paper training a not-well-adjusted model to perform OOD Detection is quite unfair. As the proposed method is a loss function, it can be combined with other contrastive optimization methods easily. A method designed for OOD detection is more suitable to be a baseline. Therefore, it makes the results less convincing.\n\nThe important hyperparameters including the scaling and shifting scalars of the final linear transformation are not studied in the ablation experiments."
                },
                "questions": {
                    "value": "Why are the parameters of two linear transformation layers directly set to (5, -4, 2, 1) or (5, -2, 2, 1)?\n\nWhat is the reason for using a smaller shifting scalar from -2 to -4 when training with a smaller dataset CIFAR10?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission226/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697438305841,
            "cdate": 1697438305841,
            "tmdate": 1699635948389,
            "mdate": 1699635948389,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "I9DU6DGQym",
                "forum": "OJoMzslBIa",
                "replyto": "V84mzRSDQ4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission226/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission226/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer 8LLh"
                    },
                    "comment": {
                        "value": "We thank reviewer for their presented concerns which we address them below.\n\nIt's important to note that the primary focus is to demonstrate the effectiveness of our proposed method in OOD detection. Furthermore, we study the reweighting approach\u2019s efficacy for the first time in OOD detection. Such work in the domain has been missing, which makes our work novel in OOD detection. \n\nWe perform the comparison of our method with various approaches well suited for OOD detection. The key takeaway lies in the superior performance of our approach compared to competitive approaches like SupCon, CSI, and CIDER. Moreover, as presented in the paper, our work demonstrates the distinctively remarkable performance in comparison to strong post-hoc methods too. As requested by reviewer XxBj, we haver updated the manuscript with additional posthoc methods.\n\nThe hyperparameters are determined from the validation set.\n\nThe sensitivity study of these hyperparameters using ResNet18 network with CIFAR100 datasets is presented below.\n\n\n|$m_b$ | Average FPR | &#124; | $c_b$ | Average FPR | &#124; | $m_w$ | Average FPR | &#124; | $c_w$ | Average FPR | &#124;\n|----|--------------|-------|-----|--------------|-------|-----|--------------|-------|-----|--------------|-------|\n| 4  | 51.01        | &#124;| 1   | 44.96        | &#124;| 1   | 69.10        | &#124;| 1   | 38.36        | &#124;|\n| 5  | 38.36        | &#124;| 2   | 38.36        | &#124;| 2   | 38.36        | &#124;| 2   | 67.63        | &#124;|\n| 6  | 39.14        | &#124;| 3   | 52.66        | &#124;| 3   | 43.44        | &#124;| 3   | 70.84        | &#124;|"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700479753324,
                "cdate": 1700479753324,
                "tmdate": 1700479753324,
                "mdate": 1700479753324,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "gUgTGVxpnz",
            "forum": "OJoMzslBIa",
            "replyto": "OJoMzslBIa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission226/Reviewer_tSwH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission226/Reviewer_tSwH"
            ],
            "content": {
                "summary": {
                    "value": "This paper uses contrastive learning to address out-of-distribution (OOD) problems. The article introduces what contrastive learning is and discusses the challenges encountered by classical contrastive learning in tackling OOD problems. The authors believe that the main issue with contrastive learning in addressing OOD problems is that the discrimination between many difficult samples is not high enough, resulting in a close proximity among these challenging samples. As a result, it becomes difficult to recognize OOD samples. Therefore, the authors propose a reweighting approach to enhance the discrimination between different categories in contrastive learning, thereby improving the effectiveness of OOD detection."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The method proposed in this paper is simple and intuitive, and may be a good way to solve OOD problems.\n2. According to the author's experimental results, the proposed method can indeed improve the performance of OOD detection.\n3. The author's writing is very clear, and the description of the method section is easy to understand, combining formulas and diagrams."
                },
                "weaknesses": {
                    "value": "1. In the abstract, the author emphasizes that their method outperforms the baseline by 38%, which seems impressive. However, this improvement is mainly due to the low performance of the baseline method itself. The proposed method does not actually achieve such a significant improvement compared to the state-of-the-art (SOTA). In my opinion, this exaggerates the contribution of this paper. It would be better to clarify the improvement relative to SOTA in the beginning to avoid misleading the readers.\n\n2. The simplicity of the method itself can be considered an advantage. However, based on the experimental results, the improvement of this paper compared to the state-of-the-art is limited. Therefore, I hope the authors can further explore this direction and achieve more substantial advancements.\n\n3. The experiments conducted in this paper are not comprehensive enough. Firstly, experiments on complete ImageNet-1K were not conducted. Additionally, the comparison with the latest methods, such as those presented in recent conferences like CVPR 2023, was not included."
                },
                "questions": {
                    "value": "Please address the problem in weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission226/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698656392018,
            "cdate": 1698656392018,
            "tmdate": 1699635948311,
            "mdate": 1699635948311,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "w0WdgsJqFL",
                "forum": "OJoMzslBIa",
                "replyto": "gUgTGVxpnz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission226/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission226/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer tSwH."
                    },
                    "comment": {
                        "value": "We thank the reviewer for the suggestions. We address the concerns below.\n\n- We will clarify the improvement relative to the SoTA approaches by being more specific in the abstract in the upcoming versions. We believe the performance improvement compared to the current competitive approaches such as SupCon and CIDER is still significant. \n\n- Orthogonal to the papers presented in CVPR2023, our work has the distinction in that it adopts a reweighting approach which is novel to the best of our knowledge.\n\n- The ImageNet-1k experiments adopting the ImageNet100 setup is presented below:\n\n  | Method                 | iNaturalist | SUN  | Textures | Places | SSB Hard | Ninco | Openimage | Average **FPR** $\\downarrow$ |\n  |------------------------|-------------|------|----------|--------|----------|-------|-----------|--------------------------------|\n  | SupCon                 | 61.93        | 68.85 | 25.43     | 75.28   | 90.79    | 78.82 | 55.64      | 65.25                          |\n  | CIDER                   | 53.54        | 61.27 | 23.95     | 68.76   | 91.52    | 79.15 | 54.22      | 61.77                          |\n  | **(ReweightOOD) *Ours***| 50.70        | 59.46 | 24.27     | 66.27   | 90.18   | 76.76 | 50.97      | **59.80**                      |\n  \n  It can be observed that the proposed approach has noticeable gains over SupCon and CIDER demonstrating its superiority."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700479708951,
                "cdate": 1700479708951,
                "tmdate": 1700479708951,
                "mdate": 1700479708951,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KkVBSjDmm5",
            "forum": "OJoMzslBIa",
            "replyto": "OJoMzslBIa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission226/Reviewer_XxBj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission226/Reviewer_XxBj"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes some modifications to contrastive optimization-based OOD detection. Previous approaches assign equal importance to all similar instances. This paper proposes to give different weights to these instances and tries to enforce the minimum enclosing sphere and higher inter-class dispersions. Experiments on CIFAR100 and ImageNet 100 demonstrate the effectiveness of the proposed approach."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. The proposed method is very simple and intuitively makes sense. The idea of obtaining a minimum closure sphere makes sense to separate OOD and ID data, and it is also easy to implement this idea by adding weights to the loss functions."
                },
                "weaknesses": {
                    "value": "1. **There are many recent OOD baselines but they are not taken into consideration for comparison.** There are many recent OOD baselines but the authors either do not cite them [1,2,3] or do not add them in the comparison (e.g., ASH, GradNorm). In particular, these are very strong baselines and I see the performance of this method at the same level as ReAct. It is a bit strange that the evaluation does not involve any activation-clipping baselines such as ReAct and ASH (they are clear state-of-the-art methods and do not require any training). \n\n\n>[1] React: Out-of-distribution detection with rectified activations. NeurIPS 2021.\n>\n>[2] RankFeat: Rank-1 Feature Removal for Out-of-distribution Detection. NeurIPS 2022. \n>\n>[3] Boosting Out-of-distribution Detection with Typical Features. NeurIPS 2022. \n\n\n2. **The experiments are not sufficient only on CIFAR/ImageNet100.** The authors only validate the proposed approach on CIFAR100 and ImageNet100, which is far from sufficient and comprehensive. Usually, people evaluate OOD methods on CIFAR10, CIFAR100, and ImageNet-1k benchmarks. I would be convinced if the method also works for ImageNet-1k. \n\n3. **The instance weight can be replaced with learnable temperatures.**  Adding weight significance to the samples is one way to obtain a higher inter-class separation, but I am wondering if would it also make sense to make the temperature learnable. Compared with weight significance, it would bring another benefit: learnable distribution shaping for each category.  \n\n4. **How does the method perform when scaling to more/fewer categories?** I would suspect the performance is highly related to the number of categories. If the value is too large (e.g., 1000) or too small (e.g., 5), the performance might deteriorate. Can authors provide some ablation studies on subsets of the used datasets?\n\n5. **Does the method also work for Transformer-based architectures?** Currently the authors evaluate their approach with ResNet-18, DenseNet and WideResNet? Can authors do more experimental evaluation on Transformers?"
                },
                "questions": {
                    "value": "Please see the weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission226/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission226/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission226/Reviewer_XxBj"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission226/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698852295842,
            "cdate": 1698852295842,
            "tmdate": 1699635948243,
            "mdate": 1699635948243,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wgDLLesVcE",
                "forum": "OJoMzslBIa",
                "replyto": "KkVBSjDmm5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission226/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission226/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer XxBj."
                    },
                    "comment": {
                        "value": "We thank the reviewer for the concrete suggestions. We address the presented concerns below:\n\n- The updated manuscript now contains the suggested comparisons and we do cite all the mentioned works in the manuscript.\n\n- The experiments with the Imagenet-1k dataset following the setup of the ImageNet-100 experiment are shown below.\n  | Method                 | iNaturalist | SUN  | Textures | Places | SSB Hard | Ninco | Openimage | Average **FPR** $\\downarrow$ |\n  |------------------------|-------------|------|----------|--------|----------|-------|-----------|--------------------------------|\n  | SupCon                 | 61.93        | 68.85 | 25.43     | 75.28   | 90.79    | 78.82 | 55.64      | 65.25                          |\n  | CIDER                   | 53.54        | 61.27 | 23.95     | 68.76   | 91.52    | 79.15 | 54.22      | 61.77                          |\n  | **(ReweightOOD) *Ours***| 50.70        | 59.46 | 24.27     | 66.27   | 90.18   | 76.76 | 50.97      | **59.80**                      |\n  \n  It can be observed that the proposed approach has noticeable gains over SupCon and CIDER demonstrating its superiority.\n\n- We thank the reviewer for the possible further extensions. We aim to undertake such an approach in future work.\n\n- As can be observed from the above ImageNet-1k experiments, our approach demonstrates performance gain even when scaled to an even more challenging (higher number of categories) setting."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700479625314,
                "cdate": 1700479625314,
                "tmdate": 1700479625314,
                "mdate": 1700479625314,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vOuwunlLBy",
            "forum": "OJoMzslBIa",
            "replyto": "OJoMzslBIa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission226/Reviewer_NpEj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission226/Reviewer_NpEj"
            ],
            "content": {
                "summary": {
                    "value": "The traditional distance-based OOD detection assumes that OOD samples are far from In-Distribution (ID) clusters in the embedding space. A recent method involves contrastive optimization to create an OOD-detection-friendly embedding space. However, this approach doesn't effectively reduce the Minimum Enclosing Sphere (MES) for each class and achieve higher inter-class dispersion, leading to potential overlap between ID and OOD samples. To address this, the paper proposes a reweighting scheme called ReweightOOD. This scheme prioritizes optimizing less-optimized contrasting pairs while assigning lower importance to already well-optimized pairs."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper addresses the important issue of Out-of-Distribution (OOD) detection in neural networks, crucial for ensuring safety and reliability in critical applications."
                },
                "weaknesses": {
                    "value": "1. The figures 3 and 4 are not mentioned in the article.\n2. I find Figure 5 visually unappealing, and I wonder why there is only one category in the right figure.\n3. Table 2 only has two columns, it's not worth occupying such a large space in the paper.\n4. More importantly, why not conduct experiments on the ImageNet dataset, like existing works [1] have done?\n\n[1] Sun Y, Guo C, Li Y. React: Out-of-distribution detection with rectified activations[J]. Advances in Neural Information Processing Systems, 2021, 34: 144-157."
                },
                "questions": {
                    "value": "See above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission226/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698907854076,
            "cdate": 1698907854076,
            "tmdate": 1699635948158,
            "mdate": 1699635948158,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1UCJzauzXa",
                "forum": "OJoMzslBIa",
                "replyto": "vOuwunlLBy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission226/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission226/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer NpEj."
                    },
                    "comment": {
                        "value": "We thank Review NpEj for the presented concerns. We address the concerns below.\n\n- We have resolved the issue in the latest manuscript by referencing Figure 3 and Figure 4.\n\n- Apologies for the overleaf rendering issues, the correctly rendered visualization is updated in the manuscript.\n\n- Thanks for noticing the space consideration. We'll be mindful of it in the subsequent version.\n\n- Thanks for pointing it out. Adopting the training setup of ImageNet100, we present the requested comparison with ImageNet-1k below: \n             \n  | Method                 | iNaturalist | SUN  | Textures | Places | SSB Hard | Ninco | Openimage | Average **FPR** $\\downarrow$ |\n  |------------------------|-------------|------|----------|--------|----------|-------|-----------|--------------------------------|\n  | SupCon                 | 61.93        | 68.85 | 25.43     | 75.28   | 90.79    | 78.82 | 55.64      | 65.25                          |\n  | CIDER                   | 53.54        | 61.27 | 23.95     | 68.76   | 91.52    | 79.15 | 54.22      | 61.77                          |\n  | **(ReweightOOD) *Ours***| 50.70        | 59.46 | 24.27     | 66.27   | 90.18   | 76.76 | 50.97      | **59.80**                      |\n\n  It can be observed that the proposed approach has noticeable gains over SupCon and CIDER demonstrating its superiority."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700479579532,
                "cdate": 1700479579532,
                "tmdate": 1700479579532,
                "mdate": 1700479579532,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "WB4Hs6GcEP",
            "forum": "OJoMzslBIa",
            "replyto": "OJoMzslBIa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission226/Reviewer_4EKT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission226/Reviewer_4EKT"
            ],
            "content": {
                "summary": {
                    "value": "This paper tackles the problem of OOD detection. It is motivated from supervised contrastive learning and propose to further disperse the inter-class distance while reduce intra-class variance via reweighting. Specifically, it encourages the model to focus more on hard positives and negatives samples. The experimenets on several benchmarks show the performance advantages of the method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The motivation is clear and presentation is easy to follow.\n- The proposed method is straightforward and weights for positives and negatives are dynatmically adjusted based on the similarity score. \n- Table 1 and 2 shows the dispersion cross class and compactness within the class for the proposed method compared to SupCon\n- Performance gains on CIFAR10/100 and ImageNet100"
                },
                "weaknesses": {
                    "value": "Novelty:\n- Although the reweighting on constrative learning has been under-explored in OOD detection community, focusing more on hard postivie/negatives are widely applied in deep metric learning (especially in face recognition). E,g [1][2]. I think the novelty is sort of limited as the paper adopt hard sample mining/weighting into OOD detection task. In rebuttal, can you explain the difference bewteen your work and [1,2] in terms of hard samples re-weighting?\n\nExperiment:\n- In ImageNet100, can we have numbers from other methods (e.g, CIDER) instead of SupCon only.\n- For Table 1,2, I am interested to see how the MES score and Average centroid dispersion for CIDER. \n- Hyperparameters test on linear transformation are encouraged. It is said that ResNet18 network are set to (5, \u22122, 2, 1) and (5, \u22124, 2, 1). Do you have to set differently for other backbones or datasets?\n- For Figure 5 (b), why there is only one cluster? also, can you provide feature vislization for SupCon or CIDER as well?\n\n[1] CurricularFace: Adaptive Curriculum Learning Loss for Deep Face Recognition\n[2] AdaFace: Quality Adaptive Margin for Face Recognition"
                },
                "questions": {
                    "value": "Please refer to the weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission226/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699580650606,
            "cdate": 1699580650606,
            "tmdate": 1699635948088,
            "mdate": 1699635948088,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GiAELcsd2v",
                "forum": "OJoMzslBIa",
                "replyto": "WB4Hs6GcEP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission226/Authors"
                ],
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission226/Authors",
                    "ICLR.cc/2024/Conference/Submission226/Senior_Area_Chairs",
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission226/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 4EKT."
                    },
                    "comment": {
                        "value": "We thank Reviewer 4EKT for raising insightful concerns and queries. We address them below.\n\nA detailed clarification of the distinction between our proposed approach against CurricularFace and AdaFace is presented below.\n\n-  CurricularFace adopts a curriculum-style learning approach, wherein early/late training dynamics are taken into account. It emphasizes easy samples at the earlier stage while prioritizing the hard samples at the later stage. ReweightOOD does not impose curriculum-style learning at all, as it does not distinguish between early and late training phases. The reweighting function of ReweightOOD, in the form of a sigmoid, strategically suppresses easy samples from the outset, directing attention toward challenging samples. AdaFace, another proxy-based approach, adopts the quality of the image -- approximated by feature norm -- into the weighting of the sample's importance. In AdaFace, hard samples from higher-quality images receive increased weighting, while easy samples from lower-quality images are weighted higher. In contrast, our approach focuses solely on the cosine similarity when reweighting pair instances. Moreover, ReweightOOD facilitates distinct treatment of positive and negative pairs due to the presence of a transformation function with separate hyperparameters. The utilization of two sets of linear transformations, specific to positive and negative pairs, enables flexible weighting tailored to achieving optimal OOD detection. Additionally, both curricularFace and adaFace adopt cross-entropy-based optimization while ReweightOOD uses similarity maximization/minimization optimization as shown in equation (3).\n\nRegarding the experiments, we address the queries below:\n\n- The result of ImageNet100 including CIDER is presented below:-\n\n  | Method                 | iNaturalist | SUN  | Textures | Places | SSB Hard | Ninco | Openimage | Average **FPR** $\\downarrow$ |\n  |------------------------|-------------|------|----------|--------|----------|-------|-----------|--------------------------------|\n  | Baseline               | 3.07        | 2.39 | 4.57     | 5.47   | 35.39    | 29.15 | 7.05      | 12.44                          |\n  | SupCon                 | 2.43        | 1.98 | 2.59     | 5.43   | 34.25    | 25.58 | 5.28      | 11.08                          |\n  | CIDER                  | 5.07        | 1.85 | 1.77     | 5.70   | 37.35    | 27.93 | 5.73      | 12.20                          |\n  | **(ReweightOOD) *Ours***| 2.18        | 1.97 | 2.73     | 5.29   | 32.00    | 24.63 | 5.06      | **10.55**                      |\n  \n  As can be observed from the above Table, our approach yields the minimum average FPR of 10.55.\n\n\n- The updated MES Table with the results of CIDER is given below:\n   | Method                 | Apples | Aquarium Fish | Baby | Bear | Beaver | Bed  | Bee | Beetle | Bicycle | Bottles | ... | Mean  |\n   |------------------------|--------|---------------|------|------|--------|------|-----|--------|---------|---------|-----|-------|\n   | Baseline               | 1.09   | 1.11          | 1.07 | 0.93 | 0.97   | 1.07 | 1.03| 1.07   | 1.10    | 1.07    | ... | 1.05  |\n   | SupCon                 | 0.97   | 1.01          | 0.97 | 1.00 | 1.00   | 0.98 | 0.99| 0.97   | 1.04    | 1.03    | ... | 1.01  |\n   |  *CIDER*              | 0.96   | 0.94          | 0.89 | 0.91 | 0.86   | 0.88 | 0.87| 0.88   | 1.04    | 0.99    | ... | 0.92  |\n   | **(ReweightOOD) *Ours***| 0.95   | 0.90          | 0.90 | 0.89 | 0.84   | 0.90 | 0.89| 0.91   | 0.99    | 0.96    | ... | **0.90** |\n\n   As evidenced from the above Table, the average MES of ReweightOOD is minimum among all. Moreover, the class centroid dispersion of ReweightOOD (0.63) is comparable to that of CIDER (0.64) despite not explicitly encouraging the inter-class dispersion.\n\n- The random hyperparameter optimization is employed with respect to the validation set (gaussian noise). The hyperparameter set to (5, \u22124, 2, 1) consistently demonstrates strong performance in experiments conducted on both CIFAR100 and ImageNet100 datasets, across all architectures used in the paper.\n\n- Apologies for the overleaf rendering issues, the correctly rendered visualization is updated in the manuscript."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699808946016,
                "cdate": 1699808946016,
                "tmdate": 1700479562751,
                "mdate": 1700479562751,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]