[
    {
        "title": "Learning in reverse causal strategic environments with ramifications on two sided markets"
    },
    {
        "review": {
            "id": "KasoiY2scC",
            "forum": "vEfmVS5ywF",
            "replyto": "vEfmVS5ywF",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2693/Reviewer_L1Mv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2693/Reviewer_L1Mv"
            ],
            "content": {
                "summary": {
                    "value": "* The paper introduces a reverse-causal strategic classification setting, and analyzes it primarily within the context of the Coate-Loury labor market model.\n* In the Coate-Loury labor market model, an employer trains a screening function $f(x)$ to detect high-skill workers ($y=1$), and workers respond strategically by possibly increasing their skill level at cost $c$. Worker features $x\\\\in[0,1]$ are a noisy function of skill ($x\\\\sim\\\\Phi(\\\\cdot | y)$), making the strategic response reverse-causal.\n* The analysis investigates the gap between the associated repeated risk minimization (RRM/\u201dstable\u201d) and performatively optimal (PO/\u201dperformative\u201d) policies (eq. (2.2) and eq. (2.3), respectively).\n* For a Coate-Loury model with a uniform decision rule (same decision threshold $\\\\theta$ for all population), Theorem 3.1 gives conditions under which a PO policy results in a higher proportion of skilled workers and increased employer\u2019s utility compared to RRM.\n* For a model with non-uniform decision policies (two groups {Maj,Min} and a separate decision threshold for each), Theorem 3.2 gives conditions under which RRM leads to a discriminatory population composition, and PO leads to population composition which is approximately balanced.\n* Finally, a generalization of the Coate-Loury model with inter-group interactions is investigated by numerical simulation. Results indicate that a PO policy leads to higher employer utility, but can generally reduce the welfare of the workers."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* Problem is well-motivated. Theoretical framework is interesting.\n* Performative response is derived directly from an established economic model.\n* Running examples in the introduction aid understanding, and strengthen applicability.\n* Model assumptions are presented clearly, and relaxed gradually."
                },
                "weaknesses": {
                    "value": "* Soundness concern: Repeated risk minimization (RRM) plays a central role in the theoretical analysis (eq. (2.2) ,eq. (3.1)), and convergence is claimed to be due to \u201crepeated risk minimization, which is known to converge to performatively stable policies (Perdomo et al., 2020)\u201d. However, if I understand correctly, the convergence guarantees in Perdomo et al. 2020 rely on strong regularity assumptions (e.g., $\\\\beta$-joint smoothness, $\\\\gamma$-strong convexity, $\\\\varepsilon$-sensitivity) and RRM can fail to converge in their absence (see Theorem 3.5 and Proposition 3.6 in Perdomo et al. 2020). I was unable to find a discussion of these assumptions and their applicability in the paper, and therefore it is not clear why RRM is guaranteed to converge in this context.\n* The learning setting is unclear (see questions below).\n* Code is not provided, making it hard to validate and reproduce the results of Section 4, which rely on numerical evaluation.\n* Interaction model assumes one dimensional features and strict monotone likelihood ratio. It is not clear how results extend to higher-dimensional features and more complex distribution structures."
                },
                "questions": {
                    "value": "* RRM convergence: How does the claim about convergence to performative stability relate to the formal guarantees given by Perdomo et al.?\n* Additional related results in Perdomo et al.: In the paragraph below the statement of Theorem 3.1, it is claimed that \u201cTheorem 3.1 gives conditions for there to be an appreciable gap. This complements prior results (for example, in Perdomo et al. (2020)) that provide conditions under which the gap is small.\u201d. In contrast, Theorem 4.3 in Perdomo et al. 2020 predicts that the gap between the PO and RRM policies is expected to be small. What is the relation between the gaps presented in this paper and Theorem 4.3 in Perdomo et al.? If some required Theorem 4.3 are not met, which ones? And how does it relate to the RRM convergence guarantees discussed in the question above?\n* Learning setting: At what stage data is available to the employer, and how do they learn from it? How do the main results extend to scenarios where predictors are learned from finite datasets?\n* Do similar results hold for the content creation scenario described in Example 2.2? What would be required in order to apply the results in other scenarios?\n* Small question about notations: What is the difference between $w\\\\int_X 1_{\\\\{f(x)=1\\\\}} d\\\\Phi(x|Y=1)$ and $\\\\int_{[0,1]} w f(x) d \\\\Phi(x|1)$ in Example 2.1?\n* Small typo in Section 2: examplse. Appendix has undefined references: (??)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2693/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2693/Reviewer_L1Mv",
                        "ICLR.cc/2024/Conference/Submission2693/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2693/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698774700382,
            "cdate": 1698774700382,
            "tmdate": 1700524145673,
            "mdate": 1700524145673,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jsNiQJGnke",
                "forum": "vEfmVS5ywF",
                "replyto": "KasoiY2scC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2693/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2693/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal for Reviewer L1Mv"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the helpful comments, we address particular concerns below.\n\n*Soundness concern: Repeated risk minimization (RRM) plays a central role in the theoretical analysis (eq. (2.2) ,eq. (3.1)), and convergence is claimed to be due to \u201crepeated risk minimization, which is known to converge to performatively stable policies (Perdomo et al., 2020)\u201d \\ldots  I was unable to find a discussion of these assumptions and their applicability in the paper, and therefore it is not clear why RRM is guaranteed to converge in this context.*\n\nIn response to this soundness concern we have made the following changes to the submission:\n\n1. We have re-written the discussion of performative prediction in the Coate-Loury model  (section 3.1) in order to clarify that our results DO NOT depend on the convergence of RRM. Each theorem is a comparison of the impacts of the two types of solutions in performative prediction (stable and optimal points) on labor markets, and for such a comparison to be valid we only need that both solution types exist, which is always guaranteed. We also point out that  the conditions provided in (Perdomo et al. (2020)) are sufficient, but not necessary, and our empirical results demonstrate that in practice the convergence of RRM/reactive firms is not an issue in a wide range of markets.\n\n2. A more thorough discussion on the market conditions needed to guarantee RRM convergence is added to the appendix (see appendix D). The primary benefit of imposing such conditions on the market is that all ``reactive\" employers are guaranteed to eventually stabilize. This is not needed for our results but is still nice conceptually. Given this, we have added two new theorems (now theorems 3.2 and 3.4) which provide results in markets which are compatible with these conditions (particularly we show our main take aways are similar in low wage markets). \n\n*Additional related results in Perdomo et al.: In the paragraph below the statement of Theorem 3.1, it is claimed that \u201cTheorem 3.1 gives conditions for there to be an appreciable gap. This complements prior results (for example, in Perdomo et al. (2020)) that provide conditions under which the gap is small.\u201d. In contrast, Theorem 4.3 in Perdomo et al. 2020 predicts that the gap between the PO and RRM policies is expected to be small. What is the relation between the gaps presented in this paper and Theorem 4.3 in Perdomo et al.? If some required Theorem 4.3 are not met, which ones? And how does it relate to the RRM convergence guarantees discussed in the question above?*\n\nNone of the conditions in (Perdomo et al. (2020)) are broken, but the ``$\\epsilon$-sensitivity condition\" is only satisfied for a large value of $\\epsilon$ when the $w$ is large. Thus the upper bound on the gap between PO and PS policies from (Perdomo et al.(2020)) is also large under the conditions of our theorems 3.1 and 3.3. Appendix D now clarifies the importance that wage plays in convergence of RRM. \n\n*Learning setting: At what stage data is available to the employer, and how do they learn from it? How do the main results extend to scenarios where predictors are learned from finite datasets?*\n\nIn a stochastic (or finite data) setting the order of learning at time $t$ is as follows: \n\n1. The firm deploys decision $\\theta_t$\n\n2. Firm recieves data (and corresponding loss/reward) drawn from $\\mathcal{D}(\\theta_{t})$. The firm may use this to either deploy a reactive decision or in some algorithm that converges towards an optimal policy (the discussion on this in appendix A assumes a finite data set) \n\nAlthough we work in the population setting, we expect similar results in the finite-sample setting in which the firm has to learn its predictor from data. Under standard assumptions that guarantee generalization, the firm's learned predictor will be close to its optimal predictor in the population setting that we study.\n\n*Do similar results hold for the content creation scenario described in Example 2.2? What would be required in order to apply the results in other scenarios?*\n\nThis is an intersting line of follow up research, the content creation game is quite different, as the ``content creators\" actually compete with one other for user attention. This means the response of the creators are participants in a game and their response will be some type of equilibria of the game. This type of agent response is very different from the agent best response that we study.\n\n*Small question about notations: What is the difference between $w\\int_X 1_{f(x)=1}d\\Phi(x|1)$ and $w\\int_{[0,1]} 1_{f(x)=1}d\\Phi(x|1)$ in Example 2.1?*\n\nThis is a typo, $X$ should be [0,1] in this case.\n\n*Code is not provided, making it hard to validate and reproduce the results of Section 4, which rely on numerical evaluation.*\n\nWe have now uploaded our code."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2693/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700062672812,
                "cdate": 1700062672812,
                "tmdate": 1700063422828,
                "mdate": 1700063422828,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YjaZ687CBT",
                "forum": "vEfmVS5ywF",
                "replyto": "KasoiY2scC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2693/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2693/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow up with reviewer L1Mv"
                    },
                    "comment": {
                        "value": "Dear reviewer L1Mv,\n\nThank you for taking time to review our paper and provide valuable feedback. Hopefully you have had time to read our response. Please let us know if you have further questions or comments, we would be happy to address them. If you found our responses and updated submission satisfactory, please consider updating your score."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2693/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700440825450,
                "cdate": 1700440825450,
                "tmdate": 1700440825450,
                "mdate": 1700440825450,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7hvaIFA2Nj",
                "forum": "vEfmVS5ywF",
                "replyto": "YjaZ687CBT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2693/Reviewer_L1Mv"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2693/Reviewer_L1Mv"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the detailed response, and for the revision. The added discussion regarding RRM convergence, the clarifications regarding the gap between PO and PS policies, and the added code are all very helpful. I increase my overall rating to 6.\n\nI believe the paper would benefit from a thorough discussion of limitations, particularly with respect to the applicability of assumptions, and the case of finite data sets: Regarding applicability, I wonder if the Coate-Loury literature contains works in which the model is fitted to actual data, providing evidence to support the assumptions made about parameter relationships, regularity, etc. For the finite data case, I believe the paper would also benefit from a more detailed discussion of the finite data setup, limitations of the proposed methods, and remaining questions. \n\nAlso note that the revised manuscript appears to contain minor typos - in the paragraph after the statement of Theorem 3.1 (\"Theorems 3.1 and 3.1\" - appears twice), and in the last equation of Example 2.1 (uppercase Y in the first integral, lowercase y in the second integral)."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2693/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700526105300,
                "cdate": 1700526105300,
                "tmdate": 1700526105300,
                "mdate": 1700526105300,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "mU1MXri6tE",
            "forum": "vEfmVS5ywF",
            "replyto": "vEfmVS5ywF",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2693/Reviewer_jt3C"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2693/Reviewer_jt3C"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a novel formulation of the causal strategic classification problem. Here, there is a set of agents, each described by x, the values for a set of features and with a true label y. A classifier wishes to classify agents based on their features x to minimize some loss function defined w.r.t. the true labels y of the agents. \n\nHowever, the agents are strategic, and given a classifier with parameters \\theta, can change their label y by changing their features at a certain cost, in order to obtain a utility from the classification. The problem is motivated through the running example of the labor market, where the employer has a hiring policy based on the skill of the worker. Workers can change their skill in order to increase their chances of being hired and obtain the wage from being hired. \n\nThe model assumes that there is a (reverse) causal model that determines the relationship between the features and the label (or vice-versa respectively). The paper focuses on the setting with a reverse causal model. Here, agents are allowed only to determine whether they want a change in their label, and the reverse causal model determines how the features must be changed. \n\nThe technical results of the paper deal with analyzing the solutions of the game that results from the interactions between the classifier and agents under such a reverse causal model, with interesting results and consequences for a well-studied model of the labor market. The paper provides interesting results on the effect of a reactive classifier (which iteratively updates the parameters \\theta after the agents respond to the classifier used in the previous iteration) and a strategic classifier which anticipates the best response of the agents on the welfare of the classifier and agents."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- First, I found the model very interesting, and the main technical contribution of the reverse causal setting for performative prediction to be interesting and significant. The topic is clearly relevant to ICLR, and similar models may be relevant several other applied fields.\n- The main technical results appear sound, and I appreciate the nice discussions following the theorems discussing how to interpret the results and the implications for the running example of the labor market.\n- The findings that the presence of a performative classifier can hurt agent welfare and that its fairness properties are brittle are also interesting."
                },
                "weaknesses": {
                    "value": "- No major weakness. The authors may consider doing a more thorough pass to fix some minor typos."
                },
                "questions": {
                    "value": "None"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2693/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2693/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2693/Reviewer_jt3C"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2693/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699277006244,
            "cdate": 1699277006244,
            "tmdate": 1699636210758,
            "mdate": 1699636210758,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "G8W0O2ByMV",
                "forum": "vEfmVS5ywF",
                "replyto": "mU1MXri6tE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2693/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2693/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal for Reviewer jt3C"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the encouraging words on our work, and alert them that in response to another reviewer a second version of the submission has been posted."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2693/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700062681002,
                "cdate": 1700062681002,
                "tmdate": 1700062681002,
                "mdate": 1700062681002,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]