[
    {
        "title": "Contextual Bandits with Online Neural Regression"
    },
    {
        "review": {
            "id": "wsOSP9zXl2",
            "forum": "5ep85sakT3",
            "replyto": "5ep85sakT3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7040/Reviewer_Gbgm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7040/Reviewer_Gbgm"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies neural contextual bandits (CB) with the reduction to online regression under the realizability assumption. \nUsing existing results for wide neural networks, it immediately gets a regret of $O(T^{3/4})$ for neuCB. \n\nWhen the loss function of the online regression satisfies $\\epsilon$-almost convexity, Quadratic Growth condition and uniqueness of minima, this paper provides a $O(\\log T) + \\epsilon T$ regret for the online regression.\n\nThen, since the above result does not directly apply to wide NN due to the violation of uniqueness of minima, this paper proposes a novel trick of adding a small perturbation to the NN prediction. This seemingly simple trick makes the loss satisfy the Quadratic Growth condition with a unique minimum. Consequently, an $O(\\log T)$ regret for the online regression with KL loss and squared loss is established. \n\nFurthermore, this paper provides a lower bound of $\\Omega(T)$ for NeuralUCB and NeuralTS with an oblivious adversary.\n\nFinally, Experimental results show that the proposed algorithms outperform baselines on 6 classification datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "**Significance**: this paper is a quite extensive theoretical work on NeuralCB. The theoretical results as well as the techniques are of independent interest. \n\n**Quality**: the quality of the paper is good. Definitions are introduced without ambiguity; the theoretical analysis seems solid to me; experimental details are given. \n\n**Originality**: this paper contains some novel idea. The perturbation trick is a very interesting trick for bypassing the restriction on the uniqueness of minima. \n\n**Clarity**: this paper is very well written. The theoretical proof is divided into steps. A sketch of proof like this make it easier for the readers to follow and understand."
                },
                "weaknesses": {
                    "value": "I did not detect any major technical flaw or major weakness in this paper."
                },
                "questions": {
                    "value": "1. Is it possible to extend the current results to a broader choice of loss functions? It would be great if the authors can elaborate on this."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7040/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698460460670,
            "cdate": 1698460460670,
            "tmdate": 1699636827084,
            "mdate": 1699636827084,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CDuiPL6b3T",
                "forum": "5ep85sakT3",
                "replyto": "wsOSP9zXl2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7040/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7040/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Gbgm"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the encouraging comments. The summary provided by the reviewer indeed captures the main story-line of this work and we have incorporated the structure in our general response as well. We adress the question raised by the reviewer below.\n***\n**[Q1] Extension to other loss functions:**\nOur QG regret bound (Theorem 3.1) is a general result that holds for any loss function as longs as it satisfies the following conditions: (i) almost convexity, (ii) QG and (iii) unique minima. In Theorem 3.2 and 3.3 we show that these conditions hold for square loss and KL loss respectively with the perturbed network. These results do not immediately extend to other loss functions and one needs to carry out an independent analysis for each such loss function."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7040/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700548263880,
                "cdate": 1700548263880,
                "tmdate": 1700548263880,
                "mdate": 1700548263880,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qNz5viUGH1",
            "forum": "5ep85sakT3",
            "replyto": "5ep85sakT3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7040/Reviewer_uhN1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7040/Reviewer_uhN1"
            ],
            "content": {
                "summary": {
                    "value": "This work provides a solid investigation on neural regression in contextual bandits. One interesting point is to use perturbation to construct a surrogate network output with unique minimizer. In that analysis, the work manage to get a approximate loss to satisfy strong-convexity-like condition (Quadratic Growth condition) to get analysis through. The article is full of useful theoretical insights and enjoyable to read."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The work provides solid investigation on improving online neural regression for better online decision making. The paper also is well-written, easy to read for audience with relative expertise."
                },
                "weaknesses": {
                    "value": "Maybe not so readable for people without theoretical background."
                },
                "questions": {
                    "value": "1. One particular point that draws my attention is to adopt KL loss in the online gradient descent step. Could you make comments on when should we use NeuFastCB and when should we use NeuSquareCB in practice? In particular, how the dimension or datatype of the real dataset impact this decision? \n\n2. Could you provide your comments on why NeuFastCB and NeuSquareCB outperform NeuralTS?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7040/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698775351226,
            "cdate": 1698775351226,
            "tmdate": 1699636826955,
            "mdate": 1699636826955,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "OwnQtYz38T",
                "forum": "5ep85sakT3",
                "replyto": "qNz5viUGH1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7040/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7040/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer uhN1"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the encouraging comments. We are especially glad that the reviewer found the paper full of useful theoretical insights and enjoyable to read. Despite being a theory heavy paper, we had put in a lot of efforts to ensure that the results are accessible to wide range of people. We have further updated the draft to incorporate suggestions from this and other reviewers. Below we respond to all the questions posed by the reviewer.\n***\n**[Q1] NeuSquareCB vs NeuFastCB:**\nThis is an interesting question and we thank the reviewer for bringing this up. \nIn practice, we recommend using NeuFastCB, both because it seems to perform better empirically in our experiments and theory results are much stronger (see below).\n\nNext recall that the regret bound for NeuFastCB is $\\mathcal{O}(\\sqrt{KL^*} + K)$ and that of NeuSquareCB is $\\mathcal{O}(\\sqrt{KT})$. Note that the regret bound for NeuFastCB is a first order bound, i.e., it depends on $L^*$, the loss of the best policy and not the time horizon $T$ as in NeuSquareCB. Since $L^* \\leq T$ then $\\mathcal{O}(\\sqrt{KL^*}) \\leq \\mathcal{O}(\\sqrt{KT})$. Therefore NeuFastCB is expected to perform better in most settings ``in practice'', especially when $L^*$ is small, i.e., the best policy has low regret.\n\nAlso note that going by the upper bounds on the regret, especially the dependence on $K$, the number of arms, NeuSquareCB could outperform NeuFastCB only if $L^* = \\Theta(T)$ and $K>>T$.\n\nSince this discussion would indeed help users choose between the two algorithms, we have included a brief discussion about this in Section 4 of the new draft (Remark 4.1 in the updated draft).\n***\n**[Q2] Why NeuFastCB and NeuSquareCB outperform NeuralTS:**\n\nThe improved empirical performance of NeuFastCB and NeuSquareCB in comparison to NeuralTS and NeuralUCB can be explained by the following.\n\n1. Both NeuralUCB and NeuralTS need to invert a matrix given by $\\sum_{i=1}^t g_i g_i^T + \\lambda I$, where $g_i$ is the vectorized gradient of the neural network at time $i$ and $\\lambda$ is the regularization parameter. However, since the matrix is of very high dimensions, both the works implement their respective algorithms with a diagonal approximation to the matrix to make it computationally feasible. The regret guarantee does not hold with the approximation and {possibly} leads to sub-par performance.\n\n2. In this work we also show that the regret bounds for NeuralUCB and NeuralTS (even without the diagonal approximation) is $\\Omega(T\\sqrt{K})$ which could explain why their performance is not entirely satisfactory. Further note that the regret of our algorithm NeuFastCB is sub-linear in $L^*$, the loss of the best policy and not the time horizon $T$. Therefore, in situations where the best policy has low regret, our algorithm NeuFastCB will also have low regret.\n***\n**[Q3] Readability for people without theoretical background.**\n\nWe thank the reviewer for reminding us to be mindful that the contributions should be accessible to a broader set of audience. We describe some of the measures we had adopted along with some changes made to the new draft to ensure that.\n\n1. We give a gentle introduction to NeuCBs in Section 1 and specifically discuss the research gaps in the current NeuCB literature in Section 1.1 to ensure that the reader can appreciate the contributions of this work in the context of available works.\n2. All the algorithms and clearly stated and should be easy to implement.\n3. In Section 1.2 we enumerate the contributions of this work that clearly describe the main story-line: \n>**(A)** QG condition along with additional standard assumptions gives logarithmic regret if the loss has unique minima,\n\\\n>**(B)** Neural networks do not have unique minima\n\\\n>**(C)** Small perturbation to the output of neural networks yield unique minima as well as all other desirable properties.\n4. The relative merits of the different approaches in NeuCBs are summarized in Table 1.\n5. In the experiments section we clearly describe the baselines, datasets and how contexts are chosen adversarially along with a description of the results.\n***\nIf the reviewer has further suggestions to help make the paper more accessible, we would be glad to include them in the subsequent draft."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7040/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700548186922,
                "cdate": 1700548186922,
                "tmdate": 1700548186922,
                "mdate": 1700548186922,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "S7DRvLMigp",
            "forum": "5ep85sakT3",
            "replyto": "5ep85sakT3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7040/Reviewer_EQUF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7040/Reviewer_EQUF"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the contextual bandits problem. The paper proposed NeuCB, an algorithm based on applying SquareCB to neural networks with some assumptions. The paper proved a novel online regression guarantee for neural networks satisfying QG condition and some other assumptions. Based on this, the paper converted this into a $\\sqrt T$-type bandit regret bound for NeuCB. Furthermore, the paper presented experiments on various real-world classification datasets to show its advantage over existing neural contextual bandits algorithms."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The online regression bound is novel and could further benefit the community.\n2. The paper presents experiments to corroborate their theoretical findings."
                },
                "weaknesses": {
                    "value": "1. The paper seems not to mention about whether the reward function $h$ in Assumption 1 is realizable by a neural network. Is it the case?\n2. Similar to most previous NTK bandit paper, the paper made the assumption on both gaussian initialization and lower-bounded eigenvalue of the NTK. This limits the scope of this and all the NTK bandits papers.\n3. The paper is written in a nested way so that I have to chase after the links between theorems, lemmas, and assumptions to figure out the true assumption set of a theorem: for each theorem, I need to consider its assumption and the assumptions in all lemmas/theorems it used.\n4. The bounds in various theorems used $\\widetilde{\\mathcal O}$ without saying what's exactly being omitted by it. I suggest the author complete this part of information."
                },
                "questions": {
                    "value": "1. In regret bounds Theorems 4.1 and 4.2, what's the dependency of the regret bound w.r.t. width $m$? If there's dependency, could you please write it out? If neither the Theorem nor the algorithm used $m$, then we could omit it."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7040/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698861704200,
            "cdate": 1698861704200,
            "tmdate": 1699636826854,
            "mdate": 1699636826854,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "a6ul2f332x",
                "forum": "5ep85sakT3",
                "replyto": "S7DRvLMigp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7040/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7040/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer EQUF"
                    },
                    "comment": {
                        "value": "We thank that the reviewer for the encouraging comments. We are glad that the reviewer is of the opinion that the online regression bounds are novel and could further benefit the community and that experiments do corroborate the theoretical findings. We are further thankful for the interesting questions and suggestions brought by the reviewer. Below we respond to all of them.\n\n***\n**[Q1] Realizability of the reward function:** The reward function $h$ could be arbitrary, and we do not assume any specific form. The interpolation result (Theorem E1) shows that the neural network defined in (1) of the paper with Assumption 2 (network initialization) and Assumption 5 (NTK full rank) can realize any function $h$ on a finite set of $T$ points. To make the discussion clearer we have added a short remark (Remark 2.1) in the new draft.\n***\n**[Q2] Gaussian Initialization and lower bounded eigen value of the NTK**\n1. **Gaussian Initialization:** Pytorch supports both \"Xavier Normal'' and \"Kaiming Normal'' (also called He initialization) both of which use a gaussian distribution for initialization (see pytorch/torch/nn/init.py in the pytorch repository).\nFurther many works in deep learning assume that the parameters are initialized using a gaussian distribution (eg. [Du et al., 2019],[Du et al., 2018],[Chen et al. 2015],[Allen-Zhu et al., 2019a],[Allen-Zhu et al., 2019b],[Cao and Gu, 2019]).\n\\\n\\\nFurther, we expect the analysis to go through (however, this will need additional work) for any sub-Gaussian distribution based initialization, with suitable changes in (distribution dependent) constants in the results. Initialization from the uniform distribution is also supported in PyTorch (default initialization for linear layer) and is an example of a sub-Gaussian distribution.\n\n2. **NTK full rank:**  The assumption that the NTK is full rank is used in many deep learning works ([Du et al., 2019],[Liu et al., 2022],[Du et al., 2018]). We use the assumption to show that PL (and hence the QG condition holds in our analysis). We share the following points regarding the assumption.\n\\\n\\\n**(1)** In practice experiments have also shown that the assumption of NTK being full rank holds (see [Fort et al. 2020]). Moreover, as long as there are no two contexts that are identical or in parallel, the assumption holds. We can ensure this is satisfied by removing the duplicate contexts.\n\\\n\\\n**(2)** It should be noted that NeuralUCB and NeuralTS also assume that NTK is full rank. Our lower bound results show that their regret bounds are $\\Omega(T)$ (see Appendix A of our paper). Therefore even under Assumption 5 our regret bounds are the first sub-linear bounds for NeuCBs when contexts are otherwise chosen adversarially.\n***\n**[Q3] Writing Style:**\n\nTo ensure that our work is accessible to a broader audience and is easy to follow we have incorporated suggestions from this and other reviewers. We highlight some of the aspects that should make the presentation better.\n1. In the proof of the main theorems (Theorem 3.1 and 3.2), we included a proof sketch to ensure that the reader has an overall idea of the way the analysis proceeds.\n2. We have also ensured in the Appendix that all the Lemma statements explicitly state the assumptions being used. To enhance the readability we have also included a description every time we invoke an assumption in the proof in the new draft. We hope this would eliminate moving back and forth between the assumption statements in the main paper and the proof details in the appendix, thus enhancing the proof reading experience.\n3. For a non-theoretical audience we give a gentle introduction to NeuCBs in Section 1 and specifically discuss the research gaps in the current NeuCB literature in Section 1.1 to ensure that the reader can appreciate the contributions of this work in the context of available works.\n4. Further, in Section 1.2 we enumerate the contributions of this work that clearly describe the main story-line: (A) QG condition gives logarithmic regret if the loss has unique minima, (B) neural networks do not have unique minima (C)  small perturbation to the output of neural networks yield unique minima as well as all other desirable properties.\n\nIf the reviewer has further suggestions to help make the paper more accessible, we would be glad to include them in the subsequent draft.\n***\n**[Q4] Definition of $\\tilde{\\mathcal{O}}$**\n\nWe thank the reviewer for bringing this to our attention. Indeed a precise definition would help improve the exposition and we have included the definition in Section 2.\n***"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7040/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700547597356,
                "cdate": 1700547597356,
                "tmdate": 1700547597356,
                "mdate": 1700547597356,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rUxOewJtLS",
            "forum": "5ep85sakT3",
            "replyto": "5ep85sakT3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7040/Reviewer_eHnV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7040/Reviewer_eHnV"
            ],
            "content": {
                "summary": {
                    "value": "The paper provides $O(\\log T )+\\epsilon T$ regret for online regression when the loss function satisfies $\\epsilon$-almost convexity, QG condition, and has unique minima. The authors show that even though QG with unique minima may not be realistic, adding a suitably small random perturbation to the predictions, makes the losses satisfy QG with unique minima. Using a reduction from contextual bandits to online regression oracles, the authors use the results to show regret bounds for contextual bandits."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper shows nearly-constant regret for online regression under certain assumptions.\n- Some of the assumptions are valid for wide range of networks or can be enforced by perturbing the loss function.\n- The regret bounds for contextual bandits are tight in some cases."
                },
                "weaknesses": {
                    "value": "- The results require strong assumptions (2.a, 3, 5).\n- The failure probability is large (grows with T) and cannot be controlled (see for example Thm 3.2).\n- The regret bounds for contextual bandits grow with the number of arms rather than a complexity measure of the underlying class of functions. A typical scenario for CBs is when the number of arms is very large or even infinite. This does not recover even the simple result of contextual linear bandits where the regret grows as $\\tilde{O}(\\sqrt{dT\\log K})$."
                },
                "questions": {
                    "value": "Please see weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7040/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7040/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7040/Reviewer_eHnV"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7040/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699142297735,
            "cdate": 1699142297735,
            "tmdate": 1699636826742,
            "mdate": 1699636826742,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mODAdSOkJ7",
                "forum": "5ep85sakT3",
                "replyto": "rUxOewJtLS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7040/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7040/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are thankful to the reviewer for their insightful questions and suggestions. Below we address all of them.\n***\n**[Q1] Restrictive Assumptions**: \n\n>**Assumptions 2 and 3:** We clarify that Assumption 2 and 3 were used only in the preliminary QG regret result (Theorem 3.1) and not by the regret bounds for NeuSquareCB and NeuFastCB (Theorem 3.1 and 3.2 respectively). For our algorithms, **_we rigorously proved that these assumptions hold_** for the class of models being used and the choice of loss functions with output perturbation. For example, in the proof sketch of Theorem 3.2 Assumption 3 is shown to be satisfied in Step-1, Assumption 2 (a) and (b) are shown to be satisfied in Step-2, and Assumption 2 (c) in Step-3. To make sure that this is clearer, we have added the following sentence at the beginning of the proof sketch: \"Note that we do not use Assumptions 2 and 3 and, but rather explicitly prove that they hold''.\n\n>**Assumptions 5:** The assumption that the NTK is full rank is used in many deep learning works ([Du et al., 2019],[Liu et al., 2022],[Du et al., 2018]). We use the assumption to show that PL (and hence the QG condition holds in our analysis). We share the following points regarding the assumption.\n\\\n\\\n**(1)** In practice experiments have also shown that the assumption of NTK being full rank holds (see [Fort et al. 2020]). Moreover, as long as there are no two contexts that are identical or in parallel, the assumption holds. We can ensure this is satisfied by removing the duplicate contexts.\n\\\n\\\n**(2)** It should be noted that NeuralUCB and NeuralTS also assume that NTK is full rank. Our lower bound results show that their regret bounds are $\\Omega(T)$ (see Appendix A of our paper). Therefore even under Assumption 5 our regret bounds are the first sub-linear bounds for NeuCBs when contexts are otherwise chosen adversarially.\n\n***\n**[Q2] Failure probability grows with $T$**\n\nWe clarify that the expression was not completely simplified to only show the dependence on $T$. Like NeuralUCB, NeuralTS and EE-Net our results are for wide neural networks (i.e., width, $m \\gg T$, the number of samples/steps). We have plugged in the choice of $m$ and simplified to obtain the final expression that is given by $\\left(1 - \\frac{C}{T^4}\\right)$, where $C > 0$ is some constant. Note that this decreases with $T$ as expected. We thank the reviewer to bring this up. We have updated the new draft with the simplified expression to avoid this confusion. Also note that for any $\\delta > 0$ we can choose $m \\geq \\frac{2CTL}{\\delta}$, to ensure that the theorem holds with probability at least $1 - \\delta$.\n***\n**[Q3] Dependence on number of arms.**\n\nOur regret bounds indeed have a $\\sqrt{K}$ dependence. We provide the following discussions about this aspect of the bounds.\n\n1. NeuralUCB and NeuralTS provide regret bounds that depend on $\\tilde{d}$ the effective dimension of the NTK matrix. As we show in Appendix-A both these bounds are in fact $\\Omega(\\sqrt{K}T)$ with the same dependence on $K$ as in this paper and a damaging linear dependence on the horizon $T$. Therefore under the same setting as in this paper there does not exist any NeuCB algorithm that even gives a sub-linear regret in the time horizon $T$ and as such our results do significantly improve the state of art in NeuCBs.\n\n2. We inherit the dependence on the number of arms from the online regression to bandit reduction from [Foster and Rakhlin, 2020] and [Foster and Krishnamurthy, 2021] and are not artifacts of our analysis. Improving the dependence on $K$ is an important direction for future work.\n***\n[Fort et al. 2020]: Fort S, Dziugaite GK, Paul M, Kharaghani S, Roy DM, Ganguli S. Deep learning versus kernel learning: an empirical study of loss landscape geometry and the time evolution of the neural tangent kernel. Advances in Neural Information Processing Systems. 2020;33:5850-61.\n\n[Foster and Rakhlin, 2020]: D. Foster and A. Rakhlin. Beyond ucb: Optimal and efficient contextual bandits with regression oracles. In International Conference on Machine Learning, pages 3199\u20133210. PMLR, 2020.\n\n[Foster and Krishnamurthy, 2021]: D. J. Foster and A. Krishnamurthy. Efficient first-order contextual bandits: Prediction, allocation, and triangular discrimination. Advances in Neural Information Processing Systems, 34, 2021.\n\n[Du et al., 2019]: S. Du, J. Lee, H. Li, L. Wang, and X. Zhai. Gradient descent finds global minima of deep neural networks. In International conference on machine learning, pages 1675\u20131685. PMLR, 2019.\n\n[Liu et al., 2022]: Chaoyue Liu, Libin Zhu, and Mikhail Belkin. Loss landscapes and optimization in over-parameterized non-linear systems and neural networks. Applied and Computational Harmonic Analysis, 2022.\n\n[Du et al., 2018]: Simon S Du, Xiyu Zhai, Barnabas Poczos, and Aarti Singh. Gradient descent provably optimizes over-parameterized neural networks. In: arXiv preprint arXiv:1810.02054 (2018)."
                    },
                    "title": {
                        "value": "Response to Reviewer eHnV"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7040/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700546588010,
                "cdate": 1700546588010,
                "tmdate": 1700546647611,
                "mdate": 1700546647611,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4wFcUFM8of",
                "forum": "5ep85sakT3",
                "replyto": "mODAdSOkJ7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7040/Reviewer_eHnV"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7040/Reviewer_eHnV"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your reply.\n\nCould you please expand on what you mean by \"the class of model being used\"? What are the assumptions on that class of models?\n\nFor assumption 5, how can you remove duplicate contexts? What if all contexts are the same? That should be an easy case to handle.\n\nI am not convinced by Q2 answer. I understand that the failure probability decreases with the width m. However, for a fixed width m, as time increases, we should be able to learn and achieve a small regret with high probability. The results in the paper do not show this."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7040/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700550021881,
                "cdate": 1700550021881,
                "tmdate": 1700550021881,
                "mdate": 1700550021881,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TyEBdAMYTM",
                "forum": "5ep85sakT3",
                "replyto": "rUxOewJtLS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7040/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7040/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Comment by Reviewer eHnV"
                    },
                    "comment": {
                        "value": "Thank you for replying to our response. Below we clarify the points raised by you.\n\n***\n\n1. **Class of model:** By the class of models being used we mean the feed forward network defined in (1) of the paper that satisfies Assumption 4 (gaussian initialization scheme of the network) and Assumption 5 (positive definite NTK).\n\n***\n\n2. **NTK Assumption:** Assumption 5 implies the $T$ contexts are unique, i.e., not duplicate, and duplicate contexts will imply Assumption 5 has been violated.\n\\\n\\\nNote that **all** existing work on neural contextual bandits ([Zhang et al., 2021],[Zhou et al., 2020],[Ban et al., 2022]) make this assumption. In fact, this is also the standard assumption is most work in optimization and generalization with neural networks. While we agree with you that relaxing the assumption will be a big advance, that is beyond the scope of the current work.\n\\\n\\\nOur work presents the first theoretically correct algorithm for NeuCBs with sub-linear regret bound under Assumption 5 (see Table 1 in the current paper) in the standard setting. In particular, no prior work has managed to do this even under Assumption 5. We have already specifically discussed that NeuralUCB and NeuralTS have $\\Omega(T)$ regret and EE-Net needs i.i.d. contexts and needs to store all previous networks.\n\\\n\\\nOn a more pragmatic side, one can remove duplicate contexts to ensure that the training data for neural networks is non-degenerate. \nFrom this perspective, the results are in terms of $T$, the number of unique contexts. More broadly, consider any standard learning setting, say classification or regression, with data $(x_t,y_t), t \\in [T]$ but $x_t = x, \\forall t \\in [T]$. We effectively have one training point. We do not expect a learning algorithm to successfully learn anything in this setting.\n\n***\n3. **Width requirements:** All existing results in neural contextual bandits need width $m = \\Omega(poly(T))$, i.e., $m$ has to grow with $T$. Keeping m fixed limits the representation power of the neural network, and such networks cannot be expected to model (including interpolate) an arbitrary function h on T points, where $T$ is arbitrarily large and the points are chosen by an adversary. An interesting variant of your question is: can we get similar results with a smaller $m$, perhaps $m = \\mathcal{O}(T)$ or even $m = \\mathcal{O}(\\log T)$? No prior work has managed to accomplish this without additional assumptions, but this does constitute an important direction for future work. \n\\\n\\\nFor a fair comparison with existing NeuCB algorithm, below we specifically discuss the width requirements for existing algorithms:\n\n    >**(i)** Neural Thompson Sampling (TS) [Zhang et al., 2021]:  $m (\\log m)^{-3} \\geq T^{13}$ (see Condition 4.1 in their paper).\n    \\\n    \\\n    >**(ii)** Neural UCB [Zhou et al., 2020]: $m \\geq T^{16}$.  The main regret bound in Theorem 4.5 requires the width to be $\\tilde{\\Omega}(\\text{poly}(T))$ but does not specify the exact dependence on $T$. However we can infer the exact dependence of $m$ on $T$ from the proof as follows. Consider the last term in the regret bound in the \\emph{Proof of Theorem 4.5}: $m^{-1/6}\\sqrt{\\log m} T^{8/3} \\lambda^{-2/3}L^3$. At the end of the proof the authors conclude that the above term is $\\leq 1$ by choosing sufficiently large $m$. To ensure this one has to choose $m^{-1/6} \\geq T^{8/3}$ or $m \\geq T^{16}$.\n    \\\n    \\\n    >**(iii)** EE-Net [Ban et al., 2022]: $m \\geq T^{30}$.  Theorem 1 requires the width to be $\\tilde{\\Omega}(\\text{poly}(T))$ and does not specify the exact dependence on $T$. Again we can infer it from the proof as follows. Consider the term $\\xi_1 = \\Theta(\\frac{t^4}{m^{1/6}})$ in equation (C.4). The final regret expression sums this term from $t=1$ to $t=T$ (see the display below C.5). The sum is therefore $\\Theta(\\frac{T^5}{m^{1/6}})$ and the authors make it $\\mathcal{O}(1)$ by choosing sufficiently large $m$, which leads to choosing $m^{1/6} \\geq (T^5)$ or $m \\geq T^{30}$ (see the text below C.6).\n\n\\\nOur results need $m = \\Omega(T^5)$. Note that the width requirements of EE-Net is prohibitively large in comparison to our requirements. Further the other two algorithms NeuralUCB and NeuralTS have $\\Omega(T)$ regret in worst case (we show this in Appendix A of the current paper). Therefore for NeuCB even in terms of width requirements our results are better than EE-Net, the only NeuCB algorithm with provably sub-linear regret.\n\\\n\\\nAlso, following your line of thinking, another interesting question to consider is: How would the algorithm look like if T is not known upfront? Note that then we cannot set $m = \\Omega(T^5)$. In this more general setting, the **double trick** would work. In essence, we work with $\\mathcal{O}(\\log T) $ episodes, and for $t \\in (2^{k-1}, 2^k]$, we use a neural network with width $m = \\mathcal{O}(2^{5k})$. Once $t$ crosses $2^k$, a new episode starts, and we initialize a new neural network with width $m = \\mathcal{O}(2^{5(k+1)})$."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7040/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700628492896,
                "cdate": 1700628492896,
                "tmdate": 1700725401625,
                "mdate": 1700725401625,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ASITy3k8Yt",
                "forum": "5ep85sakT3",
                "replyto": "TyEBdAMYTM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7040/Reviewer_eHnV"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7040/Reviewer_eHnV"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your reply.\n\n3. I am confused about the representation power part. I thought by the realizability assumption (assumption 1), you mean that the true function can be represented within the considered class of neural networks with width m? If that is the case then we do not need to worry about the representation power as the considered class of functions contain the true function?"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7040/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700630890528,
                "cdate": 1700630890528,
                "tmdate": 1700630890528,
                "mdate": 1700630890528,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "oLN9U1ntRq",
            "forum": "5ep85sakT3",
            "replyto": "5ep85sakT3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7040/Reviewer_PXpv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7040/Reviewer_PXpv"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the contextual bandit problem with the use of a neural network for online regression. The authors build upon recent progress in our understanding of neural networks, providing an online regression algorithm that for the KL and squared loss acheives O(log T) regret a significant improvement over previous O(sqrt(T)) results. Using this, they employ the reduction of contextual bandits to online regression presented in the SquareCB algorithm of Foster/Rakhlin."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- I found the paper to be easy to read, well-presented and interesting.\n- The results are interesting and seem like a potentially important contribution. \n- It was harder for me to gauge the novelty of the approach used to prove the given results."
                },
                "weaknesses": {
                    "value": "- The main result of this paper is given in section 3, where the authors show that a noise perturbed version of the neural network can be used to obtain a O(log T) regret bound. From what I understood, compared to the past results of Chen which just used Assumption 2a, this result exploited 2b and 2c to gain an improvement. This is akin to the fast rates that one gets for gradient descent run on strongly convex functions vs convex functions. Though the result is natural and intuitive based on Chen, I failed to understand what technical contributions the authors made to achieve the result in Theorem 3.1. Is this a straightforward application of existing results, or did it require a new perspective? Is the noise perturbation the main novelty?  Further discussion would have helped couch this work in the existing literature.\n\n- I was a bit confused about why Section 4 was presented in the context of KL-loss. Presumably it applies to squared loss as well given the results of the previous sections?\n\n- I have some concerns about the experiments. Building on the previous comment, it seems that part of the novelty of this paper is the use of a perturbed neural network. In the experiments you compare your algorithm using KL loss to NeuSquareCB and show an improvement. However, it feels like the natural comparison would be NeuFastCB against a variant using the KL loss where you don\u2019t perturb. Similarly for the square loss. This \u201cablation\u201d-esque study would highlight the important of the algorithmic contributions you have proposed.\n\nMinor Typos\n\n- theta_t in equation 4 should be theta"
                },
                "questions": {
                    "value": "See above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7040/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699565807596,
            "cdate": 1699565807596,
            "tmdate": 1699636826639,
            "mdate": 1699636826639,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "enBW2sU9Ow",
                "forum": "5ep85sakT3",
                "replyto": "oLN9U1ntRq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7040/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7040/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are encouraged by the reviewer's comments. As requested we provide a thorough discussion of the novel aspects of the results and analysis. Further we also clarify the concerns raised in the review.\n***\n**[Q1] Novelty of our results and analysis**\n1. **QG Result (Theorem 3.1):** The regret bound under QG condition (Theorem 3.1) is a new contribution. Unlike [Chen et al., 2021] that uses existing analysis for online regression with convex functions, we develop a new analysis using the following assumptions on the loss function (i) almost convexity, (ii) QG and (iii) unique minima. \n\\\n\\\nWhile Theorem 3.1 is new, (iii) is not satisfied by (wide) neural networks. So, the central challenge was: how to ensure unique minima for losses on neural networks while holding on to QG and almost convexity. The following two points describe this for square loss and KL loss respectively.\n***\n2. **Regret with square loss (Theorem 3.2):** Square loss for (wide) neural networks satisfies (i) almost convexity and (ii) QG. To ensure (iii) unique minima, our novel idea of combining predictions from perturbed networks and a very delicate analysis achieved the following (a) ensured Strong Convexity (SC) with SC constant $\\mathcal{O}(1/\\sqrt{m})$ and therefore unique minima, (b) QG condition with QG constant $\\Theta(1)$, and (c) maintained almost convexity as before. There are two delicate aspects to this approach: \n    >**(i)**  Our analysis ensured that the QG constant is $\\Theta(1)$. This was necessary since the regret bound in (8) was given by \n    $$\\tilde{R}(T)\\leq \\mathcal{O}\\left( \\frac{\\lambda^2}{\\mu}\\log T\\right) + \\epsilon T + 2 \\underset{\\theta \\in B}{\\inf}\\sum_{t=1}^T \\ell(y_t,g(\\theta;x_t))$$ and the QG constant $\\mu$ needed to be $\\Theta(1)$ to ensure that the first term is indeed $\\mathcal{O}(\\log T)$. Also, $\\lambda$ is the lipschitz constant of the loss and we also show that it is $\\Theta(1)$ (see Lemma 5 for square loss and Lemma 9 for KL loss in the current paper)\n\n    >**(ii)** We added a small $\\left(\\Theta(\\frac{1}{m^{1/4}})\\right)$ perturbation to ensure strong convexity (SC) of the loss with SC constant $\\Theta(\\frac{1}{\\sqrt{m}})$, but used this only to ensure uniqueness of the minima. Adding \"small'' perturbation ensured that the perturbed network is not far away from the un-perturbed one and we used this to bound the regret for the original problem.\n\n    **Why ridge regularization does not work**: If one uses the traditional route of adding ridge ($L_2$ squared) regularization to the loss function, then although the loss now has a unique minima, the original analysis with $\\Theta(1)$ PL/QG constant does not work. \n     \n     **Why directly using SC does not work:** Naively using the $\\mathcal{O}(\\log T)$ regret for SC functions also does not work. This is because the constant hidden by $\\mathcal{O}$ scales as $\\frac{1}{\\nu} = \\sqrt{m}$, where $\\nu$ is the SC constant. For large width models, $m \\gg T$, and the bound is $O(\\sqrt{m}\\log T)$, which does not yield a $\\mathcal{O}(\\log T)$ bound (also see Remark 3.5 in the current paper). \n***\n3. **Regret with KL loss (Theorem 3.3):** We showed that a similar set of results hold for KL loss, and thereafter obtained a \"first order\" regret bound, a bound that is data-dependent in the sense that it scales sub-linearly with the loss of the best policy $L^*$ instead of $T$.\n\\\nA noteworthy point about the analysis is the following - although for square loss (without the perturbed network) it was shown that (wide) neural networks satisfy PL and therefore QG, we are the first to show that KL-loss satisfies PL and QG condition which would be of independent interest.\n***\n4. **Regret Lower bounds for existing NeuCB methods:** Further note that our lower bound results which show that NeuralUCB and NeuralTS incur an $\\Omega(T)$ are novel contributions and further highlight the need for provable sub-linear regret guarantees for NeuCBs. To give some details about the lower bounds, for both algorithms we show two kinds of results:\n    \\\n    \\\n    **(i)** An instance where an oblivious adversary selects a set of contexts (at the beginning; doesn't even need to know the set of arms played by the algorithm) and a reward function such that the regret of the algorithm is $\\Omega(T)$.\n\n    **(ii)** We show that for any choice of reward function $h$ and context vectors, the regret of the algorithm is $\\Omega(T)$ as long as $\\frac{||\\mathbf{h}||_2}{\\kappa}$ is $\\mathcal{O}(1)$. Here $\\mathbf{h}$ is the vector of rewards for all contexts and $\\kappa$ is the condition number of the NTK matrix.\n    \\\n    \\\n    These lower bounds make our regret bound contributions far more important. Note that the only other NeuCB algorithm that provides provable sub-linear regret is EE-Net. However EE-Net makes restrictive assumptions (i) EE-Net assumes all contexts are drawn iid from the same distribution, (ii) EE-Net stores all past networks which does not scale to real word deployment."
                    },
                    "title": {
                        "value": "Response to Reviewer PXpv: Novelty of Results and Analysis"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7040/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700542474349,
                "cdate": 1700542474349,
                "tmdate": 1700544184846,
                "mdate": 1700544184846,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sVZH9xSIrN",
                "forum": "5ep85sakT3",
                "replyto": "oLN9U1ntRq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7040/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7040/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer PXpv"
                    },
                    "comment": {
                        "value": "We hope the above discussion helps further clarify all the technical efforts we have put into this paper and better position the paper in the context of current neural contextual bandits literature.\n***\n**[Q2] Section 4 only for KL losses**\n\nWe clarify that Section-4 applies to **both square loss and KL loss**. Algorithm 1 (NeuSquareCB) uses square loss and the corresponding regret bound is given by Theorem 4.1. Algorithm 2 (NeuFastCB) uses KL loss and the corresponding regret bound is given by Theorem 4.2. To further emphasize this we have added a description in the captions of Algorithm-1 and Algorithm-2 in the new draft that explicitly states the loss function being used.\n***\n**[Q3] Concerns about Experiments**\n\nWe did include an ablation study of the perturbed network in Appendix G.1. We also clarify that both NeuSquareCB and NeuFastCB are NeuCB algorithms proposed in the current paper. We have also stated this in Table-1 for quick access. NeuSquareCB uses the novel results developed by us using the perturbed network for square loss in Section 3.2 while NeuFastCB uses a similar set of results for KL loss that we develop in Section 3.3.\nTherefore in our experiments we compare both our NeuSquareCB and NeuFastCB against existing baselines: NeuralUCB, NeuralTS, and Neural $\\epsilon$ greedy.\n\\\n\\\nThe output perturbation ensured a provable $\\mathcal{O}(\\sqrt{KT})$ and $\\mathcal{O}(\\sqrt{KL^*} + K)$ regret bound for NeuSquareCB and NeuFastCB respectively. For the set of problems in our experiments we observe that the non-perturbed versions of NeuSquareCB and NeuFastCB empirically behave similarly to the perturbed versions. However, since the non-perturbed algorithms do not come with a provable regret bound, one may be able to construct a problem where the non-perturbed version performs poorly.\nBecause of space constraints, these comparisons and discussions were included in Appendix G.1. We have included a brief discussion in the main paper with a forward reference to the appendix in the new draft. \n***\n**[Q4] Minor typo:**\n\nThanks for pointing this out. We have updated it in the new version.\n***\n[Chen et al., 2021]: X. Chen, E. Minasyan, J. D. Lee, and E. Hazan. Provable regret bounds for deep online learning and control. arXiv preprint arXiv:2110.07807, 2021."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7040/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700543530285,
                "cdate": 1700543530285,
                "tmdate": 1700544077818,
                "mdate": 1700544077818,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]