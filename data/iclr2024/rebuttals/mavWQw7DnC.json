[
    {
        "title": "Explaining recommendation systems through contrapositive perturbations"
    },
    {
        "review": {
            "id": "NnDY3zZIXH",
            "forum": "mavWQw7DnC",
            "replyto": "mavWQw7DnC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5544/Reviewer_ck6L"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5544/Reviewer_ck6L"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers the interpretability problem \u201cbecause the user interacted with item $j$, we recommend item $i$ to the user\u201d in a factorization model commonly used in recommender systems. From the perspective of contrapositive logit (\u201cbecause the user did not interact with item $j$, we did not recommend item $i$ to the user\u201d), this paper proposes a new explanation algorithm (Contra+) consisting of two steps: (1) perturbing the user embedding to ensure item $i$ is not recommended; (2) given the perturbed user embedding, identifying the historical items that have lost most relevance to the user. Overall, the proposed algorithm is interesting but is more empirical and lacks theoretical guarantees."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. the writing is well and the presentation is clear.\n\n2. the topic is interesting."
                },
                "weaknesses": {
                    "value": "1. the proposed method is more empirical and lacks theoretical guarantees (see main question 1 for more details).\n\n2. something about the key logic of the algorithm is not clearly explained (see main question 2 for more details)."
                },
                "questions": {
                    "value": "**Main Questions**\n\n1.\tthe perspective of contrapositive logit is not fully novel. In fact, Pearl (1999)[1] defined the notation of **probability of necessary causation**, which follows the same logic as contrapositive. There may be some connection between the probability of necessary causation and the method proposed in this paper. Linking the method proposed in this paper with the necessary causality probability may provide a theoretical guarantee for the method proposed in this paper. Could you discuss something about the possible connections?\n\n2.\tHere are some questions about the key logic of the proposed method.\n\n>(1) In terms of the perturbation, (a) Why only the user embedding is perturbed and not the item embedding? It is a bit confusing to me. intuitively, the user after the perturbation is no longer the same user before. (b) Do all user-item pairs, using the same strength ($\\gamma$ and $\\epsilon$ in equation (4)) of perturbation? (c) How to choose the parameters $\\gamma$ and $\\epsilon$ in practical applications?\n\n>(2) For step 2, i.e., identifying the historical items that have lost most relevance to the user. Why the historical items that have lost the most relevance to the new perturbed user embedding is the explanation? Is it equivalent to the statement \u201cbecause the user did not interact with item $j$, we did not recommend item $i$ to the user\u201d? \n\n[1] Judea Pearl (1999), Probabilities of causation: three counterfactual interpretations and their identification.\n\n\n**Minor Questions**\n\n(1)\tThere are some problems with the format of the citation. For example, at the end of the first paragraph in the Introduction, the citation format should appear as (Lu et al., 2012; Aggarwal et al., 2016; Beel et al., 2016; Jannach et al., 2022), which can be generated using the \\citep{XXX} command.\n\n(2)\tThere are some grammatical errors. For example, at the end of the Abstract, \u201c\u2026 because the user did not **interacted** with item $j$ \u2026.\u201d should be  \u201c\u2026 because the user did not **interact** with item $j$ \u2026.\u201d."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5544/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5544/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5544/Reviewer_ck6L"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5544/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698743664205,
            "cdate": 1698743664205,
            "tmdate": 1699636569636,
            "mdate": 1699636569636,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Xk15p6fVjQ",
                "forum": "mavWQw7DnC",
                "replyto": "NnDY3zZIXH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part [1/2] Rebuttal \"Explaining recommendation systems through contrapositive perturbations\""
                    },
                    "comment": {
                        "value": "Thank you! Thank you very much for your insightful comment regarding the connection between the contrapositive logic in our Contra+ method and Judea Pearl\u2019s concepts of the probability of necessary and sufficient causation. This is indeed a very interesting connection to causality that we have tried to touch upon in our discussion on connecting our work to Counterfactual backtracking [1]. We appreciate this opportunity to clarify and elaborate on the novel aspects of our approach, particularly on the established frameworks of causal inference.\n\n1. Connection Between Contra+ and Pearl\u2019s Framework of Necessity and Sufficiency\n\nThe Contra+ method, while distinct in its application, shares a conceptual connection with Judea Pearl\u2019s framework of necessity and sufficiency in causal inference. This connection lies in the underlying logic that both frameworks employ.\n\n- Logical Foundations (our approach): In propositional logic, necessity and sufficiency are expressed as x \u2192 y (sufficiency) and y \u2192 x (necessity). The Contra+ method utilises contrapositive logic, where the inversion of these implications (-y \u2192 -x for sufficiency and -x \u2192 -y for necessity) is central to its explanatory mechanism. For instance, if a recommendation system suggests a movie based on a user's preference for a genre, our method uses contrapositive logic to infer non-preferences from non-recommendations, akin to the logical structure of sufficiency.\n\n- Probabilistic causal Interpretation: Pearl\u2019s work extends these concepts into the probabilistic and causal realm, assessing the likelihood of causation. While Contra+ does not directly engage with probabilistic causation, its logical structure echoes the principles Pearl discusses. The method\u2019s efficiency in explanation generation can be seen as a practical application of these ideas, albeit in a different context and using different assumptions as we will discuss in the following.\n\n2. Delineating the Difference Between Our Method and Pearl\u2019s Framework\nWhile there are conceptual similarities, there are key differences in the application and objectives of our Contra+ method and Pearl\u2019s causal inference framework.\n- Focus on Explanation vs. Causal Analysis: Pearl\u2019s framework is deeply rooted in understanding and quantifying causal relationships in complex systems, where one has to assume a causal structure of the problem. In contrast, our Contra+ method is primarily focused on enhancing the interpretability and efficiency of recommendations in factorization models without any causal assumptions. Our approach is about using logical inferences to provide clear and computationally feasible explanations for recommendations, not to establish causal relationships as this would require causal assumptions such as the graph (not clear in our case) etc. Nevertheless, we agree that this future research direction of bridging this gap between these two frameworks is interesting and would allow us to potentially provide theoretical guarantees.\n\n3. Future Work Outside the Scope of This Paper\nNevertheless, there are several avenues for future research that, while outside the scope of this paper, could enrich the Contra+ method.\n- Integrating Causal Inference Principles: One promising direction is the exploration of how causal inference principles can be applied to explaining recommendation systems. This could involve adapting aspects of Pearl\u2019s framework to better understand the causal mechanisms behind user preferences and behaviours, thereby enhancing the depth and robustness of our explanations. We have also, in section 3.3, mentioned a connection to the recent paper on \"*Counterfactual backtracking*\" [1] which we believe gives a theoretical understanding of what Contra+ is doing under the hood. However, given that we wish to have a general algorithm without too many causal assumptions, we did not opt to connect them via this route 1-to-1. However, for future work, which is outside the scope of this paper, we will consider making this connection more formal as it would enhance the reliability of the method. This paper primarily focuses on a computationally efficient manner to generate explanations for recommender systems and we have shows on extensive experiments the merits of our proposed method.\n\nIn conclusion, while the Contra+ method shares logical underpinnings with Pearl\u2019s framework of necessity and sufficiency, it stands as a distinct approach focused on the specific challenges of explanation in recommendation systems. Future work would aim to explore these theoretical connections further, expanding the method\u2019s capabilities and theoretical foundations.\n\n[1] von K\u00fcgelgen, J, Counterfactual Backtracking"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700235510053,
                "cdate": 1700235510053,
                "tmdate": 1700235510053,
                "mdate": 1700235510053,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZfZwbc8ijP",
            "forum": "mavWQw7DnC",
            "replyto": "mavWQw7DnC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5544/Reviewer_PpEb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5544/Reviewer_PpEb"
            ],
            "content": {
                "summary": {
                    "value": "This paper is trying to address the challenge of explaining recommendations, which is meaningful and important because recommender systems like factorization models based or neural network based are lack of transparency. The paper introduces a novel approach called \"contrapositive explanations (Contra+)\" to provide clear and efficient explanations for recommendations. Contra+ focuses on finding explanations in the form of \"Because the user interacted with item j, we recommend item i to the user.\" This is in contrast to traditional counterfactual explanations, which aim to explain why an item was not recommended. This paper provides detailed discussion for previous methods, many toy examples and figures to make the concepts easier for readers to understand. Finally, the authors demonstrate the effectiveness and efficiency of Contra+ through empirical experiments on real-world datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "S1: This paper considers a interesting questions (explaining recommendation system) from a contrapositive perspective, which is novel.\n\nS2: This paper provides detailed discussion for previous methods, many toy examples and figures to make the concepts easier for readers to understand.\n\nS3: This paper gives a comprehensive review of differences and similarities between contrapositive and counterfactual explanations."
                },
                "weaknesses": {
                    "value": "W1: The key concern is whether there is another way to get the \"explanation\". Further, is there infinite number of ways to perturbation the embedding that can achieve the same purpose, i.e., \"We did not recommend item i to user u\"? In such case, does each way of perturbing embedding correspond to a different h, i.e., \"User u would not have interacted with item h\"? How can we distinguish merits and drawbacks of each perturbation?\n\nW2: Previous literature like Tan et al. [1], studied cause on a particular aspect, i.e., If the item had been slightly worse on [aspect(s)], then it will not be recommended. This can find the cause on a particular aspect, whereas in this paper, the cause is found on perturbation on all embedding. Is any comments for the difference?\n\nW3: The authors give a lot of toy examples, such as rain and slippery roads, or godfather and godfather 2. Can some experiments be added to give some examples of real world datasets where the proposed method finds an explanation? For example, in Netflix or ML-1M, are there any cases where users don't interact with \"computer\" because \"cell phone\" is not suggested?\n\nW4: Counterfactual explanations don't necessarily guarantee removing the explanation or changing the recommendation. Therefore, in figure 1, counterfactual explanations should be 1 as a proportion of all areas, that is, 1/(1+2+3+4), not 1/(1+2).\n\nW5: The experiment process is Evaluations part is not so clear. For example, why is $M_{contra}$ greater than 1? In addition, consider doing some runtime experiments and some other hyper-parameter sensitivity analysis or in-depth analysis like the effect of varying total amount data could be better.\n\n[1] Juntao Tan, Shuyuan Xu, Yingqiang Ge, Yunqi Li, Xu Chen, and Yongfeng Zhang. Counterfactual explainable recommendation. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management, pp. 1784\u20131793, 2021"
                },
                "questions": {
                    "value": "Please refer to the weaknesses part for the questions."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5544/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5544/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5544/Reviewer_PpEb"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5544/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698838035856,
            "cdate": 1698838035856,
            "tmdate": 1699636569546,
            "mdate": 1699636569546,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ScsFkHmhUc",
                "forum": "mavWQw7DnC",
                "replyto": "ZfZwbc8ijP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part [1/2] Rebuttal \"Explaining recommendation systems through contrapositive perturbations\""
                    },
                    "comment": {
                        "value": "First of all, we would like to thank the reviewer for their comprehensive review to improve our paper as well as allowing us an opportunity to clarify any concerns or misunderstandings. We would also like to thank the reviewer for praising our paper for considering an \"*interesting question (explaining recommendation system) from a contrapositive perspective, which is novel.*\" Here below, we have addressed all your concerns.\n\n> W1: The key concern is whether there is another way to get the \"explanation\". Further, is there infinite number of ways to perturbation the embedding that can achieve the same purpose, i.e., \"We did not recommend item i to user u\"? In such case, does each way of perturbing embedding correspond to a different h, i.e., \"User u would not have interacted with item h\"? How can we distinguish merits and drawbacks of each perturbation?\n\nWe thank the reviewer for this clarification question. We agree and have acknowledged this observation in our main text of the paper : \"We emphasize, that do not claim that we are able to find the one and only explanation, but rather, that we are able to provide a contrapositive explanation which fits our logical statement -B\u2192 -A, which is equivalent to A \u2192 B. This is corroborated by our extensive experiments as well.\" \nTo provide more details, even though there are in theory an infinite number of ways to perturb the representations, in this paper, our main focus is on computationally efficient ways to construct contrapositive explanations. We could use more elaborate ways to construct perturbations, however, given that we are practically oriented, we decided to go with the most natural and efficient way to construct the perturbations, which is our proposed method Contra+. We show the merits of Contra+ on numerous experiments in section 4 and demonstrate that this way of constructing perturbations is effective and even matches the performance of the Influence function in some cases. Note that influence functions, which are computationally much more expensive have only been added for completeness and transparency. Future research would investigate how one could trade off computational efficiency with possibly superior explanations. However, this is outside the scope of this paper as we are mainly focusing on computationally efficient algorithms.\n\n> W2: Previous literature like Tan et al. [1], studied cause on a particular aspect, i.e., If the item had been slightly worse on [aspect(s)], then it will not be recommended. This can find the cause on a particular aspect, whereas in this paper, the cause is found on perturbation on all embedding. Is any comments for the difference?\n\nIn Tan et al. the authors focus on counterfactual explanations (-A -> -B i.e. if A did happen then B would not happen), which are different to our proposed method, which utilizes the contrapositive (-B -> -A) nature of explanations. However, the reviewer is raising a very interesting point here, whereby one could potentially perturb the embeddings only in a specific direction such that only a given aspect can be affected and subsequently the rating will drop (-B). This perturbation could then be used to determine the contrapositive explanations. However, there are also challenges associated with this approach, such as accurately determining the appropriate direction to push the embeddings in the direction of these aspects. \nAdditionally, it remains uncertain whether this approach would be more effective compared to the perturbation suggested in our paper, which showcased substantial enhancements in our experimental section. Note that in our contrapositive formulation, we only care about -B\u2192 -A, i.e. conditioned on the user not being recommended item j, the user would not have watched item i. Therefore, any method of inducing -B could be used and we leave this interesting avenue for future research as this would be out of the scope of this paper.\nIn summary, we thank the reviewer for their interesting suggestion to incorporate aspect-specific perturbation in the embedding space, a concept that could provide a valuable addition to our paper. However, it is important to acknowledge that our unique contribution lies in the explanation from a different perspective, which is separate from aspect-specific perturbation.\n\n[1] Kaffes et al Model-Agnostic Counterfactual Explanations of Recommendations\n\n[2] Yao et al, Counterfactually Evaluating Explanations in Recommender Systems \n\n[3] Tran et al, Counterfactual Explanations for Neural Recommenders"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700235011232,
                "cdate": 1700235011232,
                "tmdate": 1700235011232,
                "mdate": 1700235011232,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "mYrPXF3Szv",
            "forum": "mavWQw7DnC",
            "replyto": "mavWQw7DnC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5544/Reviewer_5dmR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5544/Reviewer_5dmR"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes an interesting explanation method to explain recommendation systems through contrapositive perturbations, leveraging the key insight that (negation of B => negation of A) and (A=>B) are equivalent . The proposed method is computational efficient to SVD and MLP-based recommender systems. Lastly, the paper evaluates the approach against benchmarks on several datasets to demonstrate its effectiveness and efficiency in explanations. \n\nThe approach seems novel and interesting but have some questions and concerns on the experimentation session.  Mostly concern if the paper is comparing to the compelling baselines, and M_contra seems to on part to \"influence\" functions in some datasets:\nQ1: do we have compelling baselines to compare against? The reason asked is because if we comparing item similarity and influence comparing to random, they seem to be not very statistically different in M_contra in many cases (i.,e, Figure 2 on Dimension 32 for # of expl Q2:  in Figure 4, it seems that \"Influence\" is comparable or have higher M_contra value as \"Contrapositive\" approach in Dataset ML-100k, is that expected?"
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper proposes an interesting explanation method to explain recommendation systems through contrapositive perturbations, leveraging the key insight that (negation of B => negation of A) and (A=>B) are equivalent . The proposed method is computational efficient to SVD and MLP-based recommender systems. Lastly, the paper evaluates the approach against benchmarks on several datasets to demonstrate its effectiveness and efficiency in explanations."
                },
                "weaknesses": {
                    "value": "Mostly have some concern and/or questions on the Experiment session if the paper is comparing to the compelling baselines. \nQ1: do we have compelling baselines to compare against? The reason asked is because if we comparing item similarity and influence comparing to random, they seem to be not very statistically different in M_contra in many cases (i.,e, Figure 2 on Dimension 32 for # of expl Q2:  in Figure 4, it seems that \"Influence\" is comparable or have higher M_contra value as \"Contrapositive\" approach in Dataset ML-100k, is that expected?"
                },
                "questions": {
                    "value": "Mostly have some concern and/or questions on the Experiment session to prove out on the claims. \nQ1: in Figure (2) and (3), as the number pf experiments increase, in particular at 5, it seems that the contrapositive approach is non-stats sign from other baselines, especially Item Similarity or Influence. Was this the expected behavior?  \nQ2: in Figure 4,  it seems that \"Influence\" is comparable or have higher M_contra value as \"Contrapositive\" approach in Dataset ML-100k, is that expected."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5544/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699274175477,
            "cdate": 1699274175477,
            "tmdate": 1699636569451,
            "mdate": 1699636569451,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XNdaBnLsy0",
                "forum": "mavWQw7DnC",
                "replyto": "mYrPXF3Szv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal for \"Explaining recommendation systems through contrapositive perturbations\""
                    },
                    "comment": {
                        "value": "First of all, we would like to thank the reviewer for their time reviewing our manuscript and giving thought-provoking clarification questions. We would also like to thank the reviewer for praising our paper for being an \"*interesting explanation method to explain recommendation systems through contrapositive perturbations*\". In the following, we will address and clarify all the questions raised in the review.\n\n> Q1: in Figure (2) and (3), as the number pf experiments increase, in particular at 5, it seems that the contrapositive approach is non-stats sign from other baselines, especially Item Similarity or Influence. Was this the expected behavior?\n\nWe thank the reviewer for pointing out this interesting experimental observation in our paper. The fact that the results are similar to influence function and item similarity for ML-100K, when the number of explanations increases to 5 is somewhat expected because the contrapositive and the counterfactual metrics are correlated. This has been shown in the experimental section as well as mentioned at the bottom of section 4, where we state that \"*Both contrapositive and counterfactual metrics make use of the quantity in the top left corner in Figure 1 in their computation and hence there is a clear correlation between the metrics*\". Hence, as we increase the number of explanations, quadrant 1 will increase and quadrants 2 and 3 will decrease for the counterfactual and contrapositive metric respectively.\n\nIntuitively, as we increase the number of explanations, we are more likely from the counterfactual perspective, to select a historical item that, if removed, will change the recommendation. Therefore, as we increase the number of explanations, we expect both counterfactual and contrapositive metrics to increase up to a certain point and we observe that at around 5 explanations they both plateau for ML-100K. \n\nLastly, we want to emphasize that in real application settings (such as social media apps), the goal is to keep the explanations to a minimum to reduce user confusion. Hence, we only added the experiments with 5 explanations as ablation to understand the behaviour and large explanation sizes. Previous works such as [1] only considered explanation sizes of 3.\n\n\n> Q2: in Figure 4, it seems that \"Influence\" is comparable or have higher M_contra value as \"Contrapositive\" approach in Dataset ML-100k, is that expected.\n\nWe thank the reviewer for this observation and we will add a detailed discussion in the final version of the paper. In particular, we want to first highlight that influence functions have only been added for completeness and transparency, as they are not computationally feasible in large recommender systems. The main focus of our paper is on computationally efficient methods for explanations in the realm of recommender systems. Therefore computational cost of influence functions is not directly comparable, as influence functions require the computation of a Hessian matrix inverse. Nevertheless, for completeness and transparency, we show that even despite these computational differences, our proposed method Contra+ can perform on par with influence functions, not only on the contrapositive but also on counterfactual metric, which is a very promising result.\nSecondly, in terms of the results being higher or comparable to our proposed method, we would like to highlight that for all the methods that are computationally comparable to our proposed methods (Random, item similarity), we perform significantly better for explanation sizes 1 to 3 for the contrapositive metric and do significantly better on the counterfactual metric across explanation sizes.\n\nWe thank the reviewer again for their time reviewing our paper and hope that the above has clarified all of the reviewer's questions. We would appreciate it if the reviewer could increase their score if the above has appropriately answered all your concerns and we are more than happy to answer any remaining questions the reviewer might have.\n\n[1] Yao et al, Counterfactually Evaluating Explanations in Recommender Systems"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700234366257,
                "cdate": 1700234366257,
                "tmdate": 1700234366257,
                "mdate": 1700234366257,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]