[
    {
        "title": "Swift Sampler: Efficient Learning of  Sampler by 10 parameters"
    },
    {
        "review": {
            "id": "JvRypeyEoW",
            "forum": "OwHAzbkk5z",
            "replyto": "OwHAzbkk5z",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2232/Reviewer_YacP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2232/Reviewer_YacP"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces an efficient automatic sampler search algorithm, SS, designed to optimize data selection for deep learning model training. While previous methods relied on heuristic guidelines or labor-intensive trials, SS offers a streamlined approach by mapping samplers to a reduced set of hyper-parameters. It quickly gauges sampler quality using an approximated local minimum, making it computationally economical and ideal for vast datasets. Extensive testing shows SS-enhanced sampling delivers notable performance gains, such as a 1.5% improvement on ImageNet, and offers transferability across different neural network architectures."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Data sampling strategy is indeed an important topic and could benefit the community.\n2. The paper is well written and there are rigorous motivations for the choice of the SS method and the algorithm is well presented."
                },
                "weaknesses": {
                    "value": "Despite the good presentation and mathematical formulations, the results of the proposed method are not convincing enough. The reported baseline methods seem to be significantly lower than the common baselines. For example, MobileNetV2 is known to be able to achieve 72% - 74% top-1 accuracy on the ImageNet-1K dataset. The reported value in the paper is 70.4%. In fact, even the improved results of MBV2 with SS is still significantly lower than the common baseline. The same trends hold for all the models reported in the paper. It would be more convincing if the authors could verify the effectiveness of the proposed method on baseline models with \"normal\" training."
                },
                "questions": {
                    "value": "Please refer to the weakness part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2232/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2232/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2232/Reviewer_YacP"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2232/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698737681497,
            "cdate": 1698737681497,
            "tmdate": 1699636156468,
            "mdate": 1699636156468,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pevEYM8lJW",
                "forum": "OwHAzbkk5z",
                "replyto": "JvRypeyEoW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2232/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2232/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer YacP"
                    },
                    "comment": {
                        "value": "We really appreciate for your valuable comments, and are sincerely sorry for this late reply due to the time cost of conducting necessary experiments.\n\n***\n\n__Reproducction of common baseline.__\n\nThanks for your good advice to further improve our work. The reason is that we used the official training script of ResNet for all experiments, without further tricks added. Also, the baseline performance of ResNet and SE-ResNet in our paper is not worse than that released in their original papers. To make our result more convincing, we re-conduct our MobileNetV2 experiment with the official released code on both MobileNetV2, and MobileNetV2(1.4) with the expansion ratio 1.4. Also, we tried __SS__  with the recent model Swin-B on the official released code. The result below verifies that __SS__  does have the ability to improve the performance based on the common baselines:\n\n\n| Model | MobileNetV2  | MobileNetV2(1.4) | Swin-B |\n|-----------|-----------|-----------|-----------|\n| Baseline |  72.0   | 74.7     | 83.5 |\n| __SS__  | 73.4   |75.9|84.3|"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2232/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700632734382,
                "cdate": 1700632734382,
                "tmdate": 1700632734382,
                "mdate": 1700632734382,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hqkyakThPN",
                "forum": "OwHAzbkk5z",
                "replyto": "pevEYM8lJW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2232/Reviewer_YacP"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2232/Reviewer_YacP"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their newly added experiments. However, I still have concerns about the accuracy of the baseline methods. The improvements of the proposed methods are obvious in the reproduced model results. However, it is important to see if the proposed methods can be combined with other training tricks to make improvements under stronger training settings. Thus, I decided to keep my original score."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2232/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700633959434,
                "cdate": 1700633959434,
                "tmdate": 1700633959434,
                "mdate": 1700633959434,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "T3P09E7jnB",
                "forum": "OwHAzbkk5z",
                "replyto": "JvRypeyEoW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2232/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2232/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer YacP"
                    },
                    "comment": {
                        "value": "Thank you for your patience while we supplement our experiments.\n\nTo evaluate the performance of __SS__ in strong setting with advanced tricks, we apply  __SS__ in ResNet 50 along with a set of tricks proposed in [1], the table below verifies that __SS__ can further boost the performance even based on strong tricks.\n\n| Model | ResNet-50   | \n|-----------|-----------|\n|Baseline  |  79.4  | \n| __SS__ | 80.2 |\n\n\n[1]. He, Tong, Zhi Zhang, Hang Zhang, Zhongyue Zhang, Junyuan Xie, and Mu Li. \"Bag of tricks for image classification with convolutional neural networks.\" In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 558-567. 2019."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2232/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700716922149,
                "cdate": 1700716922149,
                "tmdate": 1700718393665,
                "mdate": 1700718393665,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "oBoMQuzrQ7",
            "forum": "OwHAzbkk5z",
            "replyto": "OwHAzbkk5z",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2232/Reviewer_BnW4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2232/Reviewer_BnW4"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose an automatic swift sampler search algorithm to explore automatically learning effective samplers. They then examine the quality of a sampler at a low computational expense by mapping a sampler to a low dimension of hyper-parameters and use an approximated local minimum."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper introduces a novel formulation to map a sampler to a low dimension of hyper-parameters\nThe paper uses an approximated local minimum to quickly examine the quality of a sampler rather than training from scratch, which is efficient and rarely done in previous works.\nThe paper also designs a transform function to smooth the objective function of the sampler search problem and uses Bayesian optimization as the agent for the search process\nThe paper demonstrates the transferability of the learned samplers"
                },
                "weaknesses": {
                    "value": "The paper does not provide enough theoretical analysis or justification for its proposed formulation, transform function, and approximation method. \n\n             Can the author provide more profound  justification ?\n\nThe paper does not explain why its method can generalize to different tasks and datasets, or  provide any experiment on how it compares with other sampler search methods in terms of complexity and scalability.\n             \nCan the author complete the relevant comparative experiments ? \n\nThe paper does not conduct ablation studies or sensitivity analysis to show the impact of different components or hyper-parameters of its method.\n\nCan the author explain the effectiveness of components separately?\n\nThe paper does not report the standard deviation or confidence interval of its experimental results, which makes it hard to assess the statistical significance and robustness of its method."
                },
                "questions": {
                    "value": "see above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2232/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698829072489,
            "cdate": 1698829072489,
            "tmdate": 1699636156386,
            "mdate": 1699636156386,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bWog3QjxmY",
                "forum": "OwHAzbkk5z",
                "replyto": "oBoMQuzrQ7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2232/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2232/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer BnW4"
                    },
                    "comment": {
                        "value": "We really appreciate for your valuable comments, and are sincerely sorry for this late reply due to the time cost of conducting necessary experiments.\n***\n__Theoretical justification of the proposed components.__\n\nIn this paper, we focus on verifying that a family of sampler with a simple form can be well combined with bayesian optimization to achieve general improvement on various datasets and tasks. Unfortunately, when considering the theoretical justification, we find that there are nearly no mathematical tools to relate the neural network performance with the sampling function, due to the high complexity of neural network. In the early stage of this work, we achieved several theoretical conclusions with the assumptions of linear regression on noisy labeled dataset, but we found it hard to extend to neural networks and more complex tasks. We really hope that more strong mathematical tools can be developed to well support our research.\n***\n__Complexity and scalability.__\n\nCompared with the baselines in this paper, the proposed method __SS__ has natural advantage in scalability, as verified in Table 2, __SS__ can search with a small network and achieve a once-for-all sampler, which means it can be reused in all further training as well as reused for other network architectures. For complexity, in the experiment of this paper, the GPU x time cost of __SS__ is 2.3~3.1 times of training a network from scratch, which is in the same level as the baseline methods.\n***\n__The impact of different components.__\n\nWe design ablation experiments in Figure 3 to validate the proposed transform function cgf compared with cdf, and the choice of Bayesian optimization compared with reinforcement method. The result reveals that the designed components have obvious performance margins over the comparative baselines. For hyper-parameters of Bayesian Optimization, we use the most common parameter combination which is shown to work well in most optimization tasks.\n***\n __Standard deviation.__\n\nThanks for your valuable advice, we will add the standard deviation of all experiments in the final version. We omit it in the paper because the standard deviation is quite small (0.04~0.10 for 5 runs). We are sincerely sorry for not being rigorous enough."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2232/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700633071800,
                "cdate": 1700633071800,
                "tmdate": 1700633071800,
                "mdate": 1700633071800,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "xTkMgHN11W",
            "forum": "OwHAzbkk5z",
            "replyto": "OwHAzbkk5z",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2232/Reviewer_UJut"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2232/Reviewer_UJut"
            ],
            "content": {
                "summary": {
                    "value": "The purpose of this paper is to create a sampler that can assign appropriate sampling probabilities to training data in order to improve performance. Unlike previous approaches that relied on heuristic rules or expensive learning methods, this paper proposes an automatic and efficient sampler search algorithm called SS. Specifically, SS employs a new formulation to map a sampler to a lower-dimensional space of hyper-parameters and uses an approximated local minimum to quickly evaluate the quality of a sampler. SS can be applied on large-scale data sets with high efficiency and leads to performance gains on various datasets, e.g., CIFAR10, CIFAR100, ImageNet-1k, and YTF."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The motivation of this paper is clearly illustrated, and it is convincing. How to efficiently and effectively search for a proper data sampling policy is important. \n\n2. The solution is reasonable. The proposed inner loop and outer loop pipeline with Dimension Reduction, Smooth the Objective Function, and Local Minima Approximation designs are innovative."
                },
                "weaknesses": {
                    "value": "1. The outer loop searches for the sampler that has the best score on the validation set. It seems the final performance is also reported on the validation set. Should this lead to the model overfitting the validation set? This paper should also report the performance of test sets.\n\n2. The experimental results of the proposed SS is not impressive. The performance of reported models is far behind the SOTA methods, e.g., Swin Transformer and ConvNext. The SS should be tried on SOTA methods to make the performance gains more convincing.\n\n3. More recently proposed works, e.g., automated loss function search e.g., Li et al. (2019a) and augmentation policy search methods Lin et al. (2019); Tian et al. (2020), should be compared in performance."
                },
                "questions": {
                    "value": "See weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2232/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698841305878,
            "cdate": 1698841305878,
            "tmdate": 1699636156320,
            "mdate": 1699636156320,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "UN7Lr68k5P",
                "forum": "OwHAzbkk5z",
                "replyto": "xTkMgHN11W",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2232/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2232/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer UJut"
                    },
                    "comment": {
                        "value": "We really appreciate for your valuable comments, and are sincerely sorry for this late reply due to the time cost of conducting necessary experiments.\n\n***\n\n__Overfitting on validation set.__\n\nWe are sorry for not clarifying the experiment details, in our ImageNet and MS1M experiments, the outer loop search is on the validation set, which are separately 10% and 15% of the train set of ImageNet and MS1M. And the final performance is reported on the test set.\n\n***\n__Experiments with SOTA model.__\n\nThanks for your good advice, to better reveal the convincing gain of __SS__, we tried it on the Swin Transformer. Due to the limitation of computational cost, we perform __SS__ on Swin-T (4.5GFLOPS) and evaluate the searched sampler on Swin-B (15.4GFLOPS), the result is:\n\n| Model | Swin-T  | Swin-B |\n|-----------|-----------|-----------|\n| Baseline |  81.2/95.5  | 83.5/96.5 |\n| __SS__ on Swin-T | 82.1/95.6| 84.3/96.5|\n\nwhich verify the gain of __SS__ is not only convincing but also general on different families of network architecture.\n\n***\n__Important relative works__\n\n\nThanks for providing the important relative works about auto augmentation and auto loss function search. In our opinion, these works and our __SS__ are orthogonal components of AutoML and should be compatible with each other. To verify it, we empirically show that __SS__ can further boost the performance based on the auto augmentation method in Lin et al. (2019), with the result listed below.\n\n| Model | ResNet-50   | SRNext-101 |\n|-----------|-----------|-----------|\n|AutoAug  |  78.9/94.3  | 80.7/95.4 |\n| __SS__ w/ AutoAug  |  79.7/94.4| 81.4/95.4|"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2232/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700632649622,
                "cdate": 1700632649622,
                "tmdate": 1700632649622,
                "mdate": 1700632649622,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]