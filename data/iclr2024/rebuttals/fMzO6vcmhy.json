[
    {
        "title": "QORA: Zero-Shot Transfer via Interpretable Object-Relational Model Learning"
    },
    {
        "review": {
            "id": "SxkZ77HC6n",
            "forum": "fMzO6vcmhy",
            "replyto": "fMzO6vcmhy",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7177/Reviewer_XA1i"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7177/Reviewer_XA1i"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a QORA \u2013 algorithm that constructs versatile models from domain-agnostic object-based state representations, addressing the generalization challenges faced by current approaches. On a proposed benchmark to depict the generalization capability, they depict better predictive accuracy with significantly fewer observations compared to their baselines, showcasing zero-shot transfer to altered environments, and quick adaptation capabilities to tasks with previously unseen object interactions."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The presented benchmarking environment in this study is thoughtfully designed, offering a clear understanding of the rationale behind each component, including walls, doors, and the fish system. \nAdditionally, Section 3, which delineates the different elements of the proposed approach, provides readers with a comprehensive insight into the methodology's operation."
                },
                "weaknesses": {
                    "value": "The proposed benchmark exhibits limitations in terms of its representation of real-world complexities. Despite featuring three distinct testing environments, it falls short of capturing the nuanced and open-ended nature of real-world concepts. The grid world benchmark, while valuable for assessing agent generalization capabilities, may be considered relatively straightforward and may not fully address the complexities exhibited by current deep learning systems with intricate behaviors. Moreover, its discrete nature may not adequately mirror the continuous nature of many real-world generalization challenges.\nWhile the paper attempts to evaluate against neural network-based approaches, it predominantly relies on relatively simplistic methods, with the best-performing one being the CNN. I recommend the authors expand the range of neural network baselines for a more comprehensive comparison with the proposed approach. Additionally, extending the evaluations to larger grid sizes would provide valuable insights into how performance scales."
                },
                "questions": {
                    "value": "The paper could benefit from providing more detailed information on hyperparameters and implementation specifics. Including a section on the potential broader impact of the proposed approach would also enhance the reader's understanding and appreciation of the work.\nAs mentioned in Weaknesses, I would recommend the authors evaluate against a more exhaustive set of approaches."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7177/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7177/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7177/Reviewer_XA1i"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7177/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697929716034,
            "cdate": 1697929716034,
            "tmdate": 1699636851600,
            "mdate": 1699636851600,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LfrrDusVrO",
                "forum": "fMzO6vcmhy",
                "replyto": "SxkZ77HC6n",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7177/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7177/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (1/2)"
                    },
                    "comment": {
                        "value": "> [1] The proposed benchmark exhibits limitations in terms of its\n    representation of real-world complexities. Despite featuring\n    three distinct testing environments, it falls short of capturing\n    the nuanced and open-ended nature of real-world concepts.\n\nWhen assessing the capabilities of QORA, it is important\nto compare it to similar work to ensure that the comparison is fair.\nWhile deep reinforcement learning *in general* is applied to a\nwide variety of problems, if we consider the specific subtask we are\nfocusing on here -- object-oriented transition modeling without\ndomain knowledge, with a focus on generalization, efficiency, and\ninterpretability -- we see that existing methods struggle in many\nways, while QORA performs enormously better. For example, transition\nmodeling is a notoriously difficult problem, resulting in modern deep\nreinforcement learning approaches often being model-free. Even notable\nmodel-based techniques, such as MuZero, do not actually attempt to\nmodel the environment's full transition function (and even then, the fact that\nMuZero makes model-based reinforcement learning work is a big\nachievement). When compared with non-deep methods, QORA is applicable\nto *substantially* more complex domains, as it learns rules in a\ngeneral form and requires no domain-specific information. We have\nrevised the introduction to highlight some of these points and\naddress possible confusion.\n\n> [2] The grid world benchmark, while valuable for assessing agent\n    generalization capabilities, may be considered relatively\n    straightforward and may not fully address the complexities\n    exhibited by current deep learning systems with intricate\n    behaviors.\n\nWe agree that these test domains are valuable for\nassessing generalization, as this is part of the motivation for each\nenvironment's design. However, we believe that our experiments\n(especially those in the revised paper) demonstrate that our\nenvironments, though they may *seem* straightforward to humans,\nare actually far from it: as shown in Figures 2a and 2b of the\nrevision, the deep-learning baselines are unable to learn even our\nsimplest domain *and* they show a massive increase in error\nafter transfer. In the same task, QORA demonstrates perfect zero-shot\ntransfer to an even more complex setting after training on far less\ndata.\n\n> [3] Moreover, its discrete nature may not adequately mirror the\n    continuous nature of many real-world generalization challenges.\n\nThe continuous nature of the world does indeed bring many\nchallenges, which we should be able to tackle in future work based\nthe ideas proposed in the current paper. However, as QORA is an\ninitial prototype in this research direction, dealing with these\ngeneralizations is beyond the scope of this paper.\n\n> [4] While the paper attempts to evaluate against neural\n    network-based approaches, it predominantly relies on relatively\n    simplistic methods, with the best-performing one being the CNN. I\n    recommend the authors expand the range of neural network\n    baselines for a more comprehensive comparison with the proposed\n    approach.\n\nUnfortunately, there are not many existing approaches that\nare applicable to the specific problem we are concerned with; we have\nrevised the introduction to be more clear about this. We have also\nincluded an additional baseline method, MHDPA, though it performs\nquite similarly to NPE no matter how we adjust its parameters or\narchitecture. We have also added details to the new appendix to\nclarify that the implementations of these two baselines are quite\nsophisticated (especially relative to the problem they are being\napplied to).\n\nWe have also removed comparisons to the CNN, as it was a hand-crafted\n    architecture specifically designed to solve the walls domain.\n    Thus, it incorporated domain knowledge, which disqualifies it\n    from being a valid approach within the context of the paper."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700724476494,
                "cdate": 1700724476494,
                "tmdate": 1700724476494,
                "mdate": 1700724476494,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Tgtj9KazpZ",
                "forum": "fMzO6vcmhy",
                "replyto": "SxkZ77HC6n",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7177/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7177/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (2/2)"
                    },
                    "comment": {
                        "value": "> [5] Additionally, extending the evaluations to larger grid sizes\n    would provide valuable insights into how performance scales.\n\nThe revision contains new zero-shot transfer experiments\nthat go from 8x8 to 64x64 and 128x128. We also demonstrate its\ncapabilities in going from a small number of bulbs to a large number. In\neither case, once QORA learns the proper relational rules, the\nworld's size has no bearing on its predictive accuracy, so the domain\ncould be scaled up to any size without affecting QORA's accuracy.\n\nIn terms of computational performance, as with all existing work,\n QORA's runtime (for both training and prediction) is related to the\n number of objects; thus, scaling up the world does increase the\n training and evaluation cost. This actually makes QORA's\n generalization ability even more impressive -- it can be trained on\n small worlds at low cost and immediately deployed in larger ones\n without having to invest the extra cost to learn the bigger world\n from scratch. In the new Figure 3c of the revision, we demonstrate\n the utility of this approach.\n\n> [6] The paper could benefit from providing more detailed\n    information on hyperparameters and implementation specifics.\n\nQORA has only a single hyperparameter, $\\alpha$, which is\ndiscussed in Section 3 and whose value is included in each relevant\nexperiment. In the revision, we have outlined the design/training of the neural-network baselines\nused in our experiments in the new Appendix.\n\n> [7] Including a section on the potential broader impact of the\n    proposed approach would also enhance the reader's understanding\n    and appreciation of the work.\n\nWe have revised the introduction to be more explicit about\nthe motivation behind our approach and its potential for paving the\nway towards more sophisticated future applications.\n\n> [8] As mentioned in Weaknesses, I would recommend the authors\n    evaluate against a more exhaustive set of approaches.\n\nPlease see our response to weakness \\#4"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700724488614,
                "cdate": 1700724488614,
                "tmdate": 1700724488614,
                "mdate": 1700724488614,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Soz0qLbuOj",
            "forum": "fMzO6vcmhy",
            "replyto": "fMzO6vcmhy",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7177/Reviewer_95NR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7177/Reviewer_95NR"
            ],
            "content": {
                "summary": {
                    "value": "In their submission, the authors present QORA, a novel algorithm that seeks to address the persistent challenge of generalization in reinforcement learning. QORA distinguishes itself by utilizing an object-oriented framework capable of forming models from a domain-agnostic, object-based state representation. This approach allows it to effectively handle environments with stochastic transitions.\n\nKey contributions of the paper include:\n\n1. Algorithmic Development: The introduction of QORA, which can efficiently construct expressive models that are demonstrated to solve a diverse array of domains.\n2. Generalization Capability: QORA's design enables it to achieve perfect predictive accuracy in the authors' test domains, far surpassing the baseline neural network model in terms of the number of observations needed by nearly four orders of magnitude.\n3. Zero-Shot Transfer: The algorithm's capacity for zero-shot transfer is particularly noteworthy, as it can adapt to environments that have been modified without the necessity for retraining.\n4. Adaptability: The adaptability of QORA is further evidenced by its rapid learning curve when faced with tasks that include interactions with new objects not present in the training set.\n5. Interpretability of Results: QORA's ability to generate easily interpretable rules is a significant step towards bridging the gap between performance and understandability in machine learning models.\n6. Benchmark Suite: The authors also contribute a novel benchmark suite tailored to assess the generalization capabilities of learning algorithms, which is a valuable asset for future research in the field.\n\nOverall, QORA represents an advancement in the pursuit of generalizable reinforcement learning algorithms, with a clear emphasis on efficiency, transferability, and interpretability."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Originality:\n\n- QORA's approach to utilizing object-oriented representations for state transitions in RL is a refreshing direction that diverges from standard neural network methodologies. It contributes to the field by removing the limitations seen in prior model-based RL methods.\n- The paper's novelty is also evident in the creative combination of interpretability and generalization, which are often challenging to achieve simultaneously in RL.\n\nQuality:\n- The authors make a good effort to provide benchmarks that can directly evaluate the particular angles they investigate. \n\nClarity:\n\n- The interpretability of QORA's learned rules is a testament to the clarity of the approach, which is commendably communicated through examples in the paper.\n\nSignificance:\n\n- The significant reduction in sample complexity and successful zero-shot transfer capability indicate that QORA could have a substantial impact on the efficiency of RL models."
                },
                "weaknesses": {
                    "value": "1. Overall, the writing is overly complex, detracting from the key methods involved.\n2. The proposed model is difficult to conceptualize, especially without a supporting figure.\n3. The proposed benchmarks, while suitable as toy tests, do not extend to nuanced representation learning and remain within grid worlds, where performance does not always translate to more realistic settings.\n4. There are technical imprecisions; contrary to the authors' claims, CNNs can support variable length inputs, and architectures using 3x3 convolutions can model longer-term dependencies through mechanisms like average pooling, self-attention, max pooling, and CNN cascades.\n5. The neural network details used for comparison are not provided, which is a critical omission for reproducibility and transparency.\n6. Figures intended for side-by-side comparison have differing scales, which could mislead the interpretation of the results.\n7. The evaluation is not sufficiently robust and lacks the depth needed to substantiate the claims made."
                },
                "questions": {
                    "value": "- **Writing Clarity:**  \nThe manuscript could benefit from a more streamlined exposition. Is a revision feasible to improve clarity and conciseness, particularly in the methodological description of QORA?\n\n- **Model Visualization:**  \nIncluding a figure to visualize QORA's architecture may aid in understanding. Could such a figure be provided?\n\n- **Benchmark Scope:**  \nThe benchmarks focus on grid-world environments. Can you extend these to more complex settings to better illustrate QORA's generalization?\n\n- **Technical Precision:**  \nClarification is needed on the statements about CNNs' capabilities. Can you reconcile these with the known utility of CNNs in handling variable input lengths and context-length dependencies?\n\n- **Baseline Details:**  \nA detailed description of the neural network baselines would be beneficial. Could you provide this additional context?\n\n- **Figure Consistency:**  \nThe varying scales in comparative figures may lead to misinterpretation. Can you ensure uniform scales across all relevant figures for clarity?\n\n\nAddressing these points could significantly improve the quality and impact of the work, and would improve substantially any conclusions drawn."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7177/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698722300040,
            "cdate": 1698722300040,
            "tmdate": 1699636851463,
            "mdate": 1699636851463,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1LCZ4oYuPz",
                "forum": "fMzO6vcmhy",
                "replyto": "Soz0qLbuOj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7177/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7177/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> [W1] Overall, the writing is overly complex, detracting from the key methods involved.\n\nSome parts of the paper may be technical, but QORA is\n quite complex by itself and unfortunately the limited space of ICLR\n does not allow for a more detailed explanation.\n\n> [W2] The proposed model is difficult to conceptualize, especially\n    without a supporting figure.\n\nWe have added a figure to the Appendix, with a reference in Section 3.2, to help the reader\nunderstand the overall operation of our algorithm.\n\n> [W3] The proposed benchmarks, while suitable as toy tests, do not\n    extend to nuanced representation learning and remain within grid\n    worlds, where performance does not always translate to more\n    realistic settings.\n\nQORA is not limited to grid worlds; instead, it can\noperate in a wide variety of scenarios that follow causality\nprinciples that can be conceptualized by predicate logic. Hence, the\nenvironments included in the paper should be viewed as examples that\ndemonstrate specific aspects of QORA's functionality rather than its\ninherent limitations. To highlight this further, the revised paper\nincludes experiments with a new domain where QORA has to learn the\noperation of a switch that toggles a number of light bulbs. As given\nin the new conclusion, future work will extend QORA to additional\nmodes of operation (e.g., planning, exploration) and explore\ndomains with more complex object interactions. We consider these\ntopics beyond the scope of the current paper.\n\n> [W4] There are technical imprecisions; contrary to the authors' claims, CNNs can support variable length inputs, and architectures using 3x3 convolutions can model longer-term dependencies through mechanisms like average pooling, self-attention, max pooling, and CNN cascades.\n\nIndeed, we could've worded this better. The intent was to communicate that CNNs would not work (at least, not in a reasonable way) with our object-based state representation. In the revision, the relevant text has been removed due to restructuring, so the problem is no longer present.\n\n> [W5] The neural network details used for comparison are not provided, which is a critical omission for reproducibility and transparency.\n\nThis information eventually could be obtained\nfrom the release of our neural-network test scripts, along with a\nQORA implementation. But in the mean time, the revision contains an\nAppendix with information on the neural networks used in the\ncomparison.\n\n> [W6] Figures intended for side-by-side comparison have differing\n    scales, which could mislead the interpretation of the results.\n\nIt is unclear which plots the reviewer refers to and/or which\naxes. If this is the y-axis in the six graphs of Figure 2, there is\nabsolutely no way that error curves that peak at 0.4 can be on the\nsame scale as those that reach 100. This would make the former\nbasically a flat line at zero. Instead, the figures are scaled to\nmake the various curves clearly visible. If the question refers to\nFigure 3 or 4, the various plots therein are either on the same scale\nor they show completely different metrics that are not meant to be\ncompared (e.g., space complexity of QORA vs error).\n\n> [W7] The evaluation is not sufficiently robust and lacks the depth needed to substantiate the claims made.\n\nWe believe that our experiments are quite thorough,\nespecially with the new results included in the revision (e.g.,\nzero-shot transfer to 128x128 worlds, the light bulb domain). If the\nreviewer has the specifics about which parts of the evaluation are\nnot robust and/or which claims are unsubstantiated, we would be\ninterested in addressing them in the camera-ready version."
                    },
                    "title": {
                        "value": "Response (1/2)"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700724385531,
                "cdate": 1700724385531,
                "tmdate": 1700724431241,
                "mdate": 1700724431241,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "OLDbYi5wqD",
                "forum": "fMzO6vcmhy",
                "replyto": "Soz0qLbuOj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7177/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7177/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> [Q1] Writing Clarity: The manuscript could benefit from a more\n    streamlined exposition. Is a revision feasible to improve clarity\n    and conciseness, particularly in the methodological description\n    of QORA?\n\nDue to the nature of the content, as well as the\nneed to include details for future readers, it is difficult to make\nSection 3 any shorter. It is also unlikely that making a description\nshorter can make it more clear. In any case, to help ease the reader\nthrough the description of our algorithm, we have added more\nexplanations to parts of QORA, especially in Section 3.2, and\nintroduced Figure 4 in the revision.\n\n> [Q2] Model Visualization: Including a figure to visualize QORA's architecture may aid in understanding. Could such a figure be provided?\n\nYes, Figure 4 in the appendix visualizes some of the structures described in Section 3.2.\n\n> [Q3] Benchmark Scope: The benchmarks focus on grid-world\n    environments. Can you extend these to more complex settings to\n    better illustrate QORA's generalization?\n\nThe fact that the included environments are primarily\ngrid-worlds is not due to a limitation of QORA; in fact, the revision\nincludes a new light-bulb environment that is not a grid-world (it\nactually has no specific positional information at all). Rather,\ngrid-worlds are a convenient tool for helping the reader understand\nthe workings of the environment. QORA can learn rules in a fairly\ngeneral form, but many of these domains would make little sense to\nhumans (e.g., relations in a 7-dimensional space) or be unnecessarily\ncomplex (e.g., rules with hundreds of predicates). Instead, the paper\nurges the reader to focus on the essence of QORA's generalization\ncapability: QORA learns rules *as simple as possible* to better\nreflect the underlying transition dynamics of the environment\n*without* relying on information specific to some arbitrary\nsubset of states. This property holds no matter what environment QORA\nis applied to, while the same universally does *not* hold for\nprior work (as demonstrated by Figure 2b in the revised paper).\n\n> [Q4] Technical Precision: Clarification is needed on the statements\n    about CNNs' capabilities. Can you reconcile these with the known\n    utility of CNNs in handling variable input lengths and\n    context-length dependencies?\n\nPlease see response to weakness #4 (W4).\n\n> [Q5] Baseline Details: A detailed description of the neural network baselines would be beneficial. Could you provide this additional context?\n\nPlease see response to weakness #5 (W5).\n\n> [Q6] Figure Consistency: The varying scales in comparative figures\n    may lead to misinterpretation. Can you ensure uniform scales\n    across all relevant figures for clarity?\n\nPlease see response to weakness #6 (W6)."
                    },
                    "title": {
                        "value": "Response (2/2)"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700724413310,
                "cdate": 1700724413310,
                "tmdate": 1700724438756,
                "mdate": 1700724438756,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ErqHX70lbq",
            "forum": "fMzO6vcmhy",
            "replyto": "fMzO6vcmhy",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7177/Reviewer_Kowy"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7177/Reviewer_Kowy"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new object-oriented transition model, Quantified Object Relation Aggregator (QORA). Different from the previous work, DOORMAX, it can learn the general class of transition rules, which are interpretable and cover stochastic transitions. Additionally, they also proposed a new benchmark to evaluate the object-oriented transition models. In this environment, there are several object classes which attributes and transition rules are different, and one of the class has a stochasticity in its movement. In this paper, the authors evaluated their proposed model, QORA outperformed the baselines including several Neural Network models, and it showed a good generalization performance for diverse size of rooms, and can be trained for the stochastic transitions also."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This paper proposes a new object-oriented transition model which can cover general rules of stochastic transitions.\n- To evaluate the object-oriented transition model, a new benchmark is proposed, and it is reasonably designed to evaluate the object-oriented models.\n- The evaluation is done step-by-step, which can make the reader understand the strengths of their model easily.\n- Unseen size of environments, and object attributes are evaluated for showing the generalization performance of their model."
                },
                "weaknesses": {
                    "value": "- Their presentation looks not ready to be published yet in many aspects.\n    - Ambiguous expression or not introduced terms.\n        - In the introduction, the terms \"generalization\" (the model's ability to make effective decisions when exposed to novel inputs), \"interpretability\" (how easily its learned parameters can be inspected and understood by a human), and \"robustness\" (the predictability of its behavior on arbitrary inputs) need clarification. Explain the distinction between \"novel\" inputs (previously unseen) and \"arbitrary\" inputs (inputs that may not follow a specific pattern or structure) to avoid confusion.\n        - On page 4, when discussing the player's ability to swap its color with the \"new change-color action,\" it's important to introduce the \"new change-color action\" before using it in the sentence. Provide a brief explanation or definition of this action to ensure readers understand its context and purpose.\n        - On page 5, when referring to the \"best\" candidate, explicitly define what \"best\" means within the context of the paper. Clarify whether \"best\" refers to candidates that are most relevant for prediction, those with the highest confidence scores, or some other criteria.\n        - Regarding the explanation of boosting and the working set in the sentence on page 5, consider whether this explanation is necessary. If it adds value to the reader's understanding of how the working set is updated, provide a concise summary of how boosting is related to the working set, ensuring that it enhances clarity.\n        - In section 3.2, provide a clear definition or explanation of the \"learnable module\" within the context of Quantified Function Learning. Specify its purpose and functionality to ensure the reader understands its role in the paper.\n        - Equation 2 needs clarification regarding the conditions for movement to the right and the meaning of first and second coordinates.\n        - The explanation of the relation group is insufficient, and details about its design or training architecture are lacking.\n        - The meaning of \"c\" is not provided in Section 3.3.\n        - In Section 4, different notations for different meanings should be used to avoid reader confusion.\n        - The abbreviation \"EMD\" is used before it is introduced.\n    - The analysis of experimental results needs improvement\n        - The use of $m=1$ for Neural Networks and larger $m$ for DOORMAX and QORA should be justified more, as it may raise fairness concerns.\n        - More analysis is needed to explain the errors that occur when $m=1000\" for QORA, beyond the fact that a single layout is used.\n        - The explanation for DOORMAX's inability to resolve the effect of the change-color action is insufficient.\n    - There are several literatures studied the object-centric or object-oriented representation for the Reinforcement Learning tasks, but they are missed. For example, in [1], the unsupervised object-centric representation for model-free reinforcement learning agent is investigated, and in [2], the world model learning of given object attributes is studied.\n    - The evaluation is limited to a synthetic environment, and the paper should discuss the potential for extending the model to more realistic environments and the expected limitations in such cases.\n    - The choice of baselines lacks diversity, and the paper could benefit from considering relevant studies in the object-centric representation field [3,4,5].\n\n[1] Yoon, Jaesik, et al. \"An investigation into pre-training object-centric representations for reinforcement learning.\" arXiv preprint arXiv:2302.04419 (2023).\n\n[2] Sancaktar, Cansu, Sebastian Blaes, and Georg Martius. \"Curious exploration via structured world models yields zero-shot object manipulation.\" Advances in Neural Information Processing Systems 35 (2022): 24170-24183.\n\n[3] Locatello, Francesco, et al. \"Object-centric learning with slot attention.\" Advances in Neural Information Processing Systems 33 (2020): 11525-11538.\n\n[4] Singh, Gautam, Yeongbin Kim, and Sungjin Ahn. \"Neural systematic binder.\" The Eleventh International Conference on Learning Representations. 2022.\n\n[5] Jiang, Jindong, et al. \"Object-centric slot diffusion.\" arXiv preprint arXiv:2303.10834 (2023)."
                },
                "questions": {
                    "value": "All questions are addressed in the \"Weaknesses\" section.\n\n### Additional Comments\nIn general, the paper's presentation requires significant improvement before publication. Additional references could provide a more comprehensive context for the work. The writing and analysis for the experiments should be further developed, including more detailed explanations of the model."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7177/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698743112976,
            "cdate": 1698743112976,
            "tmdate": 1699636851355,
            "mdate": 1699636851355,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TJVg8lfq8x",
                "forum": "fMzO6vcmhy",
                "replyto": "ErqHX70lbq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7177/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7177/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (1/3)"
                    },
                    "comment": {
                        "value": "> [1A] In the introduction, the terms \"generalization\" (the\n    model's ability to make effective decisions when exposed to\n    novel inputs), \"interpretability\" (how easily its learned\n    parameters can be inspected and understood by a human), and\n    \"robustness\" (the predictability of its behavior on arbitrary\n    inputs) need clarification. Explain the distinction between\n    \"novel\" inputs (previously unseen) and \"arbitrary\" inputs\n    (inputs that may not follow a specific pattern or structure)\n    to avoid confusion.\n\nThe revised introduction no longer uses terms \"novel\ninput\" or \"arbitrary input.\"\n\n> [1B] On page 4, when discussing the player's ability to swap its\n    color with the \"new change-color action,\" it's important to\n    introduce the \"new change-color action\" before using it in\n    the sentence. Provide a brief explanation or definition of\n    this action to ensure readers understand its context and\n    purpose.\n\nIt is a bit unclear what the reviewer means because\n\"changing color\" is not an ambiguous action. From the rest of the\nparagraph in the paper, it should be clear that a) colors are\nbinary; b) players can flip their color to the opposite using\nthis action; and c) the purpose of changing the color is to be\nable to pass through doors that have the same color. In any case,\nwe have rephrased this sentence to flow better, but feel that the\nrest of the paragraph is pretty self-explanatory.\n\n> [1C] On page 5, when referring to the \"best\" candidate,\n    explicitly define what \"best\" means within the context of the\n    paper. Clarify whether \"best\" refers to candidates that are\n    most relevant for prediction, those with the highest\n    confidence scores, or some other criteria.\n\nSentence rephrased.\n\n> [1D] Regarding the explanation of boosting and the working set\n    in the sentence on page 5, consider whether this explanation\n    is necessary. If it adds value to the reader's understanding\n    of how the working set is updated, provide a concise summary\n    of how boosting is related to the working set, ensuring that\n    it enhances clarity.\n\nYes, boosting is an essential part of QORA, which is a\nmethod for iteratively improving a model by focusing on its\ncurrent weaknesses. The paper explains this in fairly unambiguous\nterms: \"candidates in the working set do not receive\nobservations that the best hypothesis predicts with high\nconfidence, thereby magnifying the score of candidates that are\nwell-suited to correct existing errors.\" Due to limited space and\nthe fact that boosting is a well-known concept in the field of\nML, we do not believe that elaborating on the rationale for using\nthis method is warranted. Instead, the revision now cites the\npaper that invented boosting, while as a brief reference, the reviewer is directed to\nthe following page for more information:\n\nhttps://en.wikipedia.org/wiki/Boosting_(machine_learning)\n\n> [1E] In section 3.2, provide a clear definition or explanation\n    of the \"learnable module\" within the context of Quantified\n    Function Learning. Specify its purpose and functionality to\n    ensure the reader understands its role in the paper.\n\nThe paper does not contain the phrase \"learnable module\", which makes it difficult for\nus to specify its purpose and functionality in the context of\nQORA. If the reviewer uses this term to refer to deep learning,\nwhere modules are composed to produce complex neural-network\narchitectures, this concept is not relevant to the current paper.\nInstead, we are proposing an entirely new (non-neural-network\nbased) algorithm for learning predictive models, where QORA (and,\nmore specifically, the topics covered in the Quantified Function\nLearning subsection) are not meant to be used as composable\nmodules in this sense.\n\n> [1F] Equation 2 needs clarification regarding the conditions for\n    movement to the right and the meaning of first and second\n    coordinates.\n\nIt is a bit unclear what the reviewer means, but\ngenerally speaking most fields agree on a convention that\na position in 2D space is commonly described by a tuple in which\nthe $x$ coordinate appears first and the $y$ coordinate appears\nsecond. Hence, movement to the right corresponds to an increase\nin the $x$ coordinate, which the paper confirms just above (2) by\nstating \"a player $x$ can move to the right: $P(x): \\exists y \\in\nwalls: y.pos - x.pos = (1, 0)$\". In more detail, this predicate is\ntrue when there is a wall on the right side of the player's\ncurrent position; hence, the move is successful iff the predicate\nis false. More broadly, the operation of QORA does not depend on\nthe direction in which left/right/up/down actions move the\nplayer. Its algorithms would work exactly the same if the domain\nwere flipped sideways, e.g., moving up would cause the $x$\ncoordinate to reduce.\n\nSince the original formulas used $x$, $y$, $z$ to prepresent objects,\nwhich may be causing confusion with coordinates, we have changed\nthese variables to $o_1$, $o_2$, $o_3$ in the revision."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700724697926,
                "cdate": 1700724697926,
                "tmdate": 1700724697926,
                "mdate": 1700724697926,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SpJfWtqF7k",
                "forum": "fMzO6vcmhy",
                "replyto": "ErqHX70lbq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7177/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7177/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (2/3)"
                    },
                    "comment": {
                        "value": "> [1G] The explanation of the relation group is insufficient, and details about its design or training architecture are lacking.\n\nIndeed, some of the notation used in this section is\nfairly technical, but it is based on standard first-order logic. The\nlimited space in the paper does not permit going into much depth\non these topics. In brief, relation groups are a part of the\nstructure that QORA uses to represent rules. In particular, they\nenable QORA to efficiently keep track of quantified groups of\npredicates and generate expressive outputs. They are not\ntrainable, so there is no \"training architecture\" related to\nthem. Instead, QORA constructs more complex relation groups\nthrough its iterative process described in Section 3.\n\n> [1H] The meaning of \"c\" is not provided in Section 3.3.\n\nIt appears the reviewer missed that $(c, m, a)$ triplets\nwere previously introduced at the beginning of Section 3, where\nthe paper states \"We separate transition rules based on the\n(class, member attribute type, action) $(c, m, a)$ triplet they\napply to and predict changes independently for each attribute of\nevery object.\" In the revision, we have added text to Section\n3.3 to remind the reader of this previous definition.\n\n> [1I] In Section 4, different notations for different meanings should be used to avoid reader confusion.\n\nIt is unclear what notation the reviewer refers to. Any variables that were reused (e.g., $m$) were in clearly different contexts, but to ensure there could be no notation-related confusion throughout the paper, we have gone through and changed some of the variables (e.g., the $m$ used in Section 4 is now $n$).\n\n> [1J] The abbreviation \"EMD\" is used before it is introduced.\n\nThank you for catching this; we have fixed it.\n\n> [2A] The use of $m=1$ for Neural Networks and larger $m$ for\n    DOORMAX and QORA should be justified more, as it may raise\n    fairness concerns.\n\nIt appears the reviewer got this backwards -- as\nmentioned in Section 4.1 \"neural networks used $m=1$ to increase\nlearning speed.\" Additionally, as shown in the original Figure\n2(c), decreasing $m$ leads to better performance, which means\nthat neural networks obtain the maximum advantage over QORA when\nrunning with $m=1$. This happens because lower $m$ means the\nalgorithm receives more variety in the training data. The correct\ninterpretation of the results in Section 4 should be: even\nthough neural networks run with the best possible $m$, they\nstill cannot come anywhere near QORA's efficiency and ability to\nlearn. To prevent this confusion in the future, we have added a\nnew Figure 2(a) in the revision that tests the neural network\nbaselines with varied episode lengths (now called $n$ instead of\n$m$). This new plot perhaps makes it more clear that having\n$m=1$, i.e., generating a new level for every observation, leads\nto best performance.\n\n> [2B] More analysis is needed to explain the errors that occur\n    when $m=1000$ for QORA, beyond the fact that a single layout\n    is used.\n\nWe appreciate the comment, but disagree that more\nanalysis is needed to explain the poor performance with larger\n$m$. This follows from common sense. When a model is trained on\nonly a single level, it will still *typically* learn most of\nthe information it needs, but it's possible for a\nrandomly-generated level to be unusually difficult (e.g., to trap\nthe player in a series of long hallways, not allowing it to\nexplore the entire level as freely as normal). If the agent is\n\"unlucky\" enough to have this as its only experience, it may\nnot be able to gather enough evidence over the course of 1,000\nrandom actions to properly learn the environment's general rules.\nThis is a problem that is not unique to QORA; if an agent is not\nin control of the data it receives, learning may become\narbitrarily difficult.\n\n> [2C] The explanation for DOORMAX's inability to resolve the\n    effect of the change-color action is insufficient.\n\nAlthough the revision no longer compares against\nDOORMAX or points out its inability to work with the doors\ndomain, we can elaborate on this topic in the response. DOORMAX\ncan learn effects of two types: arithmetic (add or subtract a\nconstant) and assignment (set to a constant value). As part of\nthe learning process, it attempts to determine which of these two\ntypes of effects is actually being enacted by a given rule.\nNotably, for a given transition, DOORMAX will not make *any*\nprediction if there is still a rule that has ambiguous effects.\nIn the case of the doors domain, the effect toggles an attribute\nfrom $0 \\to 1$ or $1 \\to 0$, which could be considered either\narithmetic *or* assignment (since the initial value of the\nattribute is given as input to the rule). Thus, DOORMAX is unable\nto disambiguate the effect type, which forces it to give up and\nmake no prediction."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700724721976,
                "cdate": 1700724721976,
                "tmdate": 1700724721976,
                "mdate": 1700724721976,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vYIbK74ayn",
                "forum": "fMzO6vcmhy",
                "replyto": "ErqHX70lbq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7177/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7177/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (3/3)"
                    },
                    "comment": {
                        "value": "> [3] There are several literatures studied the object-centric or\n    object-oriented representation for the Reinforcement Learning\n    tasks, but they are missed. For example, in [1], the unsupervised\n    object-centric representation for model-free reinforcement\n    learning agent is investigated, and in [2], the world model\n    learning of given object attributes is studied.\n\nWe do not believe \"missed\" is the right word, as many of\nthese works are not relevant to our particular problem (transition\nmodeling). For example, [1] seems to deal with the problem of\nperception (i.e., converting visual input to an object-oriented\nrepresentation), while in the current paper, we assume such a system\nexists and work directly with objects without focusing on how they\nwere processed. Paper [2] deals with object-oriented transition\nmodeling, like us, but because it assumes domain-specific knowledge,\nit is not comparable to our method. Specifically, the GNN structure\ndescribed in that paper assumes knowledge of a singular\nagent-controlled object within the environment, which is not always a\nvalid assumption; for example, in our fish domain, there are multiple\nobjects that are partially controlled by the agent (or, depending on\nperspective, there is *no* object that is directly controlled by\nthe agent). If this domain knowledge were to be removed from the GNN,\nit would become incredibly similar to the NPE baseline that we have\nalready included in the paper. However, since it was mentioned here,\nwe have added a citation to [2] in our revised introduction.\n\n> [4] The evaluation is limited to a synthetic environment, and the\n    paper should discuss the potential for extending the model to\n    more realistic environments and the expected limitations in such\n    cases.\n\nMany reinforcement learning experiments are done in synthetic\nenvironments due to the high cost of real-world experiments\n(especially when millions of training iterations are required, as\nwith most deep-learning approaches). In this case, the environments\nwe introduce are designed to test specific aspects of QORA's learning\nwithout adding unnecessary complexity. In the revised introduction, we\nmention that future work will expand QORA's capabilities and address\nmore challenging domains.\n\n> [5] The choice of baselines lacks diversity, and the paper could\n    benefit from considering relevant studies in the object-centric\n    representation field [3,4,5].\n\nWe do not believe the listed papers [3, 4, 5] are relevant\nto our problem as they mostly deal with learning object-centric\nrepresentations. Instead, the current paper assumes such a\nrepresentation is given, but the goal is to learn object-based state\ntransition models of a given world. The revised introduction should\nexplain this better, in addition to pointing out that the field lacks\nbaselines that fit our requirements (i.e., model-based,\nobject-oriented domain learning with no a-prior knowledge). While we\nfound another such technique (MHDPA) and included comparison against\nit in the revision, the outcome is not promising, i.e., it performs\nas poorly as NPE."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700724733828,
                "cdate": 1700724733828,
                "tmdate": 1700724733828,
                "mdate": 1700724733828,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DRyIPWKQzk",
                "forum": "fMzO6vcmhy",
                "replyto": "TJVg8lfq8x",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7177/Reviewer_Kowy"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7177/Reviewer_Kowy"
                ],
                "content": {
                    "title": {
                        "value": "Response to the author's reply"
                    },
                    "comment": {
                        "value": "Thank you for your reply.\n\n[1B] On page 4, when discussing the player's ability to swap its color with the \"new change-color action,\" it's important to introduce the \"new change-color action\" before using it in the sentence. Provide a brief explanation or definition of this action to ensure readers understand its context and purpose.\nIt is a bit unclear what the reviewer means because \"changing color\" is not an ambiguous action. From the rest of the paragraph in the paper, it should be clear that a) colors are binary; b) players can flip their color to the opposite using this action; and c) the purpose of changing the color is to be able to pass through doors that have the same color. In any case, we have rephrased this sentence to flow better, but feel that the rest of the paragraph is pretty self-explanatory.\n\nYes, it is understandable, but what I pointed out is when using a new word (e.g., new change-color action), giving more kind introduction should be helpful (what is \"new\" change-color action? I checked again, I think you aimed to say this action is an introduced action for door, maybe it is better to say ..... with a new action called as change-color.\n\n [1D] Regarding the explanation of boosting and the working set in the sentence on page 5, consider whether this explanation is necessary. If it adds value to the reader's understanding of how the working set is updated, provide a concise summary of how boosting is related to the working set, ensuring that it enhances clarity.\nYes, boosting is an essential part of QORA, which is a method for iteratively improving a model by focusing on its current weaknesses. The paper explains this in fairly unambiguous terms: \"candidates in the working set do not receive observations that the best hypothesis predicts with high confidence, thereby magnifying the score of candidates that are well-suited to correct existing errors.\" Due to limited space and the fact that boosting is a well-known concept in the field of ML, we do not believe that elaborating on the rationale for using this method is warranted. Instead, the revision now cites the paper that invented boosting, while as a brief reference, the reviewer is directed to the following page for more information:\n\nhttps://en.wikipedia.org/wiki/Boosting_(machine_learning)\n\nIt is okay, I didn't understand what it means, when revisiting I can understand.\n\n[1E] In section 3.2, provide a clear definition or explanation of the \"learnable module\" within the context of Quantified Function Learning. Specify its purpose and functionality to ensure the reader understands its role in the paper.\nThe paper does not contain the phrase \"learnable module\", which makes it difficult for us to specify its purpose and functionality in the context of QORA. If the reviewer uses this term to refer to deep learning, where modules are composed to produce complex neural-network architectures, this concept is not relevant to the current paper. Instead, we are proposing an entirely new (non-neural-network based) algorithm for learning predictive models, where QORA (and, more specifically, the topics covered in the Quantified Function Learning subsection) are not meant to be used as composable modules in this sense.\n\nthe learnable module means, then what is learned? which parameters are learned? you commented the function is learned, then which components in the function are learned?\n\n[1F] Equation 2 needs clarification regarding the conditions for movement to the right and the meaning of first and second coordinates.\nIt is a bit unclear what the reviewer means, but generally speaking most fields agree on a convention that a position in 2D space is commonly described by a tuple in which the  coordinate appears first and the  coordinate appears second. Hence, movement to the right corresponds to an increase in the  coordinate, which the paper confirms just above (2) by stating \"a player  can move to the right: \". In more detail, this predicate is true when there is a wall on the right side of the player's current position; hence, the move is successful iff the predicate is false. More broadly, the operation of QORA does not depend on the direction in which left/right/up/down actions move the player. Its algorithms would work exactly the same if the domain were flipped sideways, e.g., moving up would cause the  coordinate to reduce.\n\nSince the original formulas used , ,  to prepresent objects, which may be causing confusion with coordinates, we have changed these variables to , ,  in the revision.\n\nSame to the above. Yes, usually x-axis is first and y-axis is second. But you didn't notice it clearly. Kind introduction should improve the readability of your paper, so I recommended."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700730797190,
                "cdate": 1700730797190,
                "tmdate": 1700730797190,
                "mdate": 1700730797190,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XfmoneI6HM",
                "forum": "fMzO6vcmhy",
                "replyto": "vYIbK74ayn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7177/Reviewer_Kowy"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7177/Reviewer_Kowy"
                ],
                "content": {
                    "title": {
                        "value": "response to the author's reply"
                    },
                    "comment": {
                        "value": "[3] There are several literatures studied the object-centric or object-oriented representation for the Reinforcement Learning tasks, but they are missed. For example, in [1], the unsupervised object-centric representation for model-free reinforcement learning agent is investigated, and in [2], the world model learning of given object attributes is studied.\nWe do not believe \"missed\" is the right word, as many of these works are not relevant to our particular problem (transition modeling). For example, [1] seems to deal with the problem of perception (i.e., converting visual input to an object-oriented representation), while in the current paper, we assume such a system exists and work directly with objects without focusing on how they were processed. Paper [2] deals with object-oriented transition modeling, like us, but because it assumes domain-specific knowledge, it is not comparable to our method. Specifically, the GNN structure described in that paper assumes knowledge of a singular agent-controlled object within the environment, which is not always a valid assumption; for example, in our fish domain, there are multiple objects that are partially controlled by the agent (or, depending on perspective, there is no object that is directly controlled by the agent). If this domain knowledge were to be removed from the GNN, it would become incredibly similar to the NPE baseline that we have already included in the paper. However, since it was mentioned here, we have added a citation to [2] in our revised introduction.\n\n[1] focused on the model-free reinforcement learning on top of the pretrained object-centric perception model. \n\n\n[5] The choice of baselines lacks diversity, and the paper could benefit from considering relevant studies in the object-centric representation field [3,4,5].\nWe do not believe the listed papers [3, 4, 5] are relevant to our problem as they mostly deal with learning object-centric representations. Instead, the current paper assumes such a representation is given, but the goal is to learn object-based state transition models of a given world. The revised introduction should explain this better, in addition to pointing out that the field lacks baselines that fit our requirements (i.e., model-based, object-oriented domain learning with no a-prior knowledge). While we found another such technique (MHDPA) and included comparison against it in the revision, the outcome is not promising, i.e., it performs as poorly as NPE.\n\nWhat I mentioned is, even though there are several studies relevant to object-centric representation, and your paper is focusing on the object-oriented transition model learning, but they are not considered as relevant works or baselines. Yes, maybe they cannot be the baselines due to several reasons, then you need to discuss it as related work, and why they are not compared in your experiments I think."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700731134241,
                "cdate": 1700731134241,
                "tmdate": 1700731134241,
                "mdate": 1700731134241,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7mRrU5pL3f",
                "forum": "fMzO6vcmhy",
                "replyto": "ErqHX70lbq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7177/Reviewer_Kowy"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7177/Reviewer_Kowy"
                ],
                "content": {
                    "title": {
                        "value": "response to the author's reply"
                    },
                    "comment": {
                        "value": "[1G] The explanation of the relation group is insufficient, and details about its design or training architecture are lacking.\nIndeed, some of the notation used in this section is fairly technical, but it is based on standard first-order logic. The limited space in the paper does not permit going into much depth on these topics. In brief, relation groups are a part of the structure that QORA uses to represent rules. In particular, they enable QORA to efficiently keep track of quantified groups of predicates and generate expressive outputs. They are not trainable, so there is no \"training architecture\" related to them. Instead, QORA constructs more complex relation groups through its iterative process described in Section 3.\n\nThank you for your kind explanation. Could you update the details in your appendix? It could be very helpful to understand your paper more.\n\n[1I] In Section 4, different notations for different meanings should be used to avoid reader confusion.\nIt is unclear what notation the reviewer refers to. Any variables that were reused (e.g., ) were in clearly different contexts, but to ensure there could be no notation-related confusion throughout the paper, we have gone through and changed some of the variables (e.g., the  used in Section 4 is now ).\n\neach starting state m in section 4 and m in \"the (class, member attribute type, action) (c, m, a) triplet they apply to and predict changes independently for each attribute of every object\" are same?\n\n\nI cannot check every reply in the discussion period due to the limitation of the time, but I will check more even after the discussion period.\n\nThank you for your reply."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700731367420,
                "cdate": 1700731367420,
                "tmdate": 1700731394717,
                "mdate": 1700731394717,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "6myO07Ujbs",
            "forum": "fMzO6vcmhy",
            "replyto": "fMzO6vcmhy",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7177/Reviewer_RNSv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7177/Reviewer_RNSv"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces QORA, a new algorithm for learning interpretable object-relational models that can efficiently solve reinforcement learning tasks with zero-shot generalization. QORA represents states as sets of objects and attributes. It constructs transition rules for each object type by iteratively generating relational predicate hypotheses and combining them using first-order logic with quantification. In experiments on three environments, QORA achieves zero error with orders of magnitude fewer observations than neural networks. It demonstrates strong generalization via zero-shot transfer and rapid adaptation to new object types and interactions. The learned conditional probability rules are compact and interpretable. Overall, QORA advances object-oriented RL by increasing applicability to complex stochastic environments while retaining interpretability."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- This paper presents a novel object-oriented RL algorithm with strong empirical results on efficiency, generalization, and interpretability. Compared to DOORMAX, QORA is able to solve more complex environments (e.g., doors) and perform zero-shot transfer to modified environments. Moreover, the rules QORA deduced are also interpretable.\n-  The source code of both QORA\u2019s reference implementation and the benchmark suite will be public, which is beneficial to the community."
                },
                "weaknesses": {
                    "value": "- While QORA tacles more challenging environments than prior works (e.g., DOORMAX_D in Marom and Rosman, 2018), the evaluations are still on small-scale games, which limits its wide applicability.\n- There are no theoretical guarantees provided for convergence or sample complexity.\n\nThis paper is not at all in my area. I am not familiar with OO-MDPs and the follow up works. I think the results presented in this paper is promising compared to existing works but not sure whether it makes adequte contribution in this field."
                },
                "questions": {
                    "value": "N/A"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7177/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7177/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7177/Reviewer_RNSv"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7177/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698805943533,
            "cdate": 1698805943533,
            "tmdate": 1699636851233,
            "mdate": 1699636851233,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "rAbECIx2yp",
                "forum": "fMzO6vcmhy",
                "replyto": "6myO07Ujbs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7177/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7177/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> While QORA tacles more challenging  environments than prior works (e.g., DOORMAX\\_D in Marom and Rosman, 2018), the evaluations are still on small-scale games, which limits its wide applicability.\n\nWe appreciate the comment, but QORA is applicable to a\nmuch larger variety of environments than just those shown in the\npaper, both in terms of their size (i.e., number of objects) and\nthe types of rules that govern their behavior. Furthermore, it should be\nnoted that even the domains that appear simple/small require\nconstruction and consideration of a large number of hypotheses. For\nexample, the 8x8 walls domain contains 28 external (perimeter) walls\nand 10 interior walls, whose semantics QORA isn't given (e.g., it\nhas no idea that walls cannot move). Therefore, it must consider all\npossible interactions between them, as well as the position of the\nagent and action taken, to build a predictive model. Given the\nlimited space in the paper, we focus on the most basic examples to\ndemonstrate QORA's particular capabilities rather than achieve an\nexhaustive coverage of all possible worlds it can operate in. Future\nwork will focus on extending QORA to handle game playing, exploration, and planning, but\nthese topics are clearly beyond the scope of the current paper.\n\nWith this in mind, the revised paper contains new experiments with\nlarger (64x64 and 128x128) worlds, a new domain with light bulbs, and\nadditional discussion emphasizing some of the points in the preceding\nparagraph.\n\n> There are no theoretical guarantees provided for convergence or sample complexity.\n\nIndeed, QORA tackles much more general problems than prior\nwork, making theoretical analysis correspondingly more difficult and\ntherefore beyond the scope of this introductory paper. However, we\nagree this is an important topic, which we plan to address in future\npublications."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700724353554,
                "cdate": 1700724353554,
                "tmdate": 1700724353554,
                "mdate": 1700724353554,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]