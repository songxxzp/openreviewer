[
    {
        "title": "Learning Multi-Agent Communication with Contrastive Learning"
    },
    {
        "review": {
            "id": "5zuAvwivqn",
            "forum": "vZZ4hhniJU",
            "replyto": "vZZ4hhniJU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2048/Reviewer_Y1JN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2048/Reviewer_Y1JN"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies multi-agent communication by contrastive learning. It is motivated by the fact that communicated messages based on local observation can be viewed as incomplete views of the global state. From this perspective, a contrastive learning based approach is proposed, where states from close time steps are considered as positive samples, and those from distant time steps or episodes are considered as negative samples. The proposed algorithm is tested on several multi-agent benchmarks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper has an innovative perspective on the multi-agent communications, which motivates the use of contrastive learning.\n- The paper is well-written, and the proposed contrastive learning framework is easy and clean to implement.\n- There are various ablation studies over different components of the proposed algorithm and visualizations over the learned communicated messages."
                },
                "weaknesses": {
                    "value": "- The improvement over the baselines is not obvious, especially in Traffic Junction in Figure 2. The standard error is also too large with a lot of overlaps, so it may need more seeds of experiments.\n- The proposed algorithm CACL is only tested on three tasks. The paper could benefit from additional experiments on some more challenging tasks with partial observability where communications are intuitively beneficial."
                },
                "questions": {
                    "value": "- The policy $\\pi$ defined in section 3 seems to be only conditional on the local observation $\\tau^i$. Should it also be conditional on the communicated messages?\n- If some local observations miss important information, the approximated global states reconstructed by the message encoders may be very different from the true ones. Will this make the contrastive learning not meaningful?\n- Does CACL require all-to-all communications, i.e., each agent communicate to all the other agents? If so, CACL is not scalable with large number of agents.\n- During a time step, each agent receives multiple approximations of the global state from the communicated messages. This seems to include redundant information if the messages are not selectively received. How does CACL handle redundant information?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2048/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2048/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2048/Reviewer_Y1JN"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2048/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698004706075,
            "cdate": 1698004706075,
            "tmdate": 1699636136472,
            "mdate": 1699636136472,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0JLCy3UzJW",
                "forum": "vZZ4hhniJU",
                "replyto": "5zuAvwivqn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2048/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2048/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "Thank you very much for your helpful comments. We are glad that you find our work \u2018innovative\u2019 and \u2018well-written. We hope we\u2019ve addressed your concerns and questions below. Does the reviewer have any remaining concerns that prevent them from raising their score? We are happy to address them\n\n**More seeds**\n\nFor fairness, we chose the number of seeds following our closest baseline AEComm. Note that CACL outperforms AEComm on Traffic Junction more than AEComm outperformed their own baseline in their paper. The task demonstrates that even if all methods fully solve a task, CACL can reach perfect reward faster.  \n\n**More challenging environments**\n\nWe use the same environments as baselines but made harder. E.g. in Predator-Prey, predators must fully surround a moving prey without being able to see each other, so communication is essential. In Find-Goal, we also reduce field-of-view to make communication key to good performance.\n\n**Policy is conditioned on messages**\n\nWe include messages as part of the observation and have clarified this in section 3. Thank you for pointing it out.\n\n**CACL with different local information**\n\nCACL does not explicitly reconstruct the whole state with each message, but brings messages closer together. So a local observation without the goal cannot communicate goal location. But its message can communicate that the goal is *not* in that location, which should be meaningfully cohesive with another agents\u2019 message containing goal location.\n\n**All-to-all communication is not necessary**\n\nOther agents\u2019 messages act as positive / negative samples, so reducing all-to-all communication is possible, it just reduces the number of positive / negative samples. Scaling to more agents increases the number of samples so limiting communication directions should be completely fine. \n\n**Redundant information**\n\nYou are correct that messages may contain redundant information, especially if the observations overlap. In our particular setup, this doesn\u2019t seem to be a problem as the message encoder learns to extract useful information."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2048/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699999540860,
                "cdate": 1699999540860,
                "tmdate": 1699999540860,
                "mdate": 1699999540860,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SNVOsgTedi",
                "forum": "vZZ4hhniJU",
                "replyto": "5zuAvwivqn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2048/Reviewer_Y1JN"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2048/Reviewer_Y1JN"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your response"
                    },
                    "comment": {
                        "value": "Thanks for the clarifications. Some of my concerns are addressed. However, I still have some reservations.\n\n- I don't find the results in figure 2 to be convincing due to very high standard errors. The curves are largely overlapped and can hardly be separated. More seeds are needed regardless of the number of seeds used in other works. The performance boosting of CACL over the baseline ACEComm is limited in Traffic-Junction. \n\n- Even if the selected baselines are made harder, I still think it is necessary for CACL to be tested on some commonly used MARL benchmarks with more complex tasks such as [1].\n\n- CACL has only been tested on scenarios with relatively small number of agents (<=5), so the redundancy/scaling issue may not be a problem. It is is not clear to me if this is still the case in scenarios such as 27m_vs_30m in [1] with 27 controllable agents.\n\n[1] StarCraft Multi-Agent Challenge"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2048/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700327251445,
                "cdate": 1700327251445,
                "tmdate": 1700327325915,
                "mdate": 1700327325915,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "MjRMb6TllG",
            "forum": "vZZ4hhniJU",
            "replyto": "vZZ4hhniJU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2048/Reviewer_aKdr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2048/Reviewer_aKdr"
            ],
            "content": {
                "summary": {
                    "value": "The authors describe CACL, a contrastive learning approach for inducing communication among multiple agents. There are close parallels to classic contrastive learning methods in vision, for example, but the authors apply their technique to \"emergent communication\" to allow teams of agents to communicate with each other. \"Postive\" examples are grouped based on a window of recent timesteps, and, as in standard constrastive learning, agents learn to encode positive examples near each other.\n\nIn experiments, the authors show that CACL outperforms numerous baselines, including the SOTA AEComm method (which in some ways is similar in that it is a non-reward-based mechansim for inducing emergent communication)."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "I like this paper. It presents a simple idea that works well.\n\n## Originality\nApplying contastive losses to emergent communication is somewhat novel. (I know other works have also come out in this area, but they remain different in some important ways).\n\n## Quality\nThe work is well-scoped and presented, with good results backing up claims.\n\n## Clarity\nI find the paper quite clear. Some figures could likely be redone to present the same information better (e.g., Figure 3), but mostly these are small changes.\n\n## Significance\nI think this work, should it be published, would be an important baseline for future emergent communication work."
                },
                "weaknesses": {
                    "value": "Overall, this is a strong paper. To further improve the paper the authors could\n\n1) Conduct further experiments to fill in Figure 4 in more detail (instead of just 3 or 4 checkpoints along the curve)\n\n2) Run more trials, especially in the traffic junction where variance is high and not all methods seem to have converged."
                },
                "questions": {
                    "value": "I have no outstanding questions. Overall, this was a clear paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2048/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698438638847,
            "cdate": 1698438638847,
            "tmdate": 1699636136404,
            "mdate": 1699636136404,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kyLYjbRJSF",
                "forum": "vZZ4hhniJU",
                "replyto": "MjRMb6TllG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2048/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2048/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "Thank you very much for your review. We are glad that you enjoyed our work and find it \u201cclear\u201d, \u201cwell-scoped [...] with good results\u201d, and a \u201cstrong paper\u201d that will be an \u201cimportant baseline for future emergent communication work\u201d. We are currently running more experiments to fill in Figure 4 as well as more trials for Traffic Junction, that will be included in the final paper. We would also be happy to rework Figure 3 to better present the information if the reviewer has suggestions."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2048/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699999294337,
                "cdate": 1699999294337,
                "tmdate": 1699999294337,
                "mdate": 1699999294337,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hBAJMWOHTd",
            "forum": "vZZ4hhniJU",
            "replyto": "vZZ4hhniJU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2048/Reviewer_64q7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2048/Reviewer_64q7"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new method for fully independent communication in MARL, CACL. The proposed method leverages the power of contrastive learning to ground communication and learning efficient communication for MARL tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper tackles the problem of communication for fully independent learners, which is a very important topic in MARL and it is often underexplored. Also, mixing contrastive learning with MARL is interesting. Generally, the paper is well organised and well written."
                },
                "weaknesses": {
                    "value": "Overall, this paper is interesting and investigates an important topic in MARL. However, I still have some concerns and questions that I would like the authors to comment on. Please find my comments below and questions ahead.\n\n* The example of predator prey in figure 1 (right) is a bit confusing. I would not agree that the given examples correspond to similar views; for example, the first view (counting from the top) seems more similar to the third view rather than to the second view.\n* In section 1, the authors mention: \"we propose that an agent\u2019s observation is a \u201cview\u201d of the environment state. Thus, different agents\u2019 messages are encodings of different incomplete \u201cviews\u201d of the same underlying state.\". This is in fact the premise of a dec-pomdp; Observations are tipically local perceptions of the environment's state; in other communication methods in MARL where observation encodings are used as messages, I would say that the same logic is followed: individual perceptions of the environment are being shared as message encodings to the others. As described by the authors is section 3, the observations come from a function of the state.\n* In the loss function, the RL loss is not defined. It would be good to have it for clarity purposes.\n* A more detailed diagram of the architecture of this method could be beneficial to get a better understanding of the approach; the one presented in figure 8 in the appendix seems very simple and lacks detail and we cannot clearly understand how the gradients flow; this can be important since the authors are dealing with fully independent learning, without sharing parameters.\n\nMinor:\n* In section 3, do the authors mean $m_{t-1}^{-i}$ instead of $m_{t-1}^{-1}$?\n* In section 3 \"At each time step, each agent $i \\in N$ chooses an action $a \u2208 A^i$\": shoud be $a^i$ since ahead $a$ is defined as the joint action."
                },
                "questions": {
                    "value": "* I have questions about whether it is reasonable to evaluate the similarity of messages of different agents by simply looking at a window of a few timesteps in the trajectory. The observations corresponding to the generated messages can be different in important aspects from one timestep to the other, and thus would require distinct messages that could be biased by the contrastive loss. I am unsure whether this would scale to more complex cases, since it could not capture these differences in the observations.\n* The experimented environments seem a bit simple and model scenarios where the observations can indeed be more similar to each other in some cases. Have the authors tested in more complex scenarios where there can be stronger variations on the observations such as SMAC? It would be interesting to see the performance in such complex environments.\n* The authors mention that the setting followed is a fully decentralised setting where the agents do not share parameters or gradients (section 1); does this apply to the message encoder? I.e., do the agents share the same message encoder or does each one of them use a separate encoder to generate messages? \n* I believe another potential direction for further work would be to investigate how to make methods such as the proposed one work together with the reward. I.e., in section 5.5 it was shown that currently it is detrimental. Yet, have the authors thought whether the method can be improved in any way in order to take advantage of the reward as well?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2048/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2048/Reviewer_64q7",
                        "ICLR.cc/2024/Conference/Submission2048/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2048/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698691430374,
            "cdate": 1698691430374,
            "tmdate": 1700615388276,
            "mdate": 1700615388276,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "nQOH7zHA3J",
                "forum": "vZZ4hhniJU",
                "replyto": "hBAJMWOHTd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2048/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2048/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their detailed comments, corrections, and helpful suggestions and are glad they find our work interesting! We have implemented all the suggestions in the updated paper and answered all questions below. Are there any particular details that the reviewer would like cleared up in order to increase their score? We are happy to oblige.\n\n**Sliding Window Reasonability**\n\nContrastive learning doesn\u2019t force messages within a timestep to be exactly the same, just more similar, allowing for variation within the window. We expect it to work with more complex observations e.g. [TACO (Zheng et al, 2023)](https://arxiv.org/abs/2306.13229) use a similar time window for contrastive learning in single agent RL on DM control suite and Meta-World.\n\n**Environments with variable observations**\n\nAll methods we have seen on SMAC use centralized training, so we choose environments with well known decentralized MARL + communication baselines, and make them harder. We expect more complex observations to make it easier to communicate some generic state info (e.g. location using visual cues) but make SSL harder, though contrastive learning should even more outperform autoencoding.\n\n**Message Encoder are not shared**\n\nAgents are fully decentralized and have completely separate message encoders, highlighting the difficulty of the task.\n\n**Figure 1 reworked**\n\nWe have reworded the caption. Messages are positive samples if they are derived from [observations of] the same state. We\u2019ve also changed the images to clarify our connection to image multi-view learning\n\n**Learning Representation with Reward**\n\nOur negative results reinforce a similar finding in AEComm, and likely stem from the two training signals (SSL and RL) conflicting, causing instability. A possible future approach could alternate training one signal then the other or add an attention layer that conditions on the state to decide on a weighted mixture of the two losses.\n\n**CACL vs Dec-POMDP**\n\nThis is exactly our view. CACL\u2019s innovation is to leverage the premise of Dec-POMDP to explicitly capture state info in the message. Other methods (e.g. AEComm) reconstruct observation from message, missing key state info. \n\n**RL Loss Added**\n\nThank you for pointing that out. We have added a RL loss in Appendix A.1 for clarity, with text in red.\n\n**Figure 8 reworked**\n\nThank you for the suggestion. Some details were in Appendix A.2, we\u2019ve added them to the figure and illustrate gradient flow of each loss, with caption text in red.\n\n**Section 3 notation**\n\nThank you for finding these minor errors. We have corrected it to m_{t-1}^{-i} and a^i  in the updated paper in red."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2048/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699999241627,
                "cdate": 1699999241627,
                "tmdate": 1699999241627,
                "mdate": 1699999241627,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rbCuAEotJa",
                "forum": "vZZ4hhniJU",
                "replyto": "hBAJMWOHTd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2048/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2048/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "As the rebuttal period is coming to an end, we would like to thank you again for your detailed comments and helpful suggestions on our work. We hope that our clarifications, together with the additions to the revised manuscript, have addressed your concerns. Please let us know if you have any further questions we can address in order for the reviewer to increase their score."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2048/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700265132394,
                "cdate": 1700265132394,
                "tmdate": 1700511491532,
                "mdate": 1700511491532,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LTRoKwtej7",
                "forum": "vZZ4hhniJU",
                "replyto": "VGUOr1INuK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2048/Reviewer_64q7"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2048/Reviewer_64q7"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "Thank you for your response. After reading the comments, most of my concerns were addressed. While I am aware that usually approaches in SMAC follow centralised training, that does not mean that decentralised approaches should not be able to solve these environments. In fact, I think it would demonstrate improved robustness to have a decentralised method capable of solving the complex communication environments presented by the authors, but that can also solve other complex tasks where usually centralisation is assumed, such as SMAC.\n\nOverall, the method to ground communication is interesting and I believe that decentralised control is important. Thus, I will raise my score."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2048/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700615369198,
                "cdate": 1700615369198,
                "tmdate": 1700615369198,
                "mdate": 1700615369198,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "PV6Y37BhBb",
            "forum": "vZZ4hhniJU",
            "replyto": "vZZ4hhniJU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2048/Reviewer_sueF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2048/Reviewer_sueF"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a novel approach to guide multi-agent communication learning via contrastive learning in a decentralized MARL scenario. The intuition is that under similar circumstances the agents should emit similar messages, and vice versa. Hence the authors employ contrastive learning to maximize the mutual information between messages of a given trajectory and minimize other cases. The authors claimed their method has outperformed exisiting approaches on several benchmarks."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The idea delivered by this work is clear and somewhat grounded. Indeed it would be worthwhile for agent to learn a guidance of its message during multi-agent communication. And the intuition of enforcing messages under similiar state to be alike with each other is a straightforward motivation, for which contrastive learning might be one of the most popular method to achieve."
                },
                "weaknesses": {
                    "value": "However, after going through the whole paper, It is easy to find that the proposed idea is less sufficiently proved and there are many flaws in the manuscript. There are a few such perspectives:\n1. In section 4, the negative samples are defined as from outside the current time window or other trajectories. This is not technically sound since it would be possible for agents to encounter similar states at different trajectories (which would be considered as negative by the proposal). It is suggested that the authors should discuss such cases in detail and figure out more solid principle to decide positive/negative samples for contrastive learning.\n2. The selected benchmark for comparison is kind of limited. Public MARL evaluation platforms like SMAC[1] or MATE[2] which involves higher complexity should be considered for more pursuasive comparison. In addition, in the compared task of Traffic Junction, the improvement seems to be marginal.\n3. The compared baseline methods are sort of obselete. Newer published works in recent 3 years should get included. (especially new work in 2022-2023).\n\n[1] Samvelyan, M., Rashid, T., De Witt, C. S., Farquhar, G., Nardelli, N., Rudner, T. G., ... & Whiteson, S. (2019). The starcraft multi-agent challenge. arXiv preprint arXiv:1902.04043.\n[2] Pan, X., Liu, M., Zhong, F., Yang, Y., Zhu, S. C., & Wang, Y. (2022). Mate: Benchmarking multi-agent reinforcement learning in distributed target coverage control. Advances in Neural Information Processing Systems, 35, 27862-27879."
                },
                "questions": {
                    "value": "More comprehensive comparison and analysis are expected:\n1. It is encouraged for the authors to demonstrate the scalability of the proposed approach, like in a continuous state/action space environments which may involve a large number of agents with quite dense communication load. In such cases, would the proposed scheme be better than the most recent communication-based work like ATOC[1], MF-MARL[2], TarMAC[3], I2C[4], ToM2C[5]?\n2. Besides showing the similarity of messages among multiple states, the exact improvement from such a contrastive learning method should be analyzed. For instance, it is better to compare the adjacency/disparity of positive/negative sample pairs before/after the proposed training.\n\n[1] Jiang, J., & Lu, Z. (2018). Learning attentional communication for multi-agent cooperation. Advances in neural information processing systems, 31.\n[2] Yang, Y., Luo, R., Li, M., Zhou, M., Zhang, W., & Wang, J. (2018, July). Mean field multi-agent reinforcement learning. In International conference on machine learning (pp. 5571-5580). PMLR.\n[3] Das, A., Gervet, T., Romoff, J., Batra, D., Parikh, D., Rabbat, M., & Pineau, J. (2019, May). Tarmac: Targeted multi-agent communication. In International Conference on Machine Learning (pp. 1538-1546). PMLR.\n[4] Ding, Z., Huang, T., & Lu, Z. (2020). Learning individually inferred communication for multi-agent cooperation. Advances in Neural Information Processing Systems, 33, 22069-22079.\n[5] Wang, Y., Zhong, F., Xu, J., & Wang, Y. (2021). Tom2c: Target-oriented multi-agent communication and cooperation with theory of mind. arXiv preprint arXiv:2111.09189."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2048/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698808180435,
            "cdate": 1698808180435,
            "tmdate": 1699636136243,
            "mdate": 1699636136243,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "naJnyjpYBs",
                "forum": "vZZ4hhniJU",
                "replyto": "PV6Y37BhBb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2048/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2048/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "Thank you for your helpful feedback, we hope we have addressed your comments below. Given the borderline score, are there any other concerns or questions the reviewer would like addressed in order to increase their score? \n\n**CACL\u2019s negative sample window is sufficient**\n\nAlthough edge-cases can exist, contrastive learning does not require perfect negative mining, just a good general rule. E.g. [TACO (Zheng et al, 2023)](https://arxiv.org/abs/2306.13229) uses a similar time window for negative samples in contrastive learning for single agent RL. \n\n**Our benchmarks are thorough and robust**\n\nWe extend and harden benchmarks used in baselines, e.g. AEComm, see section 5.1 for details, and they are nearly identical or harder versions of benchmarks in the most recent papers you reference (I2C and ToM2C). SMAC does not generally require communication. MATE is interesting but all of its communication baselines use centralized training and we focus on benchmarks with existing decentralized training baselines. \n\n**Baselines are SOTA**\n\nOur baselines are current state-of-the-art in decentralized communication. Can the reviewer point to other decentralized RL + communication methods? All noted papers seem to be centralized training methods.\n\n**Evaluating Contrastive Learning**\n\nAs requested, we plot the distance between positive and negative samples (i.e. our contrastive loss) over the course of training in Figure 9 in Appendix A.4. As training evolves, contrastive loss decreases so positive and negative samples become more separated. \n\n**Scalability of CACL**\n\nAll noted works (ATOC, TarMAC,...) are centralized training methods whereas CACL is decentralized training which should be better at scaling to large number of agents [(Lyu et al, 2021 Section 6.3)](https://arxiv.org/pdf/2102.04402.pdf). We do not investigate communication overhead, but targeting methods (e.g. TarMAC) could be applied to CACL as well."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2048/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699999040129,
                "cdate": 1699999040129,
                "tmdate": 1699999040129,
                "mdate": 1699999040129,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wODQ0ldLfa",
                "forum": "vZZ4hhniJU",
                "replyto": "naJnyjpYBs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2048/Reviewer_sueF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2048/Reviewer_sueF"
                ],
                "content": {
                    "title": {
                        "value": "Reply to rebuttal"
                    },
                    "comment": {
                        "value": "As claimed in Sec.1 of the manuscript, \"Centralized training with decentralized execution (CTDE) (Lowe et al., 2017) is a middle-ground between purely centralized and decentralized methods but may not perform better than purely decentralized training (Lyu et al., 2021). \" It would be better for the author to comprehensively prove such argument with firm results, otherwise it is unclear how the proposed approach compare with SOTA effort on CTDE setting. Especially when current transformer based centralized training can afford a higher complexity for multi-agent communication compared with previous RNN/LSTM modules, it would be uncertain whether a decentralized training is really necessary. Since CTDE has been a publicly approved setting for MARL, these works shouldn't be ignored and need appropriate citations & fair comparisons."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2048/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700277852822,
                "cdate": 1700277852822,
                "tmdate": 1700277852822,
                "mdate": 1700277852822,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Rgm4X6YrAD",
                "forum": "vZZ4hhniJU",
                "replyto": "PV6Y37BhBb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2048/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2048/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your active discussion. We agree that CTDE is an interesting setup but believe that decentralized training is a separate research area with important research questions that we tackle in our work.\n\n**Justifying Decentralized**\n\nWe cite [Lyu et al. 2021](https://arxiv.org/pdf/2102.04402.pdf) because they show theoretically and empirically that decentralized critics can match or exceed CTDE performance on a variety of tasks and refer to their work for comprehensive proof. Empirically, decentralized seems to match CTDE performance e.g. CTDE MAPPO is similar to decentralized IPPO on many tasks including Starcraft (Table 4 in [Yu et al. 2022](https://arxiv.org/abs/2103.01955)). Decentralized training is desirable in real-world scenarios where you don't have synchronous information for all agents ([Li et al. 2023](https://jmlr.org/papers/volume24/20-700/20-700.pdf)) and it is generally a well-studied area of research (see related work in [Lu et al, 2022](https://arxiv.org/pdf/2211.03032v1.pdf) and section 4 in [Oroojlooy and Hajinezhad, 2021](https://arxiv.org/pdf/1908.03963.pdf)). \n\n**Why CACL is decentralized**\n\nWhere CTDE's issue is scalability ([Lyu et al, 2021](https://arxiv.org/pdf/2102.04402.pdf)), decentralized training suffers in stability, especially for learning communication. CACL's contrastive learning provides an elegant framework to learn communication while explicitly solving the problem of consistency in decentralized protocols (which implicitly improves stability). Centralized controllers could easily enforce a uniform, symmetric communication but it is novel to achieve this with decentralized training."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2048/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700308094701,
                "cdate": 1700308094701,
                "tmdate": 1700719104935,
                "mdate": 1700719104935,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]