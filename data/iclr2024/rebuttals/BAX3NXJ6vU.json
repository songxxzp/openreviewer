[
    {
        "title": "Escaping Saddle Point Efficiently in Minimax and Bilevel Optimizations"
    },
    {
        "review": {
            "id": "7e6ExujdiK",
            "forum": "BAX3NXJ6vU",
            "replyto": "BAX3NXJ6vU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6660/Reviewer_5LK2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6660/Reviewer_5LK2"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a perturbed stochastic gradient method for bi-level and minimax optimization. Crucially, the gradient complexity of their proposed methods (suppressing the condition number dependence) achieve \\tilde{O}(\\epsilon^{-3}) gradient complexity in order to find a second order critical point.  This seems to match the best gradient complexity known among stochastic methods converging just to a critical point."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The theoretical result is quite strong, polynomially improving upon the gradient complexity of the best known result (improving from \\epsilon^{-4} to \\epsilon^{-3}).  I appreciate the inclusion of condition number dependence in the results as well.  The example chosen for the numerical result is also quite illustrative and well chosen."
                },
                "weaknesses": {
                    "value": "The main weakness is the presentation of the paper.  I provide a few (small) comments here.\n\nMinor comments:\n\n- The paper makes strong smoothness assumptions (which do seem to be standard in the literature), but it would be useful to include references to methods which do not require such strong assumptions, such as Chen, et. al (https://arxiv.org/pdf/2306.12067.pdf).  \n\n- There are several small issues riddled throughout that should be resolved before publication.  To give one such example (among several), Assumption 2 is not quite precise: There should be a quantifier on \\xi, \\zeta (e.g. I suppose this should hold for almost every \\xi and \\zeta).\n\n- The authors never define HV and JV as stated in Theorem 2.  I assume these are the number of required Hessian and Jacobian vector products.\n\n- The description of the algorithm is fairly difficult to follow.  I would recommend moving the second empirical result on hyper-representation learning to the appendix and perhaps using the extra space to more clearly explain the algorithm."
                },
                "questions": {
                    "value": "1. This question is a bit broader than the scope of the paper, but answering it would help quite a bit in terms of clarity.  The authors mention a lower bound of Zhang et. al (2021) which is achieved for deterministic algorithms by Lin, et. al (2020b).  Could the authors clarify the situation on the lower bound in the specific setting they consider? E.g. with the smoothness assumptions imposed by Assumptions 2, 3 and strong convexity Assumption 1, are there known results for lower bounds on reaching a second order stationary point as considered here? It is interesting to improve upper bounds as done in this paper, but some guidance on lower bounds would either (i.) situate and clarify the results quite a bit if known or (ii.) strengthen the results significantly if not known. \n\n2. Regarding the numerical experiments, the trajectory of the proposed algorithm exhibits some interesting behavior which would be nice to clarify.  In particular, should the reader interpret the flat regions (e.g. Figure 1.(a) iterations 10^{4} \u2013 2\\cdot 10^{4}) as while the algorithm is trying to escape from a bad critical point? Moreover, there seem to be distinctions in the convergence behavior in the different phases.  It is a bit hard to tell, but the proposed method seems to enjoy linear convergence to the first critical point and thereafter sublinear convergence behavior (with different rates of convergence, for instance at iterate 4*10^{4} in Figure 1.(a)).  Could the authors clarify this a bit?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6660/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6660/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6660/Reviewer_5LK2"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6660/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698770431815,
            "cdate": 1698770431815,
            "tmdate": 1699636761936,
            "mdate": 1699636761936,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PzlYJzQU5N",
                "forum": "BAX3NXJ6vU",
                "replyto": "7e6ExujdiK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6660/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6660/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "We appreciate the recognition of the contribution of our paper. We will reply to your questions as follows.\n1. Thank you for the suggestion of studying the lower bound for second-order stationary point. We can reach some conclusions based existing works. Since the hard instance constructed by Zhang et al (2021) automatically satisfies Assumption 3 and second-order stationary point is a special case of first-order stationary, the lower bound of second-order stationary point should be no smaller than first-order stationary point. In addition, the complexity of perturbed gradient method matches the result of searching first-order stationary point if ignoring logarithmic term, which indicates our method is near-optimal to achieve second-order stationary point.\n2. Yes, we think the flat region is probably the stage of escaping from a bad critical point. When $x$ is far away from a first-order stationary point, the algorithm will stay in the descent phase and the convergence is fast in this stage. When $x$ is approaching a first-order stationary point, perturbations and escaping phases will occur and sometimes they could be slower than the original descent phase, which can be a possible reason for the slow convergence after $4 \\times 10^4$ gradient oracles."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6660/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700629802633,
                "cdate": 1700629802633,
                "tmdate": 1700629802633,
                "mdate": 1700629802633,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "2JdJhO7vQN",
            "forum": "BAX3NXJ6vU",
            "replyto": "BAX3NXJ6vU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6660/Reviewer_tUHe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6660/Reviewer_tUHe"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a new algorithm, PRGDA, that combines the ideas of LENA, a\nfirst-order algorithm for escaping saddle points, and SREDA, a variance\nreduction method for nonconvex-strongly-concave (NC-SC) minimax optimization.\nThe authors provide convergence guarantees for the proposed algorithm. For\nstochastic NC-SC minimax optimization, this is the first first-order algorithm\nto achieve second-order convergence, and it requires $\\tilde{O}(\\kappa^3\n\\epsilon^{-3})$ gradient complexity to find an $O(\\epsilon, \\sqrt{\\rho\n\\epsilon})$ second-order stationary point. For stochastic NC-SC bilevel\noptimization, it achieves $\\tilde{O}(\\kappa^3 \\epsilon^{-3})$ and\n$\\tilde{O}(\\kappa^7 \\epsilon^{-3})$ gradient complexities for the upper and\nlower level functions, respectively. Further experiments are conducted to show\nthe ability of the algorithm to find local minima instead of saddle points."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The proposed PRGDA is the first first-order stochastic algorithm for NC-SC\n  minimax optimization with a second-order convergence guarantee, and its\n  complexity matches the best result for finding a first-order stationary\n  point.\n\n* For bilevel optimization, the new method improves upon the complexity of\n  existing methods."
                },
                "weaknesses": {
                    "value": "* I suggest that the author motivate and discuss in the paper why, in minimax optimization, we aim to find the local minimum of the primal function in the first place. In minimization problems, this is natural. However, in games, we care about equilibria. For instance, [1] discussed the significance of the local minimax point in this area, while [2] mentioned that a second-order stationary condition implies a local minimax point (Fact 1). Nevertheless, the relationship between saddle points of the primal function and the local minimax point remains somewhat unclear to me. Do they not intersect at all? Why should we escape these saddle points? What happens in bilevel optimization?\n\n* Although the work proposes the first first-order stochastic algorithm for NS-SC minimax optimization with second-order convergence and improves the complexity for bilevel problems, the techniques seem similar to existing methods, namely, LENA [3] and SREDA. Could the author elucidate the novelty in the algorithm design or proof techniques?\n\n* Regarding the experiments, how did the author choose the hyper-parameters? Were these hyper-parameters optimized for each algorithm? While the sensitivity of StocBio + iNEON to hyper-parameters is discussed, I am curious about the fairness of the comparison.\n\n* Some claims appear unsound:\n    - Theorems 1 and 2 should also include assumptions regarding noise. This is only mentioned in the appendix during the proof of these theorems. Additionally, the noise assumption (Equation 13) is not \"bounded variance\" but should be termed as bounded noise or bounded noise support, which is stronger than bounded variance.\n    - \"PRGDA is the first algorithm that is guaranteed to obtain second-order stationary point for stochastic nonconvex minimax optimization problems.\" However, newer versions of the cited paper (Chen et al. (2021b)) introduce a stochastic version. This should also be reflected in Table 1; for instance, Cubic-GDA should be marked in the \"Stochastic\" field.\n    - Some references appear to be inaccurate, for example, \"including intuitive methods SGDmax (Jin et al. (2019))\", and \"SGDmax (Jin et al. (2019)) is an intuitive double loop algorithm\".\n\n* Some notations either are not introduced or are only formally defined in later sections, such as:\n    - \"$Gc$\" in the abstract.\n    - \"$\\Phi$\" is introduced early on but is only defined in section 3.\n    - \"SFO\" is not defined. I assume it stands for \"stochastic first-order oracle\".\n    - \"$JV$\" and \"$HV$\" in Theorem 2 are not defined.\n\n# References\n\n[1] Jin, Chi, Praneeth Netrapalli, and Michael Jordan. \"What is local optimality in nonconvex-nonconcave minimax optimization?.\" International conference on machine learning. PMLR, 2020.\n\n[2] Chen, Ziyi, Zhengyang Hu, Qunwei Li, Zhe Wang, and Yi Zhou. \"A Cubic Regularization Approach for Finding Local Minimax Points in Nonconvex Minimax Optimization.\" Transactions on Machine Learning Research. 2020.\n\n[3] Chen, Zixiang, Dongruo Zhou, and Quanquan Gu. \"Faster perturbed stochastic gradient methods for finding local minima.\" International Conference on Algorithmic Learning Theory. PMLR, 2022."
                },
                "questions": {
                    "value": "Could the author clarify the concerns in Weaknesses 1-3?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6660/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6660/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6660/Reviewer_tUHe"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6660/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698847088449,
            "cdate": 1698847088449,
            "tmdate": 1699636761834,
            "mdate": 1699636761834,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "licXmwbYw2",
                "forum": "BAX3NXJ6vU",
                "replyto": "2JdJhO7vQN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6660/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6660/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "Thank you for the effort to review our work and we will address your concerns as follows.\n1. Thank you for the suggestion of discussing the relation between saddle point of $\\Phi(x)$ and local minimax point. Here we will prove that under Assumption 1 and Assumption 2, a saddle point of $\\Phi(x)$ is not a local minimax point. Suppose $x$ is a saddle point of $\\Phi(\\cdot)$, then for $\\forall \\delta > 0$, there exists $x\u2019$ such that $|| x\u2019 \u2013 x || \\le \\frac{\\delta}{\\kappa}$ and $\\Phi(x\u2019) < \\Phi(x)$. Let $y = y^*(x)$ and $y\u2019 = y^*(x\u2019)$. By Proposition 1 in Appendix F we have $|| y\u2019 \u2013 y || \\le \\delta$. As $y$ and $y\u2019$ are maximizers for $x$ and $x\u2019$, we know $g_{\\delta} (x) = \\Phi(x)$ and $g_{\\delta} (x\u2019) = \\Phi(x\u2019)$ since $|| y\u2019 \u2013 y || \\le \\delta$. Therefore, we have $ g_{\\delta} (x\u2019) \\le g_{\\delta} (x)$ according to the definition of $x\u2019$, which implies that $(x, y)$ is not a local minimax point. \n2. We summarize some fundamental challenges as follows. Firstly, the estimation of $v_t - \\nabla \\phi(x_t)$ is different to the original minimax optimization as we introduce the perturbation and adopt a larger stepsize in the escaping phase. It should be estimated in these new situations. Secondly, since in minimax problem $y$ also produces noise rather than just one variable $x$, the noise of gradient estimator is larger than conventional single-level optimization. Meanwhile, the noise is also influenced by the parameters of the escaping phase (such as $r$ and $\\bar{D}$) as we have mentioned, which indicates that the selection of parameters is harder than the work of the LENA algorithm. Thirdly, the dependence of $\\kappa$ is not included in related works of Perturbed GD and its variant. But we need to analyze the relation between the parameters of escaping phase and $\\kappa$ and provide proper options.\n3. In StocBiO + iNEON, a subroutine iNEON is run to compute the negative curvature. In each inner loop iteration of this subroutine, the full batch loss function value is estimated approximately via the stochastic minibatch. In theoretical analysis the batchsize is $O(\\epsilon^{-2})$, which makes the estimation precise. However, it is too expensive in practice. The precision of this estimation is crucial to StocBiO + iNEON, and hence it suffers poor performance if the batchsize used for this estimation is not large enough. In our experiment, all regular batchsize is fixed as 40. In PRGDA, a large batch of $S_1 = S_2 \\cdot q = 1000$ is loaded periodically for q = 25. The averaged batchsize is small, while StocBiO + iNEON needs the large batch in every iteration in the subroutine. In our experiment, the batchsize used for estimating the loss function value in iNEON is set to 40, in which condition StocBiO + iNEON fails to escape saddle point. We conduct some additional experiments to increase the batchsize to 1/10 full batch and StocBiO + iNEON still fails to escape saddle point. When we increase the batchsize to 1/4 full batch and other hyperparameters keep the same, StocBiO + iNEON escapes saddle point and achieves the ratio of distance of 0.42 after $8 \\times 10^4$ gradient oracles and 0.29 after $1.2 \\times 10^5$ gradient oracles when d = 100. The result is still slower than PRGDA in Figure 2 (c)."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6660/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700629768871,
                "cdate": 1700629768871,
                "tmdate": 1700629768871,
                "mdate": 1700629768871,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7vpkSJHryO",
            "forum": "BAX3NXJ6vU",
            "replyto": "BAX3NXJ6vU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6660/Reviewer_JNob"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6660/Reviewer_JNob"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a stochastic first-order algorithm called PRGDA for nonconvex-strongly-concave minimax optimization. For bilevel optimization in particular, the authors prove convergence to a second-order stationary point with a gradient complexity of $O(\\epsilon^{-3})$, which improves upon the previous best result in Huang et al. 2022, which achieved a complexity of  $O(\\epsilon^{-4})$."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "I think the main strength of this paper is a theoretical improvement of the gradient complexity, as I've summarized above."
                },
                "weaknesses": {
                    "value": "While I think the theoretical result in this paper is interesting, there are a few reasons that prevent me from giving this paper a higher score.\n- The overall presentation is not clear. Specifically, in sections 4 and 5 where algorithm 1 is introduced, the description is very dense and difficult to parse. The authors refer to quite a few previous algorithms such as SREDA, PiSARAH and SPIDER without actually giving a brief summary of what these algorithms do. Also missing from this section is a highlight of what makes PRGDA different from the previous SOTA method in Huang et al. 2022. \n- Another major weak point in the presentation is a lack of clearer comparison with prior work. In tables 2 and 3, it is unclear to me if most of these results are actually comparable, since I'm not sure if they use all the assumptions 1-5 in this paper. In addition, the related work is scattered throughout the whole paper, and many prior algorithms are named, but not described at all. Obviously the authors do not need to describe all prior work in detail, but I think it is important to highlight what makes PRGDA from prior algorithms except from stochasticity and a simple perturbation. \n- Section 6 is called convergence analysis, so i expected this section to include a discussion of the theoretical innovations of PRGDA that allows the authors to prove a better gradient complexity. However, there is no convergence analysis at all. Instead, only the two main theorems are stated, without any further explanation. This makes it hard to gauge how significant the theoretical guarantees are. For instance, in section 2.3 the authors claim that perturbed GD in the deterministic and stochastic settings are totally different. However, this is not the case at least in Jin et al. [1], where the proof for GD and SGD are quite similar. The analysis for GD and SGD might be more different in bilevel and minimax optimization, but I think it needs to be spelled out in more detail. \n\nOverall I think the actual contributions of this paper are a bit hard to see because of the presentation. I suggest the authors spend more space to clarify difference with prior work and spell out the innovations in both your algorithm and proof technique.\n\n[1] Jin, Chi, et al. \"On nonconvex optimization for machine learning: Gradients, stochasticity, and saddle points.\" Journal of the ACM (JACM) 68.2 (2021): 1-29."
                },
                "questions": {
                    "value": "Please see the weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6660/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6660/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6660/Reviewer_JNob"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6660/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699672386712,
            "cdate": 1699672386712,
            "tmdate": 1699672473032,
            "mdate": 1699672473032,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "l7AkoW6I6U",
                "forum": "BAX3NXJ6vU",
                "replyto": "7vpkSJHryO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6660/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6660/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "Thank you for pointing out the problems of our presentation. We will improve our presentation and address your concerns as follows.\n1. In our final version, we will refer to the SREDA algorithm in the Appendix and provide more details to ensure that readers can compare our work with previous works more easily. The most significant difference between StoBiO + iNEON and our work is that StoBiO + iNEON applies a subroutine (iNEON) to compute the negative curvature when reaching a first-order stationary point, while our method adds a perturbation. A weakness of StoBiO + iNEON is that large batch of $O(\\epsilon^{-2})$ is required to estimate the loss function value in every iteration in the iNEON subroutine. In contrast, our method only requires an averaged batchsize of $O(\\epsilon^{-1})$. Our experimental results show that StoBiO + iNEON cannot escape saddle point effectively with small batch, under which setting our method succeeds to find second-order stationary point.\n2. In our final version, we will specify the assumptions that is used for each method in Table 2 and 3. For example, in Table 3 Acc-MDA and SREDA require Assumption 1 and 2. SGDA requires Assumption 2 (more complexity) or Assumption 1 and 2 (less complexity). Our PRGDA (minimax) requires Assumption 1, 2 and 3. The assumption of Lipschitz continuous second-order derivative is common in previous works that analyze the second-order optimality, including PGD, SSRGD, Cubic-GDA, MCN and StocBiO + iNEON. Besides, without the escaping phase, algorithms such as SREDA still cannot reach second-order stationary point even Assumption 3 is hold (considering the example that GD is trapped at saddle points). \n3. We summarize some fundamental challenges as follows. Firstly, the estimation of $v_t - \\nabla \\phi(x_t)$ is different to the original minimax optimization as we introduce the perturbation and adopt a larger stepsize in the escaping phase. It should be estimated in these new situations. Secondly, since in minimax problem $y$ also produces noise rather than just one variable $x$, the noise of gradient estimator is larger than conventional single-level optimization. Meanwhile, the noise is also influenced by the parameters of the escaping phase (such as $r$ and $\\bar{D}$) as we have mentioned, which indicates that the selection of parameters is harder than the work of Pullback algorithm. Thirdly, the dependence of $\\kappa$ is not included in related works of Perturbed GD and its variant. But we need to analyze the relation between the parameters of escaping phase and $\\kappa$ and provide proper options."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6660/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700629724496,
                "cdate": 1700629724496,
                "tmdate": 1700629724496,
                "mdate": 1700629724496,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]