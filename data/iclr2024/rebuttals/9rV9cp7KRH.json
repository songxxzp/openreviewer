[
    {
        "title": "Incentivized Collaborative Learning: Architectural Design and Insights"
    },
    {
        "review": {
            "id": "MPzrB8ylye",
            "forum": "9rV9cp7KRH",
            "replyto": "9rV9cp7KRH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4013/Reviewer_R699"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4013/Reviewer_R699"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes an architecture framework for collaborative learning with the aim of incentivizing collaboration among multiple entities while maximizing the utility of the coordinator. The framework is realized by formulating a pricing plan, which determines participants\u2019 participation cost, and a selection plan, which selects active participants to determine the collaboration outcome. The conditions of Nash equilibriums and also the optimization objectives for the system are derived in the paper. The authors have also empirically shown the versatility of the framework by applying it to three concrete learning scenarios of interests, including federated learning, assisted learning and multi-armed bandits."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The motivation considering the incentives of both the coordinator/system and the participants is sound.\n2. The framework includes important stages of the incentivized learning pipeline, such as pricing, selection and rewarding, which is rather comprehensive.\n3. The paper has shown the application to three scenarios to incentivize FL, AL and MAB and presented empirical evidence for the effects of pricing and selection designs in the framework."
                },
                "weaknesses": {
                    "value": "1. The novel contributions and the new insights from the unified framework need further clarification.\n2. The pricing plan formulation and its dependency on the individual outcomes of active and non-active participants is not clearly elaborated in the paper.\n\nThe details for the weaknesses raised above are elaborated below in the Questions."
                },
                "questions": {
                    "value": "1. This work proposes a grand framework with abstract terminologies that unifies existing formulations for the incentivization problem into a unified framework. However, what are the new insights that can be derived because of this unification and cannot be observed otherwise? I can see that the work still mainly relies on deriving Nash equilibriums with individual rationalities (IR) constraints, and strives to maximize some system utility (maybe more flexible with hyperparameters). These concepts are commonly seen in the existing literature that the authors have cited. And mutual benefits of the coordinator (or, system) and the participants (or, clients) are not rare in existing works, either. Therefore, I wonder what are the new insights? This point is important to assess the significance of this paper.\n2. Could you elaborate on the specific meaning and implications of \u201cprior works has often focused on designing an incentive as a separate problem based on an existing collaboration scheme, instead of treating incentive as part of the learning itself\u201d? This is stated at the end of the \u201cRelated Works\u201d section.\n3. The pricing plan $\\mathcal{P}$ looks at the realized collaboration gain from the outcomes of the active participants in $I_A$ to charge all participants in $I_P$. Does the pricing differentiate participants with high $z_m$ from those with low $z_m$?\n4. It appears strange to me that the pricing for the non-active participants depends on the individual gains of the active participants $z_m$, stated in (1). Please correct me if I am mistaken.\n5. Under the formulation of this paper, the incentive of participation for $m$ only depends on the utility income of $m$ himself minus the participation cost. This means that the client is incentivized as long as (9) is fulfilled. However, in practice, a candidate\u2019s incentive should also depend on other candidates. For example, knowing that others have a higher expected gain with lower-quality data can deter participation. How does the framework address this scenario?\n6. Clarification: At the end of Page 5, it is stated that \u201cif not selected, it will become an inactive participant with zero gain, which will contribute to the system\u2019s profit but not harm the collaboration.\u201d Why would the gain be zero? All participants will receive $z_{I_A}$ and there might be a large utility income gain for this \u201cinaccurate candidate\u201d. \n7. How does Theorem 1 translate to functional forms of the pricing plan in practice?\n8. Why is it acceptable and reasonable to assume the utility functions (e.g., utility income $\\mathcal{U}$) of the candidates are known to the system for pricing and selection? Also, how practical is it to calculate $E [ \\mathcal{U}(z_{I_A}) - \\mathcal{U}(z_m) ]$?\n9. It was mentioned in Remark 5 that \u201cif following the above-optimized selection plan, will not select it as active\u201d. However, I could not find descriptions in the main text about the selection plans that make a decision based on the prices $\\mathcal{P}_m$ or local gain $z_m$. I only see descriptions about randomized selection. Could you point me to the relevant sections or elaborate here?\n\n[Minor]\n1. Better not to overload the collaborative gain function $\\mathcal{G}$ to take an individual $z_m$ as input, since $z_m$ should also depend on the outcomes of other active participants in $I_A$?\n2. Some other notations are confusing. For example, $I_P = Incent_m (\\mathcal{P})$, here $I_P$ is a set while $Incent_m()$ outputs whether a client $m$ is incentivized to participate."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4013/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698396164354,
            "cdate": 1698396164354,
            "tmdate": 1699636363573,
            "mdate": 1699636363573,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hA0ZJYyncK",
                "forum": "9rV9cp7KRH",
                "replyto": "MPzrB8ylye",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4013/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4013/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your constructive comments."
                    },
                    "comment": {
                        "value": "**1**. This work proposes a grand framework with abstract terminologies that unifies existing formulations for the incentivization problem into a unified framework. However, what are the new insights that can be derived because of this unification and cannot be observed otherwise? I can see that the work still mainly relies on deriving Nash equilibriums with individual rationalities (IR) constraints, and strives to maximize some system utility (maybe more flexible with hyperparameters). These concepts are commonly seen in the existing literature that the authors have cited. And mutual benefits of the coordinator (or, system) and the participants (or, clients) are not rare in existing works, either. Therefore, I wonder what are the new insights? This point is important to assess the significance of this paper.\n\n**Response**: Thanks for your query about new insights from our framework. We extract some concrete examples from the paper to demonstrate the insights of our approach.\n\nInsight 1: suitable incentives can improve collaboration performance. Unlike prior work that treats incentives as a separate problem, our framework integrates incentives into the learning process itself. For example, in the federated learning use case, we developed a theory-guided algorithm for simultaneously optimizing the pricing plan and performing federated learning (Appendix D). The insight is that a client, especially an adversarial client, will opt out of the selection process if participation costs are too high. This reduces system exploration costs and improves collaboration efficiency.\n\nIn the assisted learning use case, we showed the insight that entities could be incentivized to autonomously collaborate to enhance personal learning objectives, even without a central coordinator (Section 3.2.1 and Appendix E). \n\nIn the multi-armed bandit use case (Appendix F), we showed the insight that screening at both participation and selection stages could simultaneously achieve the following goals: 1) prevent the laggard arms from participating by leveraging their incentives, which can further improve the collaboration gain, 2) encourage the medium-performing arms to participate to enjoy the collaboration gain, which can boost the overall profit, and 3) reward the top-performing arms to participate to make sure that they can be consistently selected to be active. Consequently, incentives reduce the complexity of exploration, which can further improve the quality of generated outcomes and engage a broader range of entities.\n\nInsight 2: Each participant can simultaneously play the roles of contributor and beneficiary of the collaboration gain. Each entity\u2019s participation cost can be positive or non-positive to reward those who contribute positively and charge those who hinder collaboration or disproportionately benefit from it. An interesting case is to have the system incur a net zero cost, as exemplified in Section 3.2.2. The insight is that a system can still engage entities to achieve the maximum collaborative gains even without incurring net costs.\n\nInsight 3. The joint architecture of pricing and selection plans could manage free-riders and adversarial participants.\n \nA free-rider is an entity that hopes to participate and enjoy the collaboration gain realized by other more capable participants with a relatively small participation cost. By ensuring a minimum probability of being active and incurring a related cost, one could effectively prevent entities from exploiting the system without contributing. Additionally, for adversarial participants, the pricing plan may impose a high cost whenever the realized local gain revealed after the collaboration exceeds a pre-specified threshold, so no adversary would dare to risk paying an excessively high cost after participating in the game. \n\nThese insights, derived from our case studies and theoretical work, illustrate how the unified ICL framework fosters win-win situations in collaborative settings, a perspective not extensively explored in existing literature. We believe these contributions significantly advance the understanding and application of incentivization in collaborative learning."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4013/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700713844085,
                "cdate": 1700713844085,
                "tmdate": 1700713844085,
                "mdate": 1700713844085,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "aHfufuryAu",
            "forum": "9rV9cp7KRH",
            "replyto": "9rV9cp7KRH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4013/Reviewer_cras"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4013/Reviewer_cras"
            ],
            "content": {
                "summary": {
                    "value": "Starting from the significant challenge of collaborative learning, this paper aims to solve how to effectively motivate multiple entities to collaborate before any collaboration occurs. And proposed ICL framework. This work elaborates on the roles, processes, and principles of the games used in the framework, and proved the effectiveness of ICL through mathematical derivation. By using different pricing or selection plans in the experiments, the authors discussed how incentive settings affect the effectiveness of the framework."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThe authors proposed a clear incentivized collaborative learning framework, along with detailed descriptions of the roles and principles of ICL.\n2.\tThe authors gave sufficient and detailed mathematical derivation to prove the effectiveness of ICL.\n3.\tMany experiments were conducted to validate the effectiveness of the proposed ICL framework and analyse the influences from pricing and selection plans."
                },
                "weaknesses": {
                    "value": "1. The discussion in the paper cannot fully reflect the superiority of the proposed framework compared to previous methods. For example, there seems no specific comparative experiment to confirm that the proposed ICL framework is more efficient than previous works.\n2. It\u2019s kind of confusing that the description of the experiements is less detailed about their design. For example, the employed model and the meaning of the metrics in the first experiment are not very clear.\n3. Experiment settings are kind of insufficient to support all the contributions, such as the discussion about the influences from the selection plans, while most of the selection plan is based on Bernoulli distribution. The discussion about how to select appropriate pricing and selection plans is also insufficient.\n\nOverall, the research problem is meaningful and well-defined. However, the paper is somewhat lack of clarity to make readers understand the superiority of the proposed method fully and easily."
                },
                "questions": {
                    "value": "1.\tCan you give more explicit evidences that the proposed ICL framework utilizes the incentive mechanism more effectively than previous works?\n2.\tI wish the experiment settings can be more detailed written in the main body of the paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4013/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698646208159,
            "cdate": 1698646208159,
            "tmdate": 1699636363507,
            "mdate": 1699636363507,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "z1HjatMhLu",
                "forum": "9rV9cp7KRH",
                "replyto": "aHfufuryAu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4013/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4013/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your constructive comments."
                    },
                    "comment": {
                        "value": "**Comment 1**: The discussion in the paper cannot fully reflect the superiority of the proposed framework compared to previous methods. For example, there seems to be no specific comparative experiment to confirm that the proposed ICL framework is more efficient than previous works. \n\n\n**Response**: Thank you for your valuable feedback regarding the comparative analysis of our ICL framework. We have included several experimental studies that compare incentivized and nonincentived/standard collaborative learning in federated learning (FL), assisted learning (AL), and multi-armed bandit (MAB) settings. We did not compare it with other incentivation techniques because the introduced architectural framework fundamentally differs from previous methods. The ICL framework is designed to address the under-explored area of when and why incentive mechanisms can enhance collaboration performance. The core contribution of our work is the establishment of general principles and insights into incentivized collaboration. Our experimental validation is strategically designed to corroborate the theoretical insights and principles developed in the ICL framework. Our experiments are not merely about efficiency comparisons but are aimed at demonstrating the practical applicability and benefits of the proposed framework in a variety of settings. \n\n\n**Comment 2**: It\u2019s kind of confusing that the description of the experiments is less detailed about their design. For example, the employed model and the meaning of the metrics in the first experiment are not very clear. \n\n**Response**: Thank you for pointing this out. We will add more details such as model architectures, learning rates, and optimizers in the revised appendix. In particular, in the first experiment shown in Figure 2, we visualized the top-1 accuracy against communication rounds on the CIFAR10 dataset to show that a suitably incentivized FL algorithm in our framework can converge faster and better than the non-incentivized counterpart.\n\n\n**Comment 3**: Experiment settings are kind of insufficient to support all the contributions, such as the discussion about the influences from the selection plans, while most of the selection plan is based on Bernoulli distribution. The discussion about how to select appropriate pricing and selection plans is also insufficient.\n\n**Response**: Thank you for your insightful feedback. In our study, we focused on a probabilistic selection plan as detailed in Sections 2.4.2 and 3.1.1. This approach was chosen due to its broad applicability in various collaborative learning scenarios. In Remark 5, we provided a discussion of how these plans can be effectively utilized to mitigate issues like free-riding and adversarial behavior. However, we acknowledge that our analysis does not extend to more complex, jointly dependent selection probabilities, which presents a challenging yet exciting avenue for future research. Regarding the pricing plans, we explored specific functional forms in our three use cases. These plans were chosen to align with the unique requirements of each scenario, highlighting the framework's adaptability. For example, in the federate learning experiments in Appendix D, we postulated a parametric form of the pricing plan in Equation (18) and proposed to optimize it online under the ICL framework. Such optimization will automatically identify/select a concrete pricing plan to operate for the next round of collaboration. Again, we appreciate your feedback which has improved the clarity of the work. If you have any suggestions or specific areas you believe would benefit from further exploration, we would greatly appreciate your input."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4013/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700713754804,
                "cdate": 1700713754804,
                "tmdate": 1700713754804,
                "mdate": 1700713754804,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "a3M7wiMwYQ",
            "forum": "9rV9cp7KRH",
            "replyto": "9rV9cp7KRH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4013/Reviewer_npuS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4013/Reviewer_npuS"
            ],
            "content": {
                "summary": {
                    "value": "This work investigates incentivized collaborative learning where there are candidates that are potentially looking into joining the federation, the participants who will get the reward from the actual outcomes of the collaboration, and the active participants who participate in the training. The work defines a coordinator who orchestrates the participation of the clients and the pricing plan and profit, and depending on these components, propose to maximize the system-level profit under constraints of individual clients' incentives. The work investigates different use cases of the proposed incentivized collaborative learning framework along with analysis on robustness and accuracy."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The work investigates an interesting area in collaborative learning regarding client incentives and monetary compensations and cost analysis. The work proposes a framework for incentivized collaborative learning where federated learning, assisted learning, and MAB all come under their umbrella.\n\n- The work provides theoretical results, although limited to specific scenarios such as the three-entity setting. \n\n- The work evaluates their framework under robustness against byzantine attacks and scenarios where there are both competing and non-competing clients."
                },
                "weaknesses": {
                    "value": "- A major concern I have over the work is that in stage 1 of the method, the coordinator needs to set a pricing plan based on prior knowledge of candidates potential gains from previous rounds. This means that first the client needs to participate first to know its incentives, and moreover, if the potential gain is erroneous, the ICL framework may not be able to properly incentivize the clients. This becomes even more trickier when clients have the flexibility to opt-in or opt-out which can often be the case for incentivized collaborative learning settings.\n\n- Another concern I have is that the work did not compare their method against other relevant work for incentivization in collaborative learning such as \n [1] Yae Jee Cho, Divyansh Jhunjhunwala, Tian Li, Virginia Smith, and Gauri Joshi. To federate or not to federate: Incentivizing client participation in federated learning. arXiv preprint arXiv:2205.14840, 2022. \n[2] Avrim Blum, Nika Haghtalab, Richard Lanas Phillips, and Han Shao. One for one, or all for all: Equilibria and optimality of collaboration in federated learning. In International Conference on Machine Learning, pp. 1005\u20131014. PMLR, 2021. \n[3] Rachael Hwee Ling Sim, Yehong Zhang, Mun Choon Chan, and Bryan Kian Hsiang Low. Collaborative machine learning with incentive aware model rewards. In International Conference on Machine Learning, pp. 8927\u20138936. PMLR, 2020.\nEspecially for parts of the work such as 3.1.1 which aims for large participation approximation works like [1] seem relevant and other parts such as section 3.2, [2,3] seems relevant. It seems strange to me that the work does not compare their work with such relevant line of work.\n\n- Lastly, the work seems mainly theoretical since the experimental validation is rather limited. However, the assumptions they use for the theoretical work such as having a three entity setting is rather restrictive. Moreover the implications of the main theoretical results such as Theorem 2 and 4 is unclear to me. In what conditions it is guaranteed that the clients benefit from the system for each corresponding theorems? \n\nDue to these main reasons I am leaning towards rejection. I look forward to the author's rebuttal phase and discussion."
                },
                "questions": {
                    "value": "See weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4013/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4013/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4013/Reviewer_npuS"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4013/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698875092204,
            "cdate": 1698875092204,
            "tmdate": 1699636363400,
            "mdate": 1699636363400,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5NiHKfsjxo",
                "forum": "9rV9cp7KRH",
                "replyto": "a3M7wiMwYQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4013/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4013/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the constructive comments."
                    },
                    "comment": {
                        "value": "**Comment 1**: A major concern I have over the work is that in stage 1 of the method, the coordinator needs to set a pricing plan based on prior knowledge of candidates potential gains from previous rounds. This means that first the client needs to participate first to know its incentives, and moreover, if the potential gain is erroneous, the ICL framework may not be able to properly incentivize the clients. This becomes even more trickier when clients have the flexibility to opt-in or opt-out which can often be the case for incentivized collaborative learning settings.\n\n**Response**: Thank you for this comment. It is indeed a valid concern that the coordinator needs to set the pricing plan according to prior knowledge of candidates\u2019 potential gains in order to optimize the system gain. In the experimental studies, we implemented this for each round using realized gains from previous rounds. Nevertheless, this does not necessarily mean that a client needs to participate first to know its incentives. For example, in the multi-armed bandit (MAB) use case, each candidate decides its incentive by observing the gains achieved by selected arms and contrast with its local potential to generate rewards; if it does not know its potential to generate reward, it could locally simulate to obtain an estimate of its potential. Similarly, in FL, a client could choose to run a local update to decide its incentive to participate, should local computation cost be not a matter of concern. In the paper, we did not specify the concrete way of obtaining such prior knowledge in the framework description, and instead, mentioned specific possible choices when introducing the three use cases. We will incorporate your comment in the revision.\n\n**Comment 2**: Another concern I have is that the work did not compare their method against other relevant work for incentivization in collaborative learning such as [1] Yae Jee Cho, Divyansh Jhunjhunwala, Tian Li, Virginia Smith, and Gauri Joshi. To federate or not to federate: Incentivizing client participation in federated learning. arXiv preprint arXiv:2205.14840, 2022. [2] Avrim Blum, Nika Haghtalab, Richard Lanas Phillips, and Han Shao. One for one, or all for all: Equilibria and optimality of collaboration in federated learning. In the International Conference on Machine Learning, pp. 1005\u20131014. PMLR, 2021. [3] Rachael Hwee Ling Sim, Yehong Zhang, Mun Choon Chan, and Bryan Kian Hsiang Low. Collaborative machine learning with incentive aware model rewards. In the International Conference on Machine Learning, pp. 8927\u20138936. PMLR, 2020. Especially for parts of the work such as 3.1.1 which aims for large participation approximation works like [1] seem relevant and other parts such as section 3.2, [2,3] seem relevant. It seems strange to me that the work does not compare their work with such a relevant line of work.\n\n**Response**: Thank you for highlighting these excellent papers. While they are relevant as they all study incentives in federated learning from different perspectives, there are some essential differences with our work. Specifically, the main objective in [1] is to increase the number of incentivized clients by maximizing a proxy of the Incentivized Participation Rate. The section 3.1.1 in our work established a large-sample analysis of the equilibrium condition and an individual entity\u2019s incentive under that. From the version of [1] we read, we could not find a large sample analysis similar to our section 3.1.1. Reference [2] studies the (centralized) resource allocation problem that aims to minimize the total social resource while meeting individual constraints. This is different from our section 3.2 that studies a decentralized incentive setting regarding how entities could be incentivized to work together autonomously. Reference [3] proposes to reward a federated learning client based on Shapley value and provide a model as a reward. We have cited the above works and mentioned their relevance and difference in the paper. Thank you again for pointing out these references."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4013/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700713659759,
                "cdate": 1700713659759,
                "tmdate": 1700713659759,
                "mdate": 1700713659759,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]