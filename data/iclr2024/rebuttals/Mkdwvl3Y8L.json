[
    {
        "title": "Discovering Knowledge-Critical Subnetworks in Neural Language Models"
    },
    {
        "review": {
            "id": "IYxTqGrZN0",
            "forum": "Mkdwvl3Y8L",
            "replyto": "Mkdwvl3Y8L",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7241/Reviewer_VC2F"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7241/Reviewer_VC2F"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes to use a differentiable weight masking strategy to find subnetworks within pretrained language models that are critical for encoding specific knowledge. It is demonstrated that such subnetworks are highly sparse, and removing such subnetworks can selectively remove certain triplet knowledge without significantly affecting other knowledge and general language abilities in the model. The paper also shows that the knowledge-critical subnetworks determine the model's utilization of knowledge in downstream tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The authors introduce a novel method for finding subnetworks in large language models responsible for encoding specific knowledge, and demonstrate that it effectively finds highly-sparse subnetworks that are specific to a given set of knowledge.\n\n* The paper uses analysis from different dimensions to verify the causal effect of the knowledge-critical subnetwork on the selected knowledge, including ablation study, expansion of the mask, and performance on downstream tasks controlled for the selected knowledge. The results strengthen the conclusion that the knowledge-critical subnetwork has a causal effect on the storage and expression of knowledge.\n\n* The paper is well-written, well-structured and very accessible to the readers. \n\n* The existence of knowledge-critical subnetworks may have significant implications on the interpretability of pretrained language models and could guide future research in the field. Future research may be able to explore how these subnetworks can be adapted, potentially leading to more efficient model fine-tuning."
                },
                "weaknesses": {
                    "value": "* The effectiveness of knowledge removal is not quite clear due to limited metrics: the paper mainly uses \"perplexity increase on verbalized triplet prompts\" as a measure of knowledge removal but does not provide a solid interpretation of this metric. For example, one does not know how much perplexity increase corresponds to a complete (or near-complete) removal of the knowledge. Therefore, it may be hard to evaluate whether knowledge is truly removed with this metric alone. Also, there is a possibility that the perplexity drop is specific to the verbalizing template, so it may be helpful to evaluate on different templates as well.\n\n  Perhaps knowledge-centric question-answering benchmarks, like those used in Section 6.4, could provide more interpretable results. However, the results currently presented in Section 6.4 also fail to prove reliable removal of knowledge, as pruning knowledge subnetworks only results in a small decrease in performance (3-4%).\n\n* The effectiveness of knowledge preservation is also unclear due to possible overfit: the loss function is designed to preserve performance on ControlKG and ControlLM, and results show a negligible decrease in performance on them. However, it is possible that besides removing knowledge in TargetKG, the pruned model also sacrifices some other knowledge that is not in ControlKG and ControlLM. This would go against the goal of finding subnetworks specific to TargetKG. To rule out this possibility, the pruned model should be evaluated on a separate KG and a different corpus than those used in the loss function to make sure that the maintenance criterion is not overfitted to ControlKG and ControlLM.\n\n* Lack of analysis on the discovered knowledge subnetworks\n\n  * On sparsity: how sparse is truly sparse for a knowledge-critical subnetwork? If there are only 10-20 triplets in TargetKG, then 99% sparsity (~1M parameter for GPT2-small) does not seem very sparse, because it's unlikely that the model truly uses 1M parameter to store 10-20 triplets. I would personally expect a much higher sparsity (e.g., 99.99%) for a knowledge-critical subnetwork of 10-20 triplets, as a pre-trained language model typically stores a vast amount of knowledge.\n  * On specificity: one way to examine the specificity of the subnetwork could be comparing the subnetwork for two different groups of triplets. If the subnetworks are largely different, it will provide evidence that the subnetworks are specific to the selected knowledge.\n  * On trading-off suppression and maintenance: for two competing goals like suppression and maintenance, there is usually a tradeoff rather than a single best solution. It may be helpful to show this tradeoff by varying the weights in Equation 6, and it could also give justification for the choice of the weights."
                },
                "questions": {
                    "value": "* On model choice: GPT2 is a slightly outdated model, recent models such as LLaMA are much better at knowledge tasks and may provide more statistically significant results.\n* It's probably better to list some basic statistics of TargetKG, ControlKG, and ControlLM in the main text as they can be important for interpreting the results (e.g., sparsity).\n* How does the expression criteria in Section 6.2 differ from the suppression criteria? It seems that Equation 7 is (approximately) just the reverse of Equation 3."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7241/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7241/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7241/Reviewer_VC2F"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7241/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698408590038,
            "cdate": 1698408590038,
            "tmdate": 1699636862493,
            "mdate": 1699636862493,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MIfJt8GBqb",
                "forum": "Mkdwvl3Y8L",
                "replyto": "IYxTqGrZN0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7241/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7241/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer VC2F (Part 1)"
                    },
                    "comment": {
                        "value": "We would like to thank reviewer VC2F for their helpful feedback. We are grateful that the reviewer finds our analysis vast and our paper well-written and accessible. The reviewer also stated that our work has significant implications for future work in model interpretability. We address their questions on *limited metrics* and whether *knowledge erasure is prompt dependent* in the general message to all reviewers. We wrote the requested changes and clarifications in the paper in purple.\n\n> The effectiveness of knowledge removal: Due to limited metrics, it is not clear whether knowledge removal is effective. Perplexity on verbalized triplet prompts alone is not enough.\n\nAs mentioned in the general message to all reviewers, the reviewers wondered whether the rank of the gold tail entity can be used as an alternative metric. We also wondered about this and we report the rank differences between the remaining model and the original pretrained model in **Appendix D**, Table 10 (originally Table 11). These results align with the suppression and maintenance criteria described in Section 4.1. We added a forward pointer to these results in the main body in **Section 5** - \u201cSuccess Metrics\u201d paragraph.\n\n> The effectiveness of knowledge removal: Could the perplexity drop be specific to the verbalization template?\n\nWe provide performance on paraphrases in **Appendix H** (originally Appendix G) for three WordNet hypernym TargetKGs. We have found that the average perplexity differences are high on paraphrases of TargetKG, and the perplexity differences for ControlKG either are near 0 or are negative. We added a forward pointer to these results in our main body in Section 6.3.\n\n> The effectiveness of knowledge preservation: Besides removing knowledge in TargetKG, the pruned model could sacrifice some other knowledge that is not in ControlKG and ControlLM. To make sure that the maintenance criterion is not overfitted to ControlKG and ControlLM the authors should use a separate corpus for ControlKG and ControlLM.\n\nAs stated at the end of Section 5, paragraph \u201cDatasets\u201d, all results on ControlKG and ControlLM are on a held-out test set.\n\n> Lack of analysis on sparsity: 99% sparsity (~1M parameter for GPT2-small) for 10-20 triplets in TargetKG does not seem very sparse. I would personally expect a much higher sparsity (e.g., 99.99%) for a knowledge-critical subnetwork of 10-20 triplets, as a pre-trained language model typically stores a vast amount of knowledge.\n\nThe reviewer has an interesting intuition on the size of knowledge-critical subnetworks, which we also share. An efficient and modular language model would ideally dedicate only a small amount of parameters to remove information on 10-20 triplets. However, it is not clear whether the amount of parameters needed to encode information scales with the amount of knowledge. In particular, the model could robustly encode information in a repeated manner across several parameters, since it has been originally pretrained with dropout. Moreover, this size could also be dependent on the knowledge type. For example, with limited analysis, we found that subnetworks for the representation KG tend to be larger than the location and communication KGs, although representation has fewer triplets than the rest. A hypothesis could be that more common or fundamental knowledge that affects other types of knowledge requires more parameters to be removed.\n\nWe also want to emphasize that the sparsity was calculated over the masked regions rather than the whole subnetwork. Therefore, the majority of the subnetworks were a bit smaller than 1M parameters."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7241/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740754721,
                "cdate": 1700740754721,
                "tmdate": 1700740754721,
                "mdate": 1700740754721,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qHBtfMKBwa",
            "forum": "Mkdwvl3Y8L",
            "replyto": "Mkdwvl3Y8L",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7241/Reviewer_njyU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7241/Reviewer_njyU"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigates the presence of knowledge-critical subnetworks in pretrained language models (LMs) and proposes a method to discover and remove these subnetworks while minimizing adverse effects on the behavior of the original model.  Overall, the paper presents a novel approach for discovering knowledge-critical subnetworks in pretrained language models. However, further evaluation and comparison with existing methods, as well as addressing the mentioned weaknesses and clarifying the typos, would strengthen the paper's contribution."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Novel approach for discovering knowledge-critical subnetworks: The paper introduces a differentiable weight masking scheme that allows for the identification of subnetworks responsible for encoding specific knowledge in pretrained language models. This approach provides insights into how knowledge is encoded and can be potentially useful for model editing and finetuning.\n\n2. Analysis of seed-based variance and subnetwork composition: The paper investigates the stability of subnetwork discovery under seed-based variance and explores the composition of subnetworks from different seeds. This analysis adds valuable insights into the robustness and generalizability of the proposed method."
                },
                "weaknesses": {
                    "value": "1. Lack of comparison with other existing methods: The paper does not provide a comprehensive comparison with other existing methods for discovering knowledge-critical subnetworks in pretrained language models. This makes it difficult to assess the novelty and effectiveness of the proposed method.\n\n2. Limited evaluation on downstream tasks: The paper primarily focuses on the discovery of knowledge-critical subnetworks but lacks a thorough evaluation of the impact of these subnetworks on downstream tasks. It would be beneficial to include experiments that demonstrate the effect of subnetwork removal on various NLP tasks."
                },
                "questions": {
                    "value": "1. How does the proposed differentiable weight masking scheme compare to other existing methods for discovering knowledge-critical subnetworks in pretrained language models?\n\n2. Can the discovered knowledge-critical subnetworks be used for targeted model editing or finetuning to improve specific task performance?\n\n3. Can you provide more details about the filtering processes applied to the sampled connected KGs? How did these processes ensure the quality and balance of the sampled graphs?\n\n4. How did you validate the effectiveness of the discovered subnetworks in suppressing the expression of target knowledge triplets?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7241/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698738770113,
            "cdate": 1698738770113,
            "tmdate": 1699636862386,
            "mdate": 1699636862386,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "v0OPG5nkwQ",
                "forum": "Mkdwvl3Y8L",
                "replyto": "qHBtfMKBwa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7241/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7241/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer njyU"
                    },
                    "comment": {
                        "value": "We would like to thank reviewer njyU for their feedback. Notably, the reviewer found our approach as a novel way to discover knowledge-critical subnetworks. The reviewer considers our approach a potential future application in model editing and finetuning. We wrote the requested changes and clarifications in the paper in purple.\n\n> Can you provide more details about the filtering processes applied to the sampled connected KGs? How did these processes ensure the quality and balance of the sampled graphs?\n\nWe describe the filtering processes applied to the sampled connected KGs in **Appendix A**. In summary, once a small connected KG is sampled, we apply two filtering processes. The first one enforces many-to-one relationships in the $K_T$ graph to avoid head entities with multiple tails. This ensures that the dataset is not dominated by certain head entities and balances the graph. The second filtering process reduces the tail-entity imbalance to avoid over-fitting to a small set of tokens. For this, we count the frequency of the tail tokens in the sampled graph and keep at most a quartile amount of triplets with shared tail entities.\n\n> How did you validate the effectiveness of the discovered subnetworks in suppressing the expression of target knowledge triplets?\n\nWe validate the effectiveness of the discovered subnetwork by:\n1. Measuring the effect on the TargetKG, a validation ControlKG, and a validation LModeling when the subnetwork is removed from the original model\n2. Comparing with a randomly masked baseline to see if the increase in the perplexity can be matched with an equally sparse removed subnetwork\n3. Doing an ablation study to test whether all of the terms are required to get the most effective suppressing effect\n4. Verifying whether, for a downstream task, a forgotten test set knowledge can be transferred through finetuning \u2013 we find that removing the subnetwork indeed hinders this ability\n5. Establishing whether worse scoring paraphrases of the triplet on average increase in perplexity for TargetKG and stay similar for ControlKG."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7241/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740685681,
                "cdate": 1700740685681,
                "tmdate": 1700740685681,
                "mdate": 1700740685681,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7m8Xods8bw",
            "forum": "Mkdwvl3Y8L",
            "replyto": "Mkdwvl3Y8L",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7241/Reviewer_ikUx"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7241/Reviewer_ikUx"
            ],
            "content": {
                "summary": {
                    "value": "The paper argues that language models contain sparse subnetworks of parameters that are critical for expressing specific knowledge relationships. The authors then use an existing selected-pruning method to identify these \"knowledge-critical\" subnetworks: learning a binary mask over the parameters. They propose to optimise the binary mask jointly with three objectives 1) suppressing the expression of target knowledge triplets when the subnetwork is removed 2) maintaining performance on other knowledge triplets of a predefined KG and language modeling 3) sparsity regularizer as most work on pruning. \n\nExperiments on GPT-2 variants find highly sparse subnetworks of  ~98% sparsity, which is similar as most sparsity work using hard concrete.  Interestingly, the authors show that, removing the subnetworks significantly reduce the model's ability to express the associated knowledge, but maintain other capacities, indicating a certain level of controllability over the specific knowledge."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The authors address a very timely problem -- identify LLM subnetworks that correspond to certain knowledge and manipulate over the subnetworks to control the access of the knowledge.\n- The authors propose a sensible approach for tackle the problem. Empirical experiments over GPT-2 show consistent trends in different datasets."
                },
                "weaknesses": {
                    "value": "I think the paper can be improved in the following aspects:\n- Lack of Meaningful Metrics. \n    - The authors are showing the sparsity level over the masked parameters. Therefore 98% sparsity does not mean 98% of parameters in LLMs are not used. It would be more clear if the authors display the real sparsity levels.\n    - The authors only use PPL to measure the effectiveness of their method. However, the ppl values can be a bit confusing as its range can be very big. Would it more sensible to use ranking metrics? for example, the rank of the target entity token?\n- Lack of ablation studies\n    - ablation on sparsity levels. does varying the sparsity level from 98% to 20% or 60% change the conclusion? \n    - pruning methods based on hard concrete are usually sensitive to hyper-parameters. do you have any hyper-parameter sensitivity analysis?\n- Limited baselines. \n    - The only baseline is random masking of the maskable parameters, which is no surprise working poorly. The random baseline has no access to either TargetKG or ControlKG. It seems unfair to compare it with the proposed method if it uses much less information."
                },
                "questions": {
                    "value": "- Does your method generalise to other pretrained language models?\n- What's the computational complexity of the proposed method? Can it generalise to 7B parameter model [1]?\n- What are the computational infrastructure for your experiments? If the readers want to reproduce your results, how many GPUs do they need?\n- Prior research show that the embedding layer might contain lots of redundancy as the tokens follow long-tailed distribution. If you want to achieve high sparsity, pruning the embeddings can be a good choice. At the same time, the embeddings can be very informative. One simple baseline to remove a certain knowledge would be just erasing entity-related token embeddings. Why this is not one of your baseline?\n- Does combining two knowledge-critical subnetworks lead to suppress of both pieces of knowledge?\n- Does predicting missing entity fully represent this knowledge triplet? I am not sure. Even if it can correctly predict the missing entity, the prediction might be only based on the (subject, object) pair instead of based on the specific relation. In general, a knowledge triplet can be rephrased in multiple ways, eg. swapping the order of subject and object, missing relation prediction [2] etc. Can the proposed method can deal with the various rephrasing of a certain knowledge?\n\n[1]: https://arxiv.org/abs/2302.13971\n\n[2]: https://arxiv.org/abs/2110.02834"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7241/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698825739464,
            "cdate": 1698825739464,
            "tmdate": 1699636862263,
            "mdate": 1699636862263,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1JqxhnKHat",
                "forum": "Mkdwvl3Y8L",
                "replyto": "7m8Xods8bw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7241/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7241/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ikUx (Part 1)"
                    },
                    "comment": {
                        "value": "We would like to thank reviewer ikUx for their thoughtful feedback. We appreciate that the authors find the problem very timely and our method as a sensible way to approach it. We also address the reviewer\u2019s question on *limited metrics*, *cross-topic subnetwork analysis*, and *robustness to knowledge rephrasing* in the general message to all reviewers. We wrote the requested changes and clarifications in the paper in purple.\n\n> The authors are showing the sparsity level over the masked parameters. Therefore 98% sparsity does not mean 98% of parameters in LLMs are not used. It would be clearer if the authors displayed the real sparsity levels.\n\nIndeed, 98% sparsity means the sparsity of the removed subnetwork mask over the masked layers (in this case, the upper-half layers of the model). To make this more intuitive, we suggest reporting the **density of the removed subnetwork across all parameters** in the network, including those that are not masked. As it would affect the phrasing in many parts of the paper, we suggest making this revision for camera-ready.\n\n> Perplexity ranges can be very big. Would it be more sensible to use the rank of the target entity token?\n\nAs mentioned in the general message to all reviewers, the reviewers wondered whether the rank of the gold tail entity can be used as an alternative metric. We also wondered about this, and so in the submission, we report the rank differences between the remaining model and the original pretrained model in **Appendix D**, Table 10 (originally Table 11). These results align with the suppression and maintenance criteria described in Section 4.1. We added a forward pointer to these results in the main body in **Section 5** - \u201cSuccess Metrics\u201d paragraph.\n\nWe chose to display perplexity differences in the main body instead of rank as they better capture model certainty on the gold-tail token. For example, there could be cases where the remaining model has a larger rank than the original model leading to a large difference, but the probability differences between the two can be very small, and therefore not enough information about model certainty is reflected. Particularly, in our setting, where we optimize for a small difference between the TargetKG tail-token prediction distribution and a uniform distribution over all tokens in the vocabulary, we are bound to have multitudes of tokens being considered equally probable. This makes the rank metric less interpretable than perplexity. However, we agree that both metrics provide complementary views on this question, which is why we reported rank in the appendix initially.\n\n> Lack of ablation on sparsity levels \u2013 Does varying the sparsity level from 98% to 20% or 60% change the conclusion?\n\nThe reviewer brings an interesting perspective from the point of view of compression. Differentiable-weight masking is popular as a compression technique (Sanh et al 2020, Zhao et al 2020). Varying the sparsity level would require implementing a different type of regularization which could be possible. However, we instead designed an aggressive sparsity regularization as our goal in finding a knowledge-critical subnetwork is to find the minimum compression ratio to achieve semantic suppression of the knowledge. As a result, while an interesting research direction on its own, we think this analysis may not align with the core inquiry of our paper."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7241/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740602266,
                "cdate": 1700740602266,
                "tmdate": 1700740602266,
                "mdate": 1700740602266,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "D3mdIAcHAR",
            "forum": "Mkdwvl3Y8L",
            "replyto": "Mkdwvl3Y8L",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7241/Reviewer_cTTe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7241/Reviewer_cTTe"
            ],
            "content": {
                "summary": {
                    "value": "This paper explores a method for detecting and zeroing-out the parameters of an LLM which contain knowledge relevant to a specific topic. Such masks are posited as forming sub-networks critical to the topic area. To do this, the authors formulate a loss function whose optimization has four objectives, each corresponding to a term in the loss function:\n\n 1. topic-specific knowledge erasure: increase the perplexity on knowledge-base triples for the target topic area\n 2. preserve knowledge about non-target topics: perplexity on knowledge-base triples from non-target topics should be maintained at baseline (pre-intervention) levels\n 3. preserve general language fluency: the perplexity of non-target topic text should be maintained at baseline (pre-intervention) levels\n 4. sparsity: the learned parameter mask should mask out few parameters of the original LLM -- i.e., it should be sparse\n\nExperiments performed on triples from two different knowledge bases (WordNet and ConceptNet) show that the knowledge erasure procedure given does in fact increase perplexity on target-topic triples but not on triples from other topics. And the experiments show that basic linguistic fluency is maintained such that language perplexity does not increase for text outside of the target topic area.\n\nThe authors also perform experiments to examine whether knowledge erasure causes the effected LLMs to perform worse on downstream Q&A tasks for questions related the target topic. And indeed they do.\n\nFinally, ablation studies are performed to determine the importance of the first three component terms of loss function; additional experiments are performed to determine whether the detected knowledge-relevant subnetwork masks are robust such that expanding or shrinking their area does not drastically alter the level of knowledge erasured; and a slightly different objective function based on \"knowledge expression\" is tried but abandoned for the objective above."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The question of how topic-specific knowledge and expertise is stored in LLMs is important and fascinating since very little is currently well understood; and it is practically useful for purposes like correcting factual errors and censoring bigotry learned by a language model. So I view this area of research as one that will be active for the years to come.\n\nAnd the approach of finding topic relevant parameter networks by learning to erase subject-specific knowledge while preserving other knowledge appears rather novel and clever.\n\nLast, the experimental results demonstrate that the objectives optimized in the loss are achieved."
                },
                "weaknesses": {
                    "value": "While an interesting start, I feel as though the paper falls short of its promise. The big piece that feels missing from this paper is an analysis of the detected subnetworks. The experiments showed that the subnetworks typically consisted of between 1% and 2% of the network parameters. But which groups of parameters were they? And at which network layers? How distributed throughout the network were they? Did they consist of adjacent/localized blocks of parameters, or were they isolated and distributed? Was there any other sort of topological structure associated with these subnetworks?  And how might the masked regions be working to zero-out knowledge? These questions are not explored. (Moreover, in the appendix, the authors show that rerunning the knowledge erasure procedure from different random seeds finds alternative subnetworks that erase the same set of facts but that have with fairly little overlap with each other. This shows that the found critical subnetworks are not unique, so there is perhaps a bigger story to be told.)\n\nAnother question I felt wasn't sufficiently explored relates to the permanence of the knowledge erasure process. In particular, could a motivated individual recover the erased knowledge by using clever prompting or a fine-tuning process? That is to say, is the erased knowledge still in the network somewhere?\n\nLast, I found section 6.3's use of the term \"overfitting\" to be a bit confusing, since overfitting means that the loss on the training set is significantly less on the test set. But that's not what's being examined here. Instead, it seems like section 6.3 is devoted to sensitivity analysis, to see how robust the perplexity differences are to changes in the mask. But I found the region growing and shrinking approach used here to be unwarranted since, as mentioned above, no analysis is performed to determine whether the masks even have regional (contiguous) structure."
                },
                "questions": {
                    "value": "My main question is whether there is some analysis performed which reveals the nature of the found masks. Are they contiguous / network-like structures, or something else?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7241/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7241/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7241/Reviewer_cTTe"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7241/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698917299978,
            "cdate": 1698917299978,
            "tmdate": 1701042518772,
            "mdate": 1701042518772,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "L3grg9FGz6",
                "forum": "Mkdwvl3Y8L",
                "replyto": "D3mdIAcHAR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7241/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7241/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer cTTe (Part 1)"
                    },
                    "comment": {
                        "value": "We would like to thank reviewer cTTe for their insightful feedback. We thank the reviewer for emphasizing that very little is known about how pretrained language models represent knowledge. We also value their acknowledgement of the possible future applicability of our work in factual error correction. In addition to this comment, we also address the reviewer\u2019s questions on *cross-topic analysis of subnetwork structures* and *whether knowledge erasure is prompt-dependent* in the general message to all reviewers. We wrote the requested changes and clarifications in the paper in purple.\n\n> The experiments showed that the subnetworks typically consisted of between 1% and 2% of the network parameters. But which groups of parameters were they?\n\nTo address the question, we created new sections **Section 6.2** and **Appendix K** called \u201cStructural Analysis\u201d. While a more detailed analysis can be found in the revised paper, we summarize here our findings across three WordNet TargetKGs and three seeds:\n- Depth-wise: We have found that consistently the subnetwork is most dense around the first and final masked layers (in the case of GPT2-small, these would be layers 7 and 12).\n- Layer-type wise: \n    - For layer 7 and layer 12, we found that knowledge-critical subnetworks are most dense in the output layer of attention modules.\n    - However, in middle layers, the most dense layer types are the Feed-Forward networks, in particular, the first linear layer in each Feed-Forward network.\n- Contiguity/Locality/Distributedness: \n    - We have not found any complete columns or rows of weights that were dense in the critical subnetwork. This means that there are no input or output neuron features that get completely removed when the critical subnetwork is removed. Therefore the masked region may not be working to zero-out the knowledge by turning specific features off, which would counter the prevailing view that neuron-level changes are necessary for mechanistic interventions (Dai et al. 2022, Meng et al. 2022). \n    - However, in Figure 9, in the case of three WordNet TargetKGs and three seeds, regardless of the KG and seed configuration, we found that the 10th head in layer 7, and the 1st and 9th head in layer 12 are significantly less sparse. Therefore while the subnetworks are not overlapping according to the Intersection-over-Union metric, they tend to be dense in similar areas.\n\n> Was there any other topical structure associated with these subnetworks?\n\nAs mentioned in the general message to all reviewers, to address this inquiry, we created a new section in **Appendix J** called \u201cKnowledge-Based Analysis\u201d. We did the same experiments as Appendix I (originally H), where we calculated the Intersection-over-Union of the subnetworks across different layers and layer types for the same seed but different KGs (Fig. 7) and composed subnetworks for the same seed and different KGs (Table 18). \n\nWe had similar findings as **Appendix I**, where the Intersection-over-Union was overall low but most significant at the attention sublayer of the final transformer block. We also observed similar results for composing subnetworks. Therefore, it may be possible to combine subnetworks across seeds or KGs naively, however, they may not guarantee the maintenance criteria to the same extent.\n\n> Could a motivated individual recover the erased knowledge using clever prompting or a fine-tuning process? (i.e. the knowledge is still in the network)?\n\nWe provide performance on paraphrases in **Appendix H (originally Appendix G)** for three WordNet hypernym TargetKGs. We have found that the average perplexity differences are high on paraphrases of TargetKG, and the perplexity differences for ControlKG either are near 0 or are negative. We added a forward pointer to these results in our main body in Section 6.3, as it is also a robustness analysis.\n\nMoreover, we show in **Section 6.4** that removing a knowledge-critical subnetwork harms the ability to transfer the knowledge to a downstream task. We have changed Tables 5 and 15 to clearly show accuracy differences from the original model (rather than the actual accuracy result for each baseline). \n\nIf there were many explicit instances of the knowledge in the training set used to finetune the model, it\u2019s possible that fine-tuning the model after removing the knowledge-critical subnetwork could re-form a representation to recover the knowledge. However, we also note that in the case of blackbox systems, users often have no access to finetune the underlying model, so removing subnetworks may represent a promising method for dampening the model\u2019s knowledge of particular types of sequences."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7241/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740484934,
                "cdate": 1700740484934,
                "tmdate": 1700740484934,
                "mdate": 1700740484934,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]