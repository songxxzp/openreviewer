[
    {
        "title": "RetinexGAN Enables More Robust Low-Light Image Enhancement Via Retinex Decomposition Based Unsupervised Illumination Brightening"
    },
    {
        "review": {
            "id": "O2fgqDeepZ",
            "forum": "3SqnZXg24T",
            "replyto": "3SqnZXg24T",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission190/Reviewer_p4zt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission190/Reviewer_p4zt"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed a Retinex-decomposition-based generative adversarial network for low-light image enhancement, which is trained with unpaired samples. The experiments showed the superior performance of the proposed neural network over some recent approaches."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ Combination of GAN, Retinex model, and unpaired learning.\n+ Interpretability of the neural network architecture from due to the use Retinex model."
                },
                "weaknesses": {
                    "value": "- The compared methods in the expriements are somehow out of data. Only one compared method is published at or after 2022. This makes the experiemtns not convincing.\n- GAN, unpaired training, and Reintex model are widely studied and utillized in low-light enhancement. The papers lacks a detailed discussion with existing methods and ideed it seems that the proposed components have no big differences from the existing ones."
                },
                "questions": {
                    "value": "See the Weakeness part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No ethics review needed."
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission190/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698638057992,
            "cdate": 1698638057992,
            "tmdate": 1699635944868,
            "mdate": 1699635944868,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mp0XfD1b4R",
                "forum": "3SqnZXg24T",
                "replyto": "O2fgqDeepZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission190/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission190/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer p4zt"
                    },
                    "comment": {
                        "value": "We sincerely thank the reviewer for carefully reading our paper and pointing out our shortcomings. We have carefully incorporated them in the revised paper. In the following, your comments are first stated and then followed by our point-by-point responses.\n\n[Q1] The compared methods in the expriements are somehow out of data. Only one compared method is published at or after 2022. This makes the experiemtns not convincing.\n\n[A1] Thank you for pointing this problem. According to your suggestions, we have provided more qualitative results on the LOL dataset and except for that, we also show some visualization results on the LOL dataset that contains significant noise.More importantly, we include comparisons with many methods proposed in 2023 such as NeRCo (ICCV2023), CLIP-LIT (ICCV2023) and Neural Preset(CVPR2023).\n\n[Q2] GAN, unpaired training, and Reintex model are widely studied and utillized in low-light enhancement. The papers lacks a detailed discussion with existing methods and ideed it seems that the proposed components have no big differences from the existing ones.\n\n[A2] Thank you for pointing out this concern. There is a significant difference between the FPN illumination generator and self-attention mechanism in our work and other works. For self-attention mechanism, we first used the value channel in the HSV channel model and used exponential average pooling to obtain the self attention map, which allows the model to focus more on modifying the darker areas in the map and enable it to be applied in more flexible and diverse scenarios. For FPN network, we have adopted the basic architecture of FPN network and applied it to adjust the illumination map of low-light images for the first time. Specifically, we have designed a switchable pretrained backbones for the downsampling part of the FPN based illumination map adjustment network. Users can choose between the timeliness and performance of the model according to their actual needs. At the same time, in order to accelerate model convergence, we have designed a self-attention weighted global residual connection for the FPN network. These designs make our model very different from other models, That is where the innovation of this study lies."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission190/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700496743169,
                "cdate": 1700496743169,
                "tmdate": 1700496743169,
                "mdate": 1700496743169,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "jbD778Ezou",
            "forum": "3SqnZXg24T",
            "replyto": "3SqnZXg24T",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission190/Reviewer_TqR9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission190/Reviewer_TqR9"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a semi-supervised illumination brightening framework for low-light image enhancement. A lightweight CNN model is used to achieve Retinex decomposition, and then a feature pyramid network is employed to brighten the illumination maps in a unsupervised manner. The proposed method has been evaluated on several datasets, and improved results have been achieved."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "* The paper is easy to follow.\n* The proposed framework achieves improved performances on both synthetic and real-world low light images."
                },
                "weaknesses": {
                    "value": "* My main concern about this paper is its limited novelty and technical contribution. The adopted FPN network and the spatial attention mechanism are very common strategies in many research fields.\n* For the experimental results, although improved qualitative results have been obtained, the visual results in Fig.1(a), Fig.6 and Fig.7 still look poor. For better comparisons, can the authors provide more comparison results with ground truth as a reference? For downstream applications, it may be more intuitive to use P-R curves for comparisons (as Zero-DCE).\n* The paper\u2019s readability is poor. A lot of technical details are missing. The writing should be improved for a better review.\n* The literature survey should be more elaborate. Several newly published works are not discussed, especially the supervised methods."
                },
                "questions": {
                    "value": "Other issue:\n* The abbreviation \"RetinexGAN\" has been used in \"Ma et al., RetinexGAN: Unsupervised low-light enhancement with two-layer convolutional decomposition networks, IEEE Access\"."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission190/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission190/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission190/Reviewer_TqR9"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission190/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698658358854,
            "cdate": 1698658358854,
            "tmdate": 1699635944786,
            "mdate": 1699635944786,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZtHh18T6f0",
                "forum": "3SqnZXg24T",
                "replyto": "jbD778Ezou",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission190/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission190/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer TqR9"
                    },
                    "comment": {
                        "value": "We sincerely thank the reviewer for carefully reading our paper and pointing out our shortcomings. We have carefully incorporated them in the revised paper. In the following, your comments are first stated and then followed by our point-by-point responses.\n\n[Q1] My main concern about this paper is its limited novelty and technical contribution. The adopted FPN network and the spatial attention mechanism are very common strategies in many research fields.\n\n[A1] Thank you for pointing out this concern. There is a significant difference between the FPN illumination generator and self-attention mechanism in our work and other works. For self-attention mechanism, we first used the value channel in the HSV channel model and used exponential average pooling to obtain the self attention map, which allows the model to focus more on modifying the darker areas in the map and enable it to be applied in more flexible and diverse scenarios. For FPN network, we have adopted the basic architecture of FPN network and applied it to adjust the illumination map of low-light images for the first time. Specifically, we have designed a switchable pretrained backbones for the downsampling part of the FPN based illumination map adjustment network. Users can choose between the timeliness and performance of the model according to their actual needs. At the same time, in order to accelerate model convergence, we have designed a self-attention weighted global residual connection for the FPN network. These designs make our model very different from other models, That is where the innovation of this study lies. \n\n[Q2] For the experimental results, although improved qualitative results have been obtained, the visual results in Fig.1(a), Fig.6 and Fig.7 still look poor. For better comparisons, can the authors provide more comparison results with ground truth as a reference? For downstream applications, it may be more intuitive to use P-R curves for comparisons (as Zero-DCE).\n\n[A2] Thank you for pointing out this concern. Since we did not optimize the model to the best during hyperparameter tuning, the enhanced version of low-light images exhibit evident color shifts and artifacts. We have readjusted the hyperparameters of our enhancement model to improve the performance and eliminate color deviation and artifacts in the enhanced images. According to your suggestions, we have provided more comparison results with ground truth as a reference and use P-R curves to illustrate the application in dark face detection in the revised manuscript.\n\n[Q3]The paper\u2019s readability is poor. A lot of technical details are missing. The writing should be improved for a better review.\n\n[A3] Thank you for pointing out this concern. We have improved the writing of this paper and improved its readability.\n\n[Q4]The literature survey should be more elaborate. Several newly published works are not discussed, especially the supervised methods.\n\n[A4] Thank you for pointing out this concern. We have revised the writing of literature survey of this paper and disscussed more supervised methods.\n\n[Q5]The abbreviation \"RetinexGAN\" has been used in \"Ma et al., RetinexGAN: Unsupervised low-light enhancement with two-layer convolutional decomposition networks, IEEE Access\".\n\n[A5] Thank you for pointing out this problem. We have renamed our method."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission190/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700496277970,
                "cdate": 1700496277970,
                "tmdate": 1700496376597,
                "mdate": 1700496376597,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "nOcwxFEDxt",
            "forum": "3SqnZXg24T",
            "replyto": "3SqnZXg24T",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission190/Reviewer_tFmg"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission190/Reviewer_tFmg"
            ],
            "content": {
                "summary": {
                    "value": "The work introduces a decomposition network based on the Retinex theory. Subsequently, it incorporates a Generative Adversarial Learning strategy by constructing an illumination generation network based on FPN to further enhance low-light images captured in unknown scenarios. A series of related experiments demonstrate the superiority of the proposed method and the effectiveness of the various modules and constraints designed."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The approach of building an illumination enhancement network by introducing FPN is quite intriguing. The overall framework's process and structural details are described clearly, and the overall presentation is commendable."
                },
                "weaknesses": {
                    "value": "1. Unclear Motivation: The motivations behind the various components in the overall framework constructed by the author seem to lack clear explanations. For instance, the initial intention of decomposition followed by enhancement, the benefits of introducing FPN, and the reasons for employing different training strategies at different stages, among other aspects, are not adequately addressed. Unfortunately, the author appears to have not provided relevant analyses for these issues. Furthermore, it is suggested that the author should provide additional evidence in their response to support their claims.\n2. Lack of Novelty: Whether it's the decomposition network based on Retinex, generative adversarial networks, attention mechanisms, or the range of introduced loss functions, these are common approaches for addressing low-light image enhancement problems. Additionally, while the idea of introducing FPN is promising, the lack of a clear explanation by the author impacts the inevitability of the contribution's novelty. In other words, this work appears more like a combination of existing effective techniques, leaving room for increased novelty.\n3. Unconvincing Experimental Results: Most of the visual results presented in the manuscript exhibit evident color shifts, and some even contain artifacts. In comparison to other methods, the superiority of the proposed approach in terms of qualitative results is hard to establish.\n4. Need for Improvement in Experimental Settings and Presentation: From the manuscript, it can be seen that the author conducted a series of comparative experiments on the LOL dataset, but it seems that no qualitative results are provided. I am curious about the performance of the proposed method on data from the LOL dataset that contains significant noise. Furthermore, it appears that no comparisons were made with low-light image enhancement methods proposed in 2023. As far as I am aware, there have been many recent representative advances in this field, and it is hoped that the author can include comparisons with them to more comprehensively validate the effectiveness of the proposed method.\n\nOverall, this work requires significant improvement in several aspects. The ablation experiments section also suffers from a lack of comprehensiveness. It is hoped that the author can provide sufficiently detailed responses to the above-mentioned issues."
                },
                "questions": {
                    "value": "Please refer to Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission190/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698758020083,
            "cdate": 1698758020083,
            "tmdate": 1699635944702,
            "mdate": 1699635944702,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8PHJuChlkK",
                "forum": "3SqnZXg24T",
                "replyto": "nOcwxFEDxt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission190/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission190/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer tFmg"
                    },
                    "comment": {
                        "value": "We sincerely thank the reviewer for the time reading our paper. We have carefully incorporated them in the revised paper. In the following, your comments are first stated and then followed by our point-by-point responses.\n\n[Q1] Unclear Motivation: The motivations behind the various components in the overall framework constructed by the author seem to lack clear explanations. For instance, the initial intention of decomposition followed by enhancement, the benefits of introducing FPN, and the reasons for employing different training strategies at different stages, among other aspects, are not adequately addressed. Unfortunately, the author appears to have not provided relevant analyses for these issues. Furthermore, it is suggested that the author should provide additional evidence in their response to support their claims.\n\n[A1] Thank you for pointing out these concerns. First, the initial intention of decomposition is to remove the influence of environmental illumination on imaging, obtain reflectance components that are not dependent on the external environment. Then, by adjusting the illumination maps and recombining the illumination and reflectance maps, the enhanced image is obtained. Second, through feature propagation and fusion, FPN can combine high-level semantic information with low-level detail information, enabling the network to simultaneously obtain rich semantic and detail information during illuminance map restoration, thereby improving the robustness and generalization ability of illuminance map restoration. We provide algorithm pseudocode in the appendix to demonstrate the training logic of the model in detail. According to your suggestions, we have provided relevant analyses in the revised manuscript.\n\n[Q2] Lack of Novelty: Whether it's the decomposition network based on Retinex, generative adversarial networks, attention mechanisms, or the range of introduced loss functions, these are common approaches for addressing low-light image enhancement problems. Additionally, while the idea of introducing FPN is promising, the lack of a clear explanation by the author impacts the inevitability of the contribution's novelty. In other words, this work appears more like a combination of existing effective techniques, leaving room for increased novelty.\n\n[A2] Actually, our research is certainly not a combination of existing effective techniques. You mention that Retinex theory, generative adversarial networks, attention mechanisms and even designed loss functions are common. However, our data-driven Retinex decomposition is realized through some newly proposed learning constraints in section 2.2. There is a significant difference between the self-attention map calculation in our work and other works. We first used the value channel in the HSV channel model and used exponential average pooling to obtain the self attention map, which allows the model to focus more on modifying the darker areas in the map and enable it to be applied in more flexible and diverse scenarios. Accordingly, we specially use the cosine similarity function to design a new loss term (attention loss) for FPN and we have conducted an ablation study on it.\n\n[Q3] Unconvincing Experimental Results: Most of the visual results presented in the manuscript exhibit evident color shifts, and some even contain artifacts. In comparison to other methods, the superiority of the proposed approach in terms of qualitative results is hard to establish.\n\n[A3] Thank you a lot for pointing this problem. Since we did not optimize the model to the best during hyperparameter tuning, the enhanced version of low-light images exhibit evident color shifts and artifacts. We have readjusted the hyperparameters of our enhancement model to improve the performance and eliminate color deviation and artifacts in the enhanced images. All experimental parameter corrections are highlighted in blue in the main text.\n\n[Q4] Need for Improvement in Experimental Settings and Presentation: From the manuscript, it can be seen that the author conducted a series of comparative experiments on the LOL dataset, but it seems that no qualitative results are provided. I am curious about the performance of the proposed method on data from the LOL dataset that contains significant noise. Furthermore, it appears that no comparisons were made with low-light image enhancement methods proposed in 2023. \n\n[A4] Thank you for pointing this problem. According to your suggestions, we have provided more qualitative results on the LOL dataset and except for that, we also show some visualization results on the LOL dataset that contains significant noise.More importantly, we include comparisons with many methods proposed in 2023 such as NeRCo (ICCV2023), CLIP-LIT (ICCV2023) and Neural Preset(CVPR2023)."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission190/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700496117625,
                "cdate": 1700496117625,
                "tmdate": 1700496117625,
                "mdate": 1700496117625,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rhjJPTccKR",
            "forum": "3SqnZXg24T",
            "replyto": "3SqnZXg24T",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission190/Reviewer_6g5x"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission190/Reviewer_6g5x"
            ],
            "content": {
                "summary": {
                    "value": "The research direction of this article is low-light image enhancement, which mainly solves the image degradation problem through Retinex decomposition theory and FPN-based attention mechanism. The contribution of the article is to simultaneously provide flexibility in low-light image enhancement by leveraging lightweight cellular neural networks for data-driven Retinex decomposition and leveraging FPN with different types of pre-trained backbones for downsampling in illumination generation."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The main purpose of this article is to propose a flexible framework for enhancing low-light images, which has practical applications.\n2. Motivation of this paper is clear and the main idea is easy to understand."
                },
                "weaknesses": {
                    "value": "1. The author did mention that the work aims to find a balance between efficiency and performance, but the main body of the text primarily focuses on the analysis of performance. Furthermore, based on the experimental results regarding computational efficiency in the appendix, it seems that the proposed method may not have achieved a sufficiently prominent advantage in terms of efficiency.\n2. In the second section of the method introduction, the author dedicates a significant amount of space to explaining specific network structures and the various constraints introduced, without providing an explanation for the reasons. In other words, the motivations for the various components in the proposed framework may require additional clarification from the author.\n3. Compared to other methods, the results shown in Figure 1, Figure 7, and Figure 11 do not appear to be the best. In Figure 5, there are even instances of artifacts. It is suggested that the authors provide an explanation for the phenomena mentioned above.\n4. In the ablation experiment section, the author only analyzed the loss function. To further validate the effectiveness of the constructed framework, it is recommended that the author include ablation experiment results for each component of the framework in the manuscript."
                },
                "questions": {
                    "value": "The relevant questions have been raised in the weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission190/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698759531094,
            "cdate": 1698759531094,
            "tmdate": 1699635944628,
            "mdate": 1699635944628,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tENMBbvbOF",
                "forum": "3SqnZXg24T",
                "replyto": "rhjJPTccKR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission190/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission190/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 6g5x"
                    },
                    "comment": {
                        "value": "Thank you for your constructive comments and suggestions, and they are exceedingly helpful for us to improve our paper. We have carefully incorporated them in the revised paper. In the following, your comments are first stated and then followed by our point-by-point responses.\n\n[Q1] The author did mention that the work aims to find a balance between efficiency and performance, but the main body of the text primarily focuses on the analysis of performance. Furthermore, based on the experimental results regarding computational efficiency in the appendix, it seems that the proposed method may not have achieved a sufficiently prominent advantage in terms of efficiency.\n\n[A1] Thanks very much for pointing out these two important problems of our paper.  First, we show the model performance and model parameter size in Figure 1. And in appendix, we also exhibit the inference time of our model and other state-of-the-art algorithms to show that our work aims to find a balance between efficiency and performance. According to your comments, we have spent more space in the revised manuscript to analyze the advantages of this method in balancing image enhancement efficiency and performance. Second, you said that the proposed method may not have achieved a sufficiently prominent advantage in terms of efficiency. Actually, according to Table 3 in Appendix, our model achieves the second best performance in terms of inference time. However, ZeroDCE++ with the best inference time is significantly weaker than this method in terms of model performance. Our method achieve the best enhancement performance with the second fastest inference time, so we conclude that this method can navigate a balance between performance and efficiency.\n\n[Q2] In the second section of the method introduction, the author dedicates a significant amount of space to explaining specific network structures and the various constraints introduced, without providing an explanation for the reasons. In other words, the motivations for the various components in the proposed framework may require additional clarification from the author.\n\n[A2] Thanks for your constructive comments. We have further elaborated and explained the various components, loss terms and constraints in network training.\n\n[Q3] Compared to other methods, the results shown in Figure 1, Figure 7, and Figure 11 do not appear to be the best. In Figure 5, there are even instances of artifacts. It is suggested that the authors provide an explanation for the phenomena mentioned above.\n\n[A3] Thanks for pointing out this concern. We are very sorry for the presentation of poor enhancement results in the paper due to our failure to optimize the model to the best during hyperparameter tuning. But after adjusting the hyperparameters and network structure parameters, we have achieved the best enhancement effect. All experimental parameter corrections are highlighted in blue in the main text. \n\n[Q4] In the ablation experiment section, the author only analyzed the loss function. To further validate the effectiveness of the constructed framework, it is recommended that the author include ablation experiment results for each component of the framework in the manuscript.\n\n[A4] In the ablation study, we did not only analyze the components of the loss function, but also conducted ablation experiments on the attention mechanism in FPN and the downsampling pretraining backbones in FPN. According to your suggestion, we have conducted supplementary ablation experimental analysis on the number of ResBlocks in the decomposition network."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission190/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700495812189,
                "cdate": 1700495812189,
                "tmdate": 1700495812189,
                "mdate": 1700495812189,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]