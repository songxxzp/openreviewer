[
    {
        "title": "DASFormer: Self-supervised Pretraining for Earthquake Monitoring"
    },
    {
        "review": {
            "id": "0pMuCV4Fnf",
            "forum": "7ipjMIHVJt",
            "replyto": "7ipjMIHVJt",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6627/Reviewer_gsBc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6627/Reviewer_gsBc"
            ],
            "content": {
                "summary": {
                    "value": "The authors present a new self-supervised learning model for the task of earthquake monitoring given Distributed Acoustic Sensing (DAS) data. Specifically, the authors specify the evaluation as an anomaly detection task, where the DASFormer outperforms a wide range of various supervised models for detecting seismic phases. The details and motivation of the construction of the DASFormer, with the accompanying figure, are clear. The study adds to the existing literature of demonstrating the opportunities that DAS data has to offer."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is clearly written and has a good structure that makes the paper nice to read. Enough details are given to understand the introduced DASFormer and the experimental setup. The evaluation on the seismic phase detection task includes an extensive range of supervised Deep Learning approaches, as well as a traditional baseline. On the downstream tasks the introduced SSL method shows significant improvement across metrics compared to the supervised methods."
                },
                "weaknesses": {
                    "value": "Training Regime:\n\n- The laborious objective function came a bit surprised and is the part that could benefit from an inclusion in the figure\n\nEvaluation Scheme:\n\nThe main weakness I see in the paper, as I aim to layout below, is whether the selected methods DASFormer is compared to, are reasonable, or whether there could be other baselines that would perform stronger than the selected ones (even though they are regarded as SOTA)\n\n- I understand your main claim of the paper to be that your choice of architecture and training scheme can achieve superior results to existing Deep learning Models. However, your evaluation scheme is mainly demonstrating the usefulness of SSL pretraining using a lot more data than the other supervised methods have available. Thus, to me the more relevant question is why is your extensive pretraining technique necessary as opposed to \"more standard\" SSL methods in Computer Vision like MAE, Moco etc. In other words you should compare your SSL technique to another SSL technique to support the claim that it is necessary and superior. Therefore, I would be highly interested in a \"baseline\" SSL technique that you can compare the DASFormer results to. I would believe that this could potentially also give more insights into the unique aspects of DAS data. Additionally, you could evaluate the quality of extracted features from different SSL methods via Linear Probing\n- ignoring the DASFormer approach for a second, your results table shows that the \"traditional\" aggregation baseline \"aggregation-0\" is actually really strong, on par with or better than all the Deep Learning models, doesn't this illustrate that there could be potentially some other, much simpler modelling approach to achieve good results?\n- There is some literature, for example [Makridakis et al 2020](https://www.tandfonline.com/doi/full/10.1080/01605682.2022.2118629) and [Nixtla](https://github.com/Nixtla/statsforecast/tree/main/experiments/m3), showing that simple models outperform Deep Learning methods on time-series tasks, so I wonder what results you would get with a Random Forest for example, that could also offer more insights into \"explaining\" a model prediction\n- The authors point out several times that it is not appropriate to train models with the standard point-wise loss. However, this point-wise loss is applied in all the baseline models that the DASFormer is compared to, so shouldn't there be a comparison to a baseline that does not have this weakness?\n\nGeneral Comment:\n\n- Given the crucial task of earthquake monitoring and the author's acknowledgement that \"DAS data includes various stochastic noise, such as environmental and instrumental noise\", I was very surprised to not find the word \"uncertainty\" or a discussion thereof anywhere in the paper. Uncertainty is of course not a trivial topic, especially with Deep Learning models that are so over parameterized, nevertheless there should be an effort to at least discuss its influences and impacts."
                },
                "questions": {
                    "value": "Content:\n- Under 5.1\"Implementation Details\" you state that the anomaly score is defined between the predicted model values and the actual values. How does your approach work in a \"real\" setting then when you are forecasting into regions without any data? Or is it enough due to the time-scale of seconds to detect an anomaly \"in hindsight\"? This was not entirely clear to me.\n- Are there advantages/disadvantages of the selected anomaly score distance metrics that you could discuss? \n\nWriting:\n- First sentence of section 3, I think you mean \"also known as\" instead of \"as known as\""
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6627/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6627/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6627/Reviewer_gsBc"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6627/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698592906221,
            "cdate": 1698592906221,
            "tmdate": 1699636756696,
            "mdate": 1699636756696,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YxUIq7NA6Y",
                "forum": "7ipjMIHVJt",
                "replyto": "0pMuCV4Fnf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6627/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6627/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1:** The evaluation scheme mainly demonstrates the usefulness of SSL pretraining with a large amount of data, but it is unclear why the extensive pretraining technique is necessary compared to more standard SSL methods in CV.\n\n**A1:** Thanks for your valuable suggestion. We have indeed considered representing DAS data as images, but drawing an analogy between DAS data and images can also be misleading. Image data does not inherently consider the causal information along the time axis that is present in DAS data. Adapting image-based methods to a causal-related forecasting-based approach would require additional design considerations. We will explore the possibilities like adapting ViT-based image methods in the future.\n\n---\n\n**Q2:** The comparison table shows that the \"traditional\" aggregation baseline performs on par with or better than the deep learning models, suggesting the potential for simpler modeling approaches. There is literature showing that simple models can outperform deep learning methods on time-series tasks like Random Forest.\n\n**A2:** Thanks for pointing out this. Aggregation-0 in Table 1 is a variant of well-known traditional method \"STA/LTA\" for DAS data. \n\nThe traditional time-series methods like Random Forest and ARIMA-family are not applicable to our task, as they are designed for stationary time series. However, DAS data is characterized by dynamic and evolving patterns, making it challenging to model using traditional stationary time series methods\n\n---\n\n**Q3:** The paper does not include a comparison to a baseline that does not use the point-wise loss, despite mentioning its weakness in the baseline models.\n\n**A3:** Thanks for pointing out this. To alleviate the drawback of point-wise loss, DASFormer utilizes an extra pretrained VGG-based on intermediate features (it's a features-to-features autoencoder, not on the final predictions) in DASFormer to extract the high-level features, and use the feature-wise loss as the metric. This feature extractor is not universal for other methods, so we have to design feature extractors/encoders to suit the specific architecture and characteristics of each baseline model. Therefore, we only use the point-wise loss for other baselines.\n\n---\n\n**Q4:** The paper lacks a discussion of uncertainty, which is important for earthquake monitoring given the stochastic noise in DAS data.\n\n**A4:** Thanks for your suggestion. We show the confidence intervals of the results in Table 4 in Appendix, where we can observe that the results are stable and reliable with small variance. Due to the limitations of time and computation, we will explore and add more uncertainty analysis in the future work. \n\nWe also conduct comparison experiments for different magnitude (different noise levels) of earthquakes. The results are shown in the following tables:\n\nDistribution of the magnitude of the 45 earthquakes in the training set:\n\n| Magnitude | Numbers |\n|-----------|---------|\n| M0 ~ M1   | 0       |\n| M1 ~ M2   | 0       |\n| M2 ~ M3   | 31      |\n| M3 ~ M4   | 12      |\n| M4 ~ M5   | 2       |\n\nDistribution of the magnitude of the 45 earthquakes in the evaluation set and the performance:\n\n|DASFormer          |         | AE   |      | EMD  |      | sliced EMD |      |\n|-----------|---------|------|------|------|------|------------|------|\n| Magnitude | Numbers | AUC  | F1   | AUC  | F1   | AUC        | F1   |\n| M0 ~ M1   | 0       | N/A  | N/A  | N/A  | N/A  | N/A        | N/A  |\n| M1 ~ M2   | 1       | N/A  | N/A  | N/A  | N/A  | N/A        | N/A  |\n| M2 ~ M3   | 27      | 0.84 | 0.4  | 0.88 | 0.46 | 0.86       | 0.42 |\n| M3 ~ M4   | 14      | 0.89 | 0.59 | 0.92 | 0.58 | 0.93       | 0.6  |\n| M4 ~ M5   | 3       | N/A  | N/A  | N/A  | N/A  | N/A        | N/A  |\n\n|Aggregation-0 |         | AE   |      | EMD  |      | sliced EMD |      |\n|-----------|---------|------|------|------|------|------------|------|\n| Magnitude | Numbers | AUC  | F1   | AUC  | F1   | AUC        | F1   |\n| M0 ~ M1   | 0       | N/A  | N/A  | N/A  | N/A  | N/A        | N/A  |\n| M1 ~ M2   | 1       | N/A  | N/A  | N/A  | N/A  | N/A        | N/A  |\n| M2 ~ M3   | 27      | 0.74 | 0.24 | 0.7  | 0.28 | 0.7        | 0.25 |\n| M3 ~ M4   | 14      | 0.73 | 0.24 | 0.69 | 0.26 | 0.7        | 0.25 |\n| M4 ~ M5   | 3       | N/A  | N/A  | N/A  | N/A  | N/A        | N/A  |\n\n\nFor the earthquakes in the range of M2 ~ M3 and M3 ~ M4, we can see that the performance is becoming better for larger magnitude earthquakes. In each level, the performance of DASFormer is better than Aggregation-0. For the earthquakes in the range of M0 ~ M2 and M4 ~ M5, the number of samples is too small to draw a conclusion."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6627/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700738569252,
                "cdate": 1700738569252,
                "tmdate": 1700738569252,
                "mdate": 1700738569252,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "05NAb3fdBC",
            "forum": "7ipjMIHVJt",
            "replyto": "7ipjMIHVJt",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6627/Reviewer_Hht1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6627/Reviewer_Hht1"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a foundation model for DAS data (optic fiber), used in particular for earthquake detection. The specificities of the data (noise, time dependence, spatial dependence) are well studied in order to propose a specific fondation model; based on Swin-Unet, convolutional U-net and GAN-strategy. For the self-supervision, a masking strategy is applied. Comparisons with forecasting multi-variate time series and anomaly detection methods are performed."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is correctly written, the method is interesting (even though very complex) and the forecasting results are convincing. But I have several major concerns that needs to be clarifed first."
                },
                "weaknesses": {
                    "value": "1) The first concern is the goal of the paper. Indeed, DAS earthquake detectors exists (one of them was cited by the autors, PhaseNet-Das, Zhu et al. 2023, there might be others), and no comparison was made, nor a justification on the benefit of your method against theirs. If the claim is to say that this is a foundation model, and the test on this task is only as a proof of concept, it should be clearer, and then show or justify a future useful application.\n2) I think the purpose of a foundation model would be its applicability at a larger scale. Yet, is your method generalizable to other DAS sensors? It is not clear whether it is site and sensor-specific or not; if so it means a new self-training needs to be performed again for any new DAS.\n3) The whole idea of this method is that earthquakes are unpredictible. It is clever indeed, but I see 2 major limitations: 1) this foundation model is thus harder to use for other tasks (which could be predictable) 2) in a series of aftershocks (which could maybe be seen as more predictable), how does your measure performs? \n4) The comparison with other multi-variate time series are somehow misleading. Indeed, in multi-variate time-series, we suppose that the different time series (or sensors) are not ordered and not equally-spaced: DAS is a very particular type of 'multi-variate time-series'. I don't think it is worth presenting all of these methods (maybe only one), and it should be clearly stated in the paper. Yet, a comparison with image 2D foundation models, or by modifying a video framework from a 2D+t to a 1D+t, would be more relevant."
                },
                "questions": {
                    "value": "Other questions:\n\nQ1) Masking: the authors said that it is inspired by BERT, but maybe closer to this application, by self-supervised on image data? like Pathak, Deepak, et al. \"Context encoders: Feature learning by inpainting.\" CVPR 2016.(and later works with ViTs)\nQ2) I don't understand the dynamic masking, and I don't see why it is useful. Does it comes from other studies?\nQ3) The ablation study should first be 'ablation': i.e. what if we only use the fine generator, or the fine coarse? What if we only use a 'generator' without the need of the discriminator? Also, why is the fine generator a convolutional U-net, and the coarse a Swin-based Unet?\nQ4) comparison with PhaseNet is rather unclear. First, it is stated that the table 1 shows comparisons with time series forecasting and anomaly detection, but PhaseNet is neither of those, and is only single-station. In the table, it is unclear the use of 'traditional method', and the 'aggregation'. Would have been best to compare with PhaseNet-DAS, no?\n\n- Figure 1 left: sensors and time axes not clear.\n- page 2 : define P and S\n- Figure 2: what is smm?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6627/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698670838720,
            "cdate": 1698670838720,
            "tmdate": 1699636756563,
            "mdate": 1699636756563,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5QVN2qg6pN",
                "forum": "7ipjMIHVJt",
                "replyto": "05NAb3fdBC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6627/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6627/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1:** Lacks a comparison with other DAS earthquake detectors like PhaseNet-DAS.\n\n**A1:** To the best of our knowledge, the existing DAS earthquake detectors like PhaseNet-DAS are for P/S phase pickup tasks, which are different from seismic detection tasks we did. Please refer to the Answer to A6.\n\nP/S phase pickup refers to the identification and classification of seismic wave phases, specifically the arrival times of the P (primary) and S (secondary) waves, which focuses on accurately detecting and labeling these specific phases point-wise in DAS data.  On the other hand, seismic detection task (in Table 1) involves identifying and classifying anomalies or abnormal patterns in DAS data. The main differences between P/S phase pickup and seismic detection tasks can be summarized in the following aspects: \n\n(1) **Wave identification**: In P/S phase pickup, the method needs to accurately distinguish between P and S waves in seismic data. But seismic detection tasks do not require this specific wave identification, only with earthquake events. Most of the existing P/S phase pickup methods like PhaseNet-DAS learn on the context of P/S phases, while our method is a forecasting-based method which is easier and more suitable for real-time systems.\n\n(2) **Data representation**: P/S phase pickup typically provides point-wise results, indicating the exact arrival times of P and S waves. In contrast, seismic detection tasks focus on determining whether there is an event or anomaly within a specific time span, without the need for precise point-wise results. Moreover, our training/valid/testing splits are different from PhaseNet/PhaseNet-DAS.\n\n(3) **Learning setting**: P/S phase pickup methods are typically implemented in a supervised learning setting, where labeled data with ground-truth P/S wave information is required for training. However, our seismic detection task is addressed in an unsupervised learning setting like anomaly detection, as obtaining labeled data for anomalies can be challenging.\n\nAs a self-supervised learning model, DASFomer can be adapted to the P/S phase pickup tasks and we've done some preliminary experiments shown in the paper. However, considering the above points and the limited ground-truth annotations of P/S phases of our data, we hardly find a fair evaluation metric to compare with PhaseNet-DAS. We will explore more in the future work.\n\n---\n\n**Q2:** The generalizability of the method to other DAS sensors is not addressed, and it is unclear if the self-training needs to be performed again for different DAS setups.\n\n**A2:** Our method is applicable to any other DAS site. In the preprocessing stage, we downsample and resize the DAS data to match the resolution required by the model. By downsampling the data to the same resolution, our method can be easily transferred and applied to new DAS sensors. This approach is similar to computer vision models trained on ImageNet, where they are designed to be applicable to various image resolutions. \n\n---\n\n**Q3:** The method's suitability for other tasks and its performance in predictable scenarios, such as aftershocks, is not discussed.\n\n**A3:**  The effectiveness of our model for unpredictable earthquakes is derived from its good capabilities for other predictable events.\n\nIn this work, we primarily showcase the usage of DASFormer as a forecasting-based earthquake monitor. For tasks that are predictable, we can remove the masking and directly employ DASFormer as a feature extractor. We demonstrate its capability as a feature extractor in detecting malfunctioning sensors in Figure 4. Additionally, Figure 3 also illustrates its ability to detect predictable events such as traffic signals.\n\nRegarding your concern about the assumption that \"earthquakes are unpredictable\" may potentially confuse the model, it is important to note that our look-back window is only around 13 seconds, with a prediction window of approximately 1 second. At this time scale, the level of predictability is nearly indistinguishable for relatively predictable events like aftershocks. Thus, we can treat each aftershock as a separate earthquake event, considering them as individual instances rather than relying on their predictability."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6627/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700738511167,
                "cdate": 1700738511167,
                "tmdate": 1700738511167,
                "mdate": 1700738511167,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "L0ntUSYvcU",
            "forum": "7ipjMIHVJt",
            "replyto": "7ipjMIHVJt",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6627/Reviewer_RSrX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6627/Reviewer_RSrX"
            ],
            "content": {
                "summary": {
                    "value": "Authors apply self-supervised learning to Distributed acoustic sensing (DAS) data to learn representations that are suitable for several downstream tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "**Originality.** While the application to DAS data might be original, the paper is essentially an application of self-supervised learning to a new domain.\n\n**Quality and clarity.** The paper is well-written and easy to follow.\n\n**Significance.** Results seem to be promising, lacks comprehensive sensitivity analysis to be a viable real-world solution."
                },
                "weaknesses": {
                    "value": "* While the approach seems to outperform several baselines, the visual inspection of the forecasting results in the appendix is underwhelming.\n\n* Detection becomes more important and challenging for smaller earthquakes. It is unclear how the method performs for smaller earthquakes and whether there are many false positives.\n\n* I found this paper to be too focused on the application and not enough on the method. I feel there are not enough methodological novelties to make it a suitable choice for this conference."
                },
                "questions": {
                    "value": "* It would be beneficial to conduct a sensitivity analysis of the method concerning the choice of hyperparameters, especially since this is a real-world application. As authors have indicated, this application is associated with hazards to public safety so quantifying the uncertainty of the method is crucial.\n\n* What is the distribution (histogram) of the metric as a function of earthquake magnitude? How does it compare to the baseline? How about traditional signal processing techniques?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6627/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6627/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6627/Reviewer_RSrX"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6627/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698793591521,
            "cdate": 1698793591521,
            "tmdate": 1699636756433,
            "mdate": 1699636756433,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "QVQfspvWLi",
                "forum": "7ipjMIHVJt",
                "replyto": "L0ntUSYvcU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6627/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6627/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1:**  It is unclear how the method performs for smaller earthquakes and whether there are many false positives.\n\n**A1:** For performance on smaller earthquakes, we visualized several cases ranging from M2.0 to M3.66 in Figure 9 in Appendix. And we show the performance for different magnitudes in answer **A3**. The false positive rate (FPR) and true positive rate (TPR) for DASFormer are shown as follows:\n\n|     | AE   | EMD  | sliced EMD |\n|-----|------|------|------------|\n| FPR | 0.22 | 0.24 | 0.19       |\n| TPR | 0.79 | 0.82 | 0.81       |\n\n---\n\n**Q2:** It would be beneficial to conduct a sensitivity analysis of the method concerning the choice of hyperparameters since this application is associated with hazards to public safety\n\n**A2:** Thanks for your suggestion. We have the results with confidence intervals in Table 4 in Appendix. Actually we didn't careflly tune these hyperparameters due to the time and computation limitation. The training time of DASFormer is about 3~4 days on 4 NVIDIA RTX A5000 GPUs. We list all the 7 hyperparameters and the empirical setup in Table 7 in Appendix, where we think only $\\alpha$ and $\\beta$ are sensitive to the performance. For the resolution $V$ and $L$, they are larger is better, and are set to $128$ which is the maximum under our computation. For the number of heads $h$, it is empirically set as in multi-head attention mechanism. For the dimension of kernels $K$, it is less is better, and $2$ is the minimum value that we can use. For $\\alpha$ and $\\beta$, they are the trade-off between the reconstruction loss and the normalization tricks, which are empirically set to $1$ and $0.1$.  We will conduct a sensitivity analysis of the method concerning the choice of hyperparameters once we have the results in the future. Thanks!\n\n---\n\n**Q3:** What is the distribution (histogram) of the metric as a function of earthquake magnitude? How does it compare to the baseline? How about traditional signal processing techniques?\n\n**A3:** We provide the magnitude distribution of our datasets with performance here:\n\nDistribution of the magnitude of the 45 earthquakes in the training set:\n\n| Magnitude | Numbers |\n|-----------|---------|\n| M0 ~ M1   | 0       |\n| M1 ~ M2   | 0       |\n| M2 ~ M3   | 31      |\n| M3 ~ M4   | 12      |\n| M4 ~ M5   | 2       |\n\nDistribution of the magnitude of the 45 earthquakes in the evaluation set and the performance on DASFormer and Aggregation-0(STA/LTA baseline):\n\n|DASFormer          |         | AE   |      | EMD  |      | sliced EMD |      |\n|-----------|---------|------|------|------|------|------------|------|\n| Magnitude | Numbers | AUC  | F1   | AUC  | F1   | AUC        | F1   |\n| M0 ~ M1   | 0       | N/A  | N/A  | N/A  | N/A  | N/A        | N/A  |\n| M1 ~ M2   | 1       | N/A  | N/A  | N/A  | N/A  | N/A        | N/A  |\n| M2 ~ M3   | 27      | 0.84 | 0.4  | 0.88 | 0.46 | 0.86       | 0.42 |\n| M3 ~ M4   | 14      | 0.89 | 0.59 | 0.92 | 0.58 | 0.93       | 0.6  |\n| M4 ~ M5   | 3       | N/A  | N/A  | N/A  | N/A  | N/A        | N/A  |\n\n|Aggregation-0 |         | AE   |      | EMD  |      | sliced EMD |      |\n|-----------|---------|------|------|------|------|------------|------|\n| Magnitude | Numbers | AUC  | F1   | AUC  | F1   | AUC        | F1   |\n| M0 ~ M1   | 0       | N/A  | N/A  | N/A  | N/A  | N/A        | N/A  |\n| M1 ~ M2   | 1       | N/A  | N/A  | N/A  | N/A  | N/A        | N/A  |\n| M2 ~ M3   | 27      | 0.74 | 0.24 | 0.7  | 0.28 | 0.7        | 0.25 |\n| M3 ~ M4   | 14      | 0.73 | 0.24 | 0.69 | 0.26 | 0.7        | 0.25 |\n| M4 ~ M5   | 3       | N/A  | N/A  | N/A  | N/A  | N/A        | N/A  |\n\n\nFor the earthquakes in the range of M2 ~ M3 and M3 ~ M4, we can see that the performance is becoming better for larger magnitude earthquakes. In each level, the performance of DASFormer is better than Aggregation-0 (STA/LTA baseline). For the earthquakes in the range of M0 ~ M2 and M4 ~ M5, the number of samples is too small to draw a conclusion."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6627/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700738399380,
                "cdate": 1700738399380,
                "tmdate": 1700738399380,
                "mdate": 1700738399380,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "aefLZvQc2M",
            "forum": "7ipjMIHVJt",
            "replyto": "7ipjMIHVJt",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6627/Reviewer_8ntH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6627/Reviewer_8ntH"
            ],
            "content": {
                "summary": {
                    "value": "This article leverages a self-supervised pretrained network model to enhance seismic detection efforts, addressing the challenge of insufficient labeling for distributed acoustic sensing (DAS) data. The network architecture is thoughtfully designed with a Swin U-Net and Convolutional U-Net, allowing it to efficiently capture the spatio-temporal characteristics of DAS data. The network's performance is further enhanced through the implementation of various strategies, including convolutional pathing, DASFormer blocks, and noise injection. The primary contribution of this article lies in its introduction of a self-supervised pre-training framework for DAS seismic monitoring, even in cases where labeled data is unavailable. This framework is validated in downstream tasks such as earthquake detection and P/S seismic phase pickup."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The research problem is of great importance to society and is not well studied. \n2. Using a self-supervised pre-trained network model to enhance seismic detection efforts sound promising to address the challenge of insufficient labeling for distributed acoustic sensing (DAS) data.\n3. The network architecture is thoughtfully designed with a Swin U-Net and Convolutional U-Net.\n4. This framework is validated in downstream tasks such as earthquake detection and P/S seismic phase pickup."
                },
                "weaknesses": {
                    "value": "This article introduces a novel self-supervised pretrained model for DAS data, yet it falls short in demonstrating its superiority over existing methods. The reasons for this decision are outlined below:\n1. While the paper compares different structures of pre-trained Benchmark models for seismic detection, these benchmarks suffer from poor representation and fairness issues:\n(1)\tThe 'Aggregation-0' and 'Aggregation-inf' models provided in Table 1 lack clear descriptions and references to existing work, making it difficult to understand their characteristics and suitability (I am not sure if this is the LTA/STA method?)\n(2)\tThe use of the j-DAS method, primarily designed for DAS data denoising, in a seismic detection comparison is considered unfair and may not yield equitable results.\n(3)\tThe absence of an effective comparison with established DAS seismic detection methods, such as CNN-RNN (Hern\u00e1ndez et al., 2022) and PhaseNet-DAS (Zhu et al., 2023), diminishes the paper's ability to demonstrate the effectiveness of its proposed approach\n2. The resampling of the dataset from 2000-4000Hz to 10Hz for pre-training lacks a comparative verification of its impact on downstream tasks. Notably, the usual data sampling frequency for seismometer-based seismic detection tasks is within the range of 100-250Hz.\n3. The paper does not adequately address the low signal-to-noise ratio (SNR) characteristic of DAS data, failing to provide clear information about the magnitude distribution and SNR of the training data. This omission leaves unanswered questions regarding the model's ability to detect earthquakes below a certain magnitude or signal-to-noise ratio. \n4. The paper fails to make a clear distinction between P/S phase pickup and seismic detection tasks. For seismic monitoring purposes, distinguishing between P/S phases might be unnecessary, causing confusion in the results presented in Table 1. Additionally, the paper lacks a detailed description of the dataset and evaluation metrics for the downstream task of accurate seismic phase-on-arrival pickup. It only mentions fine-tuned training with 20 labeled data points in Figure 4, leaving crucial aspects of this task unexplained.\n5. The paper lacks ablation experiments to elucidate the quantity of training data necessary for effective seismic monitoring.\n\n\nThe paper has many imprecise parts. Here are a few\n1.  The 'Deep Learning on DAS Data' section of the RELATED WORKS lacks sufficient relevance to DAS data, apart from PhaseNet-DAS and j-DAS. More pertinent related work should be incorporated to provide a comprehensive context.\n2. In the 'Time Series Modeling' section, the paper emphasizes the limitations of existing time series models in incorporating spatial information. However, there are network structures that can effectively integrate both spatial and temporal analyses. Including and comparing these structures with the work presented in this section would enhance the paper's precision.\n3. The paper emphasizes the role of the coarse and fine steps in its approach, but it does not include ablation experiments to demonstrate the individual contributions and effectiveness of these two components. Such experiments would provide valuable insights into the significance of each step.\n4. Figure 3 exclusively compares the earthquake detection effects of different prediction methods, with DASFormer being the only one shown to predict effective information. To enhance credibility, the paper should consider verifying and comparing these solutions with examples where other methods are equally capable of prediction, thus providing a more comprehensive assessment of their capabilities."
                },
                "questions": {
                    "value": "please check the weakness part"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6627/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699089278448,
            "cdate": 1699089278448,
            "tmdate": 1699636756316,
            "mdate": 1699636756316,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "BJzeFy5WZF",
                "forum": "7ipjMIHVJt",
                "replyto": "aefLZvQc2M",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6627/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6627/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1:**  The 'Aggregation-0' and 'Aggregation-inf\u2019 lack description.\n\n**A1:** (1) \"Aggregation-0\" is a multi-variate version of STA/LTA method. It calculates the average of the absolute values of the STA/LTA scores across all variables, which is used as our anomaly score.\n\n(2) \"Aggregation-inf\" functions as a ransdom detector with no detection ability. It randomly assigns labels of 0 or 1 with a 50% probability for each sample.\n\n---\n\n**Q2:** The use of the j-DAS method for seismic detection comparison is considered unfair and may not yield equitable results.\n\n**A2:** We understand the reviewer's concern that j-DAS seems more focused on denoising tasks. To the best of our knowledge, j-DAS is the only existing model that the authors claim to be a foundational model on DAS data. Therefore, considering the claimed potential capabilities of j-DAS, we decided to conduct comparison experiments with it.\n\n---\n\n**Q3:** The paper does not effectively compare with established DAS seismic detection methods, diminishing its ability to demonstrate the effectiveness of its proposed approach.\n\n**A3:** Please refer to the Answer to A6.\n\n---\n\n**Q4:** The resampling of the dataset from 2000-4000Hz to 10Hz for pre-training lacks a comparative verification of its impact on downstream tasks.\n\n**A4:** As you mentioned, the original sampling of our DAS data is 250Hz. Resampling the data from 250Hz to 10Hz allows us to retain the important features and characteristics of the seismic signals while reducing the data size and computational complexity. ****For seismic detection tasks, the lasting time of P waves typically spans a few seconds, while S waves can last even longer, up to several minutes. Given this context, a sampling frequency of 10Hz is sufficient to capture the necessary temporal information required for accurate seismic detection.\n\n---\n\n**Q5:** The model's ability to detect earthquakes below a certain magnitude or signal-to-noise ratio.\n\n**A5:** Thanks for your suggestion. We provide magnitude distribution of our datasets here:\n\nWe provide magnitude distribution of our datasets here:\n\nDistribution of the magnitude of the 45 earthquakes in the training set:\n\n| Magnitude | Numbers |\n|-----------|---------|\n| M0 ~ M1   | 0       |\n| M1 ~ M2   | 0       |\n| M2 ~ M3   | 31      |\n| M3 ~ M4   | 12      |\n| M4 ~ M5   | 2       |\n\nDistribution of the magnitude of the 45 earthquakes in the evaluation set and the performance:\n\n|DASFormer          |         | AE   |      | EMD  |      | sliced EMD |      |\n|-----------|---------|------|------|------|------|------------|------|\n| Magnitude | Numbers | AUC  | F1   | AUC  | F1   | AUC        | F1   |\n| M0 ~ M1   | 0       | N/A  | N/A  | N/A  | N/A  | N/A        | N/A  |\n| M1 ~ M2   | 1       | N/A  | N/A  | N/A  | N/A  | N/A        | N/A  |\n| M2 ~ M3   | 27      | 0.84 | 0.4  | 0.88 | 0.46 | 0.86       | 0.42 |\n| M3 ~ M4   | 14      | 0.89 | 0.59 | 0.92 | 0.58 | 0.93       | 0.6  |\n| M4 ~ M5   | 3       | N/A  | N/A  | N/A  | N/A  | N/A        | N/A  |\n\n|Aggregation-0 |         | AE   |      | EMD  |      | sliced EMD |      |\n|-----------|---------|------|------|------|------|------------|------|\n| Magnitude | Numbers | AUC  | F1   | AUC  | F1   | AUC        | F1   |\n| M0 ~ M1   | 0       | N/A  | N/A  | N/A  | N/A  | N/A        | N/A  |\n| M1 ~ M2   | 1       | N/A  | N/A  | N/A  | N/A  | N/A        | N/A  |\n| M2 ~ M3   | 27      | 0.74 | 0.24 | 0.7  | 0.28 | 0.7        | 0.25 |\n| M3 ~ M4   | 14      | 0.73 | 0.24 | 0.69 | 0.26 | 0.7        | 0.25 |\n| M4 ~ M5   | 3       | N/A  | N/A  | N/A  | N/A  | N/A        | N/A  |\n\n\nFor the earthquakes in the range of M2 ~ M3 and M3 ~ M4, we can see that the performance is becoming better for larger magnitude earthquakes. In each level, the performance of DASFormer is better than Aggregation-0. For the earthquakes in the range of M0 ~ M2 and M4 ~ M5, the number of samples is too small to draw a conclusion."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6627/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737504377,
                "cdate": 1700737504377,
                "tmdate": 1700737504377,
                "mdate": 1700737504377,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bcWSBgwFip",
                "forum": "7ipjMIHVJt",
                "replyto": "aefLZvQc2M",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6627/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6627/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q6:** The paper fails to make a clear distinction between P/S phase pickup and seismic detection tasks, causing confusion in the results presented in Table 1.\n\n**A6:** P/S phase pickup refers to the identification and classification of seismic wave phases, specifically the arrival times of the P (primary) and S (secondary) waves, which focuses on accurately detecting and labeling these specific phases point-wise in DAS data.  On the other hand, seismic detection task (in Table 1) involves identifying and classifying anomalies or abnormal patterns in DAS data. The main differences between P/S phase pickup and seismic detection tasks can be summarized in the following aspects: \n\n(1) **Wave identification**: In P/S phase pickup, the method needs to accurately distinguish between P and S waves in seismic data. But seismic detection tasks do not require this specific wave identification, only with earthquake events.\n\n(2) **Data representation**: P/S phase pickup typically provides point-wise results, indicating the exact arrival times of P and S waves. In contrast, seismic detection tasks focus on determining whether there is an event or anomaly within a specific time span, without the need for precise point-wise results. Moreover, our training/valid/testing splits are different from PhaseNet/PhaseNet-DAS\n\n(3) **Learning setting**: P/S phase pickup methods are typically implemented in a supervised learning setting, where labeled data with ground-truth P/S wave information is required for training. However, our seismic detection task is addressed in an unsupervised learning setting like anomaly detection, as obtaining labeled data for anomalies can be challenging.\n\n---\n\n**Q7:**: The paper lacks a detailed description of the dataset and evaluation metrics for the downstream task of accurate seismic phase-on-arrival pickup.\n\n\n**A7:**: We will update more description of the dataset, including the distribution of the magnitude of the earthquakes and the SNR analysis of the training data. Actually, we don't have evaluation metrics for the downstream task of accurate seismic phase-on-arrival pickup. We just visually show the results. It is worth mentioning that while resampling the frequency to 10Hz is sufficient for earthquake detection and monitoring, it may not be adequate for tasks like P/S phase pickup that require original-resolution (250Hz) data. We acknowledge that generalizability for original-resolution data is an area we plan to explore in the future.\n\n---\n\n**Q8:** The paper lacks ablation experiments to elucidate the quantity of training data necessary for effective seismic monitoring.\n\n**A8:** We agree that ablation studies on the quantity of training data can investigate the performance especially the scalability of DASFormer. The results of this ablation study is shown in following table:\n\n|                      | AE   |      | EMD  |      | sliced EMD |      |\n|----------------------|------|------|------|------|------------|------|\n|                      | AUC  | F1   | AUC  | F1   | AUC        | F1   |\n| 5 earthquake events  | 0.71 | 0.34 | 0.74 | 0.37 | 0.72       | 0.37 |\n| 10 earthquake events | 0.78 | 0.37 | 0.80 | 0.44 | 0.80       | 0.42 |\n| 20 earthquake events | 0.86 | 0.52 | 0.88 | 0.51 | 0.88       | 0.54 |\n| 45 earthquake events (Full data) | 0.88 | 0.55 | 0.89 | 0.52 | 0.90       | 0.56 |\n\n---\n\n**Q9:** The \"Deep Learning on DAS Data\" section of the RELATED WORKS lacks sufficient relevance to DAS data, apart from PhaseNet-DAS and j-DAS.\n\n**A9:** In the revision, we will make sure to include more relevant works that are related to DAS data. It would be better if you can give some suggestions on the related works. Thanks!"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6627/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737555422,
                "cdate": 1700737555422,
                "tmdate": 1700737555422,
                "mdate": 1700737555422,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "acdGqFyPp5",
                "forum": "7ipjMIHVJt",
                "replyto": "aefLZvQc2M",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6627/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6627/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q10:** The paper emphasizes the limitations of existing time series models in incorporating spatial information, but does not include network structures that can effectively integrate both spatial and temporal analyses.\n\n\n**A10:** Thanks for the suggestion. There are many existing spatio-temporal time series methods aim to capture and integrate spatial information for multi-variate time series data. We select three representative methods (Autoformer, GDN, and Crossformer) and compare them with DASFormer. The results are shown in Table 1 and Table 6. Autoformer and Crossformer are two Transformer-based methods utilizing spatial dependency in multi-variate time series. GDN is a graph-based method that uses a graph neural network to capture the spatial dependency of the multi-variate time series.\n\nThere are many existing spatio-temporal time series methods aim to capture and integrate spatial information for multi-variate time series data. However, to the best of our knowledge, all of them are order-agnostic models (with GNNs or Transformers) to capture spatial dependency, which typically do not consider the order or sequence of the variates in the data. This can be problematic in the context of DAS data, where the order of variates is crucial as it represents the location of stations along the fiber optic cable.\n\n---\n\n**Q11:** The paper emphasizes the role of the coarse and fine steps in its approach, but it does not include ablation experiments to demonstrate the individual contributions and effectiveness of these two components.\n\n**A11:** Thanks for the suggestion. We conduct ablation studies on the three steps (Coarse, Coarse-to-Fine, Coarse-to-Fine with Discriminator). The results are shown in the following table:\n\n|                       | AE   |      | EMD  |      | sliced EMD |      |\n|-----------------------|------|------|------|------|------------|------|\n|                       | AUC  | F1   | AUC  | F1   | AUC        | F1   |\n| Coarse-only           | 0.79 | 0.41 | 0.81 | 0.44 | 0.83       | 0.47 |\n| Coarse-to-Fine        | 0.85 | 0.52 | 0.87 | 0.53 | 0.87       | 0.50 |\n| Coarse-to-Fine w/ GAN | 0.88 | 0.55 | 0.89 | 0.52 | 0.90       | 0.56 |\n\nThe results demonstrate the effectiveness of the coarse-to-fine framework and the discriminator. We will add these results to the revision.\n\n---\n\n**Q12:** Figure 3 exclusively compares the earthquake detection effects of different prediction methods, with DASFormer being the only one shown to predict effective information, lacking a comprehensive assessment of the capabilities of different methods.\n\n\n**A12:**  In fact, all samples of baselines are like \"not capable of prediction\", we didn't select the worse ones. We suggest to consider the results of both aggregation-0 (sta/lta) and aggregation-inf in Table 1 together with Figure 3. Note that if an algorithm consistently predicts 0 as the predicted future DAS signals, which corresponds to a completely white region in the forecasting region of Figure 3, it can be seen as a special case of the sta/lta algorithm.  This means that the expected long-term average is 0, and the difference between the real value and 0 (LTA) is kind of equivalent to the sta/lta value (assuming the expected average of lta remains constant). Given this context, we can observe that almost all methods (except FEDformer) perform similarly to aggregation-0 (sta/lta) in Table 1. And in Figure 3, we can see that most of the baselines (except FEDformer) output values close to white (close to 0 in values) , resulting in similar results to aggregation-0."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6627/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737576138,
                "cdate": 1700737576138,
                "tmdate": 1700737576138,
                "mdate": 1700737576138,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]