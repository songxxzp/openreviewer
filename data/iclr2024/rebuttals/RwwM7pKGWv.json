[
    {
        "title": "Towards Dynamic EHR Phenotyping: A Generative Clustering Model"
    },
    {
        "review": {
            "id": "8UjQQXJVOv",
            "forum": "RwwM7pKGWv",
            "replyto": "RwwM7pKGWv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7811/Reviewer_4mzC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7811/Reviewer_4mzC"
            ],
            "content": {
                "summary": {
                    "value": "The authors present an innovative time-series clustering (phenotyping) approach designed to comprehensively capture both the \"observational\" and \"outcome\" dimensions of EHR time-series data. This proposed method incorporates the Dirichlet distribution under a Markovian assumption for cluster assignments and employs a VAE-like structure for forecasting future observations and predicting the outcome of interest, leveraging the cluster assignments and centroids. While distinct from prior works such as AC-TPC, T-Phenotype, and CAMELOT in temporal phenotyping, a comprehensive evaluation of the proposed method's enhancements and technical contributions (from both quantitative and qualitative perspectives) relative to existing approaches is not clear. The authors should provide a thorough exploration of the practical (clinical) validity of the experimental setup on why it is a valid scenario for the proposed method and not for the previous temporal phenotyping works. Moreover, the authors should sufficiently elucidate the implications of different components and design choices such as the number of clusters introduced in the model."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThe paper is generally well-written.\n2.\tThe idea of incorporating both the outcome of interest and the observations into clustering is different from previous works.\n3.\tWhile utilizing the Dirichlet Process is not new in clustering (e.g., Dirichlet Process Gaussian Mixture Models), the authors effectively contextualize this well-known concept within the dynamic temporal phenotyping framework."
                },
                "weaknesses": {
                    "value": "1.\tThe distinction of this work from AC-TPC and T-Phenotype is not clearly articulated in Section 2. These methods are all considered \"dynamic temporal phenotyping\" approaches, capable of incorporating any outcome of interest at each time step, implying that these method can also consider future (e.g., step-ahead) observations and/or the clinical outcome available at the end of the sequence as their \u201coutcomes\u201d at each time step.\n2.\tThe impact of utilizing both future observations and clinical outcomes is not convincingly motivated nor adequately supported by the experimental results.\n3.\tThe description of performance metrics should assist readers in comparing clustering performance across different methods. Additionally, it is unclear how similarity (distance) is measured to compute the Silhouette Index, Davies-Bouldin Index, and Variance Ratio Criterion.\n4.\tExperimental results on benchmarks and baselines appear incomplete. There is a notable absence of results on AC-TPC (as mentioned in Section 4.2) and T-Phenotype, both of which can incorporate either future observations or final outcomes of interest with a simple modification. Furthermore, results on the Normalized Mutual Information (NMI) are lacking. The discriminative power of the proposed method should be compared with the same network architecture without incorporating clustering, rather than relying solely on simple ML baselines, which may not be suitable for handling time-series data.\n5.\tThe heterogeneity of time-series EHR data, especially its multiple modalities, which motivated this work, is not thoroughly explored. There is no architectural contribution to address this issue, and the modeling of future outcomes with a Gaussian distribution may not be suitable for binary/categorical observations, which are often prevalent in EHR data."
                },
                "questions": {
                    "value": "1.\tRegarding Weakness #2: What clusters were discovered in the experiments, and how do they differ from those in previous works? How do the discovered clusters vary when future outcomes are incorporated, and what happens if they are not?\n2.\tRegarding Weakness #3: What similarity (distance) metric is used to compute SIL, DBI, and VRI? Are the ground truth future observations taken into account?\n3.\tThe discriminative power is relatively small, and it is not clearly stated how well the evaluated methods and the proposed method handle imbalanced labels. The authors should also provide performance at each class level and AUPRC, which would be more appropriate for assessing methods under imbalance.\n4.\tHow was the number of clusters (K) determined? This is crucial for gauging the discriminative power of the discovered clusters."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7811/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7811/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7811/Reviewer_4mzC"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7811/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698463416570,
            "cdate": 1698463416570,
            "tmdate": 1699636956042,
            "mdate": 1699636956042,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8XdxjUexC1",
                "forum": "RwwM7pKGWv",
                "replyto": "8UjQQXJVOv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7811/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7811/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer 4mzC"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their feedback. We answer some of the points raised: \n\n**[Distinction with AC-TPC and T-Phenotypes]**:     Apologies for the lack of clarity in clarifying how DeepGC differs from AC-TPC [1] and T-Phenotypes [2]. \n\nAC-TPC, a deep learning approach for identifying phenotypes across two dimensions, achieves this through an iterative process involving cluster assignment and refinement. These subprocesses utilize an outcome prediction task, enabling weight backpropagation through the entire network. Unlike DeepGC, AC-TPC is limited in its capability to a) handle data generation, b) model both observation and outcome data, and c) was specifically designed for a binary outcome task, making it less adept at handling multiclass outcome, obtaining particularly poor performance when classes are highly imbalanced [3]. Additionally, AC-TPC's dynamic phenotyping relies on adverse event occurrences during the observation temporal period (I.e, it updates its phenotypes when new data are being observed). The dynamic modeling approach employed by DeepGC effectively captures the evolving phenotype assignments of a patient over time, a feature that AC-TPC struggles to achieve. T-Phenotype, builds upon AC-TPC with Laplace Encoders, seeks to enhance the trade-off between strong performance on the outcome and observation aspects. However, it shares largely similar limitations to those with AC-TPC. \n\n**[Usefulness of leveraging Future Data]**:  We disagree with the reviewer with respect to the usefulness of future observations and clinical outcomes. The premise of our work is that there are naturally occurring phenotypes in medical cohorts based on various aspects, such as observation and outcome. Incorporating outcomes, therefore, can be invaluable in improving subgroup identification and phenotyping. This can be seen regarding clustering performance. Except for TSKM, we outperform all other benchmarks with respect to clustering observation data, including purely unsupervised models. \n\nIn the medical setting, having a generative model would serve the benefit of allowing us to generate trajectories of physiological variables that change over time to demonstrate and explain the behavior of our model prediction. For example, if an individual is predicted to have a cardiac arrest in the next two days, we would like to show the clinician the deterioration of his/her EHR information that changes over time. Having the ability to generate such trajectories would be helpful in model interpretation and explanation. \n\nWe have empirically demonstrated that our model is able to utilize the generated information to improve outcome prediction (see Table 1 where DeepGC outperformed CAMELOT in almost all metrics on all datasets). Furthermore, it is very important to have the ability to provide information about potential patient outcomes as it is the ultimate function that clinicians look for in a decision-support tool. We will motivate the rational of future observation and outcome prediction in our revised manuscript. \n\n**[Clustering Metrics]**: The evaluation metrics were calculated via the scikit-learn [4] package in Python 3. To account for the temporal 3D dimensionality of the input data, we represented each unique feature-time pair of values as a unique feature when evaluating clustering performance.  \n\n**[Benchmarking]**: We did not include experiments for AC-TPC due to the work in [5] which showed CAMELOT outperformed AC-TPC in a slightly different task. We will include the experiments with AC-TPC and T-Phenotype in the final edited submission. We note that the top performance obtained by these two benchmarks was lower to DeepGC on both datasets at least 5% (average AUROC), 4% (average F1), 2% (average Recall), 2% (average Precision).\n\nWe also agree with the reviewer that it would be important to compare our baselines with similar models that do not leverage clustering, to ensure that its advantages are properly taken care of, and to that end we illustrate in the manuscript the performance obtained from using the VRNN model."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7811/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700675345889,
                "cdate": 1700675345889,
                "tmdate": 1700675345889,
                "mdate": 1700675345889,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VaKvco1KY4",
                "forum": "RwwM7pKGWv",
                "replyto": "8UjQQXJVOv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7811/Reviewer_4mzC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7811/Reviewer_4mzC"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Rebuttal"
                    },
                    "comment": {
                        "value": "I appreciate the authors for their response. While some of the responses effectively addressed my initial comments, many of them have not yet addressed my concerns. Please find the follow-up comments and clarifications below:\n \n**[Distinction with AC-TPC and T-Phenotypes]**\n- AC-TPC can also handle not only binary but also multi-class categories or continuous outcomes. The only thing that needs to be changed is the loss function depending on the outcome type. (By the way, I agree that this model may not be suitable for high imblanceness). \n- What the authors mentioned \"It updates its phenotypes when new data are being observed\" implies the ability of AC-TPC to perform dynamic clustering. Moreover, given any trained temporal clustering method, one can take the input sequence, $x_{1:T}$ and make a set of subseries, $x_{1:1}, x_{1:2}, x_{1:3}, \\dots, x_{1:T}$, to see how the cluster assignment can be dynamically changed over time. So, I do not believe the ability of DeepGC to dynamically perform clustering is a novel contribution over the other methods.\n\n**[Usefulness of leveraging Future Data]**\n- I agree with the authors that using both future observations and clinical outcomes can be very important. What I mentioned initially in the review is to point out that the authors failed to provide an in-depth analysis of how the identified clusters can be distinguished by utilizing that information. \n- It will be impossible to apply Euclidean distance to time-series with different number of observations\n\n**[Clustering metrics]**\n- I am not inquiring about the specific package you used for computing those metrics. To utilize these metrics (without the ground-truth cluster labels), one must establish the 'similarity' between input samples, which is not straightforward for time-series data. Using Euclidean distance for a pair of time series with different numbers of observations is not feasible. Furthermore, many recent deep learning-based temporal clustering methods, including DeepGC, avoid relying on Euclidean distance in the input space. Instead, they focus on leveraging latent representations for clustering. Given these considerations, how can we consider clustering performance based on Euclidean distance in the input space as a plausible metric, especially when Euclidean distance is known to be unsuitable for time series data?\n\n**[Using AUPRC]**\n- I disagree with the authors. AUPRC is a widely used metric even though the value stays between [0, 1]. Even though the value of AUPRC is low due to the high imbalance, one can compare the value with the AUPRC of the null distribution to highlight the gain of the discriminative power. \n- The F1-score depends on how a user sets the threshold for converting continuous predictions into binary predictions. If the model is well-calibrated, one can straightforwardly use the label frequency for imbalanced data. However, different performance orders may arise if the threshold is set individually for each method based on the validation performance. So, I believe a more general way to show the discrimination performance for imbalance data is AUPRC."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7811/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700701234487,
                "cdate": 1700701234487,
                "tmdate": 1700723641416,
                "mdate": 1700723641416,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "oiXk5TjeHC",
            "forum": "RwwM7pKGWv",
            "replyto": "RwwM7pKGWv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7811/Reviewer_BDLh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7811/Reviewer_BDLh"
            ],
            "content": {
                "summary": {
                    "value": "Motivation: EHR data lacks labeled phenotypic information, relies on unsupervised learning, hard to validate. Multi-dimensional nature also makes things harder. Previous work is limited to a time frame / not  outcome-sensitive / not end-to-end. \nThe authors propose DeepGC combining VAE with dynamic clustering (Markovian Dirichlet distribution) to model physiological status over time. It also also enables generation of future observation data.\nEvaluation performed on HAVEN and MIMIC demonstrates good performance over other baselines in all tasks, including clustering and outcome prediction."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Motivation is clear, and grammar + style is quite fluent\n- The work appears to be generally sound, with proofs, and performs well with respect to baselines\n- A good number of baselines with respect to the task\n- Datasets used to evaluate models are well-known in the field of ML for healthcare"
                },
                "weaknesses": {
                    "value": "- Please use bolded vectors for variables that are not scalars, e.g. \\bm{x} = \\{x_1,x_2,...\\}\n- The figure is slightly pixilated, please use svg or pdf format. Additionally I found it confusing. The green solid line has no arrow, whereas the other lines do. Furthermore, the genreation of x' is not depicted. \n- Paper writing needs some edits. E.g. spaces after commas, X and $X$ both being used to refer to datasets, etc.\n- Eqn 1 and the following paragraph has inconsistent $<$ and $\\leq$\n- Lack of discussion on interpretability, visualization of patient clusters.\n- No ablations performed"
                },
                "questions": {
                    "value": "- Is it possible to to run results from general tabular data generators, like TabDDPM (https://arxiv.org/abs/2209.15421) or PAR Synthsizer (https://docs.sdv.dev/sdv/sequential-data/modeling/parsynthesizer)?\n- Can the authors include s quantitative evaluation of the different patient phenotypes discovered by the algorithm?\n- Further analysis of the generated data / more ablations would be useful to see the full scope of the work. E.g. How different is the generated data from the original? Parameter tuning of the RNN? \n- Why does CAMELOT display a similar performance to DeepGC on one dataset and not the others?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7811/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7811/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7811/Reviewer_BDLh"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7811/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698665078705,
            "cdate": 1698665078705,
            "tmdate": 1699636955926,
            "mdate": 1699636955926,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5UBFnmoI4C",
                "forum": "RwwM7pKGWv",
                "replyto": "oiXk5TjeHC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7811/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7811/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer BDLh"
                    },
                    "comment": {
                        "value": "Thank you to the reviewer for their comments. We address the questions and weaknesses raised as follows:\n\n**[Typos and Editing]**: Figures will be made clearer on an eventual submission, as well as better care with boldening vector objects, and editing the document for errors in writing.\n\n**[Ablation]**: We believe that any type of ablation studies on DeepGC would simmer down to benchmarking our model against benchmarks already considered. Specifically, the benchmark VRNN and its variant VRNN-GMM, both subjects of comparison, can be seen as simplified versions of DeepGC. To elaborate further, VRNN-GMM is 2-stage process (i.e., the latent space is fixed and learnt from VRNN separately, then clustering is achieved via GMM), where ours is end-to-end joint learning with the combination of outcome modelling and phenotyping. Additionally, pure VRNN lacks the phenotyping component. Our argument posits that it is the synergistic combination of outcome prediction, phenotyping, and sequential modelling that enhances the models' ability to learn improved phenotypes, sensitive to both outcome and observation aspects.\n\n**[Generative Benchmarks]**: We thank the reviewer for the suggestion to use TabDDPM and PAR Synthesizer as comparisons to evaluate the quality of our generative component. We will use these comparisons for further analysis, however, we would like to stress that generation is not our main goal. DeepGC was designed to tackle the task of phenotyping across two different aspects. The addition of a generative component results from the fact that observations closer in time to an event were more separable with respect to outcome than earlier observations. Combined with the fact that observations are seen only earlier to a certain window of time from the outcome time, we developed a generative approach to generate forward looking data to allow phenotypes to better capture the relevant outcome particularities. Furthermore, the generative feature provides explainability to clinicians for the model decision making as well as improving the outcome prediction\n\n**[Training Details]**: Hyper-parameter tuning of all models was conducted in the same fashion. We used a cross-validation approach with 5 folds, iteratively training a model on a train and validation sets for each fold. The model with the top average performance on the validation data was selected. Consequently, we trained this model on the joint training-validation data, and evaluated on a hold-out test set that was unseen throughout the whole process. We evaluated testing performance using the same set of 10 seeds.\n\n**[CAMELOT Performance]**: It is not immediately clear why Camelot performs similarly to DeepGC on the HAVEN dataset, but not so on the MIMIC data. It could potentially be due to the ratio between different outcome prevalences in the data. As an example, the ratio of the number of patients with a given outcome between the most frequent and second most frequent outcomes is around 12% on HAVEN, but closer to 21% on MIMIC. Consequently, it could be the case that DeepGC has more modelling capabilities than CAMELOT, and henceforth is better equipped to navigate this variability in outcome distributions."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7811/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700686324777,
                "cdate": 1700686324777,
                "tmdate": 1700686324777,
                "mdate": 1700686324777,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "UREMZEsmc3",
            "forum": "RwwM7pKGWv",
            "replyto": "RwwM7pKGWv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7811/Reviewer_rHc6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7811/Reviewer_rHc6"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a generative model designed for patient subgrouping, namely DeepGC. This proposed method is rooted in variational inference to identify phenotypes within temporal clinical data. DeepGC accomplishes this by modeling the joint distribution among input, output, and cluster probabilities derived from observational data, leveraging this joint distribution to generate future data used for making clinical predictions. Experimental results based on two real clinical datasets (HAVEN and MIMIC-IV) demonstrate that DeepGC enhances patient subgrouping capabilities when compared to baseline models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper targets EHR-based clinical risk prediction which is an important research area in machine learning for health."
                },
                "weaknesses": {
                    "value": "- The paper's technical novelty appears somewhat limited. In particular, it fails to adequately address the unique challenges presented by modeling EHR data compared to other sequential data. It also does not sufficiently explain the novelty in terms of model design compared to existing sequential generative models. It's important to note that in the machine learning context, several VAE-based architectures have been proposed to handle various types of sequential data, such as images, audio, and videos [1, 2].\n\n- The model's design lacks clear explanations or motivation. For instance, it is unclear why VAE was chosen over other generative models for modeling the EHR data distribution. Furthermore, the rationale behind modeling the cluster probability distribution using a Dirichlet distribution remains unexplained.\n\n- Connected to the previous concerns, it's uncertain whether the improvement in prediction performance stems from modeling patient subgrouping or is merely a consequence of the neural network architecture's high capacity. In other words, it is unclear whether patient subgrouping is essential, and the paper does not explore the consequences of removing patient subgrouping from DeepGC. To clarify, why did the authors not use a VAE architecture to model the temporal data (i.e., $P(X,Y)$) directly, instead of modeling $P(X,Y,\\pi)$?\n\n- The concerns raised are somewhat substantiated by the results presented in Table 1. The model with strong patient subgrouping performance (TSKM) does not perform well on downstream prediction tasks. Additionally, DeepGC's performance falls within one standard deviation of the second-best baseline models. Consequently, the paper would benefit from statistical testing to establish the significance of the proposed method.\n\n- Several important technical details are omitted, such as the evaluation of patient subgrouping in an unsupervised setting. Furthermore, the paper does not explain how clustering metrics like SIL, DBI, and VRI were calculated. Data statistics and processing steps are also missing, including information about which clinical features were employed and how missing values were handled.\n\n- The paper lacks the provision of code and supplementary documentation, which would enhance clarity and reproducibility.\n\nReferences:\n\n[1] S3VAE: Self-Supervised Sequential VAE\nfor Representation Disentanglement and Data Generation. ICLR 2020\n\n[2] Disentangled Sequential Autoencoder. ICML 2018."
                },
                "questions": {
                    "value": "Questions in the above section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7811/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698715437711,
            "cdate": 1698715437711,
            "tmdate": 1699636955817,
            "mdate": 1699636955817,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6VW0BK8Pkd",
                "forum": "RwwM7pKGWv",
                "replyto": "UREMZEsmc3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7811/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7811/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer rHc6"
                    },
                    "comment": {
                        "value": "Thank you for your contribution and for the questions raised. We have addressed the comments below. \n\n**[Technical Novelty]**: Addressing the technical novelty and challenges related to EHR data, we do not claim to have solved EHR modelling, but we disagree with the reviewer regarding the usefulness of DeepGC given the results obtained. DeepGC obtains close to top performance across all evaluation metrics (evaluated at both the observation and outcome aspects) and all datasets. We note that both models reference by the reviewer are extremely similar in methodology to VRNN [1] (in fact, one can argue that they are a particular type of VRNN-type network), but, more fundamentally, they lack the ability to phenotype or dynamically identify clusters (i.e., clustering changes over time). Recall our main task is that of developing methods capable of dynamically identifying relevant phenotypes/clusters across a variety of aspects (in our case a temporal, and an outcome aspect). \n\n**[Model Design]**:  The rationale for adopting a generative approach in our study is grounded in empirical observations. It became apparent through experimentation that existing phenotypes encountered challenges in learning meaningful and expressive patterns across both modeling aspects, particularly in a dynamic approach. We observed that the separability of outcome sub-cohorts is bigger at time indices closer to the actual event occurrence. Consequently, we decided to leverage a component capable of generating future observation data to reduce the conflation between modeling both aspects. \n\nIn the medical setting, having a generative model would serve the benefit of allowing us to generate trajectories of physiological variables that change over time to demonstrate and explain the behavior of our model prediction. For example, if an individual is predicted to have cardiac arrest in the next two days, we would like to show the clinician the deterioration of their EHR information as it changes over time. Having the ability to generate such trajectories would be helpful in model interpretation and explanation. Furthermore, we have empirically demonstrated that our model is able to utilise the generated information to improve outcome prediction (see Table 1 where DeepGC outperformed CAMELOT across both tasks on almost all metrics) \n\nCrucially, our modeling assumptions hinge on the utilization of the Dirichlet distribution, playing a pivotal role in our model's performance. To achieve dynamically changing phenotype assignments, accurately modeling the temporal evolution of cluster assignment probabilities is essential. We opted for the Dirichlet distribution due to its parametrization over the space of probability vectors of dimension K, and its useful mathematical properties, such as a closed formula for the Kullback-Leibler divergence and an approximate reparameterization scheme that enables efficient backpropagation through the distribution parameters. \n\n**[Performance Improvement]**: We believe that the observed improvement in performance is not attributable to an increase in modeling capacity. Where applicable, all Deep Learning (DL) models underwent evaluation with an identical number of layers and nodes, where applicable. In fact, a closer look into our modeling assumptions shows the modeling capacity of DeepGC is slightly inferior to that of VRNN [1] due to the difference in latent variables. Notably, the benchmark VRNN, along with its variant VRNN-GMM model, can be viewed as ablated versions of DeepGC. Both approaches do not model outcome, however, they can model the multidimensional time-series data directly via latent variables. Although VRNN-GMM also implements a clustering component, this is a 2-stage process (i.e., the latent space is fixed and learned from VRNN separately, then clustering is achieved via GMM), where ours is end-to-end joint learning with the combination of outcome modeling and phenotyping that contributes significantly to the observed performance improvements."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7811/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700674474706,
                "cdate": 1700674474706,
                "tmdate": 1700674474706,
                "mdate": 1700674474706,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "O39nKI5ue4",
            "forum": "RwwM7pKGWv",
            "replyto": "RwwM7pKGWv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7811/Reviewer_1hAY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7811/Reviewer_1hAY"
            ],
            "content": {
                "summary": {
                    "value": "The authors present a deep generative model to model longitudinal EHR data as well as to identify clusters. Their model is implemented utilizing RNNs to model the latent state and variational inference is used to learn model parameters. The authors evaluate the utility of the approach on two separate datasets, where they evaluate both clustering and outcome prediction of the model against standard benchmarks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. I found the paper very easy to read and follow. \n2. The datasets and empirical evaluation seem reasonable albeit somewhat limited."
                },
                "weaknesses": {
                    "value": "1. It's not clear to me what outcome prediction task was chosen by the authors. Also, one randomly chosen outcome prediction task seems like a somewhat incomplete evaluation. \n2. I am curious why the authors chose SVM, xgboost as standard outcome prediction methods instead of say more standard time series approaches like RNN and LSTM. It would be nice to see these benchmarks.\n3. For both the clustering and the outcome prediction tasks, it is not at all clear from the results that DeepGC is better or significantly better than existing models. \n4. It would be nice to see some interpretation of the learned clusters in the paper to motivate why we need to cluster patients at all."
                },
                "questions": {
                    "value": "See weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7811/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699106057763,
            "cdate": 1699106057763,
            "tmdate": 1699636955716,
            "mdate": 1699636955716,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Cr8NAGLmPo",
                "forum": "RwwM7pKGWv",
                "replyto": "O39nKI5ue4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7811/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7811/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1hAY"
                    },
                    "comment": {
                        "value": "Many thanks to the reviewer for the useful comments. We address the points raised below:\n\n**[Outcome Prediction]**: The outcome prediction task in our analysis stems directly from the clinical applications. For example, within the HAVEN ecosystem, admissions to the wards were categorized based on the occurrence of clinically significant events such as cardiac arrest (Cardiac), admission to an Intensive Care Unit (ICU), death (Death), or successful hospital discharge (Discharge). We represented outcomes in a 4-class multiclass setting, emulating clinical practice and focusing on key clinical variables of interest to practitioners. Notably, our models excluded data within 48 hours of an event/discharge to prevent learning immediate deteriorations and aimed to provide clinicians with insights into potential future events.\n\nSimilarly, for the MIMIC dataset, we defined outcomes based on patient location within 48 hours post-discharge from the Emergency Department (E.D.): death (Death), successful discharge (Discharge), ICU escalation (ICU), or whether the patient remained within a ward under observation (Ward). This approach, mirroring the 4-class representation above, captures clinically relevant measures of patient severity. Our rationale for these outcome definitions is grounded in their alignment with clinical practice, ensuring the applicability and robustness of our models in real-world settings.\n\n**[Benchmarking]**: We benchmarked Support Vector Machines (SVMs), XGBoost as standard outcome prediction models due to their relevance and usage in healthcare, as well as relatively easy training and hyper-parameter training procedure. Given we are proposing a Deep Learning (DL) methodology, it is unclear what would be the best LSTM or RNN-type architecture to validate our models against. Not only this, but previous approaches have been validated against types of LSTM/RNN baselines. However, we will include this in the final manuscript for completeness.\n\nWe selected Support Vector Machines (SVMs) and XGBoost as standard outcome prediction models due to their established relevance and widespread usage in healthcare. Furthermore, these models are also straightforward to train and tune, making them suitable benchmarks for our objective. Regarding comparisons with other Deep Learning (DL) models, we note this is a difficult problem as there are a huge number of architectures to select and there are yet no clearly defined benchmarks in our clinical setting. Nevertheless, previous studies have employed LSTM/RNN baselines, we acknowledge the importance of including such benchmarks for a more comprehensive evaluation and will incorporate this comparison in the final manuscript. We note, however, that we have already included some DL methods as part of our benchmarks, e.g. CAMELOT, and VRNN.\n\n**[Performance]**: We believe our quantitative evaluation of DeepGC provides evidence for its advantage over other benchmarks. Focusing on the observation aspect, assessed through clustering metrics, our model outperforms all benchmarks on the MIMIC dataset (14.2 VRI increase, 0.12 DBI decrease) and on HAVEN (0.08 SIL increase, 22.7 VRI increase, 0.44 DBI decrease), except for TSKM. To address the notable performance of TSKM within our evaluation pipeline, as mentioned in Section 5, we present a rationale: a) clustering evaluation metrics favour convex clusters, and b) our evaluation metrics operate on the input data, whereas deep learning methods cluster within a latent space. Notably, TSKM outperforms all other state-of-the-art (SOTA) methods, as well, not just our proposed model.\n\nMoreover, in terms of the outcome aspect, we surpass all benchmarks on HAVEN (0.02 average AUROC increase, 0.01 average F1 increase) and on MIMIC (0.02 average AUROC increase, 0.03 average F1 increase). Our model's performance is comparable to top benchmarks across other metrics, except for the average Precision score on MIMIC data. Importantly, we demonstrate an ability to identify relevant clusters, a capability TSKM lacks, showcasing our model's effectiveness beyond previously proposed state-of-the-art models."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7811/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700686109910,
                "cdate": 1700686109910,
                "tmdate": 1700686109910,
                "mdate": 1700686109910,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]