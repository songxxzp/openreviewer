[
    {
        "title": "SoftPhy: Soft-Body Physical Concept  Learning  and Reasoning from Videos"
    },
    {
        "review": {
            "id": "NBlczcD8M0",
            "forum": "pNlntv7A9X",
            "replyto": "pNlntv7A9X",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6857/Reviewer_P1S1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6857/Reviewer_P1S1"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces the Soft-Body Physical Dataset (SOPHY), a new benchmark for testing AI's physical reasoning with soft objects. SOPHY covers various physical properties like mass and density in dynamic scenarios. Despite the comprehensive nature of the dataset, current AI models show limited performance on it, revealing a gap in their understanding of soft object dynamics. The authors aim for SOPHY to drive improvements in AI's physical world perception and reasoning."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThis paper targets a really interesting problem, the motivation is sound. \n2.\tThe paper is well-written and easy to follow."
                },
                "weaknesses": {
                    "value": "1.\tOn the conceptualization of this work. From the bottom of my heart, I like the topic this paper discusses. But since it concerns physics understanding, the description of physics should have a high standard, at least, the very basic concept should be coherent:\n\na.\tIn Intro \u2013 Second Paragraph. The examples given for humans are very irrelevant to the \u201csoft body\u201d, the topic of this paper. For the liquid example, it can demonstrate the density, but for the pulley example, which physics parameters are the humans trying to distinguish? Moreover, humans can distinguish these physics properties do no means AI models can, so there is a logic leap between the human examples to \u201cHowever, it remains an \u2026\u201d\n\nb.\tFrom this paragraph on, I notice that the paper has a confusing meaning of \u201csoft body\u201d, how is liquid a type of soft body? According to Wikipedia (Soft-body dynamics - Wikipedia), it should be a solid object at least. Yes, I can find more rigorous sources (e.g. a textbook), but I think a simple checkup on Wikipedia can avoid such concept mistakes.\n\nc.\tAccording to Section 3 Dataset, the paper mentions physical properties: mass, friction, elasticity, density, deformability, and stretchiness.\nFirst, there\u2019s a difference between the physical properties a physics simulator can simulate and a property with genuine physics meaning. Sometimes the physics simulator just combine many underlying physics process and expose some high-level properties for the game developer or artist to control. Here is exactly the case. For example, physically speaking, elasticity and stretchiness are both two types of deformability. I wonder how they can be put at the same level. Besides, stretchiness and deformability are both parameters without corresponding basic physics meaning, which means you cannot measure them in the real world. How would the authors measure the stretchiness of cloth from the real world, as is the method of measurement coherent with what\u2019s inside the physics engine? Besides, for soft body objects, there are more physics properties to influence the deformation such as plasticity, viscosity, etc.\n\n2.\tOn the writing: The pie charts of Fig 3 and Fig 5-7 do not give precise ratio numbers. The labels of the sections of the pie charts are not clear enough. Take Fig 3 for example, it has \u201cMass\u201d, \u201cMass Change\u201d, and \u201cMass Goal\u201d, then why it does not have \u201cShape\u201d, \u201cShape Change\u201d, or \u201cShape Goal\u201d, if the shape is not a physical property, then why no \u201cTension\u201d, \u201cTension Change\u201d, \u201cTension Goal\u201d. A similar confusion goes for Fig 5-7.\n\n3.\tOn the dataset: The number of videos is not large. A potential reason is the lack of variance in the scene setup. The soft body can deform in infinite ways, how can a 500-video dataset satisfy the coverage of dynamics?\n\n4.\tOn the experiments: Will the model train on the proposed dataset be generalized to real-world videos? Or is there any potential way the paper aims for real-world physics reasoning?"
                },
                "questions": {
                    "value": "For the questions, please see the Weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6857/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6857/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6857/Reviewer_P1S1"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6857/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698697057807,
            "cdate": 1698697057807,
            "tmdate": 1700598913903,
            "mdate": 1700598913903,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mwR8zUnMuQ",
                "forum": "pNlntv7A9X",
                "replyto": "NBlczcD8M0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6857/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Look forward for your further feedback! (Part 1)"
                    },
                    "comment": {
                        "value": "Thank you for the constructive comments!\n\n**Q1(a). About Pulley**\n\n> [P1S1] a. In Intro \u2013 Second Paragraph. The examples given for humans are very irrelevant to the \u201csoft body\u201d, the topic of this paper. For the liquid example, it can demonstrate the density, but for the pulley example, which physics parameters are the humans trying to distinguish? \n\nWe are sorry for the potential confusion regarding the liquid and rope (pulley) example. Generally, in this work, we emphasize both the parametric side and the behavioral side of the soft-bodies. In detail, we address this question from two perspectives.\n\n**[Why we choose pulley system as the basis of *rope* scenario?]** We believe, as for human perception, rope is very different from liquid in that rope is 1-dimensional. When we think of rope, we mainly consider the connectivity and length constraints in ropes as well as the derivative dynamics. Viewing liquid dynamics is quite different when we may focus more on the physical properties and its global contour behaviors. In the *rope(aka. pulley)* dataset, we attempt to guide models to learn the embedded physical mechanics and constraints behind a variety of objects. To some extent, lift-up and push-down, cooperating with pulleys, are the most common use of rope in both everyday life(e.g. gym) and industry(e.g. crane). For a simple case, humans could easily perceive the motion of another side of the rope if we see one side of the rope lifted up or pushed down, which is proven diffcult for many VLMs due to dataset gap. As for a more complex case, we know that the dynamic pulley in Fig. 1 (c) of the paper could reduce the tension between ropes compared with static pulley, helping us to pull the cargo up more easily. Hence, we think it's crucial to equip vision language models with a conceptual perception of these phenomena, which is more related to physical dynamics reasoning, as opposed to physical parameter or concept reasoning. For each scenario, we consciously include both reasoning sides.\n\n**[What physical parameters relevant to \"soft-body\" we are trying to distinguish?]** Typical physical parameters of rope are like elastic coefficient and bending stiffness. Since these parameters are already displayed in the scenario of *cloth* or *ball*, where the parameters are shown in a more comprehensive and complicated way, thus considering the diversity of physical parameters in our overall dataset, in the *rope* scenario, we mainly focus on other physical characteristics of this kind of material. One is the relative weight of load attached to the rope, indicating the external force exerted to the rope terminals, the other is the relative tension force within the rope segments. We hope these two physical parameters can be ideal testing criteria for the conceptual/parametric perception of rope.\n\n**Q1(b). About Logic Leap**\n\n> [P1S1] Moreover, humans can distinguish these physics properties do no means AI models can, so there is a logic leap between the human examples to \u201cHowever, it remains an \u2026\u201d\n\nThank you for your concern. In this paragraph, we express concerns about whether current AI models have the capability to accurately identify distinctions in the physical properties and dynamics of soft-body objects, which humans can intuitively discern. To improve our writing, we show the revised paragraph below and have incorporated it in our revision of paper.\n\n*We are able to know that the clear liquid in Fig.1(a) at the bottom has a higher density than the yellow liquid on the top; we know that the dynamic pulley in Fig.1(c) could reduce the tension between ropes compared with static pulley, helping us to pull the cargo up more easily. These innate human skills raise an intriguing question\uff1acan current AI models have the physical common sense to infer soft objects' physical properties and predict their corresponding dynamics?*\n\n**Q2. About Definition of Soft-Body**\n\n> [P1S1] b. From this paragraph on, I notice that the paper has a confusing meaning of \u201csoft body\u201d, how is liquid a type of soft body? According to Wikipedia (Soft-body dynamics), it should be a solid object at least. Yes, I can find more rigorous sources (e.g. a textbook), but I think a simple checkup on Wikipedia can avoid such concept mistakes.\n\nThe Wikipedia focuses on **Soft-body dynamics, a specialized area within computer graphics**. This term is used to differentiate soft-body dynamics from fluid dynamics, distinct in computer graphics simulation process. While our emphasis is on physical reasoning, not graphic methods. We adopt this concept to underline that prior benchmarks primarily featured rigid bodies, like spheres and cubes. Fluids, being neither rigid nor adequately addressed previously, are a separate and worthwile consideration. \n\nWe hope our clarification can resolve your concerns on the \"soft body\". If there are still concerns on the confusion of the name or any suggestion, we can discuss more and revise the whole paper correspondingly."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700321514300,
                "cdate": 1700321514300,
                "tmdate": 1700322088437,
                "mdate": 1700322088437,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7VtrsSgIW7",
                "forum": "pNlntv7A9X",
                "replyto": "NBlczcD8M0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6857/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Look forward for your further feedback! (Part 3)"
                    },
                    "comment": {
                        "value": "2. **Former works are in support of this combination.** Concepts such as deformability and elasticity, which is highly abstract and on the different descriptional levels, have been equally proposed and discussed in a series of former cognitive AI research. For example, in Physion++([A]), it includes mass, deformability and elasticity and put them at the same level (see ref[A] Fig.1&2). The parameter levels discussed in our work are proposed similarly as Physion++([A]).\n\n[A] Tung, Hsiao-Yu, et al. \"Physion++: Evaluating physical scene understanding that requires online inference of different physical properties.\" NeurIPS (2023).\n\n3. **High level properties are easy to both understand and control.** Using APIs from physics engine facilitates the control of diverse parameters and allows us to change different settings in different videos, while it would be inconvenient for us to modify the underlying parameters and to distribute them in a good manner(e.g. cloths are 50% likely to be very rough and 50% likely to be very smooth). Besides, we think that using APIs also assures that the concepts are familiar to humans, which tells why they are extracted as APIs. \n\n**[Q3(b). Question: How to measure high level properties in real world and align with the methods used in simulation?]** \n\n> [P1S1] c. ...Besides, stretchiness and deformability are both parameters without corresponding basic physics meaning, which means you cannot measure them in the real world. How would the authors measure the stretchiness of cloth from the real world, as is the method of measurement coherent with what\u2019s inside the physics engine? \n\n\n\n1. **These high-level concepts are valuable in cognitive AI research.** As we mentioned above, in this work, we focus on those concepts acceptable for common people, like stretchiness, plasticity, etc. Just as you kindly stated, they are kind of subjective and can hardly be strictly defined in physics and measured in the real world. But as our human study shows, most people can distinguish and apply these physical concepts, which means these concepts are valuable to discuss in cognitive AI field. **We hope models can understand these high-level concepts like humans.**\n\n2. **It's worth noting that, in this work, we focus more on fuzzy judgment (e.g. which one's X is much greater), not accurate prediction.** Just as you kindly pointed out, these concepts like stretchiness can hardly be strictly defined by any physics formula, so we choose to design fuzzy judgment tasks. And we think measuring the accurate values might not be an urgent problem. In detail, the physical parameter values in the sampling pool are not diversely specified. Typically, for most parameters, we only set 2 or 3 values to sample from and they are greatly different. For example, for a cloth's stretching stiffness, we set 2 values, one value very high and the other very low, to make the cloth appear either difficult to stretch or highly elastic, so that the property difference can be easily captured by humans at the first glance. Thus, in this work, we focus on the agent's ability to distinguish properties, rather than predict numerical values. At least at this visual-language AI research stage, we believe if models fail to do simple fuzzy judgment in the simulation dataset, they may hardly predict the values as well, regardless of whether it is simulated or real-world.\n\n3. **Although the properties are not measured from simulation (but preset values), we can still find the closest physics parameters and measure them using the same method both in simulation and real world.** Take stretchiness as an example, we think people may agree that it shares a very close meaning with Young's modulus which has strict physical definition. So if we need to collect data in the real world, maybe we can take Young's modulus as a criteria of stretchiness. \n    In mechanics of materials,\n    - Formula of Young's Modulus: $E = \\frac{\\sigma}{\\varepsilon}$\n        - Where $E$ is Young's Modulus, $\\sigma$ is stress, and $\\varepsilon$ is strain\n\n    - Stress ($\\sigma$): $\\sigma = \\frac{F}{A}$\n        - Where $\\sigma$ is stress, $F$ is the force applied, and $A$ is the area of the surface on which the force is acting.\n\n    - Strain ($\\varepsilon$): $\\varepsilon = \\frac{\\Delta L}{L_0}$\n        - Where $\\varepsilon$ is strain, $\\Delta L$ is the change in length, and $L_0$ is the original length.\n\n    Since in the dataset we record the **2D/3D data** (image, segmentation, point cloud, mesh, etc.) for each frame, we can follow the above formulas to measure the property value just like scientists do in the real world."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700321667358,
                "cdate": 1700321667358,
                "tmdate": 1700321745013,
                "mdate": 1700321745013,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "23IqOduGfT",
                "forum": "pNlntv7A9X",
                "replyto": "mwR8zUnMuQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6857/Reviewer_P1S1"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6857/Reviewer_P1S1"
                ],
                "content": {
                    "title": {
                        "value": "Reply to part1"
                    },
                    "comment": {
                        "value": "Thanks for your response.\n\nI will start with the concept of the soft body. First, \"dynamics\" is a serious physics term, which describes/studies the physics phenomenon related to Newton's second law. \"soft body dynamics\" is the dynamics of a soft body. And a soft body is solid. Liquid is not solid. These are just physics facts that have nothing to do with the CG community or else. I am sorry if I put up this Wikipedia page and potentially misled you about the real problem. All I want to say is that liquid is not a kind of soft object. If you want to unite the concept of soft body and liquid, you can refer to continuum mechanics (https://en.wikipedia.org/wiki/Continuum_mechanics). Basically, it distinguishes solid objects (rigid, articulated, deformable/soft) from liquid objects. \nFor a rigorous description, I recommend textbooks in continuum mechanics, for example, introduction to continuum mechanics (https://www.sciencedirect.com/book/9780750685603/introduction-to-continuum-mechanics).\n\nSo, if this work is for continuum objects, then it should involve rigid and articulated objects. If this work is for the solid object, then it should not have liquid. But the scope of this work slices the concept of solid objects and combines it with liquid, I don't understand how the categorization is done.\n\nEven put in the context of computer graphics, not strictly physics, I have found no place to state liquid is the soft body."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700598011399,
                "cdate": 1700598011399,
                "tmdate": 1700598011399,
                "mdate": 1700598011399,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vE8uvUomOt",
                "forum": "pNlntv7A9X",
                "replyto": "5NMiRqKpgm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6857/Reviewer_P1S1"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6857/Reviewer_P1S1"
                ],
                "content": {
                    "title": {
                        "value": "Reply to part 2"
                    },
                    "comment": {
                        "value": "Thanks for your response.\n\nSo, I gather the physics in this work is more leaning toward intuitive physics or cognitive physics. I accept narrowing the scope, but I strongly advise making it clearer. Because when this work becomes a popular benchmark, and expose to a wider audience, they might think researchers in the AI field are not rigorous."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700598465546,
                "cdate": 1700598465546,
                "tmdate": 1700598465546,
                "mdate": 1700598465546,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3JkQiW0QNt",
                "forum": "pNlntv7A9X",
                "replyto": "NBlczcD8M0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6857/Reviewer_P1S1"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6857/Reviewer_P1S1"
                ],
                "content": {
                    "title": {
                        "value": "Adjust rating after taking into account the authors and other reviewers' feedback"
                    },
                    "comment": {
                        "value": "During rebuttal, the authors have made clear the scope of the \"physics\" in this work. Given this change of precondition, I can relax the questions on the rigor of physics. But it still does not justify including liquid objects in soft objects, and I see no possibility to fix this.\nThus, I raise my rating to 5."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700599082340,
                "cdate": 1700599082340,
                "tmdate": 1700599082340,
                "mdate": 1700599082340,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oUgdXA9pCQ",
                "forum": "pNlntv7A9X",
                "replyto": "NBlczcD8M0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6857/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your constructive comments and suggestions!"
                    },
                    "comment": {
                        "value": "Thank you for your insightful suggestions! We agree with your idea that physical concepts should be clearer and more rigorous. Therefore, we've broadened our work's description **from 'soft body' to 'continuum'** to more accurately reflect its scope. \n\nIn both physics and computer graphics, 'continuum' encompasses various bodies such as liquids, soft materials (e.g., soft balls, cloth, and ropes), rigid bodies (e.g., cubes, pillars, plates, and spheres), and articulated bodies (e.g., pulleys). Our dataset comprehensively encompasses fluids, soft bodies, rigid bodies, and articulated bodies (e.g., in the rope scenario). This inclusion leads to our utilization of the continuum concept, enhancing the breadth and relevance of our study.\n\nMoreover, we consciously include both physical dynamics reasoning (e.g., interactions between fluids, soft bodies and rigid bodies), and physical parameter or concept reasoning (e.g., density for fluids; tension, elasticity for soft bodies; mass for rigid bodies). For instance, our rope and pulley scenario involves elements of rope, rigid bodies, and articulated bodies; the fluid scenario includes liquids; the cloth scenario covers both cloth and rigid bodies; and the ball scenario focuses on soft balls. This extensive coverage ensures that our dataset provides a comprehensive understanding of the interactions and couplings within these various types of continua, capturing the complexity and diversity of real-world physical phenomena.\n\nIn light of this, we have renamed the dataset **from SoPhy to ContPhy**. We have added an entire section in **Appendix A.4** to elaborate on the concept of the continuum. We have also **updated the entire paper accordingly**. \n\nWe hope this clarification addresses all your concerns. We are looking forward to your further reply and suggestions. **If you find our response satisfactory, we would be grateful if you could consider revising your score.**"
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700630388988,
                "cdate": 1700630388988,
                "tmdate": 1700631027316,
                "mdate": 1700631027316,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Wg6PQgSeqN",
            "forum": "pNlntv7A9X",
            "replyto": "pNlntv7A9X",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6857/Reviewer_Vp2g"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6857/Reviewer_Vp2g"
            ],
            "content": {
                "summary": {
                    "value": "The authors present the Soft-Body Physical Dataset (SOPHY), an innovative benchmark designed to assess machine learning models' capacity for physical reasoning within a range of scenarios involving soft bodies. The authors subsequently assessed several visual models, such as CNN and MAC, using the dataset. Their findings suggest that contemporary AI models are yet to fully grasp the physical commonsense associated with soft objects, underscoring the significance of the introduced dataset."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper boasts several commendable attributes. Foremost, the dataset it introduces is characterized by a notable diversity in its scenarios, offering a comprehensive spectrum for analysis. Furthermore, the evaluation of the properties associated with soft objects is designed with meticulous detail. Another significant strength is the decent render quality, which not only enhances the visual clarity but also aids in the accurate interpretation of data. Moreover, the paper provides a comprehensive comparison between human perception, random/frequent answer, non-visual model, and other visual models."
                },
                "weaknesses": {
                    "value": "- Some results are just stated without further discussion.\n  - In Section 4.2 Paragraph \"Physical Property\", The author stated that \"ALPRO achieves the best results in the rope scenario, and maintains competitive results in other scenarios, showing the value of large-scale video-text pre-training and alignment.\". However, why other models slightly outperform ALPRO in scenarios other than Rope is not discussed.\n  - In Section 4.2 Paragraph \"Dynamics\", only the result of ALPRO and HCRN is discussed, and why other models do not work well is missing.\n  - In Section 4.2 Paragraph \"Scenario Analysis.\", only cloth and rope scenarios are discussed.\n\n- The writing could benefit from some improvements.\n  - In Section 4.2 Paragraph 1, \"We summarize the performance of all baselines in Table 1.\", should be Table 2.\n\n- Some statement is not supported well.\n  - In Section 4.2 Paragraph \"Evaluation Conclusion\", the authors concluded that \"Machine models results show that even state-of-the-art models struggle with answering physical questions based on the visual input.\". However, the relationship between \"soft body physics reasoning capability\" and \"answering physical questions based on visual input\" is not clear. For example, AI models may understand soft body physics well, but unable to understand the questions, as the semantic information is not recognized by the model.\n  - In conclusion, the authors stated that \"Despite progress, our evaluation of AI models revealed an ongoing challenge: they struggle to perform well on our benchmark, highlighting their limited physical commonsense for soft objects.\", but there are already articles(i.e. [1]) concluded that AI models lack physical reasoning capability, if this capability is missing, the model should also lack physical reasoning capability for soft objects.\n\n[1] Li, Shiqian & Wu, Kewen & Zhang, Chi & Zhu, Yixin. (2022). On the Learning Mechanisms in Physical Reasoning."
                },
                "questions": {
                    "value": "- Should tasks related to reasoning on liquids and soft objects be evaluated in different ways? The comprehension of physics for soft objects and liquids may represent divergent capabilities."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6857/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6857/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6857/Reviewer_Vp2g"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6857/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698775110853,
            "cdate": 1698775110853,
            "tmdate": 1699636795595,
            "mdate": 1699636795595,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FG3SoHMLIx",
                "forum": "pNlntv7A9X",
                "replyto": "Wg6PQgSeqN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6857/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Look forward for your further feedback! (Part 1)"
                    },
                    "comment": {
                        "value": "Thank you for all these constructive comments!\n\n**Q1. About Further Discussion of Experiments**\n\nThank you for all these suggestions! We discuss each question below, and have added them in Section 4.2 of our revised paper.\n\n> [Vp2g] In Section 4.2 Paragraph \"Physical Property\", The author stated that \"ALPRO achieves the best results in the rope scenario, and maintains competitive results in other scenarios, showing the value of large-scale video-text pre-training and alignment.\". However, why other models slightly outperform ALPRO in scenarios other than Rope is not discussed.\n\n**[Q1 (a). Other Models Slightly Outperform ALPRO]** Actually, all the baseline models struggle to achieve decent performance on physical property questions, except ALPRO, which achieves the best results in the rope scenario and maintains competitive results in other scenarios, showing the advantages of large-scale video-text pre-training and alignment.\n\n> [Vp2g] In Section 4.2 Paragraph \"Dynamics\", only the result of ALPRO and HCRN is discussed, and why other models do not work well is missing.\n\n**[Q1 (b). Other Baselines]** Traditional pure neural networks have difficulty understanding the physical scenarios and in capturing the physical laws from videos and question-answer pairs. Thus, they perform worse than their previous performance on our benchmark.\n\n> [Vp2g] In Section 4.2 Paragraph \"Scenario Analysis.\", only cloth and rope scenarios are discussed.\n\n**[Q1 \\(c\\). Other Scenarios]** ALPRO performs well in the rope and cloth scenario. Except for the reason that the cloth and rope scenarios share some similarities, another important reason is the fewer question types in the rope and cloth scenario than those in the fluid and ball scenarios. Specifically, the rope scenario has counterfactual and goal-driven, and the cloth scenario has predictive. Conversely, in the fluid and ball scenarios, we incorporated all four problem types, thereby making situations much more complicated. To effectively address these scenarios, models must tackle four distinct question types, each focusing different aspects of physical dynamics. Consequently, no baseline models can gain an absolute advantage in these scenarios. This indicates that our four proposed question types well evaluate different dimensions of physical reasoning, making the fluid and ball scenarios particularly challenging for AI models.\n\nAll these comments have been updated in Section 4.2 of our revised paper to further analyze the experiments.\n\n\n**Q2. Reference of Table**\n\n> [Vp2g] In Section 4.2 Paragraph 1, \"We summarize the performance of all baselines in Table 1.\", should be Table 2.\n\nThanks for the reminder. We have already fixed this and checked the whole paper again to improve our writing.\n\n**Q3. About Concerns for Semantic Information**\n\n> [Vp2g] In Section 4.2 Paragraph \"Evaluation Conclusion\", the authors concluded that \"Machine models results show that even state-of-the-art models struggle with answering physical questions based on the visual input.\". However, the relationship between \"soft body physics reasoning capability\" and \"answering physical questions based on visual input\" is not clear. For example, AI models may understand soft body physics well, but unable to understand the questions, as the semantic information is not recognized by the model.\n\nAdmittedly, semantic information can influence results. However, using QA formats to evaluate physical reasoning abilities has been widely acknowledged and shown effectiveness in previous works, such as ComPhy [A] and CLEVRER [B]. QA gives the flexibility to estimate different kinds of physical reasoning abilities such as understanding different physical properties like mass, density, viscosity, and predict the corresponding dynamics based on variance of such physical properties. To correctly answer these questions, AI models need to have both the physical common sense and the ability to understand natural language queries and answers. Since the question-answer pairs in our benchmark are synthesized by templates, the major challenge of AI models is from physical reasoning. Thus, we claim that our SoPhy benchmark mainly evaluates \"soft-body physical reasoning capability\". \n\n[A] Chen, Zhenfang, et al. \"ComPhy: Compositional physical reasoning of objects and events from videos.\" NeurIPS (2022).\n\n[B] Yi, Kexin, et al. \"CLEVRER: Collision events for video representation and reasoning.\" ICLR (2020)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700321336781,
                "cdate": 1700321336781,
                "tmdate": 1700322156749,
                "mdate": 1700322156749,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LYhRRXwgvE",
            "forum": "pNlntv7A9X",
            "replyto": "pNlntv7A9X",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6857/Reviewer_U8tp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6857/Reviewer_U8tp"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a new dataset, / and benchmark for targeting to assess machine learning models in physical reasoning. \nThe paper explains how this dataset is complementary o existing datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The motivation behind creating SPHY is to advance ML / AI techniques to bridge the gap between human and AI in the physical world. The authors generated results for several benchmarks."
                },
                "weaknesses": {
                    "value": "NA"
                },
                "questions": {
                    "value": "NA"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6857/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698824846439,
            "cdate": 1698824846439,
            "tmdate": 1699636795477,
            "mdate": 1699636795477,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LiDQX5jxy8",
                "forum": "pNlntv7A9X",
                "replyto": "LYhRRXwgvE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6857/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Look forward for your further feedback! (Part 1)"
                    },
                    "comment": {
                        "value": "Thank you for the constructive comments! \n\nWe are glad to hear that you think our SOPHY dataset is novel and invaluable, which advances ML / AI techniques to bridge the gap between human and AI in the physical world. \n\nWe are looking forward for your further feedback!"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322824935,
                "cdate": 1700322824935,
                "tmdate": 1700322824935,
                "mdate": 1700322824935,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "0U4xQSqfjC",
            "forum": "pNlntv7A9X",
            "replyto": "pNlntv7A9X",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6857/Reviewer_t1H7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6857/Reviewer_t1H7"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents SOPHY a new soft-body benchmark including four types of simulated videos (based on Unity) and their corresponding question-answering pairs which can serve as a new benchmark to study AI models on understanding complex physical properties and dynamics for soft-body scenarios. The paper also evaluate the performance of several SotA methods and show that there is still a lot room to improve as they fall behind human performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- the paper proposes a new benchmark that involves careful task environment designs and question-answering pairs generation, which is technically novel and interesting.\n- the proposed four types of soft-body tasks are indeed lacking from existing benchmarks and they are more complex so the proposed benchmark adds values to the community.\n- the authors benchmarked several SotA methods on the proposed benchmark, provided good analysis, conducted human performance study, and showed that there is still a lot room to do research, which are all quite valuable to the community."
                },
                "weaknesses": {
                    "value": "- the task family is limited to the designed four types. Also the questions are generated from pre-defined sets of templates. These restrict the general use of the benchmark for other tasks, environments, and questions. Could the authors comment on how is it possible to extend the framework for other tasks?\n- the authors claimed that previous benchmarks cannot change mass and friction, but as many of them are also based on physical simulators, it's unclear why they couldn't do that. \n- the paper doesn't propose a solution to improve the performance based on the findings."
                },
                "questions": {
                    "value": "see weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6857/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698866138150,
            "cdate": 1698866138150,
            "tmdate": 1699636795375,
            "mdate": 1699636795375,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZTlBw3JO1t",
                "forum": "pNlntv7A9X",
                "replyto": "0U4xQSqfjC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6857/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Look forward for your further feedback! (Part 1)"
                    },
                    "comment": {
                        "value": "Thank you for all these constructive comments!\n\n**Q1. About Extending the Framework for Other Tasks**\n\n> [t1H7] the task family is limited to the designed four types. Also the questions are generated from pre-defined sets of templates. These restrict the general use of the benchmark for other tasks, environments, and questions. Could the authors comment on how is it possible to extend the framework for other tasks?\n\nWe have developed various templates for each question type across four distinct scenarios. Our experiments reveal that current AI models fail in understanding soft-body physical dynamics, leading to poor performance on our dataset, independent of template design. Additionally, our dataset generation framework is capable of producing different question types and video types, such video annotations for segmentation and depth. This framework can support a range of common vision tasks, such as video segmentation, object detection, text-video retrieval and video grounding. Since our primary objective is to evaluate physical reasoning abilities in the form of question answering, we will not prioritize other vision tasks.\n\n**Q2. About Previous Benchmarks**\n\n> [t1H7] the authors claimed that previous benchmarks cannot change mass and friction, but as many of them are also based on physical simulators, it's unclear why they couldn't do that.\n\nWe agree with the reviewer that many prior benchmarks, such as Physion [A] and ComPhy [B], are also based on physical simulators. However, their benchmarks fall short in thoroughly assessing whether machine models have human-like visual reasoning abilities, particularly in understanding physical object properties and dynamics. These physical benchmarks do not adequately cover dynamics influenced by varying physical object properties across diverse scenarios, notably in the case of soft objects. Some of them lack the variance of object parameters, such as Physion [A], in which solids share the same mass and water maintains a consistent density. Some of them limit their scope to simple primitives and scenario, such as ComPhy [B], in which they only consider mass and electric charge in a basic solid collision scenario of cubes and spheres. In contrast, we are the only comprehensive benchmark with object-specific properties in a wide range of scenarios, which even encompasses soft-body objects and unique language-based questions about dynamics in counterfactual and goal-planning scenarios. Our dataset addresses the gap in existing benchmarks, which often **overlook complex intrinsic properties** and **corresponding dynamics** in diverse scenarios, a key aspect our SoPhy emphasizes.\n\n[A] Bear, Daniel M., et al. \"Physion: Evaluating physical prediction from vision in humans and machines.\" NeurIPS (2023).\n\n[B] Chen, Zhenfang, et al. \"ComPhy: Compositional physical reasoning of objects and events from videos.\" NeurIPS (2022).\n\n\n**Q3. About Proposed Solution**\n\n> [t1H7] the paper doesn't propose a solution to improve the performance based on the findings.\n\nWe thank the reviewer for this suggestion. We have presented a proposed solution for the fluid scenairo to better investigate the characterstics of the current benchmark in **G2** of the **General Response**. Please kindly refer to it and we are looking forward to your further feedbacks!"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700321214908,
                "cdate": 1700321214908,
                "tmdate": 1700322196153,
                "mdate": 1700322196153,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]