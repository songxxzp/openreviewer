[
    {
        "title": "Unified Anomaly Detection via Multi-Scale Contrasted Memory"
    },
    {
        "review": {
            "id": "hfgucU843q",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5400/Reviewer_t6Z1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5400/Reviewer_t6Z1"
            ],
            "forum": "9o7KuFcsps",
            "replyto": "9o7KuFcsps",
            "content": {
                "summary": {
                    "value": "The paper presents a solution to address the challenges of one-class anomaly detection and the outlier-exposure scenario, where labeled anomalies are scarce in the training dataset. The authors introduce a method that incorporates a memory module, employing Hopfield layers, which is integrated with contrastive learning techniques. The approach allows for the memorization of multi-scale normal class prototypes during training, but also facilitates the learning of informative representations. This innovation significantly enhances the model's ability to capture subtle features of normal data while adapting to varying levels of anomaly complexity."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The authors provide a well-structured and clear motivation for their proposed method. Moreover, the introduction of Hopfield layers for anomaly detection represents a novel concept. This innovative utilization adds efficiency to the model's memory capabilities."
                },
                "weaknesses": {
                    "value": "The paper demonstrates several areas where it could be improved. \n\n1. While the authors assert that their model outperforms state-of-the-art approaches across a wide range of anomalies, it is notable that the paper lacks evaluation on widely-accepted benchmark datasets such as MVTec [1] and VisA [2]. These datasets contain texture anomalies, which are crucial for a comprehensive evaluation. Although CIFAR-10/100 and CUB are important, their evaluation should be complemented by assessments on these texture-oriented datasets.\n\n2. The paper mentions superior performance over existing methods, but Table 2 reveals that AnoMem, at best, achieves comparable results in out-of-distribution (OOD) detection. It's important to ensure that the claims made align with the empirical findings.\n\n3. While it may be justifiable not to compare with state-of-the-art pretrained approaches like [3], given their exposure to external datasets, it remains important to include these comparisons in the evaluation. CIFAR and CUB datasets share similarities with ImageNet-pretrained data, but the FPAD dataset exhibits a significant distribution shift, which calls for a comparative analysis. Additionally, it's worth noting that AnoMem's performance benefits significantly from exposure to anomaly types, which pretrained methods do not rely on.\n\n4. Several crucial components of the proposed method are not examined by the authors. For example, while the authors briefly mention the potential substitution of the NTX objective with alternative contrastive frameworks like Barlow-Twins, which are known for their efficiency and ability to operate effectively with smaller batch sizes, this proposition lacks empirical demonstration. The absence of a comparative analysis or experimental results to support this claim leaves a gap in the evaluation of the method's adaptability and robustness across different contrastive learning frameworks. \n\n[1] MVTec AD \u2014 A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection, Bergmann et. al, CVPR 2019.\n\n[2] SPot-the-Difference Self-Supervised Pre-training for Anomaly Detection and Segmentation, Zou et. al, ECCV 2022.\n\n[3] Mean-shifted contrastive loss for anomaly detection, Reiss & Hoshen, AAAI 2023."
                },
                "questions": {
                    "value": "1. In FPAD, the CSI method is not included in performance metrics. What are the CSI results?\n\n2. The explanation of the linear evaluation protocol, while briefly described, lacks depth. It would be valuable to have a more detailed elaboration on the rationale behind employing this protocol and why it is considered an important metric in the context of anomaly detection. Moreover, given that this protocol may not be standard within the AD community, it raises curiosity about how other existing methods perform under this evaluation criterion. Could the authors shed light on the performance of competing methods using this protocol for comparison and context? This information would further enrich the assessment of the proposed approach."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5400/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5400/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5400/Reviewer_t6Z1"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5400/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697382553176,
            "cdate": 1697382553176,
            "tmdate": 1699636547035,
            "mdate": 1699636547035,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vohrs7Wmzl",
                "forum": "9o7KuFcsps",
                "replyto": "hfgucU843q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5400/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5400/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer t6Z1 (1/2)"
                    },
                    "comment": {
                        "value": "Dear reviewer,\nThank you for providing constructive reviews and your recognition. We have addressed each of your questions individually in our response and hope these clarifications contribute to an improved rating. We have revised the paper according to your feedback, marking the changes in magenta. Additionally, we've highlighted in brown the text that was part of the initial submission, which may have been overlooked.\n\nWe are eager to continue the discussion. Have all your concerns been addressed in our rebuttal, or are there any remaining comments you would like us to consider?\n\n**Question. While the authors assert that their model outperforms state-of-the-art approaches across a wide range of anomalies, it is notable that the paper lacks evaluation on widely-accepted benchmark datasets such as MVTec and VisA. These datasets contain texture anomalies, which are crucial for a comprehensive evaluation. Although CIFAR-10/100 and CUB are important, their evaluation should be complemented by assessments on these texture-oriented datasets.**\n\n**Reply:**\nOur extensive tests cover a wide range of anomalies, including coarse object anomalies (CIFAR), subtle style anomalies (CUB200, a challenging fine-grained dataset for anomaly detectors with random performance of Sota method like CSI [1]; while recent method MSC [2] does not report their performance on this dataset), and a real-world dataset of face presentation attack WMCA with local anomalies. We would like to highlight that the WMCA conveys different texture anomalies with different forms of attacks, i.e., paper print (PP), screen recording (SR), paper mask (PM) and flexible mask (PM).\n\nWith respect to datasets such as MVTec and VisA, only a few studies have employed them for evaluating anomaly detection. Notably, these datasets are primarily designed for anomaly localization purposes. We intend to consider the localization task in future work, as mentioned at the end of the paper.\n\n[1] Tack et al., \u201cCSI: Novelty detection via contrastive learning on distributionally shifted instances\u201d, NeurIPS 2020.\n\n[2] Tal Reiss and Yedid Hoshen, \u201cMean-shifted contrastive loss for anomaly detection\u201d. AAAI 2023\n\n**Question. The paper mentions superior performance over existing methods, but Table 2 reveals that AnoMem, at best, achieves comparable results in out-of-distribution (OOD) detection. It's important to ensure that the claims made align with the empirical findings.**\n\n**Reply:**\nThank you for your effort for the detailed review. Indeed, we were already aware of the positioning of our results in the literature for OOD detection.\n\nWe have thoroughly reviewed the initial submission and found that we did not explicitly claim superior performance over existing methods for OOD detection. For example, in the abstract, we stated, 'Our model outperforms the state-of-the-art on a wide range of anomalies, including object, style, and local anomalies, as well as face presentation attacks' without specifically mentioning superior performance for OOD. In Section 4.2.2, we began by stating, 'AnoMem performs similarly well as the state-of-the-art baseline CSI.' To eliminate any possible confusion, we have now explicitly mentioned the performance of our method for OOD in the abstract.\nIt is worth noting that for OOD detection with CIFAR10 as ID, CSI and pretrained models need to store 60000 samples, whereas ours only requires 768 samples.\n\n\n**Question. While it may be justifiable not to compare with state-of-the-art pretrained approaches like MSC, given their exposure to external datasets, it remains important to include these comparisons in the evaluation. CIFAR and CUB datasets share similarities with ImageNet-pretrained data, but the FPAD dataset exhibits a significant distribution shift, which calls for a comparative analysis. Additionally, it's worth noting that AnoMem's performance benefits significantly from exposure to anomaly types, which pretrained methods do not rely on.**\n\n**Reply:**\nThank you for your suggestion.\nWe could not find the results of MSC [3] for OOD detection with CIFAR10 as ID, and therefore, we are unable to include them. It is worth highlighting that, although classified as an OC method in Table 1, MSC used ImageNet-1K, signifying its use of approximately 1000 times more data than our OE setting, where we achieved better results.\n\nWe have now included the results of pretrained method MSC [3] for FPAD on WMCA in Table 3. As hypothesized in your remark, the performances of the pretrained method on ImageNet are impacted by the distribution shift.\nFurthermore, we note that AnoMem only benefits from anomalies in the outlier exposure setting, but not in the one-class setting where we still obtain SOTA performance when compared to pre-trained method."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5400/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700690183235,
                "cdate": 1700690183235,
                "tmdate": 1700690183235,
                "mdate": 1700690183235,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8c27IFv6DC",
                "forum": "9o7KuFcsps",
                "replyto": "FRl6TfR0H9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5400/Reviewer_t6Z1"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5400/Reviewer_t6Z1"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for providing detailed results and for responding to my concerns. I have read the author's responses and all other reviews, but I am keeping my rating the same."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5400/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700735647216,
                "cdate": 1700735647216,
                "tmdate": 1700735647216,
                "mdate": 1700735647216,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "6XOAOjzyt9",
            "forum": "9o7KuFcsps",
            "replyto": "9o7KuFcsps",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5400/Reviewer_xRL9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5400/Reviewer_xRL9"
            ],
            "content": {
                "summary": {
                    "value": "The paper analyzes the two most common problems in anomaly detection - the one-class problem and the out-of-distribution problem. It proposes a multi-scale contrastive learning framework for anomaly detection to address these two problems. Regarding the one-class problem and the out-of-distribution problem, the authors believe that the main difference between the two is the scale of the anomaly, and using memory to store normal features at different scales can solve both problems simultaneously. To enhance the detection ability of the model, the paper also introduces a contrastive learning framework to train a feature extractor from scratch to obtain class-sensitive features."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ The paper summarizes the differences between the one-class problem and the out-of-distribution problem, and proposes to combine features at different scales for anomaly detection accordingly.\n+ The paper introduces a contrastive learning framework to enhance the model's perception ability for anomalies at different scales.\n+ The paper validates its effectiveness on a one-class classification dataset for the one-class problem and a fake detection dataset for the out-of-distribution problem."
                },
                "weaknesses": {
                    "value": "+ The motivation behind the paper is very direct, but the authors do not further discuss the benefits of unifying the one-class problem and out-of-distribution problem.\n+ Although the framework of the paper for the one-class problem and out-of-distribution problem is consistent, the paper adds a classifier for the out-of-distribution problem. This may be due to the different evaluation metrics of the two problems, but it makes the two problems slightly disconnected."
                },
                "questions": {
                    "value": "+ Essentially, the authors weight different scales of features to unify the one-class problem and out-of-distribution problem. However, the parameter selection for weighting seems somewhat arbitrary.\n+ The authors mention at the end of the paper that their method can be used for anomaly localization, and the model design does seem to support this. It is possible that the authors did not consider further experiments on this due to unsatisfactory experimental results."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5400/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5400/Reviewer_xRL9",
                        "ICLR.cc/2024/Conference/Submission5400/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5400/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698481586948,
            "cdate": 1698481586948,
            "tmdate": 1700731412258,
            "mdate": 1700731412258,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "l2FGT0QZZ3",
                "forum": "9o7KuFcsps",
                "replyto": "6XOAOjzyt9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5400/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5400/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer xRL9 (1/1)"
                    },
                    "comment": {
                        "value": "Dear reviewer,\nThank you for providing constructive reviews. We have addressed each of your questions individually in our response and hope these clarifications contribute to an improved rating. We have revised the paper according to your feedback, marking the changes in magenta. Additionally, we've highlighted in brown the text that was part of the initial submission, which may have been overlooked.\n\nWe are eager to continue the discussion. Have all your concerns been addressed in our rebuttal, or are there any remaining comments you would like us to consider?\n\n\n**Question. The motivation behind the paper is very direct, but the authors do not further discuss the benefits of unifying the one-class problem and out-of-distribution problem.**\n\n**Reply:**\nThank you for the question. We made this point clearer in the revised paper.\nWe would like to emphasize that AnoMem stands out as the first to be both unified and generic.\n1.  In terms of its unified property, specifically regarding the availability of anomaly samples during training, AnoMem excels in both one-class and imbalanced outlier-exposure settings\u2014a crucial practical feature in real-world scenarios where normal samples are initially available, and anomaly samples are acquired later, a scenario not adequately addressed by existing literature.\n2. Moving on to its generic property, AnoMem demonstrates effectiveness in object-/semantic-level anomaly detection, out-of-distribution (OOD) detection, and also in industrial applications like fine-grained anomaly detection (FPAD). \n3. While not the primary focus of our paper, we further demonstrate that our learning method can enhance the more general task of image classification. This aspect might have been overlooked in the initial submission, where different results for distinct tasks were presented in the same Table 4. To provide a clearer depiction of its capabilities, we have now separated the results for different tasks into Tables 4 and 5.\n\n\n**Question. Although the framework of the paper for the one-class problem and out-of-distribution problem is consistent, the paper adds a classifier for the out-of-distribution problem. This may be due to the different evaluation metrics of the two problems, but it makes the two problems slightly disconnected.**\n\n**Reply:**\nThank you for your question. \nWe did NOT include a classifier specifically for out-of-distribution detection. The additional linear classifier is solely trained to evaluate our learned representation z on image classification tasks using CIFAR-10 and CIFAR-100. The initial submission may have contained some ambiguities due to the merging of results from two distinct tasks, as mentioned earlier. To address this, we have now separated the results for different tasks into two distinct tables (please refer to Tables 4 and 5).\n\n**Question. Essentially, the authors weight different scales of features to unify the one-class problem and out-of-distribution problem. However, the parameter selection for weighting seems somewhat arbitrary.**\n\n**Reply:**\nFor the choice of weights for each scale, we considered two types of monotonically increasing functions to give more weight to the latter scales in which we have more confidence. The results for the two weight functions linear and exponential have been included in Table 7 in Appendix (due to the space limit). As we can see, we obtained better results with the exponential function justifying our choice.\n\n**Question. The authors mention at the end of the paper that their method can be used for anomaly localization, and the model design does seem to support this. It is possible that the authors did not consider further experiments on this due to unsatisfactory experimental results.**\n\n**Reply:**\nThank you for your remark.\nWe do believe that our model could be successfully used for anomaly localization, however not in its current form. Indeed, using the two scales in the latter layers as in our proposed model yields rather low resolution anomaly maps and would have a low AUPRO segmentation metric on datasets such as MVTec. However, as discussed in the paper, adding more scales in earlier layers would result in a substantially slower and larger model. Therefore, the main issue to tackle for an efficient anomaly localization in future work would be to optimize the memory mechanism or use an alternative contrastive scheme that takes less memory per memorized pattern."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5400/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700689550285,
                "cdate": 1700689550285,
                "tmdate": 1700689550285,
                "mdate": 1700689550285,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7pUK4kYa4L",
                "forum": "9o7KuFcsps",
                "replyto": "l2FGT0QZZ3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5400/Reviewer_xRL9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5400/Reviewer_xRL9"
                ],
                "content": {
                    "comment": {
                        "value": "The author has addressed my concerns, and I am willing to increase my score."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5400/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700731395012,
                "cdate": 1700731395012,
                "tmdate": 1700731395012,
                "mdate": 1700731395012,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "dokygmiF35",
            "forum": "9o7KuFcsps",
            "replyto": "9o7KuFcsps",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5400/Reviewer_9JQe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5400/Reviewer_9JQe"
            ],
            "content": {
                "summary": {
                    "value": "This work introduces an approach for contrastive learning of multi-scale memory units for anomaly detection. It applies the idea of contrastive representation learning to prototype-based feature representations for learning multiple memory layers at various intermediate feature layers, and the resulting feature representations can then be used to learn either unsupervised one-class detection models or semi-supervised detection models with some anomaly examples. The approach is evaluated on three one-vs-all one-class classification datasets, one face representation attack detection dataset, and one OOD detection setting using CIFAR-10 as the ID dataset."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The idea of unifying unsupervised one-class anomaly detection and semi-supervised anomaly detection approaches into one framework is interesting. Most methods are focused on the unsupervised case, while some recent studies attempt to tackle a semi-supervised case. I'm not aware of an approach that works well under both cases.\n- I appreciate the efforts of bringing ideas from several research lines (contrastive learning, memory learning, OOD detection, and anomaly detection) together to create an effective anomaly detection method.\n- The method is evaluated using three different tasks and shows effective performance.\n- The method demonstrates good performance on face representation attack detection datasets."
                },
                "weaknesses": {
                    "value": "- It is unclear how much difference it makes by bringing multi-scale learning into the memory learning-based anomaly detection approaches. No appropriate ablation study or empirical comparison is presented there. The baseline in table 4 may be changed to a memory learning method that involves multiple normal prototypes to serve this purpose.\n- As demonstrated in table 4, the multi-scale learning has very limited contribution to the overall detection performance.\n- It mentions at page 4 about the issue of overfitting in existing methods that use a pre-trained encoder on large-scale image datasets, but this issue should be easily fixed by tuning on the target normal data. I cannot find convincing reasons for not using such well pre-trained encoders, and not comparing with such methods. Additionally, in this work, there is the extensive fitting of the multi-scale memory units to the limited normal data in the target data, which could easily lead to overfitting to the normal data, and so the proposed method could perform poorly on datasets with distribution shift. I wonder whether the authors could perform experiments on datasets with distribution shift to justify their argument.\n- The clarity is bad in several aspects. **1)** The memory learning in eqs. 2-4 involves ground truth $y_k$ that could be either $0$ for anomaly or $1$ for normal sample, but in sec. 3.2 there is a one-class AD objective, i.e., eq. 6, where no training anomaly examples are supposed to be available, so I'm confused that how the one-class AD model can be trained together with eqs. 2-4. **2)** The concept of outlier exposure (OE) is defined and used in OOD detection for using external datasets as pseudo OOD examples to train OOD detection models, but in this work it seems it treats real anomaly examples as OE examples. This is very confusing. Rather than using the so-called AD-OE concept, it may be clearer to use semi-supervised AD or open-set AD as in *\"Deep semi-supervised anomaly detection. arXiv preprint arXiv:1906.02694.\"*, *\"Catching both gray and black swans: Open-set supervised anomaly detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 7388-7398).\"*, or *\"Ubnormal: New benchmark for supervised open-set video anomaly detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 20143-20153).\"* **3)** It is also unclear why we need a method that works well for both anomaly detection and OOD detection, given the fact that the two tasks have quite different application settings.\n- Following up the above point, since anomaly examples are used in the training stage, recent SOTA semi-supervised/open-set anomaly detection methods should be used in the experiment comparison to justify the advantages the work has, e.g., see *\"Catching both gray and black swans: Open-set supervised anomaly detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 7388-7398).\"* for some of such methods.\n- Experiments on large-scale high-resolution image datasets, e.g., the popular setting that uses ImageNet-1k as the ID dataset, are missing for the OOD detection task."
                },
                "questions": {
                    "value": "Pls see the above Weaknesses section for detail."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5400/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698828693669,
            "cdate": 1698828693669,
            "tmdate": 1699636546807,
            "mdate": 1699636546807,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "V1eVZQKuWJ",
                "forum": "9o7KuFcsps",
                "replyto": "dokygmiF35",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5400/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5400/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer 9JQe (1/3)"
                    },
                    "comment": {
                        "value": "**Question. It is unclear how much difference it makes by bringing multi-scale learning into the memory learning-based anomaly detection approaches. No appropriate ablation study or empirical comparison is presented there. The baseline in table 4 may be changed to a memory learning method that involves multiple normal prototypes to serve this purpose.**\n\n**Reply:**\nWe include in Tab.5 an additional ablation study on the multi-scale component alone to better measure its impact on anomaly detection. As we can see, the multiple scales by themself improve notably the AD performances on CIFAR-10, CIFAR-100 and WMCA.\n\n**Question. As demonstrated in table 4, the multi-scale learning has very limited contribution to the overall detection performance.**\n\n**Reply:**\nThe limited impact on the overall detection performances of CIFAR-10 and CIFAR-100 can be explained by the low amount of local anomalies in these datasets. By including representations from earlier layers in the network we can help our model to better encompass smaller and finer anomalies that are more represented in WMCA with partial attacks, as can be seen in the **additional ablation results** on WMCA in Table 5.\n\n**Question. It mentions at page 4 about the issue of overfitting in existing methods that use a pre-trained encoder on large-scale image datasets, but this issue should be easily fixed by tuning on the target normal data. I cannot find convincing reasons for not using such well pre-trained encoders, and not comparing with such methods. Additionally, in this work, there is the extensive fitting of the multi-scale memory units to the limited normal data in the target data, which could easily lead to overfitting to the normal data, and so the proposed method could perform poorly on datasets with distribution shift. I wonder whether the authors could perform experiments on datasets with distribution shift to justify their argument.**\n\n**Reply:**\nIn Table 3, we have included additional results for the state-of-the-art pretrained method MSC [Reiss AAAI\u201923] on WMCA. As can be seen, this pretrained model encounters challenges in generalizing to the specific FPAD task, given the substantial distribution shift between the WMCA domain and the ImageNet images that MSC uses to pretrain its model.\n\nThe table also demonstrates the advantage of our simple method (without additional large-scale dataset) in the case of unseen attacks, which can be considered a form of distribution shift.\n\n\nMoreover, one motivation that can favor models without large-scale dataset for pretraining is dataset licensing, especially in the context of industrial applications like FPAD. Indeed, some collected data might not be licensed to be used in a commercial application (e.g. ImageNet21K).\n\n**Question. The memory learning in eqs. 2-4 involves ground truth that could be either  for anomaly or  for normal sample, but in sec. 3.2 there is a one-class AD objective, i.e., eq. 6, where no training anomaly examples are supposed to be available, so I'm confused that how the one-class AD model can be trained together with eqs. 2-4.**\n\n**Reply:**\nFirst, we note that in the first learning stage (Fig. 2a), anomalies are only used to further enrich the contrastive learning scheme (learning the representation z) but not for the memory learning (Mem). Indeed, at any time only normal prototypes are learned.\n\nThe provided equations 2-4 present our framework of representation learning for unified anomaly detection, meaning it can work with or without (special case where =0) anomalies. Nothing circumvents the omission of anomalous samples in the first stage since it is driven by **unsupervised** contrastive learning. We can notice that the only use of the label y_k during the first stage is inside the memory layer Mem(x,y) that act as a pass-through if y=0, i.e. an anomaly.\n\nWe made this point more clear in Sec.3.1 of the revised paper."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5400/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700693351120,
                "cdate": 1700693351120,
                "tmdate": 1700693351120,
                "mdate": 1700693351120,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]