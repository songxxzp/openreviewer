[
    {
        "title": "Observer Uncertainty of Learning in Games from a Covariance Perspective"
    },
    {
        "review": {
            "id": "1lHePF32AA",
            "forum": "Ali45HfJqJ",
            "replyto": "Ali45HfJqJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9150/Reviewer_1edF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9150/Reviewer_1edF"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigates the evolution of observer uncertainty, mainly measured by covariances, in learning dynamics of two-player zero-sum games. The authors focus on the continuous-time FTRL algorithm and its two discretization schemes, Euler and symplectic discretization, which are equivalent to simultaneous and alternating GDA/MWU for certain regularizers. The authors show that for Euclidean regularizer, Euler discretization exponentially amplifies the covariance, while continuous-time FTRL and symplectic discretization amplify the covariance of cumulative strategies polynomially and keep that of cumulative payoffs bounded. As a comparison, the differential entropy of alternating MWU remains constant, which implies that covariance might be a better measurement of observer uncertainty. For general regularizers, the authors establish a Heisenberg-type inequality on variances to demonstrate the tradeoff between strategy spaces and payoff spaces."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The strengths of this paper mainly lie in its novelty.\n1. The authors propose covariance to measure the observer uncertainty and provide evidence to show that it could be a better measurement than differential entropy.\n2. The paper establishes the connection between Euler/symplectic discretization and simultaneous/alternating algorithms through the Hamiltonian system and provides a new perspective to analyze simultaneous and alternating GDA. Moreover, the results demonstrate that the alternating algorithm is more stable than the simultaneous one.\n3. Although I do not check the details of the proofs, I believe they are correct."
                },
                "weaknesses": {
                    "value": "I have some doubts about the significance of this paper and there is room for improvement in the presentation.\n1. Although the authors claim that the 'input uncertainty' is well-motivated, I am still skeptical about this. For a convergent trajectory, measuring such an uncertainty could tell us (i) how fast we approach the solution; (ii) the initialization would not affect the convergence. However, for a non-convergent trajectory, measuring this uncertainty seems only to tell us whether the trajectory remains bounded or how fast it diverges. Although the results in this paper seem solid, I do not know what are the further implications for these cycling or divergent behaviors.\n\n2. Some results related to cumulative strategies lack interpretation.\nThe adaptation of cumulative payoffs is easy to understand because we could map it into the strategy space through $\\nabla h^*$. However, the adaptation of cumulative strategies seems just to facilitate the definition of the Hamiltonian system. Dividing it by $t$ yields a more intuitive meaning, i.e., the averaged strategies. Consequently, I think that the results in Theorem 5.1 could be transformed into those related to averaged strategies. Then the difference between the covariances of averaged strategies and cumulative payoffs can be better analyzed, because they represent the averaged-iterate and last-iterate behavior, respectively. In particular, I think it is also worth discussing the relationship between the results in Theorem 5.1 and the no-regret property of FTRL as well as the convergence of the averaged strategies. Finally, I do not understand the meaning of the covariance between cumulative strategies and payoffs.\n\n3. The form of symplectic discretization may be not rigorous. If we adopt the symplectic Euler method in [1, Theorem VI.3.3], the update rule of $Y^t$ in symplectic discretization (Type I method) should be $Y^{t+1} = Y^{t} - \\eta \\nabla_X H( X^t, Y^{t+1} )$, while the authors use $Y^{t+1} = Y^{t} - \\eta \\nabla_X H( X^t, Y^{t} )$. Although for the Hamiltonian function defined in Proposition 3.1, the two versions are equivalent, I think adopting the latter one may be misleading and less rigorous.\n\n4. The lower bound in Theorem 5.2 involves the covariance, while the amplification rates in Theorem 5.1 only hold for the Euclidean regularizer. For general regularizers, without the amplification rates of the covariance, the result in Theorem 5.2 itself is less meaningful.\n\nMinor concerns\n1. The authors could give more intuition on the definition of the Hamiltonian function.\n2. The dependence of $\\mu$ in Theorem 5.1 on the step size should be clarified.\n3. To capture the exponential growth, one could change the y-axis to a log scale. Similarly, to capture quadratic (or more generally, polynomial) growth rate in figures, one could change both axes to log scales.\n\n[1] Ernst Haier, Christian Lubich, and Gerhard Wanner. Geometric Numerical integration: structure preserving algorithms for ordinary differential equations. Springer, 2006."
                },
                "questions": {
                    "value": "1. The results about differential entropy in Section 4 are in terms of MWU and AltMWU, while covariance evolution results in Theorem 5.1 only hold for the Euclidean regularizer, i.e., GDA and AltGDA. They are not directly comparable. However, in the appendix, the authors say that the results in Section 4 hold for more general regularizers. Why not adopt the same regularizer in the main text or state a more general result in Section 4?\n\n2. In Theorem 5.2, whether $AA^\\top$ is singular has a significant influence on the rate. Could the authors give a more intuitive explanation of this phenomenon without resorting to the matrix"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9150/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9150/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9150/Reviewer_1edF"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9150/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698570903662,
            "cdate": 1698570903662,
            "tmdate": 1699637151452,
            "mdate": 1699637151452,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Cxq6jJ9aZ8",
                "forum": "Ali45HfJqJ",
                "replyto": "1lHePF32AA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9150/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9150/Authors"
                ],
                "content": {
                    "title": {
                        "value": "To reviewer 1edF (1/2)"
                    },
                    "comment": {
                        "value": "We thank you for your careful reading and suggestions in improving the clarity of the paper. We will address your questions and we will be always open for further queries and discussion. Please see our itemized responses below:\n\n >Motivation of 'input uncertainty'  and further implications for these cycling or divergent behaviors. \n\nPlease refer to the second point of the global respond for more discussion on the concept of input uncertainty. As it was shown in previous works, the dynamical behaviors of FTRL is complex, it can exhibit recurrence [1] and chaotic behaviors [2]. However, these properties only provide qualitative descriptions about the hardness of predicting the dynamics of these algorithms. The results in the current paper focus on the quantitative viewpoint, and demonstrates new characteristics of these dynamics, such as the tradeoff between cumulative strategies and payoff. For more discussion on significance, applications if needed see also our related response to Reviewer kXrY.\n\n>The role of cumulative strategies, relationships with convergence of the averaged strategies, and meaning of the covariance between cumulative strategies and payoffs.\n\nCumulative strategies have a nature game-theoretical explanation: they denote the historical frequencies of strategies used by a player, and they also provide a new coordinate system to describe the dynamics of the two players system. Cumulative strategies and payoffs are related by the identity $y_i(t) = y_i(0) + A^{(ij)} X_j(t)$, for $i,j = 1,2$, thus one player's  cumulative strategies can determine another player's cumulative payoff (although the payoff matrix is unknown), this also explain why we can trace the behaviors of a two players system from the viewpoint of a single player.\n\nWe appreciate your suggestion to consider average strategies. Our results on the covariance of cumulative strategies can be used to derive corollaries about the average strategies using the relation $\\text{Var}(X(t)/t) = \\text{Var}(X(t))/t^2$. For example, in the alternating setting, Theorem 5.1 implies that when $AA^{\\top}$ is non-singular, the variance of average strategies tends to $0$ at a rate of $O(1/t^2)$. In case $AA^{\\top}$ is singular, the variance of average strategies tends towards a non-zero value, and this number can be determined through computational methods. This suggests that in such cases, the initial distribution will not concentrate as in non-singular cases.\n\n>The form of symplectic discretization.\n\nThank you for pointing this out, we have fixed this in the update manuscripts. The parts that were modified are  marked by red color.\n \n>The result in Theorem 5.2 itself is less meaningful due to lake of amplification rates of the covariance.\n\nIn addition to providing a numerical lower bound, Theorem 5.2 also offers insight into the tradeoff phenomenon between the standard deviations of cumulative payoffs and strategies for more general regularizers. In the case of GDA, where the standard deviations can be calculated precisely, an example of such a tradeoff phenomenon is presented in figure (1) in the main paper. Note that the maximum points of the curve representing standard deviations of cumulative payoffs coincide with  minimum points of the curve representing standard deviations of cumulative strategies, and vice versa. This insight cannot be obtained by analyzing the growth rate of standard deviations of cumulative payoffs and strategies independently since Theorem 5.1 only indicates that both curves are bounded.\n\n>Intuitions on the definition of the Hamiltonian function.\n\nThe Hamiltonian function used in the current paper comes from [3], and a similar non-canonical Hamiltonian system formulation (also known as a Possion system) for continuous time  mirror descent algorithms is also presented in [4]. Theorem 5.1 of [3] demonstrates that the Hamiltonian function defined here is inherently connected to the Bregman divergence, which is a commonly used concepts in optimization, plus a an additional term determined by the regularizers and equilibrium of the game."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700118420693,
                "cdate": 1700118420693,
                "tmdate": 1700118420693,
                "mdate": 1700118420693,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "j9V7pl8Yb8",
                "forum": "Ali45HfJqJ",
                "replyto": "tWki9rxnYz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9150/Reviewer_1edF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9150/Reviewer_1edF"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "Thank the authors for their detailed response. I have no further questions now and I keep my score."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700558736687,
                "cdate": 1700558736687,
                "tmdate": 1700558736687,
                "mdate": 1700558736687,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "HbiQArMro0",
            "forum": "Ali45HfJqJ",
            "replyto": "Ali45HfJqJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9150/Reviewer_kXrY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9150/Reviewer_kXrY"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the evolution of uncertainty or observation accuracy in game dynamics by characterizing the growth rate of a certain covariance information. In particular, they focus on two-player zero-sum games and the continuous-time FTRL with different regularizers, as well as two discretization methods, namely Euler and sympletic. The theoretical results reveal that the symplectic discretization improves the accuracy of prediction in game dynamics, which is also confirmed experimentally."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper provides a novel characterization of continuous-time FTRL and discretizations thereof in two-player zero-sum games. The new results are also connected to earlier works (such as Cheung and Piliouras (2020) and Cheung (2022)). The separation in the behavior of  Euler versus sympletic discretization is also conceptually interesting. Furthermore, the results are non-trivial from a technical standpoint, combing tools from different areas. It is possible that such techniques could be of independent interest for future work in this area. The results appear to be sound; I did not find any notable issue.\n\nIn terms of the presentation, the writing overall is clear, and the key ideas are carefully explained. It was generally easy to follow the paper."
                },
                "weaknesses": {
                    "value": "The main issue I have is with regards to the motivation and the significance of the results. Although the authors already attempt to discuss about the motivation in quite length in the introduction, I still cannot see any concrete motivation or applications for those results. Overall, the paper provides throughout several facts about the game dynamics but without explaining the significance of the characterization. Can the authors provide some actual applications where the new results can be relevant? Otherwise the results appear to some extent artificial."
                },
                "questions": {
                    "value": "A couple of minor stylistic issues:\n\n1. Footnotes should come after punctuation marks\n2. The references are not used appropriately; for example Go Silver et al. (2016) should instead be Go (Silver et al.)"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9150/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9150/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9150/Reviewer_kXrY"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9150/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698602331936,
            "cdate": 1698602331936,
            "tmdate": 1699637151307,
            "mdate": 1699637151307,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TKYxJMybwo",
                "forum": "Ali45HfJqJ",
                "replyto": "HbiQArMro0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9150/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9150/Authors"
                ],
                "content": {
                    "title": {
                        "value": "To reviewer kXrY"
                    },
                    "comment": {
                        "value": "We thank you for your careful reading and suggestions in improving the clarity of the paper. We will address your questions and we will be always open for further queries and discussion. Please see our itemized responses below:\n\n>Motivation, significance of the results, and actual applications.\n\nPlease refer to the global respond for more explanation of the motivation.\n\nFor the significance : Game dynamics particularly based on zero-sum like game are seminal components in standard AI architectures such as GANS [1] (7000+ refs), PSRO [2] (600+ refs) and are actually useful even in n-player games (Diplomacy [3]) The typical way to control such dynamics so far has been to aim/hope for global convergence to equilibrium, however, there are many hurdles to this tasks both from a computational perspective [4,5] as well as from a dynamical systems perspective [6]. Here we aim at a different type of \"stability\" altogether. Stability/predictability of orbits *without* needing to converge to Nash as a necessary intermediary step from proving stability. By showing that this is possible we open the door for new multi-agent AI architectures that although maybe design around the pipe-dream of global  convergence they can still be practically useful. \n\nActual applications: (Computer Poker). Poker is of course a standard benchmark for AI and a real world application.  This direction of work could provide some insights behind the empirical success of CFR+ [7,8] in poker. CFR+ is a variant of Counter Factual Regret (CFR) minimization [9] with improved empirical performance. A key difference between CFR+ and vanilla CFR is switching from simultaneous updates to alternating updates. Our results provide some hints on why this could lead to increased performance. Increased orbit stability, reduced payoff variances due to symplectic-like discretization would lead to faster time average convergence to equilibrium and thus improved performance. Of course our current work is not on CFR and extensive form games but normal form games, nevertheless, we believe these are promising steps that provide a new vocabulary to study such real-world systems.  \n\n>Minor stylistic issues :\n\nThank you for pointing out these issues. We have fixed these issues and updated the manuscript in the system. Footnotes are moved after punctuation marks, and the references have been unified in the (authors,year) format. Thank you again!\n\n We hope these can address your concerns, and we are always open to future discussions.\n\nReferences:\n\n[1] Goodfellow, Ian, et al. \"Generative adversarial networks.\" Communications of the ACM 63.11 (2020): 139-144.\n\n[2] Lanctot, Marc, et al. \"A unified game-theoretic approach to multiagent reinforcement learning.\" Advances in neural information processing systems 30 (2017).\n\n[3] Meta Fundamental AI Research Diplomacy Team (FAIR)\u2020, et al. \"Human-level play in the game of Diplomacy by combining language models with strategic reasoning.\" Science 378.6624 (2022): 1067-1074.\n\n[4] Daskalakis, Constantinos, et al. \"The complexity of computing a Nash equilibrium.\" Communications of the ACM 52.2 (2009): 89-97.\n\n[5] Daskalakis, Constantinos, et al. \"The complexity of constrained min-max optimization.\" Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing. 2021.\n\n[6] Milionis, Jason, et al. \"An impossibility theorem in game dynamics.\" Proceedings of the National Academy of Sciences 120.41 (2023): e2305349120.\n\n[7] Oskari Tammelin. Solving large imperfect information games using cfr+. arXiv preprint\narXiv:1407.5042, 2014\n\n[8]    Michael Bowling et al. Heads-up limit holdem\npoker is solved. Science, 347(6218):145\u2013149, 2015.\n\n[9]  Martin Zinkevich et al. Regret minimization in games with incomplete information. In Advances in neural information processing systems, pages 1729\u20131736, 2008."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700117743931,
                "cdate": 1700117743931,
                "tmdate": 1700117916208,
                "mdate": 1700117916208,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PaGmNg93Vg",
                "forum": "Ali45HfJqJ",
                "replyto": "TKYxJMybwo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9150/Reviewer_kXrY"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9150/Reviewer_kXrY"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the Response"
                    },
                    "comment": {
                        "value": "I thank the authors for their response. I agree with the authors that understanding the effectiveness of alternating dynamics is an important question, which is currently poorly understood. My main concern at the moment is that there is a considerable gap between the results and the applications mentioned above, for example understanding CFR+ in poker. But the paper still makes an interesting step towards a better understanding of alternating dynamics. I have no further questions at the moment."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700418414143,
                "cdate": 1700418414143,
                "tmdate": 1700418414143,
                "mdate": 1700418414143,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tn6XaAObzj",
                "forum": "Ali45HfJqJ",
                "replyto": "HbiQArMro0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9150/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9150/Authors"
                ],
                "content": {
                    "title": {
                        "value": "About actual applications"
                    },
                    "comment": {
                        "value": "Thank you for your replying and interests to the application of our results. We have realized that the concern is about the specific application scenarios of our results. We guess the \"gap\" might refer to two possibilities, and we explain on both of them. If we have missed the point, please leave comments and we are happy to provide futher information.\n1. If the gap means the model we consider and the applications mentioned, then the actual applications follows:\n\n    First of all, we consider zero-sum games which is a model of multi-agent systems in AI, our results serves directly in any scenarios where zero-sum matrix games are involved.\n\n    Secondly, in areas like GANs, theory of zero-sum games are studied as a simlified case to provide theoretical explanation to phenomenon from GANs (and other computer games), or provide theoretical guidence on algorithm designs. \n\n    Thirdly, understanding algorithms in bilinear matrix games is a first and fundamental step towards general setting that actual captures models in real world. Recall that the standard approach on learning algorithms in min-max optimization is the following: \n    $$\\text{zero-sum matrix game=>convex-concave game=>non-convex non-concave game},$$\n   This is why we mentioned that current results have given promising steps on future works.\n\n2. If the gap refers to the application of variance/covariance, we argue that\n    The real-life application of variance/covariance is often tied with concentration inequalities. Let's take Chebyshev inequalities for example $$Pr(|X>\\mu|>k\\sigma)<\\frac{1}{k^2}.$$\nBy results of Theorem 5.1, we know that $\\text{Var}X^t_i$ is of $\\Theta(t^2)$. Say $\\text{Var}X^t_i=ct^2$ (the formulation of $\\text{Var}X^t_i$ can be explicitly determined according to our analysis process in Appendix C.2.3, using the information provided by the payoff matrix and initial conditions), and then we have\n$$\\text{Pr}(|X^t_i-\\mu|>k\\sqrt{c}t)<\\frac{1}{k^2}$$\nfor any $k>1$. Therefore, we have concrete estimate of the probability for $X^t_i$ to deviate from the mean at **Each Iterate**, which captures the accuracy of prediction in each iterate. For the cumulative payoff $y^t_i$, the alternating play keeps variance bounded, i.e., $\\text{Var}y^t_i=\\mathbb{E}|y_i^t-\\mu|^2\\le c$ and this implies (using Markov inequality)\n$$\\text{Pr}(|y^t_i-\\mu|>k)<\\frac{c}{k^2},$$\nwhich also captures the accuracy of prediction of payoff, e.g., the probability of $y^t_i$ to be greater than $\\mu+10$ or less than $\\mu-10$ is less than $c/100$.\n\nThank you again for your feedback. Please let us know whether we have addressed the \"actual application\" concern or further clarifying is needed."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700568152935,
                "cdate": 1700568152935,
                "tmdate": 1700568916325,
                "mdate": 1700568916325,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EtupG3f5Q3",
                "forum": "Ali45HfJqJ",
                "replyto": "HbiQArMro0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9150/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9150/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Have we addressed your concerns?"
                    },
                    "comment": {
                        "value": "Dear reviewer kXrY,\n\nSince the discussion time is coming to an end, may I ask if our response have solved your concerns? Please let us know if further clarifying is needed, and we are always open to provide additional discussion. If our answers have resolved your concerns, we would greatly appreciate it if you could consider updating your recommendation accordingly. Thank you again for your feedback !"
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700681909745,
                "cdate": 1700681909745,
                "tmdate": 1700682013321,
                "mdate": 1700682013321,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "BV3FoH2X3w",
            "forum": "Ali45HfJqJ",
            "replyto": "Ali45HfJqJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9150/Reviewer_3XfB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9150/Reviewer_3XfB"
            ],
            "content": {
                "summary": {
                    "value": "The authors study the observer uncertainty in deterministic learning dynamics of zero-sum games with random initializations. They explore the follow-the-regularized-leader (FTRL) algorithm in two-player zero-sum games and analyze its continuous-time as well as Euler and symplectic discretization dynamics. They give bounds on the growth rate of the covariance variables (cumulative payoff and cumulative strategy) during evolution for CT, Euler and symplectic cases for L2 and negentropy regularizations. They also establish a Heisenberg-type uncertainty inequality for variances of variables under CT, Euler and symplectic dynamics under general regularizers. Furthermore, they demonstrate by analysis and numerical experiments that symplectic discretization improves the accuracy of prediction in learning dynamics."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The uncertainty inequality for general regularizers and its connection to Hamiltonian systems seem interesting and original. Motivation, objevtives and results are stated clearly.. Theoretical results are also easy to follow."
                },
                "weaknesses": {
                    "value": "related works can be discussed more comprehensively.  the limitations of the results and assumptions can be eloborated more to make it easier to follow."
                },
                "questions": {
                    "value": "I don't have any questions to authors."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9150/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9150/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9150/Reviewer_3XfB"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9150/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699080874913,
            "cdate": 1699080874913,
            "tmdate": 1699637151190,
            "mdate": 1699637151190,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "csczjp4w3L",
                "forum": "Ali45HfJqJ",
                "replyto": "BV3FoH2X3w",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9150/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9150/Authors"
                ],
                "content": {
                    "title": {
                        "value": "To reviewer 3XfB"
                    },
                    "comment": {
                        "value": "Thank you for your supportive comments and interest to our work! We have added more discussions on related works, please see our global respond. We will be always open for further queries and discussion."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700117543655,
                "cdate": 1700117543655,
                "tmdate": 1700118920311,
                "mdate": 1700118920311,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "iXRrhNMgft",
            "forum": "Ali45HfJqJ",
            "replyto": "Ali45HfJqJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9150/Reviewer_snif"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9150/Reviewer_snif"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigate the evolution of observer uncertainty in the Follow-the-Regularized-Leader dynamics for learning to solve zero-sum games. The authors prove concrete rates of covariance evolution for different discretization schemes. The proofs rely on the techniques from symplectic geometry for analysing the evolution of uncertainty."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The authors provide rigorous, theoretical analysis for the uncertainty in the Follow-the-Regularized-Leader dynamics for learning to solve zero-sum games. The proofs are given in detail. The paper is well written."
                },
                "weaknesses": {
                    "value": "I would say this paper is not well-motivated. I appreciate the mathematical rigour of the theory, but can hardly see how it is useful for machine learning. The authors are needed to clarify why we need to study this problem, and how the results would contribute to the community in the context of machine learning (such as understanding algorithms or designing new algorithms?)\n\nI am also concerned about the novelty. The first 5 pages do not include new theory. Section 4 seems directly from Cheung et al. (2022). The proofs for Section 5 heavily rely on existing results - a very large proportion of the \"proofs\" are actually quoting existing papers, and the new part seems actually combining existing lemmas/propositions, or simple matrix calculations. Please clarify.\n\nI was excited to see the abstract talks about Heisenberg Uncertainty Principle, but later found little theory is really relevant - please consider removing \"Heisenberg Uncertainty Principle\" or giving more discussion."
                },
                "questions": {
                    "value": "Please address the above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9150/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9150/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9150/Reviewer_snif"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9150/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699194526173,
            "cdate": 1699194526173,
            "tmdate": 1700675138401,
            "mdate": 1700675138401,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZEsy0ogp0n",
                "forum": "Ali45HfJqJ",
                "replyto": "iXRrhNMgft",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9150/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9150/Authors"
                ],
                "content": {
                    "title": {
                        "value": "To reviewer snif (1/2)"
                    },
                    "comment": {
                        "value": "Thank you for your careful reading and suggestions in improving the clarity of the paper.  We will clarify the issues in revision. Please see our itemized responses below:\n\n>This paper is not well-motivated. \n\nPlease refer to our global respond. \n    \n>\u201cI am also concerned\u2026simple matrix calculations.\u201d\n\nWe are trying to address this comment but we found the descriptions are too vague. It would be great if the reviewer can make the points specific so that we can address the concerns. To elaborate:\n     \n>\"The first 5 pages do not include new theory.\"\n\nYes, the first 5 pages are devoted to explaining the setting, motivation, and background material related to our work. Since we are combining ideas, tools and techniques from different fields such as online learning (e.g. GDA/MWU/AltMWU), game theory (strategies/zero-sum games), dynamical systems (Hamiltonians), information theory (differential entropy) and statistics (covariance), we clearly need some space to establish the necessary vocabulary for the reader.  We believe that given the breadth of the ideas explored, we are actually using space rather efficiently. If the reviewer believes otherwise, we will be happy to hear some concrete suggestions about which parts are superfluous and should be cut out.\n\n>\"Section 4 seems directly from Cheung et al. (2022).\"\n\nThis is not true. Both the theoretical results and proof strategies of section 4 in the current paper are different from Cheung et al. (2022).\n           \nFirstly,  Cheung et al. (2022) didn't consider how differential entropy evolve in the alternating play setting. In Proposition 4.2, we prove\nthe differential entropy keeps constant in the alternating play setting, thus the concept of differential entropy can not capture the uncertainty evolution in the alternating play setting. This also motivate us to seek other measure of uncertainty evolution.\n           \nSecondly, the proof by Cheung et al. (2022) involves a complex calculation on the Jacobian of the multiplicative weights update algorithm, which is difficult to generalize to the alternating play setting due to its requirement for two strategies updating. Our proof of Proposition 4.2 simplifies this kind of calculation by establishing a connection between symplectic discretization and the alternating play setting (Proposition 3.1). Please refer to the discussion below Proposition 4.2 in the paper for more detailed explanations on the differences of the proof strategies."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700116884268,
                "cdate": 1700116884268,
                "tmdate": 1700116884268,
                "mdate": 1700116884268,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "9bIgTVZ42x",
                "forum": "Ali45HfJqJ",
                "replyto": "va3L45XEyu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9150/Reviewer_snif"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9150/Reviewer_snif"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your response. My previous concerns are largely clear. The \"global\" response needs to be clearly included in your paper. A discussion on the novelty and significance of your proofs is also needed. I'm willing to raise my score."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700675087160,
                "cdate": 1700675087160,
                "tmdate": 1700675087160,
                "mdate": 1700675087160,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]