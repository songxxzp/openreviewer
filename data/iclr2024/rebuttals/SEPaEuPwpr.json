[
    {
        "title": "SOI: Scaling down computational complexity by estimating partial states of the model"
    },
    {
        "review": {
            "id": "ulX1c0R6HF",
            "forum": "SEPaEuPwpr",
            "replyto": "SEPaEuPwpr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7827/Reviewer_LqQF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7827/Reviewer_LqQF"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a novel method called Scattered Online Inference (SOI) that aims to reduce the computational complexity of Artificial Neural Networks (ANNs) while maintaining their performance. The SOI method is based on the principles of partial predictions of the network's future state, a two-phase system involving data compression using strided convolutions and reconstruction through extrapolation, achieving an RNN-like inference pattern within CNNs by leveraging the capabilities of Short-Term Memory Convolution (STMC) layers, preserving the causal nature of the optimized network architecture, and being applicable to single-frame online inference."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Originality: The proposed SOI method is a creative combination of existing ideas and techniques, such as strided convolutions, STMC layers, and partial predictions, to achieve a unique approach to reducing computational complexity in ANNs.\n\nQuality: The authors have provided a thorough explanation of the SOI method, its underlying principles, and its implementation, as well as experimental results demonstrating the effectiveness of the method in reducing computational complexity while maintaining performance.\n\nClarity: The paper is well-written and organized, with clear explanations of the concepts and methods involved, making it easy for readers to understand the proposed approach and its implications.\n\nSignificance: The SOI method addresses an important challenge in the field of ANNs, particularly for real-time applications and small appliances where energy consumption and time are crucial factors. By reducing the computational complexity of ANNs, this method has the potential to enable more efficient deployment of neural networks in such scenarios."
                },
                "weaknesses": {
                    "value": "The paper could benefit from a more comprehensive comparison with other existing methods for reducing computational complexity in ANNs, highlighting the specific advantages and potential limitations of the SOI method compared to alternative approaches.\n\nWhile the authors have provided experimental results for the audio separation and acoustic scene classification tasks, it would be beneficial to see the performance of the SOI method in other application domains, to demonstrate its generalizability and potential impact across different types of problems. \n\nIn the experimental results presented in Table 2, the SOI method, when compared to STMC, does not show a significant difference in complexity for the closest SI-SNRi metric: STMC achieves 7.69 with 100% complexity, while Predictive 1 achieves 7.41 with 96.3% complexity. It is worth noting that a slight compromise in performance metrics can lead to a significant reduction in model complexity. Therefore, the claim of computational optimization in the abstract, which states a 64.4% reduction in computational complexity at the cost of 9.8% of SI-SNRi for the PP variant, and a 41.9% reduction at the cost of 7.70% SI-SNRi with the FP variant, may not be entirely convincing, as similar results might be achievable by simply reducing the model size without necessarily relying on the SOI method.\nA more fair comparison should be made on the same performance level with different complexities or the same complexity level with different performances. From the experiments, I did not see a significant advantage of the SOI method compared to STMC in this regard."
                },
                "questions": {
                    "value": "How does the SOI method perform when applied to other types of ANNs, such as Recurrent Neural Networks (RNNs) or Transformer-based models? Can the method be easily adapted to these architectures?\n\nAre there any specific types of problems or application domains where the SOI method is particularly well-suited or might encounter difficulties? If so, could the authors provide some insights into the factors that contribute to these differences in performance?\n\nCan the SOI method be combined with other techniques for model optimization, such as pruning or quantization, to further improve efficiency and performance? If so, are there any potential trade-offs or challenges that need to be considered when combining these methods?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7827/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698719619494,
            "cdate": 1698719619494,
            "tmdate": 1699636958778,
            "mdate": 1699636958778,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KA3alkuSk5",
                "forum": "SEPaEuPwpr",
                "replyto": "ulX1c0R6HF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7827/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7827/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Hello! We are thankful for the constructive feedback and the pointers on how to improve on our work. We carefully studied the input of all the reviewers and made the best effort to thoroughly address the main concerns in the limited time frame. Due to the limited resources, the presented results should be treated as preliminary and we strongly believe that larger gains could be achieved after more extensive parameter tuning.\n\nThe main concern regarding our research was raised about limited comparison with other methods as well as constrained application domain. We have addressed these issues by extending our experiments with video action recognition tasks utilizing ResNet and MoViNet architectures. The latter is used with so-called stream buffers, which additionally shows the possibility of applying the SOI without the STMC. The experiments showed that the application of SOI leads to the improvement of the performance for chosen task in the video domain.\n\nTo improve the understanding of distinctive properties and differences of SOI and STMC we designed experiments showing that the application of strided convolutions improves the results when the predictive inference is required. It is a crucial observation because depending on the application, one may be interested in minimization of either an average or a maximal cost of the inference of a single frame, and thus inclined to choose between a partially or a fully predictive inference modes. To accustom the readers with STMC we have added an appendix with a brief overview of STMC.\n\nSOI was designed as an overlay to STMC in order to address STMC's shortcomings. We strongly believe that the model's computational complexity can be further reduced by applying the pruning method. Assuming the correctness of the Lottery Ticket Hypothesis, pruning can effectively reduce model's size without affecting the performance, and thus can be utilized as a next optimization step after application of STMC and/or SOI. Early preliminary results of such an approach are presented in appendix G. Further research on that matter is currently in progress and we intend to publish it as a separate study.\n\nPlease let us answer to all your questions and concerns:\n\n> The paper could benefit from a more comprehensive comparison with other existing methods for reducing computational complexity in ANNs, highlighting the specific advantages and potential limitations of the SOI method compared to alternative approaches.\n\n> In the experimental results presented in Table 2, the SOI method, when compared to STMC, does not show a significant difference in complexity for the closest SI-SNRi metric: STMC achieves 7.69 with 100% complexity, while Predictive 1 achieves 7.41 with 96.3% complexity. It is worth noting that a slight compromise in performance metrics can lead to a significant reduction in model complexity. Therefore, the claim of computational optimization in the abstract, which states a 64.4% reduction in computational complexity at the cost of 9.8% of SI-SNRi for the PP variant, and a 41.9% reduction at the cost of 7.70% SI-SNRi with the FP variant, may not be entirely convincing, as similar results might be achievable by simply reducing the model size without necessarily relying on the SOI method. A more fair comparison should be made on the same performance level with different complexities or the same complexity level with different performances. From the experiments, I did not see a significant advantage of the SOI method compared to STMC in this regard.\n\nWe hope that the added experiments in Appendices E-G will strengthen our paper. Please note that there are not a lot of methods that we can compare against as SOI can work alongside most (if not all) of state-of-the-art methods, like any type of pruning.\n\n> While the authors have provided experimental results for the audio separation and acoustic scene classification tasks, it would be beneficial to see the performance of the SOI method in other application domains, to demonstrate its generalizability and potential impact across different types of problems.\n\nWe added the experiment with an application of SOI to the video action recognition task in Appendix E.\n\n> How does the SOI method perform when applied to other types of ANNs, such as Recurrent Neural Networks (RNNs) or Transformer-based models? Can the method be easily adapted to these architectures?\n\nPlease be informed that our method can work in RNN. In fact we have the RNN-based model that works with SOI but we are planning to release it separately as in that model there is much more going on than just SOI. Another reason to not include RNN in our current research is that this paper already has 19 pages and we would like keep it concise and easy to understand."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7827/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700741020938,
                "cdate": 1700741020938,
                "tmdate": 1700741020938,
                "mdate": 1700741020938,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wni7z1DimC",
            "forum": "SEPaEuPwpr",
            "replyto": "SEPaEuPwpr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7827/Reviewer_iRws"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7827/Reviewer_iRws"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses the challenge of deploying artificial neural networks (ANNs) on small consumer electronics, such as wireless in-ear headphones, smartwatches, and AR glasses. Despite advancements in Microcontroller Units (MCUs), these devices still struggle to run state-of-the-art ANNs efficiently, especially in time-sensitive scenarios.\nIn this work, the main contribution goes to\n1. Introduction of Scattered Online Inference (SOI):\n- SOI significantly reduces the computational complexity of artificial neural networks, especially in deeper layers, by leveraging the continuity and seasonality in time-series data for extrapolation and processing speed improvements.\n- The method enables real-time processing of time-series data element by element, transforming conventional CNN models for online inference and addressing challenges associated with strided convolutions.\n2. Efficiency and Performance in Real-Time Systems:\n- SOI offers substantial computational savings with two patterns of inference: a 64.4% reduction in computational complexity for Partially Predictive (PP) and a 41.9% reduction (plus an additional 28.7% reduction in inference time) for Fully Predictive (FP), with minimal impact on performance.\n- The method is particularly beneficial for small consumer electronics in real-time scenarios, providing a solution for applying state-of-the-art DNNs without extensive model compression.\n3. Minimal Architectural Changes with Ecological and Economic Impact:\n- SOI achieves its efficiency gains with minimal alterations to the network architecture, making it versatile for various applications where time and energy consumption are critical.\n- The method addresses the need for energy-efficient neural systems, highlighting its importance from both ecological and economic perspectives."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "**Originality:**\nThe paper introduces Scattered Online Inference (SOI), a novel method that stands out for its innovative approach to reducing computational complexity in artificial neural networks, particularly for real-time applications on small devices. Building upon the Short-Term Memory Convolution (STMC) technique, SOI provides a unique treatment of strided layers and introduces a new inference pattern, showcasing a commendable level of originality. The method\u2019s ability to transform conventional CNN models for online inference while addressing challenges associated with strided convolutions further emphasizes its inventive nature.\n\n**Quality:**\nThe quality of the paper is evident in its comprehensive approach to addressing a significant problem in the field of artificial neural networks. The authors present two distinct patterns of inference, Partially Predictive (PP) and Fully Predictive (FP), and provide quantitative results demonstrating substantial reductions in computational complexity alongside minimal impact on performance. The method\u2019s applicability to real-time systems and small consumer electronics, as well as its consideration of energy efficiency, reflect a high standard of research quality. \n\n**Clarity:**\nThe paper is well-structured, providing a clear introduction to the problem, a detailed description of the SOI method, and a presentation of the results achieved. The authors succeed in explaining complex concepts in an accessible manner, making the paper comprehensible to a broad audience. \n\n**Significance:**\nSOI\u2019s potential impact is substantial, particularly in the realm of small consumer electronics and real-time systems where computational efficiency is paramount. The method\u2019s ability to achieve significant reductions in computational complexity without extensive model compression is a notable advancement, addressing a critical need in the field. Furthermore, the paper\u2019s emphasis on energy efficiency and its ecological and economic implications highlight the broader significance of the research, contributing to the ongoing discourse on sustainable and efficient computing practices."
                },
                "weaknesses": {
                    "value": "**Limited Comparison:** The paper could be strengthened by including a more comprehensive comparison with other state-of-the-art methods would further enhance the paper's quality.\n\n**Generalization:**\n\n- *Focus on CNNs:* The paper primarily discusses the application of SOI to convolutional neural networks (CNNs). While this is a significant contribution, the generality of the method could be questioned if it is not easily adaptable or applicable to other neural network architectures. And for CNN, the only baseline lies on STMC which seems not generalizable.\n\n- *Limited to Audio-Related Tasks*: The paper provides examples and results primarily related to audio separation and acoustic scene classification tasks. Demonstrating the effectiveness of SOI across a wider variety of use cases and domains would strengthen its generality and appeal to a broader audience."
                },
                "questions": {
                    "value": "9.8% reduction in metrics of speech spearation task seems significant to me, could you provide some context to justify this reduction is minor? for example, you can claim in another paper, their performance drop is much more like xx.x% when complexity is 50% so that reader can know 9.8% is minor in a rought impression."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7827/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698819914349,
            "cdate": 1698819914349,
            "tmdate": 1699636958645,
            "mdate": 1699636958645,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Ya7VHXQyJ3",
                "forum": "SEPaEuPwpr",
                "replyto": "wni7z1DimC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7827/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7827/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Hello! We are thankful for the constructive feedback and the pointers on how to improve on our work. We carefully studied the input of all the reviewers and made the best effort to thoroughly address the main concerns in the limited time frame. Due to the limited resources, the presented results should be treated as preliminary and we strongly believe that larger gains could be achieved after more extensive parameter tuning.\n\nThe main concern regarding our research was raised about limited comparison with other methods as well as constrained application domain. We have addressed these issues by extending our experiments with video action recognition tasks utilizing ResNet and MoViNet architectures. The latter is used with so-called stream buffers, which additionally shows the possibility of applying the SOI without the STMC. The experiments showed that the application of SOI leads to the improvement of the performance for chosen task in the video domain.\n\nTo improve the understanding of distinctive properties and differences of SOI and STMC we designed experiments showing that the application of strided convolutions improves the results when the predictive inference is required. It is a crucial observation because depending on the application, one may be interested in minimization of either an average or a maximal cost of the inference of a single frame, and thus inclined to choose between a partially or a fully predictive inference modes. To accustom the readers with STMC we have added an appendix with a brief overview of STMC.\n\nSOI was designed as an overlay to STMC in order to address STMC's shortcomings. We strongly believe that the model's computational complexity can be further reduced by applying the pruning method. Assuming the correctness of the Lottery Ticket Hypothesis, pruning can effectively reduce model's size without affecting the performance, and thus can be utilized as a next optimization step after application of STMC and/or SOI. Early preliminary results of such an approach are presented in appendix G. Further research on that matter is currently in progress and we intend to publish it as a separate study.\n\nPlease let us answer to all your questions and concerns:\n\n> Limited Comparison: The paper could be strengthened by including a more comprehensive comparison with other state-of-the-art methods would further enhance the paper's quality.\n\nWe believe that added experiments in Appendices E-G will strengthen our paper. Please note that there are not a lot of methods that we can compare to as the SOI will work alongside most (if not all) of state-of-the-art methods like any type of pruning.\n\n> Focus on CNNs: The paper primarily discusses the application of SOI to convolutional neural networks (CNNs). While this is a significant contribution, the generality of the method could be questioned if it is not easily adaptable or applicable to other neural network architectures. And for CNN, the only baseline lies on STMC which seems not generalizable.\n\nWe believe that the contribution to just CNNs is still substantial. Please be informed that our method can work in RNN, in fact we have the RNN-based model that work with SOI but we are planning to release it separately as in this model there is much more going on than just SOI. Another reason to not include RNN is that this paper already has 19 pages and we would like keep it concise and easy to understand. \n\n> Limited to Audio-Related Tasks: The paper provides examples and results primarily related to audio separation and acoustic scene classification tasks. Demonstrating the effectiveness of SOI across a wider variety of use cases and domains would strengthen its generality and appeal to a broader audience.\n\nWe added video action recognition task in Appendix E.\n\n> 9.8% reduction in metrics of speech spearation task seems significant to me, could you provide some context to justify this reduction is minor? for example, you can claim in another paper, their performance drop is much more like xx.x% when complexity is 50% so that reader can know 9.8% is minor in a rought impression.\n\nSOI is quite adaptable and can provide the range of complexity reductions at different cost. In our case those 9.8% of SI-SNRi do not contribute significantly to the output of a model and from our experience and experiments such difference is not detectible by a human listeners during blind tests (in this specific case)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7827/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740811048,
                "cdate": 1700740811048,
                "tmdate": 1700740811048,
                "mdate": 1700740811048,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vOja3N9u7j",
            "forum": "SEPaEuPwpr",
            "replyto": "SEPaEuPwpr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7827/Reviewer_o3ho"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7827/Reviewer_o3ho"
            ],
            "content": {
                "summary": {
                    "value": "The authors proposed a method for reducing the computational cost of a convolutional neural\nnetwork by reusing network partial states from previous inferences, leading to a generalization of\nthese states over longer time periods. The authors claimed that the proposed method achieves a computational cost reduction of 50% without any drop in metrics in the ASC task and a 64.4% reduction in computational cost with only a 9.8% reduction in metrics for the speech separation task. After the comparison, the paper implied that the proposed method offers an alternative to the STMC solution for strided convolution."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The authors introduced two possible patterns of inference achievable\nwith SOI - Partially Predictive (PP) and Fully Predictive (FP). For the audio separation task,  64.4% reduction was achieved in computational complexity at the cost of 9.8% of SI-SNRi for the PP variant, and a 41.9% reduction at the cost of 7.70% SI-SNRi with the FP variant. Moreover, the latter variant reduces inference time by an additional 28.7%. Similar results are also presented for the acoustic\nscene classification task with a model based on the GhostNet architecture. From this sense, I personally believe that the authors' work provides another option for reducing time cost for time-series data processing with reasonable explanation through the details of the experiment results and corresponding theoretical analytics."
                },
                "weaknesses": {
                    "value": "I would suggest adding at least two more experiments to the experiment part to strengthen and demonstrate the advantages of the proposed method. Although the current experiment is cool, to better support the authors' theory, it is always good to shoot some or more real application cases with sound results."
                },
                "questions": {
                    "value": "no more question"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "no concerns"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7827/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699179381698,
            "cdate": 1699179381698,
            "tmdate": 1699636958544,
            "mdate": 1699636958544,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0GFgx3xN8L",
                "forum": "SEPaEuPwpr",
                "replyto": "vOja3N9u7j",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7827/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7827/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Hello! We are thankful for the constructive feedback and the pointers on how to improve on our work. We carefully studied the input of all the reviewers and made the best effort to thoroughly address the main concerns in the limited time frame. Due to the limited resources, the presented results should be treated as preliminary and we strongly believe that larger gains could be achieved after more extensive parameter tuning.\n\nThe main concern regarding our research was raised about limited comparison with other methods as well as constrained application domain. We have addressed these issues by extending our experiments with video action recognition tasks utilizing ResNet and MoViNet architectures. The latter is used with so-called stream buffers, which additionally shows the possibility of applying the SOI without the STMC. The experiments showed that the application of SOI leads to the improvement of the performance for chosen task in the video domain.\n\nTo improve the understanding of distinctive properties and differences of SOI and STMC we designed experiments showing that the application of strided convolutions improves the results when the predictive inference is required. It is a crucial observation because depending on the application, one may be interested in minimization of either an average or a maximal cost of the inference of a single frame, and thus inclined to choose between a partially or a fully predictive inference modes. To accustom the readers with STMC we have added an appendix with a brief overview of STMC.\n\nSOI was designed as an overlay to STMC in order to address STMC's shortcomings. We strongly believe that the model's computational complexity can be further reduced by applying the pruning method. Assuming the correctness of the Lottery Ticket Hypothesis, pruning can effectively reduce model's size without affecting the performance, and thus can be utilized as a next optimization step after application of STMC and/or SOI. Early preliminary results of such an approach are presented in appendix G. Further research on that matter is currently in progress and we intend to publish it as a separate study.\n\nPlease let us answer to all your questions and concerns:\n\n> I would suggest adding at least two more experiments to the experiment part to strengthen and demonstrate the advantages of the proposed method. Although the current experiment is cool, to better support the authors' theory, it is always good to shoot some or more real application cases with sound results.\n\nWe added 3 new sections to appendix. \n\nIn Appendix E, we added experiment with action recognition task from video data to show that our method works well in other domains. In this section we also applied SOI to MoViNets which we used with their original \u2018stream buffers\u2019 method instead of STMC to show that it can also work with methods similar to STMC.\n\nIn Appendix F, we compare our method to resampling using common resampling methods.\n\nIn Appendix G, we show that our method works well with pruning which is commonly used in our scenario."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7827/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740717643,
                "cdate": 1700740717643,
                "tmdate": 1700740717643,
                "mdate": 1700740717643,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7u6GaRol67",
            "forum": "SEPaEuPwpr",
            "replyto": "SEPaEuPwpr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7827/Reviewer_sLXH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7827/Reviewer_sLXH"
            ],
            "content": {
                "summary": {
                    "value": "The authors present a method called scattered online inference that applies strides to convolutional processing of time series data, and performing partial or full prediction for extrapolating values in between. The authors test this method on a number of benchmarks and show that their method can get close to the performance of STMC."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The method seems to provide significant computational savings without too big a big drop in performance."
                },
                "weaknesses": {
                    "value": "I found it very hard to piece together what the authors have done in this paper: the problem being solved, the specific application domain, the specific format of the input, the differences from STMC etc. The authors seem to depend entirely on the STMC and other papers to provide this context. I had to read a number of previous papers to understand even the context of the paper. The authors need to give more background in the main text.\n\nThe empirical comparisons also seem very limited, including only STMC and some variants of their method."
                },
                "questions": {
                    "value": "There are various presentation issues. Examples:\n- Fig. 1: C and E seem identical.\n- Sec. 2.2: X seems to have length N and N also seems to be the number of samples.\n- in Abstract, second to last sentence: Not clear what latter refers to\n- Fig. 2 caption has two B). Seems to be off by one."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7827/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699548729892,
            "cdate": 1699548729892,
            "tmdate": 1699636958400,
            "mdate": 1699636958400,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "zKZZA9tzbE",
                "forum": "SEPaEuPwpr",
                "replyto": "7u6GaRol67",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7827/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7827/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Hello! We are thankful for the constructive feedback and the pointers on how to improve on our work. We carefully studied the input of all the reviewers and made the best effort to thoroughly address the main concerns in the limited time frame. Due to the limited resources, the presented results should be treated as preliminary and we strongly believe that larger gains could be achieved after more extensive parameter tuning.\n\nThe main concern regarding our research was raised about limited comparison with other methods as well as constrained application domain. We have addressed these issues by extending our experiments with video action recognition tasks utilizing ResNet and MoViNet architectures. The latter is used with so-called stream buffers, which additionally shows the possibility of applying the SOI without the STMC. The experiments showed that the application of SOI leads to the improvement of the performance for chosen task in the video domain.\n\nTo improve the understanding of distinctive properties and differences of SOI and STMC we designed experiments showing that the application of strided convolutions improves the results when the predictive inference is required. It is a crucial observation because depending on the application, one may be interested in minimization of either an average or a maximal cost of the inference of a single frame, and thus inclined to choose between a partially or a fully predictive inference modes. To accustom the readers with STMC we have added an appendix with a brief overview of STMC.\n\nSOI was designed as an overlay to STMC in order to address STMC's shortcomings. We strongly believe that the model's computational complexity can be further reduced by applying the pruning method. Assuming the correctness of the Lottery Ticket Hypothesis, pruning can effectively reduce model's size without affecting the performance, and thus can be utilized as a next optimization step after application of STMC and/or SOI. Early preliminary results of such an approach are presented in appendix G. Further research on that matter is currently in progress and we intend to publish it as a separate study.\n\nPlease let us answer to all your questions and concerns:\n\n> I found it very hard to piece together what the authors have done in this paper: \n\n> -\tthe problem being solved, \n\nReduction of computational complexity of NN models for real-time processing without imposing additional latency.\n\n> -\tthe specific application domain, \n\nTime-series data, Real-time processing. Beside that there is no specific domain.\n\n> -\tthe specific format of the input, \n\nThe specific format of the input depends on the used network but in all cases it needs to be time-series. In our speech separation task and ASC task we used spectrograms in BCFT format (B-batch, C-channels, F-frequency, T-time). \n\n> The authors seem to depend entirely on the STMC and other papers to provide this context. I had to read a number of previous papers to understand even the context of the paper. The authors need to give more background in the main text.\n\nAdding more context in main text is impossible as there is the 9 page limit for main text. Therefore we added more context on STMC in Appedix A and referenced it in Introduction so readers can familiarize themselves with STMC to the level that should be sufficient to understand the paper. In Appendix E, we also showed that this method does not entirely depend on STMC as we applied it with \u2018stream buffers\u2019 method in place of STMC.\n\n> The empirical comparisons also seem very limited, including only STMC and some variants of their method.\n\nIn appendix E, we added experiment with action recognition task from video data using ResNet-10 architecture and MoViNets in A0 and A1 variants. This experiment also proves that our method is not dependent on STMC as with MoViNets utlize \u2018stream buffers\u2019.\n\nIn appendix F we added comparison of our method to common resampling methods which can be used to reduce computational complexity as well.\n\nIn appendix G we show how our method works with pruning.\n\n> Fig. 1: C and E seem identical.\n\nFig. 1C and Fig. 1E are not identical as operation in Fig. 1E has an additional shift in time represented by relative position of time frames in time axis (time axis is also depicted). Position of frames in time is important as it defines how we interpret them throughout the network and at output. As this was not clear we added cropping to Fig. 1E to make it easier to follow.\n\n> Sec. 2.2: X seems to have length N and N also seems to be the number of samples.\n\nYes, 1D vector X Is composed of N samples and that\u2019s why it has length N.\n\n\n> in Abstract, second to last sentence: Not clear what latter refers to\n\nModified to clearly state that this sentence refers to FP variant of SOI\n\n> Fig. 2 caption has two B). Seems to be off by one.\n\nFixed. Thank you!"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7827/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740654647,
                "cdate": 1700740654647,
                "tmdate": 1700740654647,
                "mdate": 1700740654647,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]