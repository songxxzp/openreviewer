[
    {
        "title": "Directional Rank Reduction for Backdoor Defense"
    },
    {
        "review": {
            "id": "uuzRX1XOFc",
            "forum": "7QlKLvfVge",
            "replyto": "7QlKLvfVge",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9434/Reviewer_X3hw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9434/Reviewer_X3hw"
            ],
            "content": {
                "summary": {
                    "value": "This paper argues that existing pruning-based defense methods can be ineffective at times and introduces Directional Rank Reduction (DRR) to identify toxic directions. In this study, the method approximates the target direction by maximizing the third central moment, supported by rigorous theoretical justification, and constructs a projection matrix to eliminate the toxic direction. DRR demonstrated outstanding performance in terms of both accuracy (ACC) and adversarial success rate (ASR)."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This study shows an interesting finding that the backdoor trigger effects are not always aligned with fixed dimensions of the feature space, pruning-based methods are usually ineffective.\n2. The proposed DRR method performed well on both ACC and ASR compared to other methods."
                },
                "weaknesses": {
                    "value": "1. In the first equation on Page 3, it seems feasible to do the defense by reducing the norm of the residual matrix to align the benign and poisoned features seems feasible. The features from benign examples move towards the backdoored features. Does the movement hurt the model's clean performance?\n\n2. The last equation on Page 4 has a strong assumption that all the clean examples are centered around the mean of them. Namely, the method assumes that the distances from all the clean examples to the example center are the same. The examples marked as yellow in Figure 1 are distributed like a circle. However, the real-world data distribution often deviates from the assumption. The distribution could be elliptical-like. In this case, the obtained v is not optimal anymore.\n\n3. In the third row of Table 2, DRR achieves a better trade-off. Why it demonstrates a higher accuracy (ACC) instead of a lower ASR?\n\n4. This approach requires the optimization of a vector in each layer, which could be expensive. \n\nminor: All the equations are not numbered!"
                },
                "questions": {
                    "value": "1. \"How the direction vector v is initialized in the paper, and do different initialization methods lead to varying results?\n\n2. In Figure 2, the value of C for certain layers is not significant. Is it possible to skip some layers when computing v?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9434/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698700123582,
            "cdate": 1698700123582,
            "tmdate": 1699637188449,
            "mdate": 1699637188449,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PrWVf7MhIH",
                "forum": "7QlKLvfVge",
                "replyto": "uuzRX1XOFc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9434/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9434/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "### Weakenesses:\n\n#### W1: In the first equation on Page 3, it seems feasible to do the defense by reducing the norm of the residual matrix to align the benign and poisoned features seems feasible. The features from benign examples move towards the backdoored features. Does the movement hurt the model's clean performance?\n\nAnswer: As we points out in our paper, rank reduction is an extension of neuron pruning (which is also a modification of the weight matrix). Established neuron pruning techniques, such as CLP and EP, have been demonstrated to maintain model performance effectively post-pruning. Our rank reduction, which 1) remove only one rank (instead of multiple ranks in neuron pruning) and 2) remove more targetedly to the direction that related to the backdoor behavior should intuitively affect less to the performance than pruning methods in general. Empirically, we show that our method affects the less on the performance compare to the previous method.\n\n#### W2: The last equation on Page 4 has a strong assumption that all the clean examples are centered around the mean of them. Namely, the method assumes that the distances from all the clean examples to the example center are the same. The examples marked as yellow in Figure 1 are distributed like a circle. However, the real-world data distribution often deviates from the assumption. The distribution could be elliptical-like. In this case, the obtained v is not optimal anymore.\n\nAnswer: We appreciate the opportunity to clarify a potential misunderstanding highlighted by the reviewer regarding the assumptions underlying our method. Contrary to the reviewer's interpretation, our approach does not assume uniform distances of all clean examples from their mean, nor does it presuppose a circular distribution of data points as depicted in Figure 1. The shape of the ellipse in a multivariate Gaussian distribution is determined by its covariance matrix. Only when the covariance matrix is *isotropic*, which means the variance along all directions are the same, the data is distributed like a circle as mentioned by the reviewer. However, we *do not* put any constraints on whether the covariance is isotropic or not. The only assumption about the covariance matrix we made is assumption 2, which limits the maximum variance of the data distribution. Hence, an elliptical-like distribution is considered in our method, where the Gaussian distribution has a covariance matrix that is not isotropic.\n\nThe equation on page 4, which the reviewer refers to, formulates an optimization problem. The objective of this problem is to determine an optimal unit direction vector that maximizes the third central moment when data is projected onto this vector. The stipulation that the vector be of unit length is a constraint applied to the direction vector itself, rather than to the data samples. This is a standard practice in such optimization problems to ensure the direction vector is normalized and hence, the focus is on the direction rather than the magnitude.\n\n#### W3: In the third row of Table 2, DRR achieves a better trade-off. Why it demonstrates a higher accuracy (ACC) instead of a lower ASR?\n\n\nAnswer: We appreciate the reviewer's insightful observation and recognize the necessity of providing a clearer explanation in our manuscript. The comparatively minimal impact on model performance observed in our study can be attributed to our method's strategy of removing at most one rank per layer. This approach is considerably more conservative than traditional neuron pruning methods, which often entail the removal of multiple ranks. If the number of ranks is tuned to more according to specific scenario, DRR can achieve even lower ASR.\n\n\n\n#### W4: This approach requires the optimization of a vector in each layer, which could be expensive.\n\nAnswer: We appreciate the inquiry regarding the computational efficiency of our approach.\nPrimarily, the optimization process can be parallelized across different network layers, offering a substantial decrease in the required time for optimization. Furthermore, in scenarios with high feature dimensions or large dataset sizes, dimensionality reduction through Principal Component Analysis (PCA) can be employed prior to the directional learning phase. This step effectively reduces the computational burden. Subsequently, the learned direction within this reduced space is projected back onto the original space, thereby economizing on memory and computational demands while preserving the integrity of the optimization process."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9434/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700568976755,
                "cdate": 1700568976755,
                "tmdate": 1700568976755,
                "mdate": 1700568976755,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "FOfbfWgp15",
            "forum": "7QlKLvfVge",
            "replyto": "7QlKLvfVge",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9434/Reviewer_1xjT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9434/Reviewer_1xjT"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a novel backdoor defense method, which utilizes rank reduction to mitigate backdoor in the model. The idea of rank reduction is interesting and brings a new insight into the area."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The idea is novel and provides a new insight.\n2. This paper is technically sound and easy to follow.\n3. The experimental results demonstrate its effectiveness in backdoor defense."
                },
                "weaknesses": {
                    "value": "1.Although this work is interesting, it has a limitation. This paper assumes the defender can get access to the backdoored image. However, this is hard to get in actual situations and thus limits its use greatly. I wonder whether it works without these backdoored data.\n2. The backdoor attacks that this paper test is not enough. I suggest the authors to test the newest input-specific backdoor attacks in 2022. It's important to identify whether this method can achieve SOTA."
                },
                "questions": {
                    "value": "1.Does it work without the attacker's backdoored data?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9434/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9434/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9434/Reviewer_1xjT"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9434/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698722151547,
            "cdate": 1698722151547,
            "tmdate": 1699637188322,
            "mdate": 1699637188322,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "i08xwXSbBJ",
                "forum": "7QlKLvfVge",
                "replyto": "FOfbfWgp15",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9434/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9434/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank the reviewer for their appreciation of our work. Below, we have provided our response to the reviewer's concerns.\n\n### Weakenesses:\n\n#### W1: Although this work is interesting, it has a limitation. This paper assumes the defender can get access to the backdoored image. However, this is hard to get in actual situations and thus limits its use greatly. I wonder whether it works without these backdoored data. \n\nAnswer: First, to answer the reviewer's final question, the rank reduction framework can be adpated to *any* scenarios with or *without* backdoored data, but the metric we adopt to obtain the direction, i.e., third central moment, requires the access to the backdoored data. If other metrics is later being invented to obtain the direction, then the method could be backdoored data-free. \n\nSecond, we want to argue that the scenario in which the defender has access to the full dataset is a prevalent assumption within the backdoor attack research community, exemplified by the concept of adopting a third-party dataset as discussed in [1]. Some of methodologies that employ this setting are outlined in: [2, 3, 4, 5].\n\n[1] Li, Y., Jiang, Y., Li, Z. and Xia, S.T., 2022. Backdoor learning: A survey. IEEE Transactions on Neural Networks and Learning Systems.\n[2] Chen, B., Carvalho, W., Baracaldo, N., Ludwig, H., Edwards, B., Lee, T., Molloy, I. and Srivastava, B., Detecting Backdoor Attacks on Deep Neural Networks by Activation Clustering.\n[3] Zheng, R., Tang, R., Li, J. and Liu, L., 2022. Pre-activation Distributions Expose Backdoor Neurons. Advances in Neural Information Processing Systems, 35, pp.18667-18680.\n[4] Tran, B., Li, J. and Madry, A., 2018. Spectral signatures in backdoor attacks. Advances in neural information processing systems, 31.\n[5] Hayase, J., Kong, W., Somani, R. and Oh, S., 2021, July. Spectre: Defending against backdoor attacks using robust statistics. In International Conference on Machine Learning (pp. 4129-4139). PMLR.\n\n#### W2: The backdoor attacks that this paper test is not enough. I suggest the authors to test the newest input-specific backdoor attacks in 2022. It's important to identify whether this method can achieve SOTA.\n\nAnswer: Actually, the experiments with IAB and WaNet, which are both input-specific backdoor attacks, are in the paper. Please refer to Table 2 in our submitted paper to see our results tested on input-aware dynamic attack (IAB) and Warping-based backdoor attack (WaNet).\n\nMoreover, we conduct more experiments on other types of attacks (AdaptiveBlend, SIG and Smooth), where the results is as shown below:\n|                 |               | Backdoored |        | FP    |       | ANP   |       | EP    |       | CLP   |       | DRR   |      |\n|-----------------|---------------|------------|--------|-------|-------|-------|-------|-------|-------|-------|-------|-------|------|\n|                 |               | ACC        | ASR    | ACC   | ASR   | ACC   | ASR   | ACC   | ASR   | ACC   | ASR   | ACC   | ASR  |\n| ResNet-18       | AdaptiveBlend | 94.79      | 100.00 | 89.47 | 5.29  | 82.18 | 0.30  | 94.43 | 1.74  | 93.68 | 33.52 | 90.25 | 3.79 |\n|                 | SIG           | 94.01      | 98.22  | 88.94 | 45.70 | 89.38 | 2.36  | 87.36 | 30.84 | 89.75 | 94.28 | 87.10 | 0.07 |\n|                 | Smotth        | 94.59      | 100    | 87.12 | 100   | 92.65 | 81.23 | 94.24 | 3.99  | 87.24 | 89.03 | 94.03 | 3.58 |\n| WideResNet-28-1 | AdaptiveBlend | 92.37      | 100.00 | 84.77 | 51.88 | 82.06 | 42.70 | 90.45 | 5.18  | 84.40 | 74.57 | 91.13 | 0.86 |\n|                 | SIG           | 84.03      | 96.20  | 82.65 | 5.22  | 81.37 | 0.00  | 83.82 | 0.00  | 84.04 | 0.00  | 82.85 | 0.00 |\n|                 | Smotth        | 92.19      | 100    | 84.52 | 6.32  | 89.98 | 100   | 91.45 | 8.78  | 91.29 | 9.03  | 91.88 | 2.74 |"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9434/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700563232996,
                "cdate": 1700563232996,
                "tmdate": 1700563232996,
                "mdate": 1700563232996,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LsvjaIpscH",
            "forum": "7QlKLvfVge",
            "replyto": "7QlKLvfVge",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9434/Reviewer_niUP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9434/Reviewer_niUP"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a fascinating new method for backdoor defense in neural networks. The key idea of projecting the \"toxic direction\" that maximizes the difference between clean and poisoned features is novel and seems promising.\n\nThe theoretical analysis provides valuable insights into the limitations of standard neuron pruning approaches. Framing the problem as rank reduction along arbitrary directions rather than fixed neuron directions is a significant conceptual shift."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The idea of maximizing the third central moment is enjoyable. This idea yields a novel insight.\n2. The connection between neuron pruning and rank reduction is also an exciting topic.\n3. The visualization of the separation constant C provides good justification for the theoretical assumptions."
                },
                "weaknesses": {
                    "value": "1.\tMore experiments can be conducted (BadNet, Blended, CLA, WaNet, and IAB are insufficient.) The authors can consider attacks like SIG [1] and low frequency (Smooth) [2]. Since your method also took latent separability as an assumption, Adapt-blend and Adapt-patch attacks [3] should also be considered. Evaluating robustness to adaptive attacks that try to evade the defense would be useful to understand limitations.\n2.\tThe references and notations should be clarified. For example, what is the reference to Proposition 1? \n3.\tAlso, the readability and organization of this paper need to be improved. It is better if an algorithm is provided.\n\n[1] A new backdoor attack in cnns by training set corruption ICIP 2019\n\n[2] Rethinking the Backdoor Attacks\u2019 Triggers: A Frequency Perspective ICCV2021\n\n[3] Revisiting the Assumption of Latent Separability for Backdoor Defenses, ICLR 2023"
                },
                "questions": {
                    "value": "1.\tThe memory and computational complexity could be analyzed more thoroughly, especially how the approach scales with larger datasets/models. Are there ways to make the optimization more efficient?\n3.\tHow many extension directions v_i have you used?\n4.\tModifying the weight matrix may cause a performance drop in many cases. How can your projection keep the performance?\n5.\tThe proof needs to be more rigorous. Why use the consequence of the proof in the middle of the proof?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9434/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698763361807,
            "cdate": 1698763361807,
            "tmdate": 1699637188186,
            "mdate": 1699637188186,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bj0QsOajip",
                "forum": "7QlKLvfVge",
                "replyto": "LsvjaIpscH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9434/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9434/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank the reviewer for the detailed review. We will make changes based on the feedback. Please see our responses:\n\n### Weaknesses:\n\n#### W1: More experiments can be conducted (BadNet, Blended, CLA, WaNet, and IAB are insufficient.) The authors can consider attacks like SIG [1] and low frequency (Smooth) [2]. Since your method also took latent separability as an assumption, Adapt-blend and Adapt-patch attacks [3] should also be considered. Evaluating the robustness of adaptive attacks that try to evade the defense would be useful for understanding limitations.\n\nAnswer: We've conducted experiments according to the reviewer's suggestions. The results are shown below:\n|                 |               | Backdoored |        | FP    |       | ANP   |       | EP    |       | CLP   |       | DRR   |      |\n|-----------------|---------------|------------|--------|-------|-------|-------|-------|-------|-------|-------|-------|-------|------|\n|                 |               | ACC        | ASR    | ACC   | ASR   | ACC   | ASR   | ACC   | ASR   | ACC   | ASR   | ACC   | ASR  |\n| ResNet-18       | AdaptiveBlend | 94.79      | 100.00 | 89.47 | 5.29  | 82.18 | 0.30  | 94.43 | 1.74  | 93.68 | 33.52 | 90.25 | 3.79 |\n|                 | SIG           | 94.01      | 98.22  | 88.94 | 45.70 | 89.38 | 2.36  | 87.36 | 30.84 | 89.75 | 94.28 | 87.10 | 0.07 |\n|                 | Smotth        | 94.59      | 100    | 87.12 | 100   | 92.65 | 81.23 | 94.24 | 3.99  | 87.24 | 89.03 | 94.03 | 3.58 |\n| WideResNet-28-1 | AdaptiveBlend | 92.37      | 100.00 | 84.77 | 51.88 | 82.06 | 42.70 | 90.45 | 5.18  | 84.40 | 74.57 | 91.13 | 0.86 |\n|                 | SIG           | 84.03      | 96.20  | 82.65 | 5.22  | 81.37 | 0.00  | 83.82 | 0.00  | 84.04 | 0.00  | 82.85 | 0.00 |\n|                 | Smotth        | 92.19      | 100    | 84.52 | 6.32  | 89.98 | 100   | 91.45 | 8.78  | 91.29 | 9.03  | 91.88 | 2.74 |\n\nNote that the latent separability mentioned in the paper [3] only considers the latent space in the penultimate layer, while our methods utilize the separability within each layer of the model. This makes our method effective even when the penultimate layer feature is inseparable.\n\n\n#### W2: The references and notations should be clarified. For example, what is the reference to Proposition 1?\n\nAnswer: The reviewer's request for clarification on the references and notations is acknowledged. However, regarding the reference for Proposition 1, it should be noted that to the extent of our understanding, Proposition 1 is introduced for the first time in our manuscript. Consequently, there are no prior publications to cite for this proposition.\n\n\n#### W3: Also, the readability and organization of this paper need to be improved. It is better if an algorithm is provided.\n\nAnswer: We appreciate the feedback regarding the clarity and structural aspects of our manuscript. Recognizing the value that an algorithmic representation would add, we have taken the suggestion into consideration and will include a detailed algorithm in the revised draft to enhance comprehension of our proposed method."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9434/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700563095598,
                "cdate": 1700563095598,
                "tmdate": 1700644200998,
                "mdate": 1700644200998,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Z5ysjYl4EJ",
            "forum": "7QlKLvfVge",
            "replyto": "7QlKLvfVge",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9434/Reviewer_7hoR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9434/Reviewer_7hoR"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a rank reduction based defense against backdoor attack. Specifically, it first gives a feature-based objective to show the optimal solution to achieve the best defense effect. He then discussed the previous defense's problem based on the given objective and proposes DRR, the rank reduction based defense where aims to find a vector that would maximize the 3rd central moments of the mixed distribution. The proposed method have been verified in CIFAR10 with several backdoor methods. The result shows the proposed method could achieve a little better performance with the state-of-art defense."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper is well-written and easy to follow with only several typos.\n2. The proposed method has some good theoretical analysis and could be meaningful for the future work."
                },
                "weaknesses": {
                    "value": "1. Some of theoretical analysis might be not accurate. The utility function is defined using ||R-\\gamma_r (R)|| and also ||R||-||\\gamma_r (R)||. However, these two value is not strict equivalent. It also happens in the definition of E(R).\n2. It is unclear why the 3rd center moment would show the best performance to measure the difference. In other words, would 2nd order moment or 1st order work as well? Since 3rd order is the main metric selected, the author should explain the choice in detail.\n3. The experiment is pretty insufficient. It only covers one datasets with only one poisoning rate. I suggest the author to give a more comprehensive experiments to show their proposed method's effectiveness. Some standard setting in https://github.com/SCLBD/backdoorbench is recommended.\n\nMinor typo:\nMissing \\hat{x} in the definition of E(R(l)."
                },
                "questions": {
                    "value": "Please refer to the weaknesses part. To sum, \n1. Why does ||R-\\gamma_r (R)|| =||R||-||\\gamma_r (R)|| along with  E(R)?\n2. Why does 3rd central moment is selected?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9434/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699175723821,
            "cdate": 1699175723821,
            "tmdate": 1699637188077,
            "mdate": 1699637188077,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4dNPQa0xFq",
                "forum": "7QlKLvfVge",
                "replyto": "Z5ysjYl4EJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9434/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9434/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate the reviewer's thorough review and have taken their comments into consideration. Here are our responses to their concerns:\n\n### Weaknesses:\n\n#### W1: Some of theoretical analysis might be not accurate. The utility function is defined using $||R-\\gamma (R)||$ and also $||R||-||\\gamma (R)||$. However, these two value is not strict equivalent. It also happens in the definition of $E(R)$.\n\nAnswer: We thank the reviewer for pointing this out. Indeed, the equation $||R-\\gamma(R)||=||R||-\\gamma(R)||$ doesn't hold in the general case. However, it does hold when we use the proposed $L_{1, 1}$ norm, as defined in Definition 1. It makes sense if we specify the norm before introducing this equation. We acknowledge that the organization of this section needs to be corrected to avoid misleading the reader.\n\n#### W2: It is unclear why the 3rd center moment would show the best performance to measure the difference. In other words, would 2nd order moment or 1st order work as well? Since 3rd order is the main metric selected, the author should explain the choice in detail.\n\n\nAnswer: We clarified our choice in the revision of the paper. The first central moment (the mean of the data), doesn't make sense in this context. Because the mean only affects the position of the data center, which isn't related to the direction of the mean difference. The second central moment yields similar conclusions when it is constrained with the assumptions made in the paper. However, in practice, we find the third central moment works much better. To some extent, the third central moment not only increases with the mean difference but also with the asymmetry of the two clusters. In backdoor attacks, the amount of benign data is usually much larger than poisoned data, which cannot be captured by the second central moment. That's why the third central moment performs better than the second central moment in our scenarios.\n\n\n#### W3: The experiment is pretty insufficient. It only covers one datasets with only one poisoning rate. I suggest the author to give a more comprehensive experiments to show their proposed method's effectiveness. Some standard setting in https://github.com/SCLBD/backdoorbench is recommended.\n\nAnswer: Following the reviewer's suggestion, we conducted additional experiments on GTSRB. The results indicate that our method performs well in this context too. It's noteworthy that our attack with CLA on GTSRB didn't succeed, which is also the case in the BackdoorBench.\n\n|                 |              | Backdoored |        | FP    |       | ANP   |        | EP    |       | CLP   |       | DRR   |      |\n|-----------------|--------------|------------|--------|-------|-------|-------|--------|-------|-------|-------|-------|-------|------|\n|                 |              | Backdoored |        | FP    |       | ANP   |        | EP    |       | CLP   |       | DRR   |      |\n|                 |              | ACC        | ASR    | ACC   | ASR   | ACC   | ASR    | ACC   | ASR   | ACC   | ASR   | ACC   | ASR  |\n| ResNet-18       | BadNets      | 95.28      | 100.00 | 91.74 | 0.35  | 91.10 | 4.64   | 94.49 | 0.33  | 94.64 | 0.79  | 94.93 | 0.68 |\n|                 | BadNets(A2A) | 95.31      | 95.94  | 88.56 | 10.85 | 94.13 | 1.79   | 94.74 | 0.06  | 94.79 | 0.13  | 95.11 | 0.48 |\n|                 | Blended      | 95.87      | 99.88  | 90.44 | 3.00  | 91.91 | 3.20   | 94.92 | 0.29  | 94.68 | 0.97  | 95.04 | 0.79 |\n|                 | CLA          | 96.29      | 0.09   | 90.82 | 0.61  | 96.14 | 0.80   | 95.53 | 0.13  | 94.32 | 0.14  | 96.21 | 0.10 |\n|                 | Average      | 95.69      | 73.98  | 90.39 | 3.70  | 93.32 | 2.61   | 94.92 | 0.20  | 94.61 | 0.51  | 95.32 | 0.51 |\n| WideResNet-28-1 | BadNets      | 94.37      | 99.99  | 90.86 | 11.94 | 80.70 | 100.00 | 93.90 | 0.33  | 87.09 | 11.11 | 93.00 | 0.45 |\n|                 | BadNets(A2A) | 92.27      | 91.72  | 89.37 | 32.90 | 75.48 | 48.18  | 90.56 | 1.01  | 92.13 | 0.97  | 90.70 | 1.71 |\n|                 | Blended      | 94.68      | 99.75  | 90.51 | 11.35 | 86.06 | 99.52  | 92.86 | 10.26 | 93.96 | 0.26  | 92.82 | 3.07 |\n|                 | CLA          | 95.31      | 0.09   | 89.09 | 0.71  | 94.98 | 0.50   | 94.57 | 0.10  | 95.27 | 0.20  | 95.41 | 0.09 |\n|                 | Average      | 94.16      | 72.89  | 89.96 | 14.23 | 84.31 | 62.05  | 92.97 | 2.93  | 92.11 | 3.14  | 92.98 | 1.33 |"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9434/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700562882605,
                "cdate": 1700562882605,
                "tmdate": 1700562994581,
                "mdate": 1700562994581,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]