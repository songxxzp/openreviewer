[
    {
        "title": "The Role of Representation Transfer in Multitask Imitation Learning"
    },
    {
        "review": {
            "id": "6O99EjxyRB",
            "forum": "IQZicPtADC",
            "replyto": "IQZicPtADC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3065/Reviewer_Fs7F"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3065/Reviewer_Fs7F"
            ],
            "content": {
                "summary": {
                    "value": "This paper provides a statistical guarantee for multitask imitation learning for improved sample efficiency. Their contribution builds on others work such as Arora et al by using the Rademacher complexity. Using this they have a tighter bound which will provide benefits of transferring for imitation learning. With theoretical insights, they provide empirical results while comparing with multitask behavioral cloning. The environments they utilize are Cartpole, Frozen Lake, Pendulum, Cheetah, and Walker."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "With the experiments, you have measured some scenarios in both discrete and continuous domains to show that it works. The additional experiments in the supplementary material show the amount of rigor especially with showing the task diversity metric.\n\nThe motivation of the theory makes sense and you provide a good amount of related works to show the relevance of the significance."
                },
                "weaknesses": {
                    "value": "Writing\nYou state in the abstract \u201creadily extended to account for commonly used neural network architectures such as multilayer perceptron and convolutional network with realistic assumptions\u201d It would strengthen this claim if you had experiments with convolutional networks to show that it can be done. If not please reconsider modifying your claim.\n\nIn the theoretical contributions paragraph in page one, what do you mean by the second sentence, is that from the Arora et al. paper, if so please say that it refers to that because it sounds off?\n\nExperiment\nFor the BC baseline, it seems like an easy one to compare and in the SM you have BC with 2|D| would it not be appropriate to also show that similar comparison with the main text experiments to show what if BC had more |D| to what your method has?"
                },
                "questions": {
                    "value": "Please refer to the weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3065/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3065/Reviewer_Fs7F",
                        "ICLR.cc/2024/Conference/Submission3065/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3065/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698380052705,
            "cdate": 1698380052705,
            "tmdate": 1700514723877,
            "mdate": 1700514723877,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "rTcmSG0ZDw",
                "forum": "IQZicPtADC",
                "replyto": "6O99EjxyRB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank reviewer Fs7F for their feedback. Thank you for emphasizing the signficance and rigor of our work.\n\n**W1:** Thank you for pointing this out. Our statement here refers to the theoretical result that we derived. However, as suggested by you and reviewer Eicc, we aim to provide extra analysis on a new task with image-based observations shortly.\n\n**W2:** Thank you for pointing out the clarity issue in our statement. Our sentence aims to describe that Arora et al. provided a statistical bound that holds in expectation---while this is an interesting bound, in practice we are given a particular target task. Practitioners may want to know the sample complexity of the particular transfer which is described by a high-probability bound.\n\n**W3:** Thank you for the constructive feedback. We will include an extra ablation on larger number of demonstrations shortly during the discussion period.\n\nFinally, is there any specific improvements that we can make to increase the score? Thank you reviewer Fs7F for your feedback again!"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700111029731,
                "cdate": 1700111029731,
                "tmdate": 1700111029731,
                "mdate": 1700111029731,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "H67hcbxgzV",
                "forum": "IQZicPtADC",
                "replyto": "6O99EjxyRB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you reviewer Fs7F for suggesting to run an extra ablation on BC. We have updated our manuscript to include this result on page 29, figures 11 and 12. Our experiment includes running BC on 10 target tasks per environment, each with 5 random seeds. We normalize the returns as each target task may have different performance range.\n\nAs expected, as we increase the amount of data to 4x and 8x, BC performs very closely to the expert with very low variance. While one may question the usage of multitask imitation learning, we note that the premise of pre-training using other source data is to reduce the amount of target data required. Recall that figures 3 and 4 on page 7 already demonstrates that generally we have achieved this.\n\nWe thank you again for the suggestion and we are happy to continue our discussions on this work."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700150644896,
                "cdate": 1700150644896,
                "tmdate": 1700432816099,
                "mdate": 1700432816099,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KjpxwhACyu",
                "forum": "IQZicPtADC",
                "replyto": "H67hcbxgzV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_Fs7F"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_Fs7F"
                ],
                "content": {
                    "title": {
                        "value": "Re"
                    },
                    "comment": {
                        "value": "Thank you for providing the rebuttal. With the other experiments provided, I will increase my score."
                    }
                },
                "number": 30,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700514707318,
                "cdate": 1700514707318,
                "tmdate": 1700514707318,
                "mdate": 1700514707318,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "jeJ6P5hW83",
            "forum": "IQZicPtADC",
            "replyto": "IQZicPtADC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3065/Reviewer_F18A"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3065/Reviewer_F18A"
            ],
            "content": {
                "summary": {
                    "value": "This paper discusses the advantages of using transferred representations in multitask imitation learning. The authors propose that such transfer can improve the efficiency of learning the target task by using representations learned from sufficiently diverse and related tasks, which can lead to a reduced need for data when training on a new task. They provide theoretical guarantee to support the idea that representation transfer is beneficial, which can be extended to neural network architectures such as multilayer perceptron and convolutional networks. The paper also provides empirical analysis that validate the theoretical findings. Experiments are done in simulated environments to show that leveraging data from diverse source tasks can indeed improve learning efficiency on new tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is well organized and nicely written. The contributions are outlined and well emphasized, and the settings/backgrounds are well introduced. Definitions and theorem are formally stated and discussed with remarks. \n- Theoretical results are reasonable as far as I read into. Extensive discussions are provided in the appendix.\n- The topic on multi-task representation learning is interesting and important."
                },
                "weaknesses": {
                    "value": "- It would be better to state clearly in the main paper about what assumptions are made in the paper and discuss about the limitations.  \n- It is difficult to read Figure 1-4. The lines are hard to distinguish from one another."
                },
                "questions": {
                    "value": "See in weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3065/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699512007877,
            "cdate": 1699512007877,
            "tmdate": 1699636251948,
            "mdate": 1699636251948,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2uO8nOGErH",
                "forum": "IQZicPtADC",
                "replyto": "jeJ6P5hW83",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank reviewer F18A for their feedback. Thank you for emphasizing the importance of our work.\n\n**W1:** Assumptions and limitations of the current theoretical results: We thank you for emphasizing the interpreting consequences of the assumptions made. Due to space limitation we would like to use the space to highlight our theoretical and experimental findings, and deferred the exact assumptions and discussions on the limitations in the appendix. However, we have modified our main paper to include the high-level assumptions made and the intuitions. See paragraph before theorem 1 on page 4.\n\n**W2:** Thank you for pointing out the clarity issue. We have updated the plot in the manuscript.\n\nFinally, is there any specific improvements that we can make to increase the score? Thank you reviewer F18A for your feedback again!"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700111005513,
                "cdate": 1700111005513,
                "tmdate": 1700111005513,
                "mdate": 1700111005513,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "4a7M14GJew",
            "forum": "IQZicPtADC",
            "replyto": "IQZicPtADC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3065/Reviewer_Eicc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3065/Reviewer_Eicc"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses the statistic guarantees of transfer learning with regards to its improvements in sample efficiency, specifically with regards to imitation learning paradigms. The main result of this paper is a bound on the policy error that is indirectly related to the task diversity of the source tasks $T$, the number of demonstrations of the source task $N$, and the number of demonstrations of the target class $M$, and directly related to the Rademacher complexity. Task diversity is intuitively defined as how closely can some learned policy $\\pi^*$ perform on a new task given source tasks.\n\nThe proposed method is split into two stages: first learn a representation embedding $\\hat{\\phi}$ from source tasks, then learn a policy $\\pi$ conditioned on the task-specific mapping $\\hat{f}$ and $\\hat{\\phi}$. The training objective of the first phase is to minimize the log loss of $\\pi$ given a task-specific mapping for source task $t$ and the parameter $\\phi$. The training objective of the second phase is to minimize that same loss using $\\hat{\\phi}$ from above, this time varying the task-specific mapping $f_\\tau$. The authors perform their analysis in the tabular setting, but mention that it may be possible to extend to continuous state-action spaces in theory, and provide empirical results to support this.\n\nThe empirical questions the authors aim to answer is whether multi-task behavioral cloning training can do better than single task behavior cloning training, and ablate over $N$, $T$, and $M$ to see which affects performance the most. They find that increasing $N$ and $T$ are most impactful in improving performance and reducing the demand on target data demonstrations."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The main contributions form this paper are two fold: 1) a tighter bound on sample efficiency of multi-task imitation learning paradigms, and 2) empirical results focus on the effectiveness of representation transfer and a new metric to measure task diversity. \n\n- The paper clearly presents the hyperparameters it is interested in that is relevant to their main bound, and does a thorough ablation over each parameter.\n- The proposed KL metric is described in a digestible manner, and good to see thorough results testing its effectiveness. As mentioned, it is an important direction to prompt more empirical work analyzing task diversity.\n- Empirical findings are interpretable, and good combination of graphs and tables.\n\nFinally, the paper is generally free of grammatical errors and typos, and written in a clear manner. Overall, it is likely to be of interest to a smaller community in the multi-task learning space. However, if the authors could provide more results on experiments outside of Mujoco, such as the more challenging tasks mentioned below, it has the potential to raise interest in the larger multi-task imitation learning community."
                },
                "weaknesses": {
                    "value": "### High Level Technicals:\n- While the story told in Figures 1-4 are clear, it would have been nice to see some evaluations on at least one multitask environments such such as FrankaKitchen [[1](https://robotics.farama.org/envs/franka_kitchen/franka_kitchen/)] or Metaworld [[1](https://meta-world.github.io/)]. While the current results on Mujoco support the claim, the environments are relatively simple. The results of this paper would be of interest to a much larger community if the same compelling results are shown on just one of the above environments.\n- It would have been nice to see some more interpretation on the results of Spearman and Kendall correlations on the bottom of page 8.\n- Due to the boldness of the lines and overlap, it is a bit challenging to tell the differences between the blue, yellow, green, and red lines. I might suggest using different shapes in or decreasing the boldness of the lines. \n\n### Low Level Technicals\n- On (ii) towards the bottom half of page 7, \"let\" should be capitalized in \"let \\hat{r}_t be the average rewar of the expert...\""
                },
                "questions": {
                    "value": "1. Is there any demand on the optimality of the source task demonstrations? For example, would a large batch of suboptimal demonstrations actually deteriorate or stagnate improvement given the proposed method?\n2. I'm curious whether increasing amount of source task data would also make the policy more robust to covariate shift, since it theoretically should have a larger state-space coverage. Or when transition dynamics are stochastic.\n3. Have the authors attempted to generalize their framework to imitation learning algorithms beyond behavioral cloning, such as IRL methods?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3065/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3065/Reviewer_Eicc",
                        "ICLR.cc/2024/Conference/Submission3065/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3065/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699542685399,
            "cdate": 1699542685399,
            "tmdate": 1700622649483,
            "mdate": 1700622649483,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "meUQ1rUeCa",
                "forum": "IQZicPtADC",
                "replyto": "4a7M14GJew",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank reviewer Eicc for their feedback. Thank you for emphasizing the potential significance of our work.\n\n**W1:** Thank you for pointing this out. We agree that a task in extra environments will make the paper more impactful. As suggested by you and reviewer Fs7F, we aim to provide extra analysis on a new task with image-based observations shortly.\n\n**W2:** Both Spearman and Kendall correlations aim to find monotonic correlations. In the main manuscript we briefly discussed that they are both positively correlated, albeit rather weak in some cases. Notice that frozen lake, cartpole, and pendulum tasks are the environments with weaker correlations. Our suspicion is that each variant of these environments are very sensitive to the policy's actions. In some cases, the policy will need to make consecutively accurate actions to perform well. For example, each variant of frozen lake differs in its dynamics and initial and goal positions. Consequently the learner policy in the target task may vary significantly in actions, when compared to the learned policies in the source tasks. This relates to the last sentence where in discrete action space, there is a possibility that we can simply permute the action space and have low task diversity even if the policy can learn perfectly well.\n\n**W3:** Thank you for pointing out the clarity issue. We have updated the plot in the manuscript.\n\n**W4:** We have fixed the typo in the manuscript. Thank you for pointing that out.\n\n**Q1:** Thank you for the interesting question. Based on our theory, so long as the expert policy shares representation with the true representation, the pretraining will not stagnate or deteriorate the improvement.\nConsequently, we can likely use MMD or other divergences if the sample complexity improves and can be easily tied to the transfer risk, as suggested by reviewer StV9.\nWe find that there has been work showing that some objectives work and some do not [1, 2, 3].\n\n**Q2:** Yes, we believe that is the case based on the theory. Unless we have the degenerate case where both the representation and the task mappings are tabular, intuitively the learned representation should be capturing shared dynamics information relevant across all tasks. This is because the pretraining loss is induced by the dynamics and the policies of the source tasks. Consequently, this information should improve policy robustness to the covariate shift problem.\n\n**Q3:** We have not yet considered inverse RL (IRL) methods, however we believe this work opens a new avenue to analyze various combinations of supervised IL and IRL approaches.\n\nFinally, is there any specific improvements that we can make to increase the score? Thank you reviewer Eicc for your feedback again!\n\nReferences:  \n[1] Yang, M., & Nachum, O. (2021, July). Representation matters: Offline pretraining for sequential decision making. In International Conference on Machine Learning (pp. 11784-11794). PMLR.  \n[2] Nachum, O., & Yang, M. (2021). Provable representation learning for imitation with contrastive fourier features. Advances in Neural Information Processing Systems, 34, 30100-30112.  \n[3] Kumar, A., Singh, A., Ebert, F., Nakamoto, M., Yang, Y., Finn, C., & Levine, S. (2022). Pre-training for robots: Offline rl enables learning new tasks from a handful of trials. arXiv preprint arXiv:2210.05178."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700110954349,
                "cdate": 1700110954349,
                "tmdate": 1700111739861,
                "mdate": 1700111739861,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "g8GvImml7u",
            "forum": "IQZicPtADC",
            "replyto": "IQZicPtADC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3065/Reviewer_kWs2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3065/Reviewer_kWs2"
            ],
            "content": {
                "summary": {
                    "value": "The authors consider, theoretically and empirically, the sample-complexity benefits pre-training a shared representation on multi-task data might provide for behavioral cloning. In theory, they prove a high-probability bound on the performance difference between BC learned on top of the shared representation and the expert data. In practice, they show that on a variety of discrete and continuous control problems, pre-training on multi-task data allows for effective policy learning with limited target-task data."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "(+) The theoretical analysis is easy to follow and uses standard tools.\n\n(+) I appreciated how the experiments section was broken down into the statement and testing of various hypotheses."
                },
                "weaknesses": {
                    "value": "(-) Overall, I found the theoretical statements to be fairly simple extensions of known results by Tripuraneni et al. and Ross & Bagnell. In essence, by focusing only on behavioral cloning, the authors are able to almost entirely ignore the sequential nature of the imitation problem and apply the standard analysis for multi-task supervised learning. Then, once they have a bound on the KL divergence between the learner and the expert, they can apply the well-known upper bounds for behavioral cloning (https://www.cs.cmu.edu/~sross1/publications/Ross-AIStats11-NoRegret.pdf) to get an overall policy performance guarantee. So, I really didn't get much out of the theorems they proved.\n\n(-) There's a few pieces of odd terminology throughout the paper. First, instead of \"policy error\", people usually use \"performance difference\" or \"imitation gap\" (https://arxiv.org/abs/2103.03236). Also, I think you're missing a $H^2$ or $\\frac{1}{(1-\\gamma)^2}$ in the first equation in the paper? Second, when people talk about \"number of demonstrations\" (i.e. $|\\mathcal{D}|$ in the paper), they usually mean the number of whole trajectories rather than the number of state-action tuples (as you seem to use it in Table 1). Do you mind re-naming this? I got super confused for a while by why one would need millions of samples for BC to work on a Mujoco task. Can you also clarify whether $N$ and $M$ are measured in terms of trajectories or state-action pairs?\n\n(-) Once you divide the numbers in table 1 by the horizon of the problem (1000 for Mujoco), you realize that they're attempting to learn based on effectively 1-2 demonstrations. This is a somewhat absurdly small amount of data (usually people do ~25 demos for Mujoco tasks). So, while the experimental results make sense to me, I think it is somewhat important to note that they are under fairly contrived settings.\n\n(-) While the idea of a metric to capture the effectiveness of multi-task IL data for learning a transferrable representation is interesting, I found the ideas in Appendix B to be a bit sloppy and the empirical reported correlations in Tables 2/3 to be fairly low.\n\n(-) Most analysis of imitation learning doesn't have to make assumptions about the optimality of the expert policy. In Footnote 1, you note that you do this. Is this actually important for any of your analysis?\n\n(-) I might add some more citations for multi-task imitation learning outside of behavioral cloning. While they are clearly different than your work, it would be good to add in some references and discuss the differences: https://arxiv.org/pdf/1805.12573.pdf, https://arxiv.org/pdf/1909.09314.pdf, https://arxiv.org/pdf/1805.08882.pdf, https://arxiv.org/pdf/2309.00711.pdf. You might also want to cite some work on representation learning for sequential decision making (e.g. https://arxiv.org/abs/2207.08229)."
                },
                "questions": {
                    "value": "(1) I think it would be helpful if you could add in a comparable statement to Theorem 1 for single-task BC. You could then give ranges of T and N under which you'd have a meaningful difference in upper bounds between multi-task and single-task BC. The sharpest analysis I know for IL under a deterministic expert assumption is in https://arxiv.org/pdf/2205.15397.pdf -- you might be able to just copy some of their theorems.\n\n(2) In Figure 1, why do some of the performances for the multi-task method start lower than the corresponding BC performances? Do you think this would be fixed if you included target task $\\tau$ in the representation learning step?\n\n(3) Do you have any hypothesis for why, in Figure 2, things look quite bad for CartPole? Is it perhaps because of the kinds of environment modifications you were considering?\n\n(4) In Figures 3 and 4, you're giving the learner quite a bit of source data so perhaps the performance gap is already quite close. If you have the compute resources, could you ablate these results across smaller values of $N$?\n\n(5) Generally, could you be more specific about the ranges over which you varied environment parameters to generate the multi-task data (e.g. what link sizes for Walker)?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3065/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3065/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3065/Reviewer_kWs2"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3065/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699572758057,
            "cdate": 1699572758057,
            "tmdate": 1700511420394,
            "mdate": 1700511420394,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "n8tJXRxtwR",
                "forum": "IQZicPtADC",
                "replyto": "g8GvImml7u",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank reviewer Fs7F for their insightful feedback. We believe we have addressed your concerns and we are very thrilled to continue the thoughtful discussion with you.\n\n**W1:** We thank reviewer Fs7F for noting the simplicity of our theoretical proofs. We agree that our theoretical result is a synthesis of known results and is straightforward. Our novelty is not a new proving technique. Instead, our novelty lies in bridging and connecting learning theories in multitask learning and imitation learning. As noted by many other reviewers (StV9, Eicc, F18A, Fs7F, Ss6u), this result does not appear to be commonly known and can have significant impact in the community. Furthermore, we note that our result is an improvement of existing results by leveraging the properties of the log loss. With any policy parameterization that is Lipschitz, we can improve the sample complexity by $\\log(NT)$ when compared to using Gaussian complexity. We finally argue that a simpler proof is often preferred since it can be easily understandable, which appears to be the case as stated by many reviewers (StV9, kWs2, Eicc, F18A).\n\n**W2:** We thank reviewer Fs7F for raising an undefined term in the paper. Based on your feedback, we have modified our terminology to imitation gap.\n\nRegarding the horizon term, indeed we have neglected the horizon term. Due to Xu et al, 2020. this is an unavoidable term and we thus treat it as a constant. We further note that we also neglected other constants (e.g. $\\lvert \\mathcal{A} \\rvert$) for presentation purposes.\n\nFinally, thank you for raising this concern of the term \"demonstration\". We emphasize that we treat each demonstration as a state-action pair (i.e. a transition) and we have explicitly defined this in section 2.2. We wish to keep the term demonstration as transitions can be referred to any policies, and terms such as \"expert transitions\" are cumbersome from the reading perspective. However, we are open to suggestions on what can be a better term.\n\n**W3:** Thank you for pointing out that the number of trajectories is small for MuJoCo tasks in many papers [1,2]. We believe that this \"contrived setting\" is preferrable in practice---practitioners aim to minimize the number of demonstrations as much as possible since it can be costly (e.g. human-operating time, computational cost, etc.)\n\n**W4:** We acknowledge reviewer kWs2's comment on the task-diversity metric. We note that this is an attempt to defining a task-diversity metric that may positively correlate with the imitation performance. Indeed, we do not provide any theoretical guarantees on the metric and the conditions in appendix B are very restrictive. Intuitively we hope to have the irreducible error to be sufficiently small such that the ratio can be estimated by our proposed metric. We consequently experimentally showed that this metric can be strongly correlated to the imitation performance. Furthermore, the metric still captures the asymmetry of task transfer which is a desirable property.\n\n**W5:** Thank you for raising this. Our result does not require optimality of the expert policy as the learner policy only aims to imitate the expert. We have removed footnote 1 which hopefully resolves the confusion.\n\n**W6:** Thank you for providing extra references for multi-task IRL methods. We have included them in the first paragraph of the related work. We hope this better covers the literature and demonstrates the differences in our work."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700110316779,
                "cdate": 1700110316779,
                "tmdate": 1700110316779,
                "mdate": 1700110316779,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "56ZnwQfNF4",
                "forum": "IQZicPtADC",
                "replyto": "yhAP2S2yMN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_kWs2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_kWs2"
                ],
                "content": {
                    "title": {
                        "value": "Re:"
                    },
                    "comment": {
                        "value": "First off, let me thank the authors for their thorough and prompt rebuttal. Responding to the points raised:\n\n**W2:** You might want to cite some paper for the term \"imitation gap\" -- https://arxiv.org/abs/2103.03236 is where I first saw the term if it helps. While I agree that the $O(H^2)$ factor is unavoidable without further assumptions (e.g. coverage / recoverability, https://arxiv.org/pdf/2102.02872.pdf), I don't think this is a good reason to not include it in the presented bound, given most other papers in the offline IL space do.\n\nRe: \"demonstrations:\" given I and other reviewers seemed to be confused by this point, I would suggest using something like \"expert samples\" / \"expert tuples\" or divide all the numbers by the horizon. As a general principle, if multiple folks in your target audience are confused by your use of a term (regardless of whether it was re-defined in the text), this is not a good thing.\n\nQ1: Yup, makes total sense. Do you mind adding this in as a corollary / remark? I think it'd make the precise sample-complexity benefits of multi-task BC more apparent.\n\nQ2: Nice work! Do you mind adding in a sentence on this point in the figure caption / a footnote?\n\nQ4: Ditto the above.\n\nQ5: Thanks! Do you mind sticking this somewhere in the appendix?"
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700425840826,
                "cdate": 1700425840826,
                "tmdate": 1700425840826,
                "mdate": 1700425840826,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "B6XcTy42Su",
                "forum": "IQZicPtADC",
                "replyto": "g8GvImml7u",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank reviewer kWs2 for the feedback. We have updated our manuscript to reflect the follow-up suggestions.\n\n**W2:**\n- We have included the suggested reference on page 2, under section 2.2.\n- We have also included the horizon term in page 1, under **Theoretical contributions**.\n\nQ1:\n- We have added a remark (Remark 1) on page 4 to include the sample-complexity of BC, as well as comparing BC with MTIL on page 4.\n\nQ2 & Q4: \n- We have provided a sentence in the caption of figures 13-15 on pages 30 and 31, as well as including paragraphs under **Inclusion of Target Data during Training Phase** and **Impact of Source Tasks and Source Data** on pages 28 and 29.\n\nQ5: \n- We have included the parameter ranges and described how we sample them on pages 24 and 25.\n\nFinally, we thank reviewer kWs2 for their constructive feedback. We invite reviewer kWs2 to comment on the other points as the feedback has been very helpful. We also would love reviewer kWs2 to once again reconsider their score."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700432623400,
                "cdate": 1700432623400,
                "tmdate": 1700432857048,
                "mdate": 1700432857048,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nSNSx2xcMe",
                "forum": "IQZicPtADC",
                "replyto": "B6XcTy42Su",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_kWs2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_kWs2"
                ],
                "content": {
                    "title": {
                        "value": "Re:"
                    },
                    "comment": {
                        "value": "Thank-you for those updates! \n\nOne last question: rather than comparing the KL-Divergence between the expert and the multi-task policies as your transfer metric, do you think it would make sense to, say, compare the $\\ell_2$ norm of the difference in weights? I've seen this sort of metric used for task diversity in meta-learning (e.g. https://arxiv.org/pdf/1906.02717.pdf). Part of the reason it might be an interesting contrast to the methods you propose is that it is not a function of the expert state distribution (and therefore could correlate better with how well one has actually recovered the expert policy). Of course, one could not actually evaluate such a metric without full access to the expert policy."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700434729469,
                "cdate": 1700434729469,
                "tmdate": 1700434729469,
                "mdate": 1700434729469,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xGUVOfPlbG",
                "forum": "IQZicPtADC",
                "replyto": "LbcgUqlUGI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_kWs2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_kWs2"
                ],
                "content": {
                    "title": {
                        "value": "Re:"
                    },
                    "comment": {
                        "value": "If you still have the trained policies sitting around, would you consider adding it as another $\\hat{\\sigma}$ to the paper? I'd be quite curious as to how it works compared to the other candidates."
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700499282693,
                "cdate": 1700499282693,
                "tmdate": 1700499282693,
                "mdate": 1700499282693,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LXOEwIi2XA",
                "forum": "IQZicPtADC",
                "replyto": "S6ilj4YBWT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_kWs2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_kWs2"
                ],
                "content": {
                    "title": {
                        "value": "Re:"
                    },
                    "comment": {
                        "value": "Thanks! I have raised my score to a 5."
                    }
                },
                "number": 28,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700511403651,
                "cdate": 1700511403651,
                "tmdate": 1700511403651,
                "mdate": 1700511403651,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "BzvVoeAq7i",
            "forum": "IQZicPtADC",
            "replyto": "IQZicPtADC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3065/Reviewer_Ss6u"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3065/Reviewer_Ss6u"
            ],
            "content": {
                "summary": {
                    "value": "The paper posits that there exists a shared representation across a variety of tasks. It trains behavior cloning from a set of source tasks, learns a representation, and then learns a policy for a target task. It proposes that, the policy error is bounded by the diversity of the source tasks. It suggests that training in this paradigm will have better performance and uses less target task data than vanilla behavior cloning."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Innovative Concept: The paper introduces an interesting hypothesis about the benefits of learning shared representations from diverse source tasks to improve policy learning in behavior cloning.\n- Theoretical Contribution: It provides a theoretical framework that bounds policy error with respect to the source task diversity, offering a new perspective on the potential for generalization in behavior cloning."
                },
                "weaknesses": {
                    "value": "- Lack of Clarity: The paper does not sufficiently describe the \"shared representation\" it aims to learn. A more detailed exposition, possibly including visualizations or analysis of the learned representation, is needed.\n- Theoretical Bound Practicality: The paper presents an order bound on policy error but does not provide a comprehensive discussion on its tightness or practical applicability, leaving its usefulness in question."
                },
                "questions": {
                    "value": "Section 4 requires further detail on the nature of the source tasks for each target task investigated. The concept of \"shared representation\" is pivotal yet remains vague within the paper. Is this representation a transformation from a visual image to a latent space, or something else? A detailed analysis or visual depiction of this shared representation would greatly enhance the clarity, perhaps focusing on a single task as an example.\n\nThe paper introduces a theoretical bound but does not elucidate on its tightness or practical applicability. It is essential to quantify or provide conditions under which the bound holds with a fixed constant, thereby ensuring utility in policy improvement with additional data.\n\nHow do you define the \u201cpolicy error\u201d on Page 1? How can it be measured? Is the measurement done in the task reward, action space, or divergence perspective? Besides, you mentioned that f-divergence imitation learning states that a learned policy is minimizing the divergence between expert and learner trajectory. How does the policy error fit / contrast with such existing framework?\n\nGiven the focus on multi-task imitation learning, it is imperative to benchmark against state-of-the-art Meta Learning methods for a comprehensive comparison.\n\n\u201cHowever, current methods require thousands of demonstrations even in simple tasks (Mandlekar et al., 2022; Jang et al., 2021; Ablett et al., 2023)\u201d => *Thousands* of demonstrations seems to misrepresent the SOTA of IL? Refer to https://www.roboticsproceedings.org/rss19/p009.pdf  https://medium.com/toyotaresearch/tris-robots-learn-new-skills-in-an-afternoon-here-s-how-2c30b1a8c573 https://deepmind.google/discover/blog/robocat-a-self-improving-robotic-agent/  Please clarify. \n\nFor all experiments detailed in Section 4, please define the state and action space, including their dimensions.\n\nCan the derived bound be applied to low-dimensional imitation learning that does not learn a representation? Assuming that the learned representation is the identity matrix, can we extend the bound to low-dimensional state space? Is the result implying that, adding more data into pre-training, will result in smaller policy error?  However, given what we saw in https://ieeexplore.ieee.org/abstract/document/10161474/ it seems that more data is not guaranteed to help imitation learning performance on the real robot. Can the author provide some insight? \n\n\nOur result is due to the objective of behavioral cloning, where the method aims to minimize the Kullback\u2013Leibler (KL) divergence between the expert and the learner (Ghasemipour et al., 2019; Xu et al., 2020). => Could you elaborate how the findings from Xu et al., 2020 is related to this statement? \n\nRegarding Equation 4 and the \"under some assumptions\" qualifier, a more intuitive explanation of these assumptions and their impact on the model's generalizability would be essential."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3065/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699590619887,
            "cdate": 1699590619887,
            "tmdate": 1699636251724,
            "mdate": 1699636251724,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "s4y9XqgyUy",
                "forum": "IQZicPtADC",
                "replyto": "BzvVoeAq7i",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank reviewer Ss6u for their relevant feedback. We hope our response encourages further discussions.\n\n**W1:** We acknowledge reviewer Ss6u's concern on the structure of the shared representation. The benefit of our theoretical result is that the shared representation has a minimal structure (e.g. in $\\mathbb{R}^d$ and bounded). The sample complexity bound holds with high probability. Indeed, we believe that imposing a particular structure on the representation will yield a potentially better result and will further enable practitioners to understand the problem. The state-estimation problems in robotics are great examples for imposing structures on the representation. For example, consider a image-based pendulum task where we have no true readings of the joint information. If we are given the joint information we can solve it using linear controllers. Thus our representation can simply be enforced to be in the same space.\n\n**W2:** We thank reviewer Ss6u for highlighting the importance of lower bounds---we agree that a lower bound will provide significant insight to our result, specifically to understand whether our result is minimax optimal. We first emphasize that this result means that it is hopeful to obtain a near-expert policy as we increase the number of samples, at the rate of $O(1/\\sqrt{NT} + 1/\\sqrt{M})$. Regarding the lower bound, there are existing results on general Lipschitz and smooth loss functions (see table 1 of [1]). In the single-task BC setting, indeed the $\\Omega(1/\\sqrt{M})$ is tight and can perhaps be tightened to $\\Omega(1/M)$ with specific function classes (i.e. $L^*$ shrinks to 0 thus removing the $\\Omega(1/\\sqrt{M})$ dependence). While this bound is not established on the multi-task setting, Our intuition is that following similar proof techniques we will arrive at similar $\\Omega(1/\\sqrt{NT} + 1/\\sqrt{M})$ result. We thank reviewer Ss6u again for the very helpful comment and we plan to clearly address this in our future work due to time limitation of the rebuttal period.\n\n**Q1:** We acknowledge reviewer Ss6u's comment on the potential vagueness of the shared representation's structure. Generally, the representation can be a transformation from a visual image to a latent space, texts to a latent space, or a stacked sequence of past robot information into a latent space---our theoretical result imposes minimal latent space structure (other than $\\mathbb{R}^d$ for example). An intuitive example is a visual pendulum task where the input space is a stack of images, which allows the representation to capture positional, velocity, acceleration, and higher-order derivatives.\n\n**Q2:** We thank reviewer Ss6u for pointing out the lack of constants, conditions and assumptions made in the main paper. We provide the technical details and exact theorem result with constants in appendix C with a high-level explanation on each assumptions made.\n\nRegarding practicality, we believe we can address this through whether the assumptions are reasonable and whether the bound can be used in practice. The former is provided in appendix C.1. For the latter, we believe a concern is whether certain assumptions hold---if not, the bound is hopeless and is uninformative. However, albeit tedious, we can still validate these assumptions by increasing the complexity of the models. Suppose we make the correct assumptions, then there are multiple facets that are practical. First, we can expect the policy performance to shrink at a square-root rate, with respect to the source and target data, meaning that it is hopeful to obtain near-expert performance. Second, we know exactly how much target data to collect in order for the imitation gap to shrink below the desired value as it is independent of the task-diversity constant. Third, the fact that the representation is more complex, we are free to gather more source, perhaps even include the target data in the pretraining as suggested by reviewer kWs2. The benefit here is that it is possible for some task data to be cheaper to collect, thus we can focus on exploiting the cheaper tasks."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700110230627,
                "cdate": 1700110230627,
                "tmdate": 1700110281225,
                "mdate": 1700110281225,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5ec1xvbIVh",
            "forum": "IQZicPtADC",
            "replyto": "IQZicPtADC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3065/Reviewer_StV9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3065/Reviewer_StV9"
            ],
            "content": {
                "summary": {
                    "value": "The paper provides a tighter statistical guarantee in the sample-complexity of transferring what is learned from source tasks to target tasks and empirical evaluates this on some simple control tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "**Originality**\n- The paper uses Rademacher complexity instead of Gaussian complexity, as used heavily by work that the paper references, in order to derive a tighter bound for a sample-complexity bound of the benefits of a representation in transfer learning in multi-task imitation learning (MTIL)\n\n**Quality**\n- Good to create and evaluate algorithms on discrete action space variants of continuous action environments while also evaluating on these continuous spaces to see whether theory that the paper proposes is actually empirically supported in both spaces for the same type of problem domain.\n- The paper includes multiple correlation values in Tables 2 and 3 to cover certain limitations of individual ones.\n\n**Clarity**\n- The paper does a good job throughout explaining technical details and its experimental design.\n- The paper provides intuitive explanations to accompany well-written rigorous definitions, which can help the reader better understand the concept being explained. For example, on page 3, the paper states \"Intuitively, the Rademacher complexity of F measures the expressiveness of F over all datasets X through fitting random noise.\" after providing a rigorous definition of Rademacher complexity in its problem setup.\n\n**Significance**\n- The significance is potentially large, but I'm unsure how well it generalizes, especially due to the limitations of using only the KL-divergence and no other measure of dissimilarity between probability distributions."
                },
                "weaknesses": {
                    "value": "1. The paper uses only KL-divergence to measure task-diversity for source and target tasks.\n\n2. The paper doesn't compare using $D_{KL}$ to using other statistical measures of similarity between probability distributions, such as Bhattacharyya distance, which seem much more appropriate to do than the measures that the paper does compare $D_{KL}$ against.\n\n3. **Generally when it comes to Rademacher Complexity in this context of this work, my concerns (really just an overarching single concern) are detailed in the paragraphs below.** However, I welcome thoughts on others from whether these are valid here or out of scope. If out of scope, then I also welcome discussion on how significant is the paper context, really?\n- In the context of bounding sample-complexity in transfer learning, particularly for evaluating the richness of representation classes I wouldn't use Rademacher Complexity because of the importance of nuance in transfer learning on sequential tasks, which this measure avoids accounting for.\n- Brief descriptions of Rademacher Complexity usefulness, main advantage, and main disadvantage for context:\n  - Utility: Measures the ability of a function class to fit random noise, providing a general sense of the capacity of the function class.\n  - Pro: Provides a general and well-understood measure of complexity that is applicable across various learning scenarios.\n  - Con: It may not be as directly relevant to transfer learning scenarios because it doesn't specifically account for the nuances of transferring knowledge from a source to a target task.\n- Given the specific requirements of transfer learning, which often involve understanding the relationship and distributional differences between source and target tasks, measures like Maximum Mean Discrepancy (MMD), Discrepancy Distance, and Task Similarity Measures become more pertinent. These measures are more directly aligned with the challenges of assessing how well a learned representation from one task can be applied to another, which is at the heart of transfer learning.\n- Rademacher complexity, while powerful in many learning theory contexts, does not explicitly address these transfer-specific concerns. Therefore, it's more suited to general learning scenarios rather than the specific complexities of transfer learning.\n- In fact, Gaussian complexity is somewhat similar but might be more suitable in certain contexts, especially in which approximately Gaussian assumptions naturally occur. Therefore, I again question the significance of this finding with Rademacher complexity in practice. \n\n4. Evaluations do not include baselines using Gaussian Complexity in-place of Rademacher Complexity even though Gaussian Complexity may empirically be more useful on some tasks here."
                },
                "questions": {
                    "value": "1. What insights do you have as to what causes the issue brought up in \"We note that equation 5 is asymmetrical (i.e.  swapping \u03c4 with one of t \u2208 [T] can yield different diversity estimate.)   This is a desirable property since model transfer generally is not symmetrical (Sugiyama et al., 2007). Suppose we have the expert policies \u03c0,\u03c0\u2032 respectively for environments \u03c4,\u03c4\u2032.  while \u03c0 may stay performant in both \u03c4,\u03c4\u2032, \u03c0\u2032 may degrade when transferred to \u03c4.  We demonstrate this in appendix D where the expert from each environment variation exhibits different robustness\u2014one can stay performant in the target environment while another can degrade in performance.\"\n\n2. On Page 2, the paper states \"The consequence is that we can connect our result with deep-learning\ntheory, where the commonly used neural networks are quantified directly with Rademacher complexity (Bartlett et al., 2021).\"\n  a. Is this the best way to quantify neural network complexity here?\n  b. Could you expound on your answer to 2a?\n  c. What other options are available? \n\n3. Thoughts on using maximum mean discrepancy instead of Rademacher complexity?\n4. Thoughts on using discrepancy distances, as these are directly applicable in assessing transfer learning effectiveness.\n5. Thoughts on using local Rademacher complexities? This would be more nuanced and data-dependent though, and the Rademacher complexity avoids this nuance."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "I do not have ethics concerns with this work."
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 6,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3065/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699617741497,
            "cdate": 1699617741497,
            "tmdate": 1699636251655,
            "mdate": 1699636251655,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3NMXfPBIwM",
                "forum": "IQZicPtADC",
                "replyto": "5ec1xvbIVh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank reviewer StV9 for their feedback. We appreciate that you find this work to be potentially large.\n\n**W1:** We thank the reviewer for their comment on the limitation of our task-diversity metric. We note that our task-diversity metric is based on the observations that (1) the source tasks likely capture the target task information if there is a source policy that performs well in the target task, and (2) the KL-divergence is asymmetrical which is a desirable property in task transfer. However, we agree that there can be other metrics, as you have mentioned in the later points. We aim to consider these metrics in future work.\n\n**W2:** Thank you for pointing this out, we will include a comparison against Bhattacharyya distance shortly.\n\n**W3:** Thank you for initiating this discussion. While we do believe this may be out of scope of our paper, we are happy to discuss this. The concern with discrepancy measure is that usually it relates only one source task to one target task. Perhaps what can happen in this case is to consider the source task distribution as the distribution of mixture policies in various MDPs.\n\n**W4:** Perhaps we misunderstood the comment, could you please rephrase it? The (empirical) evaluations did not involve any complexity measure, rather we focused on minimizing the loss through KL-divergence.\n\n**Q1:** Thank you for the question. This can be answered through the pendulum example. Suppose the pendulum can vary in its maximum torque. The lower-torque variant includes less policies that can keep the link upright while the higher-torque variant includes more policies. As a result, the lower-torque variant can be used in the higher-torque environment (arguably without finetuning) to keep the link upright, while this fails in the other case.\n\n**Q2:** Thank you for the interesting question. Generally, we do not believe that Rademacher complexity is the best way to quantify neural network complexity. In fact many analyses consider Gaussian complexities due to its mathematical properties, as demonstrated in prior work outlined in our paper. Another approach for analyzing neural networks can be using algorithmic stability along with metric entropy [3,4]. It is also common to consider norm-based complexity which is used to upper bound Rademacher complexity [1,5].\n\n**Q3-Q5:** They are all very great suggestions that we believe can be considered generally. We have not considered discrepancy measure but it might be interesting, as you have discussed in W3. Our goal is to directly quantify the representations learned from the source tasks and the target task. The difficulty may lie in including the true shared representation to the empirical representations from the source tasks and the target task, and finally connecting it to the imitation gap. We can alternatively consider the MMD of the policies, taking the expectation over their respective occupancy measures. Localized Rademacher complexity may give us $O(1/M)$ rate in some situations, as you have mentioned. But, it may still be difficult to improve upon $O(1/\\sqrt{NT})$ generally, as we have discussed with reviewer Ss6u.\n\nFinally, thank you again for your insightful feedback. Please let us know if we have properly addressed your questions and what we can do to encourage you to increase our score.\n\nReferences:  \n[1] Liang, T., Poggio, T., Rakhlin, A., & Stokes, J. (2019, April). Fisher-rao metric, geometry, and complexity of neural networks. In The 22nd international conference on artificial intelligence and statistics (pp. 888-896). PMLR.\n[2] Bartlett, P. L., Montanari, A., & Rakhlin, A. (2021). Deep learning: a statistical viewpoint. Acta numerica, 30, 87-201.  \n[3] Bousquet, O., & Elisseeff, A. (2000). Algorithmic stability and generalization performance. Advances in Neural Information Processing Systems, 13.  \n[4] Li, Y., Ildiz, M. E., Papailiopoulos, D., & Oymak, S. (2023). Transformers as algorithms: Generalization and stability in in-context learning.\n[5] Neyshabur, B., Tomioka, R., & Srebro, N. (2015, June). Norm-based capacity control in neural networks. In Conference on learning theory (pp. 1376-1401). PMLR."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700110161373,
                "cdate": 1700110161373,
                "tmdate": 1700149548028,
                "mdate": 1700149548028,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jkXgj50Bpi",
                "forum": "IQZicPtADC",
                "replyto": "5ec1xvbIVh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank reviewer StV9 for suggesting another metric. We have included a metric using the Bhattacharyya distance, replacing the KL-divergence. As a preliminary step we computed the metrics only for the discrete environments. We can see that Bhattacharyya distance may negatively correlate to the imitation performance in Frozen Lake and have weaker correlation in Walker compared to KL. We plan to investigate further in the future different task diversity metrics and how their theoretical properties may correlate to the imitation performance.\n\nEDIT:\nWe have included this table (table 6) on page 32, with explanation on pages 30 and 31. we further included the L2 representation norm as suggested by reviewer kWs2\n\n## Pearson\n|               | Frozen Lake                      | Pendulum                         | Cheetah                          | Walker                           |\n|---------------|----------------------------------|----------------------------------|----------------------------------|----------------------------------|\n| L2            | $ - 0.008  \\pm  0.023 $          | $ 0.059  \\pm  0.069 $            | $ - 0.008  \\pm  0.080 $          | $ - 0.016  \\pm  0.096 $          |\n| Data Perf.    | $ 0.035  \\pm  0.223 $            | $ - 0.027  \\pm  0.023 $          | $ - 0.057  \\pm  0.041 $          | $ 0.279  \\pm  0.128 $            |\n| Bhattacharyya | $ - 0.358  \\pm  0.098 $          | $  0.071  \\pm  0.013 $ | $ 0.150  \\pm  0.029 $            | $ - 0.041  \\pm  0.011 $          |\n| L2 Repr. Norm | $0.169 \\pm 0.040$ | $\\mathbf{0.190 \\pm 0.034}$ | $0.381 \\pm 0.060$ | $0.048 \\pm 0.015$          |\n| Approx. KL (Ours)    | $ \\mathbf{ 0.276  \\pm  0.118 } $ | $ - 0.099  \\pm  0.017 $          | $ \\mathbf{ 0.386  \\pm  0.062 } $ | $ \\mathbf{ 0.383  \\pm  0.068 } $ |\n\n## Spearman\n|               | Frozen Lake                      | Pendulum                         | Cheetah                          | Walker                           |\n|---------------|----------------------------------|----------------------------------|----------------------------------|----------------------------------|\n| L2            | $ - 0.019  \\pm  0.010 $          | $ - 0.064  \\pm  0.032 $          | $ 0.091  \\pm  0.024 $            | $ - 0.008  \\pm  0.155 $          |\n| Data Perf.    | $ \\mathbf{ 0.035  \\pm  0.028 } $ | $ 0.116  \\pm  0.026 $            | $ 0.053  \\pm  0.071 $            | $ - 0.159  \\pm  0.083 $          |\n| Bhattacharyya | $ - 0.138  \\pm  0.046 $          | $ 0.079  \\pm  0.026 $            | $ 0.249  \\pm  0.037 $            | $ 0.045  \\pm  0.014 $            |\n| L2 Repr. Norm | $0.002 \\pm 0.010$ | $\\mathbf{0.288 \\pm 0.048}$ | $\\mathbf{0.404 \\pm 0.064}$ | $0.125 \\pm 0.027$          |\n| Approx. KL (Ours)   | $ 0.005  \\pm  0.022 $            | $  0.223  \\pm  0.036 $ | $ 0.363  \\pm  0.054 $ | $ \\mathbf{ 0.242  \\pm  0.039 } $ |\n\n## Kendall\n|               | Frozen Lake                      | Pendulum                         | Cheetah                          | Walker                           |\n|---------------|----------------------------------|----------------------------------|----------------------------------|----------------------------------|\n| L2            | $ 0.111  \\pm  0.022 $            | $ 0.052  \\pm  0.105 $            | $ - 0.082  \\pm  0.059 $          | $ 0.010  \\pm  0.044 $            |\n| Data Perf.    | $ - 0.033  \\pm  0.006 $          | $ 0.137  \\pm  0.068 $ | $ 0.046  \\pm  0.023 $            | $ - 0.355  \\pm  0.053 $          |\n| Bhattacharyya | $ - 0.203  \\pm  0.030 $          | $ 0.136  \\pm  0.043 $            | $ 0.422  \\pm  0.064 $            | $ 0.022  \\pm  0.026 $            |\n| L2 Repr. Norm | $\\mathbf{0.206 \\pm 0.033}$ | $\\mathbf{0.185 \\pm 0.031}$ | $\\mathbf{0.490 \\pm 0.070}$ | $0.168 \\pm 0.028$         |\n| Approx. KL (Ours)   | $ 0.121  \\pm  0.031 $ | $ 0.012  \\pm  0.025 $            | $ 0.479  \\pm  0.069 $ | $ \\mathbf{ 0.220  \\pm  0.039 } $ |"
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700152478714,
                "cdate": 1700152478714,
                "tmdate": 1700704961549,
                "mdate": 1700704961549,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bAt7fZRt1j",
                "forum": "IQZicPtADC",
                "replyto": "14MpzLvst0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_StV9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_StV9"
                ],
                "content": {
                    "title": {
                        "value": "Update"
                    },
                    "comment": {
                        "value": "Hi Authors,\n\nThank you for your response. I understand the importance of your effort in this work and the rebuttal, so I want to let you know that I will finish reviewing this + other Reviewers' reviews and your discussions with them thus far and reply by EoD today so that you have some time to address my response to your rebuttal before the deadline. I am mindful that we are nearing the deadline, so do not plan to ask you to do anything time-consuming, such as long experiment runs.\n\nBest,\nReviewer StV9"
                    }
                },
                "number": 36,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700611270222,
                "cdate": 1700611270222,
                "tmdate": 1700611270222,
                "mdate": 1700611270222,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PXpvcGCJcL",
                "forum": "IQZicPtADC",
                "replyto": "bAt7fZRt1j",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_StV9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_StV9"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal Response Part 1"
                    },
                    "comment": {
                        "value": "**W1:** It is stated in the paper somewhat often that the asymmetry of $D_{KL}$ is desirable/crucial/etc. alongside many references. For example in Appendix B, the paper states \"We note that our estimate is asymmetrical, which is a critical property for transferring (Sugiyama et al., 2007; Mansour et al., 2009; Hanneke & Kpotufe, 2019).\" \n\nBecause of the asymmetry's importance, I think that it would make the paper much more readable and credible towards readers if at least one or two reasons for the asymmetry's criticality were included. \n\nThe explanation in Page 5 is a possibility and not a certainty, and it is easy to come up with intentionally simple, or toy, examples in which the asymmetry leads to degradation of both expert policies or in which symmetry leads to improvement in both policies.\n\n**W3:** Isn't $D_{KL}$ limited in the same way as you reason: \"The concern with discrepancy measure is that usually it relates only one source task to one target task.\", as other discrepancy or dissimilarity measures, such as the Maximum Mean Discrepancy (MMD)? \n\n$D_{KL}(P || Q)$ measures the divergence of a single distribution $P$ from a a single distribution $Q$. In the paper's case $P$ is the \"expert\", which is equivalent to \"optimal\" according to the paper, policy for a single task and $Q$ is a learned target task composition policy.\n\nThis seems to be why you sum each task-specific $D_{KL}$ over all of the tasks $t$ in your primary proposed measure **Approx. KL** (Eq. 6).\n\nWouldn't you just do the same for other discrepancy measures, such as the MMD, Bhattacharyya Distance, Wasserstein Distance, and Deep CORAL [1], if you were to use them?\n\n**W4:** I believe I previously misunderstood this. It seems like Rademacher complexity is used to show the theoretical results but is not used in the algorithms proposed. Page 2 states \"building upon our theoretical contribution, we propose a new metric that measures task diversity using the KL- divergence  of  the  expert  and  the  trained  policies\" but I'm confused how the theoretical results lead to the new metric. Could you make this connection clear? Apologies if I missed it somewhere in the paper.\n\n---\n\n[1] Sun, B., & Saenko, K. (2016). Deep coral: Correlation alignment for deep domain adaptation. In Computer Vision\u2013ECCV 2016 Workshops: Amsterdam, The Netherlands, October 8-10 and 15-16, 2016, Proceedings, Part III 14 (pp. 443-450). Springer International Publishing."
                    }
                },
                "number": 37,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700667028442,
                "cdate": 1700667028442,
                "tmdate": 1700667028442,
                "mdate": 1700667028442,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vKXd8DFc9A",
                "forum": "IQZicPtADC",
                "replyto": "5ec1xvbIVh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank reviewer StV9 for their feedback. We hope our response addresses your questions and concerns.\n\n**W1:** Thank you for your question. Our statement on environment asymmetry is a motivation for why we cannot simply transfer one policy from one environment to another. Indeed, there can be cases where you can simply transfer but this is not the case **generally**, another concrete example can be found under section 3.1, example 3 of Hanneke & Kpotufe, 2020. Consequently, we want to ensure our metric to be able to capture asymmetry when we swap order of the environments.\n\nWe also thank you for pointing the paragraph out, we notice that the reference was incorrect and is now corrected to be Hanneke & Kpotufe, 2020 and have pointed the readers to the example for more intuition.\n\n**W3:** Thank you for raising this question. This depends on how MMD will be used. Suppose we compare the MMD of the representations, then it is not immediately clear because we will need to consider what is the distribution of the learned representation. On the other hand, when computing MMD of the source policies and target policy, then we agree that we can try using MMD. We note that, however, one consideration to make is what kernel to use when we compute the empirical estimation of MMD.\n\n**W4:** Thank you for indicating the possible confusion. The intuition comes from definition 4 on page 14, where $\\sigma$-diversity is defined to be upper bounded by the ratio of the worst-case representation difference (definition 3) and the task-average representation difference (definition 2).\nBoth representation differences in this case are actually KL-divergences due to the fact that we are doing behavioural cloning.\nConsequently, we approximate this ratio via our approximate KL metric. More details can be found in appendix B on page 15.\n\nWe once again thank reviewer StV9 for their thoughtful discussions!"
                    }
                },
                "number": 38,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700670259832,
                "cdate": 1700670259832,
                "tmdate": 1700672216029,
                "mdate": 1700672216029,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dUmLWzqUvI",
                "forum": "IQZicPtADC",
                "replyto": "vKXd8DFc9A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_StV9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Reviewer_StV9"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal Response Part 2 (continued from Part 1 earlier in this thread)"
                    },
                    "comment": {
                        "value": "**Q1:** Thank you for succinct explanation of the clear, concrete, and relatable pendulum example. I encourage you to include such an example in the main body of the paper, potentially with a visual, if you are able to find the space to do so and think it is important enough. I recognize you have some examples in the Appendix, but as you may agree, many readers tend to not visit the Appendix unless they find it vital to do so \n - Note: I recognize this is a presumption. I specifically stated \"tend to\" to not imply that all or even most readers don't visit the Appendix when they don't find it vital to do so. However there is friction in visiting the Appendix, so I'm certain that not all readers will visit it.\n\nSince transfer learning and asymmetry are central to the work, I think such an example will make the paper much more attractive, and more importantly, understandable and motivating to readers.\n\nI'm well versed in transfer learning, but I intentionally left my question open-ended so that I wouldn't induce bias into your response. I think a specific-concrete example is nice, as a general insights into this question will tend to be abstract, as they are in your paper at the moment. This isn't a bad thing. In fact, I think it's a good thing to have this generality, but I think including a specific-example in the main body would compound the strength of the correct general claim I quoted from your paper as part of my Question 1.\n\nThis is just a suggestion in my attempt to make the paper as strong as possible, and consequently, if your paper is accepted, the conference as strong as possible. I will not reduce my rating if you decide not to include a concrete example in the main body.\n\n**Q2:** Thank you for sharing this information and references from which this information is supported!\n\n**Q3-Q5:** Thank you for providing insightful answers to my questions. There is indeed overlap between **W3** and **Q3-Q5.** In case it is unclear, I listed MMD simply as an example discrepancy measure and not to suggest or imply that you use MMD specifically. In fact MMD might be the option I'd try the least out of the bunch that I listed. \n\nMy intent was to highlight that other discrepancy measures could, and arguably should, be used alongside $D_{KL}$ so that your algorithm is more robust to pitfalls of any one discrepancy measure. I understand a large benefit to using $D_{KL}$ is that minimizing $D_{KL}$ is equivalent to maximizing the log likelihood of the empirically seen (or \"true\") data distribution, which is what behavior cloning is trying to do, ASSUMING the function class has the capacity to represent the true data distribution. However, using $D_{KL}$ has often has serious downsides, or even pitfalls, by inducing a learned, generally continuous, policy that is spread over **every** seen data point in a \"convex hull\" type fashion (not exactly, usually ends up being Gaussian distribution, but the intuition is similar to capturing an approximate convex hull of the seen data points\", which generally puts much support over areas that may not have it in the true data distribution. \n\nI'm simply making explicit a trade-off with using $D_{KL}$.\n\nI will continue with a brief Part 3 on your Bhattacharyya results and more. Please do share your thoughts in the meanwhile, and thank you for your effort!"
                    }
                },
                "number": 40,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700697898866,
                "cdate": 1700697898866,
                "tmdate": 1700697898866,
                "mdate": 1700697898866,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wkxHJZ0yLS",
                "forum": "IQZicPtADC",
                "replyto": "5ec1xvbIVh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3065/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank reviewer StV9 for the continued discussions, we appreciate the amount of effort you have put in so far.\n\n**Q1:** This is a good point, we have included a pendulum example in the updated draft, please see page 5, figure 1. Generally, the result agrees with the intuition we have provided in the previous response, where the expert policy from the lower-torque variant is more robust to the higher-torque variants, but not the other way around. We hope that this addition would provide better intuition on the asymmetry of policy transfer.\n\n**Q3-Q5:** Thank you for pointing out the pitfalls of KL-divergence in the continuous setting. We agree that in practice the continuous setting is more difficult, and KL-divergence requires distribution realizability---often intractable to compute. Even in remark 3 (now moved to appendix A on page 15), our suggestion is to discretize the continuous space at the cost of the approximation error. We agree that this perhaps may be a limitation in practice, but we note that this limitation is very common in various areas of machine learning.\n\nWe once again thank reviewer StV9 for their insightful discussions. We hope they can reconsider our score after our adjustments."
                    }
                },
                "number": 41,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3065/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700702631693,
                "cdate": 1700702631693,
                "tmdate": 1700703285652,
                "mdate": 1700703285652,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]