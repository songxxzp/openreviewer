[
    {
        "title": "Langevin Monte Carlo for strongly log-concave distributions: Randomized midpoint revisited"
    },
    {
        "review": {
            "id": "5irkWxbvSh",
            "forum": "hOxgrGM63n",
            "replyto": "hOxgrGM63n",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission20/Reviewer_gtQ6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission20/Reviewer_gtQ6"
            ],
            "content": {
                "summary": {
                    "value": "The authors considered Langevin Monte Carlo method in the problem of sampling from a target distribution that has a smooth strongly log-concave density. Specifically, the authors developed a novel proof technique that led to nonasymptotic $W_2$ error bounds for the randomized midpoint method for the Langevin Monte Carlo (RLMC) and the randomized midpoint method for the kinetic Langevin Monte Carlo (RKLMC). The upper bounds are competitive with the best available results for LMC and are free from a term that\u2019s linearly dependent on the sample size. The authors also provided a nonasymptotic $W_2$ error bounds for the kinetic Langevin Monte Carlo (KLMC) algorithm that has an improved dependence on the condition number. Numerical experiments were conducted."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is well-organized and clearly written. The authors did a good job discussing backgrounds and intuitions. The proposed error bounds improved upon existing results, and the novel proof technique itself has the potential to be used to re-examine other existing analyses. The paper includes sufficient comparison with and reference to related results/literature. The authors also addressed several limitations."
                },
                "weaknesses": {
                    "value": "A major part of this paper\u2019s contribution is removing the (square root of) $mnh$ for the error bounds of RLMC and RKLMC, yet I\u2019m not clear on how important this is. The removal of this term, claimed by the authors, is an important step toward extending these results to potentials that are not strongly convex. Similarly, in the comments for the result for RKLMC, the authors claimed that not requiring the algorithm to be initialized at the minimizer of the potential is important for extending the method to non-convex potentials. However, as the authors pointed out in the discussion, strong convexity seems to be an essential assumption for these results. Therefore, I\u2019m a bit unclear on the significance of this paper\u2019s contribution."
                },
                "questions": {
                    "value": "Please see the weakness part. In particular, how would the extension to non-convex or non-strongly convex potentials depend on the authors\u2019 proposed methods?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission20/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission20/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission20/Reviewer_gtQ6"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission20/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697593810630,
            "cdate": 1697593810630,
            "tmdate": 1699635925447,
            "mdate": 1699635925447,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7CtQpMrYL6",
                "forum": "hOxgrGM63n",
                "replyto": "5irkWxbvSh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission20/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission20/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the valuable feedback. Please find out our response below.\n\n1. >`A major part of this paper\u2019s contribution is removing the (square root of) $mnh$ for the error bounds of RLMC and RKLMC, yet I\u2019m not clear on how important this is. The removal of this term, claimed by the authors, is an important step toward extending these results to potentials that are not strongly convex. Similarly, in the comments for the result for RKLMC, the authors claimed that not requiring the algorithm to be initialized at the minimizer of the potential is important for extending the method to non-convex potentials.`\n\nLet us provide some additional explanations related to these claims. First, let us explain the importance of removing the time horizon $T = nh$ from the upper bound on the discretization error. For most non-convex potentials, the associated Langevin process is not geometrically ergodic, but it can still be ergodic with a polynomial mixing rate. This implies that the time horizon necessary to achieve $\\epsilon$-accuracy for the continuous-time process depends polynomially on $1/\\epsilon$ (as opposed to the logarithmic dependence in the geometrically ergodic setting). Hence, removing from the discretization error a factor that is polynomial in $T$ would lead to an improvement of the upper bound on the overall sampling error that scales polynomially in $1/\\epsilon$.\n\nLikewise, the insistence on the initial point being at the minimizer is tailored to the (strong) convexity assumption, ensuring the computationally efficient determination of such a minimizer. Clearly, this is not the case when dealing with a non-convex potential function. \n\nTherefore, eliminating the term $T = nh$ and removing the requirement for the initialization to be at the minimizer constitute crucial steps in generalizing the results to the non-convex case.\n\n\n2. >`However, as the authors pointed out in the discussion, strong convexity seems to be an essential assumption for these results. Therefore, I\u2019m a bit unclear on the significance of this paper\u2019s contribution...\nPlease see the weakness part. In particular, how would the extension to non-convex or non-strongly convex potentials depend on the authors\u2019 proposed methods?`\n\nOne of the prevalent approaches to relaxing strong convexity is to replace it with some isoperimetric inequalities like LSI (Vempala and Wibisono, 2019) or Poincar\u00e9 inequality (Chewi et al. 2020). These conditions keep the contractivity of the Langevin diffusion without directly assuming strong convexity. \nTo analyze non-strongly convex methods (Dalalyan et al. 2022) and (Karagulyan et al. 2020) have proposed a quadratic penalization which renders the potential strongly convex. \n\nIn both cases, having explicit non-asymptotic and most importantly reproducible theoretical guarantees is quintessential to both directions. Thus, we believe that our methods will be relevant also in future work."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission20/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700685498241,
                "cdate": 1700685498241,
                "tmdate": 1700685498241,
                "mdate": 1700685498241,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "oGQF9m24lF",
            "forum": "hOxgrGM63n",
            "replyto": "hOxgrGM63n",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission20/Reviewer_FzXn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission20/Reviewer_FzXn"
            ],
            "content": {
                "summary": {
                    "value": "The paper is an in-depth study on the randomized Langevin algorithms, particularly emphasizing the Randomized Midpoint technique in LMC. It is claimed that the bounds are superior to those previously established in the literature."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper consider widely-used randomized midpoint discretizations, offering notable enhancements over current standards, particularly in terms of condition number dependency and the stability of bounds. A key advantage of these bounds is their explicit numerical constants. The Randomized Midpoint is important  to achieve optimal convergence rates in first-order algorithms. The potential of extending this technique to other domains also presents an intriguing avenue for exploration."
                },
                "weaknesses": {
                    "value": "While the paper presents some intriguing results, most of them primarily offers incremental advancements in the field. It applies the Randomized Midpoint technique to lessen discretization errors, which in turn marginally enhances the rate of convergence. However, the mathematical methods employed are not particularly interesting or surprising.\n\nThe empirical evidence looks weak to justify the criticality of the Randomized Midpoint in standard LMC."
                },
                "questions": {
                    "value": "Can you provide any empirical evidence that the current algorithm improves in real world?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission20/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission20/Reviewer_FzXn",
                        "ICLR.cc/2024/Conference/Submission20/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission20/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698546589352,
            "cdate": 1698546589352,
            "tmdate": 1700692374954,
            "mdate": 1700692374954,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bxeBdbzorM",
                "forum": "hOxgrGM63n",
                "replyto": "oGQF9m24lF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission20/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission20/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their valuable feedback. Please find our point-by-point response below.\n\n1. >`While the paper presents some intriguing results, most of them primarily offers incremental advancements in the field. It applies the Randomized Midpoint technique to lessen discretization errors, which in turn marginally enhances the rate of convergence. However, the mathematical methods employed are not particularly interesting or surprising.`\n\nWe firmly believe that our results and techniques are valuable. Although the proof technique appears straightforward, it is nontrivial, demanding additional efforts and meticulous handling of intermediate terms (refer to the detailed explanation of display (14) in the submission). Notably, our coherent treatment of the randomized midpoint method yields enhanced convergence guarantees for RLMC and RKLMC, and provides explicit dependence on the initialization and small constants. Furthermore, our technique eliminates the requirement for the algorithm to be initialized at the minimizer of the potential and removes the dependence of the upper bound on the time horizon $T = nh$. We believe that these improvements are crucial for envisioning to extend previously existing results to the case of non-convex potentials. Indeed, for a non-convex potential, it is not realistic to assume that the algorithm is initialized at a minimizer of the potential function. In addition, if the non-convex potential is such that the resulting Langevin process is not geometrically ergodic, then the time horizon necessary to achieve $\\epsilon$-accuracy for the continuous-time process depends polynomially on $1/\\epsilon$. Hence, removing from the discretization error a factor that is \npolynomial in $T$ would lead to an improvement of the upper bound on the overall sampling error that scales polynomially in $1/\\epsilon$.\n\nFurthermore, we demonstrated that our proof technique, applied to the analysis of the KLMC algorithm, leads to an enhanced upper bound on the sampling error compared to the results available in the literature. It is worth noting that many prominent researchers have worked on this problem, and our innovative approach, involving a smart application of the discrete integration by parts argument, improves upon their results.\n\n2. >`The empirical evidence looks weak to justify the criticality of the Randomized Midpoint in standard LMC.`\n\nWe note that the target density considered in the empirical studies satisfies a stricter set of assumptions. However, in this work, we aim to analyze the theoretical convergence in the worst-case scenario. In this context, the extent to which the randomized midpoint method outperforms its vanilla version depends on the properties of the target density.\n\n3. >`Can you provide any empirical evidence that the current algorithm improves in real world?`\n\nWe note that the primary focus of this submission is to present a thorough and refined theoretical analysis of midpoint randomization applied to (kinetic) Langevin Monte Carlo. While we acknowledge that demonstrating a more concrete and tangible real-world application could enhance the practical significance of our findings, delving into the applied aspects of midpoint randomization presents challenges. Factors such as the measurement of Wasserstein distance, estimation of smoothness and strong convexity parameters, etc., may require extensive efforts. Consequently, we regard this avenue as a direction for future research."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission20/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700685326905,
                "cdate": 1700685326905,
                "tmdate": 1700685326905,
                "mdate": 1700685326905,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "i2mMFQ2cy5",
            "forum": "hOxgrGM63n",
            "replyto": "hOxgrGM63n",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission20/Reviewer_4YVq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission20/Reviewer_4YVq"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers the randomized midpoint discretization for the kinetic Langevin diffusion for sampling from a target distribution with smooth and strongly log-concave density. A non-asymptotic upper bound on the W_2 error of this discretization is obtained. A bound on Euler discretization for the kinetic Langevin process is also obtained."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper provides strong error bounds on randomized midpoint discretization for the kinetic Langevin diffusion for sampling from a target distribution with smooth and strongly log-concave density. The bounds substantially improve upon earlier results, have explicit constant and transparent reliance on the initialization, and don't require starting at the minimizer of the potential. The proof technique is novel and is based on summation by part."
                },
                "weaknesses": {
                    "value": "It would be nice if some simulations in higher dimensions p could be included in Section 5."
                },
                "questions": {
                    "value": "In the second paragraph after (7), \"a close\" might be \"close\"?\n\nWould the qualitative behavior of numerical experiments change when the dimension p increases?\n\nIt seems that two notations d and p are used for dimension in Section 5."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission20/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission20/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission20/Reviewer_4YVq"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission20/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698810693135,
            "cdate": 1698810693135,
            "tmdate": 1699635925264,
            "mdate": 1699635925264,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pngFYTKNXg",
                "forum": "hOxgrGM63n",
                "replyto": "i2mMFQ2cy5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission20/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission20/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the positive and encouraging feedback.\n\n1. >`It would be nice if some simulations in higher dimensions p could be included in Section 5.`\n\nWe thank the reviewer for raising this question. Calculating the Wasserstein-2 distance in a high dimensional setting poses significant challenges. Furthermore, increasing the dimensionality may implicitly alter the strong convexity and smoothness parameters. This is the rationale behind our focus on low dimensions.\n\n\n2. Potential typos: \n\nWe thank the reviewer for pointing out the typos, and we corrected them in the revision of the paper."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission20/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700685194484,
                "cdate": 1700685194484,
                "tmdate": 1700685194484,
                "mdate": 1700685194484,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gz5Xcitd8K",
                "forum": "hOxgrGM63n",
                "replyto": "pngFYTKNXg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission20/Reviewer_4YVq"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission20/Reviewer_4YVq"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response and revision!"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission20/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700686013930,
                "cdate": 1700686013930,
                "tmdate": 1700686013930,
                "mdate": 1700686013930,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vZG3Io3Xra",
            "forum": "hOxgrGM63n",
            "replyto": "hOxgrGM63n",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission20/Reviewer_Y55L"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission20/Reviewer_Y55L"
            ],
            "content": {
                "summary": {
                    "value": "This paper revisits the problem of sampling from strongly log-concave continuous distributions in high dimensions. A classical sampling algorithm for this task is the \u201cLangevin Monte Carlo\u201d  MCMC method which uses Langevin diffusion, a stochastic differential equation (SDE) that models the motion of a particle in a fluid. This paper provides an improved analysis of the randomized discretization scheme called \u201crandomized midpoint method\u201d for the aforementioned SDE. The results rely on the assumption that the magnitude of the eigenvalues of the potential function (i.e logarithm of the distribution\u2019s density function) is both upper and lower bounded, while the ratio $\\kappa$ between these upper and lower bounds appears in the bounds presented. Specifically, faster convergence of the randomized midpoint method for Langevin diffusion is shown for sufficiently small ratio $\\kappa$. Similarly, the authors analyze the randomized midpoint method for the kinetic Langevin Monte Carlo method to obtain improved bounds, although with some slightly stronger conditions and with the advantage of not having to find a minimizer of the potential function for initialization."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This is a well written paper that provides improved results on existing algorithms for Langevin sampling, which can be potentially applicable in a wide range of problems."
                },
                "weaknesses": {
                    "value": "Some of the results are potentially still not optimal as the authors also suggest. It would also be nice to see how the improved bounds can be applied to some more concrete problems even for theoretical results. \n\n\nMinor comments:\n-Page 2, line 8: \u201cstrongly\u201d->\u201dstrong\u201d\n-Page 2, line 22: \u201cat\u201d->\u201da\u201d\n-Page 2, \u201cnotation\u201d paragraph, line 4: \u201csemi-definite positive\u201d->\u201dpositive semi-definite\u201d\n-Page 6, line 5: \u201cdesignatex\u201d->\u201ddesignate\u201d"
                },
                "questions": {
                    "value": "Do you an example application of the improved analysis do get better results for a specific problem?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission20/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission20/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission20/Reviewer_Y55L"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission20/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699354212526,
            "cdate": 1699354212526,
            "tmdate": 1699635925186,
            "mdate": 1699635925186,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lK4yrHwDhI",
                "forum": "hOxgrGM63n",
                "replyto": "vZG3Io3Xra",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission20/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission20/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their valuable feedback. Please find our response below.\n\n1. >`Some of the results are potentially still not optimal as the authors also suggest. `\n\nWhile our bound offers the best-known dependence on the condition number for Kinetic Langevin Monte Carlo, it's essential to note that the optimal dependence remains an open question. \n\n2. >`It would also be nice to see how the improved bounds can be applied to some more concrete problems even for theoretical results...\nDo you an example application of the improved analysis do get better results for a specific problem?`\n\nThe primary focus of our work is to present a thorough and refined theoretical analysis of midpoint randomization applied to Langevin Monte Carlo. While we acknowledge that demonstrating a more concrete and tangible real-world application could enhance the practical significance of our findings, delving into the applied aspects of midpoint randomization presents challenges. Factors such as the calculation of Wasserstein distance in high dimension, measurement of the distributions of the samples and the true underlying distribution, estimation of smoothness and strong convexity parameters, etc., may require extensive efforts. Consequently, we regard this avenue as a direction for future research.\n\n\n3. Potential typos: \n\nWe thank the reviewer for pointing out the typos, and we corrected them in the revision of the paper."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission20/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700685160518,
                "cdate": 1700685160518,
                "tmdate": 1700685160518,
                "mdate": 1700685160518,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]