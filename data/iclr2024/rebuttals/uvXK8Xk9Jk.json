[
    {
        "title": "DEEP NEURAL NETWORK INITIALIZATION WITH SPARSITY INDUCING ACTIVATIONS"
    },
    {
        "review": {
            "id": "pfyoH65aPs",
            "forum": "uvXK8Xk9Jk",
            "replyto": "uvXK8Xk9Jk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5260/Reviewer_FeGe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5260/Reviewer_FeGe"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies how very deep neural networks, including densely connected and convolutional networks, behave at initialization when using sparsity inducing activation functions. The two natural sparsity-inducing functions studied in the paper are the shifted ReLU activation, which is just a ReLU with a fixed bias, and the soft thresholding function, an activation that evaluates to zero in some fixed interval. The main result shows that these activations make the initialization unstable for very deep networks. This instability can be fixed by using a clipped version of these activation functions. The authors show some experiments, demonstrating that deep networks can be trained with a clipped version of the above activation functions, with minor drop in accuracy."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Using sparse networks, with sparse activations and/or sparse weights, is an important field of study, and it seems that the paper gives some contributions on how the activation function of the network should be adapted to support training networks with sparse activations. This work can potentially serve as a basis for future works on building sparse neural networks.\nThe theoretical analysis of sparse activation functions, their problematic behavior at initialization of deep networks and the solution of clipping the weights is to my understanding novel."
                },
                "weaknesses": {
                    "value": "The main weakness I find in the paper is that while the motivation for the paper comes from a practical perspective, namely building neural networks with sparse activations that can be implemented more efficiently in practice, it seems that the applicability of the results is not clear. To my understanding, the results only apply for very deep neural networks (the experiments use 100-layer networks). The authors should clarify whether or not their results apply to networks of reasonable depth. Specifically, it would be good to show some experiment for networks of reasonable depth and show how the activation choice affects the behavior. It seems that in this setting depth is only hurting performance, so while it is in theory interesting to analyze how such deep networks should be trained, it seems that the applicability of this method is limited.\n\nThe authors should also discuss the effect of adding residual connections on the stability of the network training. As residual-networks has been the main solution for training very deep networks, the authors should clarify whether their results also apply for residual networks.\n\nAdditionally, it seems that some of the experiments were left out of the main paper, and only appear in the appendix (for example, studying the CST activation and comparing the clipped activations with non-clipped ones). These are key experiments in the paper and should appear in the main text."
                },
                "questions": {
                    "value": "See above.\n\n==================\n\nScore is updated after author response."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5260/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5260/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5260/Reviewer_FeGe"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5260/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698672256082,
            "cdate": 1698672256082,
            "tmdate": 1700575050072,
            "mdate": 1700575050072,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "njBPjXvJxU",
                "forum": "uvXK8Xk9Jk",
                "replyto": "pfyoH65aPs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5260/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5260/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' response"
                    },
                    "comment": {
                        "value": "We are very grateful to the reviewer for their careful reading of our paper, thoughtful feedback, and constuctive suggestions. Below we respond to the concerns and/or questions raised. \n\n___\n\n**Comment:**  \n\nThe main weakness I find in the paper is that while the motivation for the paper comes from a practical perspective, namely building neural networks with sparse activations that can be implemented more efficiently in practice, it seems that the applicability of the results is not clear. To my understanding, the results only apply for very deep neural networks (the experiments use 100-layer networks). The authors should clarify whether or not their results apply to networks of reasonable depth. Specifically, it would be good to show some experiment for networks of reasonable depth and show how the activation choice affects the behavior. It seems that in this setting depth is only hurting performance, so while it is in theory interesting to analyze how such deep networks should be trained, it seems that the applicability of this method is limited.\n\n**Response:**\n\nWhile we agree that our paper provides primarily a theoretical contribution -- insofar as the experiments presented are on relatively simple tasks, and were primarily designed to verify the theory -- we believe that the contributions are important and of interest to the community nonetheless. The key goal of EoC initialisations is to preserve signal propagation and avoid vanishing and exploding gradients, and the best proof of the ability to do this is to show that we can train networks with very many layers. This is what motivated our choice of experiments. We should also note that our work is not unique in this regard, and similar experimental setups are relatively common in experiments which develop EoC theory. \n\nHaving said that, we think that your comment is fair and important, and that it is worthwhile to test how the comparisons play out in practice when the networks are not quite so deep. To explore this, we have repeated the DNN experiments from the paper, but with depth=30 instead of depth=100. The results are shown in the table below, and are now included in Table 4 and 5, in Appendix H."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5260/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700008328197,
                "cdate": 1700008328197,
                "tmdate": 1700008328197,
                "mdate": 1700008328197,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2pvTQiQtZW",
                "forum": "uvXK8Xk9Jk",
                "replyto": "zl2i0cQbKx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5260/Reviewer_FeGe"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5260/Reviewer_FeGe"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response.\n\nThese experiments are indeed more convincing, showing the potential applicability of the suggested sparsity inducing activation function. Therefore, I have raised my score.\n\nAbout the comparison to ResNets: I understand that presenting EOC analysis for ResNets is beyond the scope of the paper, but I believe that the authors should add experiments comparing networks with and without residual connections, studying how the modification of the activation function interacts with the residual connections. It is interesting to understand whether the stability issue of sparse networks can be solved by adding residual connections."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5260/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700575519694,
                "cdate": 1700575519694,
                "tmdate": 1700575519694,
                "mdate": 1700575519694,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "yDxssEltP9",
            "forum": "uvXK8Xk9Jk",
            "replyto": "uvXK8Xk9Jk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5260/Reviewer_qoAp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5260/Reviewer_qoAp"
            ],
            "content": {
                "summary": {
                    "value": "The authors study sparsity inducing non-linear activation functions in neural network training. They provide a theoretical analysis of the instability effects for using shifted ReLU and SoftThreshold when training FeedForward networks and CNNs, motivating their clipped versions of these functions. The authors use the previously introduced EoC initialization and show why training is stable, and becomes unstable with the introduction of a modified ReLU activation function that should induce sparsity.\nTo remedy the instability in training a further modification (clipping) is introduced and proven to be theoretically stable. They then demonstrate the feasibility of their CReLU and CST activation functions for training deep and wide networks on MNIST and CIFAR10, showing only minor degradation in prediction accuracy with tunable levels of activation sparsity.\n\nOverall, the paper is nicely written and relatively easy to follow, despite the math-heavy theoretical section. The argumentation on instability of the shifter ReLU and SoftThreshold seems valid, and the experiments, though not extensive, provide a proof-of-concept of the author\u2019s claim. The idea of clipping the activation functions to achieve stability is as simple as it is effective, providing a valid contribution that can be actually translated into application.  However, a bit more in-depth evaluation of certain aspects would be nice. The findings are interesting, though presentation is lacking, as well as more exploration of the introduced concept."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The proposed clipped functions are an easy and natural extension of already existing activation functions.\n- The introduced parameters tau and m are able to control sparsity and training stability as shown theoretically and experimentally."
                },
                "weaknesses": {
                    "value": "- The stddev in table 2 are a bit odd to me, either a higher numerical precision is needed, or it needs to be explained why the are many cases of zero std.\n- Results on ST are only shown in the appendix. They should be shown and discussed in the main paper, given that they are an essential part in the rest of the manuscript.\n- the higher sparsity regime in table 2 (s=0.85) needs to be explored/explained more, there are interesting things happening.\n- There is no comparison to existing methods, but the authors clearly describe the lack of related research.\n- No source Code provided, implementation details on experiments only in the appendix"
                },
                "questions": {
                    "value": "- I don\u2019t fully understand the meaning of Figure 4 and it is not sufficiently discussed in the manuscript.\n- The important EoC concept is not motived and explained enough."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5260/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698748620125,
            "cdate": 1698748620125,
            "tmdate": 1699636525141,
            "mdate": 1699636525141,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "cyzKrm5bha",
                "forum": "uvXK8Xk9Jk",
                "replyto": "yDxssEltP9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5260/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5260/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' response"
                    },
                    "comment": {
                        "value": "We are very grateful to the reviewer for their careful reading of our paper, thoughtful feedback, and constuctive suggestions. Below we respond to the concerns and/or questions raised. \n\n___\n\n**Comment:**  \n\n\"The stddev in table 2 are a bit odd to me, either a higher numerical precision is needed, or it needs to be explained why the are many cases of zero std.\"\n\n**Response:**\n\nIndeed most of the 0.00 standard deviations were simply because the results in the table were rounded to 2 decimal places. We have amended Table 2 to include higher precision to make the results clearer. 0.00 standard deviation was only accurate to higher precision as well in the cases when all of the seeds completely fail to train at all. Thank you for this suggestion.\n    \n___\n\n**Comment:**  \n\n\"Results on ST are only shown in the appendix. They should be shown and discussed in the main paper, given that they are an essential part in the rest of the manuscript.\"\n\n**Response:**\n\nThank you for this suggestion. Putting $ReLU_\\tau$, $ST_\\tau$, and $CST_{\\tau, m}$ experimental results in the Appendix was originally done purely due to space constraints, but we acknowledge and agree that it is important for all key experimental results to appear in the main paper. In order to make space, we simplified and combined Figures 2 and 3, and so we have now included all the important experimental results in Table 2. \n    \n___\n\n**Comment:**  \n\n\"The higher sparsity regime in table 2 (s=0.85) needs to be explored/explained more, there are interesting things happening.\"\n\n**Response:**\n\nWe agree that the high sparsity regime is very interesting! But we suggest that our analysis of the impact of $s$ and $m$ on the shape of the corresponding variance maps and the related failure modes accounts for the results quite nicely. In particular, we see that initially increasing $m$ is necessary to achieve good accuracy at high sparsity, as expected. However, as predicted by the theory, increasing $m$ too much results in $V'(q^*)$ and $V''(q^*)$ together being too large, causing $q^*$ to fail to be stable in practice. This relates to your other question about Figure 4. The phenomenon described here is exactly what is illustrated in Figure 4, which shows the Variance maps of $CReLU_{\\tau,m}$ and $CST_{\\tau, m}$ in the high sparsity, large $m$ regime. When the variance map curves of to trace or even cross the $q=V(q)$ line, the result is that $q^l$ does not converge to $q^*$, and instead remains larger than $q^*$ layer on layer. Figure 4 shows that the corresponding $\\chi_1$ value in this case is larger than one, which causes exploding gradients and training failure. We have tweaked the wording at the bottom of page 8 in Section 4 to make it clearer which point from the main text Figure 4 is illustrating.\n\nIf you still think something is not clear, could you perhaps explain what analysis you think is missing? \n\n___\n\n**Comment:**  \n\nNo source Code provided, implementation details on experiments only in the appendix.\n\n**Response:**\n\nThe implementation details were left to the appendix due to space constraints. We ask that this please not be considered a weakness of our paper.  We are working to make the source code available and will alert you if this is possible before the discussion period concludes."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5260/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700008132788,
                "cdate": 1700008132788,
                "tmdate": 1700008132788,
                "mdate": 1700008132788,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "8kkqh69qUm",
            "forum": "uvXK8Xk9Jk",
            "replyto": "uvXK8Xk9Jk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5260/Reviewer_auBc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5260/Reviewer_auBc"
            ],
            "content": {
                "summary": {
                    "value": "The paper aims to encourage high sparsity in the activations of neural networks with the motivation to reduce computational cost. To this end, the authors study the activation dynamics induced by common sparsity inducing nonlinearities such as ReLU and Soft-Thresholding (ST) under random initialization. The authors, via the large width Gaussian process limit of neural networks, discover a training instability for ReLU and ST nonlinearities. They show that the instability can be resolved by clipping the outputs of these nonlinearities. The authors validate the theory through experiments and show that the modification allows training MLPs and CNNs with very sparse activations with no or little reduce in test accuracy."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "* The writing is very clear and easy to follow.\n* The theory is elegant.\n* The theory works in practice and the authors effectively demonstrate being able to train neural networks while maintaining high activation sparsity."
                },
                "weaknesses": {
                    "value": "Minor weaknesses:\n* There could have been a study of the computational efficiency since that is the main motivation of the work."
                },
                "questions": {
                    "value": "Questions:\n- Is this the first time that the variance map equations are being derived for these non-linearities?\n\nMinor:\n- Plots of Figure 2 are missing axis labels and the plot legends are not readable on printed paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5260/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5260/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5260/Reviewer_auBc"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5260/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698837795348,
            "cdate": 1698837795348,
            "tmdate": 1699636525045,
            "mdate": 1699636525045,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vHyQatDymF",
                "forum": "uvXK8Xk9Jk",
                "replyto": "8kkqh69qUm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5260/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5260/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' response"
                    },
                    "comment": {
                        "value": "We are very grateful to the reviewer for their careful reading of our paper, thoughtful and positive feedback, and constructive suggestions. Below we respond to the concerns and/or questions raised. \n\n___\n\n**Comment:**  \n\n\"Is this the first time that the variance map equations are being derived for these non-linearities?\"\n\n**Response:**\n\nYes, to the best of our knowledge this is the first time they have been derived.\n\n___\n\n**Comment:**  \n\n\"Plots of Figure 2 are missing axis labels and the plot legends are not readable on printed paper.\" \n\n**Response:**\n\nThank you for highlighting this. We have added axis labels and enlarged the legend font. \n\n___\n\n**Comment:**  \n\n\"There could have been a study of the computational efficiency since that is the main motivation of the work.\"\n\n**Response:**\n\nUnfortunately it was not possible for us to perform an empirical study of the computational efficiency gains due to sparser activations, because the sparse operations necessary to leverage sparse activations are not yet well supported on the accelerator hardware on which we are running our experiments. However, better support  for efficient sparse operations is a high priority and ongoing research area for both deep learning hardware and software developers, given the potential performance gains. The  number of flops in each matrix-vector multiplication $AB$ for $A \\in \\mathbb{R}^{m \\times n}$, $B \\in \\mathbb{R}^{n \\times d}$  in the forward pass could in theory shrink from $\\mathcal{O}(mnd)$ to $\\mathcal{O}(msd)$."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5260/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700007857583,
                "cdate": 1700007857583,
                "tmdate": 1700007857583,
                "mdate": 1700007857583,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jSiEf1LVmO",
                "forum": "uvXK8Xk9Jk",
                "replyto": "vHyQatDymF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5260/Reviewer_auBc"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5260/Reviewer_auBc"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the response. I very much enjoyed reading your paper and I retain my positive opinion of the work."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5260/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700504215061,
                "cdate": 1700504215061,
                "tmdate": 1700504215061,
                "mdate": 1700504215061,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "I4xAWbXsvi",
            "forum": "uvXK8Xk9Jk",
            "replyto": "uvXK8Xk9Jk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5260/Reviewer_TyEd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5260/Reviewer_TyEd"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the effect of sparsity on the activation function for deep neural network initialization using the existing dynamical isometry and edge of stability theory. In particular, the authors compute the so-called variance map and correlation maps for sparse activating functions, namely, shifted ReLU and soft thresholding, and interpret the shape of these maps, in particular, the values $V'(q^*)$ and $V''(q^*)$ to explain the failure. Then they propose magnitude clipping as a remedy and empirically show that with these magnitude-clipped sparse activation functions, it is possible to train the deep net without losing test accuracy and with high test fractional sparsity."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper introduces two natural classes of activation functions with a tunable parameter $\\tau$. I think understanding what activation function works better for which purpose is an active and fascinating area which I also believe is to appeal to general interest. Sparsity is particularly an important goal to achieve for modern large deep learning. Making sure that the network has non-exploding or non-vanishing gradients at initialization is indeed a sufficient condition for the applicability of an activation function.\n\nThe introduction is well-written. \n\nOn the flip side, I am not entirely sure why sparse ReLU fails to train. Table 2 only shows results for magnitude clipping for CReLU and the usual ReLU with $\\tau=0$."
                },
                "weaknesses": {
                    "value": "I have three major questions that I wasn't able to resolve by reading the main text only.\n\n1. What is the criterion on $V_\\phi$ for successful training? For example, let's see Figure 2. Which of the shapes are good and expected to train well vs which are the ones that are expected to fail? I see that for $\\tau=1$ the curves have higher curvature. In particular, the blue curve intersects the line $x=y$ at one point where the derivative is non-zero but the curvature is positive. Is this expected to fail because the derivative is non-zero? I found the explanations in the text somehow repetitive and hard to parse. Can the authors explain the criterion on $V_\\phi$ in words just from Figure 2? \n\n2. Can the authors please provide experiments with CReLU $m=0$ as well and also for ReLU in Table 2? Why is there only one row for ReLU?\nAs the table stands now, I am not convinced that sparse activation functions without magnitude clipping fail to train. Is the 'unstable training dynamics' reported in the paper for very large $s$ and small $m$ as claimed in the conclusion?"
                },
                "questions": {
                    "value": "Also, I do not understand the heuristics given in Section 3.1 for how to choose $m$. I understand the dependence of $V'(q^*)$ and $V''(q^*)$ on the magnitude value $m$ is non-trivial from Figure 4. Still, the curves follow regular shapes so maybe it is possible to give simple heuristics based on Figure 4?\n\nI will consider increasing my score based on the author's response to my questions."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5260/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698958721290,
            "cdate": 1698958721290,
            "tmdate": 1699636524954,
            "mdate": 1699636524954,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "axo7Bkzhet",
                "forum": "uvXK8Xk9Jk",
                "replyto": "I4xAWbXsvi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5260/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5260/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' response part 1"
                    },
                    "comment": {
                        "value": "We are very grateful to the reviewer for their careful reading of our paper, thoughtful feedback, and constructive suggestions. Below we respond to the concerns and/or questions raised. \n\n___\n\n**Comment:**  \n\n\"I am not entirely sure why sparse ReLU fails to train. Table 2 only shows results for magnitude clipping for CReLU and the usual ReLU with $\\tau=0$.\" and \"What is the criterion on $V_\\phi$ for successful training? For example, let's see Figure 2. Which of the shapes are good and expected to train well vs which are the ones that are expected to fail? I see that for $\\tau=1$ the curves have higher curvature. In particular, the blue curve intersects the line x = y at one point where the derivative is non-zero but the curvature is positive. Is this expected to fail because the derivative is non-zero? I found the explanations in the text somehow repetitive and hard to parse. Can the authors explain the criterion on $V_\\phi$ in words just from Figure 2?\"\n\n**Response:** \n\nAccording to the theory, two things are required for stable training: \n\n1. we require that $\\chi_1 = 1$, which guards against vanishing and exploding gradients as well as instability to input perturbations at initialisation.\n\n2. we require that the variance map $V(q)$ is sufficiently stable around $q^*$ such that $q^l$ does in practice converge to and remain at $q^*$. This is a necessary requirement for the EOC initialisation in practice since $q^*$ is used in the calculation of the values of $\\sigma_w$ and $\\sigma_b$ in order to ensure $\\chi_1 = 1$. If in practice $q^l$ does not stably converge to  $q^*$, and instead grows larger, then we no longer have $\\chi_1=1$ and experience the associated training failure modes of exploding or vanishing gradients.\n\nThe problem we have shown with $ReLU_\\tau$ and $ST_\\tau$ is precisely that it is impossible for them to satisfy both criteria $\\chi_1=1$ and $q^l$ converging stably to $q^*$. \n\nIn light of the above, we agree that the original Figures 2 and 3 could be misleading, since they included variance maps for $ReLU_\\tau$ and $ST_\\tau$ which did not correspond to EOC initialisation. To address your question and to improve clarity on this point we have combined Figures 2 and 3 into a single figure, now showing only the variance maps for both activation functions corresponding to $\\chi_1=1$. We have also edited Section 2 of the paper to make this point more clearly (in particular see paragraphs 2, 3, 4, and 5 of Section 2 in the updated version). We think it reads better now, so thank you for this helpful feedback. \n\n___\n\n**Comment:**  \n\n\"Why is there only one row for ReLU?\"\n\n**Response:**\n\nStandard ReLU was simply included in Table 2 as a baseline, a commonly used activation function against which we can compare the accuracy and activation sparsity in our experiments."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5260/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700006910781,
                "cdate": 1700006910781,
                "tmdate": 1700006910781,
                "mdate": 1700006910781,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]