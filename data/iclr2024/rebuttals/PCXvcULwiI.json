[
    {
        "title": "Benchmarking Structural Inference Methods for Interacting Dynamical Systems with Synthetic Data"
    },
    {
        "review": {
            "id": "66dm30amX3",
            "forum": "PCXvcULwiI",
            "replyto": "PCXvcULwiI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5073/Reviewer_gd54"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5073/Reviewer_gd54"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a number of benchmark datasets for inferring dynamical systems from observations. Specifically, the object of interest is to uncover the adjacency matrix underlying the generation of the data. The authors then review a number of methods that have been developed for this particular task and describe their properties. To compare the different methods, the authors then apply a number of different algorithms to these benchmarks and discuss the performance between the methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The authors provide a reasonably comprehensive review of the existing methods and propose a number of relevant benchmarks datasets for reliably comparing the performance of different solutions to this problem. \n\nThe authors try to make the datasets realistic by imposing statistics from real world datasets into the synthetic datasets that they impose. Since this is graph discovery problem, often the underlying structure is impossible to obtain a ground truth."
                },
                "weaknesses": {
                    "value": "The proposed datasets seem a bit random. For example, the authors state that the miRNA dataset is too specific, but the springs dataset is a reasonable benchmark. The springs dataset seems very specific and maybe a bit contrived for most purposes. \n\nAll the benchmarked methods are synthetic with some real statistics being components. It would be nice to have some real datasets, but obtaining a ground truth structure would be impossible. I think it would be good if the authors could discuss this aspect in greater detail and describe how one can make the datasets be more realistic."
                },
                "questions": {
                    "value": "In the preliminaries section, should the vertex set be $\\{V_i, 1 \\leq i \\leq n\\}$ instead of $N$?\n\nAre there any other datasets that could be used that have a more defined structure? For example, some of the gene regulatory network datasets are popular applications of this methodology, and I would like to see if there are any that could be used for the purposes of evaluation."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5073/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5073/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5073/Reviewer_gd54"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5073/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698502978681,
            "cdate": 1698502978681,
            "tmdate": 1699636498244,
            "mdate": 1699636498244,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "D7jMF4Au62",
                "forum": "PCXvcULwiI",
                "replyto": "66dm30amX3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer gd54 (Part 1)"
                    },
                    "comment": {
                        "value": "We would like to thank Reviewer gd54 for the thoughtful comments. We are happy that the reviewer thought our benchmarking study is equipped with both review of the investigated methods and reliable benchmarking datasets. We are glad that the reviewer agreed with the challenges in obtaining real-world data for structural inference. Here are our answers to the concerns raised by the reviewer:\n\n> **W1.** The proposed datasets seem a bit random. For example, the authors state that the miRNA dataset is too specific, but the springs dataset is a reasonable benchmark. The springs dataset seems very specific and maybe a bit contrived for most purposes.\n\nIn response to your concerns about our selection of datasets, we would like to further clarify our rationale. The miRNA dataset, while valuable in its specific biological context, was deemed less suitable for our study due to its lack of chaotic dynamics. This is a critical aspect we are focusing on. In miRNA simulations, the infinitesimal changes in RNA concentration levels do not typically result in significant long-term differences in gene expression. This is due to the relatively stable inter-regulatory relationships within the miRNA network, which limits its representation of chaotic systems. In essence, the miRNA dataset does not sufficiently capture the unpredictability and sensitivity to initial conditions that are characteristic of chaotic systems.\n\nOn the other hand, the Springs dataset, despite appearing specific, is actually a more relevant and illustrative example for our study. This dataset effectively models the N-body problem, a classic example of chaotic dynamics. It employs second-order differential equations to describe the interactions between objects, accurately capturing the essence of chaotic behavior. In such systems, minor initial variations can lead to significantly divergent outcomes over time, making it a compelling choice for illustrating the complex and unpredictable nature of chaotic dynamics.\n\nTherefore, while the Springs dataset might initially seem specific or contrived, it is, in fact, a more universally applicable and illustrative example for the study of chaotic dynamics, which is a central focus of our research. Our decision to favor the Springs simulation over the miRNA dataset was driven by this desire to explore and model the unpredictability and sensitivity to initial conditions inherent in chaotic systems, elements that are less pronounced in the miRNA simulations.\n\n----------------------"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700238064362,
                "cdate": 1700238064362,
                "tmdate": 1700238064362,
                "mdate": 1700238064362,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kfL7cXuGzP",
                "forum": "PCXvcULwiI",
                "replyto": "66dm30amX3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer gd54 (Part 3)"
                    },
                    "comment": {
                        "value": "> **Q2.** Are there any other datasets that could be used that have a more defined structure? For example, some of the gene regulatory network datasets are popular applications of this methodology, and I would like to see if there are any that could be used for the purposes of evaluation.\n\nThank you for your question about incorporating more defined datasets, such as gene regulatory network (GRN) datasets (the ones used in [1]). Your suggestion aligns perfectly with our objective to enhance the applicability and relevance of our benchmarking approach. Apart from GRN datasets, we may also use following datasets for evaluation: road maps in California [3], and chemical reaction networks [4]. \n\n1. **Gene Regulatory Network (GRN) Datasets:** We recognize the potential of GRN datasets in providing a more concrete structure for evaluation. While we find the idea promising, we need to assess the reliability and representativeness of these datasets before inclusion. Notable examples under consideration are datasets from the DREAM challenges [2] and other widely-recognized, publicly available resources that have been used in benchmarking studies.\n2. **Road Maps in California (PEMS Dataset):** The PEMS dataset [3], with its traffic flow data from numerous sensors across California's roads, offers an intriguing possibility for reconstructing road maps. However, challenges such as missing data and dynamic changes in graph structures due to road construction need to be addressed, as these factors could significantly affect the accuracy of our inferences.\n3. **Chemical Reaction Networks [4]:** The dynamic nature of chemical reaction networks presents a unique opportunity for evaluation. A critical factor here is determining the appropriate observation intervals to accurately capture the dynamics involved, which is crucial for effective structural inference in such complex systems.\n\nWe acknowledge that there are other datasets potentially suitable for evaluating structural inference methods. Our team is actively exploring these options and aims to include more diverse datasets in our future research. We believe that, incorporating datasets like GRNs not only enhances the robustness of our study but also paves the way for applying our methodologies to real-world problems in fields such as biology , geography and chemistry.\n\nWe would like to thank Reviewer gd54 for the positive and inspiring comments. We hope our answers have successfully addressed the concerns. To facilitate easy identification, sections and paragraphs that have been revised in the manuscript are highlighted in blue.\n\n----------------------\n\n### References\n\n[1] A. Pratapa, A.P. Jalihal, J.N. Law, A. Bharadwaj, T.M. Murali. Benchmarking algorithms for gene regulatory network inference from single-cell transcriptomic data. *Nat Methods* **17**, 147\u2013154 (2020).\n\n[2] K. Sun, D. Yu, J. Chen, D. Yu, Y. Choi, C. Cardie. Dream: A challenge data set and models for dialogue-based reading comprehension. Transactions of the Association for Computational Linguistics. 2019 Apr 1;7:217-31.\n\n[3] C. Chen, K. Petty, A. Skabardonis, P. Varaiya and Z. Jia. Freeway performance measurement system: mining loop detector data. Transportation Research Record 1748(1):96\u2013102.\n\n[4] W. Poole, A. Pandey, A. Shur, Z.A. Tuza, R.M. Murray. BioCRNpyler: Compiling chemical reaction networks from biomolecular parts in diverse contexts. PLOS Computational Biology. 2022 Apr 20;18(4):e1009987."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700238156696,
                "cdate": 1700238156696,
                "tmdate": 1700239092715,
                "mdate": 1700239092715,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NlyrmQxRkJ",
                "forum": "PCXvcULwiI",
                "replyto": "kfL7cXuGzP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5073/Reviewer_gd54"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5073/Reviewer_gd54"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you to the authors for their hard work and for responding to the review. I believe my concerns were effectively addressed. I'll keep my score and recommend accept for the paper, I think it can be a valuable contribution for people wanting to investigate these types of problems."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700500121005,
                "cdate": 1700500121005,
                "tmdate": 1700500121005,
                "mdate": 1700500121005,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "64HxpaaKwi",
            "forum": "PCXvcULwiI",
            "replyto": "PCXvcULwiI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5073/Reviewer_MpHi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5073/Reviewer_MpHi"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a benchmark for a dynamic system, which is often represented as agents engaged in interactions, forming what we term an interaction graph. Motivated by the fact that the existing methods have often been assessed on distinct datasets and specific graph types, the paper presents a unified benchmark to evaluate the existing methods on the different interaction graphs. The paper also benchmarks the scalability and the robustness of the existing methods."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper presents the first benchmark for dynamic systems, which could facilitate future research.\n2. The benchmark evaluates performances, scalability, and robustness.\n3. The benchmark results could save the efforts for future research in this domain."
                },
                "weaknesses": {
                    "value": "1. The experiments rely on some synthetic datasets. However, it is unclear if the synthetic datasets are representative enough for real-world dynamic systems. It is also unclear how reliable it is to benchmark these synthetic data, i.e., whether the observations are reliable.\n2. The package is mainly based on Python and R. It is unclear whether the implementation is efficient."
                },
                "questions": {
                    "value": "How to ensure the synthetic datasets align with the real-world dynamic systems?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5073/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698514964052,
            "cdate": 1698514964052,
            "tmdate": 1699636498137,
            "mdate": 1699636498137,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kC4WsktbDy",
                "forum": "PCXvcULwiI",
                "replyto": "64HxpaaKwi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer MpHi"
                    },
                    "comment": {
                        "value": "We are grateful to Reviewer MpHi for the insightful comments and are pleased that the reviewer recognize the originality and comprehensive nature of our benchmarking study, as well as its value to the research community. We have carefully considered the concerns raised and provide the following responses:\n\n> **W1.** The experiments rely on some synthetic datasets. However, it is unclear if the synthetic datasets are representative enough for real-world dynamic systems. It is also unclear how reliable it is to benchmark these synthetic data, i.e., whether the observations are reliable.\n\nWe appreciate your concern regarding the representativeness and reliability of our synthetic datasets in benchmarking real-world dynamic systems. As detailed in Section 4, our synthetic data generation process has been meticulously designed to emulate real-world scenarios closely. We construct interaction graphs that reflect the network properties of real-world graphs, as outlined in Table 1, to ensure our models accurately capture real-world system characteristics. Additionally, the dynamics within these graphs are simulated using NetSims and Springs methods, chosen for their widespread adoption in structure inference research. These methods offer a robust benchmark aligned with field practices, presenting a comprehensive challenge to structure inference methods and allowing us to rigorously assess their performance in complex and chaotic dynamics.\n\n------\n> **W2.** The package is mainly based on Python and R. It is unclear whether the implementation is efficient.\n\nWe thank you for highlighting the efficiency of our Python and R-based packages. We have adhered closely to the original scripts provided by authors with minimal modifications. This approach allows our benchmark to include methods with diverse computational requirements and implementations across various programming languages, including Python, R, Julia, and C++ (with Python or R wrappers). Given the variety of methods optimized for GPU and CPU, with varying degrees of parallelizability, a direct comparison of implementation efficiency is not feasible within our study's scope. Our primary goal is to evaluate these methods' applicability, with efficiency optimization being a secondary concern. For large-scale applications, we provide the flexibility to optimize or rewrite the code in more efficient languages like C++ or CUDA, catering to diverse research needs.\n\n------\n> **Q.** How to ensure the synthetic datasets align with the real-world dynamic systems?\n\nYour question about aligning our synthetic datasets with real-world dynamic systems is crucial for our study's validity and applicability. To ensure this alignment:\n\n1. **Realistic Parameter Selection**: Parameters for generating underlying interaction graphs are based on real-world graphs from eleven disciplines, incorporating realistic variable ranges and special structure biases like self-loops from empirical studies.\n2. **Incorporation of Real-World Characteristics**: Our datasets are designed to include key characteristics of real-world systems, such as trajectories with noise, variability in initialization, and different dynamics types. We model these dynamics using models of first and second order ODE and models with quadratic dependencies, capturing real-world complexity and unpredictability.\n3. **Transparency and Limitations**: We have documented our dataset creation methods and assumptions, allowing other researchers to understand the limitations and potential biases, ensuring informed application of our datasets.\n\nIn conclusion, while achieving perfect real-world alignment is challenging, our steps ensure that our synthetic datasets are as close a representation as possible, making them valuable for dynamic system modeling research.\n\nWe thank Reviewer MpHi once again for their thorough review and hope our responses fully address the concerns."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700238006784,
                "cdate": 1700238006784,
                "tmdate": 1700238171225,
                "mdate": 1700238171225,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "F1MlC4db7b",
                "forum": "PCXvcULwiI",
                "replyto": "64HxpaaKwi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A gentle reminder for the closing rebuttal window"
                    },
                    "comment": {
                        "value": "Dear Reviewer MpHi,\n\nWe hope this message finds you well. As the deadline for the author-reviewer discussion phase is approaching, we wanted to respectfully inquire whether our rebuttal to your review of our paper has successfully addressed the concerns you raised.\n\nWe deeply appreciate the insights and feedback you provided, on the synthetic datasets and the implementation of the baseline methods, which have been instrumental in enhancing the quality of our work. In our rebuttal, we endeavored to thoroughly address each of the points you mentioned, and we are keen to know if our responses meet your expectations and clarify the aspects you highlighted.\n\nWe understand that you have a busy schedule, and we greatly appreciate any time you can spare to provide us with your feedback on our rebuttal. Your insights are not only important for the review process but also invaluable for our continued learning and development in this area.\n\nThank you once again for your time and expertise. We look forward to your response.\n\nBest regards,\nAuthors"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700569899884,
                "cdate": 1700569899884,
                "tmdate": 1700569899884,
                "mdate": 1700569899884,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KRJ1svLbeV",
                "forum": "PCXvcULwiI",
                "replyto": "F1MlC4db7b",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5073/Reviewer_MpHi"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5073/Reviewer_MpHi"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "I would like to thank the authors for the response and the reminder. However, I am not convinced that the synthetic datasets are reliable since they are simulated with assumptions, such as ODEs and Gaussian noise. Thus, the benchmark results may not be scientifically reliable. If it would be more convincing to collect real-world data to construct the datasets.\n\nRegarding the package implementation, I am concerned about the usability of the package since it is implemented across various programming languages, including Python, R, Julia, and C++. The usability of the package is important for a benchmark paper since future research may use it. It is also uncertain how efficient the implementation is as there is no benchmark comparison.\n\nThus, I will not change my score."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700671513147,
                "cdate": 1700671513147,
                "tmdate": 1700671513147,
                "mdate": 1700671513147,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WG0XAWpfDM",
                "forum": "PCXvcULwiI",
                "replyto": "64HxpaaKwi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for response."
                    },
                    "comment": {
                        "value": "Dear Reviewer MpHi,\n\nThank you for your feedback on our manuscript. We would like to clarify some points regarding your response, with the aim of enhancing the scientific discourse around our work.\n\nFirstly, we acknowledge the uniqueness of our study as the **first to benchmark structural inference methods**. The utilization of simulation data and original implementations in our benchmarking process, we argue, **is not a limitation** but rather a foundational step that paves the way for future research. This approach provides a controlled environment to evaluate and compare different methods systematically.\n\nIn response to your first question (Q1) in the response, we value your perspective on the challenges associated with collecting real-world data that possess a reliable underlying graph structure, which is indeed a critical concern in our field of research. We recognize the importance of including real-world datasets in our study and welcome any recommendations for datasets that meet specific criteria. These include datasets with **a trustworthy ground truth for interaction graphs**, those that contain **both one-dimensional and multi-dimensional data**, and those featuring **graphs of varying sizes**. We are also open to any suggestions or methodologies you could provide for collecting such data in a manner that would allow us to benchmark these datasets effectively, evaluating their **accuracy, scalability, robustness, and sensitivity to graph properties**.\n\nWe must acknowledge, however, that gathering reliable datasets can be a time-consuming and costly endeavor. Therefore, any specific instructions or insights from you in this regard would be immensely valuable to our study. We concur that real-world data typically present a host of challenges, including data occlusion, measurement errors, and the inherent limitations in capturing a comprehensive scope of all nodes. These challenges highlight the complexity and intricacy involved in evaluating structural inference methods in a way that is both unified and objective, as well as reproducible. Any *guidance you can provide* on enhancing the reliability and representativeness of these observations would be greatly appreciated and would significantly contribute to the robustness and relevance of our research.\n\nIn response to your second question (Q2), we have adopted the **original implementations** of these methods directly from their respective literature to ensure **accuracy and consistency** in our benchmarks. In our revised submission, we have added Appendix D.6, which details the running time for each method. Our study aims to provide comprehensive benchmarking results and practical use cases for these methods, enabling researchers to select and implement the most suitable approach for their needs, which is also confirmed by your review *\"3. The benchmark results could save the efforts for future research in this domain\"*. We have provided **detailed instructions and resources** on our anonymous GitHub repository for each method, facilitating their installation and application. We believe that the ease of installing Python, R, Julia, and C++, as is common in our field, should not pose a significant barrier.\n\nWe are committed to contributing meaningful insights to this domain and appreciate the opportunity to discuss and refine our work based on your valuable feedback.\n\nThank you once again for your time and review.\n\nBest regards,\nAuthors"
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700674085786,
                "cdate": 1700674085786,
                "tmdate": 1700674271046,
                "mdate": 1700674271046,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Nzm62nZgCM",
            "forum": "PCXvcULwiI",
            "replyto": "PCXvcULwiI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5073/Reviewer_fGzL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5073/Reviewer_fGzL"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors introduce a unified and objective benchmark comprising 12 structural inference methods. To overcome the challenges of collecting real-world datasets, the authors meticulously curate a synthetic dataset with over 213,444 trajectories. The benchmark not only aids researchers in method selection for specific problem domains but also serves as a catalyst for inspiring\nnovel methodological advancements in the field."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ I appreciate the authors release the source datasets and provide a nice website.\n+ Extensive experiment for the inference of dynamical systems.\n+ I believe this work provides insightful findings of exploring structural inference on real-world dynamical systems.\n+ Detailed introduction of implementations."
                },
                "weaknesses": {
                    "value": "- Why Gaussian noise. Can the authors consider other types of noises? Also, can the authors test the models' performance under Gaussian noise with different conditions.\n- Complexity/running time is missing.\n- I wonder can the authors consider robust testing for this paper?"
                },
                "questions": {
                    "value": "Please see the comments in Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "Not applicable."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5073/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699071469309,
            "cdate": 1699071469309,
            "tmdate": 1699636498059,
            "mdate": 1699636498059,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wXb9xM1ZEy",
                "forum": "PCXvcULwiI",
                "replyto": "Nzm62nZgCM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer fGzL (Part 1)"
                    },
                    "comment": {
                        "value": "We extend our sincere gratitude to Reviewer fGzL for the thorough review and insightful feedback on our paper. We are delighted that the accessibility of our datasets and the comprehensiveness of our website were well-received. Additionally, we appreciate your recognition of our extensive experiments, insightful findings, and detailed implementations. Here are our answers to the concerns of the reviewer:\n\n> **W1.** Why Gaussian noise. Can the authors consider other types of noises? Also, can the authors test the models' performance under Gaussian noise with different conditions.\n\nWe thank you for raising the question about our choice of Gaussian noise and the exploration of alternative noise models in our study. Our initial use of Gaussian noise was guided by its fundamental role in scientific modeling, given its well-characterized bell-shaped distribution and its definition by two simple parameters: mean and variance. And most measurement errors can be modeled with Gaussian noise. This choice aligns with the standard practices in structural inference research, as evidenced by its frequent application in seminal works [1, 2]. The linear and additive nature of Gaussian noise simplifies both analytical and computational modeling, making it an ideal candidate for initial model assessments.\n\nHowever, we fully acknowledge the diversity of noise types encountered in real-world data, which often deviate from the idealized Gaussian model. Variants such as Poisson, uniform, and salt-and-pepper noise present unique challenges and characteristics that are critical to consider for a comprehensive evaluation of our methods.\n\nIn line with your valuable suggestion, we plan to extend our study to include these various noise types. This broader approach will allow us to assess the robustness and adaptability of our models under a wider range of conditions, enhancing the applicability and relevance of our findings.\n\nRegarding the specific request to evaluate our models under differing Gaussian noise conditions, we aim to conduct additional experiments varying both the mean and variance of the noise. This will enable us to better understand the resilience and precision of our models under a spectrum of noise intensities and distributions. We believe that these further analyses will greatly enrich our comprehension of the practical limits and strengths of our approaches in real-world scenarios, where noise characteristics can be highly unpredictable.\n\nWe regret to inform that due to resource constraints, it might not be feasible to complete these additional experiments before the rebuttal deadline. However, we are committed to pursuing this extended analysis and will update our findings on our website and in future publications as soon as they are available. We encourage interested readers and fellow researchers to stay connected for these upcoming developments.\n\n------"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700237833026,
                "cdate": 1700237833026,
                "tmdate": 1700237833026,
                "mdate": 1700237833026,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QZfjwumfOq",
                "forum": "PCXvcULwiI",
                "replyto": "Nzm62nZgCM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer fGzL (Part 2)"
                    },
                    "comment": {
                        "value": "> **W2.** Complexity/running time is missing.\n\nWe appreciate your insightful comment on the necessity of including running time information for the structural inference methods we investigated. In response, we have added a detailed table summarizing the average running times, calculated over ten runs. The times are reported in minutes unless otherwise specified:\n\n| Methods \\ Node size | 15          | 30          | 50          | 100          |\n| ------------------- | ----------- | ----------- | ----------- | ------------ |\n| ppcor               | <1          | <1          | <1          | <1           |\n| TIGRESS             | 7.91        | 15.66       | 31.66       | 113.92       |\n| ARACNe              | <1          | <1          | <1          | <1           |\n| CLR                 | <1          | <1          | <1          | <1           |\n| PIDC                | <1          | <1          | <1          | 1.00         |\n| scribe              | 13.67       | 46.51       | 130.32      | 548.60       |\n| dynGENIE3           | 3.47        | 12.43       | 1.57        | 2.29         |\n| XGBGRN              | <1          | <1          | 1.50        | 4.70         |\n| NRI                 | 22.35 hours | 31.03 hours | 39.65 hours | 45.91 hours  |\n| ACD                 | 40.14 hours | 52.90 hours | 69.37 hours | 83.15 hours  |\n| MPM                 | 44.20 hours | 59.02 hours | 80.43 hours | 95.72 hours  |\n| iSIDG               | 43.80 hours | 67.44 hours | 91.25 hours | 106.51 hours |\n\nThese running times were recorded using BN\\_NS trajectories, chosen for their one-dimensional feature representation. This approach allows us to evaluate both VAE-based methods and other methods under uniform conditions. As indicated in the table, VAE-based methods generally require more time due to the necessity of initial training. In contrast, other methods can directly infer structure without this training phase, making them more efficient in terms of computation time. However, it's important to note that VAE-based methods offer greater versatility, as they are applicable to both multi-dimensional and one-dimensional trajectories. This broader application scope might justify the longer running times for certain use cases.\n\nThis comprehensive evaluation of running times has been included in Appendix D.6 of our revised manuscript.\n\n------\n> **W3.** I  wonder can the authors consider robust testing for this paper?\n\nWe thank you for the insightful suggestion regarding the implementation of robust testing in our research. Recognizing the critical nature of validating our findings across diverse conditions, we have undertaken the following measures:\n\n1. **Testing Under Varied Conditions:** Our synthetic dataset, comprising over 213,000 trajectories and 231 distinct underlying interaction graphs, provides a broad and diverse testing ground. This diversity in data inherently encompasses a range of conditions, thereby addressing robustness through varied input parameters within the scope of our benchmarking study.\n2. **Sensitivity Analysis:** The influence of varying input data on our model's performance is a vital aspect of our research. While a dedicated sensitivity analysis is beneficial, we believe our study partially addresses this through an examination of how different graph properties can impact the effectiveness of structural inference methods. This investigation indirectly contributes to our understanding of model sensitivity to input variations.\n3. **Error and Exception Handling:** We have rigorously evaluated the response of the structural inference methods to varying levels of Gaussian noise. This approach is instrumental in assessing how our methods handle common anomalies and errors in input data, thereby providing insights into their reliability under less-than-ideal conditions.\n4. **Replicability and Generalizability:** To foster a culture of transparency and replicability in our field, we have made available the implementations of the structural inference methods, along with their hyper-parameter configurations and datasets. This initiative is aimed at enabling fellow researchers to replicate our study seamlessly, further reinforcing the robustness and applicability of our findings.\n\nWe are confident that these measures collectively fortify the robustness of our research. They contribute significantly to a comprehensive understanding of the applicability and reliability of our findings in real-world scenarios. Furthermore, we remain open to and welcome any additional suggestions for enhancing the robust testing of our paper. Your guidance in this regard is highly valued and will be considered earnestly in our ongoing and future research endeavors.\n\n------"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700237886033,
                "cdate": 1700237886033,
                "tmdate": 1700238800042,
                "mdate": 1700238800042,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MLIvYXsD7i",
                "forum": "PCXvcULwiI",
                "replyto": "Nzm62nZgCM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A gentle reminder for the closing rebuttal window"
                    },
                    "comment": {
                        "value": "Dear Reviewer fGzL,\n\nWe hope this message finds you well. As the deadline for the author-reviewer discussion phase is approaching, we wanted to respectfully inquire whether our rebuttal to your review of our paper has successfully addressed the concerns you raised.\n\nWe deeply appreciate the insights and feedback you provided, on the Gaussian noise and the running time of the structural inference methods, which have been instrumental in enhancing the quality of our work. In our rebuttal, we endeavored to thoroughly address each of the points you mentioned, and we are keen to know if our responses and the revisions meet your expectations and clarify the aspects you highlighted.\n\nWe understand that you have a busy schedule, and we greatly appreciate any time you can spare to provide us with your feedback on our rebuttal. Your insights are not only important for the review process but also invaluable for our continued learning and development in this area.\n\nThank you once again for your time and expertise. We look forward to your response.\n\nBest regards, Authors"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700570051193,
                "cdate": 1700570051193,
                "tmdate": 1700570051193,
                "mdate": 1700570051193,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7w67NegUMS",
                "forum": "PCXvcULwiI",
                "replyto": "MLIvYXsD7i",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5073/Reviewer_fGzL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5073/Reviewer_fGzL"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response."
                    },
                    "comment": {
                        "value": "Thanks for your responses. The rebuttal has addressed parts of my concerns and I would like to keep my score."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700583804258,
                "cdate": 1700583804258,
                "tmdate": 1700583804258,
                "mdate": 1700583804258,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9qp4RQTK1g",
            "forum": "PCXvcULwiI",
            "replyto": "PCXvcULwiI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5073/Reviewer_HMKQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5073/Reviewer_HMKQ"
            ],
            "content": {
                "summary": {
                    "value": "This paper titled \"Benchmarking Structural Inference Methods for Interacting Dynamical Systems with Synthetic Data\" addresses the need for a unified and objective framework to assess structural inference methods for understanding the topological structure of dynamical systems. The authors conduct a comprehensive benchmarking study, evaluating 12 structural inference methodologies sourced from various disciplines. They use synthetic data that incorporates properties from 11 diverse real-world graph types, ensuring the realism of their evaluations. The paper's contributions include insights into the performance of various structural inference methods in terms of accuracy, scalability, robustness, and sensitivity to graph properties. Notable findings include the efficacy of deep learning techniques for multi-dimensional data and the strength of classical statistics and information-theory-based methods. The paper aims to assist researchers in method selection for specific problem domains and inspire further advancements in the field of structural inference for interacting dynamical systems."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper has several strengths, which are outlined across multiple dimensions:\n\n1. Originality:\n   - The paper contributes to the field of structural inference for dynamical systems by addressing the pressing need for a unified benchmarking framework. This is an original and valuable contribution, as it provides a systematic evaluation of various structural inference methods, which can guide researchers in selecting appropriate techniques for their specific problem domains.\n   - The inclusion of diverse real-world graph types and their properties in the benchmarking process enhances the originality of the study. It brings a more realistic perspective to the evaluation, making it relevant for practical applications.\n\n2. Quality:\n   - The paper maintains high quality in terms of its methodology and experimentation. It employs rigorous benchmarking techniques and synthetic data generation to evaluate the performance of structural inference methods. The paper's thoroughness in presenting the implementation details of these methods adds to its quality.\n   - The acknowledgment of limitations, ethical concerns, and potential misuse of the technology showcases a responsible approach to research, demonstrating the authors' commitment to addressing the broader impact of their work.\n\n3. Clarity:\n   - The paper is well-structured and presents its concepts in a clear and organized manner. It begins with a concise introduction, followed by detailed methods and implementation sections, and ends with a clear acknowledgment of limitations and broader impact.\n   - The paper effectively communicates the assumptions made, the choice of evaluation metrics, and the rationale behind selecting specific structural inference methods. This transparency enhances the clarity of the research.\n\n4. Significance:\n   - The paper's significance lies in its potential to advance the field of structural inference for dynamical systems. By providing a comprehensive benchmarking study, it serves as a valuable resource for researchers seeking to choose the most suitable methods for their work.\n   - The paper's exploration of the significance of structural inference in various domains, such as physics, chemistry, and biology, highlights the wide-ranging applications of these methods, underlining their importance in scientific research.\n\nOverall, the paper's strengths are evident in its originality, quality, clarity, and significance. It offers a valuable benchmarking study that can guide researchers and practitioners in the structural inference field, and its responsible consideration of limitations and ethical concerns further enhances its quality."
                },
                "weaknesses": {
                    "value": "Lack of Real-World Applications: The paper primarily focuses on benchmarking structural inference methods with synthetic data. However, it does not provide concrete examples or case studies demonstrating the practical application of these methods in real-world scenarios. Including real-world use cases and applications would make the paper more relevant to practitioners who are interested in applying these methods in their work.\n\nIncomplete Hyperparameter Exploration: While the paper mentions a hyperparameter search for some methods, it lacks a comprehensive discussion of the specific hyperparameters explored, the range of values considered, and the impact of hyperparameter tuning on the results. Providing more detail on hyperparameter exploration would help researchers understand the sensitivity of the methods to parameter settings.\n\nLimited Discussion of Algorithm Mechanisms: The paper briefly describes the structural inference methods but does not delve deeply into the underlying mechanisms of each method. A more detailed explanation of how each method works, its assumptions, and the computational complexity involved would provide a better understanding of the methods for readers who may be less familiar with the specific techniques.\n\nScope of Comparative Methods: The paper mentions selecting methods based on representativeness, diversity, data constraint, and computational constraint. However, it could benefit from a more thorough exploration of alternative methods from various fields. There may be lesser-known but promising methods that could offer valuable insights into structural inference for dynamical systems.\n\nLimited Discussion of Practical Implications: While the paper acknowledges the potential misuse of structural inference methods for privacy concerns, it could further elaborate on the ethical and societal implications of these technologies. Discussing potential safeguards and ethical guidelines would provide a more comprehensive perspective on the broader impact of the research."
                },
                "questions": {
                    "value": "Here are questions and suggestions for the authors that could help in clarifying certain aspects, addressing limitations, and improving the paper.\n\nReal-World Data Application: It would be valuable to understand if the authors have plans to extend their benchmarking study to real-world datasets in the future. Real-world data can introduce complexities that synthetic data may not fully capture, and such an extension would enhance the applicability of the research findings.\n\nHyperparameter Tuning Details: Could the authors provide more specifics on the hyperparameter tuning process for the structural inference methods? Details on the range of hyperparameters explored, the methodology used for tuning, and their impact on the results would offer insights into the sensitivity of these methods to parameter settings.\n\nComparison with Other Benchmarking Studies: Have the authors considered comparing their benchmarking results with similar studies in the field of structural inference for dynamical systems? This would help contextualize the significance and contribution of their work and provide insights into the relative performance of the methods.\n\nRobustness of Synthetic Data: The paper mentions the use of synthetic data but does not extensively discuss the robustness of the synthetic data generation process. How sensitive are the benchmarking results to variations in the synthetic data generation parameters? Are there considerations for addressing potential biases in the synthetic data?\n\nInterpretability of Method Outcomes: Could the authors elaborate on the interpretability of the outcomes provided by the structural inference methods? How do these outcomes translate into actionable insights for researchers in various domains, and can they be used to make informed decisions in real-world applications?\n\nPrivacy Implications: The paper mentions the potential misuse of structural inference methods for privacy invasion. Could the authors discuss potential safeguards and ethical guidelines that could be applied to mitigate these privacy concerns when implementing such methods?\n\nGeneralizability to Other Domains: The paper highlights the application of structural inference methods to fields like physics, chemistry, and biology. Could the authors provide examples of specific applications or domains within these fields where their benchmarking study can be directly applicable or where the methods might require further adaptation?\n\nFuture Directions: What are the authors' thoughts on future research directions in the field of structural inference for dynamical systems? Are there specific areas or challenges that they believe warrant further exploration or investigation?\n\nComparison with Additional Baselines: Considering the significance of baseline methods, could the authors consider including more diverse and representative baseline methods in their benchmarking study, even if they may require adaptation? This could enhance the comprehensiveness of the evaluation.\n\nImpact of Synthetic Data Discrepancies: Given the mention of potential discrepancies between synthetic data and real-world data, how does the paper account for these discrepancies, and are there considerations for addressing this limitation in future research?\n\nMy questions and suggestions aim to encourage the authors to provide further insights, clarify aspects of the research, and consider potential areas for improvement and future exploration."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5073/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699335891579,
            "cdate": 1699335891579,
            "tmdate": 1699636497963,
            "mdate": 1699636497963,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kBsI7To3pq",
                "forum": "PCXvcULwiI",
                "replyto": "9qp4RQTK1g",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer HMKQ (Part 1)"
                    },
                    "comment": {
                        "value": "We sincerely appreciate the encouraging and constructive feedback from Reviewer HMKQ. It's gratifying to know our paper's strengths in originality, quality, clarity, and significance are recognized. We also value the reviewer\u2019s perception of the potential impact of our work within the research community.\n\nHere are our answers to the concerns raised by the reviewer:\n\n> **W1 & Q7.** Lack of Real-World Applications / Generalizability to Other Domains : The paper primarily focuses on benchmarking structural inference methods with synthetic data. However, it does not provide concrete examples or case studies demonstrating the practical application of these methods in real-world scenarios. Including real-world use cases and applications would make the paper more relevant to practitioners who are interested in applying these methods in their work.\n\nWe are grateful for the reviewer\u2019s insightful comment regarding the emphasis on real-world applications. The primary objective of our study has been to benchmark structural inference methods across various disciplines, aiming to establish a unified, objective, and reproducible standard for evaluating these methods. Utilizing simulation data, which allows controlled properties and complete observations, seemed an ideal approach for developing this initial benchmark in structural inference.\n\nHowever, we acknowledge and concur with the reviewer\u2019s point that discussing real-world applications would substantially increase the paper\u2019s appeal to practitioners. To address this, we have expanded Section 1 in our revised manuscript to include the widespread adoption of structural inference methods across diverse fields. These include, but are not limited to, the inference of gene regulatory networks [1, 2, 3], the deduction of gene co-expression networks [4, 5], chemical reaction network reconstruction [6, 7], road map reconstruction [8, 9, 10], and financial network inference [11, 12]. This addition highlights the broad applicability and relevance of these methods beyond theoretical settings, underscoring their practical utility in various real-world domains.\n\nWe believe that these enhancements in our manuscript will more effectively bridge the gap between theoretical benchmarking and practical application, thereby fulfilling the interests and needs of both researchers and practitioners in the field.\n\n-----\n> **W2 & Q2.** Incomplete Hyperparameter Exploration / Hyperparameter Tuning Details: While the paper mentions a hyperparameter search for some methods, it lacks a comprehensive discussion of the specific hyperparameters explored, the range of values considered, and the impact of hyperparameter tuning on the results. Providing more detail on hyperparameter exploration would help researchers understand the sensitivity of the methods to parameter settings.\n\nWe appreciate your insightful comments regarding our hyperparameter exploration. Detailed information about our tuning process, including the hyperparameter range, is indeed provided in Appendix C of our original submission. We employed a grid search strategy, but due to computational limitations, this tuning was focused on a specific graph type. We recognize that variations in network properties can impact model sensitivity. To prevent misleading generalizations, we reported our findings with a conservative approach. While this strategy offers initial insights, we acknowledge, as you highlighted, the importance of a more comprehensive hyperparameter analysis across varied networks in future studies.\n\n-----\n> **W3.** Limited Discussion of Algorithm Mechanisms: The paper briefly describes the structural inference methods but does not delve deeply into the underlying mechanisms of each method. A more detailed explanation of how each method works, its assumptions, and the computational complexity involved would provide a better understanding of the methods for readers who may be less familiar with the specific techniques.\n\nWe thank you for your feedback on the description of algorithm mechanisms. Our aim was to provide a high-level overview of the methods in Sections 3.1 - 3.5, facilitating a clear understanding of their basic mechanisms. We endeavored to describe these methods succinctly, drawing on our in-depth understanding of their workings and grouping them based on their fundamental mechanisms for ease of reading. However, given the current length of the paper (exceeding 50 pages), a more detailed exposition of all 12 methods would significantly expand the manuscript. To avoid overwhelming readers, we recommend the readers consulting the original papers for in-depth information on these methods.\n\n------"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700237619547,
                "cdate": 1700237619547,
                "tmdate": 1700237619547,
                "mdate": 1700237619547,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mIe5NEejuh",
                "forum": "PCXvcULwiI",
                "replyto": "9qp4RQTK1g",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5073/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A gentle reminder for the closing rebuttal window"
                    },
                    "comment": {
                        "value": "Dear Reviewer HMKQ,\n\nWe hope this message finds you well. As the deadline for the author-reviewer discussion phase is approaching, we wanted to respectfully inquire whether our rebuttal to your review of our paper has successfully addressed the concerns you raised.\n\nWe deeply appreciate the numerous insights and feedback you provided, which have been instrumental in enhancing the quality of our work. In our rebuttal, we endeavored to thoroughly address each of the points you mentioned with several clusters of answers to similar questions, and we are keen to know if our responses and the revisions meet your expectations and clarify the aspects you highlighted.\n\nWe understand that you have a busy schedule, and we greatly appreciate any time you can spare to provide us with your feedback on our rebuttal. Your insights are not only important for the review process but also invaluable for our continued learning and development in this area.\n\nThank you once again for your time and expertise. We look forward to your response.\n\nBest regards, Authors"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700570163177,
                "cdate": 1700570163177,
                "tmdate": 1700570163177,
                "mdate": 1700570163177,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]