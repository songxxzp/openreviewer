[
    {
        "title": "Modeling Complex Mathematical Reasoning via Large Language Model based MathAgent"
    },
    {
        "review": {
            "id": "n1ZzjKvmpS",
            "forum": "Ge7ZqrKG9t",
            "replyto": "Ge7ZqrKG9t",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1727/Reviewer_M3Nq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1727/Reviewer_M3Nq"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on modeling the mathematical reasoning process within LLMs. The authors propose a novel framework named Planner-Reasoner-Executor-Reflector (PRER) and implement two MathAgents within this framework, i.e., MathAgent-M and MathAgent-H, to tackle complicated mathematical problems. The experimental results verify that the two agents significantly improve the reasoning accuracy."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed PRER is a general framework whose idea of decomposing mathematical reasoning process is rational. Besides, the architecture of the paper is clear to read.\n2. This framework can be implemented with different LLMs and in different grains. The motivation of describing LLMs\u2019 and human-like behaviors is reasonable, and the corresponding technique makes sense.\n3. The accuracy improvements on datasets MiniF2F and MATH are significant."
                },
                "weaknesses": {
                    "value": "1. It\u2019s necessary to give an \\emph{overall} introduction of its idea. What I mean is not the description of the workflow of Planner-Reasoner-Executor-Reflector framework. What I am concerned about is the reason of formalizing the actions as \u201cinfer\u201d\u3001\u201ccalculate\u201d and so on (Details could be referred to question 1 below). Besides, this paper presents several modules realized by prompting LLM, without a clear introduction to the internal logic and reasons for model design. \n2. Some details lack enough descriptions or explanations, bringing difficulty in reproducing the proposed framework. Details could be referred to questions 2-4 below.\nPlease see the detailed questions below, which should be answered and addressed."
                },
                "questions": {
                    "value": "1. How do the authors define the actions of different modules? For example, why does the \u201cMathematical\u201d class in MathAgent-H only contain \u201cassociate\u201d and \u201cconstruct\u201d? What is the behind idea of designing them? Are there other actions that should be considered? \n2. According to the paper, the actions of MathAgent-M is a subset of MathAgent-H's. Therefore, what is the necessity of proposing MathAgent-M independently from the perspective of technique? Besides, as described in Table 1, the \"Infer\" action in MathAgent-M has different meaning with the \"infer\" in MathAgent-H. The authors state that the action in MathAgent-H is more aligned with human actions. However, the description of \"infer\" in MathAgent-M, i.e., \"Infer new rationales using deduction methods\" can also be viewed as an action in human cognition.\n3. What is the meaning of m^1_n, m^2_n in Eqs.(2),(3) in section 2.2. They lack descriptions or explanations.\n4. In Eq.(3), why is t_n (i.e., topology of the inference) an output, not an input, and even if t_n is obtained, what is it useful for subsequent reasoning? Because t_n does not appear in Eq.(4) or other equations.\n5. According to Figure 3, \u201cinfer\u201d and \u201ccalculate\u201d occupy the most important part for MathAgent-M and MathAgent-H, respectively. It's a little weird for me due to the following reasons. First, as the authors have stated, MathAgent-H is more aligned with human actions. However, the statistics reveal that the human-like actions (e.g., \"induce\", \"rethink\") take up a very small proportion in MathAgent-H's reasoning process, contradictory with the motivation of designing MathAgent-H. Second, why \"infer\" takes up such a small proportion in MathAgent-H? Intuitively, since the testset are the same, \"infer\" should also be the prominent action in MathAgent-H, since it's more relevant to mathematical reasoning. On the contrary, \"calculate\" in MathAgent-H is indeed a computation action, which intuitively should not have such a high frequency.\n6. There exist some other works that also decompose the mathematical reasoning into several steps (e.g., Tree of Thought [1]) and adopt a generate-then-verify paradigm (e.g., [2,3]). The authors need to give more illustrations of how this work is distinctive, explain the differences with other similar works, and incorporate them in experiments.\n[1] Yao S, Yu D, Zhao J, et al. Tree of thoughts: Deliberate problem solving with large language models[J]. arXiv preprint arXiv:2305.10601, 2023.\n[2] Charlie Chen, Sebastian Borgeaud, Geoffrey Irving, Jean-Baptiste Lespiau, Laurent Sifre, and John Jumper. Accelerating large language model decoding with speculative sampling. arXiv preprint arXiv:2302.01318, 2023.\n[3] Yaniv Leviathan, Matan Kalman, and Yossi Matias. Fast inference from transformers via speculative decoding. In International Conference on Machine Learning, pages 19274\u201319286. PMLR, 2023."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1727/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698692232363,
            "cdate": 1698692232363,
            "tmdate": 1699636101564,
            "mdate": 1699636101564,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZkMOYFdEZG",
                "forum": "Ge7ZqrKG9t",
                "replyto": "n1ZzjKvmpS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1727/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1727/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer M3Nq"
                    },
                    "comment": {
                        "value": "Thanks for your valuable comments and agreement with the concepts. We sincerely apologize for the lack of clarity in our writing. We summarized and replyed the frequent key issues among reviewers in \"For All Reviewers\" (*FAR*). Here are our specific replies:\n\n**C1: How do the authors define the actions of different modules?**  \nR1: We supplemented the relevant theories in *FAR2* to explain how we define the modules and actions, including the introduction of logical reasoning and several empirical considerations.\n\n**C2: What is the necessity of proposing MathAgent-M independently?**  \nR2: We explained the rationales for providing two MAs in *FAR3*, and clarified the motivation and contributions of this paper in *FAR1*. Although MA-H might be better, the comparision of two MAs can yield some interesting conclusions.\n\n**C3: Why the authors state the MA-M is more aligned with LLMs, while the description of \"infer\" in MA can also be viewed as an action in human cognition**  \nR3: We primarily distinguish them by whether the LLM has the freedom to make decisions and self-evolve (see *FAR3*). The actions in MA-H is more specific and we contrain the LLM with program. Meanwhile, the actions in MA-M are more general. These actions like *observe* and *infer* are defined emperically, thus can contain human experiences. After all, language modeling based LLMs natually contains human knowledge. But overall, these actions allow the LLMs to execute freely.\n\n**C4: What is the meaning of $m^1_n$, $m^2_n$ in Eqs.(2),(3) in section 2.2. In Eq.(3), why is $t_n$ an output, not an input? What is it useful for subsequent reasoning?**  \nR4: We re-organized the formulas in *FAR4*. For instance, when the LLM determines to *classify*, the LLM then need to seperate the context into sub-topics, that is $t_n$. This topology plays many roles in subsequent reasoning, as filtering memory to retain context only related to the sub-topic, and tell the LLM the relationships between sub-structures when finish discussion and integrat the memories.\n\n**C5: The *calculate* intuitively should not have such a high frequency.**  \nR5: We elaborated what we observed about the actions in *FAR5*, analyzing why it is reasonable for *calculate* to have a higher proportion. However, we indeed observed some inconsistencies, which might make it abnormal. We provide further discussion in both *FAR5* and *FAR6*, explaining the possible reasons and solutions. It is also worth noting that as the difficulty increases, the proportion of other actions rises.\n\n**C6: There exist some other works that also decompose the mathematical reasoning into several steps.**  \nR6: We provided some comparisons with existing work in *FAR1*, supplemented some unique theoretical foundations in *FAR2*, and analyzed the scalability of PRER in combination with these methods in *FAR6*. We will further improve the writing and supplement the required descriptions and comparisons in future revisions of this paper."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1727/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700029341535,
                "cdate": 1700029341535,
                "tmdate": 1700029341535,
                "mdate": 1700029341535,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UowhYqpEjG",
                "forum": "Ge7ZqrKG9t",
                "replyto": "n1ZzjKvmpS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1727/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1727/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to a discussion before the deadline"
                    },
                    "comment": {
                        "value": "Dear reviewer M3Nq:\n\nThanks very much for your attention and great effort in reviewing our paper. As the deadline is approaching and there are only less than **3 days** for discussion, we would like to have a further discussion with your feedback. We understand you may have a busy schedule, but we believe that we have addressed all your concerns. If you still have further concerns or feel unclear after reading our responses, please kindly let us know and we are willing to make clarification and discussion. If you are satisfied with our responses so far, we sincerely hope you could consider your score. Thanks very much!\n\nBest regards, Authors of #1727"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1727/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700452099572,
                "cdate": 1700452099572,
                "tmdate": 1700452099572,
                "mdate": 1700452099572,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DvV34CA4sl",
                "forum": "Ge7ZqrKG9t",
                "replyto": "UowhYqpEjG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1727/Reviewer_M3Nq"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1727/Reviewer_M3Nq"
                ],
                "content": {
                    "title": {
                        "value": "Reponse to the reviewers' rebuttal"
                    },
                    "comment": {
                        "value": "Dear Authors,\nThank you for your detailed response to my comment. It is acknowledged that your responses have resolved some of my initial queries. I recommend revisiting the aspects as we discuss, ensuring that your work is presented in a manner that facilitates easy comprehension. Please consider incorporating more explicit explanations in the further version.\nBest"
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1727/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700703344220,
                "cdate": 1700703344220,
                "tmdate": 1700703344220,
                "mdate": 1700703344220,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "brNgSdGSxu",
            "forum": "Ge7ZqrKG9t",
            "replyto": "Ge7ZqrKG9t",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1727/Reviewer_CLmw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1727/Reviewer_CLmw"
            ],
            "content": {
                "summary": {
                    "value": "The paper tackles improving the mathematical reasoning capability of LLMs by proposing a set of modular decomposition actions. These actions range from infer, associate, observe, disprove, etc. All the actions are simulated by LLMs with few shot prompts. With the help of these actions, the paper shows a strong performance improvement on MATH and MiniF2F datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper attempts to systematically break down various useful actions in mathematical reasoning. The design is interesting.\n\nThe performance gain from prompting the LLM with proposed actions is quite significant especially on MiniF2F datasets, where it solves 20% IMO problems that are not solved before."
                },
                "weaknesses": {
                    "value": "The paper is not very well-written with many of the equations not explained clearly. The authors should provide more clarifications on these.\n\nThe design of various actions seem heavily engineered and the overall algorithm quite complicated. (See Algorithm 2) I wonder if the authors could break down the effect of various actions and only identify a few that contribute to the performance improvement the most. This is especially important since according to Figure 3, majority of the actions are \"calculate\"."
                },
                "questions": {
                    "value": "1. What does this sentence mean: \"whereas the MATH dataset does not offer final answers for reasoning\"? I am very certain MATH datasets have ground truth reasoning steps and final answers.\n\n2. What actions are truly necessary in improving the reasoning performance of LLM? Can the authors perform more thorough ablation?\n\n3. Given the strong MiniF2F performance with MathAgent-H on IMO problems, can the authors provide a few generated proofs for those problems? Also, I was not able to find the prompts associated with MiniF2F.\n\n4. Figure A1: where is (c)?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1727/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698723576911,
            "cdate": 1698723576911,
            "tmdate": 1699636101458,
            "mdate": 1699636101458,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "S2WITwJPyk",
                "forum": "Ge7ZqrKG9t",
                "replyto": "brNgSdGSxu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1727/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1727/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer CLmw (1/2)"
                    },
                    "comment": {
                        "value": "Thanks for your valuable comments and suggestions about the soundness of this paper. We summarized and replyed the frequent key issues among reviewers in \"For All Reviewers\" (*FAR*). Here are our specific replies:\n\n**C1: More clarifications should be provided.**  \nR1: We apologize for the deficiencies and omissions of writing. We supplemented the theoretical basis of MathAgents (MAs) in *FAR2*, and organized the key formulas of PRER in *FAR4*. We will further improve the writing.\n\n**C2: What actions are truly necessary?**  \nR2: First it should be clarified that the core principle of our designing is the completeness of actions, rather than which one is important on MATH or MiniF2F (see *FAR2*). We provided more details of the action invocation in *FAR4*. For mathematical tasks, it is reasonable that the most important action is *infer/calculate*. Besides, we analyzed why the ratio of *calculate* is so high in *FAR4*, as well as the reasons and possible solutions. It's worth noting that when the difficulty increases, the frequencies of other actions also increase (Fig.3). We conducted the ablation experiments (Table 4). Considering the cost, more combinations of ablation might be hard.\n\n**C3: What does this sentence mean: \"whereas the MATH dataset does not offer final answers for reasoning\"**  \nR3: We apologize for this error. The actual meaning is that when input to LLM, MATH does not provide the final answer, while MiniF2F informs the LLM of what the final goal to be proven is.\n\n**C4: Figure A1: where is (c)?**  \nR4: Sorry for the typo error, the (c) here refers to the bottom \"MathAgent\" in the figure. We will correct the error later.\n\n**C5: Could the authors provide examples on IMO problems and more details of prompts on MiniF2F.**  \nR5: An example is as follow:   \n\"Consider the system of equations \n$$\\\\left\\\\{\\\\begin{aligned}\na_{11}x_1 +a_{12}x_2 +\u00a0a_{13}x_3=0\\\\\\\\\na_{21}x_1 +a_{22}x_2 +\u00a0a_{23}x_3=0\\\\\\\\\na_{31}x_1 +a_{32}x_2 +\u00a0a_{33}x_3=0\n\\\\end{aligned}\\\\right.$$\nwith unknowns $x_1,x_2,x_3$. The coefficients satisfy the conditions: (a) $a_{11},a_{22},a_{33}$ are positive numbers; (b) the remaining coefficients are negative numbers; (c) in each equation, the sum of the coefficients is positive. Prove that the given system has only the solution $x_1=x_2=x_3=0.$\"\n\nOnce encountering such equations, GPT4 immediately started equation transformations. However, this attempt is wrong and useless, only making it more and more complex. GPT4 will get confused by the long memory and start to make symbolic and logical errors. At the end, it might guess the answer, pretend it had successfully prove the problem, or just access the limitation of tokens. \n\nFor instance, the generation of **GPT4** is:   \n\" (GPT4:) We can rewrite the system of equations as $[a_{11}x_1 = -a_{12}x_2 - a_{13}x_3,], ...$  \nThen $[x_1 = \\frac{-a_{12}}{a_{11}} x_2 - \\frac{a_{13}}{a_{11}} x_3,], ...$  \nSquaring each equation, we get...\" (more equation transforms until reaching the token limitation)\n\nRelatively, based on the given actions, MA could standardize the behaviour of LLMs and making it possible to solve such complex problems. This does not mean the mathematical capacity of LLMs gets stronger, but the promtps change the solving direction. \n\nFor instance, the **MA-M** first made associations and then infer correctly as:  \n\"(MA-m-associate:) The Rouch\u00e9\u2013Capelli theorem can be used to prove that a system of linear equations has only the trivial solution. This theorem states that...(detailed explanation).  \n(MA-m-infer:) Since all the coefficients of the system of equations are non-zero, the rank of the coefficient matrix is 3. And since the right-hand side of the equations are all zeros, the rank of the augmented matrix is also 3....  \n(MA-m-conclude:) According to the Rouch\u00e9\u2013Capelli theorem, this implies that the system of equations has a unique solution, which is the trivial solution.\""
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1727/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700029141653,
                "cdate": 1700029141653,
                "tmdate": 1700451166502,
                "mdate": 1700451166502,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1y83ai9WZF",
                "forum": "Ge7ZqrKG9t",
                "replyto": "brNgSdGSxu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1727/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1727/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to your feedback before deadline"
                    },
                    "comment": {
                        "value": "Dear reviewer CLmw:\n\nThanks very much for your dedication in reviewing our paper. Your comments about some unclear details have been taken into account and prompted us to improve them in a revision of manuscript. Since there are only less than **3 days** to the deadline, we would appreciate it if you could check our replies and post further valuable comments about the replies and the presented example. We sincerely hope to continue the discussion with you and address the concerns.\n\nBest regards, Authors of #1727"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1727/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700451504202,
                "cdate": 1700451504202,
                "tmdate": 1700452132821,
                "mdate": 1700452132821,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2yG9pQB9Co",
                "forum": "Ge7ZqrKG9t",
                "replyto": "1y83ai9WZF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1727/Reviewer_CLmw"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1727/Reviewer_CLmw"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "Dear authors,\n\nThank you for the response. I have read the general comments and specific responses. It seems the authors also acknowledge the issues of cost and action importance. For cost, I believe authors could calculate the accuracy with respect of total tokens used and compare the baselines more fairly. For action importance, I appreciate the theoretical design choices authors make but I am also wondering how much performance would decrease if we only use the top-k actions exclusively. This would serve as a better ablation study.\n\nAnother major issue is the MiniF2F evaluation. It seems that authors evaluate their method informally with natural language. This should usually be reasonable if a final answer is not provided and accuracy is calculated by checking if the output answer matches with the ground truth. However, for MiniF2F, the final goal to be proven is provided to the LLM. This makes evaluation not reliable since the model could concoct some invalid justification to prove the final goal. The baselines authors compared for MiniF2F are all formal theorem proving methods that do not suffer from this issue. Therefore, I believe the comparison on MiniF2F is not fair and reliable. Could the authors comment on this issue?\n\nBest regards,\n\nReviewer CLmw"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1727/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700496536692,
                "cdate": 1700496536692,
                "tmdate": 1700496536692,
                "mdate": 1700496536692,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iUc9Sn3kMy",
                "forum": "Ge7ZqrKG9t",
                "replyto": "MXBUE2dpLi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1727/Reviewer_CLmw"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1727/Reviewer_CLmw"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "Dear authors,\n\nThank you for your response. I have a different understanding of MiniF2F and below are my thoughts.\n\n> It is essential to clarify that the original form of the MiniF2F dataset is informal.\n\nIt is correct that the questions from the dataset were drawn from informal math competitions but the dataset itself focuses on formal theorem proving. The formal statements are in 4 different languages. Also, the title of the MiniF2F paper is \"MiniF2F: a cross-system benchmark for formal Olympiad-level mathematics\".\n\n> Therefore, PRER's input is consistent with the original informal format of the MiniF2F dataset, and there is no unfair comparison with the baselines we chose. The opposite truth is that some models perform an additional preprocessing step to convert the informal questions to a formal format, such as FMSCL, which means that PRER faces potential unfairness in the comparison.\n\nIf the authors believe evaluating MiniF2F in the informal format is the right thing to do, can you explain why all baselines in Table 3 except GPT4 (devised by the authors) evaluate their method in the formal format?\n\nI would like to make a note that proving theorems in a formal environment is very challenging. What is typically omitted in the informal reasoning needs to be clearly stated and right premises need to be found to prove individual steps. If the authors truly believe PRER faces unfairness in the comparison, I would be happy to see and encourage authors to also run PRER in the formal format.\n\nBest regards,\n\nReviewer CLmw"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1727/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700510198217,
                "cdate": 1700510198217,
                "tmdate": 1700510198217,
                "mdate": 1700510198217,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "76BmSgDKHz",
                "forum": "Ge7ZqrKG9t",
                "replyto": "QMdHCKkunM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1727/Reviewer_CLmw"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1727/Reviewer_CLmw"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "Dear authors,\n\nThank you for your response. Viewing the eagerness to tackle the addressed issues, I'm very confident that the authors can further polish the work and present an impactful work in their future submission.\n\nBest regards,\n\nReviewer CLmw"
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1727/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700671406238,
                "cdate": 1700671406238,
                "tmdate": 1700671406238,
                "mdate": 1700671406238,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5Ch5FfPOM2",
            "forum": "Ge7ZqrKG9t",
            "replyto": "Ge7ZqrKG9t",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1727/Reviewer_WFXS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1727/Reviewer_WFXS"
            ],
            "content": {
                "summary": {
                    "value": "The paper delves into the challenges LLMs face when solving intricate mathematical problems. To address these challenges, the authors introduce an agent-based zero-shot framework named Planner-Reasoner-Executor-Reflector (PRER) and two MathAgents, MathAgent-M and MathAgent-H. Experiments on miniF2F and MATH datasets show that the proposed approach significantly outperforms GPT-4, especially for level-5 problems of the MATH dataset."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is well written and easy to follow.\n2. The work pushed the state-of-the-art results on two datasets including MATH which seems to be a challenging dataset even for larger language models.\n3. The implementation two MathAgents is innovative and shows promise in addressing the challenges LLMs face in mathematical reasoning."
                },
                "weaknesses": {
                    "value": "1. Although the paper demonstrates advancements over GPT-4, it fails to specify the average model calls needed for each question within the PRER framework. This omission raises concerns about potential high costs. If the cost is, hypothetically, k times, would it still surpass k majority-voting? It would be advantageous to incorporate such an experiment. With succinct prompts, GPT-4 can outperform MathAgent-M on the MATH dataset. For instance, PHP achieves a score of 53.9.\n2. The experiments are centered on particular datasets (miniF2F and MATH), both of which solely encompass abstract mathematical language. The efficacy of the proposed technique on other mathematical problem-solving datasets remains uncertain, especially concerning word problems akin to those in GSM8K. Such word problems can also be complex and may require more domain knowledge.\n3. The paper's proposition of an approach that can \u201csystematically decompose and model the solving process of complex mathematical reasoning\u201d seems unsubstantiated with neither theoretical nor empirical backing. While using prompts to tailor LLM into a specialized expert is a prevalent strategy, the model doesn't acquire any fresh insights. Furthermore, there's an absence of empirical evidence emphasizing the significance or need for Executors."
                },
                "questions": {
                    "value": "The paper introduces a technique to augment LLMs' aptitude in mathematical reasoning through an agent-based framework. Although the findings are encouraging, questions remain about the method's adaptability and the absence of exhaustive comparisons with alternative techniques.\n\n**Correctness:** 3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.\n\n**Technical Novelty And Significance:** 3: The contributions are significant and novel, but there are areas that could be further explored or clarified.\n\n**Empirical Novelty And Significance:** 3: The empirical contributions are significant, but the paper could benefit from a broader range of experiments and comparisons."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1727/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698738190764,
            "cdate": 1698738190764,
            "tmdate": 1699636101372,
            "mdate": 1699636101372,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tDsyevypbJ",
                "forum": "Ge7ZqrKG9t",
                "replyto": "5Ch5FfPOM2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1727/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1727/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer WFXS"
                    },
                    "comment": {
                        "value": "Thanks for your valuable comments and meaningful concerns about the costs, theories and soundness of this work. We summarized and replyed the frequent key issues among reviewers in \"For All Reviewers\" (*FAR*). Here are our specific replies:\n\n**C1: It raises concerns about potential high costs and trade-off.**  \nR1: We explained and discussed the scalability and cost of PRER in *FAR6*, hoping these explanation can alleviate the concerns. Our main focus in this paper is to explore the potential of PRER, as stated in *FAR1*. We acknowledge the limitations and discussed how to reduce the costs as future research.\n\n**C2: Why not evaluating datasets like GSM8k.**  \nR2: The framework we designed contains a variety of mathematical actions. Thus it may be meaningless to evaluate on GSM8k, which primarily requires computational operations, considering the cost. Previous methods have achieved very high acc on GSM8k, thus we chose more challenging datasets like MATH. Besides, MATH includes the topic of \"algebra\", which can reflect the generalizability of proposed MAs.\n\n**C3: It seems unsubstantiated with neither theoretical nor empirical backing. What's the significance or need for Executors.**  \nR3: We apologize for the missing descriptions. We supplemented the theories in *FAR2* to explain how we define the actions and re-organized important formulas of PRER in *FAR4*. These contents will be added to the paper in the next version.\n\n**C4: How about the method's adaptability and comparisons with alternative techniques?**  \nR4: We apologize for any confusion caused by our writing. We explained the scalability of PRER in *FAR6*. Theoretically, most prompting methods can be integrated as a type of agent. They are not alternatives, but rather compatible with PRER."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1727/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700028975876,
                "cdate": 1700028975876,
                "tmdate": 1700028975876,
                "mdate": 1700028975876,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gPNUM5P1FG",
                "forum": "Ge7ZqrKG9t",
                "replyto": "5Ch5FfPOM2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1727/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1727/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to your feedback before the deadline"
                    },
                    "comment": {
                        "value": "Dear reviewer WFXS:\n\nThanks again for your constructive and valuable comments, which have helped us improve the paper considerably. We believe that your concerns have been addressed somewhat satisfactorily. There are only less than **3 days** to the deadline for discussions. Sincerely hope to gain further valuable feedback from you and continue to improve this work. We are also willing to clarify any additional concerns.\n\nBest regards, Authors of #1727"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1727/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700452901505,
                "cdate": 1700452901505,
                "tmdate": 1700452901505,
                "mdate": 1700452901505,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "lZTbTUFxWg",
            "forum": "Ge7ZqrKG9t",
            "replyto": "Ge7ZqrKG9t",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1727/Reviewer_DbPQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1727/Reviewer_DbPQ"
            ],
            "content": {
                "summary": {
                    "value": "In this work the authors develop a general agent-based framework, called Planner-Reasoner-Executor-Reflector (PRER), to model the problem solving process in mathematical reasoning (MR).\nA feature of the proposed framework is that it only relies on LLMs, with no calls to external theorem provers.\nThe proposed approach is evaluated experimentally."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1) The experimental evaluation is rather thorough, the proposed approach is compared with several different frameworks.\n\n2) The related literature is discussed in some detail, but it only mentions briefly related approaches that leverage on theorem-provers. Also, the paper does not discuss why avoiding the use of theorem-provers entirely."
                },
                "weaknesses": {
                    "value": "1) The authors say that \"to the best of our knowledge, systematical decomposition and meticulous\nmodeling of complex mathematical solving process have not been explored.\" However, there are a few pages on decomposition for mathematical reasoning, also cited by the authors themselves. Consider, for instance,\n\n- Xueliang Zhao, Wenda Li, and Lingpeng Kong. Decomposing the enigma: Subgoal-based demonstration learning for formal theorem proving. arXiv preprint arXiv:2305.16366, 2023.\n\n- Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:24824\u201324837, 2022.\n\n- Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. arXiv preprint arXiv:2305.10601, 2023.\n\nand related:\n\n- Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish Sabharwal. Decomposed prompting: A modular approach for solving complex tasks, 2023.\n\n2) Equation 1 is not entirely clear. It seems akin to the notion of deduction in logical systems, but its meaning is not formally specified. E.g., what is the meaning of symbol \"|-\"?\n\n3) The different components of the proposed framework (planner, reasoner, executor, reflector) are presented rather in a hurry, in less than one page, by means of Equations (1) to (5), which are not explained in much detail either, especially as for the role of the different logical functions. Consider: \"Planner\nincludes an addition function, preprocessing, to decompose the original problem into the form of (X, y).\"\nWe don't get any more information about preprocessing in the paper.\n\n4) As the authors themselves discuss limitations in the conclusions, \"the current prompts are manually\ncrafted, heavily reliant on experts.\"\nThis might not be the most promising way forward."
                },
                "questions": {
                    "value": "It is not entirely clear to me why two different agents, MathAgent-M and MathAgent-H, are required. What is the rationale for this choice?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1727/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1727/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1727/Reviewer_DbPQ"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1727/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698753317523,
            "cdate": 1698753317523,
            "tmdate": 1699636101304,
            "mdate": 1699636101304,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "IGn4qcgAWv",
                "forum": "Ge7ZqrKG9t",
                "replyto": "lZTbTUFxWg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1727/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1727/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer DbPQ"
                    },
                    "comment": {
                        "value": "Thanks for your valuable comments and suggestions about the motivation and limitations of the work. We summarized and replyed the frequent key issues among reviewers in \"For All Reviewers\" (*FAR*). Here are our specific replies:\n\n**C1: Why avoiding the use of theorem-provers.**  \nR1: We reasserted our contributions and design principles in *FAR1* and *FAR2*. Despite PRER can be combined with external tools, it is costly to provide additional implementation and the tool is not our contribution. Moreover, directly using theorem provers like lean wastes the textual ability of powerful LLMs. We will re-consider this trade-off in the future.\n\n**C2: There are a few pages on decomposition for mathematical reasoning.**  \nR2: We addressed the comparison with previous works in *FAR1*. In short, we introduced more definitions and designs to tell the model how to decompose, and provided an agents-based framework with other concepts like logical reasoning to model the reason process.\n\n**C3: Equation 1 is not entirely clear. The framework is presented rather in a hurry.**  \nR3: We apologize for the issues in writing. The formulas of the PRER are reorganized in *FAR4*. We will improve our writing and supplement required descriptions in latter paper revisions.\n\n**C4: The current prompts are manually crafted, might not be the most promising way forward.**  \nR4: We acknowledge the limitations. Prompts have many advantages (interpretability, generalization, low cost, etc) and many drawbacks (see *FAR5* and *FAR6*). We plan to explore more methods like SFT in the future. Besides, recent work proposed some methods for automatic generation [1,2] and discrete search [3,4] of prompts, which may alleviate the concerns. Identify the intentions of non-experts to generate prompts is also an interesting direction to consider. The recent released \"agents\" by OpenAI imply the possibility.\n\n**C5: What is the rationale for choosing two MathAgents?**  \nR5: We describe the how we define MAs in *FAR2* and explain why we provided two MAs and what's their diffence in *FAR3*.\n\n[1] Wang, Yizhong et al. \u201cSelf-Instruct: Aligning Language Models with Self-Generated Instructions.\u201d Annual Meeting of the Association for Computational Linguistics (2022).  \n[2] Honovich, Or et al. \u201cInstruction Induction: From Few Examples to Natural Language Task Descriptions.\u201d Annual Meeting of the Association for Computational Linguistics (2022).  \n[3] Zhou, Yongchao et al. \u201cLarge Language Models Are Human-Level Prompt Engineers.\u201d ArXiv abs/2211.01910 (2022): n. pag.  \n[4] Sordoni, Alessandro et al. \u201cDeep Language Networks: Joint Prompt Training of Stacked LLMs using Variational Inference.\u201d ArXiv abs/2306.12509 (2023): n. pag."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1727/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700028893499,
                "cdate": 1700028893499,
                "tmdate": 1700028893499,
                "mdate": 1700028893499,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GjvN96vDyC",
                "forum": "Ge7ZqrKG9t",
                "replyto": "lZTbTUFxWg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1727/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1727/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to a discussion before the deadline"
                    },
                    "comment": {
                        "value": "Dear reviewer DbPQ:\n\nThanks again for your great effort in reviewing our paper! Since there are only less than **3 days** to the deadline for discussions, we are really looking forward to having a discussion with you about all technical details and concerns. We sincerely hope to get your further feedback. Would you mind checking our response and letting us know if you have further questions?\n\nBest regards, Authors of #1727"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1727/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700450950721,
                "cdate": 1700450950721,
                "tmdate": 1700450950721,
                "mdate": 1700450950721,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mf9AjJKngY",
                "forum": "Ge7ZqrKG9t",
                "replyto": "GjvN96vDyC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1727/Reviewer_DbPQ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1727/Reviewer_DbPQ"
                ],
                "content": {
                    "title": {
                        "value": "Follow up"
                    },
                    "comment": {
                        "value": "Thanks to the authors for their comprehensive rebuttal and sorry for low reactivity.\n\nI think we all agree that the paper had serious flaws and it is not clear to me to what extent these flaws have been addressed in the revision.\nI think the paper might benefit from a further round of proofreading. I'd suggest a resubmission to another venue."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1727/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700639336103,
                "cdate": 1700639336103,
                "tmdate": 1700639336103,
                "mdate": 1700639336103,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]