[
    {
        "title": "NetInfoF Framework: Measuring and Exploiting Network Usable Information"
    },
    {
        "review": {
            "id": "YdYTw9FaqZ",
            "forum": "KY8ZNcljVU",
            "replyto": "KY8ZNcljVU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission959/Reviewer_ANgE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission959/Reviewer_ANgE"
            ],
            "content": {
                "summary": {
                    "value": "The paper discusses the NETINFOF framework, which focuses on measuring and utilizing the usable information in node-attributed graphs for graph tasks such as link prediction and node classification. The authors propose two components of the framework: NETINFOF PROBE, which measures the amount of information present in the graph structure and node features without any model training, and NETINFOF ACT, which uses the measured usable information to solve the graph tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Lots of experiments"
                },
                "weaknesses": {
                    "value": "See below"
                },
                "questions": {
                    "value": "1. \"How to connect the graph information with the performance metric on the task?\" Here are some missed related works [1,2,3,4,5].\n\n2. What is $f$ in C4? I suggest not using $f$, because you already use it as the number of features.\n\n3. In theorem 1, \"Given a discrete random variable Y , we have...\" What is \"accuracy(Y)\"? Accuracy of a a discrete random variable? This looks weird and I suggest giving a more strict and accurate statement. What is $p_y$?\n\n4. \"Predicting links by GNNs relies on measuring node similarity, which is incorrect if the neighbors have heterophily embeddings.\" The embedding will be similar even with heterophily connections if the nodes share similar neighborhood patterns [6].\n\n5. \"the node embeddings of linear GNNs require no model training\u201c I don't understand this. Why linear GNNs don't require training? Do you mean SGC [7] don't require training?\n\n6. \"It results in low value when node i and node j have heterophily embeddings, even if they are connected by an edge.\" This is not correct, see [2,3,6].\n\n\n\n[1] Characterizing graph datasets for node classification: Beyond homophily-heterophily dichotomy. arXiv preprint arXiv:2209.06177.\n\n[2] Revisiting heterophily for graph neural networks. Advances in neural information processing systems, 35, 1362-1375.\n\n[3] When do graph neural networks help with node classification: Investigating the homophily principle on node distinguishability. arXiv preprint arXiv:2304.14274.\n\n[4] Demystifying Structural Disparity in Graph Neural Networks: Can One Size Fit All?. arXiv preprint arXiv:2306.01323.\n\n[5] Exploiting Neighbor Effect: Conv-Agnostic GNN Framework for Graphs With Heterophily. IEEE Transactions on Neural Networks and Learning Systems.\n\n[6] Is Homophily a Necessity for Graph Neural Networks?. In International Conference on Learning Representations 2022.\n\n[7] Simplifying graph convolutional networks. In International conference on machine learning, pp. 6861\u20136871. PMLR, 2019."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission959/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission959/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission959/Reviewer_ANgE"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission959/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698307905440,
            "cdate": 1698307905440,
            "tmdate": 1700691566534,
            "mdate": 1700691566534,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jphnkAhUek",
                "forum": "KY8ZNcljVU",
                "replyto": "YdYTw9FaqZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission959/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission959/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ANgE"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the comments, and apologize for a few unclear writings that make the reviewer misunderstand the idea that we tried to express. \nWe sincerely hope that the reviewer can re-evaluate our paper and raise the rating after reviewing our answers and revised paper. \nWe address the questions one by one.\n\n> W1. \"How to connect the graph information with the performance metric on the task?\" Here are some missed related works [1,2,3,4,5].\n\nThank you for your supplement on related works. \nWe have added them to Section 2 (Page 2) in our revised paper.\nNoting that our focus has two major differences from [1, 2, 3, 4, 5]:\n1. These works focus on node classification, while our work majorly focuses on **link prediction**.\n2. These works focus on graphs that are heterophily defined by the node labels, while our work focuses on cases such as heterophily w.r.t. node features (\"talkative people have silent friends\"), as well as heterophily w.r.t. graph structure (forming bipartite cores). We did not consider node labels in link prediction.\n\n> W2. What is $f$ in C4?\n\nAs mentioned in the last sentence in C4 (Section 3.2, Page 3), $f$ is the column-wise L2 normalization. \nWe replace it with $l$ in our revised paper for increased clarity.\n\n> W3. In theorem 1, \"Given a discrete random variable Y , we have...\" What is \"accuracy(Y)\"?\n\nAs shown in Equation 1 (Page 4), given a discrete random variable, its accuracy is the probability of its most probable outcome. \nThis is achieved by majority voting, which is the best we can do without any other information.\nIt is also described in Appendix A.1 (Page 13).\n\n> W4. \"Predicting links by GNNs relies on measuring node similarity, which is incorrect if the neighbors have heterophily embeddings.\" The embedding will be similar even with heterophily connections if the nodes share similar neighborhood patterns.\n\nThe main point is that we use **structure** embeddings (C1, Section 3.2, Page 3).\n\nWe have clarified our wording as follows (Page 5, 4 lines from the top):\n*\u201cPredicting links by GNNs relies on measuring node similarity, which is incorrect if the neighbors are expected to have dissimilar embeddings; for example, in a bipartite graph, \u2026\u201d* in our revised paper.\n\nWe agree with the reviewer that in the (label-)heterophily graphs, the **propagated** embeddings (C4 and C5) of connected nodes will be proximity embeddings, and are very likely to be similar.\nHowever, for a (structure-)heterophily graph (e.g., consisting of bipartite cores), our proposed **structure** embeddings (C1), will not be similar even if they share similar neighborhood patterns.\n\n> W5. \"the node embeddings of linear GNNs require no model training\u201c. Do you mean SGC [7] don't require training?\n\nThe node embeddings of linear GNNs in Equations 6 and 8 (Page 6 and 7, respectively) require no training, as they do not have any learnable parameters and can be computed with the closed-form formula.\nBy \u201clinear GNNs\u201d, we mean GNNs that have linear transfer functions (instead of non-linear ones, e.g. ReLU) and do not have learnable weight matrices during message-passing.\n\nIn our revised paper, we clarified it with the sentence  (Page 5, 2 lines from the top): *\u201cCompared to general GNNs, the node embeddings of linear GNNs are given by closed-form formula.\u201d*\n\n> W6. \"It results in low value when node i and node j have heterophily embeddings, even if they are connected by an edge.\" This is not correct, see [2,3,6].\n\nThe statement in the paper is correct, when we use **structure** embeddings (C1, Section 3.2, Page 3) in a (structure-)heterophily graph.\n\nIn our revised paper, we clarified it with the sentence (Page 5, Section 4.1): *\u201cHowever, even if node $i$ and node $j$ are connected by an edge, it may result in low value if they are expected to have dissimilar embeddings (e.g. structure embeddings in a bipartite graph).\u201d*\n\nIn more detail, in the cited papers [2, 3, 6], these are node features propagated through graph structure, which are similar to our derived **propagated** embeddings (C4 and C5).\nAs discussed in W4, the **propagated** embeddings of connected nodes can be similar in a (label-)heterophily graph, while the **structure** embeddings will not be similar in a (structure-)heterophily graph."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission959/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700097181070,
                "cdate": 1700097181070,
                "tmdate": 1700097633355,
                "mdate": 1700097633355,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7rexeWQm46",
                "forum": "KY8ZNcljVU",
                "replyto": "YdYTw9FaqZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission959/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission959/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to your response!"
                    },
                    "comment": {
                        "value": "Dear Reviewer ANgE,\n\nThank you again for your thoughtful review. \nBased on your suggestions, we added the citations into the related works and clarified our wording.\nPlease let us know your thoughts or if there is anything else we can do to address your comments.\n\nBest, \n\nAuthors"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission959/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700522816999,
                "cdate": 1700522816999,
                "tmdate": 1700522816999,
                "mdate": 1700522816999,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IlqwjaPyyo",
                "forum": "KY8ZNcljVU",
                "replyto": "7rexeWQm46",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission959/Reviewer_ANgE"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission959/Reviewer_ANgE"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the response. The authors have addressed most of my concerns and I will raise my rating to 6. Remember to elaborate the statement and the proof of your theorem. Good luck."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission959/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700691675974,
                "cdate": 1700691675974,
                "tmdate": 1700691675974,
                "mdate": 1700691675974,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "0lNMc1z86T",
            "forum": "KY8ZNcljVU",
            "replyto": "KY8ZNcljVU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission959/Reviewer_WXaL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission959/Reviewer_WXaL"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a framework called NETINFOF for measuring and exploiting network usable information (NUI) in node-attributed graphs. The authors aim to determine if a graph neural network (GNN) will perform well on a given task by assessing the information present in the graph structure and node features. NETINFOF consists of two components: NETINFOF PROBE, which measures NUI without model training, and NETINFOF ACT, which solves link prediction and node classification tasks. The framework offers several advantages, including generality, principled approach, effectiveness, and scalability. The authors demonstrate the superiority of NETINFOF in identifying NUI and its performance in real-world datasets compared to general GNN baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper introduces the novel NETINFOF framework, which addresses the problem of measuring and exploiting network usable information in graph for GNNs. \n2. The paper demonstrates sound technical claims, supported by theoretical guarantees and empirical evaluations on synthetic and real-world datasets.\n3. The writing style is clear, and the paper is well-organized, making it easy to understand the proposed framework and its contributions.\n4. The paper's contributions are promising as they provide a practical tool (NETINFOF) for assessing the usefulness of graph structure and node features in GNN tasks. The framework shows promising results and outperforms existing baselines in link prediction."
                },
                "weaknesses": {
                    "value": "1. How does the NETINFOF framework handle noisy or incomplete graph data? Can it effectively measure and exploit network usable information in such scenarios?\n\n2. Are there specific types of graph structures or node features for which NETINFOF may not perform well? How robust is the framework in diverse graph settings?\n\n3. I have concerns regarding the sensitivity of NETINFOF to the estimated compatibility matrix (H) used in the framework. It would be beneficial if the authors could provide additional empirical results that examine the performance of NETINFOF under different label rates, as label rates can significantly impact the correctness of H."
                },
                "questions": {
                    "value": "see weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission959/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission959/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission959/Reviewer_WXaL"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission959/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698803631917,
            "cdate": 1698803631917,
            "tmdate": 1699636021791,
            "mdate": 1699636021791,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xe5oxATVlV",
                "forum": "KY8ZNcljVU",
                "replyto": "0lNMc1z86T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission959/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission959/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer WXaL"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the positive and detailed comments, and give us valuable suggestions. \nWe address the questions one by one.\n\n> W1. How does the NETINFOF framework handle noisy or incomplete graph data? Can it effectively measure and exploit network usable information in such scenarios?\n\nYes, in such cases, NetInfoF will give low NetInfoF_Score to the corresponding noisy components in Section 3.2 (Page 3), and down-weigh them for the upcoming predictions.\n\nDifferent graph scenarios are studied in Table 6 in Appendix C.1 (Page 16): \nFor example, if the given graph has useful structure but very noisy features, NetInfoF gives high scores to the structural embeddings (C1 and C2), and a low score to the feature embedding (C3).\n\n> W2. Are there specific types of graph structures or node features for which NETINFOF may not perform well? How robust is the framework in diverse graph settings?\n\nNetInfoF makes no assumption for either the graph structure or the node feature. \nIn fact, as shown in Table 2 (Page 8) and Table 9 (Page 17), NetInfoF successfully tackles multiple graph scenarios on link prediction and node classification, respectively.\n\n> W3. I have concerns regarding the sensitivity of NETINFOF to the estimated compatibility matrix (H) used in the framework. It would be beneficial if the authors could provide additional empirical results that examine the performance of NETINFOF under different label rates.\n\nThank you for your valuable suggestion. \nFor link prediction, even a small fraction of existing links (=\u201dlabels\u201d) is enough for estimating the compatibility matrix, as we show in the following table.\nThe table shows two medium size datasets \u201cComputers\u201d and \u201cActor\u201d, where we vary the ratio of positive edges used for estimating the compatibility matrix.\nNetInfoF still works well even with 10% of the edges for the compatibility matrix estimation, and it also performs better than without using the compatibility matrix.\n\nFor large graphs, we do not expect NetInfoF to be sensitive to the ratio of edge labels, since it requires only a few edge labels to well estimate the compatibility matrix. For example, in \u201cogbn-Products\u201d, there are 43M (= 62M * 70%) edges in the training set; as we mentioned in T3 in Section 4.1, we sample only 200K for estimating the compatibility matrix, which is 0.5% (= 200K / 43M) edges in the training set.\n\n| Edge Label Ratio | w/o CM | 10% | 30% | 50% | 70% |\n| -------- | -------- | -------- | -------- | -------- | -------- |\n| Comp.    | $27.9\\pm0.2$ | $29.4\\pm2.7$ | $33.0\\pm1.8$ | $31.7\\pm3.4$ | $31.1\\pm1.9$ |\n| Actor    | $29.5\\pm1.8$ | $33.3\\pm1.1$ | $33.9\\pm1.1$ | $34.3\\pm0.6$ | $36.2\\pm1.2$ |"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission959/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700096458212,
                "cdate": 1700096458212,
                "tmdate": 1700097801477,
                "mdate": 1700097801477,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fyjocUuztS",
                "forum": "KY8ZNcljVU",
                "replyto": "0lNMc1z86T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission959/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission959/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to your response!"
                    },
                    "comment": {
                        "value": "Dear Reviewer WXaL,\n\nThank you again for your thoughtful review. \nBased on your suggestions, we conduct an additional experiment on the sensitivity of NetInfoF on the edge label ratio.\nPlease let us know your thoughts or if there is anything else we can do to address your comments.\n\nBest, \n\nAuthors"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission959/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700522730973,
                "cdate": 1700522730973,
                "tmdate": 1700522730973,
                "mdate": 1700522730973,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "GtLnkH1PYa",
            "forum": "KY8ZNcljVU",
            "replyto": "KY8ZNcljVU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission959/Reviewer_96be"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission959/Reviewer_96be"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a novel framework, NETINFOF, designed to quantify and leverage Network Usable Information (NUI) for graph tasks like link prediction and node classification. The approach tackles the need for extensive model training by using NETINFOF_PROBE to measure NUI directly from graph data, which is a significant improvement  from traditional GNNs that rely on trained low-dimensional representations. The NETINFOF_ACT component then uses this measured information to enhance the performance of graph tasks. The framework's robustness is tested on synthetic datasets designed to include various graph scenarios and validated on real-world datasets, showing superior results in link prediction tasks over standard GNN models. This paper's primary contribution is a method that can quickly assess a graph's usefulness for a task, offering a theoretical lower bound for accuracy without the computational overhead of model training\u200b. The empirical study of this paper is very strong, surpassing most GNN methods both in accuracy and scalability."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- **Methodological Innovation**: NetInfoF introduces a novel approach to measure NUI directly from the graph structure and node features, which is a different from traditional methods that rely heavily on model training. This innovation could have a broad impact, particularly in scenarios where computational efficiency is paramount\u200b. Also, the adjustments of node similarity using compatibility matrix w/ negative edges is very interesting.\n- **Teoretical Foundation and Empirical Validation**: The paper provides a theoretical analysis for the NetInfoF_Score, presenting it as a lower bound for the accuracy of a GNN on a given task. This theoretical contribution is well-supported by empirical evidence on both synthetic datasets and real-life datasets.\n- **Scalability**: The demonstrated scalability of NetInfoF, especially its linear scaling with input size (Fig. 6), and the use of significantly fewer parameters compared to GAE methods (1280 vs 279k) demonstrates its potential for application in large-scale graph tasks, presenting a substantial advancement in the practical deployment of GNNs\u200b. Though NetInfoF is slower than SlimG [1], NetInfoF has better accuracy. \n\nCombining 2nd and 3rd points, NetInfoF is better than GAE methods both in accuracy and scalability empirically, which is a significant contribution in link prediction tasks.\n\n\n\n\n\n\n[1] Yoo, Jaemin, Meng-Chieh Lee, Shubhranshu Shekhar, and Christos Faloutsos. \"Slendergnn: Accurate, robust, and interpretable gnn, and the reasons for its success.\" arXiv preprint arXiv:2210.04081 (2022)."
                },
                "weaknesses": {
                    "value": "1. The proof of Theorem 2 is problematic due to the incorrect use of conditional entropy. The proof incorrectly states the conditional entropy in Appendix A.2 as:\n$$\nH(Y|X) = \\sum_{i=1}^{m} p_i \\left(-\\sum_{j=1}^{n} p_{ij} \\log_2 p_{ij}\\right),\n$$\nwhich is incorrect because it uses the joint probabilities $p_{ij}$ instead of the conditional probabilities. The correct expression for conditional entropy, which is based on the conditional probabilities, is:\n$$\nH(Y|X) = -\\sum_{i=1}^{m} \\sum_{j=1}^{n} p_{ij} \\log_2 P(Y=y_j|X=x_i),\n$$\nwhere $P(Y=y_j|X=x_i) = \\frac{p_{ij}}{p_i}$ is the conditional probability of $Y$ given $X=x_i$. And $p_i = \\sum_{j=1}^{n} p_{ij}$ represents the marginal probability of $X$ taking the value $x_i$. This definition adheres to the fundamental property that the conditional probabilities for a given $x_i$ should sum to 1, i.e., $\\sum_{j=1}^{n} P(Y=y_j|X=x_i) = 1$.\n\nThe misuse of conditional entropy in the proof leads to an erroneous application of Jensen's Inequality and subsequently invalidates the derived bound on the NetInfoF score.\n\n2. (Minor) Given the paper is mostly dealing with link prediction tasks. It will be beneficial to include some subgraph-based methods as baselines, such as SEAL [1]. I understand that NetInfoF is intended as an advancement beyond traditional GNN approaches, but including subgraph-based methods will give the community a more comprehensive evaluation of NetInfoF's capabilities. It's evident NetInfoF is way more scalable than subgraph-based methods, but subgraph-based methods are still SOTA on some datasets, e.g. Ogbl-collab.\n\n\n\n\n\n\n\n[1] Zhang, Muhan, and Yixin Chen. \"Link prediction based on graph neural networks.\" Advances in neural information processing systems 31 (2018)."
                },
                "questions": {
                    "value": "1. Can the authors provide a more detailed justification for Theorem 2, particularly in light of the concerns highlighted in the first weakness?  I will raise my score if the authors can give a reasonable update. \n2. How are the \"Our bound\" lines in Figures 3 and 4 derived? Additional details on this calculation would aid in understanding these figures.\n3. How NetInfoF_Probe estimates and calculates the discretizer in section 4.2? Maybe some examples or explanations will help reader understand this.\n4. An ablation study detailing the individual contributions of the five different node embedding components mentioned in Section 3.2 would be beneficial. Are these components equally influential in terms of accuracy, or do some weigh more significantly than others?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission959/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission959/Reviewer_96be",
                        "ICLR.cc/2024/Conference/Submission959/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission959/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699593563893,
            "cdate": 1699593563893,
            "tmdate": 1700550795402,
            "mdate": 1700550795402,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "k9iSrW5jOy",
                "forum": "KY8ZNcljVU",
                "replyto": "GtLnkH1PYa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission959/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission959/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 96be (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the positive and detailed comments, and truly appreciate that you even check the proof carefully. \nWe address the questions one by one.\n\n> W1 & Q1. Can the authors provide a more detailed justification for Theorem 2, particularly in light of the concerns highlighted in the first weakness?\n\nThank you for pointing out the problem, which is caused by the mistyping of the notations.\nWe update the proof of Theorem 2 in Appendix A.2 (Page 13), where our conclusion remains the same.\n\n> Q2. How are the \"Our bound\" lines in Figures 3 and 4 derived?\n\nWe update the annotations in Figure 3 (Page 4) to make it more clear.\nIn more detail, according to Theorem 2, the training accuracy can not be lower than NetInfoF_Score, and thus our bound is the dash $x=y$ line in Figure 3. \nWe show that even for validation accuracy, the results still obey Theorem 2.\nIn Figure 4, the fitting lines have high $R^2$ values, indicating that NetInfoF_Score is highly correlated with the test performance. \nSince it is difficult to connect a metric to the test performance, the ideal metric is expected to be highly correlated with the test performance.\n\n> Q3. How NetInfoF_Probe estimates and calculates the discretizer in section 4.2?\n\nIn Section 4.2, for link prediction, we did the quantile bucketization with $k=8$ bins on the adjusted node similarity.\nDue to space limitation, the detailed algorithm was provided in Algorithm 2 in the appendix (Page 15). \n\nMoreover, we conduct a sensitivity analysis on a medium size dataset \u201cComputers\" (see table below) and show that the result is insensitive to the exact value of $k$, forming a plateau when $k$ increases.\nWe put these results in the appendix (Table 8 and Figure 7, Page 16) in our revised paper. \n\n| Number of Bins | k=4 | k=8 | k=16 | k=32 | k=64 |\n| -------- | -------- | -------- | -------- | -------- | -------- |\n| C1: U    | $74.2\\pm0.3$ | $79.7\\pm0.2$ | $80.4\\pm0.3$ | $80.8\\pm0.3$ | $81.0\\pm0.3$ |\n| C2: R    | $76.5\\pm0.2$ | $80.4\\pm0.0$ | $81.2\\pm0.3$ | $81.4\\pm0.3$ | $81.5\\pm0.3$ |\n| C3: F    | $63.8\\pm0.1$ | $64.9\\pm0.2$ | $65.0\\pm0.1$ | $65.0\\pm0.1$ | $65.1\\pm0.1$ |\n| C4: P    | $77.3\\pm0.2$ | $82.1\\pm0.1$ | $83.0\\pm0.3$ | $83.3\\pm0.3$ | $83.4\\pm0.3$ |\n| C5: S    | $77.3\\pm0.1$ | $82.5\\pm0.1$ | $83.3\\pm0.1$ | $83.6\\pm0.2$ | $83.7\\pm0.2$ |\n\n> Q4. An ablation study detailing the individual contributions of the five different node embedding components mentioned in Section 3.2 would be beneficial. Are these components equally influential in terms of accuracy, or do some weigh more significantly than others?\n\nIn short, different components have variable impact depending on the input graph. \nIt is an advantage of NetInfoF that it can pinpoint which component is useful.\n\nIn more detail, we studied the information of individual components in Appendix C.1 (Page 16) on the synthetic datasets.\nIn addition, we further conduct this experiment on real-world datasets, please find additional results in the following table (major component: in bold). \n\nThis conclusion is similar to the one we have in Appendix C.1 (Page 16), where different input graphs may have different preferences on the components depending on the underlying scenarios.\nTherefore, by combining all five components of node embeddings, NetInfoF is effective as well as robust.\nWe put this table in the appendix (Table 7, Page 16) in our revised paper.\n\n| Dataset | Cora | CiteSeer | PubMed | Comp. | Photo | ArXiv | Products | Cham. | Squirrel | Actor | Twitch | Pokec |\n| -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- |\n| C1: U    | $48.3\\pm0.8$ | $36.9\\pm2.5$ | $43.7\\pm1.8$ | $24.0\\pm1.8$ | $38.5\\pm2.6$ | $18.1\\pm0.6$ | $13.2\\pm0.3$ | $75.0\\pm5.2$ | $12.3\\pm1.8$ | $23.2\\pm2.2$ | $\\mathbf{15.8\\pm0.2}$ | $\\mathbf{16.2\\pm0.6}$ |\n| C2: R    | $61.5\\pm1.2$ | $50.0\\pm1.9$ | $47.9\\pm0.8$ | $19.4\\pm0.8$ | $36.8\\pm3.3$ | $12.3\\pm1.0$ | $09.4\\pm0.7$ | $64.6\\pm3.2$ | $08.2\\pm1.4$ | $\\mathbf{34.2\\pm2.3}$ | $01.5\\pm0.2$ | $05.2\\pm0.2$ |\n| C3: F    | $58.3\\pm3.2$ | $71.5\\pm2.4$ | $41.6\\pm0.4$ | $07.1\\pm0.4$ | $15.6\\pm1.2$ | $04.9\\pm0.2$ | $00.4\\pm0.1$ | $10.7\\pm1.0$ | $00.6\\pm0.1$ | $02.6\\pm0.5$ | $01.7\\pm0.6$ | $00.5\\pm0.2$ |\n| C4: P    | $67.3\\pm1.8$ | $60.9\\pm2.5$ | $48.1\\pm1.8$ | $\\mathbf{28.6\\pm2.4}$ | $\\mathbf{42.4\\pm1.4}$ | $\\mathbf{34.2\\pm1.0}$ | $27.6\\pm0.5$ | $\\mathbf{84.3\\pm1.8}$ | $\\mathbf{20.9\\pm2.3}$ | $13.1\\pm1.1$ | $07.3\\pm1.0$ | $12.4\\pm0.8$ |\n| C5: S    | $\\mathbf{82.4\\pm1.0}$ | $\\mathbf{88.7\\pm1.5}$ | $\\mathbf{63.3\\pm1.1}$ | $29.0\\pm2.3$ | $40.3\\pm1.1$ | $33.6\\pm1.1$ | $\\mathbf{28.1\\pm0.7}$ | $80.5\\pm2.7$ | $19.2\\pm1.2$ | $22.3\\pm0.9$ | $02.7\\pm1.8$ | $\\mathbf{16.2\\pm0.6}$ |"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission959/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700095490648,
                "cdate": 1700095490648,
                "tmdate": 1700096063785,
                "mdate": 1700096063785,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Hu4SSEptKw",
                "forum": "KY8ZNcljVU",
                "replyto": "GtLnkH1PYa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission959/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission959/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 96be (2/2)"
                    },
                    "comment": {
                        "value": "> W2. It will be beneficial to include some subgraph-based methods as baselines, such as SEAL.\n\nWe add the citations in Section 2 and run the experiments of SEAL with the default settings provided by OGB and set the hidden size to 128 as the same as other baselines, please find additional results in the following table.\n\nThe experiments are run by an AWS EC2 g4dn.metal instance, with 384GB RAM and Tesla T4 GPUs.\nNoting that SEAL runs out of memory (O.O.M.) in the preprocessing step for several graphs, and exceeds time limit (T.L.E.) on \u201cPhoto\u201d, taking more than 11 hours to run one (out of five) split.\nFurthermore, as shown by Table 1 (Page 2), subgraph GNNs miss several desired properties focused by this study, i.e., SEAL is not scalable and can not be used on node classification, and NetInfoF is the only one that matches all properties.\nDue to the time constraints, we are not able to conduct hyperparameter search and will conduct a more rigorous experiment in the next version. \n\n| Dataset | Cora | CiteSeer | PubMed | Comp. | Photo | ArXiv | Products | Cham. | Squirrel | Actor | Twitch | Pokec |\n| -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- |\n| SEAL     | $65.2\\pm0.5$ | $60.0\\pm1.1$ | $\\mathbf{60.9\\pm2.1}$ | $\\color{red}{O.O.M.}$ | $\\color{red}{T.L.E.}$ | $\\color{red}{O.O.M.}$ | $\\color{red}{O.O.M.}$ | $\\mathbf{87.6\\pm0.9}$ | $\\color{red}{O.O.M.}$ | $\\mathbf{43.8\\pm0.8}$ | $\\color{red}{O.O.M.}$ | $\\color{red}{O.O.M.}$ |\n| NetInfoF | $\\mathbf{81.3\\pm0.6}$ | $\\mathbf{87.3\\pm1.3}$ | $59.7\\pm1.1$ | $\\mathbf{31.1\\pm1.9}$ | $\\mathbf{46.8\\pm2.2}$ | $\\mathbf{39.2\\pm1.8}$ | $\\mathbf{35.2\\pm1.1}$ | $86.9\\pm2.3$ | $\\mathbf{24.2\\pm2.0}$ | $36.2\\pm1.2$ | $\\mathbf{19.6\\pm0.7}$ | $\\mathbf{31.3\\pm0.5}$ |"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission959/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700096042735,
                "cdate": 1700096042735,
                "tmdate": 1700097549219,
                "mdate": 1700097549219,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yThe5xKZGk",
                "forum": "KY8ZNcljVU",
                "replyto": "GtLnkH1PYa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission959/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission959/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to your response!"
                    },
                    "comment": {
                        "value": "Dear Reviewer 96be,\n\nThank you again for your thoughtful review. \nBased on your suggestions, we corrected the proof of Theorem 2 and conducted an additional experiment on SEAL.\nPlease let us know your thoughts or if there is anything else we can do to address your comments.\n\nBest, \n\nAuthors"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission959/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700522679307,
                "cdate": 1700522679307,
                "tmdate": 1700522679307,
                "mdate": 1700522679307,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JiRBdyLcsu",
                "forum": "KY8ZNcljVU",
                "replyto": "yThe5xKZGk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission959/Reviewer_96be"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission959/Reviewer_96be"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "Thank the authors for their detailed reply and experiments and sorry for my late reply. In general, I think the authors deal with my concern effectively. I have raised my score to 8 for now. And I am looking forward to discussing with other reviewers about the paper to see if I have missed any points.\n\nW1 & Q1: Proof of theorem looks good to me now.\n\nQ2: Thanks for the clarification.\n\nQ3: It is interesting to see that NetInfoF_Probe is insensitive to $k$. \n\nQ4: The ablation study is great and reveals interesting patterns. Can the authors provide some insight about why certain components perform better on homophily/heterophily datasets?\n\nW2: It\u2019s great to see NetInfoF outperform SEAL on certain datasets and also turns out to be scalable on large datasets. It\u2019s a great supplement to this work.\n\nIn general, I am satisfied with the current paper. And it seems that the authors have made significant efforts on responding to reviewers\u2019 feedback."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission959/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700550840997,
                "cdate": 1700550840997,
                "tmdate": 1700550840997,
                "mdate": 1700550840997,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]