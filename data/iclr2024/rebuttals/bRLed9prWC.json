[
    {
        "title": "Future Language Modeling from Temporal Document History"
    },
    {
        "review": {
            "id": "4ulqHTN5pb",
            "forum": "bRLed9prWC",
            "replyto": "bRLed9prWC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4231/Reviewer_QRZD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4231/Reviewer_QRZD"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies and introduces the task of future language modeling. This practically involves generation of text that would be written at a future time, which is not present in the pre-training of the langauge model used. This is possible through extrapolating usage from historical time intervals.\n\nThe paper introduces three methods that enhance the regular transformer-based architecture. These rely on LSTMs to model the historical frequency and predict its change with time.\n\nA new data set and evaluation setup is proposed, where the task is to predict future abstracts from the ACL conference. Results show the proposed methods improve over all baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "To the best of my knowledge, the application and task are novel and interesting to study.\n\nThree architectures are introduced, each building on each other. The effects of each component are studied and give us a sense of what is working and what is needed to improve performance."
                },
                "weaknesses": {
                    "value": "More motivation and applications for this task could be provided or speculated.\n\nThe paper uses GPT-2 as the base model for all experiments. It would be better for testing robustness to potentially include a few more base models, perhaps with larger sizes or an encoder-decoder architecture for diversity.\n\nAdditional experiments and evaluation on downstream tasks can be performed using conditional generation or prompting on existing data sets with temporal dimensions e.g. the temporal NER data set (Rijhwani & Preotiuc-Pietro, ACL 2019; Luu et al NAACL 2022) or generating hashtags in future tweets using just the tweet text (similar to Preotiuc-Pietro & Cohn, EMNLP 2013). These would avoid the issues associated with evaluating generations.\n\nAnother interesting experiment to conduct would be to study prediction more into the future and quantify the expected degradation as the time window increases."
                },
                "questions": {
                    "value": "Please expand on what stopword list was used, as that plays an important role in content perplexity and meteor scores."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4231/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4231/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4231/Reviewer_QRZD"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4231/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698990201585,
            "cdate": 1698990201585,
            "tmdate": 1699636390272,
            "mdate": 1699636390272,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "d6n9w5Kcix",
                "forum": "bRLed9prWC",
                "replyto": "4ulqHTN5pb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4231/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4231/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the detailed review and comments"
                    },
                    "comment": {
                        "value": "Thank you for the detailed review and comments. \n\nMost of your mentioned weaknesses are what we\u2018d like to continue to do for future work. \n\nAnswer for Questions:\n\nSince most of the stopwords lists available online are not intended for our research purposes, the stopwords are manually curated by the following process: 1. use the data in the paper, do the word tokenization using NLTK and then compute their word frequencies, and rank from high to low based on the frequencies. 2. manually select stopwords from frequencies higher than 100 by checking if they are just general words and do not show the key idea of the content. Finally, there are 1372 stopwords selected. We will add this process later in the appendix, and the stopwords list will also be released upon acceptance."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4231/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700729733935,
                "cdate": 1700729733935,
                "tmdate": 1700729733935,
                "mdate": 1700729733935,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "akEfqFBZp8",
            "forum": "bRLed9prWC",
            "replyto": "bRLed9prWC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4231/Reviewer_YEss"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4231/Reviewer_YEss"
            ],
            "content": {
                "summary": {
                    "value": "This study pioneers the task of future language modeling, aimed at generating predictive text based on historical documents. It innovates by integrating temporal biases into a pre-trained GPT-2 model, guiding the generation of future-oriented text. The models, trained on NLP paper abstracts from the ACL Anthology spanning 2009-2021, surpass traditional non-temporal models in both automated (Perplexity, METEOR) and human evaluations."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Originality:\n- First to formalize future textual data prediction using temporal information.\nDevelops novel methods for measuring temporal dynamics in language modeling.\n\nQuality:\n- Presents a thorough structure, comparing three new models against multiple baselines.\n- Demonstrates model effectiveness through careful data handling, especially distinguishing between content and non-content words during evaluation.\n\nClarity:\n- Clearly articulates research motivations, background literature, methodology, and findings.\n\nSignificance:\n- Offers significant research outcomes with implications for various applications.\n- Discusses potential future applications and necessary adaptations."
                },
                "weaknesses": {
                    "value": "To improve readability, you can align the organization of tables and figures more closely with their corresponding text."
                },
                "questions": {
                    "value": "none"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4231/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4231/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4231/Reviewer_YEss"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4231/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699257216005,
            "cdate": 1699257216005,
            "tmdate": 1699636390204,
            "mdate": 1699636390204,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2IAG1pYuPb",
                "forum": "bRLed9prWC",
                "replyto": "akEfqFBZp8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4231/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4231/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the detailed review and comments"
                    },
                    "comment": {
                        "value": "Thank you for the detailed review and comments.  We will fix the problem you mentioned for the presentation of the figures."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4231/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700729769623,
                "cdate": 1700729769623,
                "tmdate": 1700729769623,
                "mdate": 1700729769623,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "0Rk7OGoR6p",
            "forum": "bRLed9prWC",
            "replyto": "bRLed9prWC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4231/Reviewer_dCq4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4231/Reviewer_dCq4"
            ],
            "content": {
                "summary": {
                    "value": "The authors proposed a language model that can capture the temporal pattern of text generation. They proposed 3 model variations to attack this problem and conducted experiments over a dataset of ACL paper abstracts. Their most advanced model, the doubly contextualized model, can outperform the GPT-2 based baselines and other variations in both automatic evaluations and human evaluations."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Modeling of temporal patterns in LLM has not captured much attention from the community. Yet it is an important problem to look into.\n2. The paper is very easy to follow. The authors did a good job of describing their ideas and approaches in simple yet accurate terms and notations.\n3. The proposed models look reasonable and are proven to be effective in generating future text based on historical documents."
                },
                "weaknesses": {
                    "value": "1. The proposed models are relatively simple and don't leverage the power of the most advanced LLM. Some problems the authors tried to solve, such as the gating problem in Sec 3.4 look like sth that would not be an issue to GPT-3 or other recently developed LLM as they are very effective in generating readable and coherent text. Finetuning a more powerful LLM with the latest text data seems to be a very effective way to model temporal patterns.\n2. Some details and questions from the experiment were not well discussed. For example, how many raters participated in the human evaluation, what are their agreements, and how subjective are their ratings? Besides, the results in Table 4. are worth more analysis and discussion. Why do the baselines not perform well in Problem and Method? Intuitively, they should be good at generating coherent and readable content."
                },
                "questions": {
                    "value": "NO"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4231/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4231/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4231/Reviewer_dCq4"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4231/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699288758526,
            "cdate": 1699288758526,
            "tmdate": 1701060440257,
            "mdate": 1701060440257,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ojUrj1EU04",
                "forum": "bRLed9prWC",
                "replyto": "0Rk7OGoR6p",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4231/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4231/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the detailed review and comments"
                    },
                    "comment": {
                        "value": "Thank you for the detailed review and comments. Below are our responses to weaknesses:\n\nResponse to Weakness 1:\n\nThe main reason we did not compare recent LLMs is potential data contamination issues.  Recent LLMs are likely to have trained on our testing dataset, and we do not know for certain if they are contaminated or not.  This make it difficult to compare recent LLMs to our approach fairly.  However our method is applicable to any LLM, and can easily be applied to recent open LLMs.\n\nThe gating issue that we solve is not specific to GPT-2.  GPT-2 is already a very capable generation model, and can easily generate fluent text.  The fluency issue occurs when we apply simple bias methods (sections 3.2 and 3.3) to account for temporal information.  This causes the fluency of the model to be greatly degraded, as we show in our experiments.  The gating mechanism we introduce fixes this issue.  So we do not believe a recent LLM would have fixed this issue either, since the issue wasn\u2019t originally present in GPT-2, but was introduce by the temporal information.  We think this is a fundamental problem of introducing temporal information to LLMs.  We will make this more clear in the text.\n\nResponse to Weakness 2:\n\nWe will add additional details about the number of raters and agreement for the human evaluation.\n\nThe baselines do not perform well in Problem and Method because, without any constraints, they are next token prediction language models, and they hallucinate and can generate nonsense or non-relevant content (i.e. What the method talks about may far away from the problem, or an older method is used to solve the problem).  The example outputs in the appendix give a good intuition of the problems with the baseline models.  We will discuss this further in the paper."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4231/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700729824300,
                "cdate": 1700729824300,
                "tmdate": 1700729824300,
                "mdate": 1700729824300,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]