[
    {
        "title": "Deep Variational Multivariate Information Bottleneck - A Framework for Variational Losses"
    },
    {
        "review": {
            "id": "I5Q5nAWjNY",
            "forum": "ZhY1XSYqO4",
            "replyto": "ZhY1XSYqO4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6306/Reviewer_weLs"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6306/Reviewer_weLs"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a unifying principle for viewing and designing variational bounds based on multiinformation, aka total correlation [1]. The paper combines different variational upper and lower bounds (including MI Neural Estimators \u2013 MINE). Their frameworks recovers for example beta-VAEs or DVCCA. The newly introduced deep variational symmetric information bottleneck DVSIB objective is illustrated on a noisy MNIST dataset and where it yields to clusters for t-SNE embeddings or good classification accuracies based on the latent representations.\n\n\n[1] Watanabe, Satosi. \"Information theoretical analysis of multivariate correlation.\" IBM Journal of research and development 4.1 (1960): 66-82."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "A plethora of works have been developed for multi-modal datasets that rely on variational methods in varying forms. Having a unifying framework to analyse such works is thus of great importance for the community. The submission thus addresses an important issue. Their introduced DVSIB objective is new, as far as I am aware. It outperforms other multi-modal variational methods for classifying noisy MNIST based on the latent representations."
                },
                "weaknesses": {
                    "value": "The paper is sometimes difficult to follow and I feel that the structure of the paper can be improved, for example by using Definition/Proposition/Theorem etc.\n\nTo better assess the performance of DVSIB, it would be very useful to (i) compare it against previous work that also rely on multimodal information-theoretical measures,  such as [1] using a multiinformation bottleneck, (ii) evaluate not just whether the latents can be used for classification, but also the quality and cross-model consistency of the reconstructed images, for example following standard multi-modal evaluation measures [2]; and (iii) consider additional multi-modal datasets beyond noisy MNIST.\n\n[1] Hwang, HyeongJoo, et al. \"Multi-view representation learning via total correlation objective.\" Advances in Neural Information Processing Systems 34 (2021): 12194-12207.\n[2] Shi, Yuge, Brooks Paige, and Philip Torr. \"Variational mixture-of-experts autoencoders for multi-modal deep generative models.\" Advances in neural information processing systems32 (2019)."
                },
                "questions": {
                    "value": "Can the approach be generalised to more than two modalities?\n\nHow are the $\\beta$ values in Table 2 tuned? Does it make sense to use different $\\beta$ values for evaluating the classification accuracy for different methods, as I would guess that different $\\beta$s impact how much information is encoded into the latent variables."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6306/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698634567379,
            "cdate": 1698634567379,
            "tmdate": 1699636693175,
            "mdate": 1699636693175,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SqxzUehav5",
                "forum": "ZhY1XSYqO4",
                "replyto": "I5Q5nAWjNY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6306/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6306/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely appreciate the time and effort you dedicated to evaluating our manuscript and for your thoughtful insights.\n\n$\\\\textbf{Structural concerns:}$ We acknowledge your suggestion about potentially framing the paper using Definition/Proposition/Theorem structures. However, we believe that our current outline, which delves into explaining the framework's mathematics, its implementation, the generation of new methods, and benchmarking, aims for pedagogical clarity. It seems that there's a significant disagreement among the Reviewers whether the structure of the manuscript that we've chosen is easy to understand, and we suspect that this is due to the Reviewers coming from different subfields. As we explained above, we chose to keep the current structure, aimed largely at those working in the Information Bottleneck space, and we also refined our manuscript to provide a more explicit explanation for readers from other backgrounds.\n\n$\\\\textbf{Comparison to other methods:}$ We appreciate your recommendation to compare against various multimodal architectures and evaluate cross-modal consistency. We had already included multimodal architectures such as CCA and its variants even in the original submission. Furthermore, we now integrated the architectures cited in your suggestions into our methods. As we have stated in the general response, it is important to note that our focus lies in the framework itself, enabling the integration and derivation of various methods. We do not aim for state-of-the-art classification accuracy against much better tuned and bigger AI systems. Yet, even with these caveats, our findings already indicate improved accuracy when the method's structure aligns with the expected statistical dependencies in the dataset.\n\n$\\\\textbf{Evaluation on other datasets:}$ Expanding our method's evaluation to other datasets, indeed, could strengthen our work. To address this, we applied DVSIB to the MIR-Flick dataset (please the the general response). However, the caveats remain that it is hard to benchmark a new, developing method, against state-of-the-art systems, fine-tuned using computational resources not generally available to us.\n\n$\\\\textbf{Including more than two modalities:}$ Our approach can, indeed, extend to include multiple modalities. We have updated the appendix to include implementations of such architectures, demonstrating the straightforward derivation of loss functions for multimodal architectures mentioned in the literature involving more than two modalities. And yet we can still use the elements of the code that we used in the other methods as well, ensuring a straightforward generalization towards crafting new methods that address specific research questions.\n\n$\\\\textbf{Tuning of $\\\\beta$:}$  We perform a sweep across the specified range of $\\\\beta$, selecting the value that corresponds to the highest classification accuracy. We document these sweeps comprehensively in the supplementary data (in the provided Methods Results.ipynb notebook). The varying $\\\\beta$ values indeed impact the information content differently for each model, necessitating tailored beta values for maximizing their potential and ensuring a fair comparison between different methods.\n\nWe genuinely thank you once again for your invaluable feedback and for your insightful comments. Your suggestions have been instrumental in refining our work and enhancing its clarity."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700688634183,
                "cdate": 1700688634183,
                "tmdate": 1700688634183,
                "mdate": 1700688634183,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "o8RVCwwVoi",
            "forum": "ZhY1XSYqO4",
            "replyto": "ZhY1XSYqO4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6306/Reviewer_uWuS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6306/Reviewer_uWuS"
            ],
            "content": {
                "summary": {
                    "value": "This paper provides a unifying framework for a number of variational dimensionality reduction techniques through the unifying lens of the information bottleneck.  They use this framework to quickly rederive several existing techniques, including a very slight generalization of one technique (Deep Variational Canonical Correlation Analysis).  They also derive an approach similar to DVCCA which they call Deep Variational Symmetric Information Bottleneck (DVSIB), which involves performing dimensionality reduction on two views of a set of sample simultaneously.  The novelty is that while trying to maximally compress the latent representation of each view (i.e., minimize the amount of information between the views and their latent representations) DVSIB also tries to maximize the information between the two latent representations.  They apply various methods to a variation on MNIST where each observation consists of two \"views\" of the same digit.  One view is a random sample from MNIST of that digit that is then randomly rotated.  The other view is another random draw of the same digit that is then randomly noised.  The authors find that classifiers trained on top of DVSIB representations outperform classifiers trained on top of different representations."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The presentation is extremely clear.\n* The unifying framework is a nice, conceptually clean way to unify a number of methods, and makes it easy to quickly derive loss functions for a fairly general family of dimensionality reduction techniques.  \n* DVSIB seems like a sensible and promising approach for finding probabilistic embeddings of multi-view data.\n* Table 1 is a nice compendium of methods and concisely explains how these methods fit into the proposed framework."
                },
                "weaknesses": {
                    "value": "Major:\n\n* The evaluations and benchmarking felt limited, for a few reasons that I will detail in the next few comments.  First, the MNIST example feels somewhat contrived, and MNIST in general has become something of a toy dataset.  A more complex, more realistic application dataset would make the applicability of DVSIB more clear.\n* Even on the MNIST application, I felt that the benchmarking was insufficient.  In particular, in Figure 3 and Table 2 it seems like there is almost no penalty for making $\\beta$ huge as long as it is large enough, in which case the penalty on the encoder essentially does not matter.  In the VAE setup this would cause the encoder to concentrate on the MAP instead of the posterior, essentially reverting to an Auto-Encoder.  Are only the means of the variational distributions used in the downstream classification task?  Can the authors performing any benchmarking where the probabilistic interpretation on the latent space matters?\n* Similarly, it seems like the MNIST benchmarking only gets at the importance of the size of the latent space in an oblique way.  In particular, across almost all methods performance always does better with a larger latent space (including DVSIB).  The paper would benefit from an analysis similar to the motivation suggested in the introduction, namely an example where the original dimensionality of the data is prohibitively large relative to the number of labeled examples for training the classifier, but a large unlabeled dataset exists to learn a good dimensionality reduction. In such a case dimensionality reduction would be absolutely necessary to obtain good classification performance.\n* In order to compute the mutual information between $Z_X$ and $Z_Y$, the authors essentially use an energy-based model, learning $T(z_x, z_y)$ as an unnormalized log-likelihood (up to multiplication by the marginals).  Additional details on how the normalizing constant, $Z_\\text{norm}$, is computed or approximated are warranted.\n\nMinor / typos:\n\n* Is $\\Sigma_{Z_X}(x)$ assumed to be diagonal?  If not, what does it mean to learn the ``log variance''?\n* I believe that the title of Subsection 2.2 should be \"Variational Bounds\" not \"Variation Bounds\"\n* There is a typo in Equation (13) -- the MINE subscript should be on the term involving $Z_X$ and $Z_Y$, not the term with $Y$ and $Z_Y$.\n* \"available in the Appendix 5,4\" appears to be a typo."
                },
                "questions": {
                    "value": "see weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6306/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698727132797,
            "cdate": 1698727132797,
            "tmdate": 1699636693057,
            "mdate": 1699636693057,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Mj3TMzNCSh",
                "forum": "ZhY1XSYqO4",
                "replyto": "o8RVCwwVoi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6306/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6306/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the Reviewer for the kind words regarding our presentation, framework, and method. Your recognition of the clarity in our presentation and the conceptual soundness of our unifying framework is immensely gratifying. We endeavored to present our work in a clear and coherent manner. We agree that DVSIB provides \"a sensible and promising approach for finding probabilistic embeddings of multi-view data\". This resonates deeply with our intentions to apply DVSIB to neural and behavioral data, which we are currently exploring in other research avenues.\n\n$\\\\textbf{Limited experimental evaluation:}$ Addressing the weaknesses you pointed out, particularly the limited evaluation, we want to reiterate that the core of our contribution lies in the framework itself. We aim to demonstrate how this framework provides unification, generalization, and how it facilitates the creation of new methods. We consider Table 1, as much a  primary result of our work as Table 2, which outlines how different algorithms perform on the MNIST data. We have never aimed to achieve state-of-the-art classification accuracy against much bigger and more fine-tuned learning systems. Tishby (one of the inventors of the now so popular Information Bottleneck framework) famously noted that the \"tyranny of percent correct\" limits the adoption of conceptual advances in machine learning since new, developing concepts cannot immediately compete with well-tuned older methods. We hope that the Reviewers will share this sentiment with us. Nevertheless, we are now including benchmarking of our DVSIB against well-tuned other methods on the MIR-Flicker dataset (see general response for details).\n\n$\\\\textbf{Choice of $\\beta$:}$ The reviewer questioned the lack of performance penalty for large $\\beta$ values. Our current understanding of this phenomenon is as follows. The training drives the decoder to maximize the information gathered from the obtained samples, influencing the reconstruction process significantly. Specifically, our approach involves starting with a batch of pairs of data points, feeding them into the encoder graph, and obtaining probability distributions of $p(z_X|x)$ and $p(z_Y|y)$. Subsequently, we sample from these distributions to learn the decoder. The parameter $\\beta$ plays a crucial role in the decoder's behavior. A larger $\\beta$ prompts the decoder to grasp as much information as possible from the samples $z_X$ and $z_Y$, pushing for maximal information retention in the reconstruction process, given the variational model and the dimensionality of the latent representations. Since the decoder has $I(Z_X, Z_Y)$ term, even at very large $\\beta$, and with variational and dimensional constraints, the methods, therefore, $\\\\textit{does not}$ revert to an autoencoder since not all of the features of the original samples of views are useable for predicting the representation of the other view. \n\n$\\\\textbf{Size of the latent space:}$  The rationale behind increasing dimensions, indeed, allows capturing of finer-grained information between the two latent representations, which might not be easy to capture in the initial dimensions. This is especially true when the sample size is large enough, so that these small details stand out from the statistical noise (which is the case for our tests). However, in realistic scenarios with limited samples, expanding dimensions can hurt the reduction process. See for example (https://arxiv.org/abs/2309.05649) for the analysis of this problem (we expect that more dimensions will hurt, similar to how larger cardinalities do). In such cases, maintaining low dimensionality becomes pivotal for achieving both high accuracy and feasible modeling.\n\n$\\\\textbf{Estimating mutual information in the latent space:}$ Many estimators can be used to compute the information between $Z_X$ and $Z_Y$. The only requirement is that the estimator is differentiable. However, as we discussed above, it is important to use an estimator that \"matches\" the specific task at hand. As we hinted above, we leave the detailed analysis of which estimators should be used when to future work. Finally, in the revision we provided more explicit details regarding the computation of the normalizing constant, $\\\\mathcal{Z}_\\\\text{norm}$, as the Reviewer has requested.\n\nWe would like to end with our appreciation of your meticulous detail in noting minor typos. We rectified these errors in our revised manuscript. Thank you for your detailed feedback."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700688376373,
                "cdate": 1700688376373,
                "tmdate": 1700688376373,
                "mdate": 1700688376373,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "4UMW3ERfX8",
            "forum": "ZhY1XSYqO4",
            "replyto": "ZhY1XSYqO4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6306/Reviewer_JTcS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6306/Reviewer_JTcS"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces Deep Variational Multivariate Information Bottleneck (DVIB) as a framework to derive variational losses for dimensionality reduction purposes. A method section rooted in existing literature demonstrates how to de-compose multi-information associated with encoding and decoding distribution and how to bound and estimate each term using variational inference and deriving a Deep Variational Symmetric Information Bottleneck (DVSIB) objective for a specific instance of graphical models. The effectiveness of the proposed method and model is demonstrated on augmented pairs of MNIST digits."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1) The paper introduces a general framework inspired by the Information Bottleneck principle that can in theory applied to a wide variety of graphical models as an effective dimensionality (and information) reduction strategy.\n\n2) The DVIB framework generalizes a variety of models in the literature, extending VIB [1] to graphical models with more than 2 variables."
                },
                "weaknesses": {
                    "value": "## Main concerns\n\n1) **Novelty**\n    1) The novelty of the proposed Deep Variational Symmetric Information Bottleneck seems quite limited since the objective is quite similar to the existing literature and the main differences are not clearly underlined in the main text.\n\n2) **Experimental analysis**\n   1) The paper introduces a framework that can in principle applied to complex graphical models involving multiple variables, but the experimental section (and most of the method) solely focuses on a two-variable system that has been widely explored in the literature.\n   2) The experiments revolve solely around the MNIST dataset. Further, the paper claims that \"none of the algorithms were given the data labels\" even though the training pairs are constructed by pairing digits with the same label. As a result, label information is indirectly captured in the dataset structure.\n   3) The paper lacks common baselines based on contrastive learning that can be applied in the same settings [1,2,3]. In particular [2] proposes a similar loss function and demonstrates similar performance without using the labels for pairing images.\n   4) The qualitative visualization relies solely on t-SNE even if there is evidence to support that t-SNE visualization could be misleading [4].\n\nThe paper presents an interesting approach through the DVIB framework, which holds the potential for principled dimensionality reduction in structured datasets consisting of tuples of joint observations. However, the current submission falls short of demonstrating its contributions due to a limited experimental section and lack of novelty in the chosen setting. A more compelling case could be made by extending the analysis and experiments to encompass more complex graphical models and tasks, as opposed to the limited scope of addressing well-studied symmetric 2-observed variables as reported in the main text. This expanded focus would not only enhance the novelty but also demonstrate the method's applicability and effectiveness in more challenging scenarios.\n\n## Minor issues\n1) Some of the citation years and venues are incorrect (e.g. Friedman et al., 2013 has been published in UAI 2001)\n\n\n### References\n[1] Chen, Ting, et al. \"A simple framework for contrastive learning of visual representations.\" International conference on machine learning. PMLR, 2020.\n\n[2] Federici, M., Dutta, A., Forr\u00e9, P., Kushman, N., & Akata, Z. \"Learning robust representations via multi-view information bottleneck.\" International Conference on Learning Representations, ICLR, 2020.\n\n[3] Zbontar, Jure, et al. \"Barlow twins: Self-supervised learning via redundancy reduction.\" International Conference on Machine Learning. PMLR, 2021.\n\n[4] Yang, Zhirong, Yuwei Chen, and Jukka Corander. \"T-SNE is not optimized to reveal clusters in data.\" arXiv preprint arXiv:2110.02573 (2021)."
                },
                "questions": {
                    "value": "1) What are the main differences between DVSIB and the existing methods in literature? How are they potentially related to the improved performance?\n\n2) What is the rationale behind the choice of MINE for mutual information maximization? More recent mutual information maximization strategies [1] are shown to yield more stable and effective training.\n\n3) How does the prescribed DVIB model perform on more complex datasets consisting of tuples of observations with a known graphical model? Can DVIB make better use of the structure of the problem when compared to popular modern representation learning methods that do not explicitly consider the relation between the variables?\n\n\n### References\n\n[1] Poole, Ben, et al. \"On variational bounds of mutual information.\" International Conference on Machine Learning. PMLR, 2019."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6306/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6306/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6306/Reviewer_JTcS"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6306/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698836719725,
            "cdate": 1698836719725,
            "tmdate": 1700834343494,
            "mdate": 1700834343494,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZtsVzK8dSs",
                "forum": "ZhY1XSYqO4",
                "replyto": "4UMW3ERfX8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6306/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6306/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the Reviewer for their careful assessment of our work. \n\n$\\\\textbf{Novelty:}$ We believe that an important contribution of our work is in providing a conceptually clean way to unify a number of dimensionality reduction methods within the information-theoretic language. For example, trade-off parameters that often need to be added in an $\\\\textit{ad-hoc}$ manner with other derivations naturally arise using our framework. As we emphasized in our previous responses, the Deep Variational Symmetric Bottleneck is meant to be one of the applications of our more general framework. It produces two latent variables that retain maximal information about one another, rather than about the the individual views of the data. This is a main distinction of this specific method from the others we reviewed.  Part of the loss of DVSIB anchors the $Z_X$ and $Z_Y$ via decoders to $X$ and $Y$. This is one main difference as compared to your Ref.[2]. Our method produces a generative model for $X$ and $Y$ at the same time as producing $Z_X$ and $Z_Y$ maximally informative of each other. Ref.[2], on the other hand, makes distributions for mapping of the latent variables $Z_X$ and $Z_Y$ as close to one another as possible. In fact, it enforces that $Z_X$ and $Z_Y$ have the same domain. This is different from DVSIB where the latent variables can have different units, dimensions, and domains. Please see our general response for details. Finally, we now include performance of the loss in Ref.[2]  loss in our main results table for comparison, and we thank the Reviewer for the suggestion that we should compare to this and other additional methods. \n\n$\\\\textbf{Additional evaluation:}$ We now evaluate our method using the MIR-FLICKR dataset. Please see the general response for the details of what we did. Further, we would like to clarify that the noisy MNIST dataset that we used for our main experiments was not given the data labels. The label information, of course, is indirectly captured in the dataset structure by having pairs of images with the same label. This is precisely the main point of DVSIB and related multiview methods:  if there is some relationship between $X$ and $Y$, we can recover it without telling our model about the relationship (aka, without labeling). We were able to demonstrate that DVSIB  was able to do just that by elevating the performance of a linear SVM to predict the labels from the latent space. As far as we understand, this is a standard way of testing representation learning algorithms (see e.g., Wang et al., 2015; 2016).\n\n$\\\\textbf{Concerns about visualization:}$ We recognize that t-SNE is not infallible for showing evidence of clustering or of a quality of the latent space. Hence we use t-SNE for qualitative visualization only, and our main results are quantified instead by training an SVM on our learned latent space for label identification. Our SI includes several plots of visualizations of our method reduced to two dimensions where t-SNE is not used, yielding qualitatively similar results.\n\n$\\\\textbf{Question 1:}$ We answered this question in more detail in our main response to all Reviewers.\n\n$\\\\textbf{Question 2:}$ MINE is one possible estimator that we could have used to produce a variational bound on the information between the latent representations. $I_\\\\text{NCE}$ could just as easily have taken its place (parenthetically, existing work shows that the two are related, for instance [3]). Our approach just requires a differentiable estimator. Neither of the methods will be good universally, and different estimators should be used in different applications, depending on properties of the data. We now note this in the paper text. However, for the demonstrations in this work, MINE was sufficient, and we decided to stay with it.\n\n$\\\\textbf{Question 3:}$ We believe this is an important question, and one that we are addressing in future work. We think that providing the dependence structure of the problem (as we do using the encoder and the decoder graphs) that matches the data in question will yield better methods, more tailored to their respective problems. However, none of the methods will be better than the others universally. We are working on applications in the context of neuroscience and dynamical systems inference, where we will explore this question in detail in specific datasets."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687162914,
                "cdate": 1700687162914,
                "tmdate": 1700687162914,
                "mdate": 1700687162914,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ez26NQ6Om4",
            "forum": "ZhY1XSYqO4",
            "replyto": "ZhY1XSYqO4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6306/Reviewer_MfdL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6306/Reviewer_MfdL"
            ],
            "content": {
                "summary": {
                    "value": "The authors study variational dimensionality reduction and propose a multivariate information bottleneck framework that generalizes several existing method (e.g, beta-VAE) and yields new algorithms for settings where we want to jointly compress two distinct data representations."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The authors study an important problem in dimensionality reudction\n- The proposed framework yields a nice generalization of existing methods for variational dimensionality reduction"
                },
                "weaknesses": {
                    "value": "1. I feel like the writing of the paper still has quite a bit of room for improvement\n- Even understanding the task that the authors are solving took a long time. I see it first in Section 2.1. It should be clear from the abstract and intro that we are trying to map two views into a latent space. Right now, the intro reads like a long list of related work.\n- I am familiar with the VAE and variational inference literature, and I found the derivations unnecessarily hard to follow. In particular, there exists standard notation used in variational inference (e.g., q is an encoder/approximate posterior, p is the decoder, etc.) and it doesn't seem to be used in the paper. \n- The paper is trying to solve problems that are in the domain of probabilistic modeling and variational inference, but uses techniques based on information theory. For readers that are less familiar with information theory, it would help to have a paragraph that explains more how these methods relate to the literature on VAEs and variational infernece.\n- At a high level, I found that in some places the paper is overly verbose, and in others it is overly terse.\n\n2. The experimental results are not very strong in my opinion.\n- First of all, since this is not mainly a theory paper, I feel like the authors should experiment on more than one dataset.\n- Ideally, some of these datasets would be more sophisticated than MNIST. I feel like this method would be very useful for researchers in biology or neuroscience, perhaps exploring applied problems in these fields would make the paper stronger.\n- I am not entirely sure if the set of baselines is the best one. For example, the new method is the only one which defines two separate latents for each of the two views of the data. Is the improvement in performance attributed to the fact that each view gets its own latent (which is not a novel idea from this paper; there are other methods that do this), or to the specific way in which the method generates these latents. In order to determine this, another baseline that computes one latent variable per view would be helpful.\n- In particular, what if I were to fit a VAE-type model with two latents $Z_X, Z_Y$ and two observed variables $X, Y$ such that the q and the p have the same independence structure as DVSIB in Table 1. Would this approach be equivalent to DVSIB? If yes, there should be a discussion. If they are not equivalent, then the VAE-type model should be a baseline (and there should still be a discussion of the pros/cons of each approach).\n\nOverall, I am leaning towards rejection, but I am willing to raise my score if I am missing something, or if there is additional compelling evidence that the authors could provide."
                },
                "questions": {
                    "value": "- Are there any additional datasets and baselines that could be added to the paper?\n- How does the method compare to VAE-type model with two latents $Z_X, Z_Y$ and two observed variables $X, Y$ such that the q and the p have the same independence structure as DVSIB in Table 1?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6306/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699143301579,
            "cdate": 1699143301579,
            "tmdate": 1699636692849,
            "mdate": 1699636692849,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jDNdtu9uB9",
                "forum": "ZhY1XSYqO4",
                "replyto": "ez26NQ6Om4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6306/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6306/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "$\\\\textbf{Presentation:}$ We thank the Reviewer for their suggestions for improving the paper. Existing literature for autoencoders and VAEs typically uses maximum likelihood methods for deriving the loss functions. Here we use an information bottleneck approach to achieve the same thing. The Information in the Decoder graph is maximized, which corresponds to maximizing the log-likelihood, and the information in the encoder graph is minimized corresponding to the approximate posterior.  We follow the notation used by Alemi et al. in \"Deep Variational Information Bottleneck\", which has become a $\\\\textit{de facto}$ standard in the context of information-based variational models.  Thus we use $p$ to represent the \"true\" distributions and $q$ and $r$ as variational approximations to the true distributions. We understand that this is not the notation that is used commonly in the VAE literature, which makes our paper difficult to read for some members of the community.  However, for some other members, e.g., Reviewer 4, this choice seems to have made the presentation clear. We have made the choice to stay with the information-based notation. However, to make our work accessible to the other half of the community, we added additional details in the main text describing our notation and how our framework relates to the literature on VAEs. We hope that this will make the paper easier to read for everyone.\n\n$\\\\textbf{Impact and contribution:}$ One of our primary contributions is the proposal for the general Deep Variational Multivariate Information Bottleneck (DVMIB) framework. This is a general framework, which incorporates many of the representation learning methods (the ones we explored in the paper, and most of the ones mentioned by the Reviewers) under one information-theoretic umbrella, allowing to design new methods systematically instead of $\\textit{ad hoc}$. In fact our second primary contribution was in using this flexibility of the framework to create a new specific method, DVSIB, which has not been seen anywhere in the prior literature. DVSIB is just an example of what the framework can do, and, while novel and promising, we only view it as the second main contribution, behind developing a conceptually clean and flexible framework for designing variational losses. We have clarified our main contributions in the introduction to our paper. \n\n$\\\\textbf{Additional experiments:}$ We agree with the Reviewer that evaluation of DVSIB on more complex datasets is welcome. Crucially,  we want to reiterate that we do not intend to compete with the state-of-the-art classification methods, trained using much bigger networks, on hardware beyond those available to us, and hence with the ability to fine-tune all algorithmic parameters. As we explain in our general response, we provide the current implementation of DVSIB as a proof of concept, hoping to illustrate that, even without fine-tuning and large-scale computing, its performance is already promising. To this end, we now evaluate DVSIB on an additional, more complex dataset: the MIR-FLICKR dataset. Please see the general response for more details of what we've done. We also conducted additional experiments on other algorithms suggested by this Reviewer and other Reviewers. The main Table in the manuscript already included several methods that computed one or more latent variable per view. including DVCCA and its variants. The table now includes performance using the loss from \"[1] Learning robust representations via multi-view information bottleneck\" paper, among others suggested by the Reviewers.\n\n$\\\\textbf{More on relations to VAEs:}$ With regards to your question, \"If I were to fit a VAE-type model with two latents $Z_X$, $Z_Y$ and two observed variables $X$, $Y$ such that the $q$ and the $p$ have the same independence structure as DVSIB'', we believe that this would be the same as our approach, with just a different name for the same concept. (This is as long as there is the same dependence between $Z_X$ and $Z_Y$ as shown in our model of DVSIB. If there is no dependence then, the structure you described is the same as two separate VAEs, one for $X$ and one for $Y$). This joint encoding, while keeping information between the compressed variables is crucially different from parallel VAEs in our opinion, as we have emphasized in the general response."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700686683692,
                "cdate": 1700686683692,
                "tmdate": 1700686683692,
                "mdate": 1700686683692,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]