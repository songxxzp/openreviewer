[
    {
        "title": "Improving Neural Program Induction by Reflecting on Failures"
    },
    {
        "review": {
            "id": "fiwRq0cusH",
            "forum": "OzAGE2W9yz",
            "replyto": "OzAGE2W9yz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5038/Reviewer_bWPz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5038/Reviewer_bWPz"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes FRGR, an approach to improve training of neural logic models (NLMs). The intuition behind FRGR is to guide the NLM away from incorrect solutions found in prior training iterations. FRGR works by adding an additional regularization term that penalizes the magnitude of weights that in prior training iterations were high-magnitude connections between layers of the NLM. The paper evaluates FRGR on a range of tasks, finding that it generally results in faster training and better generalization than standard NLM training without the FRGR regularization term."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The paper addresses an interesting domain and problem of improving training (both accuracy and efficiency) of neural logic programs\n* The core of the paper is an interesting insight of adding a term to avoid past errors observed when training the NLM\n* The evaluation results (taken at face value, though see weaknesses below) are quite strong."
                },
                "weaknesses": {
                    "value": "* I find Section 2.2 very hard to understand. I have some background in logic programming, but none in neural logic machines. Specifically, I was unsure on the following points:\n  * \"First, given a set of objects $\\mathcal{U}$ of size $m$...\" -- it is not clear what an object is, or what it means for an object to have a size.\n  * \"the NLM model first grounds $p$ on $\\mathcal{U}$, which derives a tensor representation of $p^\\mathcal{U}$...\" -- I'm not sure what it means to ground $p$ in this context.\n  * I broadly found the discussion of Figure 2 to be hard to understand\n* I also find Section 3 hard to understand:\n  * Algorithm 1, line 4/5: what is the difference between $f$ and $f_\\theta$?\n  * \"$b$ and $d$ denote the number of depth and breadth of the NLM model architecture respectively\" -- is this backwards, or does $b$ refer to depth and $d$ refer to breadth?\n* Broadly, I am not convinced by the high level intuition behind the approach. My understanding of the approach is to penalize the magnitude of weights that in prior iterations were high-magnitude connections between layers of the NLM. However, I don't see why this should necessarily lead to a better solution than standard gradient descent: if the set of predicates learned by the NLM is the same as in past iterations, then standard gradient descent should penalize incorrect large-magnitude weights; if the set of predicates is different than in past iterations, then this is penalizing using predicates that may not be incorrect. Essentially, this seems to have the effect of either (1) increasing the effective learning rate, and (2) adding weight decay. I do want to note that a sufficiently strong evaluation would convince me to raise my score despite not being convinced by the high level intuition. However, the evaluation does not pass that bar (see below).\n* Evaluation:\n  * Hyperparameters: as mentioned above, one of the effects of the additional term in the loss function is increasing the effective learning rate. The paper does not provide evidence that the proposed approach outperforms a baseline with a well tuned learning rate. The paper also does not justify (or state) other hyperparameter choices.\n    * The paper does not state how hyperparameters are selected. In particular, hyperparameters are (as best I can tell) identical between the training methods, which may be an unfair comparison.\n    * I also cannot find the value of the hyperparameter $\\gamma$ coefficient for the regularization, the value of the history size $\\tau$, or how these values were tuned.\n  * Regularization: as mentioned above, another effect of the additional term in the loss function is weight decay. The paper does not provide evidence that the proposed approach outperforms a baseline with weight decay (or other regularization)."
                },
                "questions": {
                    "value": "* How are hyperparameters for the evaluation tuned? What are $\\gamma$ and $\\tau$ set to?\n* Does NLM w/ FRGR still outperform standard NLM when both approaches are given the same budget for hyperparameter tuning? When NLM is ran with weight decay?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5038/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698275158239,
            "cdate": 1698275158239,
            "tmdate": 1699636493373,
            "mdate": 1699636493373,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oKxA1naj5s",
                "forum": "OzAGE2W9yz",
                "replyto": "fiwRq0cusH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer bWPz [1/3]"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the detailed review and comments. Please see the following for our response!\n\n### 1. I find Section 2.2 very hard to understand. I have some background in logic programming, but none in neural logic machines. \"First, given a set of objects U f size m \u201c it is not clear what an object is, or what it means for an object to have a size \"the NLM model first grounds p on U, which derives a tensor representation of p_U...\" -- I'm not sure what it means to ground p in this context.\n\nObject refers to an entity or element within a domain of discourse, which is a fundamental and broadly accepted concept of first-order logic [1]. \u201ca set of objects $U$ of size $m$ \u201d means there is a set $U$, and $U$ contains m objects: $|U|=m$. Grounding is a frequently used concept in first-order logic which refers to the process of creating a variable-free first-order formula equivalent to a first-order sentence [2][3]. Thus, \u201c grounds p on $U$\u201d denotes the process of instantiating the variables ($\\alpha_1, \\dots, \\alpha_n$) of atom p($\\alpha_1, \\dots, \\alpha_n$) with the corresponding truth values of the attributes/relations of the object set $U$ (of size $m$) which results in m truth values for the m respective objects. For instance, for the predicate IsFather( $X$, $Y$), and a family of three family members: $U={A, B, C}$. Grounding IsFather on $U$ results in a set of truth values of the ground atoms: IsFather($A$, $B$), IsFather($A$, $C$), IsFather($B$, $C$).\n\n### 2. Algorithm 1, line 4/5: what is the difference between $f$ and $f_\\theta$ ?\" $b$ and $d$ denote the number of depth and breadth of the NLM model architecture respectively\" -- is this backwards, or does refer to depth and refer to breadth?\n\n$f$ and $f_\\theta$ denotes the same neural model, \\theta denotes the the model $f$ is parameterized with the parameters set $\\theta$. $b$ denotes that model breadth and $d$ denotes the model depth. We will update these in our paper.\n\n### 3. However, I don't see why this should necessarily lead to a better solution than standard gradient descent: if the set of predicates learned by the NLM is the same as in past iterations, then standard gradient descent should penalize incorrect large-magnitude weights; if the set of predicates is different than in past iterations, then this is penalizing using predicates that may not be incorrect. \n\nOur approach is inspired by the success of provenance information for SAT-based program synthesis, in which previous error information is leveraged to reduce future search space. We empirically demonstrate that the vanilla training loss is not effective enough to capture model's erroneous behavior pattern and thus results in a ungeneralizable solution as well as low training efficiency. We further conduct a post hoc interpretation analysis to demonstrate the effectiveness of FRGR in refraining model from repeating erroneous behavior. We present an error pattern which FRGR manages to mitigate. Concretely, for the IsMGUncle and IsUncle tasks, their ground-truth programs only involve using binary predicates. The ground-truth programs are shown as follows:\n\nIsUncle:\n\n$$\n \\operatorname{IsUncle}(X, Y) \\leftarrow \\exists Z,  ((\\operatorname{IsMother}(X, Z) \\wedge \\operatorname{IsBrother}(Z, Y))) \\\\\n \\vee(\\operatorname{IsFather}(X, Z) \\wedge \\operatorname{IsBrother}(Z, Y)) \n $$\n\n $$\n\\operatorname{IsBrother}(X, Y) \\leftarrow \\exists Z,  ((\\operatorname{IsSon}(Z, Y) \\wedge \\operatorname{IsSon}(Z, X)) \\\\\n \\vee(\\operatorname{IsSon}(Z, Y) \\wedge \\operatorname{IsDaughter}(Z, X)))\n$$\n\nIsMGUncle:\n$$\n\\operatorname{IsMGUncle}(X, Y) \\leftarrow \\exists Z,(\\operatorname{IsMother}(X, Z) \\wedge \\operatorname{Is} \\operatorname{Uncle}(Z, Y))\n$$\n\nTherefore, it is considered a erroneous behavior if the model strongly attributes its induction based on unary predicates. We calculate the ratio of all output binary predicates whose most attributed input predicate is unary during the training process. We evenly sample 5 epochs from the training process till nlm w/ FRGR converge to a optimal solution. The results are shown in Table 1. It is obvious that with the use of FRGR, the ratio of unary predicates are rapidly decreased compared with the vanilla NLM. The results indicate the FRGR is effectively in recognizing repetitious error pattern during the training process and actively regularizing the model based on it, which results in higher training efficiency and better generalization.\n\n||**IsMGUncle**|||||\n|:--|:-|:--|:--|:--|:--|\n|NLM|0.417|0.444|0.426|0.486|0.394|\n|NLM w/ FRGR|0.417|0.426|0.454|0.394|0.356|\n||**IsUncle**|||||\n|NLM|0.433|0.458|0.450|0.433|0.483|\n|NLM w/ FRGR|0.433|0.442|0.467|0.358|0.375|\n\n[**Table 1**: interpretation analysis.]\n\nThis process is similar to that of the provenance information used in the SAT-based synthesis, in which the solver's error is actively summarized based on previous derivation trees and is used to reduce future search space."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700155912407,
                "cdate": 1700155912407,
                "tmdate": 1700155912407,
                "mdate": 1700155912407,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vbJn468N0b",
                "forum": "OzAGE2W9yz",
                "replyto": "fiwRq0cusH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer bWPz [2/3]"
                    },
                    "comment": {
                        "value": "### 4. Hyperparameters: as mentioned above, one of the effects of the additional term in the loss function is increasing the effective learning rate. The paper does not provide evidence that the proposed approach outperforms a baseline with a well tuned learning rate. The paper also does not justify (or state) other hyperparameter choices. The paper does not state how hyperparameters are selected. In particular, hyperparameters are (as best I can tell) identical between the training methods, which may be an unfair comparison. I also cannot find the value of the hyperparameter coefficient for the regularization, the value of the history size or how these values were tuned.\n\nThe details of the training settings and hyperparameter choices are delivered in Appendix B&C with clear reference on page 6&7 of the paper. We state that all the training settings and hyperparameter choices for the NLM model strictly follow previous work [3] instead of being cherry-picked by ourselves. \nWe have to state that it is inappropriate for the reviewer to state that: \u201chyperparameters are (as best I can tell) identical between the training methods, which may be an unfair comparison.\u201d as it is an extremely common practice to set hyperparameters (such as learning rate) the same for the evaluated baseline models. Please feel free to refer to the cited literature for details [4][5]. Nevertheless, we conduct the hyperparameter analysis of the learning rate, the results are shown in Table 2: We conduct hyperparameter analysis for the IsGrandparent task from the family tree benchmark and 2-outdegree from the graph reasoning benchmark. Specifically, we experiment with the following learning rates: 0.005 (default of NLM), 0.01, 0.05, 0.1 for both NLM and NLM w/ FRGR. \nFor IsGrandparent, the results are shown in the table below. Concretely, for the original NLM model, it performs the best under the default setting (0.005 learning rate) while for NLM w/ FRGR, it performs even better under the 0.1 learning rate. Specifically, the learning iterations can be decreased by +49.82% (from 55.80 to 28.00). \n\n| IsGrandparent|lr |grad-rate|n=20 |n=100|Iterations  |\n|:--|:--|:--|:-|:-|:--|\n|NLM|0.005|100.00% |100.00%|100.00%|96.20\u00b121.87|\n|NLM w/ FRGR|0.1|100.00% |100.00%|100.00%|28.00\u00b16.73 |\n\n[**Table 2**: learning rate analysis.]\n\nFor 2-Outdegree, the best results for both the NLM and NLM w/ FRGR are achieved under the default learning rate (0.005), which are the same results shown in Table 1 of our paper. Therefore, with the same budget of hyperparameter tuning, NLM w/ FRGR steadily outperforms the original NLM."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700156002539,
                "cdate": 1700156002539,
                "tmdate": 1700156002539,
                "mdate": 1700156002539,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6AMFeriOrP",
                "forum": "OzAGE2W9yz",
                "replyto": "fiwRq0cusH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer bWPz [3/3]"
                    },
                    "comment": {
                        "value": "### 5. Regularization: as mentioned above, another effect of the additional term in the loss function is weight decay. The paper does not provide evidence that the proposed approach outperforms a baseline with weight decay (or other regularization).\n\nThe weight decay mechanism is already implemented in the original NLM model, which further demonstrates the effectiveness of FRGR\u2019s effectiveness over this regularization approach. Besides, we further conduct an ablation study by comparing our approach with a random regularization baseline (i.e., randomly penalizing the same percentage of the model\u2019s weights as that of FRGR), denoted as NLM w/ random. The results are shown in Table 3:\n\n|2-Outdegree|grad-rate|n=10|n=20|Iterations|\n|:-|:--|:-|:--|:--|\n|NLM|90.00%|96.52%\u00b10.10|90.80%\u00b10.28|77.9\u00b1150.5|\n|NLM w/ random|80.00%|82.10%\u00b10.36|81.18%\u00b10.38|114\u00b1203.70|\n|NLM w/ FRGR|100.00%|100.00%\u00b10.00|100.00%\u00b10.00|13.40\u00b111.13|\n\n[**Table 3**: regularization comparisons.]\n\nThe results illustrate that by adding random regularization, the model's performance decreases compared to that of the original NLM. Specifically, compared to the original NLM model, the grad-ratio decreases by +10.00%, and the performance decreases by -14.42%.\nWhile with FRGR, it is effective in improving grad-ratio, performance, generalization, and training efficiency.\nThe results demonstrate that the vanilla training loss, random regularization as well as weight decay regularization are not sufficient enough to capture the repetitious error pattern during training thus incapable of improving the NLM model. \n\n### 6. How are hyperparameters for the evaluation tuned? What are $\\gamma$ and $\\tau$ set to?\n\nWe haven\u2019t conducted specific hyperparameter tuning for our method. And we directly adopt the hyperparameter settings from the original NLM paper and used them for all evaluated methods. $\\gamma$ is set to be 0.99 and $\\tau$ is set to be 100 for all tasks.\n\n[1] https://www.cs.rice.edu/~vardi/comp409/lec14.pdf\n\n[2] Migimatsu, Toki, and Jeannette Bohg. \"Grounding predicates through actions.\" 2022 International Conference on Robotics and Automation (ICRA). IEEE, 2022.\n\n[3] Dong, Honghua, et al. \"Neural Logic Machines.\" International Conference on Learning Representations. 2018.\n\n[4] Kim, Donggyun, et al. \"Universal Few-shot Learning of Dense Prediction Tasks with Visual Token Matching.\" The Eleventh International Conference on Learning Representations. 2022. (Outstanding Paper)\n\n[5] Riad, Rachid, et al. \"Learning Strides in Convolutional Neural Networks.\" International Conference on Learning Representations. 2021. (Outstanding Paper)"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700156120860,
                "cdate": 1700156120860,
                "tmdate": 1700156120860,
                "mdate": 1700156120860,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ybRHoyYpvr",
                "forum": "OzAGE2W9yz",
                "replyto": "fiwRq0cusH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would appreciate it if the reviewer can be more involved in the discussion (Nov 10-22) and let us know whether the response has clarified the corresponding questions."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700456073590,
                "cdate": 1700456073590,
                "tmdate": 1700456073590,
                "mdate": 1700456073590,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HpS0tEWmtt",
                "forum": "OzAGE2W9yz",
                "replyto": "fiwRq0cusH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would appreciate it if the reviewer could let us know whether the response has clarified the corresponding questions as it is approaching the Author/Reviewer Discussion period deadline (Nov 22) and it has already been 5 days since we posted our response (Nov 16)."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700570148856,
                "cdate": 1700570148856,
                "tmdate": 1700570148856,
                "mdate": 1700570148856,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XZZqxykGir",
                "forum": "OzAGE2W9yz",
                "replyto": "HpS0tEWmtt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Reviewer_bWPz"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewer_bWPz"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks to the authors for the detailed rebuttal. Based on this rebuttal, I'm currently planning to keep my score as-is. I do think the paper is interesting and the results are strong (assuming they hold up to more rigorous scrutiny, which is not currently possible with the description of the technique and its evaluation in the paper). But though the authors have clarified the approach and presented more evidence of its effectiveness, I still believe that the paper needs another round of revision (and fresh reviews) before acceptance.\n\nMy main critiques of the paper are of the clarity of the writing, and of the strength of evidence for the presented approach. \n\n**Clarity:** This was a common issue among all reviewers, and while I appreciate the clarifications offered in the response and the promises to update the paper, I don't feel comfortable raising my score on these grounds without a revised version of the paper that is significantly more clear. \n\n**Strength of evidence:** Given the lack of theoretical results and that other reviewers also do not have an intuition for why the proposed approach should work, this paper requires strong empirical evidence to support the claim \"that FRGR can considerably improve the training efficiency\u2026 of the neural program induction model\". However even with the additional experiments and details provided on hyperparameters in the rebuttal, I still believe the paper needs another revision and set of reviews to provide sufficiently solid evidence on this point. In particular, the paper does not provide enough details on hyperparameters and their tuning to reproduce the experimental results or to give confidence that a practitioner or follow-up paper would be able to apply this technique with the same success as in this paper (relative to the baseline).\n\nThe authors state that it is inappropriate for me to ask about hyperparameter tuning for the baseline. I strongly disagree with this. The original submission did not provide any evidence that the chosen hyperparameter settings were reasonable for the baseline (for the settings not explicitly evaluated in Dong et al., 2018) or discuss the resources required to choose the hyperparameters for FRGR (e.g., the response to Reviewer 7KpG shows that the choice of tau=100 leads to significant increases in performance on 6-connectivity relative to tau=75 or 125; the paper and response do not discuss how this choice was initially made to set tau to 100, rather than e.g. 1, 10, or 1000, or how gamma was set to 0.99). The rebuttal provides learning rate experiments, but still does not provide a complete description of how all hyperparameters were tuned.\n\nFurther, many hyperparameters and methodological details are still left unclear. For instance, the rebuttal states that  \"the weight decay mechanism is already implemented in the original NLM model\". The paper does not mention this, say what the weight decay hyperparameter is, or how it was tuned. Especially given that the paper is comparing an alternative regularization term, this is a crucial detail, and leaving it out significantly decreases my confidence in the results.\n\nIn writing this response, I also noticed that the results for vanilla NLM reported in the paper (Table 1) are significantly worse than the results for vanilla NLM reported in Dong et al., 2018: specifically, Dong et al report 100% accuracy for all family tree and graph reasoning tasks. Maybe I'm missing something in the paper, but why are the NLM results in this paper much worse than the NLM results in Dong et al, 2018?"
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700587707182,
                "cdate": 1700587707182,
                "tmdate": 1700587707182,
                "mdate": 1700587707182,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "iPiU9tTgSy",
            "forum": "OzAGE2W9yz",
            "replyto": "OzAGE2W9yz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5038/Reviewer_YeEy"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5038/Reviewer_YeEy"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors introduce a regularisation scheme for Neural Logic Machines, aimed at improving their performance on Neural Program Induction tasks. The scheme works by \"recording\" the errors committed during training and regularising the neural networks weights associated with them via $L_1$-type loss. The authors report improved performance (w.r.t a NLM trained without using their scheme) and data efficiency over a range of program induction tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The proposed regularisation scheme appears logically sound and ultimately relatively simple to implement.\n- The authors demonstrate that it does improve performance and data efficiency on a range of tasks."
                },
                "weaknesses": {
                    "value": "- The paper is written for a specialist audience, with little context or background given about NLP, about what the challenges in it are, about how ML methods can help solve it, or even just about what the tasks look like. In general, a formulation of the problem as a task that can be used to train a neural network on a certain experience and with a certain performance metric is omitted completely and taken for granted. As a result, most readers (as well as this referee) will not be able to get much from this paper.\n- Because of this, it's hard (though not impossible, see below) for me to assess the scientific content of this paper and the scope of its contribution to the field. Bit I nevertheless feel that the shortcomings on the presentation side are still sufficient to recommend that it be rejected or at least substantially revised.\n- The authors' method appears to work as intended, but also to be quite narrow in applicability: it only presumably works on NLMs (since it requires direct control of the weights) and only for the particular task considered by the authors. At first sight, the scope of the contribution appears very limited.\n- The authors refer to their scheme as a constraint on the weights, which seems to imply thet an hard constraint is imposed on them, whilst the scheme is more properly defined as a regularisation strategy, or a \"soft\" constraint."
                },
                "questions": {
                    "value": "My main recommendation would be for the authors to provide context on NLP, NLMs, and on how their task can be solved via ML methods to begin with, and on how one would train a neural net to do so. Without such context, it's for me impossible to do justice to the content of this paper, but it is also going to be impossible for a mainstream ML reader (such as most of those attending ICLR) to profit from the paper to begin with.\n\nOn the contribution side, the authors should prove that their regularisation scheme does have any general applicability beyond NLP tasks carried out with NLMs.\n\nUnless both of these shortcomings can be suitably addressed, the implication will be that this work is more suited for publication in a specialised venue rather than a broad conference such as ICLR.\n\n## Post-rebuttal edit:\n\nThe authors' rebuttal did convince me that my assertion of the general applicability of their method was erroneous and that \"NLP tasks\" was a somewhat misleading designation on my part. The architecture that the paper's regularisation method is applied to (the Neural Logic Machine or NLM) can indeed be used for multiple reasoning benchmarks of interest, which the authors do in their submission. In reason of this, I have revised my contribution score to \"good\".\n\nI think that the papers still suffers from unclear writing, which results in the context of the author's work not being properly outlined for anyone not already familiar with it. The authors have not seemingly addressed these concerns in their revision, which is also missing markers to highlight changes w.r.t the original version.\n\nIn reason of this, while I do revise my score upwards, I still consider this paper to be below the acceptance threshold."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No concerns."
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5038/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5038/Reviewer_YeEy",
                        "ICLR.cc/2024/Conference/Submission5038/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5038/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698694790149,
            "cdate": 1698694790149,
            "tmdate": 1700573847186,
            "mdate": 1700573847186,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HHDpWFxGVb",
                "forum": "OzAGE2W9yz",
                "replyto": "iPiU9tTgSy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer YeEy [1/2]"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the detailed review and comments. Please see the following for our response!\n\n### 1. The paper is written for a specialist audience, with little context or background given about NLP, about what the challenges in it are, about how ML methods can help solve it, or even just about what the tasks look like. In general, a formulation of the problem as a task that can be used to train a neural network on a certain experience and with a certain performance metric is omitted completely and taken for granted. As a result, most readers (as well as this referee) will not be able to get much from this paper.\n\nOur work is unrelated to NLP and the term \u201cNLP\u201d or \u201cnatural language processing\u201d never exists throughout our paper. The focus of our work is on relational reasoning and decision-making tasks which is clearly stated many times in our paper as well as supplementary materials. Furthermore, it is a factual error to state that the description of the tasks and evaluation metrics are omitted. The corresponding details are all clearly delivered in section 4.1 and Appendix C with clear reference in the footnote of page 6. We sincerely recommend the reviewer carefully reread the paper and provide a more objective assessment.\n\n### 2. My main recommendation would be for the authors to provide context on NLP, NLMs, and on how their task can be solved via ML methods to begin with, and how one would train a neural net to do so. Without such context, it's for me impossible to do justice to the content of this paper, but it is also going to be impossible for a mainstream ML reader (such as most of those attending ICLR) to profit from the paper, to begin with.\n\nOur work is unrelated to NLP. The concrete details of the NLM model are delivered in section 2.2 and Appendix D with clear reference in the footnote of page 4. The training details can be found in section 4.1 and Appendix B with clear reference on page 7. Again, We sincerely recommend the reviewer to carefully reread the paper and provide a more objective judgment.\n\n### 3. On the contribution side, the authors should prove that their regularisation scheme does have any general applicability beyond NLP tasks carried out with NLMs.\n\nOur work is unrelated to NLP. The benchmarks evaluated in our work range from relational reasoning tasks and decision making tasks, which are all broadly used by many domains such as LLMs [1], program induction [2], SAT-based program synthesis [3], etc.\n\n### 4. The authors' method appears to work as intended, but also to be quite narrow in applicability: it only presumably works on NLMs (since it requires direct control of the weights) and only for the particular task considered by the authors. At first sight, the scope of the contribution appears very limited. [1/2]\n\nIt is a disparagement to regard our method as \"work as intended\" and \"presumably works on NLMs and only for the particular task considered by the authors\". First, we state that the domain of neural program induction is not narrow and limited and the NLM is an influential sota baseline: It manages to outperform previous enlighting methods such as DILP and MemNN. We also show that it also manages to outperform the sota gpt-4 model on the relation reasoning tasks. The results are shown in Table 1, where n denotes the number of family (graph) members. \n\n||GPT-4||GPT-4 w/ CoT||NLM||\n|:--|:---|:---|:--:|:---:|:---|:---|\n|Task|n=20|n=30|n=20|n=30|n=20|n=30|\n|grandparents|93.97%|93.69%|95.67%|97.00%|96.15%|96.53%|\n|uncle|97.05%|96.44%|97.98%|97.87%|99.15%|98.68%|\n|mguncle|98.95%|99.00%|99.47%|99.46%|99.85%|99.68%|\n||n=10|n=20|n=10|n=20|n=10|n=20|\n|1-outdegree|85.00%|76.50%|85.00%|76.50%|97.00%|85.50%|\n|6-connectivity|93.80%|58.58%|94.70%|58.58%|91.80%|91.73%|\n\n[**Table 1**: LLMs evaluation.]\n\nSpecifically, all models are given samples with n=20 for few-shot learning, and tested with n=20 samples for performance and n=30 for generalization evaluation for the Family tasks. And for the graph reasoning tasks, all models are given samples with n=10 for few-shot learning, and tested with n=10 samples for performance and n=20 for generalization evaluation. The results indicate that the NLM outperforms the gpt-4 model as well as the gpt-4 with chain-of-shot mechanism [1] under few-shot learning setting with much smaller model size. It is also demonstrated in previous work that the LLM methods perform poorly on the blocksworld decision making benchmark [2] while NLM manages to excel it."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700153390455,
                "cdate": 1700153390455,
                "tmdate": 1700153390455,
                "mdate": 1700153390455,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "g1ndan228v",
                "forum": "OzAGE2W9yz",
                "replyto": "iPiU9tTgSy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer YeEy [2/2]"
                    },
                    "comment": {
                        "value": "### 4.The authors' method appears to work as intended, but also to be quite narrow in applicability: it only presumably works on NLMs (since it requires direct control of the weights) and only for the particular task considered by the authors. At first sight, the scope of the contribution appears very limited. [2/2]\n\nTo demonstrate the fact that FRGR is general, we also evaluated our method on more recent DLM model [3]. The results are shown in Table 2 & 3. The results indicate that FRGR is also effective in improving the DLM model under both the data-rich and data-scarce settings.\n\n|Family Tree|DLM||||DLM w/ FRGR (Ours)||||\n|:--:|:---:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n||\\# Iterations|Grad-ratio|n=20|n=100|\\# Iterations|Grad-ratio|n=20|n=100|\n|HasFather|22.00(\u00b14.69)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|23.6(\u00b17.13)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|\n|HasSister|68.80(\u00b112.67)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|67.20(\u00b13.27)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|\n|IsGrandparent|50.80(\u00b114.46)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|55.60(\u00b17.40)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|\n|IsUncle|319.20(\u00b1165.54)|60.00%|60.00%(\u00b10.49)|60.00%(\u00b10.49)|278.40(\u00b1155.48)|80.00%|80.00%(\u00b10.40)|80.00%(\u00b10.40)|\n|IsMGUncle|459.20(\u00b191.23)|40.00%|48.1%(\u00b10.30)|20.00%(\u00b10.40)|423.80(\u00b1104.35)|60.00%|58.20%(\u00b10.35)|40.00%(\u00b10.49)|\n|Graph|DLM||||DLM w/ FRGR (Ours)||||\n||\\# Iterations|Grad-ratio|n=10|n=20|\\# Iterations|Grad-ratio|n=10|n=20|\n|1-OutDegree|46.20(\u00b12.39)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|50.00(\u00b17.24)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|\n|2-OutDegree|81.60(\u00b113.74)|100.00%|100.00%(\u00b10.10)|100.00%(\u00b10.28)|73.60(\u00b13.84)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|\n|4-Connectivity|90.40(\u00b122.42)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|87.40(\u00b115.09)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|\n|6-Connectivity|282.40(\u00b1146.44)|80.00%|86.90%(\u00b10.26)|53.28%(\u00b10.34)|230.80(\u00b1166.14)|80.00%|95.40%(\u00b10.09)|90.10%(\u00b10.20)|\n\n[**Table 2**: Results under data-rich scenario with DLM and DLM-FRGR]\n\n|Family Tree|DLM||||DLM w/ FRGR (Ours)||||\n|:--:|:---:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n||\\# Iterations|Grad-ratio|n=20|n=100|\\# Iterations|Grad-ratio|n=20|n=100|\n|HasFather|23.20(\u00b13.63)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|27.00(\u00b16.41)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|\n|HasSister|58.80(\u00b17.56)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|67.60(\u00b17.67)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|\n|IsGrandparent|44.40(\u00b14.77)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|56.80(\u00b17.82)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|\n|IsUncle|401.60(\u00b1149.62)|40.00%|40.20%(\u00b10.49)|40.00%(\u00b10.49)|362.80(\u00b1141.94)|80.00%|80.00%(\u00b10.40)|80.00%(\u00b10.40)|\n|IsMGUncle|500.00(\u00b10.00)|0.00%|0.00%(\u00b10.00)|0.00%(\u00b10.00)|500.00(\u00b10.00)|0.00%|0.00%(\u00b10.00)|0.00%(\u00b10.00)|\n|Graph|DLM||||DLM w/ FRGR (Ours)||||\n||\\# Iterations|Grad-ratio|n=10|n=20|\\# Iterations|Grad-ratio|n=10|n=20|\n|1-OutDegree|47.20(\u00b12.28)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|48.00(\u00b15.83)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|\n|2-OutDegree|92.00(\u00b136.93)|100.00%|100.00%(\u00b10.10)|100.00%(\u00b10.28)|83.620(\u00b127.69)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|\n|4-Connectivity|82.80(\u00b115.27)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|68.00(\u00b15.83)|100.00%|100.00%(\u00b10.00)|100.00%(\u00b10.00)|\n|6-Connectivity|424.00(\u00b1169.94)|20.00%|75.30%(\u00b10.22)|59.80%(\u00b10.23)|359.20(\u00b1196.01)|40.00%|83.60%(\u00b10.17)|70.00%(\u00b10.261)|\n\n[**Table 3**: Results under data-scarce scenario with DLM and DLM-FRGR]\n\nSecond, in terms of the tasks used for evaluation in our work, it is inappropriate to state the \"...only for the particular task considered by the authors\" as we did not cherry-pick the evaluation tasks. All the benchmarks we used are directly adopted from the NLM and DLM papers. All these tasks are also broadly used for the reasoning ability evaluation of LLMs [2] as well as SAT-based program synthesis [4].\nIn summary, all the above-mentioned evidence suggests that FRGR is not \"intended\" and \"limited in contribution\" by significantly improving over the state-of-the-art neural program induction models (which are sota in terms of relational reasoning ability) on previously adopted and broadly used benchmarks.\n\n[1] Wei, Jason, et al. \"Chain-of-thought prompting elicits reasoning in large language models.\" Advances in Neural Information Processing Systems 35 (2022): 24824-24837.\n\n[2] Valmeekam, Karthik, et al. \"Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change).\" NeurIPS 2022 Foundation Models for Decision Making Workshop. 2022.\n\n[3] Matthieu Zimmer, et al. \"Differentiable Logic Machines\". Transactions on Machine Learning Research. (2023).\n\n[4] Raghothaman, Mukund, et al. \"Provenance-guided synthesis of datalog programs.\" Proceedings of the ACM on Programming Languages 4.POPL (2019): 1-27."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700153517523,
                "cdate": 1700153517523,
                "tmdate": 1700153517523,
                "mdate": 1700153517523,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "71znVg6ABO",
                "forum": "OzAGE2W9yz",
                "replyto": "iPiU9tTgSy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would appreciate it if the reviewer can be more involved in the discussion (Nov 10-22) and let us know whether the response has clarified the corresponding questions."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700456041771,
                "cdate": 1700456041771,
                "tmdate": 1700456041771,
                "mdate": 1700456041771,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3ePHxyc2dU",
                "forum": "OzAGE2W9yz",
                "replyto": "iPiU9tTgSy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would appreciate it if the reviewer could let us know whether the response has clarified the corresponding questions as it is approaching the Author/Reviewer Discussion period deadline (Nov 22) and it has already been 5 days since we posted our response (Nov 16)."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700570122216,
                "cdate": 1700570122216,
                "tmdate": 1700570122216,
                "mdate": 1700570122216,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "H0ibR1XMmd",
                "forum": "OzAGE2W9yz",
                "replyto": "71znVg6ABO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Reviewer_YeEy"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewer_YeEy"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their clarifications on the paper and I apologize for not engaging earlier.\n\nFirst of all, yes, with NLP I meant Neural Logic Programming, not Neural Linguistic Programming. I thank referee JknR for suggesting that this might be the case. It is true, the acronym NLP never appears in the paper, but I though that what I was referring was obvious from the context. At any rate, the authors could have simply asked for clarification rather than jumping to conclusions, especially considering that their belief that I had mistaken their work for relating to Neural Linguistic Programming is featured in three of the points in their reply.\n\nI get the impression that the authors misconstrued my review as an attack to their work. I wish to point out that this is not the case and that I myself stated that my confidence in the score I assigned is low. To be more concrete, when I stated that their method works \"as intended\" I was not implying that they have merely found a solution for a problem they invented.\n\nI was under the mistaken impression that NLM and Neural Logic Programming were \"tasks\" whilst, after re-reading the paper and the authors' reply, I can now see that they are fundamentally architectures/inductive biases which can indeed be applied to multiple tasks. I retract my statement that the authors only considered one particular task with limited impact in order to test their method. It is indeed true that they apply their method to multiple and relevant benchmarks, and therefore their work has indeed more relevance and applicability than I first claimed.\n\nStill, my concerns on presentation and writing remained mostly unaddressed. I re-read the paper, and the writing of section 2 and 3 still seems as unclear as it was before the revision. As a matter of fact, the revised version does not clearly highlight which changes, if any, were made to the paper. The authors' responded to my concerns on their writing by simply requiring that I read the paper again; all the other referees raised similar concerns, and it does not seem to me that the authors addressed them much beyond providing explanations in their replies, whilst they should have revised the writing in the paper itself. I cannot speak for the other reviewers, but when I claim that a paper is difficult to read, I am more concerned about its potential future readers than myself. While my initial underestimation of the relevance of NLMs (and by extension, of the authors' work) to broader ML research is definitely due to my own self-admitted ignorance of that field, maybe a more carefully written introduction and sections 2 and 3 would have considerably helped me and any readers in putting the authors' work in the proper context.\n\nBased on this, I shall revise my score upward to 5 and my confidence in this assessment to 3."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700573088020,
                "cdate": 1700573088020,
                "tmdate": 1700573088020,
                "mdate": 1700573088020,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IJK9xrrKs8",
                "forum": "OzAGE2W9yz",
                "replyto": "iPiU9tTgSy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "content": {
                    "title": {
                        "value": "revised version"
                    },
                    "comment": {
                        "value": "Thanks for the response. We have not submitted the revised version of the paper before as we think the reviewer has not carefully read the paper due to the misleading use of \"NLP\" as well as the previous unfair claims. We have now submitted the revised version  of the main paper as well as the supplementary materials which explain NLM model design more plainly in the preliminary and we use a concrete case to explain the rationale of FRGR in the methodology section. Besides, we have revised all the mentioned details by all the reviewers as well. The revised parts are highlighted in blue. We hope the reviewer to inspect our revised version and take it into consideration for the rating."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700592164181,
                "cdate": 1700592164181,
                "tmdate": 1700592307538,
                "mdate": 1700592307538,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KScbpSCbcE",
            "forum": "OzAGE2W9yz",
            "replyto": "OzAGE2W9yz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5038/Reviewer_JknR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5038/Reviewer_JknR"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a training modification to improve the training efficiency, generalization, and performance of neural models for inductive logic programming. Motivated by provenance-guided SAT-based synthesis techniques, the proposed technique stores an ongoing list which contains provenance information for each error experienced, in the form of the weight location that most contributed to an error. \nThen it applies a pattern mining algorithm to summarize the errors, and applies L1 regularization to the erroneous neurons during training. Experiments show that with this training modification, the existing neural ILP approach of Neural Logic Machines improves in performance, data efficiency, computational efficiency, and generalization."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- The technique is quite novel, at least to me. I have never seen a technique of attempting to improve data efficiency of neural network training by cataloguing errors and penalizing their recurrence with L1 regularization. The success of a similar technique in SAT-based program synthesis motivates the technique well, and it appears this works due to the close connection between the NN architecture and the logical meaning of weight activations. \n- The improvements in performance seem significant! Performance is never decreased, and especially large improvements are seen in complex tasks and in data-scarce settings.\n- The paper is well-written.\n- The approach is simple and general enough that I would guess it has a good chance of successfully apply to other settings.\n- The experiments seem thorough: they cover both supervised and RL tasks, the same tasks covered in prior work, and additionally evaluate in both normal and data-scarce settings."
                },
                "weaknesses": {
                    "value": "There are two main weaknesses to the paper: (1) there is not much attempt to understand why the technique works. (2) some of the writing in section 2 and 3 is not clear or fully explained. (1) is a much more important weakness, as (2) can be fixed pretty easily.\n\n(1) there is not much attempt to understand why the technique works.\n- Given how novel the approach is to me, I have a hard time forming a mental model connecting technique's description with the resulting performance. \n    - No ablations or comparisons of design choices, or even motivation given for the design choices.\n    - The paper would be stronger with experiments (could be toy) or examples that show how the approach is working, or a discussion comparing the usefulness of provenance information for SAT-based synthesis with how the provenance information is helping the neural models\n    - I think there should be more description in section 3 of why the technique works: I guess the model is  a bunch of logical combinations simultaneously during training, and due to the logical nature of the NN activations, it's possible to get information about \"incorrect search\" happening just how the SAT solver generates erroneous formula. \n   - see questions section for more questions attempting to understand and contextualize the technique.\n   \n(2) unclear writing\n- The description of NLM's in section 2.2 is not super clear. I'm unsure how much it can be improved while keeping the section short, but I would recommend working on it. In particular, the original NLM paper did a much better job by intuitively summarizing the approach before describing the details more formally. \n- The description of the approach in section 3 is poor. it leaves out numerous details, or mentions them unsystematically. things like \"what is an error?\", eq 1 is challenging to understand, the error list updating is never described clearly outside of the pseudocode\u2014 based on the pseudocode, you store a list of the T most recent errors, and once T are found, you run the pattern mining algorithm. and then you start over with a new list, right? this could be quickly described with a sentence in the text.\n- what does the Apriori algorithm return? a single thing? based off elsewhere, it returns a set of weights, but this should be described when Apriori is brought up.\n- Supplementary material could do a better job of describing the inputs and outputs of the model for the relational reasoning tasks and the rRL tasks. \n\nTo summarize, I have no criticisms of the technique, experiments, or results, but **I do wish there were more justification of the design choices, ablations, other experiments, discussion, or comparison to related techniques, to help understand why this approach works**."
                },
                "questions": {
                    "value": "- How much of a correspondence is there between the form of the provenance information in this paper and RAGHOTHAMAN et al 2019?\n-  RAGHOTHAMAN et al 2019 provides guidance for both \"why\" an incorrect conclusion was derived and \"why not\" i.e. why a correct conclusion was not derived, but this work only provides guidance for \"why\". what about \"why not\" mistakes? \n    - To elaborate more, regularization of errors is never done with NN training in any other domain. Does this approach fail when applied to image classification? Both a yes or no answer would be quite illuminating... \n- Is there any related work of such types of techniques? (l1 penalty on negative examples, storing errors during training)\n\nAnswering these questions as well as those raised in the Weaknesses section regarding the lack of attempt to understand why the method works would improve my opinion of the paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5038/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5038/Reviewer_JknR",
                        "ICLR.cc/2024/Conference/Submission5038/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5038/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698762717131,
            "cdate": 1698762717131,
            "tmdate": 1700495655759,
            "mdate": 1700495655759,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pvnHbtQCM5",
                "forum": "OzAGE2W9yz",
                "replyto": "KScbpSCbcE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer JknR [1/2]"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the detailed review and comments. Please see the following for our response!\n### 1. No ablations or comparisons of design choices, or even motivation given for the design choices.\n\nWe conduct an ablation study by comparing our approach with a random regularization baseline (i.e., randomly penalizing same percentage of the model\u2019s weights as that of FRGR), denoted as NLM w/ random. The results are shown in Table 1:\n\n|2-Outdegre | grad-rate |n=10| n=20| Iterations |\n| :--| :--| :-- | :--- | :--- |\n| NLM| 90.00% | 96.52%\u00b10.10  |  90\\.80%\u00b10.28  | 77\\.9\u00b1150.5  |\n| NLM w/ random | 80.00%   | 82\\.10%\u00b10.36  |  81\\.18%\u00b10.38  | 114\u00b1203.70  |\n| NLM w/ FRGR | 100.00%| 100.00%\u00b10.00 |100\\.00%\u00b10.00 | 13\\.40\u00b111.13 |\n\n[**Table 1**: regularization comparisons.]\n\nThe results illustrate that by adding random regularization, the model's performance decreases compared to that of the original NLM. Specifically, compared to the original NLM model, the grad-ratio decreases by +10.00%, and the performance decreases by -14.42%.\nWhile with FRGR, it is effective in improving grad-ratio, performance, generalization, and training efficiency.\nThe results demonstrate that the vanilla training loss, random regularization as well as weight decay regularization are not sufficient enough to capture the repetitious error pattern during training thus incapable of improving the NLM model. \n\n### 2. The paper would be stronger with experiments (could be toy) or examples that show how the approach is working, or a discussion comparing the usefulness of provenance information for SAT-based synthesis with how the provenance information is helping the neural models\n\nWe present an error pattern that FRGR manages to mitigate. Concretely, for the IsMGUncle and IsUncle tasks, their ground-truth programs only involve using binary predicates.  The ground-truth programs are shown as follows:\n\nIsUncle:\n\n$$\n \\operatorname{IsUncle}(X, Y) \\leftarrow \\exists Z,  ((\\operatorname{IsMother}(X, Z) \\wedge \\operatorname{IsBrother}(Z, Y))) \\\\\n \\vee(\\operatorname{IsFather}(X, Z) \\wedge \\operatorname{IsBrother}(Z, Y)) \\\\\n$$\n$$\n\\operatorname{IsBrother}(X, Y) \\leftarrow \\exists Z,  ((\\operatorname{IsSon}(Z, Y) \\wedge \\operatorname{IsSon}(Z, X)) \\\\\n \\vee(\\operatorname{IsSon}(Z, Y) \\wedge \\operatorname{IsDaughter}(Z, X)))\n$$\n\nIsMGUncle:\n$$\n\\operatorname{IsMGUncle}(X, Y) \\leftarrow \\exists Z,(\\operatorname{IsMother}(X, Z) \\wedge \\operatorname{Is} \\operatorname{Uncle}(Z, Y))\n$$\nTherefore, it is considered an erroneous behavior if the model strongly attributes its induction based on unary predicates. We calculate the ratio of all output binary predicates whose most attributed input predicate is unary during the training process. We evenly sample 5 epochs from the training process till NLM w/ FRGR converges to an optimal solution. The results are shown in Table 2. It is obvious that with the use of FRGR, the ratio of unary predicates is rapidly decreased compared with the vanilla NLM. The results indicate the FRGR is effective in recognizing repetitious error patterns during the training process and actively regularizing the model based on it, which results in higher training efficiency and better generalization.\n\n|| **IsMGUncle** || |  |  |\n| :-- | :-- | :-- | :-- | :-- | :- |\n| NLM  |0\\.417 | 0\\.444 | 0\\.426 | 0\\.486 | 0\\.394 |\n| NLM w/ FRGR | 0\\.417| 0\\.426 | 0\\.454 | 0\\.394 | 0\\.356 |\n| | **IsUncle** || | | |\n|NLM | 0\\.433 | 0\\.458 | 0\\.450 | 0\\.433 | 0\\.483 |\n|NLM w/ FRGR  |0\\.433| 0\\.442 | 0\\.467 | 0\\.358 | 0\\.375 |\n\n[**Table 2**: interpretation analysis.]\n\nThis process is similar to that of the provenance information used in the SAT-based synthesis, in which the solver's error is actively summarized based on previous derivation trees and is used to reduce future search space.\n\n### 3. I think there should be more description in section 3 of why the technique works: I guess the model is a bunch of logical combinations simultaneously during training, and due to the logical nature of the NN activations, it's possible to get information about \"incorrect search\" happening just how the SAT solver generates erroneous formula.\n\nWe agree with the explanation of the reviewer that due to the similarity of the neuro-symbolic models' design and the SAT solving process, we can therefore effectively leverage the error pattern of the model's previous learning process (similar to the provenance information summarized from derivation tree which is used in SAT-based synthesis) to improve models' generalization and training efficiency. We will add the corresponding explanation of our method's effectiveness in the paper."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700151903136,
                "cdate": 1700151903136,
                "tmdate": 1700155356830,
                "mdate": 1700155356830,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TsCTf4RKNf",
                "forum": "OzAGE2W9yz",
                "replyto": "KScbpSCbcE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer JknR [2/2]"
                    },
                    "comment": {
                        "value": "### 4. The description of the approach in section 3 is poor. it leaves out numerous details, or mentions them unsystematically. things like \"what is an error?\", eq 1 is challenging to understand, the error list updating is never described clearly outside of the pseudocode\u2014 based on the pseudocode, you store a list of the T most recent errors, and once T is found, you run the pattern mining algorithm. and then you start over with a new list, right? this could be quickly described with a sentence in the text.\n\nAn error simply denotes a wrong final conclusion (i.e., classification results for relational reasoning tasks, actions for decision-making tasks). The understanding of the reviewer in terms of the error list update process is mostly correct: we store a list of the T most recent erroneous behavior in the erroneous behavior list, and once T is found, we run the pattern mining algorithm. And we continuously update the list from the beginning of the erroneous behavior list. We will add more explanation of the update process in our paper.\n\n### 5. What does the Apriori algorithm return? a single thing? based off elsewhere, it returns a set of weights, but this should be described when Apriori is brought up.\n\nApriori returns the position index of the frequently occurred weights of the error behavior representations stored in the erroneous behavior list, as described with a concrete example after Apriori brought up (last paragraph of section 3.1): \u201cAfter the mining process, FRGR manages to identify the error pattern representation that stores the position index of the frequently intersected weights of all historical erroneous behavior representations, \u2026\u201d\n\n### 6. How much of a correspondence is there between the form of the provenance information in this paper and RAGHOTHAMAN et al 2019?\n\nFRGR is motivated by and similar to the provenance information used in SAT-based synthesis, which leverages error from model's previous derivation to reduce future search space. FRGR is the first to propose actively summarizing neural model's error pattern from previous mistakes and using it to boost the model's training efficiency and generalization. The corresponding details are illustrated in the analogy between derivation tree based provenance used in SAT-based synthesis and the neuro-symbolic model architectures shown in the Introduction (section 1).\n\n### 7. RAGHOTHAMAN et al 2019 provides guidance for both \"why\" an incorrect conclusion was derived and \"why not\" i.e. why a correct conclusion was not derived, but this work only provides guidance for \"why\". what about \"why not\" mistakes?\n\nIn this paper, we focus on the realization of the \u201cwhy\u201d provenance on the neural program induction model. This idea of further using \u201cwhy not\u201d for neural program induction is intriguing and would be explored in our future work.\n\n\n### 8. To elaborate more, regularization of errors is never done with NN training in any other domain. Does this approach fail when applied to image classification? Both a yes or no answer would be quite illuminating...\n\nThough in this work, we focus our scope on relational reasoning and decision-making tasks, we believe that our method is general and can be well adapted to other domains such as image classification, robotics, etc. We will strive to further apply our methods to other areas if our paper gets accepted.\n\n### 9. Is there any related work of such types of techniques? (L1 penalty on negative examples, storing errors during training)\n\nTo the best of our knowledge, there are no similar techniques and we are the first to conduct pattern mining on neural model\u2019s previous erroneous behavior and use it to improve training efficiency and generalization."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700152232700,
                "cdate": 1700152232700,
                "tmdate": 1700152232700,
                "mdate": 1700152232700,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fgPFMyudcQ",
                "forum": "OzAGE2W9yz",
                "replyto": "KScbpSCbcE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5038/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would appreciate it if the reviewer can be more involved in the discussion (Nov 10-22) and let us know whether the response has clarified the corresponding questions."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700455964193,
                "cdate": 1700455964193,
                "tmdate": 1700455964193,
                "mdate": 1700455964193,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "q2ftVfeJuu",
                "forum": "OzAGE2W9yz",
                "replyto": "pvnHbtQCM5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Reviewer_JknR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewer_JknR"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for answering my questions. It helps me understand the effectiveness of this approach better. Cool! I have revised my score from a 6 to an 8."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700495634800,
                "cdate": 1700495634800,
                "tmdate": 1700495634800,
                "mdate": 1700495634800,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XB8Id2AZIN",
                "forum": "OzAGE2W9yz",
                "replyto": "71znVg6ABO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Reviewer_JknR"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewer_JknR"
                ],
                "content": {
                    "comment": {
                        "value": "By NLP the review may have meant neural logic programs, or neural logic programming. given the other meaning of NLP, this is confusing either way."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700495788315,
                "cdate": 1700495788315,
                "tmdate": 1700495788315,
                "mdate": 1700495788315,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "m1MqUPNF6P",
                "forum": "OzAGE2W9yz",
                "replyto": "ybRHoyYpvr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Reviewer_JknR"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewer_JknR"
                ],
                "content": {
                    "comment": {
                        "value": "I had similar concerns as this reviewer to be confused why the augmented feedback of penalizing weights used in erroneous solutions is better than SGD. My intuition is that SGD updates may not \"generalize\" as well as the penalized weights, which use a crude type of symbolic reasoning to determine which paths should be penalized. However, I'm not very confident in this intuition"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700496053713,
                "cdate": 1700496053713,
                "tmdate": 1700496053713,
                "mdate": 1700496053713,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "UciwHFbOhb",
            "forum": "OzAGE2W9yz",
            "replyto": "OzAGE2W9yz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5038/Reviewer_7KpG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5038/Reviewer_7KpG"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes a regularization technique called FRGR that leverages a buffer of common recent mistakes during training. The method is implemented on top of neural logic machines (NLM), a neurosymbolic architecture for logic programs. Over two domains (logical reasoning and decision-making), FRGR shows improvements in performance over a vanilla NLM baseline both in the standard setting as well as a low-data regime."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The central idea to augment the training process using representations of past failures is interesting and fairly general, and could be applicable to many important domains."
                },
                "weaknesses": {
                    "value": "The paper is unclear on a number of expository details. $\\theta_\\nu$ in Equation (2) should be given an explicit formula, as this is a key term in the regularizer. The notation is overloaded, for instance $m$ refers to both the size of $\\mathcal{U}$ in Section 2.2 as well as the matching factor in Section 3.2. I also could not find how # of iterations is defined in either the main paper or the appendix, despite this being one of the claimed improvements of FRGR over vanilla NLM.\n\nI also have some concerns about the experimental results. First, many choices of hyperparameters are not explored, such as the choice of the buffer size $\\tau$. It would be good to perform some ablation studies exploring the effect of this hyperparameter. As there is no theory to justify the regularizer, I think this raises the bar for empirical results. Second, the improvement in # of iterations appears not to be statistically significant, as the errors appear quite large. The improvements in Figure 4 appear quite marginal, again with overlapping error bars. \n\nFinally, the related work is missing a number of relevant lines of research, including hard negative mining ([1], i.a.) and experience replay ([2], i.a.).\n\n[1] Feng, Yu, et al. \"Program synthesis using conflict-driven learning.\" ACM SIGPLAN Notices 53.4 (2018): 420-435.\n\n[2] Continuous control with deep reinforcement learning. Timothy P. Lillicrap, Jonathan J. Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David Silver, Daan Wierstra. ICLR 2016."
                },
                "questions": {
                    "value": "In Tables 1 and 2, what are units for the reported errors? Specifically, the entries are generally of the form x% +/- y, so is y a raw number or a percentage?\n\nHow is $\\theta_\\nu$ defined?\n\nHow did you determine when to stop training (for # of iterations)?\n\n===\n\nPost rebuttal I have increased my scores for soundness and presentation, as well as my rating from 3 to 5."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5038/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5038/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5038/Reviewer_7KpG"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5038/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698799658652,
            "cdate": 1698799658652,
            "tmdate": 1700670972132,
            "mdate": 1700670972132,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lk7MpSsTFv",
                "forum": "OzAGE2W9yz",
                "replyto": "UciwHFbOhb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer 7KpG"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the detailed review and comments. Please see the following for our response!\n\n### 1. I also could not find how # of iterations is defined in either the main paper or the appendix\n\nThe concept of iterations is defined in the Evaluation Metrics section of page 7. Training iteration measures the number of training epochs required to train the model till reaching optimal success rate on validation set. We use it to measure training efficiency.\n\n### 2. the choice of the buffer size $\\tau$\n\nThe default value of $\\tau$ is set to 100. We conduct ablation studies to explore the effect of $\\tau$. Specifically, we conduct experiments on the IsUncle task under three different values of $\\tau$: 75, 100, 125, the results are shown in Table 1 & 2:\n\n| tau | grad-rate | n=20       | n=100      | \\# iterations |\n| :-- | :-- | :--- | :--- | :--- |\n| 75  | 100.00%  | 100%\u00b10.00 | 100%\u00b10.00 | 83\u00b122.75     |\n| 100 | 100.00%  | 100%\u00b10.00 | 100%\u00b10.00 | 82.50\u00b117.60  |\n| 125 | 100.00%  | 100%\u00b10.00 | 100%\u00b10.00 | 96.50\u00b125.61  |\n\n[**Table 1**: erroneous behavior list size analysis on IsUncle.]\n\n| tau | grad-rate | n=10         | n=20         | \\# iterations  |\n| :-- | :-- | :----- | :----- | :---- |\n| 75  | 80.00%   | 90.22%\u00b10.18 | 84.44%\u00b10.29 | 143.6\u00b1188.76  |\n| 100 | 90.00%   | 97.12%\u00b10.09 | 94.60%\u00b10.16 | 69.2\u00b1153.32   |\n| 125 | 90.00%   | 95.33%\u00b10.13 | 91.78%\u00b10.23 | 117.00\u00b1143.41 |\n\n[**Table 2**: erroneous behavior list size analysis on 6-connectivity.]\n\nThe results indicate that under all the evaluated settings of $\\tau$, FRGR steadily improves over the original NLM model. \n\n### 3. Second, the improvement in # of iterations appears not to be statistically significant, as the errors appear quite large. \n\nThe reason for the large errors (standard deviation) is that our model manages to converge to the optimal solution for most of the seeds, therefore a single timeout (reaching the maximum 500 epochs) would render the standard deviation of the results large. Whereas the original NLM model often fails to converge to an optimal solution and therefore frequently timeout. For example, Table 3 shows the results of all the evaluated seeds of the 6-Connectivity task (note that 500 training epochs is the timeout threshold):\n\n| NLM      | 151     | 500    | 10     | 500    | 500    | 176    | 500    | 500    | 62     | 500    |\n| :---- | :--- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- |\n| **Ours** | **500** | **12** | **10** | **10** | **15** | **90** | **15** | **12** | **11** | **17** |\n\n[**Table 3**: detailed training epochs of 6-Connectivity.]\n\n### 4. The improvements in Figure 4 appear quite marginal, again with overlapping error bars.\n\nWe state that the improvement is not marginal under the data-scare setting if the reviewer is referring to the curves of performance and generalization. Though the lines of the NLM and NLM w/ frgr could be close when the data volume grows larger (due to the scale of the image), we have to mention that it is critical and also difficult for the models to reach an optimal solution (100\\%) (i.e., inducing the perfect ground-truth program), and with the incorporation of FRGR, the model manages to achieve optimal performance with much fewer iterations. For instance,  NLM w/ FRGR manages to achieve optimal solution with only 800 examples on the IsUncle task, whereas the original NLM never able to achieve that across multiple seeds (only ~98%) with even 1000 examples. The results is consistent with standard deviation = 0 across 10 random seeds. Similarly, for outdegree-2, NLM w/ FRGR achieves optimal performance and generalization with only 200 examples, while the original NLM takes 600 examples.\n\n### 5. In Tables 1 and 2, what are units for the reported errors? Specifically, the entries are generally of the form x% +/- y, so is y a raw number or a percentage?\n\ny is a raw number. We will add the description regarding this format in our paper.\n\n### 6. How is $\\theta_v$ defined?\n\n$\\theta_v$ denotes the the set of instersected weights of the error pattern set and the model\u2019s current behavior representation, which is described in the last paragraph of section 3.2: \u201cIn this work, we consider matching by calculating the intersection between the error pattern set $\\epsilon$ and the model\u2019s current behavior representation $\\omega$, as shown in line 13. This matching factor, denoted by $m$, measures the degree of repetitions (regarding the error pattern presented previously) performed by the model.\u201d, \u201cTo calculate the behavioral regularization term, we obtain the intersected weights set m and apply the L1 norm to aggregate the weights \u2026\u201d\n\n### 7. How did you determine when to stop training (for # of iterations)?\n\nThe training stops when the model achieves 100% success rate on the validation set. The maximum number of epochs is set as 500 for all models, which strictly follows the settings of the original NLM paper."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700157432651,
                "cdate": 1700157432651,
                "tmdate": 1700157432651,
                "mdate": 1700157432651,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wO3n6FTOzp",
                "forum": "OzAGE2W9yz",
                "replyto": "UciwHFbOhb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Submission5038/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would appreciate it if the reviewer can be more involved in the discussion (Nov 10-22) and let us know whether the response has clarified the corresponding questions."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700455914307,
                "cdate": 1700455914307,
                "tmdate": 1700455989494,
                "mdate": 1700455989494,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SsuXrAfPgM",
                "forum": "OzAGE2W9yz",
                "replyto": "lk7MpSsTFv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Reviewer_7KpG"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewer_7KpG"
                ],
                "content": {
                    "comment": {
                        "value": "> Training iteration measures the number of training epochs required to train the model till reaching optimal success rate on validation set\n\nThanks for clarifying. I do not find this clear from the current description in Section 7 (\"Finally, training iteration refers to the number of iterations used for training.\") and would suggest replacing the text in the versions.\n\n> The reason for the large errors... a single timeout\n\nOk, but this just suggests that the standard deviation is not an informative measure of statistical significance for your data. Consider using something like quantile statistics instead\n\n> \\theta_\\nu denotes the the set of instersected weights of the error pattern set and the model\u2019s current behavior representation\n\nPerhaps this is just because I am unfamiliar with ILP, but this notation is quite confusing. $\\theta$ refers to the parameters of the MLP but $\\theta_\\nu$ refers to a set of intersected weights. I'll reiterate my request that the revision have an explicit formula for $\\theta_\\nu$."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700586550017,
                "cdate": 1700586550017,
                "tmdate": 1700586550017,
                "mdate": 1700586550017,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Dh2OuqwmJa",
                "forum": "OzAGE2W9yz",
                "replyto": "SPmfcWfVts",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5038/Reviewer_7KpG"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5038/Reviewer_7KpG"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks. I have read the revised version. I find the new notation $\\theta[\\nu]$ to be more clear, and the background on NLM is great as well.\n\nHaving said that, I still struggle to recommend the paper for acceptance. Right now, the paper proposes a regularizer on top of NLM, and the empirical results demonstrate an improvement over that single base architecture. I'm not very familiar with this subfield, but I think it would greatly improve the contribution to increase the scope of the comparisons. Perhaps with more discussion this could have been resolved, but unfortunately the paper suffered from major clarity issues until very late in the discussion period.\n\nI would also still recommend the authors use a different presentation for their error bars in a future revision."
                    }
                },
                "number": 28,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5038/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700670883323,
                "cdate": 1700670883323,
                "tmdate": 1700670883323,
                "mdate": 1700670883323,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]