[
    {
        "title": "Lyra: Orchestrating Dual Correction in Automated Theorem Proving"
    },
    {
        "review": {
            "id": "zIiCqDRTLG",
            "forum": "9Z0yB8rmQ2",
            "replyto": "9Z0yB8rmQ2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1096/Reviewer_bwwN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1096/Reviewer_bwwN"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents Lyra, an automated system integrating large language models for autoformalisation and symbolic tools such as sledgehammer in proof assistants. The two core components, Tool Correction and Conjecture Correction, are critical for its achieving SoTA performance on the miniF2F benchmark."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The proposed mechanism makes good intuitive sense. The performance improvement is impressive on the miniF2F benchmark. The ablation studies are well-presented and convincing."
                },
                "weaknesses": {
                    "value": "There needs to be more contextualisation of the prior works. For the two major correction mechanisms, there have been direct prior works doing very similar or even identical things.\n- Tool correction: in the DSP work [1], the authors already used sledgehammer + heuristics to close conjectures made. The understanding is that the Lyra method first tries a LLM-generated tactic to close conjectures, and if it doesn't work, try sledgehammer. This is largely similar and should be noted.\n- In the Baldur work [2] from April 2023, the authors have proposed to use the proof assistant error message to repair the proofs. This is very similar to the conjecture correction with error messages and should be noted.\n\n[1] Albert Qiaochu Jiang, Sean Welleck, Jin Peng Zhou, Timothee Lacroix, Jiacheng Liu, Wenda Li, Mateja Jamnik, Guillaume Lample, and Yuhuai Wu. Draft, sketch, and prove: Guiding formal theorem provers with informal proofs. In The Eleventh International Conference on Learning Representations, 2023.\n\n[2] First, Emily, Markus N. Rabe, Talia Ringer, and Yuriy Brun. \"Baldur: whole-proof generation and repair with large language models.\" arXiv preprint arXiv:2303.04910 (2023)."
                },
                "questions": {
                    "value": "None."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1096/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697905258318,
            "cdate": 1697905258318,
            "tmdate": 1699636036040,
            "mdate": 1699636036040,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Grq4E7Yjq8",
                "forum": "9Z0yB8rmQ2",
                "replyto": "zIiCqDRTLG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer bwwN"
                    },
                    "comment": {
                        "value": "Dear Reviewer bwwN,\n \nThank you for appreciating our approach. We address your comments below.\n \n**Q1: Add the contribution of DSP.**\n \nA1: The part is shown on the first page of the Appendix. Because of the paper page limit, we have added the sledgehammer+heuristic description to the Appendix.\n\nMeanwhile, compared to sledgehammer+heuristics in DSP, our proposed Tool Correction has a different motivation and implementation. For example, if \u201cby (simp add: div mult mod eq)\u201d fails, the DSP will immediately stop validating, while our proposed Tool Correction will try all other potential tools. With Tool Correction, we would like to present one important point: the post-process of formal proof can significantly further improve performance, and future work could try to design a more powerful post-process method. And the following is the number of fixed wrong steps via Tool Correction.\n\n|  Dataset | Sledgehammer+heuristics   | Tool Correction  | Number of Fixed Steps|\n|  ---- |  ----  | ----  | ----  |\n| miniF2F-valid  |2260  | 3486 |1226 |\n| miniF2F-test  |2594  | 3887 |1293 |\n\nFor more details, please kindly check our answer in  **The difference between Tool Correction and sledgehammer+heuristic** in **Author Response to All Reviewers**.\n \n**Q2: Baldur is very similar to the conjecture correction with error messages and should be noted.**\n \nA2: We have added Baldur to our reference. And the difference between Baldur and Lyra Conjection Correction is the following.\nCompared to Baldur which needs a training process, Lyra Conjection Correction is training-free, and it can reset the initial solution after several failure rounds. Please refer to the more detailed answer to **The difference between Lyra and other works** in the **Author response to all reviewers**.\n\n \nIf you think our comment and update address your concerns, could you please consider raising your rating of the paper? Thank you!"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699953972634,
                "cdate": 1699953972634,
                "tmdate": 1699953972634,
                "mdate": 1699953972634,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2il8bjM3PK",
                "forum": "9Z0yB8rmQ2",
                "replyto": "Grq4E7Yjq8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Reviewer_bwwN"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Reviewer_bwwN"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your reply. The explanation in the reply and the overall comment makes good sense. \n\nI shall retain my rating as I think it is what the contributions warrant."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700392680638,
                "cdate": 1700392680638,
                "tmdate": 1700392680638,
                "mdate": 1700392680638,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "YEOpjgUdxZ",
            "forum": "9Z0yB8rmQ2",
            "replyto": "9Z0yB8rmQ2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1096/Reviewer_NmsF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1096/Reviewer_NmsF"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a couple of approaches, namely Tool Correction (TC) and Conjecture Correction (CC), for improving the performance of LLM-guided autoformalization techniques based on the Draft-Sketch-Proof (DSP) paradigm. TC is a post-processing technique---once the LLM generates a formal proof sketch, the proof is fed to an Interactive Theorem Prover (ITP) and if the ITP returns an error, then TC uses simple heuristics to replace the tactics in the incorrect formal proof sketch one-by-one. CC, on the other hand, incorporates the error message from the ITP and generates a new prompt that includes the previous proof attempt and the error message. This interaction between the LLM and ITP is conductive up to 5 times. The proposed extensions to DSP are evaluated on the miniF2F benchmark and lead to improved proof success rates."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The techniques lead to an improvement over the state-of-the-art.\n2. I find it a little surprising that models like GPT-4 and Codex are able to understand and act based on the error messages from Isabelle. Unfortunately, the paper does not explore this surprising observation in depth.\n\n-----------------------------\nRating updated to 5 after discussion. Overall, I remain unconvinced by the technical contribution of TC but I find the empirical phenomenon of LLMs being able to interpret ITP error messages interesting\n\n-----------------------------\nRating further updated after much discussion about the general applicability of TC to 6. In particular, the authors presented evidence that TC helps improve performance on another dataset, namely, LISA."
                },
                "weaknesses": {
                    "value": "1. I am not an expert in the area so it is possible that the empirical results might be surprising to experts in a way that I am unable to appreciate. However, I find that the techniques used to achieve the state-of-the-art results do not involve any significant technical or empirical insights.\n\n2. The heuristics used in TC seem too specific to the task and dataset. Are the heuristics used for TC transferable to other theorem proving tools and datasets? How do we know that these heuristics are not overfit to the miniF2f dataset? Do these heuristics represent some general insight into how mathematical theorems ought to be proved?\n\n3. CC simply incorporates the ITP error message into the prompt. On a technical level, this is an obvious idea that has been tried before for proof generation [1] and code generation [2,3]. Some of these approaches require fine-tuning the model, so the scientific question to be evaluated here is does incorporating error feedback without any fine-tuning help **in general** for autoformalization. Since models such as Codex and GPT-4 are not explicitly trained on the error messages from ITPs, one would not expect simply providing the error messages in the prompts to be generally helpful. While the empirical results here suggest that error messages help when the ITP is Isabelle, it remains to be evaluated if it is helpful with other ITPs. It would also be useful to analyze the nature of the error messages generated by Isabelle. Do the improvements depend on the quality of the error messages? One would expect so but this would be another useful aspect to empirically evaluate.\n\n[1] First, E., Rabe, M. N., Ringer, T., & Brun, Y. (2023). Baldur: whole-proof generation and repair with large language models. arXiv preprint arXiv:2303.04910.\n\n[2] Le, H., Wang, Y., Gotmare, A. D., Savarese, S., & Hoi, S. C. H. (2022). Coderl: Mastering code generation through pretrained models and deep reinforcement learning. Advances in Neural Information Processing Systems, 35, 21314-21328.\n\n[3] Wu, X., Cheriere, N., Zhang, C., & Narayanan, D. (2023). RustGen: An Augmentation Approach for Generating Compilable Rust Code with Large Language Models."
                },
                "questions": {
                    "value": "1. Are the presented techniques overfit to miniF2F dataset and Isabelle? In particular, I am afraid this might be the case for TC.\n\n2. Would CC work with the error messages from a different ITP? How much does the availability of formal proofs and error messages for a particular ITP affect the effectiveness of CC?  How much does the quality of the error message affect CC?\n\n3. There are number of spelling errors in Algorithm 2."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1096/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1096/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1096/Reviewer_NmsF"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1096/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698772919304,
            "cdate": 1698772919304,
            "tmdate": 1700553518263,
            "mdate": 1700553518263,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3TqyX7I7iT",
                "forum": "9Z0yB8rmQ2",
                "replyto": "YEOpjgUdxZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer NmsF (Part 1/2)"
                    },
                    "comment": {
                        "value": "Dear Reviewer NmsF,\n \nThank you for the detailed review. We will address your concerns below.\n\n**Q1: The technical or empirical insights.**\n\nA1: Tool Correction presents the importance of post-processing LLM response to improve performance, and Conjecture Correction proposes a framework that can extend the non-refinement framework to a refinement framework.\n\nThe Insight of Tool Correction\n* Experiment Observation. LLM formal proof can not prove a simple conjecture x = 19\u2217(x div 19)+4. After our analysis, this is caused by LLM hallucination that LLM wrong believes by (simp add: div mult mod eq) can prove x = 19\u2217(x div 19)+4. To mitigate the hallucination, we propose to post-process the LLM-generated formal proof by predefined rules, which is called Tool Correction. \n* Following this direction,  the automated theorem proving performance can be further improved, if there are better rules to post-process the generated formal proof. And this is one of the important points that we want to present and prove by Tool Correction.\n\nThe Insight of Conjecture Correction\n* The motivation of Conjecture Correction: propose a technique that can change a non-framework (such as DSP) to a refinement framework (such as Lyra), without too many modifications.\n* Experiment Observation. If directly appends the error message at the end of the prompt,  the LLM response is various. For example, after appending error at the end of (informal Proof 1, formal Proof 1, informal Proof 2, formal Promal 2) to get (informal Proof 1, formal Proof 1, informal Proof 2, formal Proof 2, error), and then ask LLM to refine formal Proof 2, the response may begin with LLM\u2019s comments of formal proof 2, but not a formal proof.\n* Solution. Conjecture Correction adds \u201cproof -\u201d at the end of the instruction as an indicator. As most of the formal proofs begin with \u201cproof -\u201d, adding such an indicator could ask LLm to generate a formal proof.\n\n**Q2: Are the heuristics used for TC transferable to other theorem proving tools and datasets.**\n \nA2: The proposed Tool Correction can be transferable to other theorem proving tools and datasets.  The corresponding heuristics can be transferable to other datasets, and the heuristics need to be designed for different provers as they have different syntaxes.\n\nWe discuss how can we transfer Tool Correction to other theorem proving tools, using Lean Prover as an example.\n* The Lean Prover has proving tools, such as simp, linarith, ring, and so on (these are its heuristics). When proving a conjecture, we can also try these different proving tools (heuristics) in Lean if the current tactic fails. Hence. Tool Correction is transferable to Lean Prover with Lean. \n* Tool Correction and heuristics are not related to datasets, but related to a prover (such as Isabelle or Lean). Hence, as long as we adapt Tool Correction to a prover, the proposed Tool Correction and heuristics can be transferable to other datasets.\n* Therefore, the Tool Correction and heuristics are transferable to other theorem proving tools datasets.\n* Finally, Tool Correction provides the following insights to overcome LLM hallucination. First, decompose the LLM response into different parts. Then, employs predefined rules to post-process the parts.\n\n**Q3: How do we know that these heuristics are not overfit to the miniF2f dataset?**\n\nA3: These heuristics are not overfit to the miniF2F dataset because they are related to a prover, but not a dataset.\n\nThe proposed Tool Correction focuses on post-processing the formal proof which is written in Isabelle in this work. Therefore, the heuristics are related to Isabelle (in this work), but not any dataset, such as the miniF2F dataset.\n\n**Q4: Are the presented techniques overfit to miniF2F dataset and Isabelle? In particular, I am afraid this might be the case for TC.**\n\nA4: The presented techniques are not overfit to miniF2F or Isabelle.\n\nFor Tool Correction, \n* We can easily adapt it to other provers, such as Lean. And this is illustrated in **Q2**.\n* Also, Tool Correction implementation is dataset-agnostic, and it is not related to any datasets, including miniF2F.\n\nFor Conjecture Correction,\n* Conjecture Correction needs formal proof and the corresponding error message, which can come from Isabelle (in this work) and other provers (such as Lean)\n* Conjecture Correction is also not overfit to miniF2F, because its implementation is dataset-agnostic."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699953924720,
                "cdate": 1699953924720,
                "tmdate": 1699953924720,
                "mdate": 1699953924720,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "y8TLIBEUrd",
                "forum": "9Z0yB8rmQ2",
                "replyto": "a7gq01kOo7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Reviewer_NmsF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Reviewer_NmsF"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their long and detailed response. However, there seems to be a misunderstanding about some of my questions and I will try to clarify them below. I will refer to the question numbering used by the authors in their response.\n\n**Q2, Q3, Q4**: I understand that TC as a *technique* depends only on the ITP and not on the dataset. However, whether TC will be effective or not *does* depend on the dataset. There is no guarantee that performance gains due to TC demonstrated on the miniF2F dataset will also transfer to another dataset. Therefore, I fear that the heuristics presented in the paper might be overfit to improving the performance on the miniF2F dataset. \n\n**Q7, Q8**: Again, I understand that CC is a general technique and can work with other ITPs. However, the interesting empirical observation of this paper is that off-the-shelf LLMs (**without any fine-tuning**) are able to understand the Isabelle error messages and fix the proofs.  Would the LLMs evaluated in the paper be able to understand error messages from other ITPs? Do the authors have any hypotheses for why the LLMs are even able to understand Isabelle error messages (for instance, does the publicly available Isabelle proof corpus also have examples of error messages)?"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699978896530,
                "cdate": 1699978896530,
                "tmdate": 1699978896530,
                "mdate": 1699978896530,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PWVanuqC9l",
                "forum": "9Z0yB8rmQ2",
                "replyto": "YEOpjgUdxZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer NmsF (Part 2/2)"
                    },
                    "comment": {
                        "value": "**Q3: Do the authors have any hypotheses for why the LLMs are even able to understand Isabelle error messages (for instance, does the publicly available Isabelle proof corpus also have examples of error messages)**\n\nA3: There are two hypotheses for why the LLMs are even able to understand Isabelle error messages.\n\nLet\u2019s start from an easy point: the LLMs can understand English and Isabelle syntax.\n* LLMs can understand English. This is approved by OpenAI. Therefore, this conclusion is obvious.\n* LLMs can understand Isabelle syntex. \n   * There are publicly available Isabelle proof corpus. For example, The entire AFP library, the\nlargest formal library that contains most of Isabelle proofs, is 180MB in size [2].\n   * LLMs can understand Isabelle's syntax, and this is proved by previous works [2-5]. \n\nHypothesis 1: The publicly available Isabelle proof corpus also has examples of error messages.\n* The training dataset of GPT-3 [6] contains Common Crawl datasets [7], which contain Stackflow.\n* On the Stackflow, we find examples of error messages.\n   * Example 1: Failed to apply initial proof method: using this: [ ] \u2208 ns_public goal (1 subgoal): 1. \u2200A B X. Says A B X \u2209 set_of_list [ ]\n   * Example 2: Failed to apply proof method: using this: (y, x) \u2208 r^* (z, y) \u2208 r goal (1 subgoal): 1. (z, x) \u2208 r^*\n   * Example 3: Failed to apply initial proof method: using this: n < a n < b goal (1 subgoal): 1. n * n < a * b\n* Therefore, the publicly available Isabelle proof corpus may also have examples of error messages.\n\n\nHypothesis 2: the LLMs may understand Isabelle's error message if they understand English and Isabelle's syntax, but do not have to see Isabelle's error messages before. \n* First, we show what Isabelle's error messages look like. The error message is written in English, such as \u201cFailed to apply proof method using this:  0 < y goal (1 subgoal): 1. 9 * (x * sin x) + 4 / (x * sin x) =    (9 * (x * sin x)\\<^sup>2 + 4) / (x * sin x) At command \u201cby\u201d \u201c. \n* According to the error message, we can find that the error message only contains English words and Isabelle syntax (such as \\<^sup>). \n* Therefore, to understand Isabelle's error message, the proposed LLM may not need to see Isabelle's error message before, but just has to understand English and Isabelle's syntax.\n\nIf you think our comment and update address your concerns, could you please consider raising your rating of the paper? Thank you!\n\n[1] Thakur, A., Wen, Y., & Chaudhuri, S. (2023). A Language-Agent Approach to Formal Theorem-Proving. arXiv preprint arXiv:2310.04353.\n\n[2] Wu, Y., Jiang, A. Q., Li, W., Rabe, M., Staats, C., Jamnik, M., & Szegedy, C. (2022). Autoformalization with large language models. Advances in Neural Information Processing Systems, 35, 32353-32368.\n\n[3] Jiang, A. Q., Li, W., Tworkowski, S., Czechowski, K., Odrzyg\u00f3\u017ad\u017a, T., Mi\u0142o\u015b, P., ... & Jamnik, M. (2022). Thor: Wielding hammers to integrate language models and automated theorem provers. Advances in Neural Information Processing Systems, 35, 8360-8373.\n\n[4] Jiang, A. Q., Welleck, S., Zhou, J. P., Li, W., Liu, J., Jamnik, M., ... & Lample, G. (2022). Draft, sketch, and prove: Guiding formal theorem provers with informal proofs. arXiv preprint arXiv:2210.12283.\n\n[5] Zhao, X., Li, W., & Kong, L. (2023). Decomposing the Enigma: Subgoal-based Demonstration Learning for Formal Theorem Proving. arXiv preprint arXiv:2305.16366.\n\n[6] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020). Language models are few-shot learners. Advances in neural information processing systems, 33, 1877-1901.\n\n[7] Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., ... & Liu, P. J. (2020). Exploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research, 21(1), 5485-5551."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700119293297,
                "cdate": 1700119293297,
                "tmdate": 1700119932558,
                "mdate": 1700119932558,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xOwY2828RP",
                "forum": "9Z0yB8rmQ2",
                "replyto": "PWVanuqC9l",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Reviewer_NmsF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Reviewer_NmsF"
                ],
                "content": {
                    "comment": {
                        "value": "I again thank the authors for their long and detailed response.\n\nRegarding **Q1**, I understand that TC is guaranteed to not cause any reduction in performance. As the authors say, it is guaranteed that performance gains due to TC are larger or equal to zero. However, my point was simply that there is no guarantee that the performance gains due to TC will be larger than zero for any dataset. The reason TC helps for miniF2F might be because the heuristics in TC are tailored to this dataset. Is there a reason to believe that these heuristics will also be useful for other datasets?\n\nThank you for the responses to **Q2** and **Q3**.  I think it would be helpful incorporate the discussion on why LLMs might be able to understand error messages in the paper.\n\nOverall, I remain unconvinced by the technical contribution of TC but I find the empirical phenomenon of LLMs being able to interpret ITP error messages interesting. I am updating my score to 5."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700121877747,
                "cdate": 1700121877747,
                "tmdate": 1700121877747,
                "mdate": 1700121877747,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7YEaVJz2z3",
                "forum": "9Z0yB8rmQ2",
                "replyto": "YEOpjgUdxZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer NmsF"
                    },
                    "comment": {
                        "value": "Dear Reviewer NmsF,\n\nThank you very much for the reply, and thank you very much for updating the score. \n\nWe have incorporated the discussion on why LLMs might be able to understand error messages in the paper (please check the updated version). We will explain the question of TC in detail below.\n\n**Q1: However, my point was simply that there is no guarantee that the performance gains due to TC will be larger than zero for any dataset.**\n\nA1: **Our claim and this point does not have conflict**. There is a guarantee that TC does not cause any reduction in performance, and there is no guarantee that the performance gains due to TC will be larger than zero for any dataset. And we prove that **there does not exist** that \u201cthere is a guarantee that the performance gains due to Algorithm A will be larger than zero, compared to baseline sledgehammer+heuristics, for any dataset (**the pass rate limit is 100%**), for any Algorithm A\u201d. We will explain it below.\n\n* **Recall when TC works**. As described in **previous Q1**, TC is employed to reduce the occurrence of \u201cThe Conjecture is correct, but the proving tool is incorrect\u201d.\n   * For a very easy dataset, if any automated proving tool can prove the formal proof from the dataset, then TC may not further improve performance.\n   * For a very difficult dataset, if all conjectures are incorrect for the proof from the dataset, then TC may not further improve performance.\n   * For other datasets (have the occurrence of \u201cThe Conjecture is correct, but the proving tool is incorrect\u201d), the proposed TC has the potential to further improve the performance.\n* Therefore, **both the following two claims are correct**:\n   * There is a guarantee that the performance gains due to TC will be larger than zero or equal to zero.\n   * There is no guarantee that the performance gains due to TC will be larger than zero.\n\nMeanwhile, as we both agree that \u201cthere is a guarantee that the performance gains due to TC will be larger or equal to zero, for any dataset\u201d, we want to prove that there **does not exist** \u201cthere is a guarantee that the performance gains due to TC will be larger than zero, for any dataset\u201d.\n* We already know that both TC and sledgehammer+heuristics (baseline) can solve some problems.\n* Then, we can select a subset, so that the subset\u2019s problem can be solved by both TC and sledgehammer+heuristics.\n   * Therefore, the pass rate of sledgehammer + heuristics is 100%.\n   * If \u201cthere is a guarantee that the performance gains due to TC will be larger than zero, for any dataset\u201d, then the pass rate of TC will be larger than 100%, which is a contradiction.\n* Therefore, there **does not exist** \u201cthere is a guarantee that the performance gains due to TC will be larger than zero, for any dataset\u201d. \n* Actually, it is also easy to prove that there **does not exist** that \u201cthere is a guarantee that the performance gains due to Algorithm A will be larger than zero, compared to baseline sledgehammer+heuristics, for any dataset(**the pass rate limit is 100%**), for any Algorithm A\u201d.\n* Hence, it is **good enough** that \u201cthere is a guarantee that the performance gains due to TC will be larger or equal to zero, for any dataset.\u201d\n\n\n**Q2: The reason TC helps for miniF2F might be because the heuristics in TC are tailored to this dataset.**\n\nA2: We do not tailor the heuristics for the miniF2F dataset.\n\nThese heuristics tools (such as sledgehammer, by simp and so on) are mentioned by the DSP paper (ICLR 2023, Oral). To have a fair comparison, we directly use and keep the same heuristics tools from DSP. Hence, we do not optimize the heuristics tools set for the miniF2F dataset, but directly use these mentioned heuristics tools from the DSP paper. \n\nThough TC and sledgehmmaer+heuristics employ the same heuristics, we both agree that there is a guarantee that TC is better than sledgehammer+heuristics (larger or equal to zero performance gains). Therefore, compared to baseline DSP\u2019s sledgehammer+ heuristics, the improvement of TC is not caused by tailoring the heuristics for the miniF2F dataset.\n\n**Q3: Is there a reason to believe that these heuristics will also be useful for other datasets?**\n\nA3: There are two reasons to believe that these heuristics will also be useful for other datasets: \n* For any given formal proof (dataset), the TC always gets non-negative performance gains, compared with baseline sledgehammer +heuristics (we both agree). \n   * **That TC is helpful and good enough**. Because there does not exist that Algorithm A always gets positive performance gains for any dataset (**the pass rate limit is 100%**), compared to baseline sledgehammer+heuristics, for any Algorithm A (proved in Q1).\n* We do not tailor or optimize the heuristics set for the miniF2F dataset (proved in Q2).\n\n\nIf you think our comment and update address your concerns, could you please consider raising your rating of the paper? Thank you!"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700287539122,
                "cdate": 1700287539122,
                "tmdate": 1700376690571,
                "mdate": 1700376690571,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PwxiIk2pgw",
                "forum": "9Z0yB8rmQ2",
                "replyto": "7YEaVJz2z3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Reviewer_NmsF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Reviewer_NmsF"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for engaging in this discussion. My concerns about the general applicability of TC on datasets other than miniF2F remain and I will keep my updated score."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700404861209,
                "cdate": 1700404861209,
                "tmdate": 1700404861209,
                "mdate": 1700404861209,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HTnnlJB0Hp",
                "forum": "9Z0yB8rmQ2",
                "replyto": "YEOpjgUdxZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer NmsF"
                    },
                    "comment": {
                        "value": "Dear Reviewer NmsF,\n\nThank you very much for your reply. We will address the concerns of TC's general applicability in the following. \n\n**Empirical Results**\n* **Experiment Setting**. Our experiment setting follows previous work, including DSP (ICLR 2023) and Sub-goal learning, which all only conduct experiments on the miniF2F dataset. To the best of our knowledge, the miniF2F is the only dataset that has both informal problem, informal proof and formal statement. And all DSP, subgoal-learning and Lyra need informal problems for inference.\n* To better analyze the TC, we modify the miniF2F to build an IMO problem set (which has 40 IMO problems). The IMO problem set is much more challenging than common automated theorem proving problems, which can effectively prove the TC generalization. The results are the following.\n\n|  Dataset   | Human Informal Proof |  Lyra w/o Tool Correction  |  Lyra | Improvement |\n|  ---- |  :----:  | :----:  | :----:  |  :----:  | \n| IMO problem set | &cross; |2.5% |  2.5% | 0.0%|\n| IMO problem set | &check; |0.0% |  2.5% | 2.5%|\n\nThis proves that: for the other datasets, such as IMO problem set, Tool Correction can still improve the performance. And the emperical results also prove the previous conclusion: the performance gains of TC are larger or equal to zero, compared to baseline sledgehammer+heuristics, for any dataset.\n\n**Theoretical Analysis**\n\nThe following is the analysis of TC's general applicability.\n* The miniF2F is a common and widely used dataset which contains different-level problems and various problem types, so that it can sufficiently evaluate the method. And DSP and subgoal-learning also use the dataset for all their experiments.\n* The TC presents an important idea: post-process LLM response to further improve the performance, which can be widely used for other datasets or tasks.\n* **TC generalization**. **We both agree** that the performance gains of TC are **larger or equal to zero**, compared to baseline sledgehammer+heuristics, for any dataset (TC does not cause performance reduction).\n* **Reviewer NmsF\u2019s requirement of generalization**. the performance gains of TC are **larger than zero**, compared to baseline sledgehammer+heuristics, for any dataset.\n\n* **Obvious point**: as proved in Q2 of Nov 18 response, there is **no model/algorithm that can fullfills** the Reviewer NmsF\u2019s requirement of generalization. \n\nAccording to both **Empirical Results** and **Theoretical Analysis**, the concern of TC's general applicability is addressed.\n\nIf you think our comment and update address your concerns, could you please consider raising your rating of the paper? Thank you!"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700457033169,
                "cdate": 1700457033169,
                "tmdate": 1700457522197,
                "mdate": 1700457522197,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0npSGP7ibI",
                "forum": "9Z0yB8rmQ2",
                "replyto": "HTnnlJB0Hp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Reviewer_NmsF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Reviewer_NmsF"
                ],
                "content": {
                    "comment": {
                        "value": "I again thank the authors for the discussion but perhaps we have to agree to disagree at this stage . Some responses below:\n\n> Reviewer NmsF\u2019s requirement of generalization. the performance gains of TC are larger than zero, compared to baseline sledgehammer+heuristics, for any dataset.\n\nNo, I don't expect TC to perform better than sledgehammer+heuristics for **any** dataset. Perhaps the way I phrased this was unclear and my apologies for the same. In my earlier message when I said that, \"there is no guarantee that the performance gains due to TC will be larger than zero for any dataset\", **any** was meant to be interpreted as an existential quantifier and not as a universal quantifier. My comment was in response to the authors' argument that performance gains due to TC will be zero or larger than zero for any dataset, and it was meant to highlight the fact such a guarantee does not really suggest that TC is going to improve performance on other datasets. It only suggests that TC is not going to hurt performance.\n\n\n> To better analyze the TC, we modify the miniF2F to build an IMO problem set (which has 40 IMO problems).\n\nDoesn't miniF2F also include IMO problems?"
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700464227834,
                "cdate": 1700464227834,
                "tmdate": 1700464227834,
                "mdate": 1700464227834,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "B8HR661hCa",
                "forum": "9Z0yB8rmQ2",
                "replyto": "c0EARhtexc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Reviewer_NmsF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Reviewer_NmsF"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for all the hard work in running these additional experiments to address my concerns. These new results are impressive and I am increasing my score to 6. I hope that the authors will include these additional results and discussions in the paper (or its appendix).\n\nAs a non-expert, there is one question that comes to mind. Why does the simple strategy used by TC, i.e., iteratively replacing the tactics in a failed proof with one of the 11 tactics from the *tool_heuristics* set, work? Does it tell us something fundamental about the nature of mathematical proofs? Or is it an artifact of the types of problems included in datasets such as miniF2F and PISA? I would guess that the same set of 11 tactics are not effective for proofs from every branch of mathematics. \nI do not expect the authors to answer these questions. Instead, I present these as questions that came to my mind as a reader. However, if the authors do have thoughts about this, it would help the paper to include a discussion on it."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700553384302,
                "cdate": 1700553384302,
                "tmdate": 1700553384302,
                "mdate": 1700553384302,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "R3jZBvFWYw",
            "forum": "9Z0yB8rmQ2",
            "replyto": "9Z0yB8rmQ2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1096/Reviewer_1Jjk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1096/Reviewer_1Jjk"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents an LLM-augmented automated theorem proving framework called Lyra in a formal theorem proving environment. The distinguishing features of Lyra include Tool Correction (TC) and Conjecture Correction (CC), which respectively post-edit formal proofs emitted from LLMs given feedback from the proving environment. Good performance has been shown over the miniF2F dataset with 3 IMO problems being solved."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is well written with a clear illustration of its two contributions TC and CC. I especially appreciate the ablation study where Lyra downgrades to DSP without TC and CC. The performance gain also looks good."
                },
                "weaknesses": {
                    "value": "Although I very much like the idea of CC, the innovation of TC appears slightly limited. At least to me, it does not involve much interaction with LLMs -- it is more like an exhaustive attempt on a set of heuristically chosen proof methods other than Sledgehammer."
                },
                "questions": {
                    "value": "- page 1, 'However, they have not been able to post-process LLM generation or gradually refine previous generations.': The Baldur paper (https://arxiv.org/abs/2303.04910) has explored post-processing LLM-generated proofs. I would love to see a comparison between Baldur and Lyra if possible.\n- This paper is mostly based on the previous DSP paper, where LLMs are used to produce proof skeletons (i.e., unproved conjectures). In the tool correction part, it appears that LLMs are prompted to produce a full mechanised proof including the tactic 'by (simp add: div mult mod eq)', which is considered as LLM hallucination by the authors. Is that the case? If so, it might be a good idea to make the distinction clear as this may affect the ablation study. \n- Figure 3, the informal proof and the formal sketch are actually quite different. For example, the formal one does not cover continuity nor limit, which have been mentioned several times in the informal proofs. I was wondering if the authors could elaborate a bit on the discrepancy between the informal proof and the formal one.\n\nminor\n- page 3, 'conducted on LLLMs' -> 'conducted on LLMs'\n- page 5, 'As all formal proof begins with proof -': strictly speaking this is not quite true, as some Isabelle proofs start with 'proof (...)' or 'apply (...)', where ... can be some Isabelle tactics."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1096/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698791868112,
            "cdate": 1698791868112,
            "tmdate": 1699636035896,
            "mdate": 1699636035896,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oB3quvEhUI",
                "forum": "9Z0yB8rmQ2",
                "replyto": "R3jZBvFWYw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1Jjk (Part 1/2)"
                    },
                    "comment": {
                        "value": "Dear Reviewer 1Jjk,\n\nThank you for appreciating our approach. We address your comments below.\n \n**Q1: the innovation of TC appears slightly limited.**\n\nA1: TC implementation reveals an important point: post-process of formal proof can significantly further improve performance, which does not get enough attention in previous work. Future work can explore how to design better post-process rules or techniques to improve the formal proof quality. And this is one important point that we want to present and prove via Tool Correction. For more details, please refer to **The difference between Tool Correction and sledgehammer+heuristic** in **Author Response to All Reviewers**.\n\n**Q2: I would love to see a comparison between Baldur and Lyra if possible.**\n \nA2: The following is our comparison between Baldur and Lyra. We have clarified this in our general response to all reviewers. Please kindly check our answer in **The difference between Lyra and other works** in **Author Response to All Reviewers**.\n\n|  Method   | Training-Free  |Information Besides Response and Error  |Reset Initial solution| Control Indicator |\n|  ----  | ----  | ----  | ----  | ----  | \n| Baldur  |&cross;  |&cross;  |&cross;  |&cross;  |\n| Lyra  | &check; |&check; |&check; |&check; |\n\nCompared to Baldur which needs a training process, the proposed Lyra is training-free. As Baldur does not release code or conduct experiments on miniF2F, currently we cannot directly compare their performance. However, we can compare Baldur, Thor [1] and Lyra to draw a conclusion between Baldur and Lyra.\n\n|  Method   | AFP-Computer Science  | AFP-Logic  | AFP-Mathematics  | AFP-Tools|  miniF2F-valid|miniF2F-test| \n|  ----  | ----  | ----  | ----  | ----  | ----  | ----  |\n| Baldur  | 50.0%  | 51.6%  | 41.9%  |53.9%  |-  |-  |\n| Thor [1]  |57.5% | 53.6% |  50.5%  |51.8%  |28.3%  |29.9%  |\n| Lyra  |- | - | -  |-  |55.3%  |51.2%  |\n\nFortunately, we can 1) first compare Baldur with Thor [1] on AFP topic classification; 2) then compare Thor with Lyra on miniF2F; 3) finally, conclude: that Lyra is significantly better than Thor, while Thor is better or comparable to Baldur. \n\n\n\n**Q3: In the tool correction part, it appears that LLMs are prompted to produce a full mechanised proof including the tactic 'by (simp add: div mult mod eq)', which is considered as LLM hallucination by the authors. Is that the case? If so, it might be a good idea to make the distinction clear as this may affect the ablation study.**\n \nA3: Yes, that is the case. And we update the following to make the distinction clear.\n\n* Page 1: \u201c As shown in the observation in Figure 1, prover fails to prove conjecture x = 19 \u2217 (x div 19) + 4 because LLM wrongly believes that by (simp add: div mult mod eq) can prove x = 19 \u2217 (x div 19) + 4\u201d \u2014>  \u201c As shown in the observation in Figure 1, prover fails to prove conjecture x = 19 \u2217 (x div 19) + 4 because by (simp add: div mult mod eq) generated by LLM cannot prove x = 19 \u2217 (x div 19) + 4 (considered as LLM hallucination)\u201d\n* Figure 1: \u201cThe prover fails because LLM wrongly believes that by (simp add: div mult mod eq) can prove x = 19\u2217(x div 19)+4\u201d \u2014> \u201cThe prover fails because by (simp add: div mult mod eq) generated by LLM cannot prove x = 19\u2217(x div 19)+4, which is considered as the hallucination.\u201d \n* Moreover, we have highlighted that this is the LLM hallucination in our paper in Page 4: \u201cFor instance, consider the statement x = 19 \u2217 (x div 19) + 4, where LLM proposes to utilize the tactic by (simp add: div mult mod eq), leading to failure. This is the LLM hallucination\u2026\u201d\n\n \n**Q4: Informal proof and the formal sketch are quite different. Elaborate a bit on the discrepancy between the informal proof and the formal one.**\n \nA4: The informal proof is a guide to formal proof, and it is not necessary that the informal proof steps and formal proof steps are one-to-one. The detailed explanation is the following.\n* Why Informal proof and the formal sketch are quite different? $Reason$: The informal proof is a guide to formal proof generation. According to the original DSP paper, the informal proof only needs to be useful for producing a sketch in the next stage.\n* Why the formal one does not cover continuity or limit? $Reason$: Actually, the formal one covers the limit. For example, the formal proof has shown that \"ultimately have \"1 < ?S\" by simp [ATPWithTC]\", which covers the limit. The limit is proved via the ATP and Tool Correction."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699953827321,
                "cdate": 1699953827321,
                "tmdate": 1699953861471,
                "mdate": 1699953861471,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JUNdds6TpC",
                "forum": "9Z0yB8rmQ2",
                "replyto": "5LxWYrbP1i",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Reviewer_1Jjk"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Reviewer_1Jjk"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the elaborate responses."
                    },
                    "comment": {
                        "value": "I sincerely thank the authors for the elaborate responses to my queries, most of which have been adequately addressed. Nevertheless, I still see the limitation of the current TC: it focuses on the 'by'-style proofs, which are essentially single-step proofs and leave little space for the LLMs to interact with the ITP. Most of those single step proofs fall within the scope of sledgehammer + heuristic tactics. Longer proofs starting with 'apply' could involve more interactions the ITP and tackle more complicate proofs beyond a single 'by'-style proof. In daily theorem proving, we often find a proof through a sequence of 'apply' steps and compress these steps into a single 'by' step in the cleanup phase; similar procedures also occur in Lean, which is termed as 'golf'. I see the authors plan to explore the 'apply'-style proofs, which could certainly be a valuable extension to the current work. For now, I will keep my score."
                    }
                },
                "number": 25,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700602611214,
                "cdate": 1700602611214,
                "tmdate": 1700602611214,
                "mdate": 1700602611214,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zvuaH0xvIu",
                "forum": "9Z0yB8rmQ2",
                "replyto": "R3jZBvFWYw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1Jjk (Part 1/2)"
                    },
                    "comment": {
                        "value": "Dear Reviewer 1Jjk,\n\nThank you very much for your reply. The following is one of the potential extensions of TC for \u2018apply'-style proofs. The difference between \"by\" and \"apply\" is in a pdf named \"The Isabelle/Isar Reference Manual\", while \"by\" is mainly introduced on Page 148 and \"apply\" is introduced on Page 167.\n\n* Recall the core idea of TC: replace potential incorrect tools/tactics with predefined correct ones. In this setting, we replace incorrect \"apply\"-style tactics with 12 predefined \"apply\"-style tactics.\n* Step 1:  Check whether we need to process the \"apply\" tactics. If we need and the previous tactic does not begin with \"apply\", then we directly change \u2018apply'-style proofs to single-step method, which is sledgehammer+11 tactics. And if succeed via sledgehammer+11 tactics, then we continue. That is, if succeed via sledgehammer+11 tactics, for the next tactic, if it still begins with \u201capply\u201d, we directly ignore it. If fails, we move to Step 2\n* Step 2: Try the given \"apply\"-style tactics. If fails, we move to Step 3.\n* Step 3: If Step 2 fails, then try sledgehammer+11 tactics. And if it succeeds, we continue. And if it fails, we try all 12 predefined \"apply\"-style tactics.\n* If Step 3 fails, then the prover fails.\n\n\n\n\nThe following is the Python-like pseudocode. \n\n```python \n#tactic_list: list of the tactics of formal proof\n#prover: Isabelle Prover \n#TCUsage: whether employ Tool Correction\ntool_heuristics=['by auto','by arith','by blast', 'by simp',\n'by fastforce', 'by force', 'by eval', 'by presburger', 'by sos',\n'by linarith', 'by (auto simp: field_simps)', 'sledgehammer']\n\n\n# can be other heuristics, such as dynamic heuristics.\napply_heuristics=['apply auto','apply arith','apply blast', 'apply simp',\n'apply fastforce', 'apply force', 'apply eval', 'apply presburger', 'apply sos',\n'apply linarith', 'apply (auto simp: field_simps)', 'apply assumption']\n\n\noutput={}\nprevious_tactics=\"None\"\nfor tactic in tactic_list:\n    use_heuristics=False\n    \n    if tactic.strip().startswith(\"done\") and output.has_key('ignore_apply'): #solve \"apply\"-style via \"by\".\n        previous_tactics=\"done\"\n        continue\n\n    # Step 1 Begin\n    if tactic.strip().startswith(\"apply\") and TCUsage:\n        if output.has_key('ignore_apply') and previous_tactics.startswith(\"apply\"): \n            # solved by previous tactics, such as single-step\n            continue\n        elif not (previous_tactics.startswith(\"apply\")) #If previous one is not \"apply\"\n            for tool_try in tool_heuristics: # try single-step\n                output = prover.run_tac(tool_try)\n                if output['error'] is None:\n                    break\n            if output['error'] is None: \n                #go to next tactic, and ignore the following \"apply\" \n                #becuase already finish the proof\n                output['ignore_apply']=True #solve the proof\n                continue\n        else:\n            #do nothing\n    # Step 1 End\n            \n\n    previous_tactics=tactic\n    \n    #Step 2 Begin        \n    output = prover.run_tac(tactic)\n    #Step 2 End\n\n    if output['error'] is not None:\n        if TCUsage: # Use Tool Correction or Not\n            if tactic.strip().startswith(\"by\") or tactic.strip()==(\".\"):\n                use_heuristic=True\n    \n        if (\"sledgehammer\" in tactic) or use_heuristic:\n            for tool_try in tool_heuristics:\n                output = prover.run_tac(tool_try)\n                if output['error'] is None:\n                    output['ignore_apply']=True\n                    break\n                    \n                    \n        # Step 3 Begin\n        if TCUsage and tactic.strip().startswith(\"apply\"):\n            for tool_try in tool_heuristics:\n                output = prover.run_tac(tool_try)\n                if output['error'] is None:\n                    output['ignore_apply']=True #solve the proof\n                    break\n            \n            if output['error'] is not None:\n                for apply_try in apply_heuristics:\n                    output = prover.run_tac(apply_try)\n                    if output['error'] is None: \n                        # if not use by-style tactic, \n                        # not sure whether the whole proof is solved or not here. \n                        # So that NO output['ignore_apply']=True\n                        break\n        # Step 3 End\n                    \n        \n    if output['error'] is not None:\n        return \"tactic_failed\", output\n    if output['tactic_state'] == 'no goals':\n        return \"success\", output\n        \nreturn \"proof_incomplete\", output\n```"
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700630002444,
                "cdate": 1700630002444,
                "tmdate": 1700709962789,
                "mdate": 1700709962789,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "T6PZOmUc4F",
                "forum": "9Z0yB8rmQ2",
                "replyto": "R3jZBvFWYw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1Jjk (Part 2/2)"
                    },
                    "comment": {
                        "value": "Another direction could be dynamic heuristics. For example, though the given tactic is incorrect (such as the \"by (simp add: div_ mult_mod_eq) in Figure 1), there is still some useful information (such as something like div_mult_mod_eq). We may design corresponding methods to utilize the information. For example, search the lemma that is similar to div_mult_mod_eq and replace it. Therefore, another direction of TC extension could be dynamic tactic creation. \n\nIf you think our comment and update address your concerns, could you please consider raising your rating of the paper? Thank you!"
                    }
                },
                "number": 28,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700646266512,
                "cdate": 1700646266512,
                "tmdate": 1700655719438,
                "mdate": 1700655719438,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xmOGKkvJf9",
                "forum": "9Z0yB8rmQ2",
                "replyto": "T6PZOmUc4F",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Reviewer_1Jjk"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Reviewer_1Jjk"
                ],
                "content": {
                    "comment": {
                        "value": "I believe the dynamic tactic creation would be a more appealing direction of TC in the future. Note that there has been a static/pre-defined tactic exploration framework in Isabelle [1].\n\n[1] Nagashima, Yutaka, and Ramana Kumar. \"A proof strategy language and proof script generation for Isabelle/HOL.\" Automated Deduction\u2013CADE 26: 26th International Conference on Automated Deduction, Gothenburg, Sweden, August 6\u201311, 2017, Proceedings. Springer International Publishing, 2017."
                    }
                },
                "number": 32,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700736069754,
                "cdate": 1700736069754,
                "tmdate": 1700736069754,
                "mdate": 1700736069754,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "AwfBTIhIrF",
            "forum": "9Z0yB8rmQ2",
            "replyto": "9Z0yB8rmQ2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1096/Reviewer_Wc5t"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1096/Reviewer_Wc5t"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes two methods for postprocessing and fixing the errors in the proof steps generated by LLM for theorem proving. The first method is Tool Correction, which tries a list of automation tactic such as sledgehammer, auto and arith on the fails steps. The second method is Conjecture Correction, which asks LLM to regenerate the proof step based on the error message or simply regenerate this step to start a new iteration. Experiments show that TC and CC could improve the performance significantly on the miniF2F valid (50.4%->55.3%) and test set( 42.6%->51.2%), and achieves the new state-of-the-art results."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Both Tool Correction and Conjecture Correction are technically sound. Tool Correction implies the insights that LLM is better at generating the next conjecture to prove than closing the conjecture. Extensive search is helpful to close the conjecture."
                },
                "weaknesses": {
                    "value": "The paper doesn't have much novelty in terms of the approach. It seems that the set of 11 tactics in TC have been proposed in DSP. The method of appending error message for self-debugging and generating multiple candidates have been commonly used for code generation."
                },
                "questions": {
                    "value": "1 I think one good baseline would be replace Minerva and Codex in DSP with GPT4. So we still have GPT4 to generate the proof sketch (the intermediate conjectures) but use 11 tactics + sledgehammer to close the open goals. \n2 Could you calculate the number of wrong proof steps fixed by each tactic in TC?\n3 The proposed method adds a lot more computation. How much time would be token by calling GPT4, TC and CC? If we set a time limit for each question like 10 or 30 minutes, what would be the performance of TC/CC compared with the GPT4 baseline and DSP+GPT4 baseline?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No ethics concern."
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1096/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699046111527,
            "cdate": 1699046111527,
            "tmdate": 1699636035812,
            "mdate": 1699636035812,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vi9NpLw1GD",
                "forum": "9Z0yB8rmQ2",
                "replyto": "AwfBTIhIrF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Wc5t (Part 1/2)"
                    },
                    "comment": {
                        "value": "Dear Reviewer Wc5t,\n \nThank you for the detailed review. We will address your concerns below.\n\n**Q1: novelty in terms of the approach.**\n\nA1: For Tool Correction, it provides this insight: post-process of formal proof can significantly further improve performance. Please refer to the **The difference between Tool Correction and sledgehammer+heuristic** in **Author Response to All Reviewers**. \n\nAnd, we also show the **The difference between Lyra and other works** in **Author Response to All Reviewers** to present the innovation of Conjecture Correction.\n\n \n**Q2: I think one good baseline would be replace Minerva and Codex in DSP with GPT4. So we still have GPT4 to generate the proof sketch (the intermediate conjectures) but use 11 tactics + sledgehammer to close the open goals.**\n \nA2: We have shown the result in Table 2 in our paper. Our proposed Lyra degrades to DSP if removes both Tool Correction and Conjecture Correction. That is, $DSP+Tool Correction + Conjecture Correction = Lyra$, while the original DSP has sledgehammer + 11 tactics  implementation (only works when the given tactic is \"sledgehammer\"), achieving 50.4% on miniF2F-valid and 42.6% on miniF2F-test. \n\n|  Method   | Model |TC  | CC  | miniF2F-valid|miniF2F-test|\n|  ----  | ----  | ----  | ----  | ----  | ----  |\n| DSP  | GPT-4|&cross; |&cross; |50.4% |42.6% |\n| DSP+TC  | GPT-4|&check; |&cross; |52.8% |45.9% |\n| DSP+CC  | GPT-4|&cross; |&check; |46.7% | 43.0% |\n| DSP+TC+CC (Lyra)  | GPT-4|&check; |&check; |55.3% |51.2% |\n \n \n**Q3: Could you calculate the number of wrong proof steps fixed by each tactic in TC?**\n \nA3: The following is the number of wrong proof steps fixed by each tactic in TC.\n* Proof comes from: the miniF2F validation set (pass rate 55.3%) and test set result (pass rate 51.2%), with GPT-4, human informal proof, Conjecture Correction and Tool Correction. \n* The definition of proof step: a proof step is regarded as a tactic.\n* Calculation protocol: if sledgehammer+heuristic or Tool Correction fails to validate the current tactic, then the current proving process will be terminated and we will turn to the next formal proof validation. Finally, we calculate how many correct tactics/proof steps.\n\n|  Dataset | Sledgehammer+heuristics   | Tool Correction  | Number of Fixed Steps|\n|  ---- |  ----  | ----  | ----  |\n| miniF2F-valid  |2260  | 3486 |1226 |\n| miniF2F-test  |2594  | 3887 |1293 |\n\nOn miniF2F-valid, sledgehammer+heuristics can help the prover successfully pass 2260 steps. After adding Tool Correction, the number increases to 3486 steps. Therefore, Tool Correction fixes 1226 wrong steps. On miniF2F-test, Tool Correction fixes 1293 wrong steps\n \n \n**Q4: The proposed method adds a lot more computation. How much time would be token by calling GPT4, TC and CC?**\n \nA4: There may be a slight misunderstanding here. Our method running time is similar to DSP.\n\nBoth tool Correction and Conjecture Correction do not add a lot more computing time.  The upper bound of Tool Correction time cost is 120+11*10=230 seconds for each tactic (same as the sledgehammer+heuristics in DSP), and formal proof generation (Calling GPT-4 and CC)  time varies from 10 seconds to 2 minutes. On average, Lyra takes about 2 minutes per attempt, including the time cost of TC, and GPT4+CC.\n\nFor the Tool Correction, it only works when the current tactics fail and begin with \"by\" or \".\" or \u201csledgehammer\u201d. And it has the same timeout upper bound as DSP's sledgehammer+hsuristics. For sledgehammer, the timeout is 120 seconds. For every of the other 11 tactics, the timeout is 10 seconds. Hence, the upper bound of Tool Correction is 120+11*10=230 seconds. Usually, the prover validation with TC can be finished in 1 minute.\n\nFor the GPT-4+Conjecture Correction, it also does not add additional computing time. The proposed Lyra or DSP employs the aggressive model (Codex or GPT-4) to generate a formal proof. Hence, the time cost mainly depends on the length of the generated formal proof, which depends on different problems but not the Conjecture Correction. Depending on the difference of the problem, the formal proof generation is different for one attempt.\n* If the formal proof is short (such as an easy proof), formal proof generation only needs less than 10 seconds. For example, the correct formal proof is only \"by sos\".\n* If the formal proof is long (such as a difficult proof), formal proof generation needs several minutes. We have shown a long IMO formal proof example in Figure 3.\n\nTherefore, both Tool Correction and Conjecture Correction do not add a lot more computing time. The Lyra has the same time complexity as DSP."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699953770006,
                "cdate": 1699953770006,
                "tmdate": 1700733448245,
                "mdate": 1700733448245,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "AcjCsRxXkB",
                "forum": "9Z0yB8rmQ2",
                "replyto": "AwfBTIhIrF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Wc5t (Part 2/2)"
                    },
                    "comment": {
                        "value": "**Q5: If we set a time limit for each question like 10 or 30 minutes, what would be the performance of TC/CC compared with the GPT4 baseline and DSP+GPT4 baseline**\n \nA5: The result depends on whether it allows the parallel process. \n\n**As there is no GPT4 baseline (for DSP paper, they also do not have experiment results of Codex/Minerva baseline, but have DSP+Codex and DSP+Minerva)**, we list the performance of Lyra and DSP+GPT4 in the following.\n\nIf allows the parallel process, then we can keep the performance (55.3% on validation and 51.2% on test), if the time limit is larger or equal to 10 minutes. For the relationship between time limit and performance, we can refer to Figure 2 on Page 8, which presents the relationship between the number of attempts and the performance. One attempt takes 2 minutes, if not allow the parallel process.\n\nThe following is the performance under different time limits for each question, for DSP(GPT-4) and Lyra.\n\nParallel Process|  Time Limit   | Method  | Time Cost  | miniF2F-valid  | miniF2F-test| \n|  ----  | ----  | ----  | ----  | ----  |----  |\n&cross;| 10 mins  | DSP(GPT4)  | 10 mins  | 32.7%  |25.4%  |\n&cross;| 10 mins  | Lyra  | 10 mins  | 33.6%  |28.6%  |\n&cross;| 30 mins  | DSP(GPT4)   | 30 mins  | 40.1%  |31.5%  |\n&cross;| 30 mins  | Lyra  | 30 mins  | 40.1%  |36.0%  |\n&cross;| 400 mins  | DSP(GPT4)   | 400 mins  | 50.4%  |42.6%  |\n&cross;| 400 mins  | Lyra  | 400 mins |  55.3%  |51.2%  |\n&cross;| 600 mins  | DSP(GPT4)   | 400 mins  | 50.4%  |42.6%  |\n&cross;| 600 mins  | Lyra  | 400 mins |  55.3%  |51.2%  |\n&check;| 10 mins  | DSP(GPT4)   | 2 mins |  50.4%  |42.6%  |\n&check;| 10 mins  |Lyra | 10 mins |  55.3%  |51.2%  |\n&check;| 30 mins  | DSP(GPT4)   | 2 mins |  50.4%  |42.6%  |\n&check;| 30 mins  |Lyra | 10 mins |  55.3%  |51.2%  |\n\nUsually, it takes about 1\uff5e2 minutes to finish one attempt (we take 2 min/attempt here), where each problem is allowed to try 200 attempts(a total of 400 minutes), in our setting. For DSP, the 200 attempts can be processed in parallel. Hence, if allowing the parallel process, the maximum time cost is 2 minutes. For Lyra, these 200 attempts are divided into 40 patches, where each patch contains five attempts. The 40 patches can be processed in parallel.  Hence, if allowing the parallel process, the maximum time cost is 10 minutes. If not allowing the parallel process, when the time limit is 10 mins, Lyra achieves 33.6% miniF2F-validation and 28.6% miniF2F-test. And if not allow the parallel process, when the time limit is 30 mins, Lyra achieves 40.1% miniF2F-validation and 36.0% miniF2F-test. \n\nIf you think our comment and update address your concerns, could you please consider raising your rating of the paper? Thank you!"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699953796906,
                "cdate": 1699953796906,
                "tmdate": 1700733915726,
                "mdate": 1700733915726,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7EcNA5cInj",
                "forum": "9Z0yB8rmQ2",
                "replyto": "AwfBTIhIrF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1096/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Integrate Tool Correction with \"apply\"-style tactic"
                    },
                    "comment": {
                        "value": "Dear Reviewer Wc5t,\n\nThe proposed **Tool Correction can also be integrated with other Isabelle tactics besides \"by\"-style tactic** (single-step method), **while previous work (such as sledgehammer+heuristics in DSP) can not** (only work when the given tactic is \"sledgehammer\"). In the following, we present the code that integrated TC with the \"apply\"-style tactic, which can make the TC more powerful.\n\n* Recall the core idea of TC: replace potential incorrect tools/tactics with predefined correct ones. In this setting, we replace incorrect \"apply\"-style tactics with 12 predefined \"apply\"-style tactics.\n* Step 1:  Check whether we need to process the \"apply\" tactics. If we need and the previous tactic does not begin with \"apply\", then we directly change \u2018apply'-style proofs to single-step method, which is sledgehammer+11 tactics. And if succeed via sledgehammer+11 tactics, then we continue. That is, if succeed via sledgehammer+11 tactics, for the next tactic, if it still begins with \u201capply\u201d, we directly ignore it. If fails, we move to Step 2\n* Step 2: Try the given \"apply\"-style tactics. If fails, we move to Step 3.\n* Step 3: If Step 2 fails, then try sledgehammer+11 tactics. And if it succeeds, we continue. And if it fails, we try all 12 predefined \"apply\"-style tactics.\n* If Step 3 fails, then the prover fails.\n\n\n\n\nThe following is the Python-like pseudocode. \n\n```python \n#tactic_list: list of the tactics of formal proof\n#prover: Isabelle Prover \n#TCUsage: whether employ Tool Correction\ntool_heuristics=['by auto','by arith','by blast', 'by simp',\n'by fastforce', 'by force', 'by eval', 'by presburger', 'by sos',\n'by linarith', 'by (auto simp: field_simps)', 'sledgehammer']\n\n\n# can be other heuristics.\napply_heuristics=['apply auto','apply arith','apply blast', 'apply simp',\n'apply fastforce', 'apply force', 'apply eval', 'apply presburger', 'apply sos',\n'apply linarith', 'apply (auto simp: field_simps)', 'apply assumption']\n\n\noutput={}\nprevious_tactics=\"None\"\nfor tactic in tactic_list:\n    use_heuristics=False\n    \n    if tactic.strip().startswith(\"done\") and output.has_key('ignore_apply'): #solve \"apply\"-style via \"by\".\n        previous_tactics=\"done\"\n        continue\n\n    # Step 1 Begin\n    if tactic.strip().startswith(\"apply\") and TCUsage:\n        if output.has_key('ignore_apply') and previous_tactics.startswith(\"apply\"): \n            # solved by previous tactics, such as single-step\n            continue\n        elif not (previous_tactics.startswith(\"apply\")) #If previous one is not \"apply\"\n            for tool_try in tool_heuristics: # try single-step\n                output = prover.run_tac(tool_try)\n                if output['error'] is None:\n                    break\n            if output['error'] is None: \n                #go to next tactic, and ignore the following \"apply\" \n                #becuase already finish the proof\n                output['ignore_apply']=True #solve the proof\n                continue\n        else:\n            #do nothing\n    # Step 1 End\n            \n\n    previous_tactics=tactic\n    \n    #Step 2 Begin        \n    output = prover.run_tac(tactic)\n    #Step 2 End\n\n    if output['error'] is not None:\n        if TCUsage: # Use Tool Correction or Not\n            if tactic.strip().startswith(\"by\") or tactic.strip()==(\".\"):\n                use_heuristic=True\n    \n        if (\"sledgehammer\" in tactic) or use_heuristic:\n            for tool_try in tool_heuristics:\n                output = prover.run_tac(tool_try)\n                if output['error'] is None:\n                    output['ignore_apply']=True\n                    break\n                    \n                    \n        # Step 3 Begin\n        if TCUsage and tactic.strip().startswith(\"apply\"):\n            for tool_try in tool_heuristics:\n                output = prover.run_tac(tool_try)\n                if output['error'] is None:\n                    output['ignore_apply']=True #solve the proof\n                    break\n            \n            if output['error'] is not None:\n                for apply_try in apply_heuristics:\n                    output = prover.run_tac(apply_try)\n                    if output['error'] is None: \n                        # if not use by-style tactic, \n                        # not sure whether the whole proof is solved or not here. \n                        # So that NO output['ignore_apply']=True\n                        break\n        # Step 3 End\n                    \n        \n    if output['error'] is not None:\n        return \"tactic_failed\", output\n    if output['tactic_state'] == 'no goals':\n        return \"success\", output\n        \nreturn \"proof_incomplete\", output\n```\n\nIf you think our comment and update address your concerns, could you please consider raising your rating of the paper? Thank you!"
                    }
                },
                "number": 29,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1096/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700709931453,
                "cdate": 1700709931453,
                "tmdate": 1700732010417,
                "mdate": 1700732010417,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]