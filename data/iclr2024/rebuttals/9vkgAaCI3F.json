[
    {
        "title": "Balancing Stability and Plasticity in Continual Learning: the readout-decomposition of activation change (RDAC) framework"
    },
    {
        "review": {
            "id": "ReCcc3XJcD",
            "forum": "9vkgAaCI3F",
            "replyto": "9vkgAaCI3F",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7950/Reviewer_djfe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7950/Reviewer_djfe"
            ],
            "content": {
                "summary": {
                    "value": "This paper considered balancing the learning forgetting trade-off in continual learning. Specifically, this paper considered the changement of representation \\delat_h into two parts, the range of readout and Null space of readout space (maintains stability).  Then this paper derived a gradient decomposition algorithm to explicitly control the learning-forgetting trade-off. Empirical results demonstrated improved trade-off.\n\n-----Post-rebuttal update\nI would appreciate authors' efforts, which addressed my concerns. I would maintain my current evaluation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "**Disclaimer: I did not work on continual learning and thus I could not evaluate the novelty/significance parts of this paper.**  Below is my evaluation from a general view.\n\nI would think this paper presents a clear and interesting analysis in the learning/forgetting trade-off in continual learning, which seems quite important in continual learning. I would agree with the authors with their analysis on the representation decomposition (Fig 1). \n\nThe experimental parts clearly demonstrated the benefits of such an analysis by a better trade-off."
                },
                "weaknesses": {
                    "value": "I would think the clarity part in gradient decomposition could be better elaborated. I would think a clear algorithm should be presented to show how to explicitly control the learning/forgetting trade-off."
                },
                "questions": {
                    "value": "See the weakness parts."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7950/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7950/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7950/Reviewer_djfe"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7950/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698425962117,
            "cdate": 1698425962117,
            "tmdate": 1700750332473,
            "mdate": 1700750332473,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KIg9OBeDuz",
                "forum": "9vkgAaCI3F",
                "replyto": "ReCcc3XJcD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7950/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7950/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nThank you for your comments. Please check the comment - https://openreview.net/forum?id=9vkgAaCI3F&noteId=rcFk2d3LLJ - for a summary of the changes to the paper.\n\nWe have taken your suggestion into account and reworded that section, Section 5, to make it clear what parts refer to the gradient decomposition algorithm and what refers to the causal analysis between the stability-plasticity trade-off and the activation changes in the readout range and null space.\n\nWe hope that our responses and revisions have clarified our contributions and we want to thank you for your helpful insights.\n\nThank you, The Authors"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700490672634,
                "cdate": 1700490672634,
                "tmdate": 1700490672634,
                "mdate": 1700490672634,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "E3RsAENEtY",
            "forum": "9vkgAaCI3F",
            "replyto": "9vkgAaCI3F",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7950/Reviewer_gbcF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7950/Reviewer_gbcF"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces the Readout-Decomposition of Activation Change (RDAC) framework, which aims to address the stability-plasticity trade-off in continual learning (CL) algorithms. This trade-off is a significant challenge in preserving prior information while acquiring new knowledge. The RDAC framework dissects this trade-off by linking learning-induced activation changes to stability and plasticity, thereby offering insights into CL algorithms.\n\nMoreover, This paper presents a gradient decomposition algorithm for one-hidden-layer linear neural networks. This algorithm restricts activation changes within the range of prior readouts, maintaining stability without significant loss of plasticity.\n\nThe RDAC framework sheds light on the connection between learning-induced activation changes and the stability-plasticity trade-off, providing insights into representational drift in biological systems. The results show that GEM and data replay preserved stability and plasticity, while SI, EWC, and LwF traded off plasticity for stability."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The Readout-Decomposition of Activation Change (RDAC) framework addresses the stability-plasticity dilemma and its relation to catastrophic forgetting, and relates learning-induced activation changes to the degree of stability and plasticity. The paper contributes to ongoing efforts in understanding and solving the complexities of continual learning.\n\n\nThe paper also presents a gradient decomposition algorithm for one-hidden-layer linear neural networks to maintain high stability without sacrificing plasticity. Overall, the RDAC framework provides valuable insights into CL algorithms and offers potential for novel CL approaches."
                },
                "weaknesses": {
                    "value": "Theoretical analyses on one-hidden-layer linear neural networks are not scalable or too instructive.\n\nThis paper lacks empirical results, comparisons, and practical implications, which could limit its applicability in real-world scenarios.\n\nThe paper focuses primarily on evaluating existing CL algorithms and does not propose any new algorithms or techniques.\n\nLack of code and hyper-parameter configuration."
                },
                "questions": {
                    "value": "Have you considered evaluating the RDAC framework on other CL datasets or tasks? It would be interesting to see how the framework performs in different settings and if the results hold across a broader range of scenarios.\n\nIt would be helpful to have more empirical results and comparisons with other frameworks or approaches to validate the effectiveness of the RDAC framework. Are there any plans to conduct such experiments in the future?\n\nHow generalizable is the gradient decomposition algorithm for linear neural networks? Can it be extended to more complex network architectures, such as deep neural networks, and still maintain stability without sacrificing plasticity?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7950/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698589192124,
            "cdate": 1698589192124,
            "tmdate": 1699636976867,
            "mdate": 1699636976867,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1IWdc32M6a",
                "forum": "9vkgAaCI3F",
                "replyto": "E3RsAENEtY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7950/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7950/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nThe paper has substantially improved due to your insights - thank you. Please check the comment - https://openreview.net/forum?id=9vkgAaCI3F&noteId=rcFk2d3LLJ - for a summary of the changes to the paper. Here we will address your comments.\n\nRe: Weakness, Point 1 (+ Questions, Q3):\nAnalysis of the one-hidden layer neural network provides us with a causal link between the stability-plasticity trade-off and the activation changes in the readout range and null space. This is hard to do in deep non-linear networks as such a causal link is hard to derive analytically as shown in Appendix A.3. However, the approach shown in the linear case i.e. decomposition of Eq. 1 might provide a good starting point for subsequent attempts in deriving solutions.\n\nRe: Weakness, Point 2 (+ Questions, Q1):\nIn Appendix A.2. we now show that our insights generalize to a larger network (ResNet) and dataset (TinyImagenet), making our conclusions more generally applicable.\n\nRe: Weakness, Point 3:\nAs stressed in the revised Introduction, the goal of this paper is to present a new framework for analyzing continual learning algorithms, borne out of recent results mentioned in the Introduction. The gradient decomposition algorithm was primarily derived to verify the causal link between the stability-plasticity trade-off and the activation changes in the readout range and null space. Deriving such algorithms analytically for deep non-linear networks proves to be challenging (see Appendix A.3)\n\nRe: Weakness, Point 4:\nCode is now included as a .zip file. The most relevant hyperparameter settings are mentioned in the Appendix. \n\nRe: Questions, Q2:\nThis suggestion dovetails with the suggestion made by Reviewer RvDh (Questions, Q5). In general, we agree that links between RDAC and other frameworks such PCA, information theory, information bottleneck theory, and rate-distortion theory would be interesting to explore in future research, as this lies beyond the scope of the current study.\n\nWe hope that our responses and revisions have clarified our contributions and we want to thank you for your helpful insights.\n\nThank you, The Authors"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700490517490,
                "cdate": 1700490517490,
                "tmdate": 1700490517490,
                "mdate": 1700490517490,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Iyp27pm0Zg",
            "forum": "9vkgAaCI3F",
            "replyto": "9vkgAaCI3F",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7950/Reviewer_RvDh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7950/Reviewer_RvDh"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces the Readout-Decomposition of Activation Change (RDAC) framework to analyze the stability-plasticity tradeoff in continual learning algorithms. Readout layer is similar to the final linear probing layers in continual-learning/SSL scenarios. They perform SVD decomposition to get the range and null spaces. The main idea is that the range lets us observe stability, the more changes in that range, the less stability we have. On the other hand, changes in the null space allow plasticity for learning new tasks. Regularization methods restrict changes in both the range and null space, sacrificing plasticity for stability. In contrast, replay methods allow changes in the null space, maintaining plasticity. \nSurprisingly, it may seem like replay-based methods should exhibit substantial catastrophic forgetting, since they allow significant changes to activations in the range of prior readouts. However, the paper shows this is not the case - these methods can maintain strong stability and plasticity. Finally, for a simple linear network, they derive a gradient decomposition algorithm that projects weight updates into the null space to maximize stability without reducing plasticity."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- It presents a novel perspective on analyzing continual learning through the lens of readout weights and their null spaces. This provides a new tool for disentangling stability vs plasticity.\n\n- The gradient decomposition algorithm demonstrates a concrete application of the concepts that maintains stability and plasticity. I believe this gradient update method to be the biggest potential contribution of this paper. \n\n- The paper is clearly written and does a good job explaining and visualizing the key ideas."
                },
                "weaknesses": {
                    "value": "Authors acknowledged some of these limitations. \n\n- So the explanatory power of the framework for nonlinear networks is unclear. The analysis relies on precisely computing the readout null space, which may be difficult in nonlinear models where the spaces are less well-defined. It's also unclear if the insights will fully translate when there are multiple nonlinear layers. The analysis of activation changes is quite limited for the nonlinear network experiments. They only approximate the null spaces for complicated models, analyze a single layer rather than the whole network, and observe overall trends without an in-depth study like was done for the linear case.\n\n- The continual learning scenarios are relatively simple (Split CIFAR and MNIST). Needs more exploration on complicated dataset benchmarks and continual learning scenarios.\n\n- No comparison against latest SOTA."
                },
                "questions": {
                    "value": "If the authors are able to answer most of the questions and are able to further develop their algorithms as requested, this paper could significantly improve. This paper could have potential. The questions are very closely related to the weakness. \n\n- 1. You mention that your work is related to representational drift in biological networks. More details on the biological connections and plausibility of the concepts will be helpful.\n\n- 2. Do you have ideas for extending gradient decomposition algorithms to deep nonlinear networks?\n\n- 3. You propose the readout null space allows plasticity for new tasks. But how can you formally quantify or guarantee the capacity for plasticity? (Aka I want to see more maths justifying that the null space gives us plasticity. Information theory perspectives or more experimental results might help).\n\n- 4. Any performance guarantees of your proposed optimization algorithm?\n\n- 5. Please comment on any links to PCA, information theory, information bottle neck theory, rate-distortion theory etc. Some helpful pointers:\n\n  - a. PCA\n\n    - i. PCA finds the principal components that capture the directions of maximum variance in a dataset. The readout range identified in this paper spans the subspace aligned with the readout weights. So both are identifying meaningful linear subspaces in high-dimensional data.\n\n    - ii. The readout null space identified is analogous to the null space in PCA - directions that have no variance or are unimportant for the purposes of reconstruction/readout.\n\n  - b. Rate-distortion theory:\n\n    - i. Replay methods allow greater changes in the null space (less compression), maintaining plasticity. Regularization methods over-compress, losing plasticity."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7950/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698786373966,
            "cdate": 1698786373966,
            "tmdate": 1699636976709,
            "mdate": 1699636976709,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TRytVFbQok",
                "forum": "9vkgAaCI3F",
                "replyto": "Iyp27pm0Zg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7950/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7950/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nThe paper has substantially improved due to your insights - thank you. Please check the comment - https://openreview.net/forum?id=9vkgAaCI3F&noteId=rcFk2d3LLJ - for a summary of the changes to the paper. Here we will address your comments.\n\nRe: Weakness, Point 1:\nRe: the point about \"analyze a single layer rather than the whole network\", the RDAC framework was built around the observation that readout misalignment constitutes a major problem in continual learning. This implies that we can get a lot of insights by just looking at the readout layer. As shown in our experiments, this turns out to be quite informative (Figures 2 & 3). \nRe: the point about \"observe overall trends without an in-depth study like was done for the linear case\", as we mentioned in Section 5 and Appendix A.3, it is hard to analytically derive a solution to an analog of Eq. 1 (Eq. 2 for a 3-hidden layer network) in deep non-linear networks. Moreover, the framework serves as a diagnostic tool for continual learning algorithms and the hope is that the analysis shown in Figure. 2 and outlined in Section 3 can be used generally (it works for a larger dataset and architecture as shown in Appendix A.2).\n\nRe: Weakness, Point 2:\nWe now include results on continual learning on TinyImagenet with a slim ResNet that qualitatively shows the same results as in Figure. 2, solidifying the generality of our framework.\n\nRe: Weakness, Point 3:\nOur aim was to analyze continual learning algorithms from the two major classes - regularization and rehearsal, to assess our framework. All the algorithms considered are still competitive benchmarks in the field. Future work, especially when it comes to designing algorithms based on this framework, will indeed account for the SOTA algorithms.\n\nRe: Questions, Point 1:\nWe are excited about the connections of this work to representational drift, however, given the page limitations, expanding on that relationship is outside the scope of this study.\n\nRe: Questions, Point 2:\nWe have outlined our intuitions on extending that algorithm to deep networks in Appendix A.3. Currently, it poses a significant challenge but we hope our intuition paves the way.\n\nRe: Questions, Point 3:\nIn the linear network case presented in Section 5, we show how we are guaranteed to maintain stability by projecting the gradient into the null space of the prior readout. Although we do not state formal guarantees for plasticity, what we can say is if the range of the readout spans a subspace - which it usually does as in task-incremental learning there are more neurons in the representational layer than readout classes - the null space is substantial and can be utilized by another task, fostering plasticity. \n\nRe: Questions, Point 4:\nThe gradient decomposition algorithm guarantees stability as shown in Section 5, as a projection into the null space of the prior readout ensures that the already-learned mappings do not change (Eq. 1).\n\nRe: Questions, Point 5:\nRe: PCA - indeed, the PCs capture variance in the dataset. However, as mentioned in Section 2, the representations most probably span a larger space than the readout range. \nIn general, we agree that links between RDAC and PCA, information theory, information bottleneck theory, and rate-distortion theory would be interesting to explore in future research as this lies beyond the scope of the current study.\n\nWe hope that our responses and revisions have clarified our contributions and we want to thank you for your helpful insights.\n\nThank you, The Authors"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700489497966,
                "cdate": 1700489497966,
                "tmdate": 1700489497966,
                "mdate": 1700489497966,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3zAkYKeIr2",
                "forum": "9vkgAaCI3F",
                "replyto": "TRytVFbQok",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7950/Reviewer_RvDh"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7950/Reviewer_RvDh"
                ],
                "content": {
                    "comment": {
                        "value": "I have read the response, and also the other reviews.\n\nI thank the Authors for the effort. The answers are helpful, and also the improvement are useful. On the other hand, I feel that the major weaknesses remain and I will confirm my rating."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700615128131,
                "cdate": 1700615128131,
                "tmdate": 1700615128131,
                "mdate": 1700615128131,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "BWC0wDwKTe",
            "forum": "9vkgAaCI3F",
            "replyto": "9vkgAaCI3F",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7950/Reviewer_a3Rp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7950/Reviewer_a3Rp"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces the Readout-Decomposition of Activation Change (RDAC) framework to analyse plasticity and stability in networks performing continual learning. The framework projects the change in network activations upto the readout layer, onto the range and null space of the readout weights. The paper then hypothesizes that changes in the range-space projection between tasks represent changes in stability while changes in the null-space represent learning without changes in stability."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is clearly written for the most part, and fairly easy to follow.\n2. The RDAC framework is a neat idea to examine changes in the network weights / activations, and to analyse the stability-plasticity tradeoff during learning. The framework is simple enough that it can be applied to a variety of network architectures and tasks easily."
                },
                "weaknesses": {
                    "value": "1. To the best of my understanding, the RDAC framework _interprets_ projections onto the null and range spaces and any changes thereof as representing stability and plasticity in the networks. This seems to be a logical leap that is not verified -- the experiments in section 4 and 5 simply analyse the changes of gradient projections for different networks in these spaces. While I find the connection between the various network hyperparameters and the changes in these spaces interesting, it is not clear whether they truly represent a stability / plasticity tradeoff without experiments also showing how changes in these subspaces are correlated with performance on the continual learning tasks.\n\n2. The linear approximation in the RDAC framework is useful and makes it easy to analyse / apply to a variety of networks. However, given that it is non-trivial to derive a similar framework for non-linear activations or readouts, it is difficult to see how insights from the current linear framework can be extrapolated to the nonlinear setting. While the paper presents results on nonlinear networks in section 4, it is not clear whether these insights will extrapolate to other nonlinear networks. \n\nFurthermore, there are no experiments showing how tuning the regularisation strength for SI, EWC and LwF, or memory strength / replay-buffer size for GEM to achieve a particular balance of stability and plasticity affects network performance in these tasks. This also makes it hard to judge whether the insights derived from the RDAC framework on nonlinear tasks really hold, can be extrapolated to other networks / methods and whether they are useful in developing methods for continual learning.\n\n3. Related to point 2, while it is non-trivial to derive results for nonlinear projections, it would be good to have at least some intuition on how incorrect / applicable insights from a linear approximation would be to nonlinear networks, and whether any future endeavour to derive results for nonlinear networks could correct them."
                },
                "questions": {
                    "value": "1. Do the changes in the range / null space truly correlate with plasticity / stability in training the networks?\n\n2. How do we interpret insights from a linear approximation of gradient projections from a nonlinear network?\n\n3. How bad are these linear approximations, and how can we correct them?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7950/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698996029831,
            "cdate": 1698996029831,
            "tmdate": 1699636976581,
            "mdate": 1699636976581,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "M6dQiluY24",
                "forum": "9vkgAaCI3F",
                "replyto": "BWC0wDwKTe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7950/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7950/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nThe paper has substantially improved due to your insights - thank you. Please check the comment - https://openreview.net/forum?id=9vkgAaCI3F&noteId=rcFk2d3LLJ - for a summary of the changes to the paper. Here we will address your comments.\n\nRe: Weakness, Point 1 (+ Questions, Q1):\nIn the updated paper, as described in Section 3, the predicted correlations between the stability-plasticity trade-off and the activation changes in the readout range and null space are complex. We laid out the different scenarios (Cases). In the results, Section 4.2., we link the behavior of various continual learning algorithms to those Cases, thereby establishing the predicted correlations. Indeed, this does not establish a causal link. However, in Section 5, we analytically derive such a causal link for a one-hidden layer linear network, which provides support to our account. Such a causal link is hard to establish for deep non-linear networks as we do not yet have a method for disentangling the projections of the readout range and null space in the upstream layers of the network, as mentioned in Section 5. In sum, we outlined a framework based on previous findings mentioned in the introduction and took the first steps in ascertaining its causal validity.\n\nRe: Weakness, Point 2:\nIndeed deriving an analytical solution for deep networks is hard, as now shown in Appendix A.3. However, the idea that the range is related to stability and that the null space is related to plasticity comes from considerations of activation changes at the readout, as explained in Section 3. Although we do not have an analytical solution for the deep non-linear case, we think that our intuitions are valuable in characterizing the link between the stability-plasticity trade-off and the activation changes in the readout range and null space\n\nRe: Weakness, point \"Furthermore, there are no experiments showing how tuning the regularisation strength ...\":\nFigure 2 shows the relationship between the regularization strength of each algorithm and its influence on the stability-plasticity trade-off and the readout-decomposed activation changes. To show that these results are generalizable, in Appendix A.2, we show that the same pattern holds for a larger dataset (TinyImagenet) and network (slim ResNet), giving us confidence that the framework is indeed generalizable.\n\nRe: Weakness, Point 3:\nin Appendix A.3, we now provide intuitions on the complexity of analytically deriving continual learning solutions for deep networks.\n\nRe: Questions, Q2 (+ Q3):\nNone of our experiments engage in a linear approximation of gradient projections from a nonlinear network. In the linear network, we do project the gradients during learning. However, that projection is derived from the actual projection our framework wants which is related to the activations, see: Eq. 1. In the non-linear case, solving Eq. 1 does not involve simply projecting the gradients. As mentioned at the end of Section 5, \"The non-linear case is analytically more complex to analyze, as the simple decomposition of the task mapping into the old mapping and the change in that mapping, as seen in Eq. 1, is not possible.\"\n\nWe hope that our responses and revisions have clarified our contributions and we want to thank you for your helpful insights.\n\nThank you, The Authors"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7950/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700487921342,
                "cdate": 1700487921342,
                "tmdate": 1700487921342,
                "mdate": 1700487921342,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]