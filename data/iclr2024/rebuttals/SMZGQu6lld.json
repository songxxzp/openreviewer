[
    {
        "title": "LLM-Prop: Predicting Physical And Electronic Properties of Crystalline Solids From Their Text Descriptions"
    },
    {
        "review": {
            "id": "VCb3hWdE4H",
            "forum": "SMZGQu6lld",
            "replyto": "SMZGQu6lld",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6679/Reviewer_vjeb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6679/Reviewer_vjeb"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed a novel LLM-based method for the prediction of crystal properties. The authors collect a dataset including crystal text descriptions with their properties, and use a T5-based finetune network to achieve SOTA performance on their benchmark. Also, the authors perform their model on two property prediction tasks with ablation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "(1). The authors conducted enough experiments to show the efficiency and capabilities of their model. The experiment is solid and convincing.\n(2). This paper is well-written and easy to follow. The author\u2019s motivation for this work is clear.\n(3) The problem with crystal is important. And focusing on language and LLM is an important view for this problem."
                },
                "weaknesses": {
                    "value": "1. Some details are not clear. How large is the pre-trained T5 model you used? The T5-small, T5-base, or T5-large? Specify this is important for the comparison of your efficiency. \n2. The authors mentioned there\u2019s some related work that also used finetuned LLMs for crystal representation. These works collect crystal text descriptions based on Robocrystallographer too. However, the authors did not compare their dataset with theirs about the text content and text quality. So, the experiment is not solid."
                },
                "questions": {
                    "value": "(1). You have mentioned there\u2019s some related work that also used finetuned LLMs for crystal representation. They collect crystal text descriptions based on Robocrystallographer too. Could you compare your dataset with theirs about the text content and text quality? Showing the advantage of your dataset is important for your contribution to data collection.\n\n(2). Section 5.1 \u201cThe possible reason for this improvement might be that LLMProp can easily access the most important information for volume prediction, e.g. space group information, from the text descriptions compared to GNNs.\u201d Could you please make some more ablation about your text information to prove your statement? Also, this is important to measure the importance of different types of information.\n\n(3). Could you please make a task description to show the importance of the two tasks (Band gap and volume) in the experiments? Many other properties are predicted in related works such as energy per atom and bulk modulus. Why did you choose these two tasks?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6679/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698673825518,
            "cdate": 1698673825518,
            "tmdate": 1699636765005,
            "mdate": 1699636765005,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CTNyvTFP1F",
                "forum": "SMZGQu6lld",
                "replyto": "VCb3hWdE4H",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6679/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6679/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Some details are not clear. How large is the pre-trained T5 model you used? The T5-small, T5-base, or T5-large? Specify this is important for the comparison of your efficiency.**\n\n> We did add the number of parameters for the T5 model and the MatBERT baseline on table 2 and 3, and table 5. We will specify that this corresponds to T5 small in the revision.\n\n**You have mentioned there\u2019s some related work that also used finetuned LLMs for crystal representation. They collect crystal text descriptions based on Robocrystallographer too. Could you compare your dataset with theirs about the text content and text quality? Showing the advantage of your dataset is important for your contribution to data collection.**\n\n> Unfortunately, they did not release their data sets which makes it impossible to compare our benchmark with the data they used. Since we did not have access to their train-test splits, we finetuned MatBERT (the model that they finetuned on their data)  on our benchmark so as to make a fair comparison with LLM-Prop.\n\n**Section 5.1 \u201cThe possible reason for this improvement might be that LLMProp can easily access the most important information for volume prediction, e.g. space group information, from the text descriptions compared to GNNs.\u201d Could you please make some more ablation about your text information to prove your statement? Also, this is important to measure the importance of different types of information.**\n\n> This is indeed a great point, we will include this ablation in the revision.\n\n**Could you please make a task description to show the importance of the two tasks (Band gap and volume) in the experiments? Many other properties are predicted in related works such as energy per atom and bulk modulus. Why did you choose these two tasks?**\n\n> Our motivation to focus on the physical properties (Band gap and Volume) was based on the fact that while these properties are very important they are understudied in many prior works probably because prior methods seem to not perform well on these two tasks."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6679/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700163497465,
                "cdate": 1700163497465,
                "tmdate": 1700163497465,
                "mdate": 1700163497465,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "q6myy1ckQu",
            "forum": "SMZGQu6lld",
            "replyto": "SMZGQu6lld",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6679/Reviewer_Vdge"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6679/Reviewer_Vdge"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the physical and electronic property prediction problem and proposes to use large language models to predict the properties of crystals from the text descriptions. The paper provides an input processing strategy to prepare the input text of the language model and adapt T5 for predictive tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. The studied problem is interesting and AI for science is also an important research area.\n2. The paper is well-organized and easy to follow."
                },
                "weaknesses": {
                    "value": "1. Although the task of crystal property prediction is an interesting problem for AI for science, the innovation of methodology is not surprising. This paper only uses the language model to make the prediction which is less novelty.\n2. There are several recent works focusing on the text-rich graph where each node has text descriptions by jointly leveraging the GNN and LLM. These works are also related to the problem studied in this paper and should be discussed and compared.\n3. The specific challenge in this problem is not clarified."
                },
                "questions": {
                    "value": "1. What is the specific challenge in the problem of crystal property prediction?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6679/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698719227705,
            "cdate": 1698719227705,
            "tmdate": 1699636764859,
            "mdate": 1699636764859,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "t0IulSFUlX",
                "forum": "SMZGQu6lld",
                "replyto": "q6myy1ckQu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6679/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6679/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Although the task of crystal property prediction is an interesting problem for AI for science, the innovation of methodology is not surprising. This paper only uses the language model to make the prediction which is less novelty.**\n\n> Although the idea of using LMs to make predictions is not novel, finetuning LLMs to achieve SOTA results on crystal property prediction using their descriptions compared to domain-specific models requires innovative approaches and to the best of our knowledge, LLM-Prop is the first method that is based on finetuning a non-domain-specific LLM to achieve that. Different techniques (see Table 6) that we combine together to finetune T5 encoder enable LLM-Prop to outperform a naively finetuned MatBERT despite having a three times fewer parameters than MatBERT which has been pretrained on domain-specific data. As the results show, we also improved over the GNN-based methods, achieving a significant difference in performance (see Table 3-5).\n\n**There are several recent works focusing on the text-rich graph where each node has text descriptions by jointly leveraging the GNN and LLM. These works are also related to the problem studied in this paper and should be discussed and compared.**\n\n> Although there are works that use GNN and LLM, for example [Zhao et al. 2023](https://openreview.net/forum?id=q0nmYciuuZN), we would like to remind the reviewer that these works are specifically implemented for tasks that are related to text-attributed graphs (for e.g. knowledge graphs and paper citation graphs) such as node classification. In those works each node is a text/document and nodes are interconnected in a graph format. Our work specifically deals with the task of crystal property prediction where each crystal is represented by a text description and does not require building a knowledge graph between different crystals, it directly predicts crystal properties using a finetuned LLM on a text description of that crystal. Although simple, our approach achieves state-of-the-art performance, outperforming even state-of-the-art GNN-based methods.\n\n**The specific challenge in this problem is not clarified. What is the specific challenge in the problem of crystal property prediction?**\n\n> Crystals, unlike molecules, are rigid bodies. They have strong symmetries that are challenging to capture by even the current state-of-the-art GNNs ([Choudhary et al. 2021](https://www.nature.com/articles/s41524-021-00650-1)). Our work shows that working in the description space of these crystal structures is a promising way to predict the properties of crystals. The text descriptions that are the input to our proposed method already have information about symmetries such as space groups and by having a powerful pretrained language model like T5 that can easily understand text and extract useful information from the crystal descriptions, we get the crystal representation that is used to accurately predict its properties."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6679/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700163382007,
                "cdate": 1700163382007,
                "tmdate": 1700163382007,
                "mdate": 1700163382007,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Vuy24vk0ei",
            "forum": "SMZGQu6lld",
            "replyto": "SMZGQu6lld",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6679/Reviewer_WsXq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6679/Reviewer_WsXq"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigates the task of predicting crystal properties with LLM decoder-only model. The model is trained on the constructed benchmark dataset (TextEdge) which contains crystal structure, description, properties such as band gap. The experimental result shows that the proposed method LLM-Prop is slightly better than previous method MatBERT and ALIGNN."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper extends the previous crystal representations task based on text into the property prediction task based on text.\n- The benchmark dataset TextEdge should be helpful in the predicting crystal properties domain."
                },
                "weaknesses": {
                    "value": "- My top concern is the technical depth of the paper. For the method, this paper is an implementation for predicting crystal properties task with decoder part of T5. The discussion of choice of T5 is weak and Input Processing is also trivial. \n- For the Data collection in Sec 3.1, I did not see the challenging part and discussion about the process of data collection including quality control. I am not sure about the quality of data at all."
                },
                "questions": {
                    "value": "N/A"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6679/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698721763674,
            "cdate": 1698721763674,
            "tmdate": 1699636764743,
            "mdate": 1699636764743,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bHjTM1vBa0",
                "forum": "SMZGQu6lld",
                "replyto": "Vuy24vk0ei",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6679/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6679/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**My top concern is the technical depth of the paper. For the method, this paper is an implementation for predicting crystal properties tasks with the decoder part of T5. The discussion of choice of T5 is weak and Input Processing is also trivial.**\n\n> We did not use the decoder part of T5 but rather built on the encoder of T5 with a carefully designed finetuning approach. We refer the reviewer to the last paragraph of the Introduction section and section 3.2.1 and 3.2.2  for our detailed discussion of why we chose T5. We also refer the reviewer to section 5.2 and Table 6 that discuss the detailed contribution of the input processing to the overall performance of LLM-Prop. Please, note that the input processing is very crucial when handling scientific data. For instance this very recent work ([Golkar et al. 2023](https://arxiv.org/abs/2310.02989)) shows that encoding numbers in scientific text differently improves the LLMs performance substantially.\n\n\n**For the Data collection in Sec 3.1, I did not see the challenging part and discussion about the process of data collection including quality control. I am not sure about the quality of data at all.**\n\n>This is a good point. We will indeed add more details for this part in the revision. We will add details on how Robocrystallographer works, how long it took us to collect the structure data from the Materials Project database, and how to generate the descriptions with Robocrystallographer. We also add details on quality control where for instance we discarded crystals with shorter descriptions (less than 5 tokens), and statistics of the final datasets such as the average length of the descriptions, total number of tokens, average number of numerical values in each description, etc."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6679/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700163248456,
                "cdate": 1700163248456,
                "tmdate": 1700163248456,
                "mdate": 1700163248456,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]