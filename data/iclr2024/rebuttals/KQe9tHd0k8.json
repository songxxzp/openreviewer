[
    {
        "title": "Learning from Label Proportions: Bootstrapping Supervised Learners via Belief Propagation"
    },
    {
        "review": {
            "id": "pzKunYlL2H",
            "forum": "KQe9tHd0k8",
            "replyto": "KQe9tHd0k8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7839/Reviewer_hQ1X"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7839/Reviewer_hQ1X"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes an effective and efficient approach to the problem of Learning from Label Proportions. The proposed approach has two main steps. In the first step, it uses Belief\nPropagation to marginalize the Gibbs distribution to obtain pseudo labels. In the second step, it uses the pseudo labels to provide supervision for a learner. The paper conducted experiments to show the usefulness of the proposed approach."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The problem of Learning from Label Proportions could be useful. \n- This paper is well structured and easy to follow.\n- The proposed approach outperforms state-of-the-art approaches."
                },
                "weaknesses": {
                    "value": "- The proposed approach is complex; a simple framework is desirable. \n- The proposed approach assumes the case of disjoint bags; it cannot handle non-disjoint bags.\n- The paper lacks theoretical aspects of the proposed approach."
                },
                "questions": {
                    "value": "The paper should discuss theoretical aspects of the proposed approach. For example, I am interested in the time and space complexity of the proposed approach since the proposed approach has rather complex framework. What are the computational and memory costs of the proposed approach?\n\nThe graph structure has a significant impact on the proposed approach. How do you determine the number of nearest neighbors? Is there any theoretical background to determine the graph structure?\n\nAs shown in Algorithm 1, the proposed approach uses the iterative computations. Does the proposed approach have a theoretical property to converge? How do you determine the number of iterations, R?\n\nAs shown in Table 1 and 2, for UCI and Criteo datasets, the proposed approach is competitive to the previous approaches. On the other hand, the proposed approach does not work well for CIFAE dataset, as shown in Table 3. Please theoretically justify the experimental results. \n\nSince the proposed approach uses a k-NN graph, it needs a high computational time to construct the graph. In Section 6.1, the paper shows the processing time of only the proposed approach. Is the proposed approach more efficient than the previous approaches?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7839/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698389841143,
            "cdate": 1698389841143,
            "tmdate": 1699636960570,
            "mdate": 1699636960570,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5AgekzJlxK",
                "forum": "KQe9tHd0k8",
                "replyto": "pzKunYlL2H",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response 1/2 to Reviewer hQ1X"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their detailed comments and provide clarifications below:\n\n> The proposed approach is complex; a simple framework is desirable.\n\n**Ans:** We think our algorithm is a simple 2-Step Iterative algorithm with the Belief Propagation Step and Embedding Refinement Step that are easy to implement in code. In order to be comprehensive, we detail the Belief Propagation step. Given a Ising model, there are several standard packages to perform Belief Propagation like pgMax that we use.\n\n> The proposed approach assumes the case of disjoint bags; it cannot handle non-disjoint bags.\n\n**Ans:** Our method is general enough for us to accommodate overlapping bags, the only change would be in the potential terms in the Gibbs Distribution formed, and thus the factor graph would differ from the disjoint case. This does not affect the algorithm procedure but only the outcome as expected, in fact learning non-disjoint bags should be an easier problem intuitively as more information in terms of bag constraints is available to the learner. We only discuss the disjoint bag case in the paper as it is of more practical relevance and is the one previously studied in popular literature as highlighted in Section 2. We reiterate that to run our algorithm on non-disjoint bags requires no code change and it will run out of the box when provided with non-disjoint bags as input.\n\n> The paper lacks theoretical aspects of the proposed approach.\n\n**Ans:** We would like to refer the reviewer to Section A.3 in the appendix where we provide some intuition as to why our algorithm works via showing that the nearness constraints through 1-NN produces a cycle free factor graph. However, when bags are randomly formed, invariably cycles are formed. Starting from the classical paper (Frey et al., 1997) to the very recent works on message passing (Newman, 2023), loopy belief propagation does not have convergence guarantees in general. In fact, the former points out the empirical success in decoding error correcting codes even on loopy graphs which precisely inspired us.\n\nWe further provide an approximate Linearized BP analysis that shows that for large bags regime for Adult, inverse temperatures chosen actually yield convergence for the Linearized BP, in a **new Section C** in the updated manuscript. We feel this analysis of the theoretical guarantee of the algorithm\u2019s performance helps provide some theoretical backing for our strong empirical results.\n\n> Q1: The paper should discuss theoretical aspects of the proposed approach. For example, I am interested in the time and space complexity of the proposed approach since the proposed approach has rather complex framework. What are the computational and memory costs of the proposed approach?\n\nAns. We refer the reviewer to Section 6.1 in the main paper and section A.2.1 in the supplement for detailed discussion in the time complexity. With respect to the space complexity, we would like to mention that the only overhead for our approach is for a potential matrix for the factor graph to store the node and pairwise potentials. This only amounts to O(V+E) space complexity as we would have V unary and E pairwise terms. Note that V = data_size, and E = O((num_neighbours + bag_size) * data_size). This is because if two points are not in the K-NN neighborhood of each other and if they don\u2019t belong together in any bag, then there would be no pairwise term corresponding to it as discussed in section 4.1. Hence the space complexity is merely O((num_neighbours + bag_size) * data_size), thus linear.\n\n> Q2: The graph structure has a significant impact on the proposed approach. How do you determine the number of nearest neighbors? Is there any theoretical background to determine the graph structure?\n\n**Ans:** The graph is an outcome of the bag constraints and the covariate pairwise constraints in the Gibbs Distribution, both of which are given to the learner. The choice of neighbors is a hyper-parameter and we have shown that even using a single Nearest Neighbor suffices in A.1.1.\n\n> Q3: As shown in Algorithm 1, the proposed approach uses the iterative computations. Does the proposed approach have a theoretical property to converge? How do you determine the number of iterations, R?\n\n**Ans:** We refer the reviewer to Section 4.3 where we define our iterative procedure and choices explicitly. To reiterate, \u201cIn principle, we could iterate it several times to refine embeddings progressively but we stop when the new iteration does not clearly improve performance on validation set\u201c. We further refer the reviewer to section A.2.2 in the appendix where we note the performance of the algorithm on different iterations and highlight why we empirically choose iteration 2 as the stopping iteration.\n\n(1/2)"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700245412290,
                "cdate": 1700245412290,
                "tmdate": 1700248839567,
                "mdate": 1700248839567,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aMhH9QMEz0",
                "forum": "KQe9tHd0k8",
                "replyto": "pzKunYlL2H",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response 2/2 to Reviewer hQ1X"
                    },
                    "comment": {
                        "value": "> Q4: As shown in Table 1 and 2, for UCI and Criteo datasets, the proposed approach is competitive to the previous approaches. On the other hand, the proposed approach does not work well for CIFAE dataset, as shown in Table 3. Please theoretically justify the experimental results.\n\n**Ans:** As the reviewer pointed out, for the UCI and Criteo datasets our performance improvements are quite significant and outperforms all baseline methods. We would like to also reiterate that our method performs significantly well on CIFAR dataset too, as empirically demonstrated by improvements of as much as **7.4%** in AUC on larger bag sizes over the closest baseline (Table 3). An important thing to note here is that CIFAR is a much easier dataset for all algorithms as demonstrated by the closeness of the performance of all baselines to the instance wise performance which is an empirical ceiling. Due to the use of ImageNet trained SimCLR embeddings as input for all methods, the task of classification on CIFAR, especially the balanced on (CIFAR-B) is a much simpler task for all algorithms to solve and the scope for improvement is minimal. We still are competitive with, if not better than, all baselines across all bag sizes and all datasets. This is proof enough of the generalizability of our method, which is domain agnostic.\n\n> Q5: Since the proposed approach uses a k-NN graph, it needs a high computational time to construct the graph. In Section 6.1, the paper shows the processing time of only the proposed approach. Is the proposed approach more efficient than the previous approaches?\n\n**Ans:** Compared to data setup time which is common to DLLP and our method the overall algorithm time is not that significant. The training, data setup times are identical, the only overhead is the BP time. Moreover, the time taken for the kNN graph construction and the required pre-processing is merely **80.49s** (+- 6.07s) for the Adult Dataset (barely a minute for 1 nearest neighbor, for a ~50k sized dataset), which is almost 10 times smaller than the common data setup time and comparable to the training time for the MLP (**85s**). It is also in the same range as the BP time for 128 sized bags, and much faster than BP for larger bags. Thus the graph construction for kNN does not need high computational time and is not a bottleneck. As we have highlighted in section A.1.1, 1NN suffices to retrieve the majority of the performance Thus we are able to achieve a superior performance over the baselines with only additional 80s required for obtaining the neighbor graph to form our covariate factors before Belief Propagation.\n\nWe hope this clears all the doubts the reviewer had. We are happy to discuss or clarify further questions as well. \n\n(2/2)"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700245565887,
                "cdate": 1700245565887,
                "tmdate": 1700248650095,
                "mdate": 1700248650095,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IeG7RLUuJ8",
                "forum": "KQe9tHd0k8",
                "replyto": "pzKunYlL2H",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We greatly appreciate the valuable feedback on our submission. We have done our best to answer all your questions and added a new **Section C** for theoretical guarantees for our algorithm, clarified framework and bagging, provided computational and memory costs, explained the graph structure and iterative convergence, elaborated on the computational time and experimental results to address your concerns.\n\nAs the discussion deadline is nearing, we would appreciate your response to the rebuttal or any further constructive discussion.\n\nGrateful for your effort and time to review our submission!"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700680272212,
                "cdate": 1700680272212,
                "tmdate": 1700680286796,
                "mdate": 1700680286796,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "89DaUD9Dpf",
            "forum": "KQe9tHd0k8",
            "replyto": "KQe9tHd0k8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7839/Reviewer_XP46"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7839/Reviewer_XP46"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the setting of learning from label proportions (LLP), where we have access to aggregate labels over bags (i.e., grouped instances). The authors provide an approach that (1) implements belief propagation to assign pseudolabels to similar data points and (2) iteratively trains supervised classifiers with the pseudolabels (and the previous classifiers learned embeddings)."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The authors provide a new scheme (based on Ising models and belief propagation) to propagate pseudolabels across datapoints taking into account bag constraints and covariate similarity.\n* They also derive a new architecture and objective during bootstrapping their supervised model on the produced pseudolables. This involves an additional hidden layer that produces soft scores over the bag to maintain correct bag proportions.\n* Good experimental gains over existing LLP baselines with large bag sizes."
                },
                "weaknesses": {
                    "value": "1.  Lack of explanation/intuition about results. Are there any hypotheses as to why the results of your method are worse in cases with small bag sizes but better in cases with large bag sizes?\n\n\n2. Lack of discussion about work from the field of weak supervision, where there have been similar problems studied in the context of combining weak supervision (labels similar to aggregate labels over bags) and covariate information via clustering [1] and via label propagation [2]. In both cases, a model is trained after pseudolabels are generated (although no iterative refinement is done as these methods start from pretrained representations and supervised models are directly fit on the pseudolabels).\n\n\n3. A few typos that I noted (that don\u2019t overall affect my score):\n* Last line of page 7: \u201cthe iteration seem to help improve performance\u201d, should be \u201citeration seems to help improve performance\u201d\n* \u201cBag constraints\u201d in section 6.1 shouldn\u2019t be capitalized\n\n[1] Chen, Mayee F., et al. \"Shoring up the foundations: Fusing model embeddings and weak supervision.\" Uncertainty in Artificial Intelligence. PMLR, 2022.\n[2] Pukdee, Rattana, et al. \"Label Propagation with Weak Supervision.\" The Eleventh International Conference on Learning Representations. 2022."
                },
                "questions": {
                    "value": "* See first point in the weakness section. Are there any particular intuitions as to why DLLP outperforms your method (somewhat consistently) over small bag sizes?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7839/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7839/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7839/Reviewer_XP46"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7839/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698427001214,
            "cdate": 1698427001214,
            "tmdate": 1699636960427,
            "mdate": 1699636960427,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2HUJQJn5Qu",
                "forum": "KQe9tHd0k8",
                "replyto": "89DaUD9Dpf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response 1/1 to Reviewer XP46"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their detailed comments and provide clarifications below:\n\n> Lack of explanation/intuition about results. Are there any hypotheses as to why the results of your method are worse in cases with small bag sizes but better in cases with large bag sizes? Are there any particular intuitions as to why DLLP outperforms your method (somewhat consistently) over small bag sizes?\n\n**Ans.** The performance of DLLP on small bags is the result of relatively higher supervision available as compared to larger bags where the number of bags can be as few as 20! (so just 20 label counts in all for the dataset) In presence of the high supervision provided by small bags, even other algorithms are able to perform comparable to our method. In case of small bag sizes our performance is not necessarily worse but in the same ballpark, within the confidence intervals, and is really close to the instance wise performance. So there is much less margin for improvement in the case of small bags as compared to large bags (*~1% for bags of size 8 vs ~10% for bags of size 2048* for Adult dataset). We would like to reiterate that even on small bags sizes we still are competitive with, if not better than, all baselines across all datasets.\n\nOn large bags where the other methods collapse due to extremely weak supervision, our novel algorithm still holds up.\n\nWe further provide an approximate Linearized BP analysis that shows that for large bags regime for Adult, inverse temperatures chosen actually yield convergence for the Linearized BP, in a **new Section C** in the updated manuscript. We feel this analysis of the theoretical guarantee of the algorithm\u2019s performance helps provide the requested theoretical backing for our strong empirical results, especially on Larger Bags.\n\n> Lack of discussion about work from the field of weak supervision, where there have been similar problems studied in the context of combining weak supervision (labels similar to aggregate labels over bags) and covariate information via clustering [1] and via label propagation [2]. In both cases, a model is trained after pseudolabels are generated (although no iterative refinement is done as these methods start from pretrained representations and supervised models are directly fit on the pseudolabels).\n\n**Ans.** We have comprehensively cited all prior works in the LLP domain and compared against several strong baselines. We\u2019ll be happy to cite and discuss other weak supervision works, but they don\u2019t necessarily directly apply to our setup as we have a specific form of weak supervision in the form of bag level labels. Heeding the reviewer's suggestion, we have updated our manuscript\u2019s section B in the supplement to include additional discussion on Weak Supervision and would request the reviewer to take a look at the same.\n\n> A few typos that I noted (that don\u2019t overall affect my score):\nLast line of page 7: \u201cthe iteration seem to help improve performance\u201d, should be \u201citeration seems to help improve performance\u201d\n\u201cBag constraints\u201d in section 6.1 shouldn\u2019t be capitalized\n\n**Ans.** We thank the reviewer for pointing out these typos and have corrected them in the revised version of the manuscript. All the changes are highlighted in blue text.\n\nWe hope this clears all the doubts the reviewer had. We are happy to discuss or clarify further questions as well. \n\n(1/1)"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700245595185,
                "cdate": 1700245595185,
                "tmdate": 1700248817514,
                "mdate": 1700248817514,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "W8ziIdwbn5",
                "forum": "KQe9tHd0k8",
                "replyto": "2HUJQJn5Qu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Reviewer_XP46"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Reviewer_XP46"
                ],
                "content": {
                    "title": {
                        "value": "Reviewer Response"
                    },
                    "comment": {
                        "value": "Thanks for your responses! I feel that most of my concerns are addressed.\n\nRegarding the first point: Thanks for the clarifications regarding why performance with small bags is comparable with baselines across most datasets due to the nature of the higher levels of supervision.\n\nRegarding the second point: I agree that the canonical (programmatic) weak supervision setup [1] does not directly apply to the LLP domain; however, many instances of weak labelers considered in that context are of the form of predicting only positive labels and otherwise abstaining (or only predicting negatives and otherwise abstaining from predictions) -- see some of the Snorkel tutorials. In that sense, many practical demonstrations of the weak supervision frameworks (e.g., Snorkel) are applied to weak labelers that provide supervision that is very similar to that of bag level labels. Regardless, I think comparisons with some of the works in this field may be interesting, although perhaps not reasonable in the time left for the rebuttal.\n\n[1] Ratner, Alexander J., et al. \"Data programming: Creating large training sets, quickly.\" Advances in neural information processing systems 29 (2016)."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700434139934,
                "cdate": 1700434139934,
                "tmdate": 1700434139934,
                "mdate": 1700434139934,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "C2JOjCx9Gl",
                "forum": "KQe9tHd0k8",
                "replyto": "89DaUD9Dpf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer XP46"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the engaging discussion and are happy that our response addressed your concerns. We discuss below the weak supervision setup, specifically Snorkel in the context of LLP.\n\nSnorkel provides a way to aggregate different kinds of weak supervision sources like patterns, heuristics, external knowledge bases, crowdsourced labels, etc provided by different users (instead of crowdsourcing hard labels) and it proposes a method to synthesize labels from this information. Snorkel uses Labeling Functions that take as input a data point and assign labels (or abstain) using heuristics, pattern matching, and third-party models.\n\nIn the LLP problem, aggregate labels are present for groups of instances. To use Snorkel to solve the LLP problem, we\u2019ll need to convert these aggregate labels into Labeling Functions. Just using the aggregate labels won\u2019t be enough since there are many ways of labeling instances so as to satisfy the aggregate label constraints. We will need to think about what other information to use to construct labeling functions. Hence, it is not clear how to directly use the snorkel approach to solve the LLP problem but it definitely looks like an interesting research direction to pursue in the future.\n\nHope this clarifies the the doubt. We would be happy to discuss further as well. We once again thank the reviewer for their time and effort."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700555265348,
                "cdate": 1700555265348,
                "tmdate": 1700560147879,
                "mdate": 1700560147879,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "eEYvpwUf2e",
            "forum": "KQe9tHd0k8",
            "replyto": "KQe9tHd0k8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7839/Reviewer_TNZ1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7839/Reviewer_TNZ1"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors propose a method for the problem of Learning from Label Proportions (LLP), where only aggregate level labels are available for groups of instances. The proposed method incorporates both bag-level and instance-level constraints to address the LLP problem. Then, the Belief Propagation (BP) algorithm is utilized to solve the problem. Finally, the authors verify the proposed method for the  LLP Binary Classification problem."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The topic of this paper is interesting and important. Learning from Label Proportions (LLP) is a weak-supervised learning paradigm, which is beneficial for privacy protection.\n2. The proposed method exhibits good performance on large bag sizes."
                },
                "weaknesses": {
                    "value": "1. The writing of this paper needs great improvement, e.g., the connection between the LLP problem and the parity checks should be clearly elaborated. The intuition behind this should be clarified.\n2. The bag-level and instance-level constraints are commonplace, making the novelty quite limited.\n3. The experiments were only conducted on Binary Classification problems, while the multi-class classification is a more general case.\n4. The formulation of the equations should be carefully checked, e.g., in Eq.(1), according to the definition of $y(S_i)$ (the third row in Section 3), the first term equals 0. Besides, the derivation from Eq.(1) to Eq.(2) should be provided for clear understanding.\n5. The proposed method performs well on large bag sizes, but the authors do not give explanations why this is the case.\n6. According to the results of Tables 4 and 5, the running time of the proposed method is far more than that of DLLP, besides, the running time of other methods is not reported.\n7. According to the results of Tables 9-13, the parameters seem to need very careful fine-tuning, and the sensitivity studies of these parameters are missed."
                },
                "questions": {
                    "value": "1. Why do you introduce the Gibbs distribution in the modeling? The reasons should be detailedly clarified.\n2. Are the instances in each bag all labeled? If yes, then the bag level counts will equal the size of the bag.\n3. Is the size of each bag in this paper equal? What if the sizes of each bag are not equal?\n4. In Table 2, why not report the results of large size (512, 1024, 2048) as other tables do?\n5. According to the results of Tables 1-3, it is weird that the performance of DLLP(published in 2017) is better than that of GenBags(published in 2022) and EasyLLP(published in 2023). Please explain these."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7839/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698555197467,
            "cdate": 1698555197467,
            "tmdate": 1699636960309,
            "mdate": 1699636960309,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KqszHW2OPh",
                "forum": "KQe9tHd0k8",
                "replyto": "eEYvpwUf2e",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response 1/3 to Reviewer TNZ1"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their detailed comments and provide clarifications below:\n\n> 1. The writing of this paper needs great improvement, e.g., the connection between the LLP problem and the parity checks should be clearly elaborated. The intuition behind this should be clarified.\n\n**Ans.** We would be happy to elaborate on the connection between the LLP problem and the parity check paradigm. In error correction, parity check reinforces even parity in a \u2018bag\u2019. In our case, we want to make sure it equals the bag level aggregate labels. Further, we also have pairwise constraints (parity of size 2) with nearest neighbors that impose similarity. In coding theory constraints are enforced in a hard manner. However, using the Gibbs measure (an energy function), we impose a soft version of these constraints.\n\n> 2. The bag-level and instance-level constraints are commonplace, making the novelty quite limited.\n\n**Ans.** As far as we are aware, no one has attempted to utilize the constraints in such a way (formulating a Gibbs distribution for an Ising Model, performing BP) for the LLP problem, achieving a practical and scalable solution, thus we feel this is quite a novel approach to incorporate those constraints.\n\n> 3. The experiments were only conducted on Binary Classification problems, while the multi-class classification is a more general case.\n\n**Ans.** We would like to emphasize that the binary classification LLP problem is of importance and such datasets and applications can be found in healthcare or advertising (conversion modeling). Please additionally refer to [1] below for a detailed discussion on the significance of the problem and the rising interest in the domain, especially due to privacy constraints. In fact we have demonstrated our techniques on Criteo which is a large and standard dataset in the advertising domain. Prior works like references *(Ardehaly & Culotta, 2017; Saket et al., 2022; Scott & Zhang, 2020; Busa-Fekete et al., 2023; Patrini et al., 2014)* in the manuscript do deal with only the binary LLP problem. \n\n[1] O'Brien, Conor, et al. \"Challenges and approaches to privacy preserving post-click conversion prediction.\" arXiv preprint arXiv:2201.12666 (2022).\n\n> 4. The formulation of the equations should be carefully checked, e.g., in Eq.(1), according to the definition of $y(S_i)$ (the third row in Section 3), the first term equals 0. Besides, the derivation from Eq.(1) to Eq.(2) should be provided for clear understanding.\n\n**Ans.** The definition of $y(S_i)$ refers to the bag label, which would be the sum of the labels of all the instances comprising the bag. Note that individual instance labels are not available to the learner. The reviewer perhaps misunderstood the notation, as the first term corresponds to the least squared loss between sum of all labels in the bag and the bag label count as defined in Section 4.1 One term corresponds to the prediction and one term corresponds to the actual value, thus it denotes a typical loss function used often in ML adapted to the bag labels.\n\nThe step from Eq 1 to Eq 2 is simply to replace all squared terms $(y_i)^2$ by linear teams as $y^2_i=y_i$ when $y_i$ can only take 0 or 1 values, as is the case with our energy function. We further eliminate all constant terms from the energy function as on normalization they would play no role in the distribution. We then just expand the individual terms from Eq 1 to terms reflecting the pairwise and unary potentials by simply separating out the terms with $y_i y_j$ from the terms with only $y_i$ for clarity. This helps us see the pairwise and node potentials as in Eq 3 clearly. We hope this helps elaborate the derivation of Eq 2 from Eq 1. We would be happy to add this to the updated version of the manuscript if the reviewer deems it necessary.\n\n(1/3)"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700244372358,
                "cdate": 1700244372358,
                "tmdate": 1700245149087,
                "mdate": 1700245149087,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Bv9ShrALZN",
                "forum": "KQe9tHd0k8",
                "replyto": "eEYvpwUf2e",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response 2/3 to Reviewer TNZ1"
                    },
                    "comment": {
                        "value": "> 5. The proposed method performs well on large bag sizes, but the authors do not give explanations why this is the case.\n\n**Ans.** The performance of DLLP on small bags is the result of relatively higher supervision available as compared to larger bags where the number of bags can be as few as 20! (so just 20 label counts in all for the dataset) In presence of the high supervision provided by small bags, even other algorithms are able to perform comparable to our method. In case of small bag sizes our performance is not necessarily worse but in the same ballpark, within the confidence intervals, and is really close to the instance wise performance. So there is much less margin for improvement in the case of small bags as compared to large bags (**~1% for bags of size 8 vs ~10% for bags of size 2048** for Adult dataset).\n\nOn large bags where the other methods collapse due to extremely weak supervision, our novel algorithm still holds up.\n\nWe further provide an approximate Linearized BP analysis that shows that for large bags regime for Adult, inverse temperatures chosen actually yield convergence for the Linearized BP, in a **new Section C** in the updated manuscript. We feel this analysis of the theoretical guarantee of the algorithm\u2019s performance helps provide the requested theoretical backing for our strong empirical results, especially on Larger Bags.\n\n> 6. According to the results of Tables 4 and 5, the running time of the proposed method is far more than that of DLLP, besides, the running time of other methods is not reported.\n\n**Ans.** We observed the time performance of other baselines, but only provided DLLP as an indicator. We have further provided the numbers for EasyLLP and GenBags on Adult and Criteo Datasets, for the training time for both algorithms, thus appending 2 columns to Table 5 Section A.2.1 and Table 4 in Section 6.1, and reinforcing the marginal overhead our method incurs. We reiterate that the Data Setup Time (Column 4) is common to all baselines and methods as well as it comprises the data loading and preprocessing times, which is identical for all methods including ours (which we have made more clear in the updated version of the manuscript). As one can see, GenBags takes more time to train the same MLP as our method (up to 5 times more on Adult and 3 times more on Criteo), and with much higher std. dev. And thus GenBags are much more time consuming, with similar or worse performance. Also, on Criteo, MLP training time is more for EasyLLP than for our method. We have updated Table 5 in the manuscript to include the 2 additional baseline\u2019s training time as well.\n\nWe reiterate that the only additional overhead as compared to the baselines is the BP step which for large bags gives enormous performance gains. We have also updated the manuscript to make this clear.\n\n> 7. According to the results of Tables 9-13, the parameters seem to need very careful fine-tuning, and the sensitivity studies of these parameters are missed.\n\n**Ans.** We did a search over the hyperparameters and ranges using Vizier (Song  et  al.,  2022) as specified in Section 5.1 and we took the best performing one through validation scores. We provide exact values in section A.6. We would like to state that the hyper-parameters are not highly sensitive as several sets of hyper parameters lead to the best performance we quote in our Tables 1, 2 and 3. For example, on Adult Dataset, Bag Size 2048 for Iteration 1 of our method along with the hyperparameter value set listed in Row 1, Table 11, as many as 44 sets of hyper-parameters lead to the AUC % reported in Table 1 for Adult on Bag size 2048. This is evidence enough to prove that the outcome of the algorithm isn\u2019t overly dependent on the hyper-parameters, and is not very too sensitive to the choice. We only chose to report the best performing hyper parameters with a significant degree of precision to enhance exact reproducibility. We reiterate that we plan to release the code with the camera ready version of the paper.\n\n> Q.1 Why do you introduce the Gibbs distribution in the modeling? The reasons should be detailedly clarified.\n\n**Ans.** Gibbs distribution is a joint distribution over the unknown labels. By adding terms that enforce bag constraints softly and nearness constraints softly, we enforce the constraints on the label distribution. Then, we marginalize this joint distribution using BP to obtain pseudo labels which are used for the supervised learning step.\n\n(2/3)"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700244625107,
                "cdate": 1700244625107,
                "tmdate": 1700475108925,
                "mdate": 1700475108925,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dp42eRJNzl",
                "forum": "KQe9tHd0k8",
                "replyto": "eEYvpwUf2e",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response 3/3 to Reviewer TNZ1"
                    },
                    "comment": {
                        "value": "> Q.2 Are the instances in each bag all labeled? If yes, then the bag level counts will equal the size of the bag.\n\n**Ans.** No. The main setup is that we only have bag level labels, but have no access to any instance label in any bag. Hence, each bag has only one label which is equal to the mean of all instance-level labels in the bag. But we would like to train a classifier to predict instance labels on the test, thus we formulate a Gibbs Distribution and account for the uncertainty via enforcing the constraints softly. Not even one instance of the bag has labels available to the learner during training, so it\u2019s not clear what the reviewer\u2019s doubt is.\n\n> Q.3 Is the size of each bag in this paper equal? What if the sizes of each bag are not equal?\n\n**Ans.** Yes, while we deal with constant sized bags, the algorithm is directly applicable to the case of variable bag sizes, as only the potential terms would change in the Gibbs Distribution, and thus a different factor graph, leading to a different solution as expected. We need no algorithm change to incorporate datasets with variable bag sizes, and follow the fixed bag size setup following popular literature discussed in Section 2. We reiterate that to run our algorithm on variable sized bags requires no code change and it will run out of the box when provided with variable sized bags as input.\n\n> Q.4 In Table 2, why not report the results of large size (512, 1024, 2048) as other tables do?\n\n**Ans.** We would like to reiterate that while we tried our best to run our algorithm on Criteo for larger bag sizes, the limitation on the low-level code implementation of pgMax (Zhou et al., 2022) prohibited us from attaining any numbers. As we mention in a footnote on Page 8 of the manuscript, we were not able to run BP on Criteo for large bag sizes since we ran into integer-overflow issues. It will take some time and perhaps even involve changes to the underlying PGMax library code to resolve them to accommodate a large number of factors on Criteo which is a 1 million sized dataset! \n\n> Q.5 According to the results of Tables 1-3, it is weird that the performance of DLLP(published in 2017) is better than that of GenBags(published in 2022) and EasyLLP(published in 2023). Please explain these.\n\n**Ans.** It is true that in many cases, DLLP outperforms many results published later empirically. However, we would like to point out that GenBags, whose novelty as per the authors is \u201cprovable error bounds while being bag distribution agnostic and model agnostic\u201d has non trivial performance in larger bag size regimes, as seen in Table 3 for CIFAR. EasyLLP is as the author's quote \u201ca flexible and simple-to-implement debiasing approach based on aggregate labels, which operates on arbitrary loss functions\u201d is highly competitive on smaller bag sizes on UCI Datasets, as seen in Table 1. EasyLLP and GenBags in themselves are interesting approaches to tackle this problem and have been published at prestigious conferences (NeurIPS and AISTATS respectively) and thus have been considered relevant and important by the community.\n\nWe hope this clears all the doubts the reviewer had. We are happy to discuss or clarify further questions as well. \n\n(3/3)"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700244809245,
                "cdate": 1700244809245,
                "tmdate": 1700245258993,
                "mdate": 1700245258993,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FTV7ebN9zv",
                "forum": "KQe9tHd0k8",
                "replyto": "dp42eRJNzl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Reviewer_TNZ1"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Reviewer_TNZ1"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the response. My concerns are partially addressed. I suggest the authors make further improvements to the writing, especially the motivation and the intuition behind the method. Besides, I again suggest the authors to check the notations. (According to your definition in section 3 line 4, $y\\(S_{i}\\)=\\sum_{j \\in S_{i}} y_{j}$, then the term $\\sum_{j \\in S_{i}} y_{j} - y\\(S_{i}\\)$ in the parenthesis of the first term equals 0.) Math should be rigorous.\n\nI understand that binary classification has its own importance, but I would like to see the applicability of the proposed method to multi-class classification, which is a more general case. Besides, the proposed method is time-consuming compared with other methods, which is also recognized by Reviewers Svbj, c8fH. Moreover, the authors claim that the hyper-parameters are not sensitive, but they do not provide any experimental results. I  suggest the authors add the sensitivity analysis.\n\nFor all the above reasons, I currently retain my score."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700646197010,
                "cdate": 1700646197010,
                "tmdate": 1700646197010,
                "mdate": 1700646197010,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "S7kpMc2A9T",
                "forum": "KQe9tHd0k8",
                "replyto": "eEYvpwUf2e",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer TNZ1"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the engaging discussion and are happy that our response addressed your concerns. We provide further clarifications below.\n\n> (According to your definition in section 3 line 4, $y(S_i) = \\sum_{j \\in S_i} y_j$ , then the term $\\sum_{j \\in S_i} y_j - y(S_i)  $in the parenthesis of the first term equals 0.) \n\n**Ans.** We would like to emphasize that instance level labels are not available. Only bag level aggregates are available. Thus the usage of $y_j$ in the section 3 line 4 corresponds to true instance labels, which are not available to the learner. On the other hand, the second usage of $y_j$ in the Gibbs Distribution is for the predicted labels which are the ones on which the constraints are imposed softly via the least squared loss. We have updated the manuscript to clarify this and replaced the first usage of $y_j$ by $y^{true}_j$ in section 3, line 4.\n\nWe would like to emphasize that Gibbs distributions impose constraints softly on instance wise predictions with a least squares loss between the sum of predicted labels and the true bag level sum (first term reviewer is referring to). Configurations that will have 0 loss will have low energy due to that term. Note that any configuration that matches the bag level sum will have zero loss; not necessarily the true one. Also, there could be configurations that may have non zero loss for that term but are preferred due to optimizing other constraints by our algorithm.\n\n> I understand that binary classification has its own importance, but I would like to see the applicability of the proposed method to multi-class classification, which is a more general case.\n\n**Ans.** Our primary and main contributions in this paper are for the LLP problem on binary classification problem which is also a highly relevant problem in the real world where binary labeled data is available (like in Criteo) as acknowledged by the reviewer and as evidenced by rich prior work dealing with binary classification for LLP. (Ardehaly & Culotta, 2017; Saket et al., 2022; Scott & Zhang, 2020; Busa-Fekete et al., 2023; Patrini et al., 2014). Binary Classification has applications in healthcare and advertising (conversion modelling). Please additionally refer to [1] below for a detailed discussion on the significance of the problem and the rising interest in the domain, especially due to privacy constraints.\n\nDue to reviewers request and considering the time limitation, we adapted the Gibbs measure to the multi class setting as follows. Every point has $k$ labels: $y^1_i \\ldots y^k_i$ corresponding to $k$ classes.\n\nWe have three main types of terms in the Gibbs measure. \n\nWe impose a soft one hot constraint with the term: $(\\sum_p y^p_i -1)^2$  \n\nNearness terms get modified as follows: $K(x_i,x_j) \\sum_p (y^p_i - y^p_j)^2$, i.e. Euclidean distance between the vector labels of two points is small if they are nearby.\n\nAggregate Bag level constraints have counts $b_1  \\ldots b_k$. Then we simply impose a least squares constraint:\n                   $\\sum_p  ( \\sum_{i \\in B} y^p_i - b_p)^2$\n\nAll these terms are scaled by temperature hyper parameters which we search over during training. Essentially these are vectorized least squares constraints. \n\nThe results on CIFAR10 in which our method is slightly better or comparable to the SOTA, are provided in Table 11 in the updated manuscript in the new section A.2.6. While we have shown the value of a quick adaptation of our work in multi class setting in the limited time, we would like to reiterate that the focus of our paper is not on the multi class setting and binary classification for an LLP is an important problem in itself as acknowledged by the reviewers as well.\n\nWe hope this clarifies notation and satisfies concerns about the applicability to the multi class scenario.\n\n[1] O'Brien, Conor, et al. \"Challenges and approaches to privacy preserving post-click conversion prediction.\" arXiv preprint arXiv:2201.12666 (2022)."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700651326728,
                "cdate": 1700651326728,
                "tmdate": 1700653929990,
                "mdate": 1700653929990,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "AaZEuUR5rT",
            "forum": "KQe9tHd0k8",
            "replyto": "KQe9tHd0k8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7839/Reviewer_c8fH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7839/Reviewer_c8fH"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a novel algorithm for supervised learning from label proportions. One first builds a Gibbs measure that enforces the labels proportions within each bag and incentivizes nearby samples to have the same label. Then belief propagation (BP) is run on this measure, obtaining the marginals for each label. The marginals are converted to hard labels via thresholding. These new labels are then used to train a deep neural net. The network is trained on a double objective: one one side fitting the BP generated labels, on the other preserving the actual proportions of the labels in each bag. One of the internal representations of the network is then used as new covariates from which the BP and training are repeated. This algorithm achieves performances which are competitive with or superior to those of competing algorithms."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is well written\nThe proposed algorithm is interesting and novel. \nThe experimental presented experimental evidence appears complete and compelling.\nThe algorithm achieves a good performance compares to other existing methods."
                },
                "weaknesses": {
                    "value": "The proposed algorithm is slower than other algorithms it is comapred to."
                },
                "questions": {
                    "value": "1. To enforce the label proportions directly in the BP have you tried sending $\\lambda_b\\to\\infty$ and then doing MAP decoding (i.e. instead of thresholding each marginal, you take the configuration of labels that maximizes the BP approximation to the Gibbs measure)?\n\n2. Can you provide some intuition into the architecture of the network g_L? For example what is the function of the average pooling and how it is applied.\n\n3.This is more of a comment: BP is supposed to be more precise on sparse factor graphs. Your factor graph is not sparse due to the term with $\\lambda_b$ coupling all the variables within one bag. Do you think there is a way to modify the Gibbs measure to keep the desired properties but having a sparse factor graph?\n\n4. Can you comment on the convergence of the BP iterations? Did BP converge? did the convergence time change with the size of  the training set? Did you use some trick to make it converge?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7839/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7839/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7839/Reviewer_c8fH"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7839/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698762461108,
            "cdate": 1698762461108,
            "tmdate": 1700555565954,
            "mdate": 1700555565954,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3mwbLM5ZaU",
                "forum": "KQe9tHd0k8",
                "replyto": "AaZEuUR5rT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response 1/2 to Reviewer c8fH"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their detailed comments and provide clarifications below:\n\n> The proposed algorithm is slower than other algorithms it is compared to.\n\n**Ans:** We would like to emphasize that the running time of Belief Propagation is only linear in (bag_size + num_neighbours), and even for a dataset with 1 million samples, total run time for 128 sized bags is merely 106 minutes, where the MLP time is akin to the baselines with 10 minutes. On bag size 2048, for an adult dataset with 50k instances, it only takes 17 mins, which is negligible for the performance improvement obtained.\n\nAlso, we would like to emphasize that the Data Setup time (Col 4) reported in Tables 4 & 5 includes time taken for data loading, model initialization etc. which would also contribute to DLLP total time. So DLLP total time is actually DLLP training time (Col 1) + Data Setup time for DLLP. As can be seen in the tables, DLLP training time (Col 1) is comparable to Ours - MLP training time (Col 4) as expected. So the only overhead of our method over DLLP is the BP time (Col 3) which, as clarified above, is linear in (bag_size + num_neighbours). We further refer the reviewer to Section 6.1 regarding time complexity of BP step.\n\n> Q1: To enforce the label proportions directly in the BP have you tried sending $\\lambda_b \\rightarrow \\infty$ and then doing MAP decoding (i.e. instead of thresholding each marginal, you take the configuration of labels that maximizes the BP approximation to the Gibbs measure)?\n\n**Ans:** In a semi-supervised setting like with bag labels, we expect a lot of uncertainty on the labels per instance. From the MAP Decoding numbers (implemented by MaxProduct BP), it\u2019s clear that attempting to label with a single label configuration is noisy and does not consistently retrieve the same performance as in the Sum Product approach across bag sizes. We have updated the manuscript by **appending analysis in Section A.2.5** about the approach suggested by the reviewer and would like to request the reviewer to take a look at the same.\n\n> Q2: Can you provide some intuition into the architecture of the network g_L? For example what is the function of the average pooling and how it is applied.\n\n**Ans:** The intuition is to obtain a single representation for the \u201cbag\u201d, the aggregate embedding through average polling of the instances in the bag is used to train on the bag label as in a usual supervised learning setup. As we highlight in Section 6.3, the aggregate embedding helps reinforce the bag constraint and amongst various kinds of pooling that can be done, mean pooling works the best consistently. The intuition is to simply obtain an \u201caverage\u201d combined embedding representing the entire bag, and to obtain this one must utilize ways to combine individual embeddings of the instances comprising the bag into one single embedding. Usage of attention is one technique as we try by doing PMA as described in Section A.5. The average pooling function that our ablations from Section 6.3 point to being the best is mean pooling that is obtained by simply taking a mean of the all the instances of the bag to output one aggregate embedding for the bag via the following tensorflow code:\n\n` pooled_embed = tf.reduce_mean(instance_embed, axis=1) `\n\n> Q3: This is more of a comment: BP is supposed to be more precise on sparse factor graphs. Your factor graph is not sparse due to the term with $\\lambda_b$ coupling all the variables within one bag. Do you think there is a way to modify the Gibbs measure to keep the desired properties but having a sparse factor graph?\n\n**Ans:** It is also precise on forests, we also prove that the 1NN section of the factor graph is tree like in sec A.3 but the bags do introduce cycles. We can\u2019t prove convergence to true marginals due to the presence of cycles in general. However, the approximation via Loopy BP is good enough as we demonstrate empirically.\n\nWe would like to refer the reviewer to Section A.3 in the appendix where we provide some intuition as to why our algorithm works via showing that the nearness constraints through 1-NN produces a cycle free factor graph. However, when bags are randomly formed, invariably cycles are formed. Starting from the classical paper (Frey et al., 1997) to the very recent works on message passing (Newman, 2023), loopy belief propagation does not have convergence guarantees in general. In fact, the former points out the empirical success in decoding error correcting codes even on loopy graphs which precisely inspired us.\n\nWe further provide an approximate Linearized BP analysis that shows that for large bags regime for Adult, inverse temperatures chosen actually yield convergence for the Linearized BP, in a **new Section C** in the updated manuscript.\n\nWe cannot easily see a way to create a cycle free graph with bag constraints.\n\n(1/2)"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700244286066,
                "cdate": 1700244286066,
                "tmdate": 1700248871748,
                "mdate": 1700248871748,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6TXJqDskZX",
                "forum": "KQe9tHd0k8",
                "replyto": "AaZEuUR5rT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response 2/2 to Reviewer c8fH"
                    },
                    "comment": {
                        "value": ">Q4: Can you comment on the convergence of the BP iterations? Did BP converge? did the convergence time change with the size of the training set? Did you use some trick to make it converge?\n\n**Ans:** BP usually converges in 200 iterations. We did not explicitly use any trick to converge the BP. For larger sizes of the training set, it does take more iterations to converge than for a smaller training set but we discover that 200 iterations suffice across all datasets.\n\nWe hope this clears all the doubts the reviewer had. We are happy to discuss or clarify further questions as well.\n\n(2/2)"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700244331896,
                "cdate": 1700244331896,
                "tmdate": 1700244926591,
                "mdate": 1700244926591,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QSUILclae5",
                "forum": "KQe9tHd0k8",
                "replyto": "6TXJqDskZX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Reviewer_c8fH"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Reviewer_c8fH"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your answers, which I found satisfactory. After reading them and reading other reviewers comments I confirm my score.\n\nI'd suggest that you include the information about BP convergence somewhere in the manuscript."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700660390614,
                "cdate": 1700660390614,
                "tmdate": 1700660390614,
                "mdate": 1700660390614,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "EdIptndI9T",
            "forum": "KQe9tHd0k8",
            "replyto": "KQe9tHd0k8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7839/Reviewer_Svbj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7839/Reviewer_Svbj"
            ],
            "content": {
                "summary": {
                    "value": "This paper provided an algorithm to perform efficient learning from bag-level label proportions. The author utilized Belief Propagation on parity-like constraints derived from covariate information and bag-level constraints to obtain pseudo labels. Next, the Aggregate Embedding loss used instance-wise pseudo labels and bag-level constraints to output a final predictor. In the end, the authors also provided  experimental comparisons against several SOTA baselines across various datasets of different types."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Learning from bag-level Label Proportions (LLP)  is an interesting and valuable topic in the learning community. Privacy of data is one crucial consideration in this area.\n2. The literature part is clear.\n3. The structure of the paper is easy to follow.\n4. There is extensive experiment analysis on the algorithm performance."
                },
                "weaknesses": {
                    "value": "Major\n1. In the setup section (section 3, p3), it lack the assumptions and descriptions on the data distribution (x,y), and bag distribution.\n1.1 For example, for distributions,  the proposed algorithm may not work and or could not converge\n1.2 Without data distribution assumptions, it will limit the guidance for practitioners. \n\n2. There is no analysis of the theoretical guarantee of the algorithm's performance.\n\n3. The proposed algorithm is much slower than the baseline algorithm, and the running time is about one order slower Table 4. However, the performance of the proposed algorithm in Table 2 and 3 are not significantly better in many setups.\n\n4. The 4 datasets in the experimental analysis are not real data on the bag-level. The bags are manually created.\n\n5. Some notations are not reader-friendly. \n5.1 For example, in formula (2), the meaning of  | | is not defined. \n5.2 3rd line in section 3 of p3, [m] is not defined.\n\nMinor\n1. In section 6.1, there is only time for one baseline algorithm, and it lacks time for other algorithms.\n\n2. Near all parameters are tuned. There is no guidance on how to choose them in practice for quick application. For example, there is no guideline for the stopping rule of the algorithm to ensure convergence.\n\n3. In the proposed algorithm, the pair-wise calculation could lead to a high order time complexity. For example, capturing k-nearest neighbors for every point x_i is a very slow process when the data size is large."
                },
                "questions": {
                    "value": "1. What's the performance of the proposed algorithm on real bag-level data?\n\n2. What's the time performance of other baseline algorithms?\n\n3. Are there any stopping rules to decide when to stop the iteration and ensure the convergence?\n\n4. What's the distribution and bagging assumption required for the proposed algorithm?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7839/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698824758527,
            "cdate": 1698824758527,
            "tmdate": 1699636960054,
            "mdate": 1699636960054,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4uxL86yehz",
                "forum": "KQe9tHd0k8",
                "replyto": "EdIptndI9T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response 1/3 to Reviewer Svbj"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their detailed comments and provide clarifications below:\n\n> In the setup section (section 3, p3), it lack the assumptions and descriptions on the data distribution (x,y), and bag distribution. 1.1 For example, for distributions, the proposed algorithm may not work and or could not converge 1.2 Without data distribution assumptions, it will limit the guidance for practitioners. *Q. 4 What's the distribution and bagging assumption required for the proposed algorithm?*\n\n**Ans.** We would like to reiterate that we do not work under any specific assumptions for the data. We only assume that the instances in each bag are sampled randomly without replacement. As mentioned in section 5, we follow the standard practice in popular LLP literature *(Chen et al, 2023; Ardehaly & Culotta, 2017; Patrini et al, 2014; Busa-Fekete et al., 2023)* of creating disjoint random bags where we sample instances without replacement from the training set, and keep repeating this for each bag, bag-size: k number of times. We are solving for the most general case of bag construction. Thus, there is no distributional assumption on the dataset or bagging.\n\n> There is no analysis of the theoretical guarantee of the algorithm's performance.\n\n**Ans** We would like to refer the reviewer to Section A.3 in the appendix where we provide some intuition as to why our algorithm works via showing that the nearness constraints through 1-NN produces a cycle free factor graph. However, when bags are randomly formed, invariably cycles are formed. Starting from the classical paper (Frey et al., 1997) to the very recent works on message passing (Newman, 2023), loopy belief propagation does not have convergence guarantees in general. In fact, the former points out the empirical success in decoding error correcting codes even on loopy graphs which precisely inspired us.\n\nWe further provide an approximate Linearized BP analysis that shows that for large bags regime for Adult, inverse temperatures chosen actually yield convergence for the Linearized BP, in a **new Section C** in the updated manuscript. We feel this analysis of the theoretical guarantee of the algorithm\u2019s performance helps provide the requested theoretical backing for our strong empirical results.\n\n> The proposed algorithm is much slower than the baseline algorithm, and the running time is about one order slower Table 4. However, the performance of the proposed algorithm in Table 2 and 3 are not significantly better in many setups.\n\n**Ans.** We would like to emphasize that the running time of Belief Propagation is only linear in (bag_size + num_neighbours), and even for a dataset with 1 million samples, total run time for 128 sized bags is merely 106 minutes, where the MLP time is akin to the baselines with 10 minutes. On bag size 2048, for an adult dataset with 50k instances, it only takes 17 mins, which is negligible for the performance improvement obtained.\n\nAlso, we would like to emphasize that the Data Setup time (Col 4) reported in Tables 4 & 5 includes time taken for data loading, model initialization etc. which would also contribute to DLLP total time. So DLLP total time is actually DLLP training time (Col 1) + Data Setup time for DLLP. As can be seen in the tables, DLLP training time (Col 1) is comparable to Ours - MLP training time (Col 4) as expected. So the only overhead of our method over DLLP is the BP time (Col 3) which, as clarified above, is linear in (bag_size + num_neighbours). We further refer the reviewer to Section 6.1 regarding time complexity of BP step.\nTable 2 contains results on Criteo, which is a very hard, tabular dataset. Even small amounts of improvement on this data is non-trivial and significant. Over the last 7 years, the dataset has seen a 2% improvement in AUC while our method is able to produce up to **0.8%** improvement over DLLP *(Ardehaly & Culotta, 2017)*. In Table 3, the performance improvement in CIFAR-S is up to **7.4%**. CIFAR-B (balanced dataset) is a much easier dataset to learn from, as there are a lot of instances with label 1. Our method performs comparable to the baselines on this. The gap to the instance-wise performance is also minimal on CIFAR-B.\n\n(1/3)"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700242637691,
                "cdate": 1700242637691,
                "tmdate": 1700247832136,
                "mdate": 1700247832136,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zUXj4IDPEW",
                "forum": "KQe9tHd0k8",
                "replyto": "EdIptndI9T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response 2/3 to Reviewer Svbj"
                    },
                    "comment": {
                        "value": "> The 4 datasets in the experimental analysis are not real data on the bag-level. The bags are manually created. *Q.1 What's the performance of the proposed algorithm on real bag-level data?*\n\n**Ans.** We would like to refer the reviewer to several papers from the LLP literature *(Chen et al, 2023; Ardehaly & Culotta, 2017; Patrini et al, 2014; Busa-Fekete et al., 2023)* who follow the same procedure to create random bags on usual datasets. The use of Adult, Marketing, Criteo, CIFAR is well-established in the same prior literature. We request the reviewer to please take a look at Section 2 of the paper where related work from the LLP perspective is discussed. All of these prior work deal with creation of \u201cmanual\u201d bags following some bag creation techniques.\n\nIn industrial applications as well, stricter tracking regulations especially with respect to clicks as in PCM *(https://webkit.org/blog/11529/introducing-private-click-measurement-pcm/, https://developer.chrome.com/docs/privacy-sandbox/)*, have led to development of aggregation techniques with aggregation into random bags of uniform size as described by us is one of the most popular.\n\nSo our setting does reflect a real-world setup and is important to study not only from a research perspective but also from an implementation perspective for future regulation ready systems.\n\nTo reiterate, there is no \u201creal bag data\u201d that we are aware of that has been benchmarked on publicly. We would be happy to append experiments on datasets that the reviewer suggests in particular. As mentioned in section 5, we follow the standard procedure of creating disjoint random bags where we sample instances without replacement from the training set, and keep repeating this for each bag, bag-size: k number of times. \n\n> Some notations are not reader-friendly. 5.1 For example, in formula (2), the meaning of | | is not defined. 5.2 3rd line in section 3 of p3, [m] is not defined.\n\n**Ans.** We appreciate the reviewer pointing out these issues and would be happy to clarify that [m] denotes the indices {1,2,3 \u2026 m}, from which the indices corresponding to the instances in that bag S_i are obtained. | x | denotes an indicator variable which is 1 if and only if both i and j belong to the same bag. We have clarified these notations in the updated manuscript.\n\n> Near all parameters are tuned. There is no guidance on how to choose them in practice for quick application. For example, there is no guideline for the stopping rule of the algorithm to ensure convergence.\n\n**Ans.** We would like to refer the reviewer to section A.5 in the appendix where we explicitly state the default hyper-parameters and the stopping rule of the algorithm for convergence. For reproducibility purposes we also provide exact hyper-parameter values per dataset in section A.6. We would also release the code publicly with the camera ready version of the paper, further enhancing reproducibility. The choice of hyper-parameters varies from dataset to dataset, and while we cannot comment on the optimal choice of parameters for a new dataset a user might experiment on, we provide the entire implementation and experimentation detail and in near future shall provide code that we believe that should help the user extend our algorithm with ease.\n\n> In the proposed algorithm, the pair-wise calculation could lead to a high order time complexity. For example, capturing k-nearest neighbors for every point x_i is a very slow process when the data size is large.\n\n**Ans.** We refer the reviewer to Section 6.1, where we clearly state that the time complexity of Belief Propagation is linear in the number of neighbors per point. We further establish the effectiveness of 1NN in capturing the majority of the gains and thus even a small number of neighbors per point is sufficient, even when the data size is large.\n\nFurther to provide empirical evidence, compared to data setup time which is common to DLLP and our method the overall algorithm time is not that significant. Moreover, the time taken for the kNN graph construction and the required pre-processing is merely 80.49s (+- 6.07s) for the Adult Dataset (barely a minute for 1 nearest neighbor, for a ~50k sized dataset), which is almost 10 times smaller than the common data setup time and comparable to the training time for the MLP (85s). It is also in the same range as the BP time for 128 sized bags, and much faster than BP for larger bags. Thus the graph construction for kNN does not need high computational time and is not a bottleneck. As we have highlighted in section A.1.1, 1NN suffices to retrieve the majority of the performance Thus we are able to achieve a superior performance over the baselines with only additional 80s required for obtaining the neighbor graph to form our covariate factors before Belief Propagation.\n\n(2/3)"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700243023881,
                "cdate": 1700243023881,
                "tmdate": 1700243397701,
                "mdate": 1700243397701,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "unLolkgBn0",
                "forum": "KQe9tHd0k8",
                "replyto": "EdIptndI9T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response 3/3 to Reviewer Svbj"
                    },
                    "comment": {
                        "value": "> *Q.2 What's the time performance of other baseline algorithms?*\n\n**Ans.** We observed the time performance of other baselines, but only provided DLLP as an indicator. We have further provided the numbers for EasyLLP and GenBags on Adult and Criteo Datasets, for the training time for both algorithms, thus appending 2 columns to Table 5 Section A.2.1 and Table 4 in Section 6.1, and reinforcing the marginal overhead our method incurs. We reiterate that the Data Setup Time (Column 4) is common to all baselines and methods as well as it comprises the data loading and preprocessing times, which is identical for all methods including ours (which we have made more clear in the updated version of the manuscript). As one can see, GenBags takes more time to train the same MLP as our method (up to 5 times more on Adult and 3 times more on Criteo), and with much higher std. dev. And thus GenBags are much more time consuming, with similar or worse performance. Also, on Criteo, MLP training time is more for EasyLLP than for our method. We have updated Table 5 in the manuscript to include the 2 additional baseline\u2019s training time as well.\n\n> *Q.3 Are there any stopping rules to decide when to stop the iteration and ensure the convergence?*\n\n**Ans.** For the BP iterations as specified in Section 5.1, we either run Belief Propagation for T = 50, 100 or 200 steps and it is observed that convergence is achieved fairly quickly and almost surely within the specified number per dataset. Even for the largest dataset (Criteo), at max 200 iterations of BP suffice for the convergence as empirically corroborated by the high AUC scores with respect to the ground truth in Section A.2.3, Table 7. \n\nFor the stopping of training epochs during Step 2, which is the MLP training, we provide the exact tensorflow code snippet for early stopping in section A.5 and exact rule for halting the supervised training.\n\nFor the iterations of the entire algorithm, we empirically observe that 2 iterations suffice at max to obtain consistently high performance, as evidenced in section A.2.2, Table 6. Thus we show empirically that our method converges in two iterations and no further consistent improvement is observed. We stop at the first iteration if the second iteration\u2019s validation AUC does not outperform the first iteration\u2019s validation AUC beyond the confidence intervals.\n\nWe hope this clears all the doubts the reviewer had. We are happy to discuss or clarify further questions as well.\n\n(3/3)"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700243366338,
                "cdate": 1700243366338,
                "tmdate": 1700475012677,
                "mdate": 1700475012677,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "txPHAfKb29",
                "forum": "KQe9tHd0k8",
                "replyto": "EdIptndI9T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We greatly appreciate the valuable feedback on our submission. We have done our best to answer all your questions and added a new **Section C** for theoretical guarantees for our algorithm, appended additional baselines time performance to Table 4 and Table 5, clarified stopping rules, time complexity, running time, bagging scheme and clarified notations to address your concerns.\n\nAs the discussion deadline is nearing, we would appreciate your response to the rebuttal or any further constructive discussion.\n\nGrateful for your effort and time to review our submission!"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700680081859,
                "cdate": 1700680081859,
                "tmdate": 1700680308782,
                "mdate": 1700680308782,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "roOYQyj5Vj",
                "forum": "KQe9tHd0k8",
                "replyto": "txPHAfKb29",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Reviewer_Svbj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Reviewer_Svbj"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your detailed replies. My concerns are partially addressed. Here are some of my comments:\n\n1.The speed and performance issues:\n\nI appreciate you added two columns in Table 5. But from the table, all baseline methods have shorter running times as bag size increases. On the contrary, the proposed method becomes slower, and the gap becomes even larger (500-1000 times). This gap greatly limits the value performance improvement. In addition, in many experiments, the proposed method does not perform significantly better.\n\n2. The theoretical guarantee issue\n\nI appreciated the added section C of theoretical analysis. Though not very rigorous, I will consider it during the next discussion stage.\n\n3.The stopping rule issue, \n\nFrom Table 1 and Table 6, we can see that the performance of iterations 1, 2, and 3 vary. Sometimes, more iterations may even decrease the performance. Sometimes, even the iteration 1 is the best. Therefore, a clear stopping rule is quite important to be included.\n\n4.The real data issue\n\nIn the rebuttal, \"To reiterate, there is no \u201creal bag data\u201d that we are aware of that has been benchmarked on publicly. \" is claimed. The practitioner value is limited because no real bag data is available to test.\n\nTherefore, I currently retain my score. But I will consider the replies in the next discussion stage."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700723226164,
                "cdate": 1700723226164,
                "tmdate": 1700723226164,
                "mdate": 1700723226164,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7Nx75vOea1",
                "forum": "KQe9tHd0k8",
                "replyto": "EdIptndI9T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7839/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their time and effort, for their reviews and discussion.\n\n**Additional Theoretical Guarantees:**\n\nWe have further updated the new Section C, to add additional theoretical analysis for BP Convergence based on Sufficient conditions for convergence of the Sum-Product Algorithm (Mooij & Kappen (2007))\n\nTo summarize, exact loopy BP updates are shown to be a contraction based on sufficient conditions in Mooij & Kappen (2007) for smaller bag sizes for Adult Dataset. With an approximate linearized BP analysis of the ferromagnetic model with the same graph structure, for a subsampled set of data points i.i.d from the original Adult Dataset without replacement, we show that for large bags the chosen hyperparameters for inverse temperatures are well within the convergence threshold.\n\nThus we feel this provides the requested rigorous theoretical backing for our empirical results."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7839/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740274029,
                "cdate": 1700740274029,
                "tmdate": 1700740663884,
                "mdate": 1700740663884,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]