[
    {
        "title": "A representation-learning game for classes of prediction tasks"
    },
    {
        "review": {
            "id": "0wTk5tdWqH",
            "forum": "Uw8xvFqVAE",
            "replyto": "Uw8xvFqVAE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4852/Reviewer_eNwZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4852/Reviewer_eNwZ"
            ],
            "content": {
                "summary": {
                    "value": "The submission proposed a two-person game to solve the representation learning problem. It targets on a given class of tasks. A theoretical justification was made for the linear setting. A series of discussions were provided following the proposed algorithm for the general setting."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "a) The submission proposed a game to solve the representation learning for a given class of tasks. The formulation is practical as one can control the relevant tasks.\nb) The submission provided theoretical justifications for the linear setting to characterize the learned representations and the performance bounds (Theorems 2 and 3)."
                },
                "weaknesses": {
                    "value": "c) An algorithm is proposed to learn the representation for the general case. However, the evidence, from the theoretical or the practical perspective, is insufficient to determine the applicability of the proposed method."
                },
                "questions": {
                    "value": "d) The analysis for the linear case seems to be adapted from the game theory. Could you please clarify the technical contribution, if any, in the analysis?\ne) Is it possible to show the game will reach some situation, such as an equilibrium? Representations from the equilibrium may represent a negotiated outcome from both players.\nf) Although Examples 6 -- 9 help us to understand the nature of Algorithm 1, one still cannot know Algorithm 1's applicability. Would it be better to compare Algorithm 1 with baselines to show the representations output from Algorithm 1 are better than the existing methods?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4852/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4852/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4852/Reviewer_eNwZ"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4852/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697980284907,
            "cdate": 1697980284907,
            "tmdate": 1700566238082,
            "mdate": 1700566238082,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GMNufNrH2Y",
                "forum": "Uw8xvFqVAE",
                "replyto": "0wTk5tdWqH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4852/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4852/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answers to comments"
                    },
                    "comment": {
                        "value": "# Answer to c)\n\nOur main goal here is to propose a principled framework for learning representations based on partial knowledge of downstream prediction tasks. We aimed for analytical exploration of its fundamental properties, and thus focused on analysis of the linear-MSE setting, specifically Theorem 3. We believe that this provides a strong evidence for the validity of the framework. The proof of this result is rather convoluted (see our answer to d) below), and thus is also a main contribution of the paper. Algorithm 1 was developed to show that the framework is viable beyond the linear case, even in general cases (loss function, representation rules). Following this approach, we have focused the paper on the core of the framework and basic settings, rather than on practical baselines. Going beyond basic settings inherently requires some domain-knowledge, e.g., determining the class of functions $\\{\\cal F\\}$, and we believe that this deserves a separate inquiry. We hope that this would be achieved in future research, both by us, and by experts in various domains. We note, however, that the incremental algorithmic approach we take follows a widely acceptable solution in various ML problems, as we discuss in depth on page 2 (\u201cAlgorithmic contribution\u201d), and in Appendix B, pages 18-19 (\u201cGame-theoretic formulations in statistics and machine-learning\u201d and \u201cIncremental learning of mixture models\u201d). \n\n# Answer to d)\n\nThe main part of the analysis in the linear case is the proof of Theorem 3 (which is rather long, about 7 pages). Its goal is to find the optimal solution for the representation in mixed strategies. The main technical difficulty is that solving the mixed minimax problem directly, that is, solving\n\n$\\min\\_{\\boldsymbol{R}}\\max_{f\\in{{\\mathcal F}_{S}}} \\mathbb{E}\\left[\\mathsf{regret}(\\boldsymbol{R},f \\mid \\Sigma\\_{\\boldsymbol{x}})\\right]$\n\nis intractable. However, the minimax theorem from game theory implies that its value equals the maximin problem, that is, to \n$$\\max_{\\boldsymbol{f}}\\min_{\\boldsymbol{R}}\\mathbb{E}\\left[\\mathsf{regret}(\\boldsymbol{R},f\\mid\\Sigma_{\\boldsymbol{x}})\\right]$$ \nwhere now the function can be random too. This problem is still not trivial, but we managed to solve it. This resulted $\\boldsymbol{f}^{\\*}$, the function part of the saddle-point $(\\boldsymbol{R}^{\\*},\\boldsymbol{f}^{\\*})$, which solves both the minimax and maximim problems. We then exploited the maximin solution as a certificate to find the optimal representation $\\boldsymbol{R}^{\\*}$, because the minimax value is never smaller than the maxinim value. Thus, if one finds a random representation for which\n\n$\\max_{f\\in{\\cal {\\cal F}_{S}}}\\mathbb{E}\\left[\\mathsf{regret}(\\boldsymbol{R},f\\mid\\Sigma\\_{\\boldsymbol{x}})\\right]$\n\nequals the maxinim value, this guarantees that this random representation is the sought $\\boldsymbol{R}^{\\*}$. We find this by first making an educated guess regarding a simple structure that $\\boldsymbol{R}^{\\*}$ should posses. We then optimized over this structure, and shown it is reduced to solving an equation $Ap=b$. We proved that any solution to this equation leads to a representation whose regret is no larger than the maximin value, and is thus $\\boldsymbol{R}^{\\*}$, the saddle-point representation. To complete the proof, we show that a solution to $Ap=b$ must exist, and that the support of this solution is at most $\\ell^{*}+1$. This leads to an optimal random representation $\\boldsymbol{R}^{\\*}$ that is drastically simpler than a general probability distribution over $\\mathbb{R}^{d\\times r}$, and reinforces the effectiveness of the approach. \n\n# Answer to e)\n\nAs follows from our answer to d), the obtained solution $(\\boldsymbol{f}^{\\*},\\boldsymbol{R}^{\\*})$ is exactly the equilibrium of the game. If both sides agree to use this solution, no side can improve its payoff by a one-sided change of his/her strategy. \n\n# Answer to f)\n\nAs we have answered to point c), we focused this paper on the general approach, theoretical guarantees on fundamental settings, and a general algorithm. However, even though it is just a basic setting, in Example 9 we compare our method to PCA and show a significant improvement. PCA is also clearly not the state-of-the-art, but it is a classic and principled method that enables initial comparisons, and evidence of the potential of the method. \n\nIn summary, our main contributions are a general framework, an analytic solution in basic setting (linear-MSE) and its proof, and a \u201cmeta-algorithm\u201d which shows the viability of the method in the general cases. Hopefully, applications will be explored in depth in the future. In light of the above clarification, we would appreciate if you could re-evaluate our contributions, and finally thank you for your effort in reviewing the paper."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4852/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699998555560,
                "cdate": 1699998555560,
                "tmdate": 1699998555560,
                "mdate": 1699998555560,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vLAIzmlFT4",
                "forum": "Uw8xvFqVAE",
                "replyto": "GMNufNrH2Y",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4852/Reviewer_eNwZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4852/Reviewer_eNwZ"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your reply."
                    },
                    "comment": {
                        "value": "I believe the submission aims at answering an important problem: \"Is there a generic strategy to learn good representations, or is problem-by-problem representation learning unavoidable?\" But, my understanding of the submission and your reply tells me, \"You have a general methodology, but only compare the performance with PCA.\" If the statement is correct, it cannot serve as a legitimate answer to the topmost question since a generic methodology outputting suboptimal representations might not be able to replace a problem-tailored representation learner. \n\n[Question g)] Given the current submission, can you provide evidence that it at least produces good representations for a set of problems? The evidence could be proofs of convergence rates of a wide range of problems or experimental outcomes compared with existing methods. The current result (Theorem 3) characterizes the performance via regret, which I don't know how to use to compare with existing methods. [Question h)] Could you please elaborate on how we can compare methods (the proposed and the existing ones) fairly? I really do appreciate your devotion to this project and the non-trivial results provided. But maybe representation learning cannot be analyzed only mathematically; its effects must be tested. Maybe it is just not as simple as proving a convergence rate. I won't say my perspective is correct; I welcome better viewpoints that could provide fair means to justify a representation learning method.\n\nAlso, thank you for pointing out the technical contributions for the proofs. [Question i)] Are they of independent interests, or are they just tailored for the specific goal?"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4852/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700052694618,
                "cdate": 1700052694618,
                "tmdate": 1700052694618,
                "mdate": 1700052694618,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "AibHqvlqK3",
                "forum": "Uw8xvFqVAE",
                "replyto": "ZChLQgxliS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4852/Reviewer_eNwZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4852/Reviewer_eNwZ"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for clarifying"
                    },
                    "comment": {
                        "value": "From a mathematical perspective, the submission did a good job of proposing a model pretraining methodology and characterizing the performance. IMHO, practical applications are still better places for testing the effectiveness of a representation learning method than math. I will revise my score, but it is still subject to change during the discussion phase. Thank you."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4852/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700529935865,
                "cdate": 1700529935865,
                "tmdate": 1700529935865,
                "mdate": 1700529935865,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5hdRJrJyuw",
            "forum": "Uw8xvFqVAE",
            "replyto": "Uw8xvFqVAE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4852/Reviewer_yB5J"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4852/Reviewer_yB5J"
            ],
            "content": {
                "summary": {
                    "value": "They propose a game-based methodology to learn the classical machine learning problem of dimensionaity-reducing representations of feature vectors. On the machine learning they consider the linear setting and use the mean square error loss function. On the game theoretic side, they used mixed and pure strategies."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "They propose an interesting way to study a very classical problem. The paper is well-written, and clear"
                },
                "weaknesses": {
                    "value": "The computation can be complex such as in solving Ap = b for the probability p in the mixed minmax strategy."
                },
                "questions": {
                    "value": "The goal of RL is the minimize regret, while the goal of this seems to be to minimize MSE loss. There are some results relating to regret, but how does this relate to the MSE that results in applying this method? \n\nAlso for Theorem 3, does this assume there are only finitely many possible feature vectors (or does it just assume that the dimension of the feature vectors is finite). Just to check my understanding, I assume the dimension of the covariance matrix matches the dimension of the feature vectors learned correct?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4852/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698775996879,
            "cdate": 1698775996879,
            "tmdate": 1699636468765,
            "mdate": 1699636468765,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LN08ZgEjEZ",
                "forum": "Uw8xvFqVAE",
                "replyto": "5hdRJrJyuw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4852/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4852/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answers to comments"
                    },
                    "comment": {
                        "value": "# **Response to the weakness**\nAs we mention in Remark 1 on page 5, the\ndirect solution of $Ap=b$ is infeasible in high dimensions, since\nit requires solving a linear program with very large dimension ${\\ell^{\\*} \\choose r}=\\Theta((\\ell^{*})^{r})$.\nIn the paper, we mentioned that this can be circumvented by using\nour general algorithm to solve the linear case. This approach is indeed\neffective, as shown in Example 6 on page 8. However, we actually developed\na computationally effective algorithm to directly solve $Ap=b$, which\nallows to use the closed-form solution, but haven't included this algorithm\nin the paper in order not to burden the reader. It is reminiscent\nof the ``basis pursuit'' algorithm, and operates as follows: Recall\nthat $A$ has $\\ell^{\\*}$ rows and ${\\ell^{\\*} \\choose r}$ columns.\nTheory guarantees $Ap=b$ has a solution $p$ that has less than $\\ell^{\\*}+1$\nnon-zero entries. Thus, the algorithm needs to find the support of\nthis solution, that is, $\\ell^{\\*}+1$ column indices out of the possible\n${\\ell^{\\*} \\choose r}$ columns of $A$ with non-zero weights. This\ncan be done iteratively. First, we begin with an initial guess of\n$\\ell^{\\*}+1$ columns. It could be arbitrary, but as a general rule-of-thumb\nit is better to choose columns with $\\ell^{\\*}-r$ ones on the larger\neigenvalues (and zeros for other columns). Let us denote the sub-matrix\nof $A$ comprised from these $\\ell^{\\*}+1$ columns by $A_{1}$, and\nthe vector $p$ reduced to these indices by $p_{1}$. Then, a solution\nto $A_{1}p_{1}=b$ is sought that only uses this support. Specifically,\nsince an exact solution perhaps cannot be found, we instead solve\n$\\min_{p_{1}}\\||A_{1}p_{1}-b\\||\\_{1}$, which is a linear program.\nLet the solution be $p_{1}^{\\*}$. Then, the error is given by $e_{1}=A_{1}p_{1}^{\\*}-b$.\nIf $e_{1}=0$ then this means that we have found a solution to $Ap=b$\nwith a support of at most $\\ell^{\\*}+1$, as theory predicts. Otherwise,\nthe error $e_{1}$ is rounded towards a column of $A$. Specifically,\nwe find the $\\ell^{\\*}-r$ coordinates of $e_{1}$ with maximal value,\nand choose a column of $A$ with ones on these columns (and zero otherwise).\nThis new column is added to $A_{1}$ to create $A_{2}$. Next, we\nsimilarly solve $\\min_{p_{2}}\\||A_{2}p_{2}-b\\||\\_{1}$ and obtain error $e_{2}$.\nIf $e_{2}=0$ that this means we have solved $Ap=b$ with $\\ell^{\\*}+2$\ncolumns, which is sub-optimal, but still rather effective. We continue\nto more such iterations, adding columns to $A_{i}$ as necessary,\none column at a time, until $e_{i}=0$. If the number of iterations\nis not too large, then this only requires solving linear programs\nof dimensions much smaller than ${\\ell^{\\*} \\choose r}$. As an example,\nin case $d=100$, $r=20$, and the eigenvalues are $\\lambda_{i}\\propto1/\\sqrt{i}$\nit turns out that $\\ell^{\\*}=61$. While ${\\ell^{\\*} \\choose r}={61 \\choose 20}=6\\cdot10^{15}$\nis huge, this method finds a solution with $120\\approx2\\ell^{\\*}$\ncolumns, and thus feasible, and also rather effective.\n\n#  **Response to the questions**\n\n* The regret and the MSE (or more generally, the loss) are tightly related.\nFor example, in the linear-MSE setting, the regret is the MSE of the\nproposed solution, minus the noise variance. The variance of the noise\nrepresents an inevitable loss that cannot be reduced by any representation.\nIt is thus subtracted from the MSE in order to focus on the part of\nthe MSE that can be reduced by optimization of the representation. \n* In Theorem 3, the feature vector is $\\boldsymbol{x}\\in\\mathbb{R}^{d}$\nwith $d<\\infty$ and its covariance matrix is $\\Sigma_{\\boldsymbol{x}}\\in\\mathbb{R}^{d\\times d}$,\nso it is a finite-dimensional continues vector, which takes infinite\npossible values. A pure representation of $\\boldsymbol{x}$ is a matrix\n$R\\in\\mathbb{R}^{d\\times r}$ so that the representation is $\\boldsymbol{z}=R^{\\top}\\boldsymbol{x}\\in\\mathbb{R}^{r}$,\nwhich is also a continues vector. A mixed representation allows to\nchoose the matrix $R$ randomly. In Theorem 3, we show that this randomization\nmay be supported on a finite set of matrices $\\\\{R_{1},R_{2},\\ldots,R_{\\ell^{*}+1}\\\\}$\nso that the representation is $\\boldsymbol{z}=R_{j}^{\\top}\\boldsymbol{x}$\nwith probability $p_{j}$. The theorem provides the optimal choice\nof set of matrices and the probabilities $\\\\{p_{j}\\\\}$.\n\nWe hope that this clarifies your questions, and will be happy to take further ones. We thank you for your effort in evaluating the paper\nand the positive assessment."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4852/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699957958755,
                "cdate": 1699957958755,
                "tmdate": 1699957958755,
                "mdate": 1699957958755,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "pnMLCcEVmD",
            "forum": "Uw8xvFqVAE",
            "replyto": "Uw8xvFqVAE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4852/Reviewer_HEJP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4852/Reviewer_HEJP"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a new game theoretic framework for learning low-dimensional representations $z= R(x) \\in \\mathbb{R}^r$ of unlabelled data $\\\\{\\vec{x}_i\\\\} \\subset \\mathbb{R}^d$ (where $r \\ll d$) in such a way that the learned representation would be useful for a variety of downstream learning tasks (specified by a class $\\mathcal{F}$ of response functions).\n\nThe contributions are both theoretical (optimal linear representations for linear response etc) and practical/algorithmic (more general representations and response functions). This paper uses a different form of game than the one used by (Dubois et al 2020).\n1. In (Dubois et al 2020), Player 1 chooses the learning task (input distribution, response function) and the score function. Then Player 2 (knowing the above) trains a representation for the input data. Finally, Player 1 evaluates the representation, using the chosen score function on an ERM classifier trained using the representation given by Player 2 (with IID data ~ (input distribution, response function)).\n\n2. In this paper the game is a 2PZS game with: (i) Player 1 (representation player) chooses the representation mapping $R \\in \\mathcal{R}$ (ii) Player 2 chooses the response function $f \\in \\mathcal{F}$, where the data distribution ($P_{\\mathbf{x}}$), loss function ($\\mathsf{loss}$), and the class of prediction rules ($\\mathcal{Q}$) are fixed. The payoff is given by\n$$\\mathsf{Payoff}(R,f) = \\mathsf{Regret}(R, f | P_{\\mathbf{x}}, \\mathsf{loss}, \\mathcal{Q}) = \\min_{Q \\in \\mathcal{Q} \\text{ on } \\mathbb{R}^r} \\mathbb{E}[\\mathsf{loss}(f(\\mathbf{x}),Q(R(\\mathbf{x})) )] - \\min_{Q \\in \\mathcal{Q} \\text{ on } \\mathbb{R}^d} \\mathbb{E}[\\mathsf{loss}(f(\\mathbf{x}),Q(\\mathbf{x}) )]$$\n\nThe game in this paper interchanges the order of the players (in a still useful way) and also abstracts the evaluation of the representation in order to make use of the 2PZS/saddle-point framework.\n\nThey then consider the minimax and maximin regret in terms of mixed strategies, which are equal due to the minimax theorem. The former is given by $$\\min_{\\mathcal{D}^{\\mathrm{rep}} \\in \\text{distributions on } \\mathcal{R}} \\max_{f \\in \\mathcal{F}} \\mathbb{E}_{R \\sim \\mathcal{D}^{\\mathrm{rep}}} \\mathsf{Regret}(R,f)$$ \n\nwhereas the latter is given by\n$$\\max_{\\mathcal{D}^{\\mathrm{fn}} \\in \\text{distributions on } \\mathcal{F}} \\min_{R \\in \\mathcal{R}} \\mathbb{E}_{f \\sim \\mathcal{D}^{\\mathrm{fn}}} \\mathsf{Regret}(R,f)$$ \n\nwith the goal of characterizing the optimal minimax (= maximin) regret as well as the optimal $\\mathcal{D}^{\\mathrm{fn}}$ (parametrized) and as well as the optimal $\\mathcal{D}^{\\mathrm{rep}}$ (parametrized) that lead to the optimal regret. They are able to do this in the linear MSE case. In the general case, they propose an algorithm to find distributions (mixtures) over finitely many functions and representations, with no theoretical guarantees.\n\nThey also consider the minimax regret in pure strategies, given by\n$$\\min_{R \\in \\mathcal{R}} \\max_{f \\in \\mathcal{F}} \\mathsf{Regret}(R,f)$$ \nwith the goal of finding an optimal saddle point representation $(R^\\ast, f^\\ast)$ in the linear MSE case.\n\nThe results in the paper are as follows:\n\n**The linear MSE setting:** Where the data $\\mathbf{x}$ is non-degenerate with zero-mean and covariance $\\Sigma_{\\mathbf{x}}$, the representations are linear ($R(\\mathbf{x}) = R^\\top \\mathbf{x}$ for $R \\in \\mathbb{R}^{d \\times r}$), the response functions are linear (response class is $\\mathcal{F}_S$, consisting of functions of the form $f(\\mathbf{x}) = f^\\top \\mathbf{x} + \\varepsilon$, where $\\varepsilon$ is heteroskedastic, mean-zero, noise, and the coefficient vector $f \\in \\mathbb{R}^d$ lies in the ellipsoid given by a positive definite matrix $S$), the loss function is mean squared error (MSE), and the prediction functions are also linear ($Q(\\mathbf{x}) = q^\\top \\mathbf{x}$).\n\n* Here they characterize the minimax pure regret, as well as the optimal saddle point pair $(R^\\ast, f^\\ast)$ giving the minimax regret w.r.t pure strategies (Theorem 2). Interestingly, the optimal representation involves _whitening_ the input vector and then projecting the result on the _top-$r$ eigenvectors_ of the $S$-adjusted version of the data covariance $\\Sigma_{\\mathbf{x}}$.\n* They also characterize the minimax/maximin mixed regret, as well as the optimal mixed strategies $(\\mathcal{D}^{\\mathrm{fn}}, \\mathcal{D}^{\\mathrm{rep}})$ leading to this regret (Theorem 3).\n\nThe characterization results also generalize to infinite dimensional feature spaces $\\mathcal{X}$ (rather than $\\mathbb{R}^d$) with some more assumptions (independent noise). This is only done in Appendix F.\n\n**General case**: Here they do implicitly assume some finite dimensional, differentiable, representation for the representations and response functions such that the saddle point problem giving minimax regret can be approximately-solved using an iterative procedure (proposed). The algorithm is motivated by the application of some theoretically-applicable concepts (for saddle point problems) --- iteratively adding to (and hopefully improving) the sets of representations and the response functions alternately,  using projected gradient descent on the regret w.r.t one (keeping the other set fixed), and then adjusting the weights assigned to the various representations and functions in the currently explored set using MWU (as in Freund and Schapire's adaptive game playing framework). However, there are understandably no theoretical guarantees, since the saddle-point problem involved is not convex-concave in general."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "* The game-theoretic framework proposed by the paper is very interesting and is novel (in terms of application to representation learning) to the best of my knowledge.\n* The results in the linear MSE case are very precise and complete. They give the intuitive expected results when the response class is $\\mathcal{F}_S, S=\\\\{I_d\\\\}$ = unit-norm linear functions (Example 5) and when the response class is $\\mathcal{F} = \\\\{I_d\\\\}$ = identity function (Appendix E). \n* The linear MSE results also seem to have some interesting consequences (depending on the structure and correlations of $S^{-1}$ and $\\Sigma_{\\mathbf{x}}^{-1}$) in general (interpreting the entries as some form of feature importance/correlation weights in the input data and in the prediction task respectively), which are very novel to the best of my knowledge, and could well be exploited in other works.\n* The representation learning algorithm for the general case is a substantial contribution which is well-motivated using existing theoretical frameworks, even in the understandable absence of theoretical guarantees.\n* The examples in the main paper are very useful in conveying the gist of the ideas.\n* The experiments, while limited, are well-thought-out (validating the general algorithm in the linear MSE case, comparison with standard PCA etc)."
                },
                "weaknesses": {
                    "value": "* The experiments are very limited given the scope of the paper (\"learning good representations for general prediction tasks\", as it may said-to-be). The experiments do not compare to any state-of-the-art practical methods for learning representations at all, especially when applying the representations to different tasks (which I feel is important given the lack of theoretical guarantees for the general case algorithm). However, this paper may be viewed as introducing a _novel framework_ for representation learning/evaluation that links it to saddle-point-game theory (in a way that prior works do not) and hence make it possible for any advances in solving hard saddle-point-games to lead to better approaches for learning representations.\n* The meat of the paper is mostly in what is effectively the supplementary material (after the references). The authors have albeit put substantial effort in trying to condense the ideas involved in the proofs as well as illustrate using good examples in the main section. However, it seems to be a losing battle, and any useful perusal of this paper must involve substantial parts of the supplementary."
                },
                "questions": {
                    "value": "None"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4852/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4852/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4852/Reviewer_HEJP"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4852/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698852652352,
            "cdate": 1698852652352,
            "tmdate": 1699636468652,
            "mdate": 1699636468652,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9u2A8u3wOU",
                "forum": "Uw8xvFqVAE",
                "replyto": "pnMLCcEVmD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4852/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4852/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answers to comments"
                    },
                    "comment": {
                        "value": "Our answers to the mentioned weaknesses are as follows:\n\n* Indeed, our main goal in this paper was to introduce this framework and explore its basic principles. We consider our proposed algorithm as a meta-algorithm, which demonstrates that the proposed approach is not limited to the linear setting, and agree that it requires extensive experimentation in applications. We have some ideas for such applications in mind, for example, using prior knowledge on region of interest in computer vision, or using prior knowledge on non-coding DNA in genomics. However, this requires domain-knowledge in determining the class of functions ${\\cal F}$, and various other details. This will divert the paper to these applications, rather than to the broad scope of representation learning. We hope that extensive experimentation would be achieved in future research, both by us, and by experts in various domains.\n\n* Our approach in writing the paper was to first present the general framework and its importance; second, explore it theoretically in basic linear settings; and third, propose an efficient algorithmic for the general case, which cannot be covered by theoretical analysis. We believed that all these components are vital, and thus deferred the technical aspects to the appendix, leaving them to in-depth readers. We understand that this comes at a cost, and we will re-inspect the paper from this aspect. We would be happy to take any suggestions for improvement (e.g., what important points are missing in the body of the paper), and will incorporate them into an updated version. \n\nThank you for a careful reading of the paper, a detailed summary, and a positive assessment."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4852/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699946950154,
                "cdate": 1699946950154,
                "tmdate": 1699946950154,
                "mdate": 1699946950154,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "3iejW4g1ly",
            "forum": "Uw8xvFqVAE",
            "replyto": "Uw8xvFqVAE",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4852/Reviewer_crzZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4852/Reviewer_crzZ"
            ],
            "content": {
                "summary": {
                    "value": "The paper considers the online prediction problem of predicting features for learning functions. First, the paper focuses on the problem of online linear regression with reduced dimensionality. Then, it considers more general settings, including mixed representations or/and logistic regression. Finally some preliminary experimental results are shown."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The problem is well-motivated and suited for the conference. The problem formulations are reasonable. Although the first problem might look somewhat elementary, the theoretical results are solid."
                },
                "weaknesses": {
                    "value": "So far the current results only focus on simple cases where the classifiers are linear. Ideally, some attempts to cope with nonlinear classifiers or nonlinear feature mapping would be appreciated."
                },
                "questions": {
                    "value": "Is it possible to extend the first result (linear regression) to kernelized classifiers? If not, can you explain why?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4852/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699230233893,
            "cdate": 1699230233893,
            "tmdate": 1699636468580,
            "mdate": 1699636468580,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1x7U31kwTn",
                "forum": "Uw8xvFqVAE",
                "replyto": "3iejW4g1ly",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4852/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4852/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answers to comments"
                    },
                    "comment": {
                        "value": "* **Response to the weakness**: Our proposed Algorithm 1 is applicable to any differential representation, not just linear. This algorithm alternates between optimizing an adversarial function (phase 1) and a new representation rule (phase 2). We have not focused on this in the body of the paper, but the optimization of the new representation rule in phase 2 is discussed in Appendix G.2 in detail. Algorithm 3 proposed there for the phase 2 optimization of the representation is based on computing gradients of the loss with respect to the representation rule (line 20). Therefore, the algorithm is applicable as long as these gradients can be computed (sub-gradients may also suffice). In Appendix H.4 we conducted a preliminary experiment with a one hidden-layer NN architecture, and showed the improvement of the regret. In future research we plan to explore our algorithm for non-linear representations in depth. \n\n* **Response to the question**: Yes, extension to representations that are based on infinite-dimensional features is possible. In Appendix F, we provide one possible such extension, to a Hilbert space setting (this is mentioned on page 5, in the remark before Example 4). In this setting, the original feature vector $x\\in\\mathbb{R}^{d}$ is mapped to a vector $R(x)=(\\psi_{1}(x),\\ldots,\\psi_{r}(x))^{\\top}\\in\\mathbb{R}^{r}$ where $\\\\{\\psi_{i}(x)\\\\}$ are non-linear feature-maps, taken from a Hilbert space of such maps. Our theoretical results on pure and mixed representations are generalized to this setting in Theorems 19 and 20. One can also consider the opposite setting \u2013 a linear representation followed by a non-linear (kernelized) predictor. Generalizing the theoretical results to this case is interesting, but appears to be challenging. This is because it requires obtaining a closed-form expression for $\\mathsf{regret}(R,f\\mid P_{\\boldsymbol{x}})$, as was obtained for the linear case in Lemma 16, Appendix E.2. In turn, this requires understanding how the non-linear feature map affects a linear representation $z=Rx$, which is difficult in general. In future research, it would be interesting to furnish conditions that allow to analyze such cases too. By the way, referring to the weakness above, this setting is another case in which the representation is non-linear. \n\nThank you for your effort in evaluating the paper and the positive assessment."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4852/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699944557698,
                "cdate": 1699944557698,
                "tmdate": 1699944557698,
                "mdate": 1699944557698,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]