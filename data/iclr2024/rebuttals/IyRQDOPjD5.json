[
    {
        "title": "Full Elastic Weight Consolidation via the Surrogate Hessian-Vector Product"
    },
    {
        "review": {
            "id": "G3XJlT81s3",
            "forum": "IyRQDOPjD5",
            "replyto": "IyRQDOPjD5",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7245/Reviewer_HSfz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7245/Reviewer_HSfz"
            ],
            "content": {
                "summary": {
                    "value": "This work studies the elastic weight consolidation (EWC) and tries to alleviate the computation burden of the Fisher Information Matrix (FIM). The main contribution is to propose a method for obtaining the full FIM. The performance is examined in the image classification and reinforcement learning."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper is relatively easy to follow but there still remains room to improve the organization. The vector product or matrix decomposition in learning is reasonable, and this trick most applied to sparsity, e.g. kernel matrix in Gaussian processes.\nThe examination of continual learning is relatively but not all standard in terms of benchmarks."
                },
                "weaknesses": {
                    "value": "**1. About the layout of this paper.**\n\nIt seems there is too much background knowledge about the computation bottleneck in EWC from Page2 to Page4. There misses some parse in paragraph or key points are not well highlighted. These make it a bit difficult to follow in logics.\n\n**2. About the contribution.**\n\nThe theoretical advantage to obtaining the full FIM is not well clarified in this work. Does it mean more information about the FIM brings better generalization in a theoretical sense? In the visual abstract, it seems the combined EWC can achieve more superiority than the full EWC, while this work focuses on the full EWC. Does this violate the research motivation? Meanwhile, it is necessary to connect some proposition to empirical observations.\n\n**3. About the evaluation in reinforcement learning.**\n\nI am afraid three Atari games are not typical in the continual learning domain. There exist more convincing benchmarks, e.g., Continual World, for continual reinforcement learning to examine the performance."
                },
                "questions": {
                    "value": "See the weakness part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7245/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698121782045,
            "cdate": 1698121782045,
            "tmdate": 1699636863287,
            "mdate": 1699636863287,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "i8l1fWsXdI",
                "forum": "IyRQDOPjD5",
                "replyto": "G3XJlT81s3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7245/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7245/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Official Review of Submission7245 by Reviewer HSfz"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their time. For point 3 we direct the reviewer to the General Comment. For point 2, we also direct the reviewer to the General Comment but also would like to clarify a couple points here. Firstly, this paper, and EWC in general, is not concerned with generalization. It aims to avoid catastrophic forgetting. Thus, our proposition shows that Full  EWC has a theoretical advantage in avoiding catastrophic forgetting in the lazy regime. Empirically we show that Combined EWC is better at avoiding catastrophic forgetting in general. Secondly, this work introduces both Full and Combined EWC and is focused on both. Thus, the visual abstract does not violate the research motivation, but summarizes our results. Combined EWC incorporates Full EWC and so fits within the remit of this work. The connection of the proposition and empirical observation is that the proposition explains the empirical observation that the relative benefit of using the Full FIM is greater in the lazy regime. We direct the reviewer to the first paragraph of Section 4 where this point is made. If the reviewer has suggestions on how to improve on this paragraph we will gladly incorporate them.\n\nFinally, we thank the reviewer in highlighting the usefulness of vector products and matrix decompositions in machine learning algorithms as well as the connection to sparsity in Gaussian process kernels. However, we kindly note that our SHVP is directly equivalent to the Hessian and not a sparse approximation. \n\nWe hope that this addresses all of the reviewers' concerns and are happy to engage further during this discussion period."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7245/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700056363815,
                "cdate": 1700056363815,
                "tmdate": 1700056363815,
                "mdate": 1700056363815,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "D6ItBQR1bl",
            "forum": "IyRQDOPjD5",
            "replyto": "IyRQDOPjD5",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7245/Reviewer_mrqD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7245/Reviewer_mrqD"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces the SHVP (Surrogate Hessian Vector Product) algorithm, as a means to compute the product of the Hessian matrix of a neural network with a given vector, without needing to compute the matrix itself (thus significantly reducing the computational complexity), but by relying on two nested backpropagations instead.\n\nUsing this, the authors are able to train models in a continual learning context, using the Elastic Weight Consolidation (Kirkpatrick et al. 2017) training objective to avoid catastrophic forgetting, while using the complete Hessian matrix, as opposed to a diagonal approximation as is often used in practice for computational reasons.\n\nThe paper experimentally shows that using the full Hessian matrix improves the model's capacity to retain its performance on older tasks, and that the best performance is obtained by combining the full EWC with its diagonal approximation, allowing an even equilibrium between older and more recent tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The article is clear, and provides good background and context to position its work in the larger literature.\n\nThe proposed algorithm is sound and well justified, and the experimental exploration of the impact of the different variants of EWC, in relation with the two training regimes is an interesting contribution.\n\nOverall, I believe the SHVP algorithm introduced here can be an useful tool to explore the Hessian matrices of neural networks."
                },
                "weaknesses": {
                    "value": "I have one main issue with the paper and its contribution: the positioning of the authors with regard to how and when their proposed Combined EWC could be used is very unclear.\n\nAs far as I can tell, the proposed SHVP algorithm trades the one-time computation of the full Hessian of the model for a double backprop through the NN at every iteration of the training. In particular, this means that computing the gradient associated with the EWC regularization term *requires computing an expectation over the datasets of the previous tasks*.\n\nMy understanding is that the main appeal of EWC is to keep some kind of summary of the previous tasks as the Hessian of their losses (approximated as diagonal or block-diagonal for computational efficiency). This relies on the idea that keeping around the training data of the previous tasks is either not desirable or not possible, otherwise one would simply train their model on all tasks simultaneously.\n\nHere, the proposed \"Combined EWC\" requires keeping access to the data of the previous tasks, and appears to be more computationally expensive than just training the model on the multiple tasks simultaneously.\n\nAs a result, it is unclear to me what does \"Combined EWC\" actually bring to the table: while not stating it clearly, the paper frames it as an algorithm that could be used in practice to train models in the continual learning setting. But given the above remarks, I fail to see when one would actually want to do that."
                },
                "questions": {
                    "value": "**How is the computation defined by Proposition 1 done in practice?**\n\nThe paper and appendix are not very detailed about it, and the joined code is barely documented, making it difficult to understand. I don't see how it would be possible to compute the double gradient defined for SHVP without retaining the whole computational graph associated with task A in memory (for performing the second backprop).\n\n**When would someone use SHVP or Combined EWC in practice?**\n\nGiven the previous discussion, I'm having a difficult time figuring when one would opt for using Combined EWC, instead of simply training the model on multiple tasks simultaneously, given EWC is supposed to be an approximation of that. What point is there for me to use an approximation that is not cheaper to compute than the actual thing?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7245/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698757050878,
            "cdate": 1698757050878,
            "tmdate": 1699636863145,
            "mdate": 1699636863145,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "exj9aJjjSY",
                "forum": "IyRQDOPjD5",
                "replyto": "D6ItBQR1bl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7245/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7245/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Official Review of Submission7245 by Reviewer mrqD"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their time and praise of many aspects of our work. We are glad to see that the reviewer also acknowledges the connection to the training regimes as being a contribution.\n\nThe reviewer\u2019s two main points appear to be summarized in the questions and so we will respond to those. For Question 2 on when to use Combined EWC we direct the reviewer\u2019s attention to the General Comment. However, to very briefly summarize, we provide a way to make Combined EWC nearly as efficient as Diagonal EWC. Thus, we would recommend using Combined EWC whenever EWC is an appropriate algorithm to use in practice. Diagonal, Full and Combined EWC should all be used in settings where continual learning is necessary. So as the reviewer correctly points out, data for Task A is lost after moving on to Task B for example.\n\nFor Question 1 on how the computation is done and its efficiency, we are glad to say that we have a clear answer for this. The first backward pass of the gradient at the end of a previous task needs to only be computed once. So to add the Full EWC regularization term when switching to a second Task B, at the end of Task A you store $\\theta_A$ (the optimal parameters for the previous task, as is always done for EWC) and the first derivative vector at the optimal point for Task A ($\\nabla_{\\theta_A}L(\\theta_A)$). By computing and storing this gradient vector you do not need the dataset for Task A anymore and this is only computed once. To then update the parameters for Task B **we do not use two nested backpropagations**. Thus, the point which says \u201cthe proposed SHVP algorithm trades the one-time computation of the full Hessian of the model for a double backprop through the NN at every iteration of the training.\u201d is not true. Backprop is used once an iteration. This is **the main contribution of our work**. To actionably address the reviewer\u2019s concerns we will add pseudocode to the appendix making this clear, and we also direct the reviewer\u2019s attention to Figure 1 and the paragraph directly next to it.\n\nWe hope that this addresses all of the reviewers' concerns and are happy to engage further during this discussion period."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7245/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700056229950,
                "cdate": 1700056229950,
                "tmdate": 1700056229950,
                "mdate": 1700056229950,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MLqj6imEAB",
                "forum": "IyRQDOPjD5",
                "replyto": "exj9aJjjSY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7245/Reviewer_mrqD"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7245/Reviewer_mrqD"
                ],
                "content": {
                    "comment": {
                        "value": "I'm sorry, but this answer does not ease my concern, quite the opposite actually.\n\nYou construct the EWC gradient as follows:\n$$\n\\\\nabla_\\\\theta EWC(\\\\theta) = \\\\nabla_{\\\\theta_A} \\\\Big[ (\\\\theta - \\\\theta_{A_{const}})^T \\\\; \\\\nabla_{\\\\theta_A} L_A(\\\\theta_A) \\\\Big]\n$$\n\nIf, as you claim, $\\nabla_A L_A(\\theta_A)$ is computed once and for all, and no double backprop is performed, then in the training for later tasks, it behaves like a constant wrt gradient computation. As a result, in the above formula, none of the terms have a gradient wrt $\\theta_A$, and this would mean that $\\nabla_\\theta EWC(\\theta)$ would be effectively computed as identically zero, rendering your proposed algorithm meaningless.\n\nSo as far as I can tell, given your code does apparently not produce such an identically zero gradient, either you are actually performing double-backprop without realizing it, or your code is not actually computing the same thing as the text of your paper claims it is. In both cases it is in my opinion a strong issue with your submission."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7245/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700470271179,
                "cdate": 1700470271179,
                "tmdate": 1700470271179,
                "mdate": 1700470271179,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Bf1NAv6kQG",
                "forum": "IyRQDOPjD5",
                "replyto": "Pvp6To61Wa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7245/Reviewer_mrqD"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7245/Reviewer_mrqD"
                ],
                "content": {
                    "comment": {
                        "value": "I'm sorry, but it seems to me you are not understanding my point. Your initial understanding of \u00ab\u00a0double backprop\u00a0\u00bb was correct, and your followup answer still does not answer my concern, which is a mathematical one. To phrase it in another way, my point is that **Proposition 1 does not hold if you are not doing double-backprop thought $\\\\nabla_ {\\\\theta_A} L_A(\\\\theta_A)$.**\n\nAllow me to be more explicit about the mathematical issue:\n\nLet us name $g_A = \\\\nabla_A L_A(\\\\theta_A)$. According to your reasoning, this term is computed once and for all at the end of task A, and the computational graph is not retained. Thus, as far as the backprop algorithm is concerned, this is a constant.\n\nNow, what you are computing is thus the gradient wrt to $\\\\theta_A$ of the quantity $ (\\\\theta - \\\\theta_{A_{const}})^T g_A$, but this expression is a constant wrt $\\\\theta_A$:\n- $\\\\theta$ and $\\\\theta_A$ are different variables, so $\\\\nabla_{\\\\theta_A} \\\\theta = 0$\n- $\\\\theta_{A_{const}}$ is (rightly) treated as a constant as well, so $\\\\nabla_{\\\\theta_A} \\\\theta_{A_{const}} = 0$\n- You claim to not proceed to a double-backprop, so $g_A$ is also a constant: $\\\\nabla_{\\\\theta_A} g_A = 0$\n\nAs a result, if your code actually does what you are claiming it is doing, then the gradient you are computing should be identically zero.\n\nI thank you for taking the time to answer this issue, because in my opinion it is a serious one. Indeed in my initial review, I assumed your algorithm was doing double-backprop even if you don't say it explicitly, because it is what is required for your algorithm to be mathematically valid.\n\nLooking again at your code, and from what I understand of how `jax` works, it seems to me that you are not actually computing the gradient of $ (\\\\theta - \\\\theta_{A_{const}})^T \\\\nabla_{\\\\theta_A}L_A(\\\\theta_A)$ with regards to $\\theta_A$, but with regards to $\\\\nabla_{\\\\theta_A}L_A(\\\\theta_A)$. If that is indeed the case, that means that what your code is actually computing is $\\\\nabla_\\\\theta EWC(\\\\theta) = (\\\\theta - \\\\theta_{A_{const}})$, which would be equivalent to using the regularizer $EWC(\\\\theta) = \\\\frac{1}{2}\\\\|\\\\theta - \\\\theta_A\\\\|^2$."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7245/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700502826290,
                "cdate": 1700502826290,
                "tmdate": 1700502826290,
                "mdate": 1700502826290,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "cK9J6qxpY5",
            "forum": "IyRQDOPjD5",
            "replyto": "IyRQDOPjD5",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7245/Reviewer_gTVN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7245/Reviewer_gTVN"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a method to calculate the full Fisher Information Matrix for EWC (instead of the more common diagonal Fisher) that is computationally and memory efficient. The paper then argues that combining the full EWC with a diagonal EWC is better than just one or the other. The paper then argues that EWC works better in the lazy training regime (with large parameter initialisations). Finally, in Section 5, the paper applies their method to an RL problem (3 Atari games sequentially shown)."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. I really like the algorithm for Full EWC in Section 3. I like that the authors looked at empirically verifying it in Appendix A.1, and would have liked to see more of this! \n\n2. Applying to RL / Atari is not done often enough in continual learning, so it was nice to see that experiment in this paper. \n\n3. I liked the proof sketches in the main text; I thought they were well-written and useful."
                },
                "weaknesses": {
                    "value": "1. It is important to talk about other related works that use eg block-diagonal Fishers for EWC in Section 2. For example, Ritter et al., 2018 (A Scalable Laplace Approximation for Neural Networks). \n\n2. Permuted MNIST is an old benchmark with many problems. It is difficult to draw many conclusions of note from it due to the various issues with it (see for example Farquhar and Gal (Towards Robust Evaluations of Continual Learning) or Swaroop et al (Improving and Understanding Variational Continual Learning) for discussions). Additionally, the authors in this paper only use 5 tasks, which is very few, making it difficult to draw any real conclusions. It would be great if the authors ran for significantly more tasks to see if their conclusions/results still hold (eg 20 tasks). \n\n3. When comparing Figures 2 and 3, I'm not really sure if the lazy training regime is better for EWC! It looks like Figure 2 often has higher performance, at least on everything but task A's accuracy after training on the last task. Could the authors report other metrics like overall average accuracy (and maybe forward/backward transfer) too? \n\n4. Proposition 2 seems like it is re-writing that, under conditions like constant covariance (ie a quadratic loss landscape?) and mean-squared error loss, that Laplace approximation is ideal. I am not sure that there is anything new here: this is the reason that eg the EWC paper used the Laplace approximation / FIM in the regulariser / Bayesian approach. I found it odd that, in the Appendix, the authors prove this via \"Bayes Optimal estimators\" (ie looking at predictions at a test point?) and then take the limit as the Gaussian approximation becomes a delta (ie reduce the covariance to 0). This looks like a simple MAP estimation to me? Please let me know if I am missing something here. \n\n5. In the text on page 7, the authors argue why the landscape may be (more) locally convex in the lazy training regime, because parameter values do not change much during training. I am not sure I am convinced by this: just because the parameter values do not change (relatively) very much, this does not mean that the loss landscape that the parameters move through is better-behaved: it could still be highly non-convex. Is there previous literature on this (or could the authors design an experiment to show this)? \n\n6. I do not understand the intuition for why Combined EWC is better than Full EWC or diagonal EWC. Diagonal EWC seems to perform very well in Figures 2 and 3 already. In Figure 4, it does not forget task 2 when training on task 3 (although it does forget task 1), against the authors' conclusion (that Diagonal EWC prioritises new tasks). I think I need much more evidence of these claims (eg that Diagonal EWC prioritises new tasks while Full EWC prioritises old tasks) to believe them sufficiently. \n- Also, although it is nice to have an RL experiment in Section 5, having only 3 tasks/games is too few to draw conclusions."
                },
                "questions": {
                    "value": "Please see Weaknesses section. More minor questions / comments: \n1. Note that the authors are using the empirical Fisher, not just the Fisher / FIM, in Equation 1 (and throughout the paper). See for example Kunstner et al., 2020 (Limitations of the Empirical Fisher Approximation for Natural Gradient Descent) for a discussion. \n2. I think, in the text after Equation 6, the authors meant 'low uncertainty' and not 'high uncertainty'? \n3. At the bottom of page 8 (and in Sec A.7.1) the authors use a network of half the size and see lower performance. I do not see how this helps understand if the experiment in Section 5 is sufficiently over-parameterised or not."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7245/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698786280095,
            "cdate": 1698786280095,
            "tmdate": 1699636862987,
            "mdate": 1699636862987,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LfvDGyIL9D",
                "forum": "IyRQDOPjD5",
                "replyto": "cK9J6qxpY5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7245/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7245/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Official Review of Submission7245 by Reviewer gTVN (Part 1 of 2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their time, constructive comments and kind acknowledgement of a number of our work\u2019s strengths. We will address each of the points raised as Weaknesses below and then subsequently answer the points raised as Questions after.\n\nWeaknesses:\n1. On the discussion of Ritter et. al. (2018) [1]. We will gladly add this citation. We would like to point out that we do cite McInerney et. al. (2021) [2] which is a more recent work building directly on the work of Ritter et. al. (2018) and we do mention this work in our Introduction.\n2. Please see the general comment for the overall discussions on our experiments. We would just like to elaborate on one point here. This experiment uses dense neural networks. Thus, arguments around the unnatural nature of the permuted images [3] are not as relevant in a network without architectural biases such as convolution which assume spatial contiguity of objects. Additionally, avoiding catastrophic forgetting with a dense network is difficult (as our experiments highlight), even on such a simple task with an ideal input space. Consequently, even after five tasks we see a clear result on the behaviour of each of the algorithms. Moreover, [4] makes the point that Permuted MNIST is not appropriate for comparison when network architecture or other model design decisions change. However, in our controlled experiments all models and benchmarks use the exact same architecture. We believe that these points, coupled with the general comment above, justify the use of Permuted MNIST in our case. We will add the two given citations to our revised version and use them to be clearer about the design decision and limitations of our experiments - as we already do with work making a similar point such as [5].\n3. The reviewer is indeed correct, the feature learning regime does out-perform the lazy regime. However, this is not the point we were making in Section 4. In this section we note that the relative benefit of using the full FIM in the lazy regime is better than the feature learning regime. In other words, the comparison is not between the green lines in Figure 2 and Figure 3, but rather a comparison of how much higher the green line is over the blue and orange in Figure 3, compared to the same gap in Figure 2. It is a more subtle point, and we will aim to make this clearer in the revised version of the paper, by more clearly annotating Figure 2 and 3. We will also elaborate further in both figures' captions. We thank the reviewer for drawing this to our attention. We hope it is clearer now that what matters is that the green curve is much higher than the blue and orange curves in Figure 3, but only slightly higher in Figure 2 (note it still gets the best of both blue and orange curves in both cases).\n4. and 5. We believe points 4. and 5. go together and so we address them at once. We  hope that the clarification on point 3 will also help here. Proposition 2 is indeed similar to a MAP proof of optimality while also connecting the covariance of the parameter space to the FIM. This is the basis of the original EWC work. Our contribution here is to connect the assumptions necessary for this optimality to hold, to the two regimes of training which have been identified in the literature [6]. To our knowledge this is a new connection and one which we found due to the results of Permuted MNIST - that the **relative performance** when including the full FIM is greater in the lazy rather than feature learning regime. This leads to our response for point 5. In the lazy regime the parameters, which are initialized with a Gaussian of fixed covariance, do not change from their initial values much. Thus, they remain distributed by the same Gaussian from which they are sampled. As a result the necessary assumptions for the MAP proof to hold are true. In the feature learning regime, parameters can change and become potentially more coupled [7]. So the same argument (and the assumptions for EWC to be optimal) do not hold. Finally, it is indeed well established in the literature that in the lazy regime (often called the NTK regime [6]) the local loss landscape is smooth and in the infinite width limit (with the actual NTK) [8] the loss landscape is exactly convex [9,10,11]. We mention this in the last paragraph of page 7 but will gladly provide more citations as the reviewer requests, since this is a well-established point [6,7,8,9,10,11]."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7245/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700057655250,
                "cdate": 1700057655250,
                "tmdate": 1700057655250,
                "mdate": 1700057655250,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SLIYxah45n",
                "forum": "IyRQDOPjD5",
                "replyto": "LfvDGyIL9D",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7245/Reviewer_gTVN"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7245/Reviewer_gTVN"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thanks to the authors for their rebuttal. \n\n1. Thank you for pointing this out to me. \n\n2. My issue is more that there is not enough evidence if one just looks at Permuted MNIST. There are a host of things going on with Permuted MNIST (such as (i) 5 tasks being far too few to test any continual learning algorithm given the model size, and (ii) each new task is so different, in terms of gradients, to others, which is usually very unrealistic), and I need to see more evidence on other benchmarks before I believe the claims being made. \n\n3. Again, thanks for pointing this out. However, I really am not sure I agree with the authors' conclusions. Comparing the difference between green and blue lines in Figure 2 vs 3: the difference looks similar to me! But I can only inspect this visually. Perhaps the authors could devise some metric to argue this point? Comparing the green and orange lines: I can see that there is maybe a difference (mainly in the top left panel?). However, Orange is 'Full EWC', and it now seems like Full EWC performs worse (compared to diagonal) in the lazy regime (ie in Figure 3)?\n\n4. and 5. In my mind this is not a surprising or interesting result. In the NTK regime, where covariances remain similar, full EWC is always going to do very well, and this is a straightforward application of Bayes rule (and the motivation for introducing EWC as an algorithm in the first place). I realise this is my opinion, and others may disagree that this is obvious. So perhaps the authors, other reviewers and/or the AC can disagree with me, and that can go into the decision-making for this paper. \n\n6. I see, I clearly misunderstood earlier. Similarly to in point 3, I recommend the authors try to formalise this more. For example, by having some simple metric that measures performance drop for just the last task vs performance drop in previous tasks. This would help sell this much better. I would then also repeat the experiment on more benchmarks and confirm that these trends hold! \n\n7. I realise how annoying it is to be asked for more experiments, but I do really think that in this kind of paper -- where you are (i) introducing a new algorithm that you say is computationally efficient, and (ii) making empirical claims regarding Combined EWC -- it is important to show trends (particularly for (ii)) hold. I really think this would make the paper much stronger. \n\nA final passing comment (as potential future work!): another way that this work could be significantly improved would be to look theoretically into why Diagonal EWC and Full EWC might be acting in the ways they do (in terms of performance on the previous task vs tasks a long time ago). Some theory here would be extremely interesting, I think."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7245/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700164836955,
                "cdate": 1700164836955,
                "tmdate": 1700164836955,
                "mdate": 1700164836955,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]