[
    {
        "title": "Towards Subgraph Isomorphism Counting with Graph Kernels"
    },
    {
        "review": {
            "id": "zHicmPV3wO",
            "forum": "wCRTEOIdmf",
            "replyto": "wCRTEOIdmf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5943/Reviewer_bo6K"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5943/Reviewer_bo6K"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigates whether graph kernels can count substructures such as 3-stars and triangles. To improve the kernels' performance, the authors propose to re-embed the graphs into a second feature space using either the polynomial or the gaussian kernel. The paper also proposes an improvement to the family of WL kernels. The experimental results demonstrate that graph kernels can better count substructures than the baseline GNNs in most cases."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This is the first work to investigate whether graph kernels can count substructures. The work is purely empirical, but some of the conclusions are likely to be useful to practitioners.\n\n- The kernels outperform the baselines on most of the datasets. The proposed neighborhood-aware color assignment algorithm seems to improve over the standard color assignment algorithms.\n\n- The presentation is clear and the paper is easy to read."
                },
                "weaknesses": {
                    "value": "- I would suggest the authors give some context or motivate why it is important to count subgraphs/substructures. Are there any individuals or communities interested in this task? For the experiments, the authors construct some synthetic datasets and they also employ datasets whose inherent task is different from the one considered in this paper (graph classification datasets from the TUDataset repository). Thus, it is not clear to me whether there is interest into this task.\n\n- The originality of the paper is limited. The idea of re-embedding the input graphs into a second feature space and the proposed implicit schemes are not new and have been proposed in prior work [1]. However, in [1] the kernels are evaluated in a different task (graph classification). Furthermore, the neighborhood-aware color assignment algorithm is a trivial modification of the color assignment algorithms of WL kernels.\n\n- The study is purely empirical and no theoretical results are provided. Although this is not generally a weakness, I would expect such a paper to provide more extensive experimental results, ablation studies, etc. In my view, the experimental evaluation is limited and thus not fully convincing.\n\n- The baseline methods are weak. While high-order WL algorithms are included into the list of kernels, only GNNs that are at most as powerful as 1-WL are considered. The results would be more convincing if higher-order models such as the ones proposed in [2],[3] and [4] were included into the list of baselines.\n\n- Definition 3.4 is wrong. For a function to be a kernel, it needs to be symmetric and positive semi-definite.\n\n[1] Nikolentzos, G., & Vazirgiannis, M. \"Enhancing graph kernels via successive embeddings\". In Proceedings of the 27th ACM International Conference on Information and Knowledge Management, pp. 1583-1586, 2018.\\\n[2] Morris, C., Ritzert, M., Fey, M., Hamilton, W. L., Lenssen, J. E., Rattan, G., & Grohe, M. \"Weisfeiler and leman go neural: Higher-order graph neural networks\". In Proceedings of the 33rd AAAI Conference on Artificial Intelligence, pp. 4602-4609, 2019.\\\n[3] Morris, C., Rattan, G., & Mutzel, P. \"Weisfeiler and Leman go sparse: Towards scalable higher-order graph embeddings\". Advances in Neural Information Processing Systems, pp. 21824-21840, 2020.\\\n[4] Maron, H., Ben-Hamu, H., Serviansky, H., & Lipman, Y. \"Provably powerful graph networks. Advances in Neural Information Processing Systems, pp. 2156-2167, 2019."
                },
                "questions": {
                    "value": "- The standard WL algorithm cannot detect triangles in case no node features are available. Features/labels are not available for several of the considered datasets. Does that mean that WL and WLOA fail to count triangles on those datasets? Is this why there is a large difference in performance between those two kernels and 3-WL on those datasets?\n\n- Since NIE-WL embeds graphs into a larger feature space than WL, it is computationally more expensive. Could you report the increase in running time due to the neighborhood information extraction component?\n\n- In Equation 5, would it make sense to assign different weights to the WL and NIE components?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5943/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698414430714,
            "cdate": 1698414430714,
            "tmdate": 1699636632935,
            "mdate": 1699636632935,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "XyVOyU8BKz",
            "forum": "wCRTEOIdmf",
            "replyto": "wCRTEOIdmf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5943/Reviewer_oJKS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5943/Reviewer_oJKS"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigates the application of enhanced graph kernels, including polynomial and Gaussian variants, for approximating subgraph isomorphism counting. The authors conduct a set of experiments to showcase the efficacy of these enhanced graph kernels in capturing substructure correlations within diverse graphs."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper introduces a novel approach by utilizing graph kernels for subgraph isomorphism counting, offering a fresh perspective on this important problem.\n\n2. The presentation of the paper is clear and concise, making it accessible and enhancing the reader's comprehension of the proposed methods.\n\n3. The authors provide a compelling set of experiments that empirically demonstrate the advantages and effectiveness of the enhanced graph kernels."
                },
                "weaknesses": {
                    "value": "1. The paper could benefit from the inclusion of a clearly defined real-world application or use case to highlight the practical significance of the problem and its solution. While the paper discusses various applications of subgraph isomorphism counting, a concrete application or case study would better illustrate the real-world relevance of the research.\n\n2. The complexity and computational efficiency of the proposed method are not adequately discussed. It is essential to conduct a thorough analysis of the runtime complexity and compare it with existing models to provide insights of its efficiency.\n\n3. The proposed method inherits the high computational cost associated with graph kernels, which limits its scalability, particularly when dealing with large graphs. Discussing potential strategies to mitigate this limitation would be beneficial.\n\n4. The inconsistency in the y-axis scaling of Figure 4a compared to other subfigures should be rectified for clarity and to prevent any potential misunderstanding.\n\n5. The experiments show that GNN-based methods consistently outperform kernel-based methods on ENZYMES and NCI109 datasets. It would be valuable to expand the experimental scope to determine whether similar conclusions hold for other heterogeneous datasets.\n\n6. In terms of baseline selection, the best performing model CompGCN was proposed in 2020. It is desirable and more convincing to compare with recent stronger models.\n\n7. Consider adding a comparison with higher-order GNNs, such as the references [1], [2], and [3], to provide a more comprehensive assessment of the proposed approach.\n\n[1] Christopher Morris, Martin Ritzert, Matthias Fey, William L Hamilton, Jan Eric Lenssen, Gaurav Rattan, and Martin Grohe. Weisfeiler and leman go neural: Higher-order graph neural networks. AAAI 2019\n[2] Bouritsas G, Frasca F, Zafeiriou S, Bronstein MM. Improving graph neural network expressivity via subgraph isomorphism counting. TPAMI 2022\n[3] Li J, Peng H, Cao Y, Dou Y, Zhang H, Philip SY, He L. Higher-order attribute-enhancing heterogeneous graph neural networks. TKDE 2021"
                },
                "questions": {
                    "value": "See Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5943/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698630733230,
            "cdate": 1698630733230,
            "tmdate": 1699636632815,
            "mdate": 1699636632815,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "USCz2Awr0b",
            "forum": "wCRTEOIdmf",
            "replyto": "wCRTEOIdmf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5943/Reviewer_xQZL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5943/Reviewer_xQZL"
            ],
            "content": {
                "summary": {
                    "value": "This paper extensively studies the ability of graph kernel methods to solve subgraph isomorphism counting problems, the problem to determine the number of subgraphs matched to the (small) pattern graph in the given (large) input graph. Since this problem is #P-complete and thus exact count can hardly be obtained for larger graphs, so approximation algorithms and learning approaches using neural networks has been investigated. This paper extends graph kernel methods, which have been mainly used for graph classification and isomorphism testing that are binary decision problems, to be used for #P counting problems. Extensive experiments reveals us that the proposed approach beats the existing neural network approach for homogeneous datasets where all the vertex labels are identical."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The experiments are conducted on real datasets (including heterogeneous ones where there exists different vertex labels). Also, various kinds of graph kernels as well as various methodologies (e.g., w/ or w.o./ normalization, combination with kernel tricks) are tested, that make the experimental results more rigorous."
                },
                "weaknesses": {
                    "value": "I think this paper fails to present any advantages of graph kernel methods for solving subgraph isomorphism counting problems over the other existing methods.\n* For homogeneous data, this paper demonstrates that the 3-WL kernel combined with the proposed neighborhood information extraction outperforms the existing learning approach where neural network is used directly. However, for homogeneous data, as described in Section 2, there are various non-learning approximation algorithms like sampling (Jha et al., 2015) and color coding (Bressman et al, 2019). Thus, for homogeneous data, the performance should also be compared with these methods.\n* For heterogeneous data, the best of the kernel method exhibits comparable results to neural network-based methods (RGIN, Liu et al., 2020). However, the best kernel used in the kernel method differs for different topologies: \"GR, Ridge, RBF\" for ENZYMES, and \"2-WL, Ridge, Linear, NIE\" for NC1109. The author says that the fact that the 3-WL kernel (working well for homogeneous data) fails for heterogeneous data \"serve as a foundation for further research and advancements in the field of graph kernels,\" but there are almost no consideration and examination for this fact in this paper.\n\nTo facilitate the research on graph kernel methods, at least some considerations and examinations are needed to explain:\n* Why 3-WL kernel, which works well for homogeneous data, does not work well on heterogeneous data?\n* Why neighborhood information extraction, which is effective for homogeneous data, is less effective for heterogeneous data?\n\nMinor comment:\nThe descriptions for Weisfeiler-Leman algorithm in pages 3 and 4 are hard to grasp, since there are almost no descriptions for the $\\texttt{Color}$ procedure; it is only said as \"a function to assign colors to to vertices.\" $\\texttt{Color}$ seems to have two arguments, but it cannot be understood that what are given as arguments and what is returned as a result. Please improve the description for WL algorithm since it relates to the neighborhood information extraction that is one of the core contributions of this paper."
                },
                "questions": {
                    "value": "None."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5943/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5943/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5943/Reviewer_xQZL"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5943/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698653284773,
            "cdate": 1698653284773,
            "tmdate": 1699636632700,
            "mdate": 1699636632700,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]