[
    {
        "title": "Layer-wise linear mode connectivity"
    },
    {
        "review": {
            "id": "ewoEMHypIC",
            "forum": "LfmZh91tDI",
            "replyto": "LfmZh91tDI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8060/Reviewer_G1sx"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8060/Reviewer_G1sx"
            ],
            "content": {
                "summary": {
                    "value": "The presented paper proposes a new concept, layer-wise linear mode connectivity, and shows that it's possible to explain it from a robustness perspective."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The presented paper is well-written and is easy to follow. \n- The proposed phenominon is interesting and worth furthur study. \n- The paper provides specific practice guidance for federated learning.\n\n------\nAfter reading the authors' responce, I decide to keep my current rating unchanged."
                },
                "weaknesses": {
                    "value": "I don't see how robustness is possible to explain the proposed LLMC, since the LLMC is concerning the relationship of two models while robustness concerns more about the relationship of a model with a random perturbation. The authors claimed in Section 5.1 that \"the networks are much more robust to random perturbations compared to the direction of interpolation between models\". This is not surprising to me, because when togetherly trained with sufficiently many epochs, the two models should be in the same basin (as the original LMC suggests), and the direction of interpolation between models is towards the basin while a random direction might not. I don't see how the proposed robustness explaination goes furthur than the same-basin explanation in original LMC paper."
                },
                "questions": {
                    "value": "- In Section 5.1, how is \"robustness to random perturbations\" exactly calculated? \n- There are two competing definition of LLMC, namely the single layer one and the cumulative one. Which one is used in Section 5.1?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8060/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8060/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8060/Reviewer_G1sx"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8060/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698215584388,
            "cdate": 1698215584388,
            "tmdate": 1700693804280,
            "mdate": 1700693804280,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hIDwDPArDn",
                "forum": "LfmZh91tDI",
                "replyto": "ewoEMHypIC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8060/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8060/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for emphasizing the relevance of our paper, and its practical usefulness. In the following we address their questions:\n\n1) Robustness to random perturbations is computed in the following way: (i) we compute the distance between the two networks in the layer of interest (ii) we generate random vectors of the same norm (iii) we move the layer according to this random change (iv) we compute the loss of the obtained network. This is performed 5 times and the results are averaged.\n\n2) In Section 5.1 we were using only single layer aggregation. Cumulative aggregation is investigated in Section 3 in order to improve our understanding of which layers actually lead to the barrier between networks.\n\nWeakness:\n\n**I don't see how robustness is possible to explain the proposed LLMC**: We fully agree with you that robustness alone does not explain LLMC, but our results show that the full picture is complicated. First of all, in our experiments networks are trained so that they are not in the same basin, evident by the large barrier of full averaging. This differs from the original LMC paper, where a single network is trained up to a certain point, from which on two networks are finetuned - in this case, one would expect them to be in the same basin. If networks are not in the same basin, then the barrier size is influenced to some degree by robustness: the more robust a model, and thus the more flat the loss surface around it, the lower the barrier when perturbing in any direction. However, our conclusion from our robustness experiments was that layer-wise perturbations in the direction of averaging can increase the loss significantly more than a layer-wise perturbation in a random direction (see also our answer to Reviewer VziZ). This result is indeed surprising, and we do not claim to fully understand the interplay between robustness (in particular noise magnitude), perturbation direction, and barrier size. We believe that our paper highlights this issue and provides some valuable insights into this complex and interesting phenomenon."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8060/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700266398233,
                "cdate": 1700266398233,
                "tmdate": 1700266398233,
                "mdate": 1700266398233,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0GwkUCZF9X",
                "forum": "LfmZh91tDI",
                "replyto": "ewoEMHypIC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8060/Reviewer_G1sx"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8060/Reviewer_G1sx"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their responce and clarification. I think I have some misunderstanding in my original comment. I agree with the authors' claim that the robustness result is surprising and is different from the same-basin case. I think the current overall organization of this paper is kind of confusing. Based on this, I decide to keep my current rating to this paper as weakly accept and encourage the author to reorganize the paper and make it clearer in their future revision, especially in the following aspects:\n- Besides proposing the definition of LLMC, clarify when will this phenominon happen.\n- Make every term clearly defined. For example the \"robustness to random perturbations\". Although the authors clarified this term but I don't think it is nowhere defined in the paper.\n- As there are multiple definitions about LLMC, it's better to clarify in each experiment is it looking at which version of LLMC."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8060/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700693773660,
                "cdate": 1700693773660,
                "tmdate": 1700693773660,
                "mdate": 1700693773660,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Tk7XO6pQii",
            "forum": "LfmZh91tDI",
            "replyto": "LfmZh91tDI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8060/Reviewer_GMLC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8060/Reviewer_GMLC"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies layer-wise linear mode connectivity (LLMC) and finds that in most cases, there are no barriers in LLMC. The authors also study the learning dynamics behind LLMC  from the perspectives of robustness and loss landscape. Also, implications are given regarding the partial personalization in federated learning."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The motivation for studying layer-wise linear mode connectivity (LLMC) is novel and interesting. It contributes new ideas in the community of linear mode connectivity.\n* The authors study LLMC from different perspectives which are thorough.\n* The experiments are solid. The ViTs and LLMs are also studied to show the prevalence of the findings across a large range of model architectures.\n* The findings and takeaway insights are intriguing."
                },
                "weaknesses": {
                    "value": "Despite of the strengths listed above, I think this paper should be improved in the following aspects.\n* The analysis of cumulative LLMC (LLMC about the group of layers) needs further investigation. The authors should study the LLMC of $l$ consecutive layers on different parts of the models. The authors can conduct an experiment with a moving window of $l$ layers to show the group-layer-wise connectivity. For instance, given a 20-layer network with $l=5$; the experiments should be conducted: LLMC of 1-5 layers, LLMC of 2-6 layers, LLMC of 3-7 layers, ..., LLMC of 16-20 layers. Current experiments cannot jump to the conclusion that the middle part of layers will cause barriers because you didn't control the variable of the number of aggregated layers $l$. \n* For the convexity of LLMC, I think the current Theorem is not enough and is far from the practice. Theorem 4.1 didn't consider the non-linearity of the neural networks, i.e., the activation functions. I think a more solid theorem should be derived to verify the convexity of LLMC.\n* The discussions on personalized federated learning should be given more focus and I think this is an important point for this paper to have a broader audience and be more applicable to practices. However, I think current implications, experiments, and discussions are not enough. \n    * The methods of personalized layers or layer-wise aggregation in personalized federated learning should be implemented and compared.\n    * Based on the findings of this paper, a new method should be devised, but the paper didn't showcase the applicability by proposing a simple method.\n    * Experiments on feature shift non-iid in federated learning should be conducted to verify the claim that personalized-layer-based techniques can work in feature shift federated learning."
                },
                "questions": {
                    "value": "See the above weaknesses for details. I suggest the authors provide additional results according to the weaknesses and I am happy to raise my scores once my concerns are relieved."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8060/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8060/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8060/Reviewer_GMLC"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8060/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698328026571,
            "cdate": 1698328026571,
            "tmdate": 1700466471485,
            "mdate": 1700466471485,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CHRHHbHSRU",
                "forum": "LfmZh91tDI",
                "replyto": "Tk7XO6pQii",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8060/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8060/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for appreciating our work and are happy to improve it according to the proposals made. In the following we address the questions raised:\n\n1) **The authors should study the LLMC of consecutive layers on different parts of the models.**: We thank the reviewer for this idea of an interesting experiment. We performed several runs of it  and included the results in the appendix of the paper (App. 3). The results indicate that a small sliding window allows the same conclusion as our initial experiments (i.e. the barrier is produced by the middle layers), but the larger the sliding window is, the more uniform the picture becomes. We want to emphasize that we also performed random cumulation (i.e. averaging layers in random order) and minimal cumulation (i.e. averaging group of the layers that seem not to cause barrier) as well (see Figure 7 in the appendix) in order to check our conjecture about middle layers. Our results, including this new experiment, support this conjecture.\n\n2) **Theorem 4.1 didn't consider the non-linearity of the neural networks, i.e., the activation functions.**: The goal of Theorem 4.1 was not to explain the behavior in practical neural networks, but to provide a useful and interesting intuition about the difference between layer-wise and full aggregation. We do not draw any conclusion about the convexity of layer-wise averaging in non-linear neural networks from this theorem. We agree with you that investigating this challenging theoretical question further will deepen our understanding of the phenomenon, and makes for interesting future work.\n\n3) **The discussions on personalized federated learning**: We agree with the reviewer that the personalized federated learning experiments and discussion is not in the focus of the paper. We want to emphasize that PFL was one of the examples of an application where LLMC can be of use - see general comment - but our results do not provide a practical method, yet. Nevertheless, (i) we do compare to the existing approaches with partial averaging, such as aggregation of the classifier layer only or of the feature extraction layers (i.e. everything except for classifier), which are the most prominent partial averaging approaches in the existing literature. (ii) We try to conjecture an approach that will be useful in PFL using both our robustness experiments insights (averaging only critical or only non-critical layers) and cumulative aggregation insights (averaging only middle layers or only non-middle ones). (iii) In addition to our empirical results for this approach, we performed an additional experiment on DomainNet (a dataset with feature shift). The experiment and its results are described in the general comment."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8060/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700266352793,
                "cdate": 1700266352793,
                "tmdate": 1700266352793,
                "mdate": 1700266352793,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FPY4SKFsKu",
                "forum": "LfmZh91tDI",
                "replyto": "CHRHHbHSRU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8060/Reviewer_GMLC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8060/Reviewer_GMLC"
                ],
                "content": {
                    "title": {
                        "value": "Post-rebuttal"
                    },
                    "comment": {
                        "value": "I appreciate the authors' effort in the LLMC experiments with sliding windows, and it addresses my concern.\n\nAs a result, I will raise my score to 6. Thanks."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8060/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700466162068,
                "cdate": 1700466162068,
                "tmdate": 1700466162068,
                "mdate": 1700466162068,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wH1SqhetR5",
            "forum": "LfmZh91tDI",
            "replyto": "LfmZh91tDI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8060/Reviewer_zQV8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8060/Reviewer_zQV8"
            ],
            "content": {
                "summary": {
                    "value": "The paper \"Layer-wise Linear Mode Connectivity\" presents an in-depth exploration of barriers on the loss surface observed during model averaging, introducing the concept of layer-wise linear mode connectivity (LLMC). The authors investigate the behavior of individual layers, concluding that the averaging barrier at this level is consistently minor compared to the full model. A significant finding is the propensity of middle layers to create cumulative averaging barriers, suggesting potential connections to existing studies on the neural network training process. The research also examines personalized federated averaging, highlighting the inherent challenges in distinguishing between layers that carry local knowledge versus those that carry common knowledge."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The narrative construction is good, and the literature review is comprehensive and informative.\n- The reviewer appreciates the bold conjectures made throughout the paper. Although these may not always be rigorous, such daring speculations can be beneficial in stimulating further research.\n- Certain experimental outcomes are intriguing, for instance, the most sensitive layers of ViTs are the early attention and fully-connected weights; averaging directions exhibit a peculiar characteristic of having a much higher curvature than random ones of the same norm."
                },
                "weaknesses": {
                    "value": "### Weaknesses\n- The reviewer acknowledges some insightful observations in this paper. However, from the reviewer's perspective, while the findings are interesting, they may not introduce profound novelty.\n- The presented phenomenon of smaller layer-wise barriers may not be surprising. For instance, if we consider a situation where all layers are created equally, the averaging of only $\\frac{1}{s}$ layers would typically result in approximately $\\frac{1}{s}$ of the loss increase induced by averaging all layers. It is plausible that the observation of Layer-wise Linear Mode Connectivity (LLMC) is due to the averaging of a smaller number of layers rather than a unique layer-wise structure. If the loss increase from averaging $\\frac{1}{s}$ layers is significantly less than $\\frac{1}{s}$ of the loss increase induced by averaging all layers, then this observation would lend more credence to the LLMC conjecture.\n- The theory is for single layer interpolation, whereas the experiments have been conducted on a subset of layers.\n\n### Minor issues\n- There seems to be an error in the author name of the paper \"Which layer is learning faster? A systematic exploration of layer-wise convergence rate for deep neural networks\". The surname of the first author could possibly be Zhou instead of Yixiong Chen.\n- The citations for Singh & Jaggi (2020); Ainsworth et al. (2022); Jordan et al. (2022) on page 3 should use \\citep instead of \\citet.\n- There's a typographical error on page 9: 'to be less communication' doesn't make sense in the context."
                },
                "questions": {
                    "value": "- The reviewer is unclear as to why Fig. 2 indicates that \"neither the shallowest nor deepest layers cause the barrier, but the middle ones do\". In Fig. 2 (a), both middle and deep layer averaging seem to result in high losses, and Fig. 2 (a) implies high losses upon averaging both middle and shallow layers.\n- The layer-wise convexity appears straightforward since the single-layer interpolation $\\boldsymbol{X} \\boldsymbol{W}^{(1)} \\ldots\\left(\\alpha \\boldsymbol{W}^{(k)}+(1-\\alpha) \\boldsymbol{W}^{\\prime(k)}\\right) \\ldots \\boldsymbol{W}^{(L)}$ is a linear function of $\\alpha$. The reviewer questions whether interpolating two layers would render $L(\\alpha)$ non-convex.\n- Does \"non-iid\" in Table 1 represent less severe non-i.i.d., and does 'path.' signify pathological non-i.i.d? Why does partial averaging perform better in the pathological non-i.i.d setting than in the less severe non-i.i.d. setting? Shouldn't higher degrees of non-IID reduce performance?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8060/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8060/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8060/Reviewer_zQV8"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8060/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698658117102,
            "cdate": 1698658117102,
            "tmdate": 1700562833643,
            "mdate": 1700562833643,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "EPqRyXk46q",
                "forum": "LfmZh91tDI",
                "replyto": "wH1SqhetR5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8060/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8060/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the appreciation of our conjectures and experimental results.\nIn the following we address the questions raised by the reviewer.\n\n1) We are sorry for the confusion that our \u201ccumulative averaging\u201d concept caused. We will try to clarify it. The idea was to increase the number of layers that are averaged one by one starting either from the deepest or most shallow layer. That is, for shallow cumulation we average only the first layer in the first row of the plot, first two layers in the second row, and like this till the full networks are averaged in the last row. Analogously, with deep cumulation we start with only the classifier layer in the last row and end with the full network in the first row. From these experiments we  concluded that the barrier starts \u201ccumulating\u201d once the middle layers are added - and after this adding more layers has the same level of barrier.\n\n2) We want to emphasize that our theoretical result about layer-wise convexity is provided mainly for explaining the phenomenon of LLMC from all possible perspectives. Regarding the question about two layers, Figure 3 demonstrates that even in the simplest setup averaging more than one layer is not necessarily convex. Proving any further results is a challenging task, as we also mention in the general comment. Our empirical results indicate that for individual layers the loss surface is (close to) convex for realistic neural networks, too. We are excited to continue our theoretical investigation of this challenging question in future work.\n\n3) Yes, non-iid means using Dirichlet with parameter 3 and path. means pathological distribution with Dirichlet parameter 0.01. Our tentative conjecture about the obtained results is that with pathological non-iid setup there is no reason for models to exchange their parameters, so that not communicating is the optimal solution. Since partial averaging does not change models significantly, their performance is nearly as good as not communicating at all. On the other hand, when non-iid is not severe full averaging leads to the best performing model for each of the local datasets and the quality of partial averaging decreases by reducing the number of layers that are being aggregated, since it removes the advantage of knowledge exchange. Nevertheless, this is an initial exploration of a possible application of LLMC notion, detailed investigation of which is left for future work.\n\nAddressing the weaknesses:\n\n1) **not introduce profound novelty**: We kindly disagree with the position that the findings do not introduce profound novelty. Our novel contributions are as following: (i) describing the surprising phenomenon of LLMC, that was not introduced and researched before, (ii) investigating the subspaces of the loss landscape and showing that averaging direction stands out even in the training subspace, (iii) applying the knowledge about layer-wise behavior to personalized federated learning.\n\n2) **phenomenon of smaller layer-wise barriers may not be surprising**: The initial investigation for this work was exactly based on the intuition that each layer aggregation should contribute its part to the full barrier and thus the less layers are aggregated the less is the barrier and each layer separately has its share of the overall barrier value. Instead, we were very surprised that throughout our empirical investigation we found evidence that this is not the case. First, the barrier for each layer is nearly non-existent which is significantly smaller than the full barrier (Figure 1). Second, cumulative aggregation shows that different groups of layers have different \u201cthresholds\u201d of the amount needed to create a barrier. Third, in the experiments with LLMs we observed a barrier in the final layer that is even larger than the full barrier (together with absence of barriers in all other layers) and analogously in Figure 4 (2nd plot) `layer-0-0-norm` with alpha=0.5 has a higher loss (1.0) than for full interpolation (0.9). All this together falsifies the conjecture that the reason for LLMC is simply a proportionally smaller barrier than the full one."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8060/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700266247578,
                "cdate": 1700266247578,
                "tmdate": 1700266794896,
                "mdate": 1700266794896,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FhxmCecJuf",
                "forum": "LfmZh91tDI",
                "replyto": "wH1SqhetR5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8060/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8060/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "3) **theory is for single layer interpolation**: The theory provided serves as one possible approach to understanding LLMC in a minimalistic setup of linear networks. We do not claim that multiple layers or non-linear layers have the same property of convexity as shown in the theorem, but we investigate these setups in the experiments (see also our reply to your question 2) for a broader understanding of the phenomenon.\n\n4) **an error in the author name of the paper**: We used the publicly available version of the paper \"Which layer is learning faster? A systematic exploration of layer-wise convergence rate for deep neural networks\" from https://openreview.net/forum?id=wlMDF1jQF86, where Yixiong Chen is indicated as the first author. We apologize if there exists another version of the paper, but we were not able to find it. Could you please point us towards the version you have in mind?\n\n5) Thank you for your detailed comments on the text. We will fix these issues in the manuscript."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8060/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700266259450,
                "cdate": 1700266259450,
                "tmdate": 1700266289199,
                "mdate": 1700266289199,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tcDMbInZFp",
                "forum": "LfmZh91tDI",
                "replyto": "wH1SqhetR5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8060/Reviewer_zQV8"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8060/Reviewer_zQV8"
                ],
                "content": {
                    "title": {
                        "value": "Response to Author's Rebuttal"
                    },
                    "comment": {
                        "value": "The reviewer appreciates the clear explanation of cumulative averaging and layer-wise barriers. The work on LLMC is indeed novel and intriguing. Despite the room for further enhancement in the theory part, the reviewer decides to vote for acceptance.\n\nMinor corrections:\n- The surname of the first author of the referenced paper appears to be inconsistent. While the citation presents it as (Yixiong Chen, 2023), the reference section lists it as Zhou."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8060/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700562795159,
                "cdate": 1700562795159,
                "tmdate": 1700618170853,
                "mdate": 1700618170853,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ARzEd8thfX",
            "forum": "LfmZh91tDI",
            "replyto": "LfmZh91tDI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8060/Reviewer_VziZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8060/Reviewer_VziZ"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the idea of combining neural networks by averaging only certain layers of the model through the lens of the loss landscape.  If averaging the layers does not result in a model with error significantly above the average error of the two initial models, the the two networks are said to be layer-wise linearly mode connected (LLMC). The paper studies for several different networks/datasets the evolution of the error barrier of the full model as well as the error barrier in each layer.  (Note that layerwise error barrier is not \"symmetric\" as you can use either model 1 or model 2 as the base model; the paper presents plots for both.)  The general conclusion is there is often no layerwise error barrier even when there is a barrier for the full model.\n\nThe paper then makes several further contributions.  LLMC is studied for groups of layers instead of just individual layers, and a toy example of a deep linear network is given to demonstrate how there can be no layerwise error barrier when there is a barrier in the full model.  Some attempts at further understanding this phenomenon are presented by looking at the effect of random perturbations in the loss landscape and perturbations in directions related to the training subspace.  Finally, some results are presented in relation to averaging models in federated learning."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The results on LLMC for single layers and groups of layers across models and datasets is thorough and provides generally interesting results.  I did want to confirm that LLMC is the barrier with respect to *the average error of the two full models* not the average error of one full model and that model with a specified layer swapped.  The latter would not be very informative if this significantly increased the error, but Definition 2 seems to imply the authors used the former.  I would emphasize this before the definition in the paper because readers coming in with intuition from LMC will assume it's the average of the two end points of the interpolation; a figure might also be clarifying, similar to Figure 3 but illustrating how the barrier is computed.\n\nSection 4 and 5.2 are also strong sections in my opinion.  They do a good job of emphasizing the idea that certain layers may provide better directions in the loss surface as compared to averaging the full model (e.g. Fig 4)."
                },
                "weaknesses": {
                    "value": "**Section 5.1:** I found the conclusions of this section hard to parse.  I assume in Fig. 4 the intent is to compare the rows of the left 2 plots to the right 2 plots.  One would then see that the full model has less curvature along the averaging direction as compared to a random perturbation, but a few of the layers have the opposite trend.  The paper states:\n\n```\nMoreover, the networks are much more robust to random perturbations compared to the direction of interpolation between models. This suggests that averaging directions are special in the sense of having much higher curvature than random ones.\n```\nAre the authors referring to just the layerwise results here?  If so this should be made clear because my reading of the plot is this does not hold for the full model.\n\nSecond, is the random perturbation for each layer the size of the norm of the layer-wise interpolation for that particular layer?  This raised the question for me if the results on LLMC were actually better averaging directions in the loss landscape or simply much smaller perturbations to the model. (Also the build up of the error barrier over groups of layers could be increasing the size of the perturbation).  The results in Fig. 4 seem to point to the latter, and *I think this would be an important baseline to include for the other results, i.e. what would the barrier be for a random perturbation of the same size as $\\alpha =0.5$.*  If you get the same result from randomly perturbing the layer there seems to be minimal benefit to doing the averaging.\n\n**Section 6:** In Table 1, these are just the results for different groups of layers, not layers chosen based on the LLMC results.  Is the takeaway just evidence that averaging a subset of layers can be more effective?\n\nIn an application, how would you suggest choosing the layers to average? It seems it would be inefficient in some applications to compute the each layer's barrier every few epochs throughout training."
                },
                "questions": {
                    "value": "Repeating the questions from the review for emphasis:\n\n* The LLMC is the barrier with respect to *the average error of the two full models* not the average error of one full model and that model with a specified layer swapped, correct?\n\n* In Table 1, the results are for different groups of layers the authors think would be interesting, not groups selected by layerwise barriers?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8060/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8060/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8060/Reviewer_VziZ"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8060/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698867555409,
            "cdate": 1698867555409,
            "tmdate": 1699636996383,
            "mdate": 1699636996383,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "t8v3fk97Er",
                "forum": "LfmZh91tDI",
                "replyto": "ARzEd8thfX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8060/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8060/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the positive feedback and are happy to clarify the questions listed.\n\n1) We indeed compute the barrier with respect to the original models\u2019 performance. We specify it also in the Definition 2 and Definition 3 in the paper, but only in mathematical notation. We will add a clarifying note in the text as well.\n\n2) Table 1 includes the following setups: (i) standard (full model) averaging and fully local training, (ii) existing partial averaging approaches, reiterated in multiple works, averaging only body without classifier layer or only classifier layer, (iii) approaches that can be motivated by the robustness perspective of LLMC (Figure 22b in the Appendix), where we either average only the critical (fast changing loss) layers or non-critical layers, and (iv) approaches can be motivated  by cumulative averaging (Figure 2) averaging only middle layers or everything but middle layers. Given a set of critical layers, it remains an open question whether one should average these critical layers, or do exactly the opposite and average all non-critical layers. We are excited to further investigate this direction, though, since on the one hand averaging barrier prone parts means that in the end there will be less barriers and performance should improve, but on the other hand it might lead to too similar models, which is against personalization goals.\n\nTo the weaknesses:\n\n1) **I assume in Fig. 4 the intent is to compare the rows of the left 2 plots to the right 2 plots.**: In Figure 4 we compare averaging directions (left two plots) to random directions (right two plots). You are absolutely correct that the text in the paper is related to the layer-wise directions, not the full model ones. We are sorry for the confusion and will edit the text accordingly.\n\n2) **is the random perturbation for each layer the size of the norm of the layer-wise interpolation for that particular layer?**: For each particular layer, the random perturbations are generated so that their norm is equal to the norm of the perturbations in the averaging direction for this layer. We had exactly the same question in mind when performing the robustness investigation of LLMC, i.e., if the layer-wise perturbations are just so much smaller than full averaging so that the loss does not grow. Our random directions experiment indicates that it is indeed the case and we agree with the reviewer that checking if the random perturbation of each layer with a larger norm will show different results. The current experiment setup will become impossible in this case though, since (i) the norms with respect to the entire network and a single layer are not comparable due to the vastly different dimensionality, and (ii) having random perturbations with much larger norm requires to also increase the norm of the averaging perturbations, which then would shoot far beyond the other network and thereby arguably loose their meaning. Nevertheless, this would be an exciting independent investigation of the robustness directions. What fascinated us in the current setup is that some averaging directions are actually worse than random ones - even for a small norm.\n\n3) **how would you suggest choosing the layers to average**: Our general intuition for the application is that the criticality of layers (i.e. which layers  show rapid growth of loss when disturbed in particular directions) is universal with respect to architecture and task (data to model). If this is indeed the case, then the criticality can be identified once and then reused for all possible applications and training setups. There are indications to this (in particular that our robustness experiments rediscovered the same structure as in the work of Zhang et al.), but we cannot prove it yet."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8060/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700266152618,
                "cdate": 1700266152618,
                "tmdate": 1700266312050,
                "mdate": 1700266312050,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hGkq14SKUC",
                "forum": "LfmZh91tDI",
                "replyto": "t8v3fk97Er",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8060/Reviewer_VziZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8060/Reviewer_VziZ"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "I want to thank the authors for answering my questions and encourage them to make the clarifying edits described above when they revise the paper.  While I think the experiments discussed in the response would be valuable, it is my opinion that the results presented in the paper are sufficient.  Thus, I continue to recommend acceptance."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8060/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700681214082,
                "cdate": 1700681214082,
                "tmdate": 1700681214082,
                "mdate": 1700681214082,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]