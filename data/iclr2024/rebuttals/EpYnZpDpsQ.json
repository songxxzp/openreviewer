[
    {
        "title": "Self-supervised Representation Learning from Random Data Projectors"
    },
    {
        "review": {
            "id": "q6rEn80KLB",
            "forum": "EpYnZpDpsQ",
            "replyto": "EpYnZpDpsQ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission431/Reviewer_sQMY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission431/Reviewer_sQMY"
            ],
            "content": {
                "summary": {
                    "value": "This work introduces a self-supervised representation learning scheme that can be applied to any data modality and network architectures. To this end, it proposed to learn the representations from random data projects of the input data. It is a scheme that learns from randomness, aiming to extract meaningful representations from randomness that mimic arbitrary downstream tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1, this framework can accommodate various data modality\n\n2, extensive experimental results with good performance"
                },
                "weaknesses": {
                    "value": "1, Despite the good performance of the experiments, what has been learned from the latent space using the scheme introduced in this paper, even intuitively?\n\n2, It says in the paper that $g^{(k)}(x)$ uses the same architecture design of $f_{\\theta}$. Even with random initialization, it may still follow a certain distribution family. How would changing this architecture affect the learning?\n\n3, The paper only exams the accuracy on the classification task for frozen representations. Nonetheless, a good representation could used for various purposes, i.e., manipulation of each dimension in the latent space for generating new data, understanding the essential dynamics of the system in physical models and time series data. How could this strategy be applied to scenarios beyond classification?\n\n4, Although the fact that choosing good augmentations usually requires domain knowledge, in many of the application mentioned, such knowledge could be partially obtained using physical intuition. By comparing with models under random corruptions doesn't seem to be a fair comparison."
                },
                "questions": {
                    "value": "Please see Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission431/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission431/Reviewer_sQMY",
                        "ICLR.cc/2024/Conference/Submission431/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission431/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698264865431,
            "cdate": 1698264865431,
            "tmdate": 1700576989137,
            "mdate": 1700576989137,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tZ2tLYONT0",
                "forum": "EpYnZpDpsQ",
                "replyto": "q6rEn80KLB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission431/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission431/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Initial Response"
                    },
                    "comment": {
                        "value": "Thank you for your review and comments about our method\u2019s good performance. We can discuss each of your points.\n\n**W1: Despite the good performance of the experiments, what has been learned from the latent space using the scheme introduced in this paper, even intuitively?**\n\nWhile we do not have a complete theoretical explanation for the success of learning from randomness, we can offer you some indication of an interesting direction. Random orthogonal projections on high dimensional spaces have been studied in mathematics and found to have interesting properties. One result, known as the Johnson-Lindenstrauss lemma [A], says that a set of points on a high-dimensional Euclidean space can be embedded into a lower-dimensional space such that distances are preserved. It has been observed that distances are still well-preserved when the embedding is a random orthogonal projection. This rigorous mathematical setting loosely mimics the practical setting of our paper - where high-dimensional data is projected into a low-dimensional space via a randomly initialized network. While the network does not produce an orthogonal embedding, it may still approximately preserve the distance between datapoints. This information can then be leveraged by the representation learner. We anticipate that the research community will be interested in exploring more theoretical explanations after publication.\n\n**W2: It says in the paper that g^(k)(x) uses the same architecture design of f_theta. Even with random initialization, it may still follow a certain distribution family. How would changing this architecture affect the learning?**\n\nThere is literature (e.g. [B]) discussing what distributions are produced by randomly initialized networks, so we certainly agree with your point. We did not have space or capacity to give a full analysis of the types of distributions produced by each of the networks we used, but we hope that members of the community will find that direction interesting to pursue.\n\nWe found it sensible to use random projectors that share a similar architecture to the representation model since researchers have already determined classes of network architectures that have good inductive biases for extracting useful features. This information dictates the choice of representation model, and we reuse that information in choosing the projector architecture. In principle one could use any projector, but in preliminary experiments we found that matching inductive biases was beneficial.\n\n**W3: The paper only exams the accuracy on the classification task for frozen representations. Nonetheless, a good representation could used for various purposes, i.e., manipulation of each dimension in the latent space for generating new data, understanding the essential dynamics of the system in physical models and time series data. How could this strategy be applied to scenarios beyond classification?**\n\nAs with any SSRL model, training is done without reference to any specific downstream task. Evaluation is commonly performed on classification tasks since class labels are widely available, but it would be possible to predict any kind of label, such as segmentations or depth in image data. On tabular datasets which were our main focus, there are not many examples of downstream tasks other than classification for which standardized datasets are publicly available. However, please see our general comment for a new experiment on transfer learning.\n\n**W4: Although the fact that choosing good augmentations usually requires domain knowledge, in many of the application mentioned, such knowledge could be partially obtained using physical intuition. By comparing with models under random corruptions doesn't seem to be a fair comparison.**\n\nWe agree that with time and effort, it would be possible to produce useful semantic-preserving augmentations for most datasets, however our focus is on circumventing that process entirely. The advantage of LFR is that one does not need to put any effort into choosing good augmentations. In your last sentence we believe you are referring to one of the baseline methods, SCARF (Bahri et al., 2022), reviewed in Section 4.2. We believe that comparing to SCARF as one of the baselines is fair, since the random corruptions are exactly what (Bahri et al., 2022) proposed to use. We note that this is the only baseline that uses random corruptions. DACL for instance uses mixup for augmentations, while STab uses stochastic regularizations of networks.\n\n[A] Freksen, \u201cAn Introduction to Johnson-Lindenstrauss Transforms\u201d 2021\n\n[B] Roberts et al., \u201cThe Principles of Deep Learning Theory\u201d, Cambridge University Press 2022"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700281158740,
                "cdate": 1700281158740,
                "tmdate": 1700281158740,
                "mdate": 1700281158740,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6OP4rHagU8",
                "forum": "EpYnZpDpsQ",
                "replyto": "tZ2tLYONT0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission431/Reviewer_sQMY"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission431/Reviewer_sQMY"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "I want to express my gratitude to the reviewers for addressing my inquiries and to the other individuals providing reviews. As a result, I am increasing my rating."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700576958018,
                "cdate": 1700576958018,
                "tmdate": 1700576958018,
                "mdate": 1700576958018,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ipMlcBygla",
            "forum": "EpYnZpDpsQ",
            "replyto": "EpYnZpDpsQ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission431/Reviewer_Eryk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission431/Reviewer_Eryk"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes \"Learning from Randomness\" (LFR), which tackles the long-standing problem of removing augmentations from SSL. Instead, random projections of the representation are learnt via a bank of predictors, with the intuition that diverse random projections replicate a set of generic downstream tasks.\nAn objective like Barlow-Twins is used, as well as an iterative training procedure that updates the backbone and the projectors in separate steps. In order to have diverse random projections, the authors propose to sample several of them and select those that are more decorrelated.\n\nThe experiments show how the proposed method is a suitable option for time-series, tabular data and medical images datasets. Interestingly, no augmentation is used in all these settings, which I find interesting and novel. An insightful ablation study is also provided."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The problem of removing augmentations in SSL is of great importance in the community.\n\n* The paper is very well written, organized and presented.\n\n* The authors will release code."
                },
                "weaknesses": {
                    "value": "* The experimental section does not include any medium/large scale dataset, which obfuscates the benefit of the method for any SSL task.\n\n* I found a transfer learning experiment lacking in the results.\n\n* More discussion about the pros/cons of using random projections would be valuable."
                },
                "questions": {
                    "value": "I do not have a large amount of questions, since the paper is very well explained and motivated. However, I would greatly appreciate to discuss with the authors about the following:\n\n\n* The main intuition of this method is to create random downstream tasks that capture different aspects of $z$. Therefore, I would suggest adding a transfer learning experiment, in which an encoder $f_\\theta$ is learnt on a source dataset, and such features are transferred to other real downstream tasks. It would be really interesting to see a gain in such setting, wrt. other SOTA methods. I believe this would strongly reinforce the claim of the paper.\n\n* I wonder if random projections are enough to capture the diversity inherent in complex datasets. I think the paper would benefit from a discussion on the pros and cons of using random projections. Note that the datasets shown in the paper are considered small-scale in the community, which limit the understanding on how effective LFR is for _any_ dataset.   Larger, or more diverse, datasets would be extremely valuable. See following point.\n\n* I suggest evaluating LFR vs. computer vision methods in a different scenario than medical images. It is possible that SimCLR would perform better on CIFAR-10 or ImageNet, nevertheless that experiment would show how well LFR is performing against methods tailored for such scenarios. This would also help to understand how well random projections \"emulate\" the use of well-chosen augmentations. I think a natural images dataset is required for this paper for acceptance.\n  * In the Appendix, the authors provide an example of feature interpretability on CIFAR-10. Noting that the pipeline to train on natural images is already in place, I reinforce my observation that an evaluation on natural images should be part of the experimental section.\n\n* It would be great to have some discussion about how LFR could be applied to Transformers, given their wide use. Comparison with a masking approach would not be required, although of great interest.\n\n* A batch size of 256 is strongly detrimental for a contrastive approach such as SimCLR, for example. Small batch sizes harm performance for such methods. For the reader to fully grasp the scenarios where LFR is suitable, I suggest comparing with SimCLR in settings where the latter is known to excel.\n\n* I highly appreciated the breakdown of GPU hours required for this paper.\n\n-----\n\nOverall comment:\n\nThe method proposed is sound, and the goal of removing augmentations from SSL is a long-standing one. Learning from random projections seems a sensible way to tackle such problem. The overall architecture and objective is solid, I have no concerns in that sense. The manuscript is written elegantly, with the appropriate language. \n\nHowever, for the method to be rigorously evaluated, more experiments would be required. Otherwise, there is doubt about whether random projections are valuable for small datasets only, etc. \n\nNotably, I suggest the authors to:\n* Perform transfer learning experiments to support the main hypothesis of the work (random projections allow learning different aspects of $z$, thus making $z$ more generally applicable).\n* Evaluate in a setting where classic methods perform at their best, to understand the limitations of the proposed approach. I would suggest a natural images setting, using ImageNet ideally, or CIFAR-10/100 if GPU hours are a concern. \n\n* I think it would be interesting for the reader to see how the training behaves with joint training, I suggest adding some of these plots in the Appendix.\n\nI would be happy to increase my score after discussion and manuscript updates."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission431/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission431/Reviewer_Eryk",
                        "ICLR.cc/2024/Conference/Submission431/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission431/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698684932423,
            "cdate": 1698684932423,
            "tmdate": 1700576102159,
            "mdate": 1700576102159,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wy2mrghPKa",
                "forum": "EpYnZpDpsQ",
                "replyto": "ipMlcBygla",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission431/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission431/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Initial Response"
                    },
                    "comment": {
                        "value": "We are pleased that you found the motivation of our methods to be of great importance and our solution to be sensible suggestion. We will try to address each of your points.\n\n**W1: The experimental section does not include any medium/large scale dataset.**\n\nWe disagree that there are no large-scale datasets used in our experiments. Please see Table 3 in Appendix C.1 for a summary of datasets and their sizes. We point out that MIMIC-III has a training set with over 2.5M datapoints, and HEPMASS consists of 7M. Meanwhile, our medical image dataset Kvasir consists of images at 80x100 resolution which is a fair bit larger than something like CIFAR10.\n\nIn the general comment, we have added experiments on two additional datasets - CIFAR10 for the natural images domain, and a fault diagnosis dataset from (Eldele et al. 2021). \n\n**W1/Q1/S1: Perform transfer learning experiments to support the main hypothesis of the work.**\n\nWe appreciate this suggestion and that you think such results would \u201cstrongly reinforce the claim of the paper\u201d. We originally did not include transfer learning experiments because they are not straightforward in the tabular and time-series domain. However, since it was a common request, we did find a suitable setting from prior literature and applied LFR to it. The results are discussed in the general comment.\n\n**W3/Q2: More discussion about the pros/cons of using random projections would be valuable.**\n\nWe can provide some additional thoughts on the pros and cons of learning from random projections.\n\nWhile we motivate our work with reference to domains where semantic-preserving augmentations are difficult to craft, there certainly are other domains where they do exist (e.g. natural images). In those cases, LFR does not make use of the expert domain knowledge that is available. This could lead to suboptimal performance, as indicated by our new results on CIFAR-10 in the general comment. One way to improve LFR would be through incorporating this domain knowledge when available.\n\nLFR also requires initializing many networks for random projectors, but then discards many of them when selecting for diversity. This could be seen as wasteful, and the method could be improved if there were a good way to initialize more diverse networks to begin with, but we note that these are small networks, and that the entire process takes a negligible computational time compared to SSRL (3.01s to initialize and select for diversity, vs 849.21s to train). \n\nIn terms of pros, we have tried to highlight these throughout the paper. LFR can be used on any domain or modality. LFR has better performance across tasks where semantic-preserving augmentations are not well-developed, including important domains like medical images (Table 2). LFR can be more computationally efficient than methods like SimCLR and SimSiam that use multiple passes through the large encoder and CPU-based augmentations (see general comment).\n\n**Q3/S2:  Evaluate in a setting where classic methods perform at their best. A natural images dataset is required for this paper for acceptance.**\n\nThis was a common request amongst reviewers, so we have provided discussion and experimental results on CIFAR10 in the general comment. In summary, LFR (using no augmentations) does not outperform SimCLR (using the full suite of augmentations) on natural image datasets. The same can be said for several domain-agnostic approaches including DIET and DACL.\n\n**Q4: Could LFR be applied to Transformers?**\n\nWe believe it is possible to use LFR with transformers, but have not been able to implement this idea in the discussion period. Hopefully the community is able to explore these ideas upon publication. As a brief outline, one could modify contrastive approaches like SimCSE [A] to use LFR by replacing how SimCSE samples positive pairs. Using a pre-trained transformer to transform text inputs to representation space, random projections can be applied instead of sampling pairs, and then SimCSE\u2019s contrastive loss can be replaced with the batch-wise Barlow Twins loss.\n\n[A] Gao et al., \u201cSimCSE: Simple Contrastive Learning of Sentence Embeddings\u201d, EMNLP 2021\n\n**Q5: A batch size of 256 is strongly detrimental for a contrastive approach. I suggest comparing with SimCLR in settings where the latter is known to excel.**\n\nWe agree that contrastive methods have been shown to perform well at very large batch sizes. We see this as a negative of such approaches, as it increases the computational requirements of running such methods. Based on Figure 4, LFR does well at reasonably small batch sizes. However, we take your point, so for the new CIFAR10 experiments in the general comment we did increase the batch sizes to 512.\n\n**S3: It would be interesting to see how joint training behaves.**\n \nWe did experiment with joint training, with an ablation on Kvasir shown in Figure 4. This ablation helps to justify why we used an EM-like algorithm rather than the simpler joint training idea."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700281134467,
                "cdate": 1700281134467,
                "tmdate": 1700281134467,
                "mdate": 1700281134467,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "coN3XkN1kD",
                "forum": "EpYnZpDpsQ",
                "replyto": "wy2mrghPKa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission431/Reviewer_Eryk"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission431/Reviewer_Eryk"
                ],
                "content": {
                    "title": {
                        "value": "Answer to a great rebuttal"
                    },
                    "comment": {
                        "value": "I want to thank the authors for a very detailed and well written rebuttal, I definitely enjoyed reading the general answer as well as the dedicated answers to my review.\n\n* The authors answer about medium/large scale datasets is accurate, I apologize for the mistake.\n* The transfer learning experiment is insightful and shows the benefit of LFR. I think this experiment is important for the paper and strengthens it.\n* I appreciate the experiement on CIFAR-10, where the authors show that cherry-picked augmentations with domain knowledge are performing better. In my opinion, this experiment complements the claims and enriches the paper from a scientific perspective. The fact that SimCLR with dedicated augmentations would perform better was expected, being some sort of \"upper bound\" for LFR (if we had unlimited capacity to search for the optimal random projectors). I am grateful that this aspect of the method will make it to the main paper. \n* The remaining answers are also adequate.\n\nGiven all the above, as well as the detailed answers to the other reviewers, I am willing to upgrade my score."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700575987375,
                "cdate": 1700575987375,
                "tmdate": 1700575987375,
                "mdate": 1700575987375,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "05jKvzuYbR",
            "forum": "EpYnZpDpsQ",
            "replyto": "EpYnZpDpsQ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission431/Reviewer_6gYm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission431/Reviewer_6gYm"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed the method of self-supervised representation learning that can be used to learn useful representations from different modalities, e.g. images, text, time series, tabular data. Proposed method is based on recent approach where we have architectures with an additional projector (Guillotine regularization, removed for a downstream task) tries to predict multiple random projectors. The authors provide some analysis of hyper-parameter sensitivity, different initializations of random projectors, etc. Comparison with other methods on different modalities are proposed (time series, tabular, image)."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "S1. The method is simple and very generic. Removes the prior of knowing what data aug. we should use for many current SSL contrastive-based methods.\nS2. Paper easy to follow and well-written."
                },
                "weaknesses": {
                    "value": "W1. The main weakness for me is inability to compare with the existing method on well-known datasets in computer vision tasks. We have 3 x time series, 3 x tabular, and 1 x image - where Kvasir is not commonly used dataset. Not sure if the results are not picking the datasets that show good results. Why not presents the results on ImageNet, and if computationally not possible - cifar100. \n\nW2. There's no evaluation on the different downstream task for the learned representation, e.g. feature extractor trained with LFR on Kvasir and evaluated on the other dataset similar and disimilar one. We do not know how the learned representation generalize, and what if we only memorize patterns that then can be then useful for the lin. evaluation.\n\nW3. We don't know the final computational overhead of the initialization and comparison to any SSL method. In the appendix we have total time spent for a particular dataset (e.g. Kvasir V100 1095 GPU hours for all experiments). Would be better to know the comparison between SimCLR/SimSiam vs LFR. \n\nW4. 2 time series datasets (HAR, Epilepsy) and tabular Income&HEPMASS have already good accuracy on the randomized init. What is intresting, some methods are below that (HAR - Autoencoder). \n\nW5. Lack of more theoretical explanation why it should work? What random projectors can be used? etc."
                },
                "questions": {
                    "value": "Q1. How the method perform without using heavy SSL (SimCLR) data augmentations?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission431/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698686808362,
            "cdate": 1698686808362,
            "tmdate": 1699635969756,
            "mdate": 1699635969756,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xkmbHsL2Sf",
                "forum": "EpYnZpDpsQ",
                "replyto": "05jKvzuYbR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission431/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission431/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Initial Response (1/2)"
                    },
                    "comment": {
                        "value": "We are glad that you appreciated the simplicity and generality of our approach, thank you for your feedback. We will go through each of your points.\n\n**W1: The main weakness for me is inability to compare with the existing method on well-known datasets in computer vision tasks. We have 3 x time series, 3 x tabular, and 1 x image - where Kvasir is not commonly used dataset.**\n\nWe must disagree on one aspect - Kvasir is in fact widely used for benchmarking applications of ML to healthcare with over 1000 combined citations [Pogorelov et al. 2017] [A]. We used it as an example of the differences between domains (within the image modality), and how natural image augmentations are not necessarily semantic-preserving for medical images. This is a core motivation of our paper - moving towards domain-agnostic SSRL methods - and was not picked based on results.\n\nAs to your interest in seeing results on natural image data as well, and based on multiple requests from reviewers, we have rerun our experimental pipeline on CIFAR10. The results and discussion are in the general comment. In summary, LFR (using no augmentations) does not outperform SimCLR (using the full suite of augmentations) on natural image datasets. The same can be said for several domain-agnostic approaches including DIET and DACL.\n\n**W2: There's no evaluation on the different downstream task for the learned representation. We do not know how the learned representation generalize, and what if we only memorize patterns that then can be then useful for the lin. Evaluation.**\n\nAgain, many reviewers had the same thoughts, so we have addressed your idea about transfer learning in our general comment. We originally did not include transfer learning experiments because they are not straightforward in the tabular and time-series domain. However, we did find a suitable setting from prior literature and applied LFR to it.\n\n**W3: We don't know the final computational overhead of the initialization and comparison to any SSL method. In the appendix we have total time spent for a particular dataset (e.g. Kvasir V100 1095 GPU hours for all experiments). Would be better to know the comparison between SimCLR/SimSiam vs LFR.**\n\nThe initialization and selection of random projectors is a minor part of overall training time with LFR. As a concrete example, on the Income dataset training LFR for 100 epochs took 849.21s on our machine, while the DPP selection took 3.01s. \n\nIn terms of model training, SimCLR took around 9 hours on the Kvasir dataset, while LFR completed in just 2 hours on the same machine. Please see the general comment for a discussion of this result and our analysis of computational costs.\n\n**W4:  2 time series datasets (HAR, Epilepsy) and tabular Income&HEPMASS have already good accuracy on the randomized init. What is intresting, some methods are below that (HAR - Autoencoder).**\n\nThe randomly initialized encoder baseline is intended to benchmark the improvement given by the learned representations. If the downstream task is easy, or the input features are already in a useful representation, then linear evaluation could perform well on any representation, even a randomly initialized one. Methods that do not outperform Random Init on linear evaluation are not providing more useful learned representations. In Table 1 there are various instances where an SSL method underperforms this baseline, possibly because the augmentations it uses are not well suited for the domain. However, LFR, being domain-agnostic, is able to learn more useful representations in every setting."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700280919641,
                "cdate": 1700280919641,
                "tmdate": 1700280919641,
                "mdate": 1700280919641,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Ocya568X84",
            "forum": "EpYnZpDpsQ",
            "replyto": "EpYnZpDpsQ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission431/Reviewer_gtio"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission431/Reviewer_gtio"
            ],
            "content": {
                "summary": {
                    "value": "The authors of this paper propose a technique called Learning From Randomness (LFR), which allows the application of self supervised techniques in arbitrary data domains. The proposed method works by projecting the data into random representations, and then training a model to predict these random representations. The authors show that the resulting model can learn useful representations, even without domain knowledge for the datasets examined."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is very clear and easy to understand. I did not have any issues in grasping the points the authors are trying to make.\n\n- The method proposed is novel, as far as I am aware. It is also very interesting, as learning from random data is not a very explored area of research. As the authors note, the proposed technique enables self supervised learning without the need for domain knowledge, in order to create good augmentations for the data. There is also a clear benefit from using LFR in the datasets examined, without having to rely on complicated techniques.\n\n- The authors perform ablations on the random projectors used, as well as the required diversity of the random representations and the training procedure for the model. I find it interesting that the authors perform an EM-based approach in learning the model, instead of simple optimizing all of its parts all at once. Similarly, I find equally interesting the preprocessing step that selects the best random projectors to predict during training.\n\nOverall, I find the proposed method insightful, with clear benefits over previous work in datasets that are not as explored as the usual ones (e.g. CIFAR-10/100, ImageNet)."
                },
                "weaknesses": {
                    "value": "- One of the issues I have with this paper is that despite the use of several datasets used to evaluate LFR, the commonly used ones such as CIFAR-10/100 are not among them. While I understand that LFR does not aim to improve performance on these datasets (since natural image augmentations already perform very well) it would be interesting to examine those to compare as well. It would be useful to know if LFR is better/worse than optimized augmentations, such as those used in SimCLR.\n\n- I think the paper could also be improved via further experiments on the following two subjects:\n\n  - I think it would be interesting to see some ablations on the distance metric used for training. Right now, the authors use Barlow Twins as the metric, but it would be interesting to perform ablations with e.g. MSE or Contrastive losses for this (although I must note that the authors do make an argument for this design decision in the paper).\n\n  - I think it would also be interesting to see the transferability of the trained models across different datasets. I would be interested in knowing if LFR leads to learning representations that are good for the particular dataset, or good for the chosen modality in general."
                },
                "questions": {
                    "value": "I would be grateful if the authors could comment a bit on the choice of the number of projectors $K = 6$ and batch size $B = 256$. Intuitively, both of these values seem a bit small when trying to find diverse random projectors. The authors have tried going up to $K = 8$ and batch size $B = 512$, but I would like to know if they have tried higher values for these two hyperparameters (especially for the number of projectors $K$)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission431/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698707091482,
            "cdate": 1698707091482,
            "tmdate": 1699635969687,
            "mdate": 1699635969687,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PuK43Lojfw",
                "forum": "EpYnZpDpsQ",
                "replyto": "Ocya568X84",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission431/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission431/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Initial Response"
                    },
                    "comment": {
                        "value": "We are very pleased to see that you enjoyed our paper, and will address the few comments you had.\n\n**W1: While LFR does not aim to improve performance on datasets like CIFAR10, it would be useful to know if LFR is better/worse than optimized augmentations, such as those used in SimCLR.**\n\nThis was a common sentiment amongst reviewers, so we have provided discussion and experimental results on CIFAR10 in the general comment. In summary, LFR (using no augmentations) does not outperform SimCLR (using the full suite of augmentations) on natural image datasets. The same can be said for several domain-agnostic approaches including DIET and DACL.\n\n**W2.1: It would be interesting to perform ablations with e.g. MSE or Contrastive losses.**\n\nSince multiple reviewers brought up this point, we have addressed it in the general rebuttal by running experiments using LFR with InfoNCE instead of Barlow Twins. In addition to the arguments for our design decision in the paper, our batch-wise Barlow Twins loss did give a slight improvement over InfoNCE for downstream performance.\n\n**W2.2: It would also be interesting to see the transferability of the trained models across different datasets.** \n\nWe originally did not include transfer learning experiments because they are not straightforward in the tabular and time-series domain. However, since it was a common request, we did find a suitable setting from prior literature and applied LFR to it. The results are discussed in the general comment.\n\n**Q1: I would be grateful if the authors could comment a bit on the choice of the number of projectors K=6 and batch size B=256. I would like to know if they have tried higher values for these two hyperparameters (especially for the number of projectors K).**\n\nAs you noted, we performed ablations on Kvasir for both number of projectors and batch size in Figure 4 of Section 4.6. The largest values we used were $K=8$, and $B=512$. Already at these levels there was a decrease in final performance, so we have not extended it to larger values of $K$. Generally, our findings are that the projector selection approach from Section 3.3 is adequate for ensuring enough diversity in a small number of projectors that $K$ does not need to be large (which would add some cost to training, specifically from the $K$ predictor heads that try to match the $K$ projectors)."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700280881102,
                "cdate": 1700280881102,
                "tmdate": 1700280881102,
                "mdate": 1700280881102,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IGkBl7CLxR",
                "forum": "EpYnZpDpsQ",
                "replyto": "PuK43Lojfw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission431/Reviewer_gtio"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission431/Reviewer_gtio"
                ],
                "content": {
                    "title": {
                        "value": "Response to rebuttal"
                    },
                    "comment": {
                        "value": "I'd like to thank the authors for their extensive responses to both mine and the other Reviewers' comments. These provide further insight into how LFR can be used in a variety of domains. Even though in the case of CIFAR-10 the performance is significantly lower than SimCLR/SimSiam, I think that is to be expected, given that image-based augmentations have been very extensively studied.\n\nAs such, I am keeping my suggestion to accept the paper for now, since I believe the goal of LFR is very interesting and novel."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700516555338,
                "cdate": 1700516555338,
                "tmdate": 1700516555338,
                "mdate": 1700516555338,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rIxFvmROOs",
            "forum": "EpYnZpDpsQ",
            "replyto": "EpYnZpDpsQ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission431/Reviewer_ze2f"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission431/Reviewer_ze2f"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers the problem of domain-agnostic self-supervised representation learning. The proposed method introduces multiple random projectors and corresponding predictors, and optimizes the batch-wise barlow twins loss, which constructs the Gram matrix instead of the empirical correlation matrix. To encourage the diversity, many projectors are initialized and then only 10% are subsampled for use. Experimental results on datasets from various domains show the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Domain-agnostic representation learning is a timely topic.\n\n- The proposed idea is simple and the proposed method improves the performance in most cases."
                },
                "weaknesses": {
                    "value": "- Discussion/comparison with other domain-agnostic methods seem to be not enough. For example, [Lee et al.] proposed a domain-agnostic augmentation strategy applied to image, speech, and tabular datasets, and [Wu et al.] proposed randomized quantization and experimented on image, point cloud, audio domains and the DABS benchmark. I suggest including discussion and experimental comparison with them. \n\n- It is good to see that experiments include various domains including time series, tabular, and image, but they seem to be relatively small and not commonly used for benchmarking machine learning models. For example, Kvasir is a medical image dataset, which is different from the widely used \"natural\" image datasets; it should be categorized differently from natural image datasets. Authors may want to refer to [Lee et al.] and [Wu et al.] to find commonly used datasets to provide the general applicability to various domains and scalability of the proposed method.\n\n- While the authors claim that the optimization strategy for the proposed method is EM, but it is not clear how the proposed alternating optimization is related with EM by looking at the formulation. I think the transition from Eq. (2) to Eq. (3--4) requires more explanation supported with some math.\n\n- The claim around batch-wise barlow twins that MSE is preferred over cross-entropy/contrastive/triplet losses is not justified. Isn't the batch-wise barlow twins loss just a kind of contrastive loss, in that it contrasts all samples within the batch? Note that the original contrastive loss (not the InfoNCE variation) also computes the MSE loss. An ablation study with different type of losses might also be helpful.\n\n- The criterion for diversity encouragement requires more intuition. It is hard to imagine what is going on when optimizing the proposed learning objective. Also, what is the computational cost for the NP-hard objective function?\n\n- The comparison might not be fair as the proposed method requires more computational cost to encode input with multiple random projectors and predictors compared to other baselines. The computational cost should be matched for a fair comparison and reported.\n\n[Lee et al.] i-Mix: A Domain-Agnostic Strategy for Contrastive Representation Learning. In ICLR, 2021.\n\n[Wu et al.] Randomized Quantization: A Generic Augmentation for Data Agnostic Self-supervised Learning. In CVPR, 2023."
                },
                "questions": {
                    "value": "Please address concerns in Weaknesses.\n\n> **post rebuttal**\n\nAfter discussion with authors, I feel that the experimental results are not sufficient to support the claim that they cover \"a wide range of representation learning tasks that span diverse modalities and real-world applications.\" Initially their experiments covered time series, medical image, and tabular domains, and the additional results in the natural image domain show that their method is not effective for natural images, compared to other baselines. **Authors are encouraged to explicitly limit the scope to the domains they experimented in the title/abstract/intro.**\n\nAlso, I am not sure if the comparison is fair (e.g., if they tuned hyperparameters for baselines properly), so experimental results are generally not convincing to me.\n\nThough I feel more confident on my rating, given that authors addressed all concerns from the other reviewers well and the proposed method is still interesting to me, I do not want to put too much weight to my rating."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission431/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission431/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission431/Reviewer_ze2f"
                    ]
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission431/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698768252871,
            "cdate": 1698768252871,
            "tmdate": 1700674015870,
            "mdate": 1700674015870,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "n1h95SN1EU",
                "forum": "EpYnZpDpsQ",
                "replyto": "rIxFvmROOs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission431/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission431/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Initial Response"
                    },
                    "comment": {
                        "value": "Thank you for your constructive review, we are happy to address each of your points.\n\n**W1 Discussion/comparison with other domain-agnostic methods seem to be not enough:**\n\nWhile we used three approaches to domain-agnostic SSRL (along with five strong domain-specific baselines), the methods you point out are also useful and we will cite them with discussion. Random Quantization (RQ) [Wu et al. 2023] has received attention with its recent publication at ICCV 2023 in October, which post-dates our submission to ICLR. Nevertheless, this is a helpful suggestion, so we re-ran SimCLR and SimSiam using RQ augmentations on three datasets, one from each modality. However, we found i-Mix [Lee et al.] to be very similar to the more recent DIET [Balestriero 2023], and given that it was shown to be outperformed by RQ [Wu et al. 2023], we believe our addition of a RQ baseline sufficiently covers these alternatives.\n\nThe results for SimCLR, SimSiam, and LFR are reproduced from Table 1, with new results added for RQ augmentations. Note that for the Income baseline we restated the SCARF result, since it is similar to SimCLR with random feature corruptions as the augmentation. RQ appears beneficial on HAR (Time Series), but is not necessarily helpful on Income (Tabular) and Kvasir (Image). We note that when Wu et al. applied RQ to image data, they combined it with more traditional image augmentations, as using RQ alone did not produce great performance (Tables 3, 4 in [Wu et al. 2023]). Ultimately, LFR still outperformed this baseline.\n\n|Method/Dataset| HAR | Income | Kvasir|\n|---|---|---|---|\n|SimSiam| 65.1 | 79.2 | 72.6|\n|SimSiam-RQ| 78.9| 76.4 | 73.1|\n|SimCLR (*SCARF)|87.8| *84.2| 72.1|\n|SimCLR-RQ| 91.5 | 78.6 | 68.6|\n|LFR|93.1 | 85.2 | 74.9|\n\n**W2 Datasets are relatively small and not commonly used for benchmarking machine learning models.** \n\nWe respectfully disagree on this point. Table 3 in Appendix C.1 summarizes all the datasets we used, which includes MIMIC-III at over 2.5M training examples, and HEPMASS at 7M. Compared with common datasets like CIFAR-10, these datasets are very large scale. The smaller datasets, HAR and Epilepsy, were chosen because they have previously been used for benchmarking time-series SSRL methods (e.g. Eledele et al. 2021), while Income and Theorem have been used for tabular benchmarking (e.g. Hajiramenzanali et al. 2022). In fact these datasets are commonly used: the paper introducing MIMIC-III has over 6000 citations [A], Kvasir has over 1000 combined [Pogorelov et al. 2017] [B], HAR over 2000 [Anguita et al. 2013], Epilepsy over 3000 [Andrzejak 2001], and Income over 2000 [Kohavi 1996]. As a side note, we did explicitly call out that Kvasir was a medical image dataset (not natural image) in Table 2 and Section 4.1.\n\nYou also mentioned two domain-agnostic works with more suggestions for other datasets to consider. [Lee et al.] uses image, speech, and tabular datasets, while [Wu et al.] experiment on images, point clouds, and audio. As can be seen, there is a lack of consistency in which modalities are tested for domain-agnostic work, and unfortunately we are not able to introduce several new modalities in the discussion period. However, to partially accommodate your requests, we have repeated our experimental setup on CIFAR-10 as a representative natural image dataset with the results shown in the general comment. The DABS benchmark does appear useful, and we will investigate it for the future.\n\n[A] Johnson et al., \u201cMIMIC-III, a freely accessible critical care database\u201d, Nature Scientific Data 2016.\n[B] Jha et al., \u201cKvasir-SEG: A Segmented Polyp Dataset\u201d, International Conference on Multimedia Modeling 2020."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700279736762,
                "cdate": 1700279736762,
                "tmdate": 1700493448065,
                "mdate": 1700493448065,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "AmClFn5QhH",
                "forum": "EpYnZpDpsQ",
                "replyto": "YoRuGflGYU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission431/Reviewer_ze2f"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission431/Reviewer_ze2f"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for addressing my questions! Below I provide more comments.\n\n> W1 Discussion/comparison with other domain-agnostic methods seem to be not enough:\n\n> W2 Datasets are relatively small and not commonly used for benchmarking machine learning models.\n\nMy major concern is still on this, and the experimental results are not sufficient to claim your method is effective across \"a wide range of representation learning tasks that span diverse modalities and real-world applications.\" I agree that papers on domain-agnostic method such as DACL, i-Mix, and RQ do not have a consensus on the choice of domains, but at least the natural image domain is common, and you can take at least one of the prior works' setting rather than using completely different domains than others to make experimental results more convincing.\n\nOr, as I suggested in another thread, if you are not willing to incorporate them, then I think it is better to explicitly limit your focus/contribution (in the title/abstract/intro) to medical image and/or tabular domains, and explain why the proposed method is specifically useful for such domains (if possible).\n\n\n> W3 The transition from Eq. (2) to Eq. (3--4) requires more explanation.\n\nThanks for the details, hopefully you can incorporate this at least somewhere in the appendix.\n\n> W5 The criterion for diversity encouragement requires more intuition. What is the computational cost for the NP-hard objective function?\u201d\n\nThank you for your response and it is good to know that the NP-hard problem is lightweight to solve in practice. However, still **it is hard to imagine what is going on when optimizing the proposed learning objective** for me.\n\n> W6 The proposed method requires more computational cost to encode input with multiple random projectors and predictors compared to other baselines.\n\nBased on the discussion in another thread, unfortunately I feel that prior works are experimented in a suboptimal way (e.g., using suboptimal hyperparameter choices), that might result in an unfair comparison."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission431/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700672890871,
                "cdate": 1700672890871,
                "tmdate": 1700672890871,
                "mdate": 1700672890871,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]