[
    {
        "title": "Mining latent labels for imbalance classification: a regrouping perspective"
    },
    {
        "review": {
            "id": "105WCNdhLZ",
            "forum": "tkmO6bXT54",
            "replyto": "tkmO6bXT54",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4181/Reviewer_9T2x"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4181/Reviewer_9T2x"
            ],
            "content": {
                "summary": {
                    "value": "To handle imbalanced data, the authors propose RG (Regrouping) by\nclustering instances in the majority class, create pseudo-classes\nfrom the classes, and learned a classifier with more classes.  If the\nscore for the minority class is larger than the pseudo-class, the\nminority class is predicted; otherwise, the majority class is\npredicted.  For multi-class data, all classes except the smallest\nclass are regrouped.  The proposed approach is quite straightforward.\n\nFor binary classification, RG was evaluated on two datasets.  For\nmulti-class classification, RG was evaluated on one dataset."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The problem of imbalanced data in multi-class classification is\ninteresting.  RG outperforms existing techniques in balanced accuracy\n(BA) in one dataset."
                },
                "weaknesses": {
                    "value": "The efficacy of RG is not well demonstrated.  In Table 1, RG only\noutperforms in one of 3 metrics in one of 2 datasets.  For the\nmulti-class problem only one dataset is used.\n\nThe choice of datasets could be improved.  The 9 classes in CIFAR 10\nare quite different and merging to simulate a single majority class\nmight have a quite diversified class.  For example, a majority class\nhas many images of dogs, but the different kinds (subclasses/clusters)\nof dogs have commonalities to be dogs.  Hence, Binary CIFAR 10 might\nnot be a good dataset to use.  Binary HAM10000 on \"dermatoscopic\nimages of 7 common skin lesions\" is more appropriate.\n\nThe presentation could be improved.  For example:\n\nSec 2.2: Sum aggregation was discussed, but it seems to be not used\nin any experiments.  Also, the motivation for Sum aggregation was not\ndiscussed.\n\nSec. 2.2 does not discuss how clusters are formed via regrouping.\nk-means is mentioned in 4.1 Setting of experiment."
                },
                "questions": {
                    "value": "RG+WCE: since RG tries to balanced class sizes, why do you need WCE\n(weighted cross entropy)?  Why did WCE help?  Could you describe WCE\nor cite a source?\n\np7.  \"Considering that AUPRC is agnostic to the decision rule and is\noften approximated by AP given finite sample sizes\"--any citations or\nevidence to support the statement?\n\nFig. 5, caption: airplane, not apple ?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "n/a"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4181/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697843865717,
            "cdate": 1697843865717,
            "tmdate": 1699636384097,
            "mdate": 1699636384097,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "b4J5SvZhcQ",
                "forum": "tkmO6bXT54",
                "replyto": "105WCNdhLZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4181/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4181/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' Response"
                    },
                    "comment": {
                        "value": "We would like to heartfully thank the reviewer for their considerate comments and critiques of our work. In the following, we have addressed some of the questions raised in the review. Please feel free to follow up if any aspects are unclear, or if there are further questions.\n\n- More datasets: We acknowledge the limitation that we only have one multi-class dataset, and have addressed this issue by extending our experiment to include a new multi-class task. Specifically, we take the financial phasebank dataset (Malo et al. (2014)), which consists of 4840 sentences of English-language financial news categorized by sentiment with a label frequency of 2,879 (neutral), 1,363 (positive), and 604 (negative). We have shown that in the new dataset, RG surpasses other baselines and remains dominant. For more information about the experiment setups and results, we would kindly refer to Appendix C for details.\n- Choice of dataset for visualization experiments: We appreciate the reviewer\u2019s comment on how binary HAM10000 can form a more realistic dataset for visualization experiments. The choice of the CIFAR-10 dataset for the visualization experiment is based on three arguments:\n    - Popularity: CIFAR-10 is one of the most popular datasets in image classification, and the class labels are easily interpretable by the readers, and hence a natural choice for a motivating example\n    - Relevance to the regrouping idea: The fact that the majority class is diverse makes it an ideal situation for regrouping. Hence, it helps in highlighting the failure of naively using clustering algorithms to separate samples of different classes, for example in raw image space and autoencoder latent representation space.\n    - Difficulty:  As seen from the results in Section 4, the classification of HAM10000 images is a much harder task in comparison to CIFAR10 image classification, and hence presents a more clear motivation for the readers.\n\t\n    While a dataset like CATSvsDOGS could potentially be a more realistic setting for imbalance classification, the lack of fine-grained labels (for example: breeds of the animals) makes it difficult to visualize the effect of regrouping. Additionally, the discrepancy between how DNNs interpret label structures and human understanding further complicates the analysis.\n- Presentation: We would like to thank the reviewer for the comments on the presentation, we have addressed them as follows:\n    - Aggregation: We performed an ablation study to show the impact aggregation method in Appendix B, where max aggregation is found to be marginally better in comparison to sum aggregation, but since the difference is not too large it is recommended to try both methods. We have added some explanation for both aggregation methods in Sec 2.2 to avoid confusion.\n    - Clustering Method: In Appendix B, we also explored the role of clustering algorithms in the performance of the proposed method, especially focussing on whether enforcing equal cluster sizes can be beneficial to the method. Two balanced clustering algorithms: constrained K-means (Bradley et al. (2000)) and Normalized Cut (Shi et al. (2000)) have been compared with the naive K-means method. We find that balanced clustering can lead to slightly better BA, but perform much worse in terms of AP metric, and hence the choice of a simple K-means algorithm is proposed. To avoid confusion, we have also added brief information about the clustering algorithm in Sec 2.2.\n    - Image Caption: We have fixed the typo in the image caption, it should have been airplane instead of apple.\n- Why WCE is required with RG?: WCE is the weighted version of cross entropy loss where each sample is weighted by the inverse of the corresponding class frequency, so that classes with fewer samples get higher weights, check Elkan (2001) for the general concept of reweighting. Since we are using K-means algorithm to perform clustering and assign pseudo labels, the resulting classes are not guaranteed to be balanced. Hence, along with CE, we have also reported results that use WCE loss function.\n- AUPRC/AP metric clarification: AUPRC is a metric that calculates the area under precision-recall curve, where each point is based on a specific threshold (decision rule). Hence, AUPRC (similar to AUROC) is independent of the choice of decision rule. Average Precision (AP) is known to be an unbiased estimate of AUPRC (Boyd et al. (2013)). We have added the reference in the paper as well."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4181/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700114970653,
                "cdate": 1700114970653,
                "tmdate": 1700115285685,
                "mdate": 1700115285685,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "s6YcW6BUqN",
                "forum": "tkmO6bXT54",
                "replyto": "b4J5SvZhcQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4181/Reviewer_9T2x"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4181/Reviewer_9T2x"
                ],
                "content": {
                    "title": {
                        "value": "comments on response"
                    },
                    "comment": {
                        "value": "Thanks for the response.\n\nI don't think having subclasses in the majority class is important because a majority class might not have (defined) subclasses--the majority class might just has a lot of instances.  Also, if there are (defined) subclasses, one might evaluate how well the clustering algorithm recovers the subclasses.  However, the clustering algorithm is the well-known k-means algorithm, not one that is newly proposed.   \n\nWhat is the motivation for Sum aggregation?"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4181/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700598574387,
                "cdate": 1700598574387,
                "tmdate": 1700598574387,
                "mdate": 1700598574387,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "VP6nKJGV6l",
            "forum": "tkmO6bXT54",
            "replyto": "tkmO6bXT54",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4181/Reviewer_AJcJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4181/Reviewer_AJcJ"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a regrouping method to improve the performance of imbalanced learning, which decomposes the majority classes into subclasses by clustering and trains the model under the extended classes. The authors analyzed the ability of the proposed RG , demonstrating its ability to facilitate learning efficient representation and synchronizing the training progress across different classes, and verified the performance thorough a range of experiments."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1) ReGrouping method is different from the conventional loss reweighting or re-sampling methods that changes the class importance explicitly. By regrouping, the learning pace of each class (especially for rare classes) can be directly intervened as shown in the loss variation illustration in Figure 5. \n\n2) The authors provided some interesting validations to support the design about the proposed method like the synchronous learning, and presented how to design the clustering number and extend to multi-class learning as well as the underlying tricky points for the optimal performance. \n\n3) The authors conducted a range of experiments on both binary and multi-class imbalanced learning tasks, demonstrating superior performance compared to state-of-the-art methods in terms of balanced accuracy (BA) and average precision (AP) metrics."
                },
                "weaknesses": {
                    "value": "Although the methods shows the interesting points of the proposed regrouping method, some critical concerns remained and are summarized as follows.\n\n1) The novelty concern can be a big problem. As the authors mentioned about the COG method (local clustering for imbalanced learning in Wu, et. al., 2010), both the proposed method and COG shares the same spirit for imbalanced learning, and the technical major difference is COG follows the SVM classifier. Despite in different data context, they are both for imbalanced learning, which weakens the novelty of this work.\n\n2) The technical description is not sufficient, as we can see that there is lack of the clustering ways for pseudo labels that are used in the regrouping method. This also connects the lack of the corresponding experiments to verify the clustering impact on the final performance. Especially, as shown in Figure 5 and Figure 6, how to assign the pseudo labels does matter about the performance, which makes the readers care about the clustering effectiveness.\n\n3) The experiments are also not very persuasive although some experiments have shown the improvement about RG. The major concern is about the datasets and the baselines especially for the multi-class classification experiments. There are a range of explorations in long-tailed learning for multi-class classification problems. However, we cannot find any sufficient comparison with the recent advances like Decoupling, LA (logit adjustment), BCL and so on. For the datasets in long-tailed learning, CIFAR100-LT, ImageNet-LT or INaturalist are all widely adopted benchmarks, which should be included in this submission."
                },
                "questions": {
                    "value": "Overall, I am interested in this regrouping idea for imbalance learning, although it has been proposed in previous explorations. What is the intrinsic difference for imbalanced learning should be highlighted, instead of some minor difference as in the description of the submission. For other questions, please see above weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4181/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698466375024,
            "cdate": 1698466375024,
            "tmdate": 1699636383970,
            "mdate": 1699636383970,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FbL8T1q2wa",
                "forum": "tkmO6bXT54",
                "replyto": "VP6nKJGV6l",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4181/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4181/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' Response"
                    },
                    "comment": {
                        "value": "We would like to heartfully thank the reviewer for their considerate comments and critiques of our work. In the following, we have addressed some of the questions raised in the review. Please feel free to follow up if any aspects are unclear, or if there are further questions.\n\n- Novelty: We agree with the reviewer that the proposed method shares a high-level overview with Classification using local clustering (COG), proposed by Wu, et. al. (2010) to tackle imbalanced classification. However, we would like to highlight some key arguments in the paper that differ from COG:\n    - Motivation: COG was proposed in the context of linear SVM models in order to: a) decompose the majority class samples so that they become linearly separable from minority class samples, and b) produce sub-classes with relatively uniform sizes. Note that a) is irrelevant in the context of deep neural network (DNN) models, and b) is not supported (in Wu, et. al. (2010)) with any theoretical/empirical evidence. In contrast, our motivation for this method stems from the advantages demonstrated through the use of multiclass labels, for the one-vs-rest CIFAR-10 classification problem, over binary labels.\n    - Insights: Wu, et. al. (2010) justify their method by showing how linear decision boundaries between pseudo-classes found by COG can separate linearly inseparable classes. However, for DNN classifiers it is known that even random labels can fit perfectly on a training set (Zhang et al. (2021)), and hence the insight from Wu et al. (2010) is not valid for DNNs. In comparison, in this paper, we show the ability of the proposed method to learn meaningful representations (Figure 3 bottom pane), synchronize training across different labels (Figure 5), and achieve better performance (Figure 6). These insights shed light on the training dynamics in binary vs multiclass setting for the first time to the best of our knowledge, which could also be of independent interest.\n    - Implementation: In COG, pseudo labels are assigned by clustering the data in data space, we propose to cluster in the image encoding space. The choice of image encoder is central to the merits of the proposed method \u2013 it can be seen in Figure 3 (top pane) that naively clustering the data in raw image space, or even the representation space of autoencoder, will lead to very noisy pseudo labels and would result in poor final performance. We argue that this implementation detail of the proposed method is non-trivial for a practitioner implementing COG method for DNNs.\n\n\tTo conclude, we argue that this work provides a fresh perspective for exploring and expanding on the method proposed by Wu et al. (2010) as a powerful baseline method to tackle imbalance. \n- Clustering Method: We would like to thank the reviewer for pointing out the lack of clarity about the clustering algorithm in the method description, we have updated the paper to make it more clear. Essentially, the proposed method is agnostic to the choice of clustering algorithm, but the conventional K-means algorithm seems to perform well empirically. Note that the proposed method depends heavily on the choice of image encoder (which has been explored in detail in Section 2.1), but less so on the choice of clustering algorithm used in the image encoder space. A natural question could be if enforcing the clustering algorithm to generate relatively balanced clusters could be helpful, which is explored in the ablation study in Appendix B. Two balanced clustering algorithms: constrained K-means(Bradley et al. (2000)) and Normalized Cut (Shi et al. (2000)) have been compared with the naive K-means method. We find that balanced clustering can lead to slightly better BA, but perform much worse in terms of AP metric, and hence the choice of a simple K-means algorithm is proposed.\n- Comparison for long-tailed learning dataset: Extension of the proposed method to long-tailed learning setting has been left open for future work. This requires careful handling of the tail classes, and addressing the explosion in numbers of pseudo-classes due to the extremely small sample size in tail classes. We have briefly discussed the merits of exploring classical imbalance classification methods in the last paragraph of Section 3: numerous practical applications still fall under classical imbalance setting, and classical methods often form a base for long-tailed learning methods. The competing methods have also been chosen accordingly. To show that our proposed method can work well in a classical imbalance classification setting, we added an extended experiment using the financial phasebank dataset (Malo et al. (2014)). The details of the experiment setup and results can be found in the revised appendix. For a quick summary, we observed consistent improvements of RG over other baselines, both in terms of BA and AP."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4181/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700114897799,
                "cdate": 1700114897799,
                "tmdate": 1700114897799,
                "mdate": 1700114897799,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "T0SAfdvTmQ",
                "forum": "tkmO6bXT54",
                "replyto": "VP6nKJGV6l",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4181/Reviewer_AJcJ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4181/Reviewer_AJcJ"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the response. After reading the rebuttal, I appreciate the authors' effort and encourage the authors to further refine their works. The rating is remained given the current unsolved concerns.\n\nBest,\n\nThe reviewer."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4181/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700620564107,
                "cdate": 1700620564107,
                "tmdate": 1700620599719,
                "mdate": 1700620599719,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "cgnHTLlvT8",
            "forum": "tkmO6bXT54",
            "replyto": "tkmO6bXT54",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4181/Reviewer_nZ1i"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4181/Reviewer_nZ1i"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a simple solution for class imbalanced problem by grouping the majority class to smaller sub-classes. The paper is well-written and easy to read."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Showcasing how multi-class classification by regrouping the majority class to smaller sub-classes work better than a binary classification."
                },
                "weaknesses": {
                    "value": "- In the experiments there are no error bars. \n- There is no experiment that any model that is not data hungry has been applied to compare it with DNN."
                },
                "questions": {
                    "value": "- I would like to see the experiments results with error bars included. For example if you run the experiment n times and calculate standard deviation.\n- I would also like to see how the results change if you apply non-hungry methods such as Gaussian processes.\n- Sometimes groping the classes to small sub-groups is a difficult task by itself, how do you decide what type of data you can use to have this meaningful sub-groups? What happens if you can't put them into smaller groups?\n- What are the limitations of your method?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4181/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698755581378,
            "cdate": 1698755581378,
            "tmdate": 1699636383879,
            "mdate": 1699636383879,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6PLqG85GK1",
                "forum": "tkmO6bXT54",
                "replyto": "cgnHTLlvT8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4181/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4181/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' Response"
                    },
                    "comment": {
                        "value": "We would like to heartfully thank the reviewer for their considerate comments and critiques of our work. In the following, we have addressed some of the questions raised in the review. Please feel free to follow up if any aspects are unclear, or if there are further questions.\n\n- Error Bars: We have rerun all the experiments with 3 random seeds and report the mean with standard deviation, please see the updated results in the revised manuscript.\n- Gaussian Processes: In this paper, we mainly focus on classification based on deep learning models, especially in the image domain. We could find only two works that address Gaussian Process-based classification for image data (Blomqvist et al. (2020), Van der Wilk et al. (2017)), but their public code repositories have not been maintained and we are unable to implement these methods from scratch due to limited time of the discussion period. However, the method proposed by Wu et al. (2010) is similar to the proposed method for tabular data where results on linear SVM models are provided, which may be of interest to the reviewer. \n- Meaningful subgroups: A potential way to check whether the data can be partitioned into sub-groups is to make use of a visualization tool such as t-SNE plot (For example: As used in Figure 3 top pane). When data cannot be put into meaningful subgroups, it might point to the choice of encoder model (i.e. CLIP model in our case), and other encoder models can be tried.\n- Limitations: The key limitation of the proposed method is to handle long-tailed datasets, where the tail classes lie in the few-shot learning setting (i.e. tail classes have few training samples). This leads to an explosion in the number of pseudo-classes, and hence extension to this setting is non-trivial and left open for future work. Another limitation is that the number of pseudo-classes (K) in the current format is a tuning hyper-parameter, a future work could try to deduce this in a more methodological manner to save excess computation for tuning the hyper-parameter.\n\nReferences:\n- Blomqvist, K., Kaski, S., & Heinonen, M. (2020). Deep convolutional Gaussian processes. In Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2019, W\u00fcrzburg, Germany, September 16\u201320, 2019, Proceedings, Part II (pp. 582-597). Springer International Publishing.\n- Van der Wilk, M., Rasmussen, C. E., & Hensman, J. (2017). Convolutional gaussian processes. Advances in Neural Information Processing Systems, 30.\n- Wu, J., Xiong, H., & Chen, J. (2010). COG: local decomposition for rare class analysis. Data Mining and Knowledge Discovery, 20, 191-220."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4181/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700114626384,
                "cdate": 1700114626384,
                "tmdate": 1700114626384,
                "mdate": 1700114626384,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WNoYzGe2H6",
                "forum": "tkmO6bXT54",
                "replyto": "6PLqG85GK1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4181/Reviewer_nZ1i"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4181/Reviewer_nZ1i"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your response"
                    },
                    "comment": {
                        "value": "I wanted to thank the authors for their response.\nThanks for adding the error bars and also for the further explanation of the method.\nAfter reading other reviewers' comments, I decided I will keep my score."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4181/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700573650527,
                "cdate": 1700573650527,
                "tmdate": 1700573650527,
                "mdate": 1700573650527,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]