[
    {
        "title": "Neural Field Classifiers via Target Encoding and Classification Loss"
    },
    {
        "review": {
            "id": "gcNZVt5Tc6",
            "forum": "9NqC72m31m",
            "replyto": "9NqC72m31m",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1195/Reviewer_dKd6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1195/Reviewer_dKd6"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes to formulate the neural field methods as a classification problem rather than the traditional regression problem. To achieve this, the continuous RGB value is encoded as an 8-bit binary (discrete) vector, and BCE loss is used to train the model. Experiments on novel view synthesis and neural surface reconstruction validate that the proposed classification method is superior to its regression variant."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The motivation is clear, and the readability is satisfying to me (not an expert in Nerf);\n\n2. The proposed method is simple yet effective;\n\n3. Experiments on various datasets are conducted to validate the effectiveness of the method."
                },
                "weaknesses": {
                    "value": "1. The ablation study is insufficient:\n    - It can be observed from Eq. (6) that the original regression loss is still included. Although the authors pointed out that the BCE loss is significantly larger than the regression loss, I'm still curious about the effect of using BCE loss only. Since the BCE loss is more dominant, is the regression loss essential?\n    - It seems that without text encoding, the performance is close to the final version. Moreover, only two scenes of one dataset are used to conduct the ablation study. I'm wondering, on average (all scenes and other datasets), is the text encoding essential, or is it optimal?\n\n2. The implementation and comparison are conducted based on methods published in 2020 and 2021. Only DVGO was published in CVPR 2022, which was also long ago. It is kindly suggested to conduct experiments on more recent SOTA methods to evaluate the effectiveness and generality of the proposed approach."
                },
                "questions": {
                    "value": "See weaknesses.\n\nNote: Since I'm not an expert in Nerf, I'm truly wondering, why such a simple yet effective formulation is proposed in 2023."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1195/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1195/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1195/Reviewer_dKd6"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1195/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698396819383,
            "cdate": 1698396819383,
            "tmdate": 1700712309684,
            "mdate": 1700712309684,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "W8nZVF5rPc",
                "forum": "9NqC72m31m",
                "replyto": "gcNZVt5Tc6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1195/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1195/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer dKd6"
                    },
                    "comment": {
                        "value": "We sincerely appreciate Reviewer dKd6\u2019s kind support and helpful comments. \n\nWe properly addressed your concerns below.\n\nQ1: I'm still curious about the effect of using BCE loss only. Since the BCE loss is more dominant, is the regression loss essential?\n\nA1: A good question. Although the (slightly modified with ) BCE is more dominant, the regression loss is still helpful. We note that the the modification (the clip) of the classification loss is desired for the numerical stability as the integrated probability through volume rendering may be slightly greater than or equal to one. However, the clip operation is non-differentialable for some data samples where the predicted target $\\hat{C}\\geq 1-\\epsilon$. For these samples, the classification loss can only produce zero gradient. This explains when the regression loss dominate the classification loss and why the regression loss is still usually helpful.\n\nQ2: It seems that without text encoding, the performance is close to the final version. Moreover, only two scenes of one dataset are used to conduct the ablation study. I'm wondering, on average (all scenes and other datasets), is the text encoding essential, or is it optimal?\n\nA2: We respectfully note that the PSNR gains in our two ablation studies are 1.76 and 1.25, and such PNSR gains can be considered to be very significant in NeRF studies. Most new NeRF methods cannot outperform the baselines by more than 1 PSNR gain. If the reviewer want to know more about recent empirical advancements of NeRF studies, please refer to recent top-conference NeRF papers ( e.g. Trivec ICCV2023).\n\nThus, while the classification loss itself can lead to a more significant improvement, we hold that the target encoding is still expected to be helpful in most cases. \n\nIn fact, the regression loss (discussed in Q1-A1) and target encoding are both helpful and positive, while their effects are less significant than the (modified) BCE loss term.\n\nQ3: The implementation and comparison are conducted based on methods published in 2020 and 2021. Only DVGO was published in CVPR 2022, which was also long ago. It is kindly suggested to conduct experiments on more recent SOTA methods to evaluate the effectiveness and generality of the proposed approach.\n\nA3: Thanks for the constructive suggestion. The currently used NeRF backnones are all popular and representative methods covering the tasks of static scenes, geometry reconstruction, and dynamic scenes. The experiments are comprehensive.\n\nSome recent works proposed in 2023 (e.g. Strivec) are considered to be SOTA. In our recent supplementary experiment, Strivec-C can outperform Strivec-R by 3 PSNR gain. We are conducting more comparative experiments using SOTA methods proposed in 2023. We would like to present more empirical results of recent NeRF variants for comparing NFC and NFR in the revision.\n\nQ4: Since I'm not an expert in Nerf, I'm truly wondering, why such a simple yet effective formulation is proposed in 2023.\n\nA4: An interesting question. We personally tend to think that most researchers from the NeRF community focus more on modifying backbones and lack the motivation/tradition to rethink the basic formula of NeRF from a learning perspective. Moreover, the numerical instability problem of directly using the BCE loss may have prevented some researchers\u2019 early explorations along this direction.\n\n\nReference:\n\n[1] Gao, Q., Xu, Q., Su, H., Neumann, U., & Xu, Z. (2023). Strivec: Sparse tri-vector radiance fields. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 17569-17579)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700457070939,
                "cdate": 1700457070939,
                "tmdate": 1700457476573,
                "mdate": 1700457476573,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8t2g8AglZ4",
                "forum": "9NqC72m31m",
                "replyto": "W8nZVF5rPc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1195/Reviewer_dKd6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1195/Reviewer_dKd6"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the explanation, which addresses most of my concerns. I'm still curious about the ablation study of text encoding. On average (other datasets and scenes), how does it improve the performance? Moreover, I'm wondering if there are other design choices for text encoding, and how they perform."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700532578928,
                "cdate": 1700532578928,
                "tmdate": 1700532578928,
                "mdate": 1700532578928,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TRcnbb1Zsj",
                "forum": "9NqC72m31m",
                "replyto": "HxC3hYqIzI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1195/Reviewer_dKd6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1195/Reviewer_dKd6"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks. I would like to raise my rating if the mentioned results are updated in the revision."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700549121046,
                "cdate": 1700549121046,
                "tmdate": 1700549121046,
                "mdate": 1700549121046,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "OjM7o7817P",
                "forum": "9NqC72m31m",
                "replyto": "gcNZVt5Tc6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1195/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1195/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Paper Revision"
                    },
                    "comment": {
                        "value": "We gratefully appreciate your kind support! \n\nWe have revised our submission following your suggestions.\n\n\n-SOTA methods. We presented the quantitative and qualitative results of Strivec (ICCV 2023) in Table 12 and Figure 8, respectively. The results show that NFC may also improve very recent regression-based neural field methods. We will try to present more results of recent SOTA methods in future.\n\n-Ablation study. We presented the ablation study results over 8 scenes in Table 13. The results show that the classification loss plays a dominant role in the proposed NFC, while the Target Encoding module is still often helpful is most scenes (75%) and lead to expected performance improvements. We also revised our discussion on ablation study and note the dominant role of the classification in Section 4.3 (red-colored parts)."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700661441171,
                "cdate": 1700661441171,
                "tmdate": 1700665902599,
                "mdate": 1700665902599,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QUxv38jHHp",
                "forum": "9NqC72m31m",
                "replyto": "OjM7o7817P",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1195/Reviewer_dKd6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1195/Reviewer_dKd6"
                ],
                "content": {
                    "comment": {
                        "value": "After reading the responses and paper revision, I have raised my rating."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700712342647,
                "cdate": 1700712342647,
                "tmdate": 1700712342647,
                "mdate": 1700712342647,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "i59ub8CNAk",
            "forum": "9NqC72m31m",
            "replyto": "9NqC72m31m",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1195/Reviewer_fXmy"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1195/Reviewer_fXmy"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors proposed Neural Field Classifier that formulates existing neural field methods as classification tasks with target encoding and a classification loss. The authors conducted extensive experiments and visualizations to show that it is better than the regression based methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The formulation for classification with target encoding and BCE loss makes sense and is technically sound to me.\n2. Extensive quantitative and qualitative showed that it is better than standard regression based methods.\n3. Writing is good and easy to follow. The visualizations are also very informative and showed the improvement very clearly."
                },
                "weaknesses": {
                    "value": "1. Besides the experiments and visualization, there is no theoretical analysis of why the proposed classification based formulation is better than the standard regression methods. It is because that the classification loss is easier to optimize or?\n2. There is also little analysis on why it is more robust that the regression based methods?"
                },
                "questions": {
                    "value": "1. Why the proposed classification based formulation perform better than the standard regression based methods?\n2. Why is more robust that regression based methods?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1195/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698822308866,
            "cdate": 1698822308866,
            "tmdate": 1699636045771,
            "mdate": 1699636045771,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3nUyTcZo0a",
                "forum": "9NqC72m31m",
                "replyto": "i59ub8CNAk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1195/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1195/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer fXmy"
                    },
                    "comment": {
                        "value": "We highly appreciate Reviewer fXmy\u2019s kind support and hard work.\n\nWe properly addressed your concerns as follows.\n\nQ1: Besides the experiments and visualization, there is no theoretical analysis of why the proposed classification based formulation is better than the standard regression methods. It is because that the classification loss is easier to optimize or?\n\nA1: We frankly admit that there is no theoretical analysis yet. In fact, nearly all NeRF methods lack formal theoretical analysis about the rendering quality.\n\nHowever, according to the results in Figure 7, we may conjecture that the main advantage of NFC comes from better generalization of learned neural field models, while we also observe that optimizing the classification loss also leads to slightly better training quality. It will be a very promising future direction to explore why the classification loss may lead to better generalization.\n\nQ2: There is also little analysis on why it is more robust that the regression based methods?\n\nA2: Thanks for pointing out this promising research challenge. Similarly to Q1-A1, indeed, our work and related neural field studies did not formulate theoretical understanding of NeRFs. In fact, most 3D vision-related works lack formal theoretical understanding due to the methodology complexity.\n\nAccording to the intuition and existing empirical analysis, the advantages of NFC may come from multiple sources, including better training quality and better generalization. However, the formal theoretical mechanism is beyond the main scope of this work. We appreciate your suggestion and will explore the theoretical mechanism of generalization and robustness of neural field models in future. \n\nFinally, we sincerely thank the reviewer again for your kind support!"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700456653228,
                "cdate": 1700456653228,
                "tmdate": 1700456653228,
                "mdate": 1700456653228,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6DWXH8Zb6x",
                "forum": "9NqC72m31m",
                "replyto": "3nUyTcZo0a",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1195/Reviewer_fXmy"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1195/Reviewer_fXmy"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the explanation. I do not have more questions and will keep my original positive rating."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700593417410,
                "cdate": 1700593417410,
                "tmdate": 1700593417410,
                "mdate": 1700593417410,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "EuIeohnrB4",
            "forum": "9NqC72m31m",
            "replyto": "9NqC72m31m",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1195/Reviewer_WcH4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1195/Reviewer_WcH4"
            ],
            "content": {
                "summary": {
                    "value": "The paper investigates whether regression can be replaced by classification for neural fields, particularly for the application of novel view synthesis. They propose a framework for transforming regression into classification using a binary encoding. They show that this formulation can effectively be optimized and perform experiments for novel view synthesis, the primary application of neural fields. They benchmark an array of NeRF methods and show that using classification loss improves novel view synthesis metrics by a significant margin. Also they show that classification leads to better robustness to corruption and better sample efficiency."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The idea is to my knowledge the first to investigate classification as an objective for neural fields. The idea is interesting and applicable to most neural field architectures and is relatively agnostic to data type.\n\n- The idea is general and could be applied to many different applications. I think this would be of interest to people in the neural field community. \n\n- The results are strong and the experiments are thorough. The paper evaluates on multiple novel view synthesis datasets and benchmarks an array of NeRF variants.\n\nThe figures are illustrative and convey the main ideas of the paper."
                },
                "weaknesses": {
                    "value": "Overall the weaknesses are relatively minor. \n\n- The experiments are restricted to the domain of novel view synthesis. \n\n- The qualitative results for the baselines look unreasonably poor. I would think that a vanilla NeRF model would look better on the scenes presented in the figures. \n\n- Some parts of the method section are a little unclear. See questions."
                },
                "questions": {
                    "value": "- How many training views are given for the Replica scenes? I couldn't find that detail in the paper. The results for regression in figure 3 look particularly poor. I would expect a crisper result for regression with a reasonable number of views. \n\n- How is sigma being output by the MLP? Is that still being regressed, and if so why not encode it as a classification problem? \n\n- How is the volume rendering part performed? Do you use the standard volume rendering equation and integrate the bits with sigma?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1195/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698831397341,
            "cdate": 1698831397341,
            "tmdate": 1699636045693,
            "mdate": 1699636045693,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9TtzElc0dA",
                "forum": "9NqC72m31m",
                "replyto": "EuIeohnrB4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1195/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1195/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer WcH4"
                    },
                    "comment": {
                        "value": "We sincerely appreciate Reviewer WcH4\u2019s kind support and constructive comments. \n\nWe addressed your concerns below.\n\nQ1: The experiments are restricted to the domain of novel view synthesis.\n\nA1: We admit that our experiments mainly focus on novel view synthesis, because the proposed classification paradigm is mainly designed for neural field methods. We also respectfully note that the experiments on geometry reconstruction in Tables 6 and 8 also support the advantage of our NFC method over the standard NFR method.\n\nQ2: The qualitative results for the baselines look unreasonably poor. I would think that a vanilla NeRF model would look better on the scenes presented in the figures.\n\nA2: Thanks for the suggestion. We presented the qualitative results of vanilla NeRF in Figure 3 Top Row. The regression baseline look well, while the classification variant is still significantly better. We would like to present more qualitative results of vanilla NeRF in the revision.\n\nQ3: How many training views are given for the Replica scenes? I couldn't find that detail in the paper. The results for regression in figure 3 look particularly poor. I would expect a crisper result for regression with a reasonable number of views.\n\nA3: We respectfully note that the details of dataset preprocessing including datset split of Replica are presented in Appendix A.2. We used 90% images (~90 views) for training and 10% images (~10 views) for evaluation. \n\nThe results of NeuS-R on Replica in Table 6 actually look reasonably well, while the results of DVGO-R on Replica in Table 3 are indeed poor. As the training dataset are totally same, our results suggest that the accelerated NeRF variants like DVGO are not powerful enough complex scenes (e.g. Replica), which contain many details.\n\nHowever, for both NeuS and DVGO, our classifier-based method can significantly improve the rendering quality. Thus, we believe our experiments using DVGO and NeuS together can support the advantage of our NFC over the conventional NFR.\n\nQ4: How is sigma being output by the MLP? Is that still being regressed, and if so why not encode it as a classification problem?\n\nA4: A very good question. While, in principle, the density $\\sigma$ can be encoded as a classification problem, we believe regressing $\\sigma$ is a better choice for three reasons. First, most importantly, encoding $\\sigma$ does not significantly improve the rendering quality in our early experiments. Second, the extra computational cost of encoding $\\sigma$ is significantly larger than only encoding rgb, because, for example, an 8-channel $\\sigma$ encoding may reqiure $8$ decoding costs for making once prediction. Thrid, some NeRF variants use two different network backbones for predicting the rgb color and the density, where encoding the density neural network may require more coding costs. In summary, the pitfalls (more costs and complexity) significantly outweigh its benefits (nearly zero performance improvement) .\n\nQ5: How is the volume rendering part performed? Do you use the standard volume rendering equation and integrate the bits with sigma?\n\nA5: We follow the standard volume rendering process. The only difference is that we integrate the predicted probabilities of each bits with the density.\n\n\nReviewer WcH4 definitely recognizes the novelty and significance of our work.\n\nWe would gratefully appreciate it, if the reviewer could insist on the opinion during the discussion and try to avoid a possible loss to the community."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700456327671,
                "cdate": 1700456327671,
                "tmdate": 1700456327671,
                "mdate": 1700456327671,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KNiiXbvSGb",
                "forum": "9NqC72m31m",
                "replyto": "9TtzElc0dA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1195/Reviewer_WcH4"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1195/Reviewer_WcH4"
                ],
                "content": {
                    "title": {
                        "value": "Reviewer Response"
                    },
                    "comment": {
                        "value": "I thank the authors for their thorough response to my comments and questions. After reading other reviewer concerns and author comments I am maintaining my score at 6. I think the paper presents a general and interesting approach to neural fields, and could be of significant interest to the community."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700699502507,
                "cdate": 1700699502507,
                "tmdate": 1700699502507,
                "mdate": 1700699502507,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "f9vmR1VUGw",
            "forum": "9NqC72m31m",
            "replyto": "9NqC72m31m",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1195/Reviewer_zn3A"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1195/Reviewer_zn3A"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a novel Neural Field Classifier (NFC) framework that formulates existing neural field methods as classification tasks rather than regression tasks. The method also uses Target Encoding to encode continuous targets for regression tasks into discrete targets for classification tasks. The overall writing is clear. The experiments cover the comparison between the Regression model and the Classification model.\n\n\nRaise score to 6 after rebuttal."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The overall writing is clear.\n2. The experiments clearly show the improvement of the Classification model over the Regression model."
                },
                "weaknesses": {
                    "value": "1. Some important reference is missing, such as [a]. \n2. [a] uses the CNN encoders to process the images. The idea of the proposed classifier looks similar to [a].\n3. The biggest problem is the compared method. Among all the experiments, DVGO is compared extensively. However, DVGO is a method designed for acceleration, not for accuracy. It is unfair to compare the accuracy with a method not targeting accuracy.\n4. What is the State-of-the-art accuracy of NeRF? Please compare with these methods regarding accuracy.\n5. What is the computational cost of the proposed classifier-based methods? Please compare with DVGO regarding FLOPs and wall-clock time.\n\n\n[a] pixelNeRF: Neural Radiance Fields from One or Few Images, CVPR 2021"
                },
                "questions": {
                    "value": "see weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1195/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1195/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1195/Reviewer_zn3A"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1195/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698844876731,
            "cdate": 1698844876731,
            "tmdate": 1700667484400,
            "mdate": 1700667484400,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "iYKHnakZuz",
                "forum": "9NqC72m31m",
                "replyto": "f9vmR1VUGw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1195/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1195/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Reviewer zn3A"
                    },
                    "comment": {
                        "value": "We sincerely appreciate Reviewer zn3A\u2019s hard work and constructive comments. \n\nWe addressed your main concerns below. \n\nQ1: Some important reference is missing, such as [a]PixelNeRF.\n\nA1: Thanks for providing the reference. In fact, any existing regression-based NeRF variant could be the baseline. We would like to discuss more existing NeRF methods, including PixelNeRF.\n\nQ2: PixelNeRF uses the CNN encoders to process the images. The idea of the proposed classifier looks similar to PixelNeRF.\n\nA2: We are afraid that the reviewer may misunderstand our work or PixelNeRF. We respectfully argue that PixelNeRF and the proposed NF classification paradigm are two totally different methods. Our work does not use any CNN encoder to process the images. Our two contributions, Target Encoding and Classification Loss, are not touched by PixelNeRF. Moreover, the classification paradigm can be incorporated into the (regression-based) PixelNeRF rather than replacing.\n\nQ3: The biggest problem is the compared method. Among all the experiments, DVGO is compared extensively. However, DVGO is a method designed for acceleration, not for accuracy. It is unfair to compare the accuracy with a method not targeting accuracy.\n\nA3: Our work actually has only one baseline method, the regression paradigm compared with our classification paradigm. We kindly argue that, besides DVGO, we also train vanilla NeRF, NeuS, and D-NeRF as the backbone methods on 14 different scenes, including static scenes, geometry reconstruction, and dynamic scenes. The experiments are still comprehensive. Particularly, when the regression-based neural field models seriously overfit training views (as Figure 7 suggests), our classification-based method can significantly improve generalization and mitigate overfitting.  \n\n\nOur prior backbone is the accelerated NeRF variant also because the accelerated variant is more environment-friendly and can significantly reduce the energy costs and carbon emissions of our work. In the line of NeRF research, people actually focused more on improving the rendering quality of the accelerated NeRF variants, because the efficiency rather than the quality (for standard static scenes) is often considered the main limitation of vanilla NeRF.\n\nRecent NeRF works, including Strivec (ICCV2023) and Zip-NeRF (ICCV2023), almost all aimed at (1) accurate and fast rendering, or (2) accurate rendering under some constrains (e.g. sparse/dynamic/corruption). Our experiments have covered these experimental settings.\n\n\nQ4: What is the State-of-the-art accuracy of NeRF? Please compare with these methods regarding accuracy.\n\nA4: Thanks for the helpful suggestion. Some recent works (e.g. Strivec ) proposed in 2023 are considered to be SOTA. In our recent supplementary experiment, Strivec-C can outperform Strivec-R by 3 PSNR gain. We are conducting more comparative experiments using SOTA methods proposed in 2023. We would like to present more empirical results of recent NeRF variants for comparing NFC and NFR in the revision.\n\nQ5: What is the computational cost of the proposed classifier-based methods? Please compare with DVGO regarding FLOPs and wall-clock time.\n\nA5: We respectfully note that we studied the extra computational costs of the classifier-based methods in Tables 7 and 8, using DVGO and NeuS for novel view synthesis and geometry reconstruction, respectively. The numerical results show that the extra computational costs of two components are marginal (only 6% for DVGO and 5% for NeuS).\n\n\nReference:\n\n[1] Gao, Q., Xu, Q., Su, H., Neumann, U., & Xu, Z. (2023). Strivec: Sparse tri-vector radiance fields. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 17569-17579)."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700456206546,
                "cdate": 1700456206546,
                "tmdate": 1700456206546,
                "mdate": 1700456206546,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VTQdC7x16Q",
                "forum": "9NqC72m31m",
                "replyto": "iYKHnakZuz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1195/Reviewer_zn3A"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1195/Reviewer_zn3A"
                ],
                "content": {
                    "comment": {
                        "value": "> Recent NeRF works, including Strivec (ICCV2023) and Zip-NeRF (ICCV2023), almost all aimed at (1) accurate and fast rendering, or (2) accurate rendering under some constrains (e.g. sparse/dynamic/corruption). Our experiments have covered these experimental settings.\n\nThanks for the response. However, I didn't see a clear demonstration regarding the **fast speed** of the proposed method. Considering the recent methods targeting **accurate and fast**, merely reporting accuracy is insufficient. I would recommend including both training time and inference time comparisons with recent methods. Therefore, I will keep my score."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700615209526,
                "cdate": 1700615209526,
                "tmdate": 1700615209526,
                "mdate": 1700615209526,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ak1WnFP5UC",
                "forum": "9NqC72m31m",
                "replyto": "ITYB4HHZ0q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1195/Reviewer_zn3A"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1195/Reviewer_zn3A"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the explanation. This solves most of my concerns. \n\nI will raise my score to 6. For the final version, please add complementary experimental results regarding different methods (including DVGO, NeRF, NeuS, Strivec) on different datasets (including Replica Dataset, T&T Dataset). Table 1 and Table 2 show part of the combinations but not all of them. Also, I hope the algorithm can be open-sourced."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1195/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700667441925,
                "cdate": 1700667441925,
                "tmdate": 1700667441925,
                "mdate": 1700667441925,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]