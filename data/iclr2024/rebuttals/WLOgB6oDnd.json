[
    {
        "title": "KNIFE: Distilling Reasoning Knowledge From Free-Text Rationales"
    },
    {
        "review": {
            "id": "gykzbknRRB",
            "forum": "WLOgB6oDnd",
            "replyto": "WLOgB6oDnd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6075/Reviewer_HVcW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6075/Reviewer_HVcW"
            ],
            "content": {
                "summary": {
                    "value": "This paper explores the idea of distilling knowledge from free-text explanations. They start by training a \"teacher\" model, which learns to make predictions using both the free-text explanations and task inputs. This helps the teacher model absorb the knowledge from the free-text explanations into its hidden state. Next, they build a \"student\" model and make sure its hidden state aligns with the teacher's, all without directly using the free-text explanations. They then put their models to the test on two question-answering tasks, comparing them to various baseline models with different fine-tuning and initialization approaches. Impressively, their models outperform these baselines. Additionally, they carry out an ablation study to understand how different parts of their model contribute to its success."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "They study the idea of knowledge distillation from free-text rationales and did comprehensive experiments to show the effectiveness of the approach."
                },
                "weaknesses": {
                    "value": "* The idea behind this approach isn't very convincing. The teacher model can't store a lot of knowledge, and it might not work well for different tasks. Plus, it's unclear how this method is better than retrieval-augmented generation.\n* To prove its effectiveness, more experiments should be done, comparing it to retrieval-augmented generation and testing it on various downstream tasks.\n* The improvement from introducing free-text rationale into the teacher model isn't substantial, and it might be because of the extra knowledge.\n* Their best model still falls far short of the Large Language Models (LLM) by a significant margin, and the student model doesn't seem to improve model explanation and reasoning."
                },
                "questions": {
                    "value": "1. What is the upper-bound performance achievable by the small model when given the task input and free-text rationale together?\n2. How does this approach compare favorably to \"retrieve-augmented-generation,\" a method that initially retrieves relevant knowledge, such as free-text rationales, and then enhances the input with this retrieved knowledge?\n3. Why does incorporating the free-text rationale during the teacher model's fine-tuning enhance the student model's performance? It's possible that the improvement shown in Figure 3(a) is due to the extra knowledge contained in the free-text rationale, which could be beneficial for the downstream tasks. This improvement, while not substantial, might not generalize well to scenarios with less overlap in knowledge or when using larger free-text rationales for teacher model fine-tuning. This raises questions about the broader applicability of this approach."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6075/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698613008348,
            "cdate": 1698613008348,
            "tmdate": 1699636654767,
            "mdate": 1699636654767,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lul3HjngSj",
                "forum": "WLOgB6oDnd",
                "replyto": "gykzbknRRB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6075/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6075/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer HVcW"
                    },
                    "comment": {
                        "value": "Thank you for your insightful and constructive feedback! We were encouraged that you see our comprehensive experiments and analysis. Below, we provide clarifications and address the concerns you raised.\n\n**(1) Retrieval-Augmented Approach as Baseline** (Weakness 1, Weakness 2, Question 2)\n\nThanks for your helpful suggestions! Please refer to the general response for more details.\n\n**(2) Justification for KNIFE Design** (Weakness 1, Question 3)\n\nThe teacher model is indeed capable of storing task-level reasoning knowledge. This is empirically evidenced in Table 12 (see more discussions below), where the teacher model demonstrates very high performance.\n\nRegarding the improvement of the student model's performance through the incorporation of FTRs during the teacher's training: Our intuition is that the teacher's finetuning aggregates reasoning knowledge from FTRs across all instances, subsequently embedding this knowledge in the teacher\u2019s hidden states. KNIFE leverages these enriched hidden states as soft labels, enabling the distillation of reasoning knowledge from the teacher to the student via the collection of all soft labels. During the student model\u2019s inference, its output is not explicitly conditioned on specific FTRs, but rather, it is implicitly influenced by the distilled reasoning knowledge embedded within the student's parameters.\n\n**(3) Upper-Bound Performance** (Question 1)\n\nThe upper-bound performance is achieved by providing the task inputs and FTRs to models during both training and inference, which is reflected in the teacher model\u2019s performance when using FTRs during inference as reported in Table 12. Compared to FT (I\u2192O), the accuracy improvement is approximately 16% and 7% on OpenbookQA and StrategyQA, respectively, which is quite substantial. It's important to note that this performance should not be compared to results where the FTRs are not accessible during inference.\n\n**(4) Teacher Model Performance** (Weakness 3)\n\nWhile you suggest that the improvement of the teacher model might be due to extra knowledge, we posit that this is an inherent advantage of our approach. As discussed, a set of task instances that sufficiently characterizes a task implies that a set of FTRs for these instances can collectively capture task-level reasoning knowledge that generalizes to unseen task instances. This task-level reasoning knowledge is transferred to the teacher by finetuning it on both the task inputs and the FTRs. Previous works on small models failed to extract such extra knowledge. By contrast, KNIFE successfully improves the model performance by effectively extracting extra knowledge provided by FTRs.\n\n**(5) Performance Improvement** (Weakness 1, Weakness 4)\n\nWe conducted the Wilcoxon rank-sum test between KNIFE and the best baseline for each OBQA/StrategyQA setting, and for both human-written and model-annotated FTR sources. KNIFE achieves statistically significant improvements (p<0.05) over the best baseline in all settings, except in the T5-Large\u2192T5-Large on StrategyQA.\n\nWe also believe that the comparison to large-scale language models (LLMs) is unfair, as they are often approximately 100 times larger than the LMs we experimented with. Our focus is on how to improve the performance of smaller LMs. To our knowledge, previous works have even failed to improve small-scale LMs by incorporating FTRs. We believe KNIFE represents an important contribution to the field of learning from FTRs.\n\n**(6) FTRs\u2019 Influence on KNIFE\u2019s Performance** (Question 3)\n\nWe appreciate your insights regarding the influence of FTRs on KNIFE's performance. Indeed, since KNIFE distills knowledge from FTRs into the student language model, the student's performance is expected to depend on the quantity and quality of reasoning knowledge contained in the FTRs. You are correct in noting that if the FTRs are uninformative (in terms of providing task-level reasoning knowledge), KNIFE's ability to enhance model performance is limited. We have provided additional analysis and case studies in Section 4.6."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6075/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700121071466,
                "cdate": 1700121071466,
                "tmdate": 1700139576395,
                "mdate": 1700139576395,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "NlzThyYyDG",
            "forum": "WLOgB6oDnd",
            "replyto": "WLOgB6oDnd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6075/Reviewer_MPYM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6075/Reviewer_MPYM"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes KNowledge dIstillation from Free-text rationalEs (KNIFE), a distillation method that leverages open-source pretrained seq2seq models and training data with free-text rationale (FTR) annotations to develop an accurate question-answering prediction model. It first finetunes a teacher LM to input question and FTR and output the answer. Then it finetunes a student to input the question and output the answer, while aligning to the teacher's hidden states. The student outperforms finetuning and prompting baselines in fully-supervised and low-resource settings. The paper further shows that the FTR quality is important to the success."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The scenario is likely: there are rationale annotations for training data, but these annotations are not readily available at test time.\n- The method is intuitive and effective. The bottleneck architecture has novelty.\n- Compared with multiple baselines and performed careful ablation study."
                },
                "weaknesses": {
                    "value": "- The paper is about classification and shows advantages on two datasets. Results on more tasks will be helpful for showing the generality of the method. Does the method work for reasoning tasks commonly used by the chain-of-thought literature, such as, arithmetic reasoning, commonsense reasoning, and code generation? Does it work for knowledge-intensive tasks?\n- The paper doesn't have a retrieval-augmentation baseline. Will the numbers look better if you finetune T5 to learn to condition on retrieved (question, rationale, answer) demonstrations, instead of distilling rationales from text to a teacher and then to a student?"
                },
                "questions": {
                    "value": "Please refer to the Weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6075/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698823979588,
            "cdate": 1698823979588,
            "tmdate": 1699636654642,
            "mdate": 1699636654642,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Cuc8FzIDSa",
                "forum": "WLOgB6oDnd",
                "replyto": "NlzThyYyDG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6075/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6075/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer MPYM"
                    },
                    "comment": {
                        "value": "Thank you for your insightful and constructive feedback! We were encouraged that you see KNIFE\u2019s novelty, effectiveness, and usefulness and our comprehensive experiments and analysis. Below, we provide clarifications and address the concerns you raised.\n\nFor the task type, KNIFE\u2019s design is generic enough that it could be extended to generation tasks. Classification and generation tasks differ primarily in their output formats, but KNIFE\u2019s key components (i.e., teacher bottleneck and teacher-student hidden states distillation) do not involve the LM\u2019s final output specifically. We leave the extension of KNIFE to generation tasks for future work.\n\nFor the retrieved-augmented baselines, thanks for your helpful suggestions! Please refer to the general response for more details."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6075/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700120967285,
                "cdate": 1700120967285,
                "tmdate": 1700120967285,
                "mdate": 1700120967285,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "xj1TwdTZ3f",
            "forum": "WLOgB6oDnd",
            "replyto": "WLOgB6oDnd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6075/Reviewer_izvw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6075/Reviewer_izvw"
            ],
            "content": {
                "summary": {
                    "value": "This work introduces KNowledge DIstillation From Free-Text RationalEs (KNIFE) as a method to effectively distill the reasoning knowledge from a large Language Model (LM) to a smaller LM, aiming to enhance the smaller LM\u2019s task performance. Specifically, the teacher model is fine-tuned to predict the answer based on the task input (question) and the pre-defined free-text raionales associated with each training data. Then, the hidden states of the encoder and output prediction distribution are used in knowledge distillation, transferring knowledge from the teacher model to the student model. Experimental results indicate that KNIFE is effective compared to the fine-tuning variants thanks to the knowledge distillation of both hidden states and output distribution."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- **New Approach to a Specific Problem;** The proposed method represents a novel approach to a specialized problem where either human-written or machine-generated free-text rationales are available, and the language model architecture is based on an encoder-decoder system like T5. As far as I am aware,  this particular issue hasn\u2019t been addressed in previous works.\n- **Thorough Analysis;** The authors conducted comprehensive experiments under various conditions, including two different sizes of LM architectures, two distinct datasets, varying input-output compositions, and FTR variants."
                },
                "weaknesses": {
                    "value": "- **Limited Contribution;** While I acknowledge the novelty and design of the prospoed method aimed at distilling reasoning knowledge from free-text rationales in encoder-decoder LMs, its contribution appears limited for several reasons:\n    - The efficacy of the proposed method, KNIFE, seems marginal as the improvements are not statistically significant based on some results in Table 1. For instance, in the StrategyQA dataset, KNIFE\u2019s performance is comparable to FT (I\u2192RO), suggesting that simple fine-tuning of the language model with FTR and using the answer as the target yields results similar to KNIFE. Additionally, the experimental results suggest that distilling from T5-Large to T5-Base is less effective than from T5-Base to T5-base, which is weird.\n    - The application scope of the proposed method is restricted both in task type and language model architecture. It\u2019s only suitable for multi-choice QA tasks when free-text rationales are available and is exclusive to LMs with encoder-decoder architecture like T5, making it unsuitable for decoder-only models like Llama.\n    - The individual contributions of each component in the proposed method remain ambiguous. In Tables 8 and 9, KNIFE with either KD-in loss only or KD-out loss only occasionally outperforms KNIFE with both objectives combined. This raises the question: is employing both objectives truly advantageous?\n- **Limited significance of the Problem;** Lately, there have been significant works [1,2,3] into distilling the reasoning ability of large LMs (e.g., Llama-2 or GPT-3.5-turbo) into smaller LMs. Given this context, how does the proposed method compare to existing approaches? In Appendix A.1., the authors posit that their method is advantageous when large-scale LMs lack reasoning abilities, a premise that seems out of sync with current trends in large language models.\n\n[1] Ho et al., Large language models are reasoning teachers, ACL 2023 \n\n[2] Magister et al., Teaching small language models to reason, ACL 2023\n\n[3] Fu et al., Specializing smaller language models towards multi-step reasoning, ICML 2023"
                },
                "questions": {
                    "value": "1. What is the advantage of this work compared to recent CoT distillation works mentioned in the second point of weaknesses?\n2. Why do the authors not include results with In only and out only in Table 1? I think this baseline is important to show the significance of using both objectives in KNIFE."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6075/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698835046428,
            "cdate": 1698835046428,
            "tmdate": 1699636654537,
            "mdate": 1699636654537,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZV41KMdSTu",
                "forum": "WLOgB6oDnd",
                "replyto": "xj1TwdTZ3f",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6075/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6075/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer izvw [1/2]"
                    },
                    "comment": {
                        "value": "Thank you for your insightful and constructive feedback! We were encouraged that you see KNIFE\u2019s great novelty and our comprehensive experiments and analysis. Below, we provide clarifications and address the concerns you raised.\n\n**(1) Performance Improvement**\n\nWe conducted the Wilcoxon rank-sum test between KNIFE and the best baseline for each OBQA/StrategyQA setting, and for both human-written and model-annotated FTR sources. KNIFE achieves statistically significant improvements (p<0.05) over the best baseline in all settings, except in the T5-Large\u2192T5-Large on StrategyQA. By contrast, previous works, to our knowledge, have even failed to improve small-scale LMs by incorporating FTRs. We believe KNIFE represents an important contribution to the field of learning from FTRs.\n\n**(2) Comparison between T5-Base\u2192T5-Base and T5-Large\u2192T5-Base**\n\nWe agree with your observation. It is indeed true that distilling from T5-Large to T5-Base (T5-Large\u2192T5-Base) is less effective than distilling from T5-Base to T5-Base (T5-Base\u2192T5-Base) in some settings, and this is not unusual. Our paper states an important implementation detail in Section 4.2: when the student and teacher models both use the same backbone (i.e., either T5-Base or T5-Large), the student\u2019s parameters are initialized with the teacher\u2019s. Additionally, T5-Base and T5-Large have different representation spaces in their hidden states, and since we perform distillation via these hidden states (as mentioned in footnote 4), there is an added complexity. We stated that we jointly train two linear projection layers to transform the hidden states for T5-Large\u2192T5-Base distillation, while T5-Base\u2192T5-Base distillation does not require this. These factors contribute to the increased difficulty in transferring reasoning knowledge from T5-Large to T5-Base compared to T5-Base to T5-Base. Although a T5-Large teacher model is expected to be stronger, the complexity of the distillation process also impacts performance. Due to the page limit, we will include a more comprehensive discussion on this topic in our next version.\n\n**(3) Application Scope**\n\nKNIFE\u2019s design is generic enough that it could be extended to generation tasks. Classification and generation tasks differ primarily in their output formats, but KNIFE\u2019s key components (i.e., teacher bottleneck and teacher-student hidden states distillation) do not involve the LM\u2019s final output specifically. We leave the extension of KNIFE to generation tasks for future work.\n\nAdditionally, the availability of FTRs during the training stage is a fundamental assumption in our study. We have discussed the feasibility of this setting in the Introduction section of our paper.\n\n**(4) Model Architecture**\n\nOur paper follows prior FTR-based works [1-3] in focusing on encoder-decoder LMs like T5, which has been shown to achieve strong \u201cout-of-the-box\u201d finetuning performance across a wide range of different text classification and generation tasks as well as produce its own FTRs.\n\nAlthough the teacher bottleneck is currently tailored for encoder-decoder LMs (since it operates in the cross-attention mechanism), the bottleneck could potentially be modified to work for decoder-only or encoder-only LMs (e.g., GPT, LLaMA, BERT) too. For these LMs, one possible bottleneck design would be to mask out the self-attention weights for all FTR tokens in the teacher LM\u2019s last k (e.g., k=1) layers, then perform KD only via the hidden states of the task input tokens in these last k layers. However, due to computational constraints, we leave investigation of decoder-only/encoder-only KNIFE designs to future work.\n\n**(5) Individual Contributions of KNIFE (In) and KNIFE (Out)**\n\nTo clarify, both KNIFE (In) and KNIFE (Out) are novel contributions of this work and not main baselines used for comparison. We refer readers to Table 2 (instead of Tables 8 or 9) for a comparison among KNIFE (In), KNIFE (Out), and KNIFE (In+Out). We observe that KNIFE (In+Out) generally achieves the highest performance, with a few exceptions. This indicates that valuable FTR knowledge can be distilled through both encoder and decoder hidden states, thus we recommend using both by default. Additionally, KNIFE (In) and KNIFE (Out) outperform all baselines in almost all cases. We included only KNIFE (In+Out) in the main table for clarity of presentation, aiming to convey the message that \u201cKNIFE can outperform all baselines\u201d without distracting readers. Then, a detailed comparison among the three KNIFE variants is provided in the following part of our paper. We will improve our presentation to better convey our messages in our next version.\n\nTable 8 mainly presents results for KNIFE without the bottleneck design, which is not used for comparing the three KNIFE variants as the bottleneck is a critical design feature of KNIFE. Table 9 focuses on results for KNIFE with task loss, which is also not used in the comparison since incorporating task loss degrades KNIFE\u2019s performance."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6075/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700120877988,
                "cdate": 1700120877988,
                "tmdate": 1700120877988,
                "mdate": 1700120877988,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2NR40og95C",
                "forum": "WLOgB6oDnd",
                "replyto": "xj1TwdTZ3f",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6075/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6075/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer izvw [2/2]"
                    },
                    "comment": {
                        "value": "**(6) Relevant Works about CoT Distillation**\n\nTo clarify, our method, KNIFE, is not predicated on the absence of reasoning abilities in large-scale LMs. Instead, one advantage actually lies in its independence from LLMs. This allows KNIFE to work effectively without relying on the computational resources required for large LMs. Regarding the comparison with the approaches mentioned in your review and our Appendix A.1, it is important to note that these methods leverage large LMs to enhance smaller models, whereas KNIFE utilizes FTRs. This difference in approach makes fair comparison challenging.\n\nIn fact, we posit that relying on large LMs, as these methods do, is a stronger assumption compared to access to FTRs, as people can employ LLMs for generating FTRs. We have experimented with generating FTRs using a medium-sized LM, GPT-neox, and found KNIFE effective in this context. Due to computational constraints, exploring this further with larger LMs like ChatGPT and LLaMA-70B remains a goal for future research.\n\nMost of the referenced works can be seen as utilizing LMs for FTR generation and training another model in I\u2192RO. Our findings indicate that the I\u2192RO is not effective with the FTRs we have experimented with. This observation leads us to believe that the **generation of high-quality FTRs** by LLMs is crucial in those approaches. As our work focuses on the **utilization of FTRs**, positioning it also as complementary to those approaches.\n\nWe will add more discussion on the points above in our next version.\n\n[1] Narang et al. \u201cWT5?! Training Text-to-Text Models to Explain their Predictions.\u201d 2020. \n\n[2] Sun et al. \u201cInvestigating the Benefits of Free-Form Rationales.\u201d 2022.\n\n[3] Wiegreffe et al. \u201cMeasuring Association Between Labels and Free-Text Rationales.\u201d 2021."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6075/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700120912949,
                "cdate": 1700120912949,
                "tmdate": 1700121149906,
                "mdate": 1700121149906,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "o41g7OrDoU",
                "forum": "WLOgB6oDnd",
                "replyto": "xj1TwdTZ3f",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6075/Reviewer_izvw"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6075/Reviewer_izvw"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your detailed response. After reading the author's reply and other reviews, my confidence has grown that this paper is not yet ready for publication. Specifically, while I acknowledge the statistical significance of the performance improvement, I question the applicability of the proposed method in the various scenarios mentioned by the authors, in the absence of adequate empirical evidence. Beyond the novelty and performance enhancement of the proposed method, I believe the experiments are still too limited, leaving readers unconvinced of the method's merits. I hope the authors will address this gap in their next revision."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6075/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700727388348,
                "cdate": 1700727388348,
                "tmdate": 1700727388348,
                "mdate": 1700727388348,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]