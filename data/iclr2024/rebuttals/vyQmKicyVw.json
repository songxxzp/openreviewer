[
    {
        "title": "Revealing Hidden Causal Variables and Latent Factors from Multiple Distributions"
    },
    {
        "review": {
            "id": "490oTnwSLQ",
            "forum": "vyQmKicyVw",
            "replyto": "vyQmKicyVw",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission444/Reviewer_d7mo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission444/Reviewer_d7mo"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, causal inference with hidden factors is investigated. The model studied in equation (1) is quite general, and the focus of the work is to understand when and how the causal structure can be estimated from observations. \n\nIn the first set of results, the authors determine conditions under which the Markov graph underlying the conditional dependency structure of the variables can be uniquely identified from the distribution of observations (Thms 1 - 3). Furthermore, the latent factors which affect the hidden variables can also be identified (Thm 5). Finally, the authors assess their methods through simulations."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The authors study a very general model, and establish fundamental conditions for the identifiability of causal structures and latent factors. The fundamental contributions that are made for this model therefore have important and widespread applications. The paper is clearly written."
                },
                "weaknesses": {
                    "value": "While the bulk of the paper establishes fundamental results for causal inference, this seems to have little impact on the design or guarantees of machine learning algorithms. Though there is a Simulations section in which the authors apply their theory, there seem to be many details and analysis missing. For instance, it is not clear to me how the data is generated, and the results shown in Figures 2 and 3 have little explanation. Hence it is quite challenging to understand what exactly the authors are trying to demonstrate, and how well their procedure performs. \n\nThe technical side seems reasonable. However, I didn't understand the significance of the linearly independent vectors (see, e.g., bullet point 2 of Thm 1). Please explain its importance."
                },
                "questions": {
                    "value": "- On page 3, should it read $Z_j \\to X_i$ if and only if $Zj \\in PA(X_i)$?\n- How should we imagine that $(\\hat{g}, \\hat{f}, p_{\\hat{Z}})$ is learned to achieve Eq. (2)?\n- Unclear how well structure is recovered, just from looking at Figure 2. What do these scatter plots represent? Same comment for Figure 3.\n- In the text after Eqn (6), you state that $C^{(u)}$ and $S^{(u)}$ are a matrix and vector, respectively. Then in Eqn (7) you \"divide\" by $S^{(u)}$ in the right hand side. Could you elaborate on what this means"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission444/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission444/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission444/Reviewer_d7mo"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission444/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698801562567,
            "cdate": 1698801562567,
            "tmdate": 1699635970981,
            "mdate": 1699635970981,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9XgMJtDagX",
                "forum": "vyQmKicyVw",
                "replyto": "490oTnwSLQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission444/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission444/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Detailed Responses to Your Comments (1/2)"
                    },
                    "comment": {
                        "value": "We sincerely thank the reviewer for the time dedicated to reviewing our paper and the constructive suggestions. Our responses to these comments are given below.\n\nQ1: \"While the bulk of the paper establishes fundamental results for causal inference, this seems to have little impact on the design or guarantees of machine learning algorithms.\"\n\nA1: Thanks for this insightful comment. The theoretical results have two major impacts on the design of machine learning algorithms: (1) learning  $(\\hat{g}, \\hat{f},p_{\\hat{Z}})$ to achieve Eq. (2), and (2) applying sparsity constraint on the edges of Markov network over $\\hat{Z}$. We will make this clear in the revised manuscript.\n\nQ2: \"it is not clear to me how the data is generated, and the results shown in Figures 2 and 3 have little explanation. Hence it is quite challenging to understand what exactly the authors are trying to demonstrate, and how well their procedure performs.\"\n\nA2: Thanks for pointing this out. We assume that the influences from domain and its parents are location and scaling transformations. Specificically, for each component $z_i$ in each domain, suppose the parents are $PA(i)$, the $z_i=\\sum_{j\\in PA(i)} s_{j,i}z_j+b_i$, where $s_{j,i}$ are scalars sampled from $Unif[0.5, 2]$ and $b_i\\in Unif[-2,2]$. We use 100 domains such that the number of environments are sufficient. As for the nonlinear mixing function, we follow the standard nonlinear ICA literature and construct a MLP whose output dimension is the same as input dimension. Each layer of MLP consists of a orthogonal matrix weight and a leaky-relu function. Since the weights are orthogonal and the activation is invertible, the MLP is invertible too. For the Y-structure, we have $z_1\\rightarrow z_3 \\leftarrow z_2$ and $z_3 \\rightarrow z_4$. As shown in the Fig. 3(a)(b), the estimated $\\hat{z}_1$ recovers $z_2$ and $\\hat{z}_1$ is independent from $z_1$; the estimated $\\hat{z}_2$ recovers $z_1$ and $\\hat{z}_2$ is independent from $z_2$. Therefore, our estimated $\\hat{z}_1, \\hat{z}_2$ recovers the $z_2, z_1$ and their independence relationship. As for $\\hat{z}_3$, it is dependent on $\\hat{z}_1$ and $\\hat{z}_2$. Therefore, we have $\\hat{z}_1\\rightarrow \\hat{z}_3 \\leftarrow \\hat{z}_2 \\Leftrightarrow z_2 \\rightarrow z_3 \\leftarrow z_1$. As for $\\hat{z}_4$, it is dependent on all previous variables, i.e., $\\hat{z}_1, \\hat{z}_2, \\hat{z}_3$. Since we have the sparisty regularization, we can remove the redundant link from $\\hat{z}_1$ and $\\hat{z}_2$ to $\\hat{z}_4$. Therefore, we are able to recover the true latent cause structure. In addition, in eq 6, we have an adjacency matrix to learn, the learned adjacency matrix is identical to the true adjacency matrix, which further supports our theory.  \n\nQ3: \"I didn't understand the significance of the linearly independent vectors (see, e.g., bullet point 2 of Thm 1). Please explain its importance.\"\n\nA3: The linearly independent vectors are crucial to the proof of the theoretical result, and is commonly used in the literature [1]. Specifically, it allows us to obtain Eqs. (11), (12), and (13) from the equation above them that involves linear combinations of the corresponding terms. Intuitively speaking, it requires the distribution to vary sufficiently across different domains. We will explain this in the revised manuscript.\n\nQ4: \"On page 3, should it read $Z_j \\to X_i$ if and only if $Z_j \\in PA(X_i)$?\"\n\nA4: Thanks for spotting this. It should read $Z_j\\rightarrow Z_i$ if and only if $Z_j\\in\\textrm{PA}(Z_i)$, and we have fixed this typo in the revision.\n\nQ5: \"How should we imagine that $(\\hat{g}, \\hat{f}, p_{\\hat{Z}})$ is learned to achieve Eq. (2)?\"\n\nA5: Thanks for this insightful question. We estimate a model $(\\hat{g}, \\hat{f},p_{\\hat{Z}})$ that assumes the same data generating process as in Eq. (1) and matches the true distribution of $X$. We did not specify exactly how to achieve it, and leave the door open for different approaches to be used, such as normalizing flow or variational approaches. For example, we adopt a variational approach in Section 5. We have included this discussion in the updated manuscript."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission444/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700607414960,
                "cdate": 1700607414960,
                "tmdate": 1700608171934,
                "mdate": 1700608171934,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ag7mzeSxd4",
            "forum": "vyQmKicyVw",
            "replyto": "vyQmKicyVw",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission444/Reviewer_xPxb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission444/Reviewer_xPxb"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies latent causal identification under multiple distributions where multiple distributions are modeled as mechanism change. The first part tries to latents under sparsity constraint using observational distribution only. The second part uses orthogonal changes to show that latent factors can be learned with multiple distributions."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is well-written. It is quite easy to follow."
                },
                "weaknesses": {
                    "value": "- Is the condition (sufficient change) of theorem 1 too strict? What are some practical use cases for this? \n\n- The experiment section is limited, only on simulated data and very limited graphs. \n\n- The number of latents needs to be known in advance. \n\n- I am a little confused about one of the main objectives of the paper: What does identifying potential shifts even mean? Even if I can learn $\\theta$ up to component-wise invertible transformations? What does knowing $\\theta$ tell me? And I don\u2019t think theorem 5 is verified by experiments either. \n - By the way, Can you explain how the last line of the proof of theorem 5 leads to the conclusion? Also where in the proof do you need the modular change assumption?"
                },
                "questions": {
                    "value": "- the sparsity condition is not made explicit in theorem 2? Can you state it formally?\n\n- not sure how to interpret the results of theorem 1? it is not intuitive? If the main purpose of theorem 1 is to prove later theorem, maybe it should be a lemma?\n\n-  The proof of theorem 1 uses assumption 3 which is not assumed by theorem 1?\n\n- what's the relation between modular change and ICM? why do you use the \"not related via equality constraint\"? What if $\\theta_i$ and $\\theta_j$ are related by some inequalities? Does you result still hold? \n\n- How is your multi-distribution setting different from soft interventions?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission444/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission444/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission444/Reviewer_xPxb"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission444/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698803697270,
            "cdate": 1698803697270,
            "tmdate": 1699635970842,
            "mdate": 1699635970842,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "p0OC62ZtQ3",
                "forum": "vyQmKicyVw",
                "replyto": "ag7mzeSxd4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission444/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission444/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Detailed Responses to Your Comments (1/2)"
                    },
                    "comment": {
                        "value": "We greatly appreciate the reviewer's constructive comments. We have tried to address all the concerns in the following.\n\nQ1: \"Is the condition (sufficient change) of theorem 1 too strict? What are some practical use cases for this?\"\n\nA1: Thanks for this question. The requirement of a sufficient number of environments is actually standard in the literature (see e.g. a recent survey [1]). Various real-world experimental results (e.g., visual disentanglement [2], domain adaptation [3], video analysis [4], and image-to-image translation [5]) in this line of research indicate that it is likely to hold in practice. Meanwhile, for many tasks, the number of environments is actually accessible, just like the number of domains in transfer learning and the number of time indices in time series data. We have updated the manuscript to include this discussion.\n\nQ2: \"The experiment section is limited, only on simulated data and very limited graphs.\"\n\nA2: Thanks for pointing this out. Since the main focus of our manuscript is the theoretical identifiability results, our experiments mainly serve to validate our theory. The figure 3 shows that we are able to recover the true components and true causal strucuture when the components are causally related instead of mutually independent. \n\nQ3: \"The number of latents needs to be known in advance.\"\n\nA3: Thanks for this comment. Although it is a rather standard assumption in causal representation learning to assume that the number of latents is known in advance (e.g., [1, 6]), let us discuss how to deal with number of latent variables in practice. Some possible approaches are (1) selecting the number of latent variables via model selection, or (2) use a mask to automatically select the number of latent variables, similar to [7]. We will include this discussion in the revised manuscript.\n\nQ4: \"What does identifying potential shifts even mean? Even if I can learn  $\\theta$  up to component-wise invertible transformations? What does knowing  $\\theta$ tell me? And I don\u2019t think theorem 5 is verified by experiments either.\"\n\nA4: $\\theta$ denotes the latent (changing) factor (or effective parameters) associated with each latent structural equation model, which governs the changes in  causal mechanisms. Knowing $\\theta$ tells us whether a particular causal mechanism changes across certain domains.\n\nQ5: \"Can you explain how the last line of the proof of theorem 5 leads to the conclusion? Also where in the proof do you need the modular change assumption?\"\n\nA5: Thanks a lot for this question. The statement $\\frac{\\partial \\theta_l}{\\partial \\hat{\\theta}_i} \\frac{\\partial \\theta_l}{\\partial \\hat{\\theta}_j} = 0$ implies that each $\\theta_l$ is a function of at most one of $\\hat{\\theta}_1,\\dots,\\hat{\\theta}_n$. By considering the inverse of Jacobian matrix, we also have $\\frac{\\partial \\hat{\\theta}_l}{\\partial \\theta_i} \\frac{\\partial \\hat{\\theta}_l}{\\partial \\theta_j} = 0$, indicating that each $\\hat{\\theta}_l$ is a function of at most one of $\\theta_1,\\dots,\\theta_n$. Combining both of them, $\\theta_i$ are identifiable up to component-wise invertible transformation.\n\nFurthermore, the modular change assumption is needed to obtain the equation below Eq. (16). We have modified the manuscript to make these clear.\n\nQ6: \"the sparsity condition is not made explicit in theorem 2? Can you state it formally?\"\n\nA6: The sparsity constraint implies the minimal number of edges of Markov network $\\mathcal{M}_{\\hat{Z}}$ over $\\hat{Z}$. We have upadated the manuscript to make this explicit.\n\nQ7: \"not sure how to interpret the results of theorem 1? it is not intuitive? If the main purpose of theorem 1 is to prove later theorem, maybe it should be a lemma?\"\n\nA7: Thanks for the constructive suggestion. We have modified Theorem 1 to be a lemma in the revised manuscript.\n\nQ8: \"The proof of theorem 1 uses assumption 3 which is not assumed by theorem 1?\"\n\nA8: Thanks for your careful reading and spotting this. We have fixed the typo in the proof of Theorem 1. That is, the proof does not involve Assumption A3, which instead should be Assumption A2."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission444/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700607236970,
                "cdate": 1700607236970,
                "tmdate": 1700607236970,
                "mdate": 1700607236970,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "L0kjvu05Gr",
                "forum": "vyQmKicyVw",
                "replyto": "ag7mzeSxd4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission444/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission444/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Detailed Responses to Your Comments (2/2)"
                    },
                    "comment": {
                        "value": "Q9: \"what's the relation between modular change and ICM? why do you use the \"not related via equality constraint\"? What if $\\theta_i$ and $\\theta_j$ are related by some inequalities? Does you result still hold?\"\n\nA9: Thanks for asking this question. One can consider the modular change condition as an instantiation of ICM. We will discuss this conenction in the revised manuscript to explain clearly the relation between modular changes and ICM.\n\nIn our case, we have not been aware the situation where $\\theta_i$ and $\\theta_j$ are related by some inequalities. Intuitively, if it is possible for them to be related by inequality cosntraints, then in this case, one should include inequality constraints into Assumption A2.\n\nQ10: \"How is your multi-distribution setting different from soft interventions?\"\n\nA10: If soft intervention is defined this way as in [8], then it is completely general, as long as there is change in the conditional distribution. If so, then we assume soft intervention for all latent causal variables. We will discuss this in the revised manuscript.\n\nReferences:\n\n[1] Hyv\u00e4rinen, Aapo, Ilyes Khemakhem, and Hiroshi Morioka. \"Nonlinear independent component analysis for principled disentanglement in unsupervised deep learning.\" Patterns 2023.\n\n[2] Khemakhem, Ilyes, et al. \"Ice-beem: Identifiable conditional energy-based deep models based on nonlinear ica.\" NeurIPS 2020\n\n[3] Kong, Lingjing, et al. \"Partial Identifiability for Domain Adaptation.\" ICML 2022\n\n[4] Yao, Weiran, et al. \"Learning temporally causal latent processes from general temporal data.\" ICLR 2022\n\n[5] Xie, Shaoan, et al. \"Unpaired Image-to-Image Translation With Shortest Path Regularization.\" CVPR 2023.\n\n[6] von K\u00fcgelgen, Julius, et al. \"Nonparametric Identifiability of Causal Representations from Unknown Interventions.\" NeurIPS 2023\n\n[7] Xie, Shaoan, et al. \"Multi-domain image generation and translation with identifiability guarantees.\" ICLR 2022.\n\n[8] Eberhardt, F., et al. \"Direct Causes and the Trouble with Soft Interventions.\" Erkenntnis 2014."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission444/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700607254431,
                "cdate": 1700607254431,
                "tmdate": 1700607666706,
                "mdate": 1700607666706,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vYT0KqwO6h",
            "forum": "vyQmKicyVw",
            "replyto": "vyQmKicyVw",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission444/Reviewer_8efN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission444/Reviewer_8efN"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies identifiability questions for causal latent systems, in a situation where observations from multiple and diverse environments are available. The diversity here is a necessary condition for the method.  \n\nIt is shown that one can use a certain known characterisation of conditional independence using derivatives of the density to partially identify the dependence structure of the latent system, provided it is observed in a diverse enough number of environments.  \n\n\nExperiments on small synthetic examples are performed to demostrate the general problem setup and identifiability in it."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The subject of identifiability in causal systems is important.  \nI have not seen the characterisation of conditional independence via density derivatives used in recent literature, and believe it is of interest."
                },
                "weaknesses": {
                    "value": "First, there are several critical issues with presentation. Second, the setup considered in the paper is quite restrictive. In addition, the main \"sufficient changes\" assumpion is not discussed. It is not discussed when we can expect it to hold, nor is it evaluated in any actual scenarios. This is the main issue.  Third, the experiments are performed on small toy examples, and use known architectures of causal discovery.  It is not clear what is their added value. \n\nIn more detail:\n\n**Presentation:**  \n**(a)** the presentation is missleading as it positions the paper as \"treating the case of multiple environments, which is not treated in the litarture\". This makes the impression that the approach is a generalisation of a single environment case. However, it is not. The proposed methods can not be used for a single environment. In a way, the method exploits the differences in environments, and there must be many of them.   **(b)** Some critical definitions are not given in the main text. Specifically, \"Modular Changes\" of Theorem 5 is not defined, and \"sparsity constraint\" of Theorem 3.  **(c)** Literature: there is a significant amount of research on multiple environments via causality that is not mentioned in the paper. The NN architectures presented in Experiments are small modifications of known arhcitectures (normalising flows flows for causal discovery).  Proper references should be given. \n\n\n\n**Problem Setting and The Sufficient Changes Assumption**: \nThe setting (1) is restrictive in two ways: First, the observations $X$ are a deterministic function, i.e not noisy observations. Second, and more importantly, the observation map $g$ is assumed to be _invertible_. For at least somewhat smooth maps this means dimension of $X$ and $Z$ must be the same, which is unrealistic. How important is invertability? \n\nThe fundamental assumption of this paper, of Sufficient Changes, appears very strong. It requires independence for every point $z$. The number of environments must be at least as large as the number of variables (if same set of environments is good for all $z$). This condition must be discussed. When does it hold? Examples? I would suggest removing the Experiments section, and discussing this condition in detail. \n\n\n\n**Experiments**: \nIn addition to what mentioned on the experiments above:\nRegarding the following phrase in the end of Section 5: \n>However, when the noises are Gaussian, it becomes more challenging and we observe that some components are mixed, which further aligns with our theory (e.g., Theorem 3) and demonstrate the benefit of using suitable parameterization.\n\nI do not see how this results aligns with the theory, and in particular with Theorem 3. Theorem 3 does not appear to have assumptions that distinguish between Gaussainity and non Gaussianity. Please exlain."
                },
                "questions": {
                    "value": "Please see above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission444/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission444/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission444/Reviewer_8efN"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission444/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698911893722,
            "cdate": 1698911893722,
            "tmdate": 1699635970761,
            "mdate": 1699635970761,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "L3KDrBNNnP",
                "forum": "vyQmKicyVw",
                "replyto": "vYT0KqwO6h",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission444/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission444/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Detailed Responses to Your Comments (1/2)"
                    },
                    "comment": {
                        "value": "Thanks for your time and effort in reviewing our manuscript. Below we give a point-by-point response to the comments.\n\nQ1: The presentation might be misleading since it makes the impression that the approach is a generalisation of a single environment case.\n\nA1: Thanks for your question. We fully agree with you that our method exploits the distributional change to identify latent causal variables and the structure among them. Actually, we thought it is exactly the considered task and didn\u2019t treated it as a generalisation of the single environment case. In fact, the single environment case is way more difficult and most previous works in causal representation learning assume a sufficient number of different environments (e.g., [1,2]). Therefore, the multi-environments case is not a generalization of a single environment case. We have modified the introduction in order to avoid any potential confusion.\n\nQ2: Lack of some definitions.\n\nA2: Thank you for the reminder, and apologize for the potential confusion. The term \u201cmodular changes\u201d is defined in A3 of Theorem 5 (\u201c$\\theta_i$ across different $i$ are not related via equality constraints\u201d). The sparsity constraint implies the minimal number of edges of Markov network $\\mathcal{M}_{\\hat{Z}}$ over $\\hat{Z}$.  We have updated the theorem statement to make this explicit.\n\nQ3: Related work on multiple environments via causality and nomalizing flows for causal discovery.\n\nA3: Thanks for the suggestion. As detailed in A1, our theoretical results take the existence of multiple environments as an assumption of the identifiability theory for causal representation learning, which differs from previous works trying to address the challenge of multiple environments (e.g., CD-NOD [3]). And one can consider causal representation learning as an extension of causal discovery, which aims at identifying both the latent causal variables and hidden structures. We have incorporated the discussion and futher highlighted the differences in the manuscript as well as the recommended references.\n\nQ4: Observations are assumed to be noiseless and the map is invertible.\n\nA4: We appreciate the insightful questions. Let us apologize for the typo in the paragraph before Eq. 9. The map is actually injective but not invertible, which is a standard assumption in the previous work in causal representation learning [2,4]. Moreover, since most identifiability theorems in the literature stems from the theory of nonlinear ICA, many works follows the setting of it, where the observation $X$ is a deterministic (nonlinear) function of latent variables $Z$. Our work lies in this line of research and thus follows the previous setting. We will provide additional discussion on it to make the context clearer, according to your constructive suggestions.\n\nQ5: More discussion on the assumption of sufficient changes.\n\nA5: Thanks a lot for your great suggestions. In light of these, we have added more discussions in the updated manuscript, including more real-world examples. At the same time, we would like to mention that this assumption is common in the literature. For example, [4, 5] require $2n+1$ environments in order for the system to be identifiable, where $n$ is the number of variables. Some real-world experiments (e.g., visual disentanglement [6], domain adaptation [7], video analysis [8], and image-to-image translation [9]) also suggests that this assumption is likely to hold at least in certain real-world scenarios."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission444/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700607134499,
                "cdate": 1700607134499,
                "tmdate": 1700607134499,
                "mdate": 1700607134499,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7pAoZVX3RD",
            "forum": "vyQmKicyVw",
            "replyto": "vyQmKicyVw",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission444/Reviewer_mmWQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission444/Reviewer_mmWQ"
            ],
            "content": {
                "summary": {
                    "value": "The paper works on the problem of recovering the hidden causal structure of latent variables given observational data from different environments. Authors show, that under a sparsity constraint of an underlying Markov network and a sufficient number of changes across environments, the Markov network can be recovered up to the simple indeterminacies. Furthermore, under additional mild assumptions, the recovered Markov network coincides with the moralized causal DAG. Additionally, latent factors can be recovered too, under similar assumptions. The authors provide two different implementations following the theory and do several synthetic experiments."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The problem of identifying a latent structure is highly relevant in causal inference research. To tackle it, the authors made some interesting theoretical work by applying the proof technique from Lin (1997) based on second-order derivatives of the log-density. Also, I found the connection between Markov networks and causal DAGs interesting.  Additionally, I appreciate the attempts to make the proposed approach as general as possible."
                },
                "weaknesses": {
                    "value": "I identified several important flaws, which need to be addressed by the authors. Those include connections to previous works, lack of rigour and questionable correctness of the statements, realisticness of the assumptions, and experimental evidence/evaluation issues. \n  \n**Connections to previous works**. It seems like the identification technique with second-order derivatives of the log-density from  Lin (1997) is a standard technique for identifying structural causal models (SCMs), e.g., used in [1, 2]. Also, I don\u2019t understand the connections between existing identifiable SCMs, like additive noise models and post-non-linear models, and the statements of Theorems 1 and 3, as those SCMs must be special cases of the proposed Theorems. \n\n**Lack of rigour & questionable correctness**. I found it hard to understand the claims of the Theorems, as some notation was not introduced properly or sufficiently. For example, how are $\\tilde{Z}$, $h(\\cdot)$, and $q(\\cdot)$ defined? What is $m$ in Theorem 1, and which sparsity constraints Theorem 2 refers to? Are $\\theta$ one-dimensional factors (parameters)? What is $u$ in Eq. 3?  This is problematic, as, e.g., I failed to understand the proof of Theorem 1. Some statements might be even wrong, given the current version of the paper. For example, I do not understand, how the dimensions of $X$ and $Z$ can be different and $g(\\cdot)$ is an invertible transformation, and at the same time, the determinant of Jacobian is well-defined (App. A). In the case of the dimensions mismatch, an invertible transformation would be non-continuous (see Netto's theorem). On the other hand, if we assume a same-dimensional manifold embedded in higher-dimensional space, the change of variables formula used in App. A would be different, e.g., see [3].     \n\n**Realisticness of the assumptions**. The major discussion is missing on whether the assumptions in Theorems 1 and 5 are realistic. For example, how could one assume the dimensionality of $Z$ only given $X$? Or even when assuming it, how can we verify, given the data from several environments, whether the number of environments is sufficient? I would love to see a real-world application or a case\u2014study, where we could make those assumptions, or at least speculate about them.\n\n**Experimental evidence/evaluation issues**. The provided experiments aim to support the claims of Theorem 3, and I did not find any regarding Theorem 5 for identifying latent factors. The provided experiments still contain very little implementation and evaluation details, and there is no source code available. For example, it is not clear, how the synthetic data is sampled, e.g., what are \u201cnoises\u201d and \u201cbiases\u201d in Sec. 5.3? Additionally, I don\u2019t understand, how the provided synthetic datasets satisfy the assumptions of Theorem 3, e.g., what is the sufficient number of environments, what is the dimensionality of $X$, or how we ensure that the MLP is an invertible function.  On the other hand, the evaluation itself is ambiguous, as it is unclear, how the scatter plots in Figures 2 and 3 support the claim that \u201cthe hidden structure is recovered\u201d.\n\nGiven all the mentioned issues, I tend to reject the paper. I looking forward to the rebuttal and don\u2019t mind increasing my score if the issues are resolved.\n\nReferences:\n[1] Immer, Alexander, et al. \"On the identifiability and estimation of causal location-scale noise models.\"\u00a0International Conference on Machine Learning. PMLR, 2023.\n[2] Zhang, Kun, and Aapo Hyvarinen. \"On the identifiability of the post-nonlinear causal model.\"\u00a0arXiv preprint arXiv:1205.2599\u00a0(2012).\n[3] Rezende, Danilo Jimenez, et al. \"Normalizing flows on tori and spheres.\"\u00a0International Conference on Machine Learning. PMLR, 2020."
                },
                "questions": {
                    "value": "- Traditional SCMs, defined by Pearl [1], assume that latent variables by definition do not have parents. Why cannot we directly model an SCM for $X$ without assuming another latent SCM over $Z$ and a nonlinear mixing function? I would like to hear a discussion on this, as this modelling approach seems to be way simpler.\n- Why is $Z_i$ a function of the $\\hat{Z}_k$ or $\\hat{Z}_l$, if $Z$ and $\\hat{Z}$ are observed and modelled variables, respectively, and, thus, are variables of different SCMs? What is $\\frac{dZ_i}{d \\hat{Z}_k}$ in App. A?\n\nReferences:\n[1] Bareinboim, Elias, et al. \"On Pearl\u2019s hierarchy and the foundations of causal inference.\"\u00a0Probabilistic and causal inference: the works of Judea Pearl. 2022. 507-556."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission444/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission444/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission444/Reviewer_mmWQ"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission444/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699024512620,
            "cdate": 1699024512620,
            "tmdate": 1699635970696,
            "mdate": 1699635970696,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "IY5xO5MUTX",
                "forum": "vyQmKicyVw",
                "replyto": "7pAoZVX3RD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission444/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission444/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Detailed Responses to Your Comments (1/2)"
                    },
                    "comment": {
                        "value": "We sincerely thank the reviewer for the time devoted and the thoughtful comments. Please find the response to your comments and questions below.\n\nQ1: Connections to previous works.\n\nA1: Thanks for the question. We fully agree with you that the connection between independence and second-order derivatives of the log-density was the key to the identifiability of some functional causal models. At the same time, the task we are trying to address is different from causal discovery, since we need to first identify the latent causal variables and then discover the hidden structure, all from some general nonlinear mixtures of these causal variables, i.e., causal representation learning. To the best of our knowledge, our proof technique has never been introduced in this literature. \nFurthermore, as you correctly mentioned, we are dealing with a setting that might be more general than existing identifiable SCMs, since we do not have similar constraints on the functional relations and we allow both the causal variables and structures to not be observed. At the same time, these two settings are different since we are incorporating additional information such as sufficient changes in the distribution. \n\nQ2: Clarification of theorems and notations.\n\nA2: Thanks for your suggestions and sorry for the potential confusion and typos. We have incorporated the clarification into the updated manuscript. Specifically, we have made the following clarifications/corrections:\n\n- (1) $\\tilde{Z}$ should be $\\hat{Z}$, which denotes the estimated latent variables.\n- (2) $h(\\cdot)$ denotes the mapping between the estimated latent variables $\\hat{Z}$ and the true variables $Z$. This is also the case for $q(\\cdot)$. For consistency, we have changed them to $h$ or $h^{-1}$.\n- (3) $m$ should be $u$, which denotes the auxiliary variable.\n- (4) $\\theta$ represents the latent factor that govern the change of hidden causal mechanisms. $u$ in Eq. 3 denotes the auxiliary variable.\n- (5) For Theorem 1, we do not need to assume that $g$ is invertible as long as the function between estimated latent variables $\\hat{Z}$ and the true variables $Z$ (i.e., $h$) is invertible, since the change of variable formula only applies between $p(\\hat{Z};\\theta)$ and $p(Z;\\theta)$. Similar to previous work (e.g., [1,2]), $g$ only needs to be injective. We have corrected it in the manuscript.\n  \nApologies again for the potential confusion. We sincerely appreciate your detailed suggestions, which are very helpful in improving the clarity of our manuscript.\n\nQ3: Realisticness of the assumption.\n\nA3: Thanks for your question. As mentioned in A2(5), we do not assume that $Z$ and $X$ are of the same dimension, similar to many previous works in causal representation learning (e.g., [1, 2]). And the determination of the dimension in practice is a typical model selection problem. In practice, one may extend model selection method such as cross-validation or sparsity regularization on a mask to determine the number of dimension of $Z$ [9]. The requirement of a sufficient number of environments is also standard in the literature (see e.g. a recent survey [3]). Various real-world experimental results (e.g., visual disentanglement [5], domain adaptation [6], video analysis [7], and image-to-image translation [8]) in this line of research indicate that it is likely to hold in practice. Meanwhile, for many tasks, the number of environments is actually accessible, just like the number of domains in transfer learning and the number of time indices in time series data. We have updated the manuscript to hightlight the related discussion."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission444/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700606272820,
                "cdate": 1700606272820,
                "tmdate": 1700606272820,
                "mdate": 1700606272820,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ZFQzYKOdW2",
                "forum": "vyQmKicyVw",
                "replyto": "7pAoZVX3RD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission444/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission444/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Detailed Responses to Your Comments (2/2)"
                    },
                    "comment": {
                        "value": "Q4: Experiments and evaluations.\n\nA4: Thanks for pointing this out. We assume that the influences from the domain and its parents are location and scaling transformations. Specificically, for each component $z_i$ in each domain, suppose the parents are $PA(i)$, the $z_i=\\sum_{j\\in PA(i)} s_{j,i}z_j+b_i$, where $s_{j,i}$ are scalars sampled from $Unif[0.5, 2]$ and $b_i\\in Unif[-2,2]$. We use 100 domains such that the number of environments is sufficient. As for the nonlinear mixing function, we follow the standard nonlinear ICA literature and construct an MLP whose output dimension is the same as the input dimension. Each layer of MLP consists of an orthogonal matrix weight and a leaky-relu function. Since the weights are orthogonal and the activation is invertible, the MLP is invertible too. For the Y-structure, we have $z_1\\rightarrow z_3 \\leftarrow z_2$ and $z_3 \\rightarrow z_4$. As shown in the Fig. 3(a)(b), the estimated $\\hat{z}_1$ recovers $z_2$ and $\\hat{z}_1$ is independent from $z_1$; the estimated $\\hat{z}_2$ recovers $z_1$ and $\\hat{z}_2$ is independent from $z_2$. Therefore, our estimated $\\hat{z}_1, \\hat{z}_2$ recovers the $z_2, z_1$ and their independence relationship. As for $\\hat{z}_3$, it is dependent on $\\hat{z}_1$ and $\\hat{z}_2$. Therefore, we have $\\hat{z}_1\\rightarrow \\hat{z}_3 \\leftarrow \\hat{z}_2 \\Leftrightarrow z_2 \\rightarrow z_3 \\leftarrow z_1$. As for $\\hat{z}_4$, it is dependent on all previous variables, i.e., $\\hat{z}_1, \\hat{z}2, \\hat{z}_3$. Since we have the sparsity regularization, we can remove the redundant link from $\\hat{z}_1$ and $\\hat{z}_2$ to $\\hat{z}_4$. Therefore, we are able to recover the true latent cause structure. In addition, in eq 6, we have an adjacency matrix to learn, the learned adjacency matrix is identical to the true adjacency matrix, which further supports our theory.  \n\nQ5: The necessity of learning latent SCMs and the nonlinear mixing function.\n\nA5: We appreciate the great question, and would like to briefly summarize the discussion as follows: \n\n- (1) Latent causal variables are crucial because they represent unmeasured or unmeasurable influences. For example, in social science research, a latent variable might represent an abstract concept (e.g., peer support in teacher\u2019s burnout study [4]) that influences but is not directly measurable through observed variables. \n- (2) It is common to have dependencies among those abstract concepts in practice, thus allowing an SCM among them (which also covers the empty graph) instead of assuming all variables are independent is much more general and can be applied in more real-world scenarios. \n- (3) In addition, in order to identify the latent SCM, we need to first identify those latent causal variables $Z$ from only observed variables $X$. Since we do not want to put strong constraints on the relations between $Z$ and $X$, we just assume that the function $g$ in $x = g(z)$ is nonlinear, which is the nonlinear mixing function.\n\nWe have updated the manuscript in order to better highlight the practical significance of the considered general setting.\n\nQ6: Why is $Z_i$ a function of the $\\hat{Z}_k$ and $\\hat{Z}_l$? What is $\\frac{\\partial Z_i}{\\partial \\hat{Z}_k}$?\n\nA6: Thanks for pointing out this very interesting finding. In order to identify those latent causal variables $Z$, we would like to make sure that our estimated variables $\\hat{Z}$ recovered the ground-truth $Z$ up to some mild indeterminacies. Without that guarantee, $\\hat{Z}_k$ can be a mixture of an arbitrary set of latent causal variables in $Z$, making the identification less meaningful. This is similar to the task of disentanglement and we provided theoretical guarantees of the disentangled results. $\\frac{\\partial \\hat{Z}_i}{\\partial Z_k} \\neq 0$ means the estimated variable $\\hat{Z}_i$ is not a function of $Z_k$, removing $Z_k$ from the mixture.\n\nReferences:\n\n[1] Buchholz, Simon, et al. \"Learning Linear Causal Representations from Interventions under General Nonlinear Mixing.\" NeurIPS 2023\n\n[2] Khemakhem, Ilyes, et al. \"Variational autoencoders and nonlinear ica: A unifying framework.\" ATSTATS 2020\n\n[3] Hyv\u00e4rinen, Aapo, Ilyes Khemakhem, and Hiroshi Morioka. \"Nonlinear independent component analysis for principled disentanglement in unsupervised deep learning.\" Patterns 2023.\n\n[4] Byrne, Barbara M. Structural equation modeling with Mplus: Basic concepts, applications, and programming. routledge, 2013.\n\n[5] Khemakhem, Ilyes, et al. \"Ice-beem: Identifiable conditional energy-based deep models based on nonlinear ica.\" NeurIPS 2020\n\n[6] Kong, Lingjing, et al. \"Partial Identifiability for Domain Adaptation.\" ICML 2022\n\n[7] Yao, Weiran, et al. \"Learning temporally causal latent processes from general temporal data.\" ICLR 2022\n\n[8] Xie, Shaoan, et al. \"Unpaired Image-to-Image Translation With Shortest Path Regularization.\" CVPR 2023.\n\n[9] Xie, Shaoan, et al. \"Multi-domain image generation and translation with identifiability guarantees.\" ICLR 2022."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission444/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700606871835,
                "cdate": 1700606871835,
                "tmdate": 1700608221281,
                "mdate": 1700608221281,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iGKJlAtWxT",
                "forum": "vyQmKicyVw",
                "replyto": "ZFQzYKOdW2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission444/Reviewer_mmWQ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission444/Reviewer_mmWQ"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response and clarifications! Yet, I still think there are unresolved issues in the paper.\n\nNevertheless, the uploaded version of the paper seems to be different from what the authors described in their response, and there are some new unexplained changes, too. For example,  $m$ was not actually changed with $u$. Also, the proof of Theorem 1 (now it is Lemma 1) is different from the original formulation, as now it does not have $g(\\cdot)$ at all or does not use its injective property.\n\nAlso, I am still confused between the dimensionality mismatch of  $X$ and $Z$. If function $g(\\cdot)$ is injective and continuous, then it effectively sets the dim. of $Z$ higher or equal to dim. of $X$. Or do we allow for non-continuous functions as well?\n\nAfter the revision, I wonder what is $\\hat{g}^{-1}$, if we do not assume that neither $g$ nor $\\hat{g}$ are invertible functions but only injective.\n\nAs such, I still tend to keep my score the same."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission444/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700701739393,
                "cdate": 1700701739393,
                "tmdate": 1700701739393,
                "mdate": 1700701739393,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oTg9zBgolO",
                "forum": "vyQmKicyVw",
                "replyto": "AtauCApnZ2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission444/Reviewer_mmWQ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission444/Reviewer_mmWQ"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for another  clarification, but now you claim that $g(\\cdot)$ is a diffeomorphism but not just an injection? If this is the case, it is also an invertible map, which sets the dimensions of X and Z equal. If not, I\u2019m confused: what is $\\hat{g}^{-1}$ in your paper?"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission444/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700736544422,
                "cdate": 1700736544422,
                "tmdate": 1700736544422,
                "mdate": 1700736544422,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wqmmrcum2U",
                "forum": "vyQmKicyVw",
                "replyto": "7pAoZVX3RD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission444/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission444/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your feedback; the dimensions of X and Z are not necessarily the same"
                    },
                    "comment": {
                        "value": "Dear Review mmWQ,\n\nMany thanks for the feedback!  In our setting, X might have higher dimensions and redundant information (for instance, consider image pixels).  Consider the following example in the simple linear case.  Let\n$$\n\\mathbf{X} = \\begin{bmatrix} 1 & 0 \\newline 1 & 1 \\newline  1 & 1 \\end{bmatrix} \\mathbf{Z}, $$\nwhere the transformation from $\\mathbf{Z}$ to $\\mathbf{X}$ is 3-by-2, but there still exists a mapping from $\\mathbf{X}$ to $\\mathbf{Z}$.\n\nWhat do you think?\n\nThanks once again,\n\nAuthors of #444"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission444/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740457899,
                "cdate": 1700740457899,
                "tmdate": 1700740715215,
                "mdate": 1700740715215,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]