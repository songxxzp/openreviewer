[
    {
        "title": "Physics-informed neural networks for transformed geometries and manifolds"
    },
    {
        "review": {
            "id": "htph3MRZAR",
            "forum": "kIZcruKmBg",
            "replyto": "kIZcruKmBg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9410/Reviewer_2tfv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9410/Reviewer_2tfv"
            ],
            "content": {
                "summary": {
                    "value": "The paper intends to improve the performance of PINN on domains of complex geometries. The method is to  use smooth transformations to transform a complex geometry to less complex one which is a called reference domain. If the transformations are differentiable, the training of modified PINNs is the same as training vanilla PINNs."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "**Originality:** The paper implements diffeomorphisms to the problem of PINN on complex geometries.\n\n**Quality:** The paper explores the proposed methods on some typical examples to demonstrate the effectiveness of the method.\n\n**Clarity:** The idea is conveyed directly and straightforward.\n\n**Significance:** Combining diffeomorphism with training of neural network is somewhat interesting and natural, due to the differentiability of transformations."
                },
                "weaknesses": {
                    "value": "One of the major weakness is that the paper does not include experiments of comparison between modified PINN and vanilla PINN. In order to show the effectiveness of the proposed method, the author should also test the performance of PINN on all the problems in section 4."
                },
                "questions": {
                    "value": "If the original problems $L(u)=f$ in $\\Omega$ is transformed to $L_x(u \\circ \\phi) = f$ on reference domain $\\Omega_{ref}$, then $L_x$ should not equal $L$. The calculation of $L_x$ should use chain rule. In your paper, this part is hardly touched. How did you actually implement your method in experiments?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9410/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9410/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9410/Reviewer_2tfv"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9410/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698465634691,
            "cdate": 1698465634691,
            "tmdate": 1699637186245,
            "mdate": 1699637186245,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qQn4Ub0jKM",
                "forum": "kIZcruKmBg",
                "replyto": "htph3MRZAR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9410/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9410/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your review. We would like to address the following comments.\n\n_One of the major weakness is that the paper does not include experiments of comparison between modified PINN and vanilla PINN. In order to show the effectiveness of the proposed method, the author should also test the performance of PINN on all the problems in section 4._\n\nUnfortunately, we do not understand how vanilla PINNs should be applied to the case of manifolds, as directional derivatives have to be computed. \u2028It might be possible to elaborate the differential operators (e.g., Laplace-Beltrami) explicitly and compute those in a \u201cvanilla\u201d way, but this is what our approach implicitly does, formulated in local coordinates, putting all the work into the automatic differentiation.\nIn the case of equi-dimensional transformations, vanilla PINNs could actually be applied and would lead to a well-studied reference solution. Thank you for this suggestion.\n\n\n_If the original problems $L(u)=f$ in $\\Omega$ is transformed to $L_x(u \\circ \\phi) = f$ on reference domain $\\Omega$ ref, then $L_x$ should not equal $L$. The calculation of $L_x$ should use chain rule. In your paper, this part is hardly touched. How did you actually implement your method in experiments?_\n\nIn the manifold case, chain rule applies and is carried out by the automatic differentiation framework.\nIn the transformation case, we explicitly neglect the chain rule. It\u2019s somewhat arbitrary (and we are sorry if we didn\u2019t make this sufficiently clear), but this idea leads to general transformed domains.\nRegarding the actual implementation: We provide our full source code as supplementary material and refer to it for all implementation details."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9410/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700726056875,
                "cdate": 1700726056875,
                "tmdate": 1700726056875,
                "mdate": 1700726056875,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "V6wwQye7vL",
                "forum": "kIZcruKmBg",
                "replyto": "qQn4Ub0jKM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9410/Reviewer_2tfv"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9410/Reviewer_2tfv"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for clarifying. I agree that this paper has novelty in solving PDE problems on manifold. However, regarding geometry transformation, here's my follow-up question:\n\nI'm still confused with eq. (6)-(7). Given $\\mathcal{L}(u_{ref})=f$, how can $u=u_{ref}\\circ \\phi^{-1}$ satisfy $\\mathcal{L}(u)=f$, as you mentioned above eq. (6)-(7) that $\\mathcal{L}=\\mathcal{L_y}$? In my understanding, generally $u$ satisfies $\\mathcal{L_y}(u)=f$ and $\\mathcal{L}\\neq \\mathcal{L_y}$. \n\nI did look at the code, but due to this fundamental question I didn't follow."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9410/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700728447775,
                "cdate": 1700728447775,
                "tmdate": 1700728447775,
                "mdate": 1700728447775,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "huY5vqgjL2",
            "forum": "kIZcruKmBg",
            "replyto": "kIZcruKmBg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9410/Reviewer_UpPb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9410/Reviewer_UpPb"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, it is argued that the existing approaches to physics-informed neural networks are not apt for complex and transforming geometries. To this end, the paper presents an approach to introduce geometric transformation within the physics-informed neural network design. Concretely, it enforces the Dirichlet boundary condition using distance function to account for complex geometries. Experimental results on four different examples are shown to demonstrate the suitability of the method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* It is a well-written paper. \n* The use of Dirichlet boundary conditions is promising.\n* An initial approach to explore a new direction for more promising neural network design."
                },
                "weaknesses": {
                    "value": "* Some of the technical notations are not fully exposed and detailed.\n* Experiments are limited on toy-example and missing on the manifolds which are widely used in science and engineering application.\n* The paper misses to highlight the limitations of the proposed approach.\n\n\nKindly refer to the Questions section for more comments."
                },
                "questions": {
                    "value": "## Domain and Transformation\n\nIt\u2019s better to include the dimension of the variables on the side of the Eq(1). \n\n## 2.2.1 Manifold: $m < n$\n\n$\\mathcal{L}_x$ and $\\mathcal{L}_y$ need more explanation. The subscripts have not been explained. Diagram conveys that one is in the reference domain and other is in the computational domain yet it's better to write near the equation (4)-(5) and following equation.\n\n## 3.1 Exact boundary condition with output transform\n\nKindly help me understand the approximation of $\\hat{u}$, given that the inverse must hold and the proposed approximation is not linear.\n\n## 4.4 Shape Optimization with Laplace Operator\nI am not entirely convinced with the imposed boundary condition. What could be considered a weak boundary condition is not fully exposed in the paper. Furthermore, I request the authors to perform some experiments and analysis of the proposed theory on negative curvature surfaces with the introduced local approach. Also, the use of Laplace-Beltrami operator for shapes.\n\nIn addition to the above, experiment on Low-Dimensional manifolds is simple and not convincing to me for real application. I request the authors to provide some analysis and results on popular manifolds such as low-dimensional SPD, Grassmannian manifolds, etc."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9410/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698576472752,
            "cdate": 1698576472752,
            "tmdate": 1699637186110,
            "mdate": 1699637186110,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Y1PUr8Fbn5",
                "forum": "kIZcruKmBg",
                "replyto": "huY5vqgjL2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9410/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9410/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your review. We would like to answer your comments and questions as follows.\n\n$\\mathcal{L}_x$ _and_ $\\mathcal{L}_y$ _need more explanation. The subscripts have not been explained. Diagram conveys that one is in the reference domain and other is in the computational domain yet it's better to write near the equation (4)-(5) and following equation._\n\nThanks for your feedback, other reviewers addressed the same issue. We only stated \u201c$\\mathcal{L} = \\mathcal{L}_y$ with respect to global coordinates\u201d and assumed that it\u2019s clear that the subscript indicates the derivation variable. Obviously, this it is not the case and the subscript needs more explanation.\n\n_Exact boundary condition with output transform: Kindly help me understand the approximation of $\\hat u$, given that the inverse must hold and the proposed approximation is not linear._\n\nAs the smooth distance function $b$ is zero at the boundary, $N(y) u(y)$ is zero on the boundary, and, therefore, $\\hat u(y) = g(y)$ satisfies the Dirichlet boundary values $g(y)$ at the boundary. \u2028\u2028Unfortunately, we do not understand what you are referring to with \u2018inverse must hold\u2019, and why the approximation should to be \u2018linear\u2019.\n\n_I am not entirely convinced with the imposed boundary condition. What could be considered a weak boundary condition is not fully exposed in the paper._\n\nA weak boundary condition (in the context of PINNs) means imposing the boundary condition by adding a penalizing loss term, as outlined in (8). You noted correctly that we missed introducing this wording in the context of (8) and it should be added.\n\n_Experiments are limited on toy-example and missing on the manifolds which are widely used in science and engineering application._\n\n  We tried to demonstrate our method on minimal working examples to make the setup and implementation clearly understandable. It\u2019s unfortunate if you consider them as too limited, and we will take this feedback into account.\n\n_The paper misses to highlight the limitations of the proposed approach._\n\nUnfortunately, that is true, we will add a paragraph on this.\n\n_Furthermore, I request the authors to perform some experiments and analysis of the proposed theory on negative curvature surfaces with the introduced local approach. Also, the use of Laplace-Beltrami operator for shapes._\n\nWe do not see why negative curvature should have any relevant impact on our method, the proposed method also works with negative curvature surfaces. \u2028Also, our second example demonstrates a Poisson problem on a part of a sphere, which - as we formulate the derivatives in local coordinates - corresponds to a Laplace-Beltrami on the manifold. Our apologies that we didn\u2019t point this out explicitly.\n\n_In addition to the above, experiment on Low-Dimensional manifolds is simple and not convincing to me for real application. I request the authors to provide some analysis and results on popular manifolds such as low-dimensional SPD, Grassmannian manifolds, etc._\n\nWhich PDEs are commonly formulated on low-dimensional SPD or Grassmannian manifolds?"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9410/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700726787174,
                "cdate": 1700726787174,
                "tmdate": 1700726787174,
                "mdate": 1700726787174,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "JpVzxWO8Uw",
            "forum": "kIZcruKmBg",
            "replyto": "kIZcruKmBg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9410/Reviewer_VH6u"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9410/Reviewer_VH6u"
            ],
            "content": {
                "summary": {
                    "value": "This paper employs physics-informed neural networks (PINNs) for addressing intricate or changing geometrical configurations. The primary technical innovation lies in the incorporation of a geometric transformation (diffeomorphism) of a reference domain to describe the computational domain."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The problem is well defined and the author proposes a clear formulation in solving the problem."
                },
                "weaknesses": {
                    "value": "Unfortunately,  it appears that the problem tackled in the paper is somewhat incremental, and the proposed solution lacks a surprising or profound aspect. In the context of an ICLR paper, I'm seeking a novel problem that has not previously been successfully addressed, made attainable through this approach, or a novel method to solve a well-established problem that has been extensively explored. Unfortunately, neither of these elements seems to be present in the paper.\n\nFurthermore, the examples provided mainly consist of small-scale 2D toy examples. To comprehensively assess the efficacy of this approach, it would be necessary for the authors to set up larger-scale problems that are well-documented in CFD/JCP/CMAME papers."
                },
                "questions": {
                    "value": "How does this work compare with Bonev+ ICML 2023? These authors propose a neural PDE approach using spherical coordinate. Your paper seems to be more general. Can you reproduce some of the examples in their paper so we can have an apple to apple comparison?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9410/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9410/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9410/Reviewer_VH6u"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9410/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698716170783,
            "cdate": 1698716170783,
            "tmdate": 1699637185968,
            "mdate": 1699637185968,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JI6WehsaHq",
                "forum": "kIZcruKmBg",
                "replyto": "JpVzxWO8Uw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9410/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9410/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your review! Let us address your comments as follows.\n\n_Unfortunately, it appears that the problem tackled in the paper is somewhat incremental, and the proposed solution lacks a surprising or profound aspect. In the context of an ICLR paper, I'm seeking a novel problem that has not previously been successfully addressed yet, made attainable through this approach, or a novel method to solve a well-established problem that has been extensively explored. Unfortunately, neither of these elements seems to be present in the paper._\n\nThank you for your valuable feedback. We agree that one can consider the problem tackled somewhat incremental, and that our work does not propose a novel method to solve a well-studied problem.\n\nWe tried to introduce the approach of including a diffeomorphism within PINNs as a (novel) general concept, and we believe it could benefit from a common introduction. Furthermore, we consider the application of PINNs to manifolds as a problem that has not been successfully addressed, which is made attainable through this approach.\n\nA surprising aspect of our approach is that - in the transformation case - a latent representation of the PDE solution on the reference domain arises. This is likely to improve generalization capabilities for parametrized geometries, but we recognize that we were not able to demonstrate this effectively on a well-studied problem.\n\n\n_Furthermore, the examples provided mainly consist of small-scale 2D toy examples. To comprehensively assess the efficacy of this approach, it would be necessary for the authors to set up larger-scale problems that are well-documented in CFD/JCP/CMAME papers._\n\nAs mentioned above, we tried to introduce the approach as a general concept and, therefore, we set up easily understandable examples that demonstrate the efficacy of the approach. We tried to choose examples with a clear setup and analytical solutions, accompanied by a transparent and manageable implementation.\n\nHowever, we accept that there is a request for applying our method to larger-scale, well-documented problems that would comprehensively assess the efficacy for non-toy examples.\n\n\n_How does this work compare with Bonev+ ICML 2023? These authors propose a neural PDE approach using spherical coordinate. Your paper seems to be more general. Can you reproduce some of the examples in their paper so we can have an apple to apple comparison?_\n\nBonev+2023 propose Spherical Fourier Neural Operators (Spherical FNOs) that put the concept of FNOs efficiently onto spheres. As they use spherical harmonics for the Fourier transform, their approach is limited to spheres by definition.\u2028 Our approach is more general in the sense that we can model arbitrary manifolds. We think an apple-to-apple comparison doesn\u2019t make sense, because it would be restricted to the case of spheres where the SFNOs will clearly outperform all aspects of our method (accuracy and speed) as it is explicitly tailored to this case."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9410/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700727208953,
                "cdate": 1700727208953,
                "tmdate": 1700727208953,
                "mdate": 1700727208953,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "HRrBPL0Gc7",
            "forum": "kIZcruKmBg",
            "replyto": "kIZcruKmBg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9410/Reviewer_2kyY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9410/Reviewer_2kyY"
            ],
            "content": {
                "summary": {
                    "value": "The work proposes a method to enhance Physics-informed Neural Networks (PINNs) by integrating geometric transformations, to address challenges posed by complex or non-euclidean geometries. \nThe method utilizes a diffeomorphism $\\phi$ that maps a reference domain $\\Omega_{ref}$ to the observation domain $\\Omega$, adapting the derivative computation in the physics-informed loss function. The approach was demonstrated through various problems: Eikonal equation on Archimedean spiral, Poisson problem on surface manifold, Incompressible Stokes flow in deformed tube. Finally, they show that their method can be applied to perform shape optimization according to a Laplace PDE loss."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper is easy to read and the geometric transformation seems reasonable to solve this kind of problem. The first three different examples each test a different geometric setting. The figures are pretty."
                },
                "weaknesses": {
                    "value": "The method relies on the output transformation trick to enforce boundary conditions (BC), which is well suited for Dirichlet BC only. It would not be applicable as is for different kinds of BC, but the authors have a much more general claim.\n\nExcept for the last example, which we will discuss next, the diffeomorphism $\\phi$ is known a priori. Therefore the method in such case simply looks like a change in variable with a known function. How can you apply this method on a domain which is not equipped with such a transformation ?\n\nThe last example is very mysterious to me. I actually do not understand what the method is supposed to achieve by learning simultaneously to impose the PDE constraint and the geometric transformation. Do we know what target geometry the network should converge to ? Besides, the network that learns the transformation is not a diffeomorphism, so there is no guarantee that the optimization problem finds a correct solution. \n\nThe authors do not compare their method with any existing work. There is no literature review. As a result, we do not really understand why these problems cannot be tackled with existing methods. Why do they fail ?\n\nThe authors do not provide any numerical results for their methods, and even the qualitative results do not include the ground truth solutions. It is therefore impossible to judge the effectiveness of the method."
                },
                "questions": {
                    "value": "What is the difference between $\\mathcal{L}$, $\\mathcal{L}_x$ and $\\mathcal{L}_y$ concretely for each example ?\n\n What does the following sentence mean ? \"transformed PINN finds the exact length with an error of = 0.1 \\%\" ."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9410/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9410/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9410/Reviewer_2kyY"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9410/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698768765144,
            "cdate": 1698768765144,
            "tmdate": 1699637185852,
            "mdate": 1699637185852,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VJrU5Fh2jB",
                "forum": "kIZcruKmBg",
                "replyto": "HRrBPL0Gc7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9410/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9410/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your review! Allow us to respond to your comments as follows.\n\n_The method relies on the output transformation trick to enforce boundary conditions (BC), which is well suited for Dirichlet BC only. It would not be applicable as is for different kinds of BC, but the authors have a much more general claim._\n\nWe are not sure which claim you are referring to. Does this refer to \u201cFor simplicity, let us denote Dirichlet boundary conditions only\u201d?\u2028\u2028 We are not claiming that our approach is applicable to different kinds of BC than Dirichlet ones, and we definitely didn\u2019t intend to let it appear more general. Besides, regarding Neumann boundary conditions, one can use the domain transformation to compute the outer normal of the transformed geometry, but it\u2019s unclear how to strongly impose Neumann boundary conditions, as it\u2019s not clear for PINNs in general.\n\n_Except for the last example, which we will discuss next, the diffeomorphism is known a priori. Therefore the method in such case simply looks like a change in variable with a known function. How can you apply this method on a domain which is not equipped with such a transformation?_\n\nIn our work, we assume that the diffeomorphism is given, and we assume that the domain geometry is defined by the mapping of the reference domain via the diffeomorphism. If, vice versa, a geometry is given, e.g., by a mesh, the diffeomorphism might be learned, but it\u2019s definitely an open question how this would be achieved effectively.\n\n_The last example is very mysterious to me. I actually do not understand what the method is supposed to achieve by learning simultaneously to impose the PDE constraint and the geometric transformation. Do we know what target geometry the network should converge to ? Besides, the network that learns the transformation is not a diffeomorphism, so there is no guarantee that the optimization problem finds a correct solution._\n\nIn the last example, we tried to make the mapping more general by using an NN as transformation (targeting the concern of the limitation that the diffeomorphism has to be known a priori, as in your previous comment).\nIt was intended as an explorative example to show what could be done incorporating a parametrized transformation.\nWe believe that we were able to demonstrate that this idea results in a geometrically very flexible PDE solver, e.g., in contrast to classical FEM solvers that would require re-meshing.\n\nHowever, as you mentioned (and we stated clearly), the network has no guarantee to be diffeomorph and this stretches the framework we outlined beforehand beyond its assumptions.\n\nWe agree that our objective function - not including an explicit target - is somewhat arbitrary and that we are not able to state analytically what the network should converge to. Experience with PINNs suggests that a convex shape is easiest to optimize for w.r.t. weak boundary conditions, and this is what our example actually results in.\n\nAs this example opens too many concerns, we conclude in removing it completely upon further investigation.\n\n_The authors do not compare their method with any existing work. There is no literature review. As a result, we do not really understand why these problems cannot be tackled with existing methods. Why do they fail ?_\n\nWe recognize that our examples need more comparisons with similar problems from literature.\u2028\u2028 Unfortunately, to the best of our knowledge, we are not aware of previous works that applied PINNs to manifolds, which severely limits the possibilities of a comparison as well as a literature review.\n\n_The authors do not provide any numerical results for their methods, and even the qualitative results do not include the ground truth solutions. It is therefore impossible to judge the effectiveness of the method._ / \n_What does the following sentence mean? \"transformed PINN finds the exact length with an error of = 0.1 %\u201d_\n\nThe first example is constructed in a way that the numerical solution can be compared to an analytical solution. We were not providing a plot for both solutions, because they are trivial and closely aligned s.t. a plot didn\u2019t make sense. Instead, we stated that the numerical solution fits the analytical solution \u201cwith an error of 0.1%\u201d. This is what the sentence meant, sorry for the incomprehensible expression.\n\nWe acknowledge that our work is lacking analytical results for example 2 and a comparative study for example 3.\n\n_What is the difference between L, L_x and L_y, and concretely for each example ?_\n\nThe subscript indicates the derivation variable of the differential operator. As other reviewers addressed the same issue, we have to make this more explicit along with equations (4)-(5).\u2028\u2028 The examples are split into manifold and transformation cases, where manifold corresponds to L_y and transformation to L_x. We will provide more clarity here."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9410/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700727913531,
                "cdate": 1700727913531,
                "tmdate": 1700727913531,
                "mdate": 1700727913531,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MPP7sAAvsw",
                "forum": "kIZcruKmBg",
                "replyto": "VJrU5Fh2jB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9410/Reviewer_2kyY"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9410/Reviewer_2kyY"
                ],
                "content": {
                    "title": {
                        "value": "Acknowledge"
                    },
                    "comment": {
                        "value": "Thank you for your response, I will keep my score."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9410/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700731285733,
                "cdate": 1700731285733,
                "tmdate": 1700731285733,
                "mdate": 1700731285733,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]