[
    {
        "title": "Linear attention is (maybe) all you need (to understand Transformer optimization)"
    },
    {
        "review": {
            "id": "QQAc62zhnn",
            "forum": "0uI5415ry7",
            "replyto": "0uI5415ry7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2857/Reviewer_gJVN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2857/Reviewer_gJVN"
            ],
            "content": {
                "summary": {
                    "value": "This paper aims at deriving a simplified model for theoretical study of Transformers' optimization. The authors study a pure-attention without softmax Transformer variant (which is called linear attention) on a synthetic regression task. By conducting extensive empirical study, the authors claim that the proposed linear attention Transformer exhibits similar optimization properties that have been observed in the training of vanilla Transformers. Thus, this paper concludes that the proposed linear attention Transformer can be a realistic proxy for understanding Transformer optimization."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is well-written and easy to follow.\n- Sec. 2 offers a concise and informative overview of existing study on Transformers' optimization. It's helpful for readers to digest the context of this study.\n- The empirical study and comparisons look solid and convincing. I'm looking forward to optimization theories based on the proposed simplified model."
                },
                "weaknesses": {
                    "value": "- The proposed simplified model does not have feed forward network (FFN), which is yet another difference from standard Transformers. The authors should explicitly point this out (e.g., in the introduction and the formulation of model architecture) in the paper.\n\n- I strongly recommend the authors to summarize the detailed training recipes (e.g., hyperparameters) in a table and release the code for calculating relevant quantities (e.g., gradient error, robust condition numbers) to facilitate reproducibility and follow-up research.\n\n- In the beginning of Sec. 3.1, $x^{(i)}$ is defined as a row vector. But in the input matrix it seems that one has to interpret $x^{(i)}$ as a column matrix. Moreover, the matrix shape here is very confusing. The input of $F$ is $(n+1)\\times (d+1)$, while $Z_0$ is $(d+1)\\times (n+1)$. I suggest following the \"_Attention Is All You Need_\" paper and using shape $(n+1)\\times (d+1)$ consistently. The authors should fix the notation and formulas here.\n\n**Minor issues.** \n\n- Sec. 2.1: _The features defined above are typically of ..._ $\\to$ _The concepts defined above are typically of ..._\n\n- I recommend the authors to capitalize the first letter of \"Transformers\"."
                },
                "questions": {
                    "value": "The question here is just for clarification.\n\n- What is the box in the upper right of the left 3 plots in Fig. 3?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2857/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2857/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2857/Reviewer_gJVN"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2857/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697936435320,
            "cdate": 1697936435320,
            "tmdate": 1699636229369,
            "mdate": 1699636229369,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "rrNbAKGSee",
                "forum": "0uI5415ry7",
                "replyto": "QQAc62zhnn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2857/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your comments!"
                    },
                    "comment": {
                        "value": "Thank you for your fruitful comments! We revised our paper based on your comments and all the edits are highlighted in orange.\n\n- We added in our revision that \"our setting doesn't have FFN\" in the places that you suggested.\n\n- For the dimensions in the beginning of Section 3.1, those were typos. Thank you for catching them. We now corrected them. \n\n- We also corrected the \"minor issues\" raised by you; we also capitalize \"Transformers\" throughout the manuscript.\n\n- For the upper right box in  Fig. 3 are the quantile-quantile plots (QQ-plots) to see how heavy-tailed the distributions are. We added the QQ plots for our experiments as well as descriptions in our paper.\n\n- We added the summary of hyperparameter choice in Appendix A. Also, we attached the code in the supplementary material."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699979670044,
                "cdate": 1699979670044,
                "tmdate": 1699979670044,
                "mdate": 1699979670044,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ggoP0QwXYc",
                "forum": "0uI5415ry7",
                "replyto": "rrNbAKGSee",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2857/Reviewer_gJVN"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2857/Reviewer_gJVN"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for the timely response. My concerns are mostly addressed. I maintain my positive rating for the paper."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699989870930,
                "cdate": 1699989870930,
                "tmdate": 1699989870930,
                "mdate": 1699989870930,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "S42L4mY7tb",
            "forum": "0uI5415ry7",
            "replyto": "0uI5415ry7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2857/Reviewer_dN4V"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2857/Reviewer_dN4V"
            ],
            "content": {
                "summary": {
                    "value": "This paper offers empirical evidence highlighting parallels between shallow linearized transformer models and the dynamics observed during practical Transformer training. These properties span various well-known aspects: the superiority of adaptive methods over SGD, the presence of heavy-tailed stochastic gradient noise, a robust condition number characterizing the optimization landscape, and the directional smoothness gap. The findings advocate for the potential of simple linear transformers as an insightful and accessible model to elucidate the mystery of Transformer optimization trajectories."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The presented work is overall clear and of notable quality. Its innovative aspect is the unexpected empirical evidence indicating that, under certain conditions, shallow linear transformers can closely resemble conventional attention models, revealing a significant similarity between the simple model and its real-world analogs. \n\nGiven the historical challenges associated with analyzing attention mechanisms involving softmax or other nonlinearities, it is commendable to identify such marked resemblances under broad observations using a simplified framework. This study illuminates the theoretical analysis for optimization on linear transformers, which makes a valuable contribution to the literature."
                },
                "weaknesses": {
                    "value": "The paper is somewhat limited in its data distribution and optimization objective setting to support its conclusion. The data distribution discussed in this setting focuses on in-context linear regression tasks\u2014a largely statistical setting, rather than one that closely resembles language. This might be attributed to the limited expressivity of linear transformers. \n\nI fully understand that the authors are trying to *find the simplest abstraction* as a representative of the transformer\u2019s landscape. However, since the landscape is likely heavily dependent on the data distribution, it would be more convincing to see a variety of data models that exhibit the same phenomenon in simple models. Furthermore, it's difficult to assert that the linearized model is sufficient to understand Transformer optimization, especially since the properties verified in this paper represent only a portion of the optimization narrative."
                },
                "questions": {
                    "value": "- Are there other possible tasks that can be expressed by linear transformers? Do those tasks on simple linear transformers also exhibit those behaviors?\n- If we add other linearities (such as softmax) to the shallow neural networks, can you also show those properties along the training trajectory?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2857/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2857/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2857/Reviewer_dN4V"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2857/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698785498493,
            "cdate": 1698785498493,
            "tmdate": 1699636229304,
            "mdate": 1699636229304,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "RPbWv4bS4h",
                "forum": "0uI5415ry7",
                "replyto": "S42L4mY7tb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2857/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thank you for appreciating the values of our work and constructive comments! We also believe that having a simplified framework is valuable for the future rigorous study on Transformer optimization.\n\nWe also appreciate your comment \"**I fully understand that the authors are trying to find the simplest abstraction as a representative of the transformer\u2019s landscape.**\"\nThat is precisely the main scope of this work.\n\n\nTo address your comments about \"the landscape being likely dependent on the data distribution,\" in **Appendix B**, we conducted an additional set of experiments for a nonlinear regression. In particular, we consider the case where the covariates $x^{(i)}$ are distorted by a ReLU network $MLP$, i.e., the responses are generated as $y^{(i)} = \\langle w_\\star , MLP(x^{(i)}) \\rangle$. In order to cope with the nonlinearity we also added a MLP in our Transformer architecture.\nAs you can see from **Appendix B**, the results for the nonlinear regression are largely similar to the linear regression. Although we agree that nonlinear regression also can't fully explain the practical language modeling, we hope that our additional set of experiments addresses your concern."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700241125193,
                "cdate": 1700241125193,
                "tmdate": 1700241125193,
                "mdate": 1700241125193,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "cr6PdyUnzk",
            "forum": "0uI5415ry7",
            "replyto": "0uI5415ry7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2857/Reviewer_bjjH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2857/Reviewer_bjjH"
            ],
            "content": {
                "summary": {
                    "value": "This paper identifies \"use shallow linear Transformers for regression task\" as a simple setup that serves as an effective mathematical abstraction for studying Transformer optimization.\n- The linear Transformer has attention (inner product) and residual connection, without softmax and MLP. For attention, a single $Q$ matrix is used to replace the product $W_Q^\\top W_K$.\n- The aim is to find the _simplest_ setup as a surrogate for studying optimization: this paper uses a 3-layer network with 5-dim covariate, on the linear regression task."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The simple setup is able to reproduce several characteristics of the training dynamics, which are not captured by canonical optimization theory. These include heavy-tailed gradient noise, robust condition number (larger for SGD than for Adam), as well as better directional and generalized smoothness from Adam.\n- The synthetic setup allows for more precise control.\n    - The paper varies the number of layers, data distribution, and context length.\n    - It's affordable to grid search over 10 learning rates."
                },
                "weaknesses": {
                    "value": "- The main claim is that the simplified setup can be used as a proxy for larger scale systems. However, some connections are drawn by having \"qualitatively similar\" results.\n  - For example it's known that higher-order moments of the gradient noises matter, which cannot be captured by examining plots visually.\n  - e.g. How to judge whether the noises are similar based on Fig 3, or that 8-layer is qualitatively similar to 3-layer based on Fig 8?\n- The current empirical results are for confirming existing findings, but it's unclear what new discoveries can be enabled by this simplified setup."
                },
                "questions": {
                    "value": "- What are some phenomena that are not able to be captured in this simplified setup?\n    - e.g. using the $Q$ parameterization rather than $W_Q^\\top W_K$ might lead to different implicit regularization effects.\n    - There might be effects about architectural choices, e.g. consequences and limitations from the softmax.\n    - In general, it would be helpful to better clarify what is consider in-scope and what is not.\n- Could you give some examples of new discovery or actionable advice from the simple setup?\n- The current setup is entirely linear; if the data is non-linear, would there be similar optimization characteristics?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2857/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698810867837,
            "cdate": 1698810867837,
            "tmdate": 1699636229233,
            "mdate": 1699636229233,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "DgmlFv3MT8",
                "forum": "0uI5415ry7",
                "replyto": "cr6PdyUnzk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2857/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your comments!"
                    },
                    "comment": {
                        "value": "Thank you for your constructive comments. We agree with your comment that our simple setting lets us do more precise controlled experiments. \n\nLet us address your points one by one. We revised our paper based on your comments and all the edits are highlighted in orange.\n\n-- **More quantitative way of checking noise distribution?** Following [Kunstner et al., 2023], we added the quantile-quantile plot (QQ-plot) in our revision. A QQ-plot is a plot of the quantiles of two distributions against each other. In particular, we add QQ-plots that compare the quantiles of the stochastic gradient noise (y-axis) against those of its best-fit Gaussian distribution. One can see that QQ-plots go beyond $y=x$ line toward the right, suggesting that the stochastic noises are indeed heavy-tailed. Also, for the heavy-tailed covariates experiments and the more layers experiments, we now can also see clearly for which cases the noises become more heavy-tailed.\n\n-- **Regarding the $W_Q W_K$ parametrization.** Thank you for your question. In the left plot of Figure 8, we added a result for the standard Transformer parameterization of $W_Q W_K$, and observed that the result looks similar to our simplified parameterization. \n\n-- **Regarding softmax activation.** We mostly considered linear Transformer since it's better suited for the task of solving linear regression in-context as shown in Figure 7. \n\n-- **Clarifying the scope of this work** As per your suggestion, we further clarified the main scope of this work in our introduction, by saying \"....development of efficient optimization methods for Transformers. However, such directions are out-of-scope of this work, and left for future work.\"\n\n-- **Our setting entirely linear?** We would like to clarify that despite removal of nonlinearity, the linear Transformer is still highly nonlinear function due to the attention mechanism. In particular, even the output of single layer linear Transformer is a multivariate 3rd order polynomial function of the input.\n\n**[Updated Response]**: In order to address your concerns about the linearity in the data distribution, in our newest revision, we conducted an additional set of experiments for the nonlinear regression, and it's presented in **Appendix B**."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699979573308,
                "cdate": 1699979573308,
                "tmdate": 1700241063818,
                "mdate": 1700241063818,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MX9vtBn4oL",
                "forum": "0uI5415ry7",
                "replyto": "DgmlFv3MT8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2857/Reviewer_bjjH"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2857/Reviewer_bjjH"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarifications and the additional results! I have a few more questions please:\n\n- For Fig 3, the distributions in practice vs synthetic are clearly different based on the qq-plots; could you comment on how much you expect this difference to matter for analyses?\n- For Fig 15, why does Adam's robust conditional number increase in the end? The reason for me to ask about results on non-linear distribution is that I wonder what the linear setup would fail to capture, and how transferable would the conclusions on the linear setup transfer to more general cases.\n- Minor comment: please make the y-axis consistent across figures; e.g. the loss scales in Fig 8 left and right, and Fig 15 left."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700329327126,
                "cdate": 1700329327126,
                "tmdate": 1700329327126,
                "mdate": 1700329327126,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "HKu0Jpj3O5",
            "forum": "0uI5415ry7",
            "replyto": "0uI5415ry7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2857/Reviewer_GNbE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2857/Reviewer_GNbE"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the property of the shallow linear Transformer model. The evaluated phenomenon includes comparing Adam and SGD, heavy-tailed gradient noise, condition number, smoothness, etc. The experimental results show that the linear Transformer model reproduces the phenomena that have been observed for full Transformers. The results also show that more heavy-tailed data distribution and more layers can enhance the conclusion.\n\n--------------------------------------------------------\n\n**After rebuttal**: Thank you for your response. I am sorry for the late reply. I am satisfied with the feedback and revisions. I will keep my rating as 6 and support you. A minor point and suggestion: Please clarify what the four figures in Fig. 15 are to be compared within the main body. Later, I realize you are mentioning some figures on page 3. It is not a big issue anyway."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This work is novel in terms of new experiments on linear transformers from many aspects of evaluation. The paper is well-written and clear to follow. The studied problem is interesting to the community, from my understanding. The designed experiments are concise to support the conclusion."
                },
                "weaknesses": {
                    "value": "1. This work lacks theoretical understanding or explanation after the experiments in Section 3.2, 4.1, 4.2. \n2. The limitation is not discussed. One thing that should be emphasized in the introduction or the abstract is that the experiments are linear regression, which is a good fit for linear Transformers."
                },
                "questions": {
                    "value": "1. One conclusion may not be obvious for linear Transformers compared with softmax Transformers. That is, the attention weights are more concentrated (even sparsely) on some key features/tokens after training, which is observed in several existing works [Li et al., 2023a, Li et al., 2023b, Oymak et al., 2023] for softmax Transformers. Can the authors provide a comparison empirically on this? Also, I think it is better to cover such a discussion in the revision.\n\nOymak et al., 2023, \"On the Role of Attention in Prompt-tuning. \"\nLi et al., 2023a, \"A Theoretical Understanding of Shallow Vision Transformers: Learning, Generalization, and Sample Complexity.\"\nLi et al., 2023b, \"How do transformers learn topic structure: Towards a mechanistic understanding.\""
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2857/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2857/Reviewer_GNbE",
                        "ICLR.cc/2024/Conference/Submission2857/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2857/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698823145581,
            "cdate": 1698823145581,
            "tmdate": 1700786022023,
            "mdate": 1700786022023,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "DUsglx3vUx",
                "forum": "0uI5415ry7",
                "replyto": "HKu0Jpj3O5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2857/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thank you for appreciating the values of our work and your constructive comments! \n\n\nAdmittedly, we do not provide theoretical understanding of the phenomenon, but what we claim as our main contribution is the discovery of a simple abstract setting where the key characteristics of Transformer optimization persists, and we believe that our findings could serve as a useful testbed for the future theoretical investigations.\n\nIn order to address your concern regarding the limitation, we conducted an additional set of experiments for a nonlinear regression. In particular, we consider the case where the covariates $x^{(i)}$ are distorted by a ReLU network $MLP$, i.e., the responses are generated as $y^{(i)} = \\langle w_\\star , MLP(x^{(i)}) \\rangle$. In order to cope with the nonlinearity we also added a MLP in our Transformer architecture.\nAs you can see from **Appendix B**, the results for the nonlinear regression are largely similar to the linear regression. We hope that our additional set of experiments addresses some of your concern.\n\nMoreover, thank you for point us to the additional relevant works regarding the softmax Transformers. Although it's not directly related to the main message of our paper, we answer your question regarding the attention scores as below. As a summary, for the linear Transformer for linear regression, we need to combine appropriate covariates $x^{(i)}$, $i=1,2,...,n$ to figure out the missing prediction $y^{(n+1)}$ for $x^{(n+1)}$. So, the sparsity of the attention weights will depend on instances. For instance, when the covariates $x^{(i)}$ are orthogonal, we empirically observe that the attention scores are sparse both for linear and softmax Transformers, which is consistent with the results from the previous papers. As per your suggestion, we added a discussion regarding the softmax Transformer on **Page 6**."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700241001188,
                "cdate": 1700241001188,
                "tmdate": 1700241001188,
                "mdate": 1700241001188,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]