[
    {
        "title": "Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models"
    },
    {
        "review": {
            "id": "ubZZhDIJ6b",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8883/Reviewer_zJ5m"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8883/Reviewer_zJ5m"
            ],
            "forum": "PN9uaKA1nV",
            "replyto": "PN9uaKA1nV",
            "content": {
                "summary": {
                    "value": "The paper described a method to fill in templates with terms taken from medical domain knowledge graphs and LLM suggestions. Once the prompt are obtained they are fed to ChatGPT to create synthetic datasets that can be used for MLM fine-tuning and later used for wide variety of NLP tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The concept of using LLMs to generate training data is important and should be explored more to achieve best practices."
                },
                "weaknesses": {
                    "value": "- The paper mentioned privacy as an issue but I think that the method will not address any privacy issues that are accruing in the original LLM\n- Hard to understand what is the base model used for MLM training, is it PubMedBERT? If so, PubMedBERT outperforms all of the other attempts\n- Baselines descriptions could be more elaborated"
                },
                "questions": {
                    "value": "The most important question is what is the additional pre trained classifier\nIt's unclear from the paper"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8883/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697223440543,
            "cdate": 1697223440543,
            "tmdate": 1699637118107,
            "mdate": 1699637118107,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "luoNKTxDSu",
                "forum": "PN9uaKA1nV",
                "replyto": "ubZZhDIJ6b",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8883/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8883/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Initial Response to Reviewer zJ5m"
                    },
                    "comment": {
                        "value": "We deeply thank the reviewer for these detailed suggestions on improving the presentation of our work.\n\n***\n> W1: The paper mentioned privacy as an issue but I think that the method will not address any privacy issues that are accruing in the original LLM.\n\nA: Thanks for the insightful feedback. We have answered this question in the general response for all reviewers. Please refer to the **Patient privacy concerns** section for details.\n\n***\n> W2: Hard to understand what is the base model used for MLM training, is it PubMedBERT? If so, PubMedBERT outperforms all of the other attempts.\n\nA: Thanks for your question. We would like to kindly point out that for the base model, \u201cMLM training\u201d is usually conducted during the pretraining stage, while in our work, we focus on the **fine-tuning** stage where we adopt the cross-entropy loss towards the target task with the generated synthetic data (see Section 4.3 for details). This is a common setting that is widely used for evaluating the quality of synthetic text data [1,2,3], where better performance indicates better synthetic data utility.\n\nWe note that for the base model, we use the same PubMedBERT for ClinGen and baselines to **ensure fair comparison**. For the PubMedBERT model, we fine-tune it for different target tasks using the synthetic text data **without additional MLM training**. As evidenced in Table 1, our method, leveraging the same base model (PubMedBERT-base and large), consistently outperforms the baselines. This better performance is attributed primarily to the high quality of the generated data.\n\n> [1] Ye et al. \"Zerogen: Efficient zero-shot learning via dataset generation.\" EMNLP 2022.\n>\n> [2] Meng et al. \"Tuning language models as training data generators for augmentation-enhanced few-shot learning.\" ICML 2023.\n> \n> [3] Ye et al. \"ProGen: Progressive zero-shot dataset generation via in-context feedback.\" EMNLP 2022\n\n***\n> W3: Baselines descriptions could be more elaborated\n\nA: Thank you for the suggestion. We provide the baseline details in **Appendix E** in our original manuscript, and we have expanded these descriptions to provide more comprehensive information in the revision.\n\n***\n> Q1: The most important question is what is the additional pre trained classifier It's unclear from the paper\n\nA: As mentioned in W2, we utilize the same pre-trained PubMedBERT as a classifier for our method and baselines on downstream tasks to prevent unfair comparison. Please see \u201cSec 5.1 Experiment Setup\u201d for reference. The word \u201cadditional\u201d is to differentiate the classifier with the previous LLM generator. We do not conduct any additional pre-training. We have deleted the word to avoid confusions.\n\n***\nThanks again for your review! Please let us know if you have any further questions."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8883/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700361241007,
                "cdate": 1700361241007,
                "tmdate": 1700361241007,
                "mdate": 1700361241007,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "YuLlYuucy3",
            "forum": "PN9uaKA1nV",
            "replyto": "PN9uaKA1nV",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8883/Reviewer_CY6f"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8883/Reviewer_CY6f"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes CLINGEN to generate synthetic clinical text data using LLMs to enhance clinical NLP models. The prompt for LLMs incorporates clinical information and the generated synthetic data has a similar distribution as the original datasets, is more diverse, and helps NLP models perform better in few-shot settings (7 clinical NLP tasks, 16 datasets, compared to 9 baseline methods)."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The work has conducted thorough experiments on 7 clinical NLP tasks and 16 datasets in the few-shot settings and shows a clear advantage of the proposed method CLINGEN. The limitations of previous related works are also clearly discussed, quantified and demonstrated. The proposed method has shown promising results to mitigate the limitations.\n\n2. The work has potential significance in the clinical NLP domain, where gold standard data can be limited and private patient needs to be protected. Synthetic data generation can be useful to address both challenges. The work has shown a promising avenue to utilise synthetic clinical data.\n\n3. The paper is overall well-written and clear."
                },
                "weaknesses": {
                    "value": "1. The prompt design is quite simple, i.e. the method itself lacks novelty. \n\n2. The works claim to \"infuse\" clinical knowledge into the prompt but the prompt simply incorporates clinical topics/concepts (picked from a knowledge graph and LLMs) like \"Stoke\", rather than actual clinical knowledge (for example, diabetes, stroke, and CHF are risk factors for CKD). Using the word \"infuse clinical knowledge\" over-claims the novelty of the method. \n\n3. It is unclear how the prompts in Appendix F are determined. Also, the work does not experiment with different prompt designs."
                },
                "questions": {
                    "value": "One useful and missing reference: Ive J, Viani N, Kam J, Yin L, Verma S, Puntis S, Cardinal RN, Roberts A, Stewart R, Velupillai S. Generation and evaluation of artificial mental health records for natural language processing. NPJ digital medicine. 2020 May 14;3(1):69.\n\nThe paper did not discuss patient privacy in clinical NLP. Synthetic data should be anonymous and can help AI researchers build models without touching real private patient data.\n\nTextual data is an important component in clinical data but structured data (vital signs, lab tests) is also critical. This work focuses on clinical text synthetic data generation only and more types of data can be considered as future works. However, the capability of LLMs to generate synthetic structured clinical data is questionable.\n\nThe clinical topics/concepts in section 4.1.1 are picked from KG and LLMs. How many topics are from KGs and how many are from LLMs? How is this ratio determined? Would a different ratio impact results? Why not ask a clinician to hand-pick clinical topics?\n\nThe current SOTA results (regardless of fully supervised or few-shot) should be added to Table 1 as reference points.\n\nD_train in Equation 1 has only K (K<=5) samples per label?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8883/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698797607108,
            "cdate": 1698797607108,
            "tmdate": 1699637117995,
            "mdate": 1699637117995,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "DeuHIk678s",
                "forum": "PN9uaKA1nV",
                "replyto": "YuLlYuucy3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8883/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8883/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Initial Response to Reviewer CY6f (Part 1)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the constructive feedback. We answer your questions as follows.\n\n***\n> W1: The prompt design is quite simple, i.e. the method itself lacks novelty.\n\nA: Thanks for the insightful feedback. We have answered in the general response for all reviewers. Please refer to the **Lack of novelty** section for details.\n\n***\n> W2: The works claim to \"infuse\" clinical knowledge into the prompt but the prompt simply incorporates clinical topics/concepts (picked from a knowledge graph and LLMs) like \"Stoke\", rather than actual clinical knowledge (for example, diabetes, stroke, and CHF are risk factors for CKD). Using the word \"infuse clinical knowledge\" over-claims the novelty of the method.\n\nA: Thank you for the valuable suggestion. While we would like to kindly point out that we do include certain relational information for relation extraction tasks, we acknowledge that we did not define the scope of the \"clinical knowledge\" integrated into our model. Accordingly, we have made revisions in the introduction to explicitly specify that we employ clinical concepts and basic relationships among them as the form of clinical knowledge in our study. We have also recognized the potential for incorporating more fine-grained clinical knowledge as part of our future work, which is detailed in **Appendix A**.\n\n***\n> W3: It is unclear how the prompts in Appendix F are determined. Also, the work does not experiment with different prompt designs.\n\nA: Thanks for the feedback. We notice that the majority of existing research on synthetic data generation relies on manually crafted, straightforward prompts without intricate designs [1,2,3]. Thus, we design our prompt based on the structures of those existing works and task-specific information mentioned in [4], with additional instructions to further incorporate the selected clinical topics and writing styles. For other existing prompt optimization methods in the literature, we identify two related techniques that may be potentially applicable to our case. Please refer to the **Comparison with different prompt designs** section of the general response to all reviewers for the experimental results and further discussions.\n\n>[1] Ye et al. \"Zerogen: Efficient zero-shot learning via dataset generation.\" EMNLP 2022.\n>\n>[2] Meng et al. \"Tuning language models as training data generators for augmentation-enhanced few-shot learning.\" ICML 2023.\n>\n>[3] Ye et al. \"ProGen: Progressive zero-shot dataset generation via in-context feedback.\" EMNLP 2022.\n>\n>[4] Fries et al. \"Bigbio: a framework for data-centric biomedical natural language processing.\" NeurIPS 2022.\n\n***\n> Q1: One useful and missing reference: Ive J, Viani N, Kam J, Yin L, Verma S, Puntis S, Cardinal RN, Roberts A, Stewart R, Velupillai S. Generation and evaluation of artificial mental health records for natural language processing. NPJ digital medicine. 2020 May 14;3(1):69.\n\nA: Thanks for mentioning this relevant paper. We have modified our manuscript and added the reference in **Section 1** and **Appendix A**.\n\n***\n> Q2: The paper did not discuss patient privacy in clinical NLP. Synthetic data should be anonymous and can help AI researchers build models without touching real private patient data.\n\nA: Thanks for the insightful feedback. We have answered this question in the general response for all reviewers. Please refer to the **Patient privacy concerns** section for details.\n\n***\n> Q3: Textual data is an important component in clinical data but structured data (vital signs, lab tests) is also critical. This work focuses on clinical text synthetic data generation only and more types of data can be considered as future works. However, the capability of LLMs to generate synthetic structured clinical data is questionable.\n\nA: Thanks for the thoughtful feedback. We have answered this question in the general response for all reviewers. Please refer to the **Application to QA and EHR tasks** section for details."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8883/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700360520816,
                "cdate": 1700360520816,
                "tmdate": 1700360520816,
                "mdate": 1700360520816,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RVMYQ9BAME",
                "forum": "PN9uaKA1nV",
                "replyto": "YuLlYuucy3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8883/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8883/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Initial Response to Reviewer CY6f (Part 2)"
                    },
                    "comment": {
                        "value": "> Q4: The clinical topics/concepts in section 4.1.1 are picked from KG and LLMs. How many topics are from KGs and how many are from LLMs? How is this ratio determined? Would a different ratio impact results?\n\nA: Thank you for bringing up this question. In our experiments, we keep the topics from KGs and LLMs **separate**. Specifically, we create a candidate set of approximately 6000 topics from KGs and another candidate set of around 2000 topics from LLMs. We then independently sample topics from these two candidate sets to generate two distinct sets of synthetic training samples. Please refer to **Table 1** for the experimental results for both sets of synthetic data.\n\nThe motivation behind this is that, in our paper, we present KGs and LLMs as two alternative and complementary sources for obtaining topics for readers to understand the influence of topic injection from KG and LLMs distinctly. However, we agree with the reviewer that combining topics from KGs and LLMs has the potential to enhance performance. Thus, we have conducted additional experiments to demonstrate the impact of combining topics from KGs and LLMs at various ratios. Note that we still keep a total of 5000 generated synthetic samples to maintain a fair comparison.\n\n| KG : LLM| LitCovid | CDR | MEDIQA-RQE | BC5CDR-D | Average |\n|:--:|:--:|:--:|:--:|:--:|:--:|\n| PubMedBERT-Base | F1 | F1 | ACC | F1 ||\n| 1:0 | 58.01 | 61.75 | 74.85 | 60.75 | 63.84 |\n| 2:1 | 56.18 | 62.89 | 73.50 | 60.53 | 63.28 |\n| 1:1 | 56.76 | 63.86 | 74.01 | 63.26 | 64.47 |\n| 1:2 | 55.49 | 64.33 | 75.10 | 61.62 | 64.14 |\n| 0:1 | 59.22 | 63.34 | 72.40 | 61.03 | 64.00 |\n| PubMedBERT-Large ||||||||\n| 1:0 | 55.81 | 62.66 | 79.92 | 61.21 | 64.90 |\n| 2:1 | 54.21 | 64.22 | 76.15 | 62.40 | 64.25 |\n| 1:1 | 56.80 | 65.90 | 79.12 | 65.94 | 66.94 |\n| 1:2 | 54.41 | 64.68 | 80.77 | 64.55 | 66.10 |\n| 0:1 | 57.07 | 64.99 | 77.36 | 63.15 | 65.64 |\n\nThe experimental results indicate that combining knowledge from KGs and LLMs can yield a performance improvement, though not a substantial one. However, note that in practice, it is challenging to tune the ratio in the few-shot setting due to the limited volume of validation labels [5], and thus we only include the 1:1 results in **Table 6,7,8** in **Appendix G** for all 16 datasets.\n\n> [5] Perez et al. \"True few-shot learning with language models.\" NeurIPS 2021.\n\n***\n> Q4 (continued): Why not ask a clinician to hand-pick clinical topics?\n\nA: Thank you for the suggestion. While we admit clinicians' ability to select clinical topics, it is important to point out that such a manual approach involves significant time and money, thus is less scalable. Furthermore, it can be challenging for clinicians to manually create thousands of clinical topics for synthetic training samples. To this end, we utilize KGs and LLMs as more efficient methods to automatically extract clinical topics."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8883/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700360813377,
                "cdate": 1700360813377,
                "tmdate": 1700360813377,
                "mdate": 1700360813377,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lo5mRctSEm",
                "forum": "PN9uaKA1nV",
                "replyto": "YuLlYuucy3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8883/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8883/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Initial Response to Reviewer CY6f (Part 3)"
                    },
                    "comment": {
                        "value": "> Q5: The current SOTA results (regardless of fully supervised or few-shot) should be added to Table 1 as reference points.\n\nA: Thanks for the valuable suggestion. In our study, we present the supervised model performance on few-shot demonstrations and the complete original training set, denoted as \"Supervised - Few\" and \"Supervised - Full,\" respectively. We use PubMedBERT, the same classifier employed for ClinGen and all baseline models, as a reference point. \n\nFollowing the reviewer's request, we have tried our best to gather relevant data on SOTA models and their performances. However, this task is nontrivial due to several reasons: (1) Many studies only test their models on a subset of the datasets we used; (2) Original papers for some datasets might report results only for base models (like BERT) and not include more recent models (such as PubMedBERT or LinkBERT); (3) In some cases, datasets report only F1 scores without precision and recall metrics.\n\nDespite our best efforts to compile this information, there are still missing values in the available SOTA performance data. We have documented these findings in Tables 6, 7, and 8 in Appendix G, with references from [5-10]. Note that many SOTA performances are based on different classifiers, so these results should only serve as reference points and cannot be directly comparable with the performance of ClinGen and other baselines.\n\n\n> [6] Peng et al. \"Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets.\" BioNLP 2019.\n>\n> [7] Tinn et al. \"Fine-tuning large neural language models for biomedical natural language processing.\" Patterns 4.4 (2023).\n>\n> [8] Gu et al. \"Domain-specific language model pretraining for biomedical natural language processing.\" Transactions on Computing for Healthcare 2021.\n>\n> [9] Yasunaga et al. \"LinkBERT: Pretraining Language Models with Document Links.\" ACL 2022.\n> \n> [10] BLURB Leaderboard (https://microsoft.github.io/BLURB/leaderboard.html)\n\n***\n> Q6: D_train in Equation 1 has only K (K<=5) samples per label?\n\nA: $D_{train}$ has only K samples per label, where we set K=5 in our experiments. We intentionally set K to a very small value to simulate a few-shot learning scenario. Recent work on language model fine-tuning suggests that it can help model to learn a good initialization before fine-tuning on synthetic samples [2].\n\n>[2] Meng et al. \"Tuning language models as training data generators for augmentation-enhanced few-shot learning.\" ICML 2023.\n\n***\nThanks again for your feedback! Please let us know if you have any further questions."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8883/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700361060921,
                "cdate": 1700361060921,
                "tmdate": 1700361145674,
                "mdate": 1700361145674,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3pHCKsqwwG",
                "forum": "PN9uaKA1nV",
                "replyto": "lo5mRctSEm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8883/Reviewer_CY6f"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8883/Reviewer_CY6f"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the clarification and responses! I have no further questions."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8883/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700609115975,
                "cdate": 1700609115975,
                "tmdate": 1700609115975,
                "mdate": 1700609115975,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "gweK50esdo",
            "forum": "PN9uaKA1nV",
            "replyto": "PN9uaKA1nV",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8883/Reviewer_D87k"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8883/Reviewer_D87k"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new approach called CLINGEN for generating synthetic clinical text data using large language models (LLMs). The key idea is to leverage both external clinical knowledge graphs (KGs) and the knowledge encoded in LLMs to create informative and diverse prompts for guiding the LLM to generate high-quality and realistic synthetic data.\n\nSpecifically, CLINGEN extracts clinical topics from KGs and LLMs and writing style suggestions from LLMs. It composes this knowledge into prompts with a random topic and style to encourage diversity. The resulting synthetic data is used to train task-specific models.\n\nThe authors comprehensive benchmark experiments are conducted."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "-The writing is clear and easy to undersand.\n-Proposes a simple yet effective strategy to harness both structured KG knowledge and unstructured knowledge in LLMs to create informative prompts.\n-Provides thorough empirical evaluation across diverse clinical tasks and datasets demonstrating consistent gains."
                },
                "weaknesses": {
                    "value": "-The proposed prompting strategy is intuitive but lacking in novelty. Leveraging both KGs and LLMs is expected to help.\n- To best of my knowledge, the generated data is still in-domain data, generating the style the same as the training data. So, it is not surprised  for me that using more data for training can improve model performance. It is more make sense to improve small model's over medical capacity , instead of overfit on a specific task with more training data. \n-No rigorous comparison with other prompting optimization methods in the literature."
                },
                "questions": {
                    "value": "- I am not sure why the two stages training is conducted. Was the results yo mix train your training data with  generated data together for training?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8883/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8883/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8883/Reviewer_D87k"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8883/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698809617053,
            "cdate": 1698809617053,
            "tmdate": 1699637117829,
            "mdate": 1699637117829,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "zIF6hiEsBu",
                "forum": "PN9uaKA1nV",
                "replyto": "gweK50esdo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8883/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8883/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Initial Response to Reviewer D87k (Part 1)"
                    },
                    "comment": {
                        "value": "We appreciate the time and detailed comments of the reviewer. We answer your questions as follows. \n\n***\n> Q1: I am not sure why the two stages training is conducted. Was the results yo mix train your training data with generated data together for training?\n\nA: Thank you for the question. In Stage I, we perform fine-tuning of the classifier using few-shot examples in the original training set, specifically K samples per label (in our experiments, K=5). Subsequently, in Stage II, we conduct further fine-tuning of the classifier using the synthetic training data that we generate. We employ this two-stage training because it has been empirically demonstrated to be stable and is commonly employed in various works, including synthetic data generation tasks [1] and other semi-supervised learning methods [2,3]. Note that we mix the few-shot training data with the generated synthetic data and apply this two-stage training **consistently** for all the baselines to ensure a fair comparison.\n\n>[1] Meng et al. \"Tuning language models as training data generators for augmentation-enhanced few-shot learning.\" ICML 2023\n>\n>[2] Laine and Aila. \"Temporal ensembling for semi-supervised learning.\" ICLR 2017\n>\n>[3] Chen et al. \"Mixtext: Linguistically-informed interpolation of hidden space for semi-supervised text classification.\" ACL 2020"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8883/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700360145576,
                "cdate": 1700360145576,
                "tmdate": 1700360236284,
                "mdate": 1700360236284,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pMKRKaCz1Z",
                "forum": "PN9uaKA1nV",
                "replyto": "gweK50esdo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8883/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8883/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Initial Response to Reviewer D87k (Part 2)"
                    },
                    "comment": {
                        "value": "> W1: The proposed prompting strategy is intuitive but lacking in novelty. Leveraging both KGs and LLMs is expected to help. \n\nA: Thanks for the insightful feedback. We have answered this question in the general response for all reviewers. Please refer to the **Lack of novelty** section for details.\n\n***\n> W1 (continued):  To best of my knowledge, the generated data is still in-domain data, generating the style the same as the training data. So, it is not surprised for me that using more data for training can improve model performance.\n\nA: We would like to clarify that we *do not* use \u201cmore data\u201d compared to the baselines. In our experiments, all the baseline models are evaluated based on their respective generated synthetic datasets, and we maintain the **same amount of synthetic training data** across all methods, as mentioned in Appendix C. This ensures a fair comparison among all the methods evaluated in our study. In the revised version, we explicitly mention this in **Section 5.1** to avoid confusion.\n\nMoreover, it's essential to highlight that merely increasing the volume of training data **does not guarantee** better results. As shown in Table 1, some standard data augmentation methods cannot even outperform the supervised setting with few-shot examples only. Besides, for LLM-based data generation approaches, Figure 11(a) shows that the best baseline (DemoGen) using 100% of the training data actually shows lower performance compared to using only 50% of the training data. These observations illustrate the importance of the quality of training data over its quantity. Our focus, therefore, has been on developing a methodology to create high-quality synthetic training data. The results from our experiments in Table 1, Figure 5 and Figure 11 confirm that we consistently outperform baselines with the same amount of generated data under different budgets. \n\n***\n> W1 (continued): It is more make sense to improve small model's over medical capacity, instead of overfit on a specific task with more training data.\n\nA: Thanks for the suggestion. We would like to emphasize that our primary goal is indeed to improve a model\u2019s medical capacity during fine-tuning. Our approach focuses on enriching the training dataset with diverse medical knowledge, which can empower models of varying sizes with improved medical capacity. The generated synthetic data can also be easily and directly applied to improve various existing models without additional design. \n\nBesides, we believe that our approach (e.g., improving the data quality for fine-tuning task-specific models) is **orthogonal** to those efforts that improve the small models\u2019 medical capacity in the pretraining stage. As shown in Table 1, the average performance of ClinGen with *PubMedBERT-base* (110M Parameters) as the backbone is *better than* the strongest baseline using *PubMedBERT-large* (340M Parameters) on the majority of tasks (e.g. Text Class, Relation Extraction, NLI, Fact Verification, and Medication Attribute Extraction), indicating that better data quality for fine-tuning is also crucial for adapting small model on specific tasks.\n\nMoreover, it is important to note that our strategy of incorporating more diverse training data alleviates rather than exacerbates the overfitting issue. By incorporating diverse training data enriched with medical knowledge, we enhance the ability of models to generalize across various clinical scenarios.\n\n***\n> W2: No rigorous comparison with other prompting optimization methods in the literature.\n\nA: Thanks for the constructive feedback. We would like to highlight that the majority of existing research on synthetic data generation relies on manually crafted, straightforward prompts without dedicated designs [4,5,6]. That being said, we have tried our best to identify two closely related prompt optimization techniques that are potentially applicable to our case. Please see the **Comparison with different prompt designs** section of the general response to all reviewers for the experimental results and further discussions.\n\n\n> [4] Ye et al. \"Zerogen: Efficient zero-shot learning via dataset generation.\" EMNLP 2022.\n> \n> [5] Meng et al. \"Tuning language models as training data generators for augmentation-enhanced few-shot learning.\" ICML 2023.\n> \n> [6] Ye et al. \"ProGen: Progressive zero-shot dataset generation via in-context feedback.\" EMNLP 2022.\n\n***\nThanks again for your constructive suggestions! We hope our responses address your concerns."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8883/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700360298423,
                "cdate": 1700360298423,
                "tmdate": 1700361161722,
                "mdate": 1700361161722,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qtmWv8DhU7",
            "forum": "PN9uaKA1nV",
            "replyto": "PN9uaKA1nV",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8883/Reviewer_jB98"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8883/Reviewer_jB98"
            ],
            "content": {
                "summary": {
                    "value": "The paper aims to do synthetic clinical text generation using LLMs for clinical NLP tasks using the outlined approach - \n\n(1) Extract clinical knowledge in the form of sample related entities or relations from external KG (nodes and edges from KB) or query relevant knowledge from LLM (prompt LLM to list 100 entities of a certain entity type). \n(2) Include task names and  writing style into the prompt (e.g \u201cmedical literature\u201d or \u201cpatient-doctor dialogues\u201d ).\n(3) Generate data using few-shot learning\n(3) Use a pretrained model to fine tune on synthetic data.\n\nThe paper does a very comprehensive evaluation of  synthetic clinical data generation across 7 clinical NLP tasks and 16 datasets. Benchmarked with ZeroGen and DemoGen. Metrics included - evaluation task metrics, Entity Coverage. Entity Frequency, Central Moment Discrepancy (CMD), t-SNE  embeddings comparing synthetic and ground truth data. Includes a detailed ablation and parameter study."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper does a good job doing comprehensive evaluation and ablation study. The paper is well written."
                },
                "weaknesses": {
                    "value": "To better assess the importance of the work, it would be beneficial to clarify the questions listed below."
                },
                "questions": {
                    "value": "(1) The reviewer likes that the paper did a direct comparison with the prompts from GPT-3.5. However, I'm interested to know if the current medical LLMs are proficient in the tasks described. Should they already excel in these areas, it might somewhat diminish the necessity for the proposed approach.\n(2) What are the limitations of your approach - what tasks is it limited to? How will it perform on more complex tasks such as descriptive QA (since most of the evaluation is on classification tasks)? Will it work on medical records?\n(3) Some of the tasks still have some issues in regards to entity coverage and it looks like generally the performance is low on these tasks. Are these common entities that are missed and not identified by LLM or KB ? How will this looks like if a medical LLM was used for generation ?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8883/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698981843640,
            "cdate": 1698981843640,
            "tmdate": 1699637117702,
            "mdate": 1699637117702,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "rfgftWlWX6",
                "forum": "PN9uaKA1nV",
                "replyto": "qtmWv8DhU7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8883/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8883/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Initial Response to Reviewer jB98 (Part 1)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the time, valuable feedback, and suggestions for improvements. For your several questions, we clarify as follows:\n\n***\n> Q1: The reviewer likes that the paper did a direct comparison with the prompts from GPT-3.5. However, I'm interested to know if the current medical LLMs are proficient in the tasks described. Should they already excel in these areas, it might somewhat diminish the necessity for the proposed approach.\n\nA: Thank you for the suggestion. Per your request, we have included additional experimental results that compare the direct inference performance of two recent and popular medical Large Language Models (LLMs): **PMC-LLaMa** [1] and **MedAlpaca** [2]. The table below illustrates that these medical LLMs perform less effectively than both ClinGen and GPT-3.5. This result can likely be attributed to two reasons:\n- The smaller size of the medical LLMs (7B) compared to GPT-3.5, which results in limited language modeling and reasoning capabilities. While we are aware that larger medical LLMs like Med-PaLM exist, they are not publicly accessible and thus cannot be used in our experiments. \n- Furthermore, these medical LLMs are typically trained on general medical knowledge sources, such as Wikipedia and Stack Exchange, as indicated by https://github.com/kbressem/medAlpaca#data-overview. This general knowledge may not translate effectively to specific tasks like chemical-protein interaction prediction or health fact verification, leading to suboptimal performance in few-shot learning scenarios. \n\nThis observation aligns with findings from other research [3], which suggest that for certain clinical Natural Language Processing tasks, the fine-tuning of more compact models may outperform the in-context learning capabilities of larger LLMs. The results and discussions have been updated to **Table 2** in **Section 5.3**.\n\n| | HOC | | GAD | | ChemProt | MEDIQA-RQE | PUBHEALTH | | | NCBI-Disease | | | CASI | |\n|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n| | F1 | P | R | F1 | F1 | ACC | ACC | F1 | P | R | F1 | P | R | F1 |\n| GPT-3.5 Inference | 68.76 | 84.21 | **97.46** | 90.35 | 49.42 | 74.31 | **69.50** | **52.47** | 46.62 | 52.31 | 49.30 | 48.82 | **74.75** | 59.07 |\n| PMC-LLaMa Inference | 32.94 | 90.14 | 90.59 | 90.37 | 13.35 | 52.17 | 14.53 | 2.94 | 61.87 | 37.81 | 46.79 | 59.89 | 37.94 | 45.45 |\n| MedAlpaca Inference | 36.44 | 69.95 | 70.29 | 70.12 | 26.29 | 57.67 | 56.51 | 35.71 | 44.69 | 31.16 | 27.85 | 52.51 | 49.16 | 51.64 |\n| CLinGen w/ KG | 77.71 | 94.30 | 89.09 | **91.62** | 60.12 | **79.92** | 50.20 | 41.26 | **62.46** | **64.08** | **63.26** | 70.96 | 69.66 | **70.30** |\n| CLinGen w/ LLM | **78.14** | **95.08** | 86.14 | 90.39 | **63.05** | 77.36 | 52.96 | 43.31 | 61.12 | 60.16 | 60.64 | **71.61** | 66.86 | 69.15 |\n\n\n>[1] Wu et al. \"Pmc-llama: Further finetuning llama on medical papers.\" arXiv preprint arXiv:2304.14454 (2023).\n>\n>[2] Han et al. \"MedAlpaca--An Open-Source Collection of Medical Conversational AI Models and Training Data.\" arXiv preprint arXiv:2304.08247 (2023).\n>\n>[3] Lehman et al. \"Do We Still Need Clinical Language Models?.\" CHIL 2023.\n\n*****\n> Q2: What are the limitations of your approach - what tasks is it limited to? How will it perform on more complex tasks such as descriptive QA (since most of the evaluation is on classification tasks)? Will it work on medical records?\n\nA: Thanks for the thoughtful feedback. We have answered this question in the general response for all reviewers. Please refer to the **Application to QA and EHR tasks** section of the general response for details."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8883/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700359768826,
                "cdate": 1700359768826,
                "tmdate": 1700360279933,
                "mdate": 1700360279933,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fdwNd8eJ2I",
                "forum": "PN9uaKA1nV",
                "replyto": "qtmWv8DhU7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8883/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8883/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Initial Response to Reviewer jB98 (Part 2)"
                    },
                    "comment": {
                        "value": "> Q3: Some of the tasks still have some issues in regards to entity coverage and it looks like generally the performance is low on these tasks. Are these common entities that are missed and not identified by LLM or KB? How will this looks like if a medical LLM was used for generation?\n\nA: We appreciate your observation. We acknowledge that there remains a disparity in entity coverage between our generated training data and the ground truth data specifically on the LitCovid and CHEMDNER datasets.  This disparity is primarily due to the extensive and diverse sources of entities present in these datasets. Specifically, the LitCovid corpus and the CHEMDNER corpus include 24,960 and 10,000 PubMed articles, respectively, while the BC5CDR dataset only covers 500 PubMed articles. As a result, we observe that there exist more diverse entities for the original LitCovid and CHEMDNER training data. The wide range of entities present in LitCovid and CHEMDNER can be challenging to be fully covered using KGs or querying LLMs.\n\nNevertheless, it's worth noting that despite this disparity with the ground truth, our approach **consistently outperforms or matches** baselines in both entity coverage and downstream model performance. We also attempted to utilize a medical LLM (MedAlpaca) for topic generation, but the results were not promising. We provide its entity coverage and downstream model performance results below:\n\n| Source of Topics| LitCovid | CHEMDNER |\n|:--:|:--:|:--:|\n| # unique entities per sample |||\n| KG | **0.307** | **0.402** |\n| LLM (ChatGPT) | 0.253 | 0.267 |\n| LLM (MedAlpaca) | 0.244 | 0.186 |\n\n|Models| LitCovid | CHEMDNER |\n|:--:|:--:|:--:|\n| PubMedBERT-Base | F1 | F1 |\n| ClinGen w/ KG | 58.01 | **56.94** |\n| ClinGen w/ LLM (ChatGPT) | **59.22** | 54.84 |\n| ClinGen w/ LLM (MedAlpaca) | 55.45 | 52.15 |\n| PubMedBERT-Large |||\n| ClinGen w/ KG | 55.81 | **55.56** |\n| ClinGen w/ LLM (ChatGPT) | **57.07** | 55.37 |\n| ClinGen w/ LLM (MedAlpaca) | 53.90 | 52.67 |\n\nThe experimental results show that the topics generated by a medical LLM do not cover a greater number of clinical entities compared to our approach, and they also exhibit lower downstream performance. This could be attributed to the medical LLMs having fewer parameters than ChatGPT, which results in limited instruction-following capabilities. Upon inspecting the topics generated by MedAlpaca, we observe a **lack of diversity** among the entities, which may also contribute to their inferior performance. We provide 20 examples of these generated entities below:\n\n```\n1. Acebutolol 2. Acetaminophen 3. Acetylcysteine 4. Acetylsalicylic acid 5. Aciclovir 6. Acid 7. Acid chloride 8. Acid anhydrous 9. Acid citrate 10. Acid nitrate 11. Acid phosphate 12. Acid sulfate 13. Acidic 14. Acidity 15. Acidity regulator 16. Acidity regulator citric acid 17. Acidity regulator phosphoric acid 18. Acidity regulator sulfuric acid 19. Acidity regulator trichloroacetic acid 20. Acidity regulator trifluoroacetic acid\n```\n\nOne potential strategy to address this issue could involve collecting more task-specific labeled/unlabeled data so that we have more information about target distribution. However, this approach could deviate from the true few-shot scenario that we are investigating in this study [4]. For this reason, we have not included this method in the current explorations. Investigating effective ways to collect and utilize such data represents a valuable direction for future research. \n\n\n>[4] Perez et al. \"True few-shot learning with language models.\" NeurIPS 2021.\n\n***\nThank you again for your review! We hope our responses can address your concerns. Please let us know if you have any further questions."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8883/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700359854904,
                "cdate": 1700359854904,
                "tmdate": 1700375944261,
                "mdate": 1700375944261,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]