[
    {
        "title": "Understanding Parameter Saliency via Extreme Value Theory"
    },
    {
        "review": {
            "id": "2KbWyghj2L",
            "forum": "3J7foqnJkA",
            "replyto": "3J7foqnJkA",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5615/Reviewer_HPzx"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5615/Reviewer_HPzx"
            ],
            "content": {
                "summary": {
                    "value": "This study falls into the field of parameter saliency in XAI. The draft proposes to apply the peaks-over-threshold (POT) technique on neural networks to locate salient parameters or filters. The POT is a solution in the Extreme Value Theory in statistics for anomaly detection."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This study explores a very important task in AI, explaining the black-box network. And it focuses on a very interesting topic, which parameters are salient or important in classification(misclassification)."
                },
                "weaknesses": {
                    "value": "Before discussing the weaknesses, I have to admit I have more expertise in CS, and my knowledge in statistics is limited. I might ask some naive questions and please correct me if I am wrong.\n\nThe structure of the draft can be better organized for a better readability, the current version is a little confusing. The overall idea is applying an existing method from statistics, POT, to locate salient parameters. The main baseline is (Levin 2021) which also studies the parameter saliency. However, the motivation of this study is not well introduced. In the introduction and the related work, a list of studies in XAI and statistics are sequentially displayed without discussing what kind of problems this draft can solve. For instance, Sec.2 \"Related work\", Interpretability, this paragraph is more like a basic tutorial, which is not directly related to this study, neither it is complete. The second paragraph in Sec2 is more about the CAM-based, which is not in the parameter space. I would suggest only discuss the most related parameter saliency, and POT related studies.\n\nPreliminary 3.1 is re-introducing the study (Levin), which is not necessary. The most important part is missing in that section, whats the limitation in the previous solution(Levin) and how this solution can solve that. I can grab some scatter information from the draft, previous study assumes the gradient follows a normal distribution, and this assumption may not hold, as discussed in Motivation Sec 4.1. I cannot see a clear demonstration that POT can solve this problem or I might miss this. Prior to the solution, this draft didnot showcase the problem of the normal distribution assumption. I know most CS scientist naively assume normal distribution, because it is simple yet effective. If this assumption is problematic, they can simple assume a more specific distribution. Could the normal distribution be \"simple\" enough for the study now? From the view of the solution, Appendix C, EVT normally add more assumptions to catch more distributions, which means the solution could be either not necessary (the normal assumption is enough) or limited (could the combined EVD catch everything?) I might miss something in the paper, proposition 1 and appendix B also are based on normal distribution, can I ask why a simple normal distribution can be representative enough in this problem raised?\n\nWithout a clear problem introduction, the proposed method is not clear and convincing in enough at this moment. And the results in Figs 3 and 4 also show that the difference is tiny, which echos the question, do we really need a more complicated distribution for this purpose now?\n\nTiny suggestion, I know Figs 3 and 4 have different components, but it is better to use the same colour and the same name of the same thing, e.g., POT vs Levin, or (proposed vs baseline). I searched around the paper, has the term \"baseline\" been explained?"
                },
                "questions": {
                    "value": "Please see the question listed above, the current draft randomly grabbing a technique from statistics to CS without introducing the need. Thus the clarity and novelty could be further improved before publishing."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5615/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5615/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5615/Reviewer_HPzx"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5615/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698772388758,
            "cdate": 1698772388758,
            "tmdate": 1700679026530,
            "mdate": 1700679026530,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZyqJe6hyC0",
                "forum": "3J7foqnJkA",
                "replyto": "2KbWyghj2L",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5615/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5615/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer HPzx"
                    },
                    "comment": {
                        "value": "We appreciate your careful considerations on improving the work!\n\n### Questions and Answers\n\n> Q.1 Do we really need a more complicated distribution for this purpose now?\n\nA.1 We are actually further relaxing the assumption of a normal distribution. Although EVT may seem to require more assumptions, it is known that extreme values of many standard distributions follow this distribution, and the normal distribution is no exception. It is known that the maximum value from the normal distribution converges to the Gumbel distribution. It also has been demonstrated that EVT can handle various distributions, including exponential and uniform distributions. Therefore, there is no implicit need to assume a normal distribution, making it applicable to a broader range of distributions.\n\n> Q.2  What's the limitation in the previous solution(Levin) and how this solution can solve that?\n\nA.2 As stated in Section 4.1, assuming a normal distribution itself can be considered a limitation. This is particularly true when dealing with heavy-tailed distributions, where values like mean and variance are significantly influenced by outliers, making them unreliable as proper statistical measures. In the existing method (Levin et al.), the use of z-score transformation may be strongly affected by this, potentially being unable to achieve accurate comparisons. Moreover, comparing values calculated from statistics of distributions that are not necessarily the same may inherit the characteristics of each distribution. For instance, by examining the tables in Section 5.3, it becomes evident that the existing method struggles to select filters from the early convolutional layers. This is attributed to the high magnitude of gradients and increased variance in the early layers. In contrast, the POT method transforms the discussion into a probabilistic context, enabling a unified comparison irrespective of the underlying distribution.\n\n\n> Q.3  I might miss something in the paper, proposition 1 and appendix B also are based on normal distribution, can I ask why a simple normal distribution can be representative enough in this problem raised?\n\nA.3 Proposition 1 and Appendix B pertain to the methodology of Levin et al. In their approach, they employ z-score transformation as depicted in Equation (2). While z-score transformation implicitly assumes a normal distribution, Proposition 1 asserts that under such an assumption, the ranking score function can be viewed as a probability. By introducing a probabilistic perspective in this manner, a new method utilizes extreme value theory to enable statistically meaningful comparisons.\n\n\n### Others\n- Thank you for pointing out the inconvenience of the legend and colors in the figure. We will fix it.\n- For the suggestion on the related work, parameter saliency is a new concept and related work is really scarce. Also, POT is rarely used in the context of machine learning. It is rather used in fields like hydrology, finance, and environmental science. So we consider XAI related works better fit the section."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5615/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700204883390,
                "cdate": 1700204883390,
                "tmdate": 1700204883390,
                "mdate": 1700204883390,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FWnm2YUNBR",
                "forum": "3J7foqnJkA",
                "replyto": "ZyqJe6hyC0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5615/Reviewer_HPzx"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5615/Reviewer_HPzx"
                ],
                "content": {
                    "title": {
                        "value": "response"
                    },
                    "comment": {
                        "value": "I would like to thank the authors for the further explanation, which answers my main questions regarding the use case of EVT. The explanation of the limitation on normal distribution is clear to me now and the proposed method is based on a looser assumption. I would raise my rating."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5615/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700678995351,
                "cdate": 1700678995351,
                "tmdate": 1700678995351,
                "mdate": 1700678995351,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "BlX0Pvns26",
            "forum": "3J7foqnJkA",
            "replyto": "3J7foqnJkA",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5615/Reviewer_nAUC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5615/Reviewer_nAUC"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigated the parameter saliency for a CNN through the lens of EVT and provided POT-saliency.\nThis paper also analyzed the property of the original and POT-saliency ranking methods and found that the\nPOT-saliency ranking method chooses from a wide range of convolutional layers while the baseline\nmethod has a bias to choose from the later part of the layers."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "originality - The proposed concept is interesting. The POT-salience method is expected to introduce semantic features to the framework POT and hence improve the classification performance. \n\nquality - The paper presents theoretical and experimental results to demonstrate the proposed algorithm. Both theory and experiments are comprehensive. \n\nclarity - The experimental section clearly shows that the proposed POT-salience algorithm performs better than the other methods in different settings. \n\nsignificance - Upon the justified theory, the proposed method will have strong impacts on the standard CNN architecture."
                },
                "weaknesses": {
                    "value": "originality - Very confusing explanations on the new proposal in this paper. For example, it is not clear how to link Theorem 1 in Eqs. 3 and 4 with the POT method?  More detailed discussion is used to demonstrate the novelty. \n\nquality - The entire paper reads imbalanced due to the heavy weights on the theoretical justification.  The proposed algorithm lacks a full scale algorithmic discussion, including parameter update and initialization.\n\nclarity - The current form of the paper is confusing in terms of the theoretical proof. There is no clear algorithmic flowchart and discussion. The experimental results are partial and lacks comparisons against different POT variants. \n\nsignificance - The outcomes of the experiments are not significant, compared against those of the other state of the arts."
                },
                "questions": {
                    "value": "1. How does the proposed POT algorithm work? A flowchart may be used to help the discussion.\n2. More comparison experiments need to be conducted but the current version is weak in terms of experimental work.\n3. How will the parameters in the proposed POT system affect the system performance?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5615/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698966474338,
            "cdate": 1698966474338,
            "tmdate": 1699636580319,
            "mdate": 1699636580319,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JmQ06YRGu1",
                "forum": "3J7foqnJkA",
                "replyto": "BlX0Pvns26",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5615/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5615/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer nAUC"
                    },
                    "comment": {
                        "value": "We appreciate your thoughtful feedback, which has been invaluable in improving the quality of our work.\n\n> Q.1 How does the proposed POT algorithm work? A flowchart may be used to help the discussion. ( how to link Theorem 1 in Eqs. 3 and 4 with the POT method?)\n\nA.1 Thank you for your suggestion. We have added a flowchart illustrating the operation of the POT algorithm in Figure 6 of the appendix. If you have any uncertainties, please feel free to inquire with us again. \n\nRegarding the relationship between Theorem 1 and the POT method, Theorem 1 means that the more you move towards the tail of the probability distribution, the better it can be approximated by the Generalized Pareto Distribution (GPD). The POT method is a technique for estimating the parameters of this GPD, utilizing extreme values exceeding a sufficiently large threshold for maximum likelihood estimation.\n\n> Q.2 More comparison experiments need to be conducted but the current version is weak in terms of experimental work.\n\nA.2 We will add some comparison experiments within the next few days, we would appreciate it if you could wait until then.\n\n> Q.3 How will the parameters in the proposed POT system affect the system performance?\n\nA.3 One critical parameter to consider for POT is the threshold. Generally, if the threshold is set too high, the amount of data available for estimating GPD parameters becomes limited, resulting in increased variance. On the other hand, if the threshold is set too low, the approximation accuracy of GPD tends to deteriorate. \n\nIn terms of the POT method, it is worth noting that since the algorithm generates rankings for filters that exceed the threshold, the number of filters included in the ranking is influenced by the choice of the threshold. This is the largest difference between POT method and Levin et al.'s method because the latter one always gives us the ranking of the size of the total filter number. \n\nWe did an experiment on ImageNet dataset by setting the threshold to 95-th percentile of gradient data, but it did not show much difference. This can be because the ImageNet dataset is very large and the threshold has a little impact on maximum likelihood estimation of POT parameters. \n\n> Q.4  The outcomes of the experiments are not significant, compared against those of the other state of the arts.\n\nA.4 We claim that the primary objective is to comprehend the existing research (Levin et al.) from the perspective of statistical anomaly as the title suggests. Although we compare several approaches in the experiments, parameter saliency is a concept proposed recently and there is a \"knowledge gap in terms of understanding why parameter saliency ranking can find the filters inducing misidentification\" as we stated in the introduction. Therefore, we do not consider it as weakness."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5615/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700202704438,
                "cdate": 1700202704438,
                "tmdate": 1700202704438,
                "mdate": 1700202704438,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "v5tQtcpOMS",
            "forum": "3J7foqnJkA",
            "replyto": "3J7foqnJkA",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5615/Reviewer_8wd7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5615/Reviewer_8wd7"
            ],
            "content": {
                "summary": {
                    "value": "The paper investigates the topic of parameter saliency to understand misclassifications in neural networks. Unlike some prior works which focus on input saliency maps, parameter saliency is shown to be helpful to correct for misclassifications. Building over prior work, the paper formulates the ranking of salient filters through connections with statistical anomaly detection and extreme value theory. Empirical experiments show that the approach leads to plausible conclusions."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- As deep learning finds more and more applications in daily-life, interpretability is getting more important. The idea of focusing on parameter saliency is an interesting approach towards interpretability and model surgery. \n- I am not an expert in the topic, but the paper is well written for the most part. Key ideas and intuitions are well explained. \n- The approach is evaluated on multiple architectures and datasets."
                },
                "weaknesses": {
                    "value": "- 5.1.2 : \"We performed one step fine-tuning .. \" -> Is the finetuning and validation being done on the same dataset ? \n- The interpretations in Figure 4 are not clear, especially the conv5_x curve and its relation to the proposed approach. \n- I think it will be more intuitive to think of %improvement in downstream performance rather than %corrected samples. \n- How do you differentiate between label errors and misclassification ? \n- A lot of things seem to have changed when moving to the domain adaptation experiments : architecture, dataset, model size, pretraining. Instead, it would be beneficial to show results on domain adaptation datasets like ImageNet-C, DomainNet etc. \n- I am not too convinced with the one-step finetuning process apart from being \"easy\" to do. \n- 4.3 : \"anomalous behavior of filters.. is a rare event\" - Can the authors give more insight into when would this hold ? Perhaps as a function of class difficulty, model size, dataset size."
                },
                "questions": {
                    "value": "Please refer to questions in the weaknesses section. \n\n[Minor] Writing suggestions:\n- Fix tense : Abstract, \".. has efficiently corrected .. \" \n- Section 1 : \"model's decision\" ^making \"process\" ? \n- Section 2 : \"importance\" -> \"Importance\"\n- Reword title of Section 3.2\n- Section 5 : \"FOr the pruni .. \""
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5615/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5615/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5615/Reviewer_8wd7"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5615/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699108551814,
            "cdate": 1699108551814,
            "tmdate": 1700589392239,
            "mdate": 1700589392239,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8HsFcHxaVc",
                "forum": "3J7foqnJkA",
                "replyto": "v5tQtcpOMS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5615/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5615/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 8wd7"
                    },
                    "comment": {
                        "value": "Thank you sincerely for your thoughtful and constructive feedback on our paper.\n\n### Questions and Answers\n>Q.1 Is the finetuning and validation being done on the same dataset ?\n\nA.1 In general, the dataset used for finetuning is distinct from the validation dataset. When using a pre-trained model provided by deep learning frameworks, there is no access to the actual validation set during training. Also ImageNet officially offers two datasets, \u201ctraining set\u201d and \u201cvalidation set\u201d, where people commonly split \u201ctraining set\u201d for training and validation. In our work and existing work(Levin et al.), \u201cvalidation set\u201d is used for calculating the statistics and performing one-step finetuning. \n\n\n>Q.2 The interpretations in Figure 4 are not clear, especially the conv5_x curve and its relation to the proposed approach.\n\nA.2 There is no specific relationship between conv5_x and POT. As described in section 5.1.3, Kirichenko et al. reported good performance when finetuning only the final layer. Additionally, in Tables 1 and 2 of Section 5.3, it can be observed that the approach of Levin et al. is heavily biased towards the latter convolutional layers. The conv5_x method is developed based on these observations. The conv5_x curve in Figure 4 demonstrates that the model performance improves by only finetuning the convolutional filters in the latter layers in descending order of gradient magnitude. This raises the question of whether it is necessary to modify feature extractor in the earlier layers when dealing with scenes requiring different features due to domain shift.\n\n>Q.3 I think it will be more intuitive to think of %improvement in downstream performance rather than %corrected samples.\n\nA.3 Our experimental metric aligns with the one used in the existing study (Levin et al). The objective of Levin et al.'s research is to identify which part of the model parameters is responsible for misclassifications. Investigating %corrected samples is effective because if correcting a limited number of filters through one-step finetuning leads to accurate classification, it validates the saliency of those filters.\n\n>Q.4 How do you differentiate between label errors and misclassification ?\n\nA.4 Our study is predicated on the occurrence of misclassifications. The primary objective is to comprehend the existing research (Levin et al.) from the perspective of statistical anomaly. The experiments and problem settings are conducted based on this research. Consequently, the analysis is carried out in an ideal scenario, assuming there are no factors such as label errors.\n\n>Q.5 I am not too convinced with the one-step finetuning process apart from being \"easy\" to do.\n\nA.5 This is a good point. We again note that one-step finetuning employs the same experimental methodology as the existing study (Levin et al.) and is utilized for evaluation.  We would like to examine changing the salient parameters can positively affect the classification result. Also, since the statistical measures, such as the average magnitude of gradients, would change with model parameters, conducting multiple steps of finetuning would be a more complex way of evaluation. Thus, one-step finetuning is used.\n\n>Q.6. the anomalous behavior of filters causing misclassification can also be considered a rare event\" - Can the authors give more insight into when would this hold ? Perhaps as a function of class difficulty, model size, dataset size.\n\nA.6 In the context of gradients, the simplest explanation can be derived. As illustrated in Figure 1, there is a notably high frequency of instances where the magnitude of the gradient is nearly zero. This phenomenon occurs when the deep learning model correctly classifies the input. In other words, as the model's performance improves, instances where the gradient magnitude is significantly larger than zero become increasingly rare. Therefore, it is hypothesized that this becomes more achievable with larger dataset sizes and model sizes.\n\n### Others\n- For experiments on domain adaptation datasets, we will add them within the next few days, so we would appreciate it if you could wait until then.\n- Thank you for writing suggestions. We addressed them and updated our draft."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5615/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700201360753,
                "cdate": 1700201360753,
                "tmdate": 1700201360753,
                "mdate": 1700201360753,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8w7rgleGrS",
                "forum": "3J7foqnJkA",
                "replyto": "8HsFcHxaVc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5615/Reviewer_8wd7"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5615/Reviewer_8wd7"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the comments"
                    },
                    "comment": {
                        "value": "Thanks for the comments. The rebuttal helps address some of my concerns. \n- Q5 : I am not fully convinced about this yet. While I do understand the paper over which the paper builds upon uses this approach, this doesn't seem to be set in stone. \n- Looking forward to the domain adaptation experiments."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5615/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700424016251,
                "cdate": 1700424016251,
                "tmdate": 1700424016251,
                "mdate": 1700424016251,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6yeo0264Q2",
                "forum": "3J7foqnJkA",
                "replyto": "ZbAfywgo40",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5615/Reviewer_8wd7"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5615/Reviewer_8wd7"
                ],
                "content": {
                    "title": {
                        "value": "Thanks!"
                    },
                    "comment": {
                        "value": "Thanks for the comment. The responses are satisfactory. The thanks for the additional experiments too, I think these will make the paper stronger. \nI am not too convinced on why you don't see expected trends with the ImageNet-C experiments though. Perhaps something that could be investigated further at a later point. \nI have updated my score (5->6, confidence of 2)"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5615/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700589367057,
                "cdate": 1700589367057,
                "tmdate": 1700589367057,
                "mdate": 1700589367057,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]