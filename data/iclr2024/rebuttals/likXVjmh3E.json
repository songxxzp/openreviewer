[
    {
        "title": "The Expressive Power of Low-Rank Adaptation"
    },
    {
        "review": {
            "id": "UgAr4SkjsO",
            "forum": "likXVjmh3E",
            "replyto": "likXVjmh3E",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2990/Reviewer_SRgL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2990/Reviewer_SRgL"
            ],
            "content": {
                "summary": {
                    "value": "The authors conduct theoretical analysis for LoRA, a popular PEFT method for LLMs. For linear models with LoRA,  the \u201ceffective rank\u201d is the sum of these low ranks. For multi-layer ReLU FNN, the effective expressive power of LoRA is nearly optimal up to a constant factor of 2. For transformer networks, adding LoRA adapters primarily to the self-attention layers enables the adapted model to exactly represent the target model."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "+ The first theoretical analysis to understand the expressive power of LoRA. The first known results on the expressive power of LoRA\n+ Linear models, FFNs, and transforms with LoRA are analyzed, providing comprehensive theoretical results.\n+ Empirical results matches the rank requirements in theoretical analysis."
                },
                "weaknesses": {
                    "value": "+ A notation table would help understand all the notations, since the paper is mostly about theoretical proof."
                },
                "questions": {
                    "value": "In section 2, why a L-layer (instead of one-layer) linear model is considered, which is still a linear model?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2990/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698818338604,
            "cdate": 1698818338604,
            "tmdate": 1699636243921,
            "mdate": 1699636243921,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "j6F4ePFCPw",
                "forum": "likXVjmh3E",
                "replyto": "UgAr4SkjsO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2990/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2990/Authors"
                ],
                "content": {
                    "title": {
                        "value": "To Reviewer SRgL"
                    },
                    "comment": {
                        "value": "We sincerely thank the reviewer for acknowledging the theoretical significance and appreciating the empirical results of our paper. We are pleased to inform you that we have carefully addressed each of your concerns, as elaborated below. \n\n---\n\n> Q1: A notation table would help understand all the notations since the paper is mostly about theoretical proof.\n\nThanks for the suggestion. Due to the page limit, We have summarized a list of the notations in Appendix A. \n\n> Q2: In section 2, why a L-layer (instead of one-layer) linear model is considered, which is still a linear model?\n\nCorrect. In our paper, we employ *deep linear models* (L-layer linear model) as a preliminary model, which serves as a foundation for extending our results to nonlinear models (i.e., FNN and TFN). Studying this toy model is a common technique in theoretical deep learning research, which offers valuable insights into deep nonlinear models, and has been employed in many notable studies, including those by `Saxe et al., 2014`, `Kawaguchi, 2016`, `Lu & Kawaguchi et al., 2017`, `Hardt & Ma`, and `Laurent & Brecht, 2018`.\n\n---\n\n**Final Note:** We want to thank you again for all the questions and comments you have provided. If there are any remaining questions, please do not hesitate to let us know. If our responses have resolved your concerns, we kindly request you to consider increasing your score and championing our paper.\n\n*References*\n\n* Saxe, Andrew M., James L. McClelland, and Surya Ganguli. Exact solutions to the nonlinear dynamics of learning in deep linear neural networks. ICLR, 2014.\n* Kawaguchi, Kenji. Deep learning without poor local minima. NeurIPS, 2016.\n* Lu, Haihao, and Kenji Kawaguchi. Depth creates no bad local minima. arXiv, 2017.\n* Hardt, Moritz, and Tengyu Ma. Identity matters in deep learning. ICLR, 2017.\n* Laurent, Thomas, and James Brecht. Deep linear networks with arbitrary loss: All local minima are global. ICML, 2018."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700535259012,
                "cdate": 1700535259012,
                "tmdate": 1700535259012,
                "mdate": 1700535259012,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "BL4DrjFLmn",
            "forum": "likXVjmh3E",
            "replyto": "likXVjmh3E",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2990/Reviewer_U2Yh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2990/Reviewer_U2Yh"
            ],
            "content": {
                "summary": {
                    "value": "The paper provides an initial theoretical exploration of the popular parameter-efficient finetuning method LoRA. It proves for fully connected models, LoRA should be sufficient to finetune any base model for a smaller target model with a certain LoRA rank (threshold). They further provide approximation errors for the case when the rank is smaller than the threshold."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "This is a theoretically strong paper, studying a very timely topic. While empirically, LoRA has been shown to do surprisingly well, a theoretical explanation for why has been missing. This paper is a good starting point in understanding how/why/when LoRA works."
                },
                "weaknesses": {
                    "value": "While it is okay to not have them in this paper, I think it would be interesting to study other effects of LoRA theoretically. For example, how does LoRA affect generalization? What can we say about how fast LoRA can converge even if the target model can eventually be found by LoRA exactly."
                },
                "questions": {
                    "value": "See above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2990/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698821371753,
            "cdate": 1698821371753,
            "tmdate": 1699636243793,
            "mdate": 1699636243793,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "uXlUqnWeeX",
                "forum": "likXVjmh3E",
                "replyto": "BL4DrjFLmn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2990/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2990/Authors"
                ],
                "content": {
                    "title": {
                        "value": "To Reviewer U2Yh"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the encouraging feedback, especially for recognizing the theoretical contribution, timeliness, and importance of our paper in illuminating the empirical success of LoRA. Our response is detailed below.\n\n---\n\n> Q1: While it is okay to not have them in this paper, I think it would be interesting to study other effects of LoRA theoretically. For example, how does LoRA affect generalization? What can we say about how fast LoRA can converge even if the target model can eventually be found by LoRA exactly.\n\nWe agree with the reviewer that it is an interesting research topic to explore the generalization and optimization problems of LoRA theoretically. While an in-depth analysis of these properties is beyond the scope of this paper, as the reviewer acknowledges, we have included additional simulation results and discussion based on your comments that provide initial insight into these issues. `Please find our responses in the general comment to all reviewers and AC, specifically under \"(Major Update #2) Illuminating the Optimization and Generalization Aspects of LoRA\"`. \n\n\n---\n**Final Note:** We are excited that you consider our work both timely and theoretically strong. We plan to incorporate these responses into our updated version. Thank you once again for your insightful comments and for your encouraging feedback!"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700534985979,
                "cdate": 1700534985979,
                "tmdate": 1700535209178,
                "mdate": 1700535209178,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fQVHrRH7xw",
                "forum": "likXVjmh3E",
                "replyto": "uXlUqnWeeX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2990/Reviewer_U2Yh"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2990/Reviewer_U2Yh"
                ],
                "content": {
                    "title": {
                        "value": "response to the rebuttal"
                    },
                    "comment": {
                        "value": "I thank the authors for their response. I will keep my original score."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700626720019,
                "cdate": 1700626720019,
                "tmdate": 1700626720019,
                "mdate": 1700626720019,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "haxSKhZ6Ru",
            "forum": "likXVjmh3E",
            "replyto": "likXVjmh3E",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2990/Reviewer_F9Xm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2990/Reviewer_F9Xm"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a theoretical analysis of Low-Rank Adaptation (LoRA), a technique for efficiently fine-tuning pre-trained models, including large language and diffusion models. It establishes that LoRA can effectively adapt a fully connected neural network to represent a smaller target model if the LoRA-rank is sufficiently high. Specifically, the required rank is at least the product of the model's width and depth. For Transformer networks, the study demonstrates that a model can be fine-tuned to match a target of the same size using LoRA adapters of a particular rank. These theoretical assertions are underpinned by practical numerical experiments.\n\nThe paper concludes by highlighting the importance of LoRA's rank and the pre-trained model's depth in achieving close approximation to the target model. Despite these advances, it points out that the construction method for LoRA adapters might not be fully optimized and that better parameter efficiency could be achieved with more refined techniques. The paper also calls for additional research to measure approximation errors when LoRA-rank is not ideal, especially in the context of Transformer networks, and to further explore the application of LoRA in more complex network architectures."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The study conducts a thorough analysis of the expressive capabilities of LoRA, underpinned by a set of well-founded assumptions.\n\n- The findings from this research offer a theoretical foundation for applying LoRA to a diverse range of models, including Transformers and Diffusion models, and furnish insights on how to select hyper-parameters for designing LoRA effectively.\n\n- The insights provided by this work can streamline the design process for LoRA, especially when the depth and width of the model in question are specified."
                },
                "weaknesses": {
                    "value": "The experimental approach raises significant concerns. Given the widespread application of LoRA to various large language models (LLMs), such as LLaMA, there's an opportunity for the authors to substantiate their findings using models tasked with different challenges. Considering the availability of various model sizes in LLaMA and the comprehensive range of results provided by the original LoRA study, a comparison between the proposed theoretical analysis and empirical observations of LoRA would be insightful.\n\nThe use of Mean Squared Error (MSE) as a metric in the authors' presentation is questionable. Performance scores for LLMs typically exhibit a weak correlation with perplexity (PPL) or loss values. Therefore, relying solely on MSE for validation, particularly in the context of generative AI, may not adequately address the nuances of expressive capability. A multifaceted evaluation, including different performance metrics, would offer a more robust validation of the claims made in this work.\n\nAdditionally, it is acknowledged within the community that even very low ranks (such as 4, 2, or even 1) can yield satisfactory fine-tuning results. Readers would benefit from an exploration into how low-rank adjustments are able to achieve effective fine-tuning. The experimental outcomes presented in the paper currently do not offer practical insights for practitioners working with LoRA-based tuning, who would be looking for such guidance.\n\nThe authors are urged to establish a clearer connection between their theoretical discoveries and the empirical results previously reported for LoRA. Doing so could significantly streamline the hyper-parameter selection process for LoRA, reducing the effort required to fine-tune models effectively."
                },
                "questions": {
                    "value": "Please refer to Weakness comments"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2990/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2990/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2990/Reviewer_F9Xm"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2990/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698926213926,
            "cdate": 1698926213926,
            "tmdate": 1700563699310,
            "mdate": 1700563699310,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lQNNDRCcbT",
                "forum": "likXVjmh3E",
                "replyto": "haxSKhZ6Ru",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2990/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2990/Authors"
                ],
                "content": {
                    "title": {
                        "value": "To Reviewer F9Xm"
                    },
                    "comment": {
                        "value": "**We wish to clarify that our primary objective is to understand the effectiveness of LoRA via theory, rather than experiments.** We thank the reviewer for recognizing the thoroughness of our theoretical analysis and their contribution to the empirical understanding of LoRA. We believe this recognition affirms the significant theoretical contribution of our paper. While we acknowledge that not all of our findings may be directly applicable to practical settings, the theoretical insights provided by our work form a crucial foundation for future practical applications.\n\nIn light of the feedback, and although it was beyond the original scope of our work, we have conducted additional empirical studies and are excited to share these findings with you! If there are any remaining questions, please do not hesitate to let us know. If all of your concerns have been fully resolved, we kindly request you to consider increasing your score.\n\n---\n\n> Q1: Given the widespread application of LoRA to various large language models (LLMs), there's an opportunity for the authors to substantiate their findings using models tasked with different challenges.\n\nAs per your question, we have conducted additional experiments using LLMs such as RoBERTa-base and RoBERTa-large on GLUE benchmark to substantiate our theoretical results. `Please find our response in general comments to all reviewers and AC, specifically the first two findings under major update #1.`\n\n> Q2: A multifaceted evaluation, including different performance metrics, would offer a more robust validation of the claims made in this work.\n\nOur real-world experiments conducted on the GLUE benchmark include various metrics such as overall (matched and mismatched) accuracy for MNLI, Matthew's correlation for CoLA, Pearson correlation for STS-B, and accuracy for other tasks.\n\nFor our synthetic simulations, we have expanded the scope to include multi-class classifications. We quantize the results and optimize cross-entropy rather than MSE, and subsequently report the test accuracy.\n\nAs shown in Figure 5b (https://hackmd.io/_uploads/BkedJmrNT.png), consistent with our theoretical results, our construction achieves 100% accuracy when $R \\geq 8$. The performance of gradient update is also similar to our observation when MSE is employed as the metric, particularly when MSE is plotted on a logarithmic scale (Figure 4: https://hackmd.io/_uploads/HksV_SBNp.png). This observation echoes the findings of `Hui & Belkin et al. (2021)`, which indicate that optimizing MSE is fundamentally equivalent to optimizing cross-entropy.\n\nThe suboptimal performance of gradient update method in this simulation suggests that, despite LoRA's current impressive performance in practical applications, there is potential for further refinement. \n\n> Q3: Additionally, it is acknowledged within the community that even very low ranks (such as 4, 2, or even 1) can yield satisfactory fine-tuning results. Readers would benefit from an exploration into how low-rank adjustments are able to achieve effective fine-tuning.\n\nWe believe that our current results indeed explain when and why low-rank adjustments can yield satisfactory performance. We further elucidate this with additional empirical insights.\n\n1. **Theoretical Understanding**: Our theoretical findings demonstrate that larger models requires lower ranks for effective fine-tuning. This insight is particularly relevant when employing large language models or stable diffusion models.\n\n2. **New Real-World Experiments**: We have also added new experiments comparing RoBERTa-base and RoBERTa-large, `as detailed in the first two findings of our summary in major update #1 in general comments to AC and all reviewers.` These experiments further validate our theory, which suggests that larger models require smaller ranks for effective fine-tuning.\n\n\n> Q4: The authors are urged to establish a clearer connection between their theoretical discoveries and the empirical results previously reported for LoRA. Doing so could significantly streamline the hyper-parameter selection process for LoRA, reducing the effort required to fine-tune models effectively.\n\nIn response to your insightful suggestion to better integrate our theoretical findings with empirical observations, we have summarized both our theoretical and corresponding (additional) empirical results `in our summary of major update #1 in general comments to all reviewers and AC`. This enhanced and integrated discussion has been thoughtfully incorporated into the final version of our paper (Sec. H).\n\n---\n\n**Final Note**: Thank you for your detailed comments. We are excited that you found the theoretical study of our paper to be thorough. If there are any remaining questions, please do not hesitate to let us know. If our responses have resolved your concerns, we kindly request you to consider increasing your score and support the acceptance of our paper."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700534914938,
                "cdate": 1700534914938,
                "tmdate": 1700535326327,
                "mdate": 1700535326327,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ST45IVaXPW",
                "forum": "likXVjmh3E",
                "replyto": "lQNNDRCcbT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2990/Reviewer_F9Xm"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2990/Reviewer_F9Xm"
                ],
                "content": {
                    "title": {
                        "value": "Response from Reviewer F9Xm"
                    },
                    "comment": {
                        "value": "Thank you for your detailed comments and the addition of further experiments. I appreciate the efforts made to address my major concerns, particularly through the comprehensive experimental results provided. Based on these improvements, I have decided to raise my evaluation score."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700563683768,
                "cdate": 1700563683768,
                "tmdate": 1700563683768,
                "mdate": 1700563683768,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "xVnxK4MQJK",
            "forum": "likXVjmh3E",
            "replyto": "likXVjmh3E",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2990/Reviewer_YxPR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2990/Reviewer_YxPR"
            ],
            "content": {
                "summary": {
                    "value": "While conventional fine-tuning updates all model parameters for specialized tasks, full weight updating would be prohibitive for large language models (LLMs). Many methods were proposed to selectively update smaller parameter subsets or introduce lightweight adapters, significantly reducing computational and storage costs. The dominant method in this context is Low-Rank Adaptation (LoRA), which employs low-rank adapters to pre-trained weight matrices. Empirical evidence shows that LoRA can match or surpass the performance of full fine-tuning. However, there is a lack of theoretical understanding regarding how LoRA works, including questions about the minimum rank of adapters required for effective adaptation and how model architecture influences this threshold. Addressing these theoretical questions will provide valuable insights into the effectiveness and principles behind LoRA's adaptation of LLMs."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This paper claims that they are the first to study the expressive power of Low-Rank Adaptation (LoRA) for different model architectures. So, if this is true (I do not have sufficient knowledge to check), the novel of this paper is significant. \n\n2.  Their theoretical results align well with the recent advances of LoRA on LLMs. \n\n3.  Not only FNN but TFN is explored with the both theoretical and emperical study."
                },
                "weaknesses": {
                    "value": "(1) From Figure 1, I can see that LoRA of FNN performs on par with gradient update, whereas LoRA of TFNs significantly outperform gradient updates. Could the author explain this performance difference?\n\n(2) It is impressive that LoRA with rank=1 can match the performance of gradient update in Figure 3. Does this mean the gradient update does not actually learn well?"
                },
                "questions": {
                    "value": "Please see the above weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2990/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699011597658,
            "cdate": 1699011597658,
            "tmdate": 1699636243643,
            "mdate": 1699636243643,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "QiCgpi4SB4",
                "forum": "likXVjmh3E",
                "replyto": "xVnxK4MQJK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2990/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2990/Authors"
                ],
                "content": {
                    "title": {
                        "value": "To Reviewer YxPR"
                    },
                    "comment": {
                        "value": "We sincerely appreciate your recognition of the novelty of our paper, its consistency with recent advances of LoRA, and the comprehensiveness of our theoretical and empirical results. Your concerns are addressed below. If our responses have resolved your concerns, we kindly request you to consider increasing your score and championing our paper.\n\n---\n\n> Q1: From Figure 1, I can see that LoRA of FNN performs on par with gradient update, whereas LoRA of TFNs significantly outperform gradient updates. Could the author explain this performance difference?\n\nIn Fig. 1, we plot MSE, while in Fig. 5, we plot log(MSE). Sorry for the confusion, and we will make this clear in the revision. We have added Fig. 4 (https://hackmd.io/_uploads/Skgt22SV6.png) to report performances of FNN in log(MSE), and we observe that gradient update underperforms our construction on both FNN and TFN.\n\n\n> Q2: It is impressive that LoRA with rank=1 can match the performance of gradient update in Figure 3 (which is Figure 5 in the updated version). Does this mean the gradient update does not actually learn well?\n\nThe reviewer is correct that gradient update might fail to find the optimal LoRA parameters in the TFN cases. This underperformance of gradient update method, especially compared to our LoRA adapter construction, suggests that LoRA's current effectiveness might still have room for further improvement. A more sophisticated implementation could potentially yield even better results, indicating a promising direction for future exploration and development in this area.\n\n---\n\n**Final Note:** We are excited that you find our work novel and appreciate our theoreical study and the corresponding empirical validation. If you have any further questions, please do not hesitate to let us know. If our responses have resolved your concerns, we kindly request you to consider increasing your score and championing our paper."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700534703542,
                "cdate": 1700534703542,
                "tmdate": 1700534703542,
                "mdate": 1700534703542,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]