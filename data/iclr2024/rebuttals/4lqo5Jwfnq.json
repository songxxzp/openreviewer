[
    {
        "title": "Class-Incremental Learning with Parameter-Efficient Cross-Task Prompts"
    },
    {
        "review": {
            "id": "uxRRfyvWMf",
            "forum": "4lqo5Jwfnq",
            "replyto": "4lqo5Jwfnq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2478/Reviewer_9kbr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2478/Reviewer_9kbr"
            ],
            "content": {
                "summary": {
                    "value": "In this work, the author introduces the use of a parameter-efficient cross-task prompt for pre-trained models to tackle the challenges of class incremental learning in a rehearsal-free and memory-constrained manner. Specifically, unlike memory-based incremental learning methods, this approach obviates the need to retrain old samples. In comparison to the previous \"Prompt-fixed\" and \"Prompt-extending\" methods, the author proposes a more parameter-efficient manner of extracting relevant prompts."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The foundation of this idea appears solid. The parameter efficient way seems memory friendly than the previous methods.\n\nTo validate this approach, it was tested across seven popular benchmarks, yielding promising results in some datasets."
                },
                "weaknesses": {
                    "value": "However, I have several concerns:\n\n1. Data Leakage from Pre-trained Model: The model has been pre-trained on ImageNet21k, and subsequently, the author employs a subset of this, ImageNet, for the incremental learning task. This presents a potential data leakage concern, as the pre-trained model has already been exposed to the entirety of ImageNet during its initial training. This practice may inadvertently violate the foundational principles of class incremental learning.\n\n2. Not being directly immersed in prompt learning, I'm concerned that the prompts might inadvertently leak information or task-id specifics to the broader model, especially when compared with prior class incremental learning methodologies, which only obtains the task id based on model itself, no prompts are used.\n\n3. Reproducibility of experiments is crucial. The primary results in Table 1 seem to have been conducted only once, without any mention of variance or average performance.\n\n4. While the number of prompts is detailed in the table, there's a noticeable lack of information regarding model size, computational complexity, and the execution time spent on distinct model components.\n\n5. The paper neglects the discussion of certain challenging tasks. Managing tasks in larger scales, such as when the number of tasks is 50 or 100, can be formidable. I'm curious about the performance of this method under such rigorous testing scenarios.\n\n6. A missing baseline: Given that the pre-trained model might already contain a wealth of information or representations, including those of the dataset under testing, there's a potential risk of the model being over-fitted to the dataset in question. I strongly recommend that the author includes performance metrics without the prompt, thereby delineating the actual gains derived from this approach."
                },
                "questions": {
                    "value": "Regarding the weaknesses, my main concern is data leakage from the pre-trained model itself. If the author can address this concern during the rebuttals, I will increase the scores accordingly."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2478/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2478/Reviewer_9kbr",
                        "ICLR.cc/2024/Conference/Submission2478/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2478/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698101850101,
            "cdate": 1698101850101,
            "tmdate": 1700677784233,
            "mdate": 1700677784233,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "w8uKfDmSmn",
                "forum": "4lqo5Jwfnq",
                "replyto": "uxRRfyvWMf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2478/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2478/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 9kbr"
                    },
                    "comment": {
                        "value": "Thank you for your detailed review of our paper and constructive feedback! We have revised our paper and addressed your concerns. We summarize below the changes we made.\n\n\n\nQ1. \"A potential data leakage concern: as the pre-trained model has already been exposed to ImageNet21k during its initial training, which may violate the foundational principles of class incremental learning. Therefore, A missing baseline: I strongly recommend that the author includes performance metrics without the prompt, thereby delineating the actual gains derived from this approach.\"\n\nA1: *PTM-based CIL methods* do exhibit data leakage in ***Usual CIL benchmarks***, as shown in [4]. However, [4] also introduced **four new benchmarks where Data leakage phenomenon does not exist**. Notably, [4] introduces a novel baseline for *PTM-based CIL methods* called **SimpleCIL**. **SimpleCIL** performs directly on incremental tasks **without any prompting or fine-tuning**. The corresponding results can be found in the **third row** of the tables below.\n\n| ViT-B/16-IN21K   | CIFAR B0Inc10 |           | CUB B0Inc10 |           | IN-R B0Inc10 |           |\n| ---------------- | ------------- | --------- | ----------- | --------- | ------------ | --------- |\n|                  | $A$           | $A_{B}$   | $A$         | $A_B$     | $A$          | $A_B$     |\n| L2P              | 88.34         | 84.57     | 66.69       | 56.01     | 73.82        | 67.13     |\n| DualPrompt       | 89.69         | 84.14     | 74.84       | 60.84     | 70.32        | 64.80     |\n| **SimpleCIL**    | **87.13**     | **81.26** | **90.96**   | **85.16** | **61.99**    | **54.55** |\n| ADAM-Finetune    | 87.12         | 81.23     | 90.98       | 85.58     | 71.29        | 63.35     |\n| ADAM-VPT-Shallow | 90.25         | 85.04     | 90.70       | 85.54     | 70.19        | 62.75     |\n| ADAM-SSF         | 90.61         | 85.14     | 90.67       | 85.37     | 73.07        | 65.00     |\n| ADAM-Adapter     | 92.24         | 87.49     | 90.96       | 85.11     | 75.08        | 67.20     |\n| ADAM-VPT-Deep    | 90.40         | 84.62     | 89.48       | 83.42     | 74.46        | 66.47     |\n| PECTP(Ours)      | 92.53         | 87.73     | 91.01       | 85.11     | 77.42        | 70.01     |\n\n\n\n| ViT-B/16-IN21K   | IN-A B0Inc10 |           | Obj B0Inc10 |           | Omni B0Inc30 |           | VTAB B0Inc10 |           |\n| ---------------- | ------------ | --------- | ----------- | --------- | ------------ | --------- | ------------ | --------- |\n|                  | $A$          | $A_B$     | $A$         | $A_B$     | $A$          | $A_B$     | $A$          | $A_B$     |\n| L2P              | 47.16        | 38.48     | 63.78       | 52.19     | 73.36        | 64.69     | 77.11        | 77.10     |\n| DualPrompt       | 52.56        | 42.68     | 59.27       | 49.33     | 73.92        | 65.52     | 83.36        | 81.23     |\n| **SimpleCIL**    | **60.50**    | **48.44** | **65.45**   | **53.59** | **79.34**    | **73.15** | **85.99**    | **84.38** |\n| ADAM-Finetune    | 61.57        | 50.76     | 61.41       | 48.34     | 73.02        | 65.03     | 87.47        | 80.44     |\n| ADAM-VPT-Shallow | 57.72        | 46.15     | 64.54       | 52.53     | 79.63        | 73.68     | 87.15        | 85.36     |\n| ADAM-SSF         | 62.81        | 51.48     | 69.15       | 56.64     | 80.53        | 74.00     | 85.66        | 81.92     |\n| ADAM-Adapter     | 60.53        | 49.57     | 67.18       | 55.24     | 80.75        | 74.37     | 85.95        | 84.35     |\n| ADAM-VPT-Deep    | 60.59        | 48.72     | 67.83       | 54.65     | 81.05        | 74.47     | 86.59        | 83.06     |\n| PECTP(Ours)      | 66.21        | 55.43     | 70.18       | 58.43     | 81.08        | 74.54     | 87.14        | 86.32     |\n\n\n\nThe total results can be found above. Specifically, CIFAR, CUB, and ImageNet-R are widely adopted benchmark datasets for CIL. However, due to the data overlap between ImageNet-based benchmarks and the pre-trained dataset, ImageNet is **unsuitable** for evaluating *PTM-based CIL methods*. Therefore, we follow [4] to evaluate our method on four new benchmarks: ImageNet-A, ObjectNet, OmniBenchmark, and VTAB. These new benchmarks not only have **no overlap with ImageNet** but also **exhibit a large domain gap between tasks**, making it challenging for PTMs to handle. \n\nNotably, despite training on an extremely large-scale dataset, SimpleCIL fails to achieve high accuracy on certain tasks, such as ImageNet-R and ImageNet-A. In contrast, PECTP **consistently outperforms SimpleCIL on seven benchmarks**, especially on those without overlap."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2478/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700497602240,
                "cdate": 1700497602240,
                "tmdate": 1700497602240,
                "mdate": 1700497602240,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "k1IOKV5JAW",
                "forum": "4lqo5Jwfnq",
                "replyto": "uxRRfyvWMf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2478/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2478/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you!"
                    },
                    "comment": {
                        "value": "Thank you for your diligent review of our paper. With your valuable comments and suggestions, especially for the Questions about paper revision, we have significantly improved the clarity, fluency, and details of our paper. We sincerely appreciate you and your advice."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2478/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700719293575,
                "cdate": 1700719293575,
                "tmdate": 1700719293575,
                "mdate": 1700719293575,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Iv3lvYIpt9",
            "forum": "4lqo5Jwfnq",
            "replyto": "4lqo5Jwfnq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2478/Reviewer_vcUE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2478/Reviewer_vcUE"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose the prompt-fixed CIL method for rehearsal-free CIL setup. Also, they also propose the Prompt Retention Module (PRM) to regularize the updating prompt parameters, and it utilizes two granularity features called Outer Prompt Granularity (OPG) and Inner Prompt Granularity (IPG)."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "**1 (Well-defined problem).** There was a scalable issue by proposing prompt-extending methods such as DualPrompt and Coda-prompt. However, they propose the prompt-fixed method with PRM which is a regularization term for avoiding forgetting, so they solve the scalable issue as the number of tasks increases. \n\n**2 (Intuitive Idea).** Their proposed method is intuitive, and well-organized. If I have to solve this problem, I also think the approach like this paper. \n\n**3 (Enough Experiment).** There are several experimental results to prove the effectiveness of their method. Most of my concerns are solved via their experiments, but some are still remaining. I wrote them in the weakness section. \n\n**4 (Well-written).** It is easily written for understanding."
                },
                "weaknesses": {
                    "value": "**1 (Table 2).** While L2P has the prompt pool, the number of prompts does not depend on the number of tasks. As such, L2P should be prompt-fixed, not prompt-extending. Also, I'm wondering the results on comparison of PECTP and the other baselines with same prompt number (Either You can increase the prompt number in PECTP or you can decrease the prompt number in other baselines is fine).\n\n**2 (Necessity of Inner Prompt Granularity).** According to Table 3, utilizing both IPG and OPG has the good synergy to enhance the performance. To the best of my understanding, the roles of IPG and OPG are to prevent forgetting knowledge from the previous task and pretrained model, respectively. To validate the hypothesis that I mentioned, the additional ablation study is needed (i.e, we can split the test set for each task). For example, in table 3, baseline+IPG do not forget in the previous task compared to baseline+OPG or baseline, and baseline+OPG has the consistent results for all the tasks.\n\n**3 (Stress Test).** This work is noteworthy when the number of tasks is large (e.g, n_task=1000) due to scaling issue. As such, reporting the results in large number of tasks setup would be helpful to validate the effectiveness of their method."
                },
                "questions": {
                    "value": "I replace this part with weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2478/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698816907216,
            "cdate": 1698816907216,
            "tmdate": 1699636184083,
            "mdate": 1699636184083,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "immFDHIPEd",
                "forum": "4lqo5Jwfnq",
                "replyto": "Iv3lvYIpt9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2478/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2478/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer vcUE"
                    },
                    "comment": {
                        "value": "Thank you for the review, comments, and constructive feedback! We are encouraged that you found our idea promising, our method effective and our writing clear. We provide answers to your comments and questions below.\n\n\n\nQ1. \"While L2P has the prompt pool, the number of prompts does not depend on the number of tasks. As such, L2P should be prompt-fixed, not prompt-extending. \" \n\nA1: We have reviewed the description of L2P [1] in the original paper and found an error in our understanding. We categorize L2P as a *prompt-fix method* and will make the corrections in the latest version.\n\n\n\nQ2. \"Results on comparison of PECTP and the other baselines with same prompt number.\"\n\nA2: We would like to provide a detailed explanation of the specific calculation method for the number of prompts in *PTM-based CIL methods*. \n\nFirstly, in existing *PTM-based CIL methods*, the description of **'prompt' refers to a set of prompts instead of a single prompt.** For example, in L2P, $P_{i} \\in \\mathbb R^{L_{P}\\times D}$, where $L_{P}$ is the number of single prompts, and each $P_{i}$ is stored in a prompt pool. Therefore, for L2P, the total number of prompts is *$L_{P} \\times$ the number of prompts* .\n\nFurthermore, current *PTM-based CIL methods* follow VPT[6] for prompt handling, which has two variants: VPT-Deep and VPT-shallow. For instance, in DualPrompt[2], e-prompts: $e_{i} \\in \\mathbb R^{L_{e}\\times D}$ are inserted into the 3-5 layers of the VIT encoder, while g-prompt: $g_{j} \\in \\mathbb R^{L_{g}\\times D}$ is inserted into the 1-2 layers of the VIT encoder. Therefore, for DualPrompt, the total number of prompts is: *the number of e-prompts $\\times$ $L_{e}\\times$ inserted layers + the number of g-prompts $\\times$ $L_{g}\\times$ inserted layers.*\n\nFinally, we strictly reimplement the baseline method according to the description in the original paper [1-3]. Additionally, we agree with the reviewer's perspective that the **performance of PTM-based methods depends significantly on the number of trainable parameters**. Therefore, maintaining an equal number of parameters for comparison will provide meaningful results. Considering that **PECTP introduces fewer trainable parameters** compared to the baseline methods, **we have included three additional variants: PECTP-L, PECTP-D, and PECTP-C, each roughly equivalent in the number of trainable parameters to L2P, DualPrompt, and CODAPrompt[3],** respectively. Here is a summary of the results:\n\n| CIFAR  |               |    A_B     |         Overhead         |                          |\n| :----: | :-----------: | :--------: | :----------------------: | :----------------------: |\n|        |               |            | Addtional Prompt numbers | Learnable Parameters (M) |\n| extend |  DualPrompt   | 83.05+1.16 |         **602**          |    **0.57 (10.56 X)**    |\n|        |     CODA      | 86.25+0.74 |         **4000**         |    **3.92 (72.59 X)**    |\n| fixed  |     L2P++     | 82.50+1.10 |         **200**          |    **2.39 (44.25 X)**    |\n|        | ADAM_VPT_Deep |   83.26    |          **60**          |    **0.054 (1.00 X)**    |\n|        |     PECTP     |   86.27    |          **60**          |    **0.054 (1.00 X)**    |\n|        |    PECTP-L    |   87.82    |         **240**          |    **0.22 (4.07 X)**     |\n|        |    PECTP-D    |   88.14    |         **600**          |    **0.54 (10.0 X)**     |\n|        |    PECTP-C    |   88.28    |         **3600**         |    **3.24 (60.0 X)**     |\n|  NONE  |  UPPER bound  |   90.86    |            0             |            0             |\n\nThe results illustrate that the proposed PECTP demonstrates **a significant performance improvement, even with a much smaller parameters** compared to baseline methods (DualPrompt, L2P, and CODA are 10, 44, and 72 times larger than PECTP, respectively). Furthermore, as the number of prompts in PECTP increases the performance **continues to improve and approaches the UPPER bound**. This further emphasizes the superiority of our approach."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2478/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700496980479,
                "cdate": 1700496980479,
                "tmdate": 1700496980479,
                "mdate": 1700496980479,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jeQZuCkLKh",
                "forum": "4lqo5Jwfnq",
                "replyto": "Iv3lvYIpt9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2478/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2478/Authors"
                ],
                "content": {
                    "title": {
                        "value": "(Continued) Response to Reviewer vcUE"
                    },
                    "comment": {
                        "value": "Q3. \"According to Table 3, utilizing both IPG and OPG has the good synergy to enhance the performance. To the best of my understanding, the roles of IPG and OPG are to prevent forgetting knowledge from the previous task and pretrained model, respectively. \"\n\nA3: We agree with the reviewer's perspective that **there exists two catastrophic forgetting issues in PTM-based methods**: \n\n(a) forgetting knowledge of previously learned incremental tasks and,\n\n(b) forgetting knowledge obtained from the pretraining stage of PTM.\n\nHowever, we would like to clarify that the **PRM** proposed in our paper aims to **minimize the former issue by reducing it at two granularity**, specifically categorized as **OPG and IPG**. As for the latter one, we follows the approach in [4], utilizing 'feature fusion module' to mitigate the impact of continual learning on the knowledge gained during pretraining.\n\nFinally, we identify a mistake where we mistakenly quoted the results of Baseline on IN-A Inc10 from [4]. It has been corrected in the latest version of the paper, and we have included additional results from ablation experiments on CUB and ImageNet-R. Here is a summary of the results:\n\n| Method               | CIFAR Inc10 |           | IN-A Inc10 |           | CUB Inc10 |           | IN-R Inc10 |           |\n| -------------------- | ----------- | --------- | ---------- | --------- | --------- | --------- | ---------- | --------- |\n|                      | $A$        | $A_{B}$   | $A$        | $A_{B}$ | $A$      | $A_{B}$ | $A$        | $A_{B}$ |\n| SimpleCIL            | 87.13       | 81.26     | 60.50      | 49.44     | 90.96     | 85.16     | 61.99      | 54.55     |\n| Baseline             | 90.19       | 84.66     | 60.59      | 48.72     | 89.48     | 83.42     | 74.46      | 66.47     |\n| Baseline+OPG         | 92.43       | 87.66     | 65.48      | 53.92     | 90.01     | 85.09     | 77.03      | 69.38     |\n| Baseline+IPG         | 91.70       | 87.60     | 61.41      | 49.11     | 89.69     | 84.01     | 75.91      | 67.43     |\n| **Baseline+OPG+IPG** | **92.59**   | **87.73** | **66.21**  | **55.43** | **91.01** | **85.11** | **77.42**  | **70.01** |\n\nThe experimental results demonstrate that IPG exerts a stronger constraint on the prompt itself. When the domain gap between incremental learning tasks is small, such as in CIFAR and ImageNet-R, it leads to a greater improvement in performance. Additionally, the results in the last row indicate that OPG and IPG are complementary. **Using them together can significantly reduce the forgetting of knowledge acquired from previously learned incremental tasks**.\n\n\n\nQ4. \"The results in large number of tasks setup would be helpful to validate the effectiveness of their method.\"\n\nA4:  Thank you for your suggestions. Learning tasks with long sequences have consistently been a challenging research area in CIL. We followed [5] to partition tasks based on the number of classes, and **evaluated our approach on different configurations of ImageNet-R: 20 tasks (10 classes/task), 40 tasks (5 classes/task), 50 tasks (4 classes/task), and 100 tasks (2 classes/task).** \n\n\n\n|         Dataset         | ImageNet-R $A_{B}$ |       |       |       |\n| :---------------------: | :----------------: | :---: | :---: | :---: |\n|      Task Numbers       |         20         |  40   |  50   |  100  |\n|           L2P           |       65.86        | 59.22 | 57.28 | 35.56 |\n|       DualPrompt        |       67.87        | 55.22 | 58.61 | 39.66 |\n|        SimpleCIL        |       54.55        | 54.55 | 54.55 | 54.55 |\n| ADAM-VPT-Deep(Baseline) |       66.47        | 64.3  | 60.35 | 54.07 |\n|       PECTP(Ours)       |       70.01        | 68.15 | 66.18 | 59.75 |\n\n\n\nThe specific implementation results **demonstrate the consistent superiority of the PECTP across task** sequences of varying lengths. However, we also observed significant performance degradation for L2P, DualPrompt, and PECTP when learning extremely long task sequences. For instance, when continuously learning 100 tasks, PECTP only achieved an 8% improvement over SimpleCIL[4], despite incurring a substantial increase in computational overhead. We acknowledge this as an area for future exploration and investigation. Once again, thank you for bringing this issue to our attention.\n\n\n If you have any further questions, we are willing to clarify any misunderstandings and address your inquiries to the best of our ability.\n\n### Refs:\n\n[1] Learning to Prompt for Continual Learning, 2022 CVPR \n\n[2] DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning, 2022 ECCV\n\n[3] CODA-Prompt: COntinual Decomposed Attention-based Prompting for Rehearsal-Free Continual Learning, 2023 CVPR \n\n[4] Revisiting Class-Incremental Learning with Pre-Trained Models: Generalizability and Adaptivity are All You Need, 2023 Arxiv\n\n[5] iCaRL: Incremental Classifier and Representation Learning, 2017 CVPR\n\n[6] Visual Prompt Tuning, 2022 ECCV"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2478/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700497452827,
                "cdate": 1700497452827,
                "tmdate": 1700497493966,
                "mdate": 1700497493966,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ti2mDTZBt5",
                "forum": "4lqo5Jwfnq",
                "replyto": "Iv3lvYIpt9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2478/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2478/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow up"
                    },
                    "comment": {
                        "value": "We wanted to follow up and gently ask if we are able to address your concerns in our response. As the discussion period is nearing an end, we would appreciate any updates or further questions you may have, and if not, we hope you might consider raising your score. We thank you for your time in advance!"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2478/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700719200433,
                "cdate": 1700719200433,
                "tmdate": 1700719200433,
                "mdate": 1700719200433,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "OOaxiRIeYa",
            "forum": "4lqo5Jwfnq",
            "replyto": "4lqo5Jwfnq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2478/Reviewer_2DHh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2478/Reviewer_2DHh"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a prompt-fixed continual learning method based on pre-trained transformer models. By introducing a regularization module for the task prompts, the method constrains the update of prompts. Extensive experiments on benchmark datasets demonstrates the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper is easy to understand.\n- Using prompting-based method for continual learning is interesting."
                },
                "weaknesses": {
                    "value": "- The idea of adding regularization terms to a fixed set of prompts is not quite persuasive. I have a series of related questions:\n1. What is the intuition behind limiting the update of prompts? \n2. How is it different from usual regularization-based CL methods, besides the fact that you are doing on prompt parameters instead of all model parameters? \n3. Wouldn't limiting the update also limits the ability of learning new tasks?\n4. Why using a fixed set of prompts is even better than extending the set of prompts? For example, if the domain gaps are large between different tasks, the fixed set of prompts might not be able to represent them well without conflicts.\n- To me it seems the \"feature fusion\" module is the most interesting part that fixed prompts method work well. However, this is not the main contribution of the method, and the authors did not describe them in detail in the main paper."
                },
                "questions": {
                    "value": "Please see weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2478/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699090154374,
            "cdate": 1699090154374,
            "tmdate": 1699636184019,
            "mdate": 1699636184019,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Qumj96Fa0O",
                "forum": "4lqo5Jwfnq",
                "replyto": "OOaxiRIeYa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2478/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2478/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 2DHh"
                    },
                    "comment": {
                        "value": "Thank you for the review, comments, and constructive feedback! We are encouraged that you found our method effective and our writing clear. We provide answers to your comments and questions below.\n\n\n\nQ1. \"What is the intuition behind limiting the update of prompts?\" \n\nA1: The intuition behind limiting the update of prompts is to **maintain knowledge related to previous tasks within the prompts**. In existing *PTM-based CIL methods* [1-5], task-specific knowledge is encoded into prompts. The task-specific knowledge is associated with each incremental tasks, such as visual features or task information like the task ID, and is updated continually for each incremental task. Due to considerations of storage and computational overhead, we adopt *prompt-fix methods* that use only a fixed set of prompts.\n\nHowever, if prompts are **continually trained** on each incremental task using cross-entropy loss **without any constraints**, prompts are prone to losing knowledge of previous tasks. For instance, training a set of prompts $\\mathcal P$ on task 1 results in $\\mathcal P_{1}$, which acquires knowledge about task 1. This implies that utilizing $\\mathcal P_{1}$ effectively guides the PTM in classifying the first task. However, when we continue training $\\mathcal P_{1}$ on task 2, resulting in $\\mathcal P_{2}$, the parameters of $\\mathcal P_{2}$ have changed compared to $\\mathcal P_{1}$. This means that $\\mathcal P_{2}$ cannot effectively guide the PTM in correctly classifying task 1. Therefore, without adding additional constraints during the training\uff0c$\\mathcal P_{i}$ is prone to losing information about previous tasks: $1,2,...,i-1$. \n\nTo verify this point, we provide an additional set of experimental results, where ***PlainCIL* represents continuously learning new task knowledge without adding any constraints to prompts**. *SimpleCIL* [4] represents directly using a PTM to address incremental learning tasks without any prompting or finetuning. Here is a summary of the results:\n\n\n\n| ViT-B/16-IN21K          | CIFAR Inc10      |                  | CUB Inc10       |                  | IN-R Inc10       |                  | IN-A Inc10       |                  |\n| ----------------------- | ---------------- | ---------------- | --------------- | ---------------- | ---------------- | ---------------- | ---------------- | ---------------- |\n|                         | $A$              | $A_B$            | $A$             | $A_B$            | $A$              | $A_B$            | $A$              | $A_B$            |\n| L2P                     | 88.14+/-0.32     | 84.33+/-0.41     | 66.60+/-0.30    | 56.01+/-0.16     | 73.52+/-0.65     | 67.20+/-0.41     | 47.56+/-0.93     | 38.88+/-0.39     |\n| DualPrompt              | 89.61+/-0.22     | 84.02+/-0.29     | 74.80+/-0.17    | 60.81+/-0.11     | 70.12+/-0.96     | 64.92+/-0.56     | 52.76+/-1.01     | 42.38+/-1.30     |\n| SimpleCIL               | 87.13            | 81.26            | 90.96           | 85.16            | 61.99            | 54.55            | 60.50            | 48.44            |\n| **PlainCIL**            | **90.68**        | **87.0**         | **84.30**       | **77.27** | **68.40**        | **61.28**        | **59.95**        |   **49.31**                |\n| ADAM-VPT-Shallow        | 89.31+/-0.91     | 84.96+/-0.79     | 90.15+/-0.98    | 85.37+/-0.36     | 70.59+/-1.26     | 62.2+/-1.31      | 58.11+/-0.85     | 47.48+/-1.29     |\n| ADAM-VPT-Deep(Baseline) | 90.29+/-0.32     | 84.95+/-0.42     | 89.18+/-0.47    | 83.88+/-0.91     | 73.76+/-0.76     | 66.77+/-0.75     | 62.77+/-3.69     | 51.15+/-3.34     |\n| **PECTP(Ours)**         | **92.49+/-0.19** | **88.09+/-0.16** | **91.0+/-0.21** | **84.69+/-0.52** | **78.33+/-0.64** | **70.28+/-0.19** | **65.74+/-1.22** | **54.66+/-0.99** |\n\n\n\n\n\nQ2. \"Wouldn't limiting the update also limits the ability of learning new tasks?\" \n\nA2: We also concur with the reviewer's perspective that constraining the update of prompts may impede learning for new tasks, consequently limiting the acquisition of new knowledge. However, even in *usual regularization-based CIL methods* [7], there exists a trade-off between new and old knowledge. **Specifically, in usual classic incremental learning approaches, there exists weakening the forgetting of old knowledge by constraining learning for new tasks.**\n\nIn summary, we are actively seeking a **more reasonable balance between new and old knowledge**. Additionally, although the motivation behind the proposed method is to efficiently utilize prompt parameters to adapt to highly memory-constrained scenarios, our experimental results indicate that even for some methods with parameters far exceeding PECTP, the proposed method remains comparable. For specific results, please refer to **https://openreview.net/forum?id=4lqo5Jwfnq&noteId=Iv3lvYIpt9**."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2478/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700497819685,
                "cdate": 1700497819685,
                "tmdate": 1700548468352,
                "mdate": 1700548468352,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "frDzD7eWwz",
                "forum": "4lqo5Jwfnq",
                "replyto": "OOaxiRIeYa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2478/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2478/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow up"
                    },
                    "comment": {
                        "value": "Dear Reviewer 2DHh,\n\nWe thank the reviewer for their engagement in the rebuttal process. As the discussion period is nearing an end, we would appreciate any updates or further questions you may have, and if not, we hope you might consider raising your score. We thank you for your time in advance!\n\nBest,\n\nPaper 2478 Authors"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2478/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700720134990,
                "cdate": 1700720134990,
                "tmdate": 1700720134990,
                "mdate": 1700720134990,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]