[
    {
        "title": "Faster Maximum Inner Product Search in High Dimensions"
    },
    {
        "review": {
            "id": "ifjewszpXO",
            "forum": "7XXineVQeU",
            "replyto": "7XXineVQeU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8860/Reviewer_tsE3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8860/Reviewer_tsE3"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the maximum inner product search (MIPS) problem in high dimensions. The authors present a multi-armed bandit-based approach, called BanditMIPS, whose idea is to adaptively subsample coordinates for more promising atoms. Empirically, BanditMIPS can achieve 20 times faster than the prior algorithm."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The MIPS problem is important and relevant. A fast algorithm for this problem is useful.\n- The introduction of the multi-armed bandit idea is natural.\n- The empirical results look convincing."
                },
                "weaknesses": {
                    "value": "- The format of the paper is incorrect.\n- The theoretical result is as simple as a standard corollary of UCB bounds.\n- The paper only studies the runtime for a single query vector, which is not sufficient in practice since we usually face multiple queries."
                },
                "questions": {
                    "value": "- The paper discusses a single query vector and hence, mentions that BanditMIPS requires no preprocessing of the data. However, we note that there is usually a long sequence of queries in practice, which requires some preprocessing, e.g., HNSW. A discussion of the two settings maybe helpful."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8860/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698059643285,
            "cdate": 1698059643285,
            "tmdate": 1699637114623,
            "mdate": 1699637114623,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "dK0FXWhOm5",
            "forum": "7XXineVQeU",
            "replyto": "7XXineVQeU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8860/Reviewer_CJG9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8860/Reviewer_CJG9"
            ],
            "content": {
                "summary": {
                    "value": "The paper does not follow the ICLR formatting guidelines (the paper is two columns etc) and does not have any references in the main submission. Even ignoring this, I'm not sure what the main theorem is even saying. Roughly it states that 'if some parameter is small enough', then we only need to read few coordinates for maximum inner product search. But the 'parameter' in question seems to be defined circularly as 'how many coordinates are read'."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "See summary above."
                },
                "weaknesses": {
                    "value": "See summary above."
                },
                "questions": {
                    "value": "See summary above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8860/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698510352931,
            "cdate": 1698510352931,
            "tmdate": 1699637114498,
            "mdate": 1699637114498,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "yNDrb1Wuvg",
            "forum": "7XXineVQeU",
            "replyto": "7XXineVQeU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8860/Reviewer_FGUA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8860/Reviewer_FGUA"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the problem of Maximum Inner Product Search problem (MIPS): Given a dataset of n vectors in a d-dimensional space, and a new vector, the goal is to find the vector within the dataset that yields the highest inner product with it. This paper introduces a randomized algorithm inspired by bandit methods to enhance the time complexity from $O_n(\\sqrt{d})$ to $O_n(1)$, and showcases its effectiveness on four synthetic and real-world datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- the problem studied in this paper is interesting \n- the paper is well-organized, and easy to follow. \n- there are extensive evaluations of their methods over various datasets"
                },
                "weaknesses": {
                    "value": "- The paper assumes that $X_i$ follows subgaussian distribution, this is a strong assumption.\n- The presentation of this paper needs major improvement. Some of the figures are super large(Figure 3,5,6), while some of the figures are extra small to read(Figure 4). \n\nAlso, the current format of this paper doesn't align with the ICLR 2024 format file, and the references are not in the submitted 9 pages.\n\nMinor Comments:\n- Duplicate reference (in the appendix version): \nMorozov, S.; and Babenko, A. 2018a. Non-metric Similarity Graphs for Maximum Inner Product Search.\nMorozov, S.; and Babenko, A. 2018b. Non-Metric Similarity Graphs for Maximum Inner Product Search. In Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc.\n- \"Accuracy:1.0\" in figure 5 and figure 6 is not very clear to read and isn't been explained in the caption. \n- subplots in Figure 4 lacks effort, note that if we print this paper out, these subgraphs won't be big enough to read."
                },
                "questions": {
                    "value": "see weakness on the subgaussian distribution."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8860/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8860/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8860/Reviewer_FGUA"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8860/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698829072261,
            "cdate": 1698829072261,
            "tmdate": 1699637114375,
            "mdate": 1699637114375,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "DOP6B4bGvf",
            "forum": "7XXineVQeU",
            "replyto": "7XXineVQeU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8860/Reviewer_hfLb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8860/Reviewer_hfLb"
            ],
            "content": {
                "summary": {
                    "value": "This work considers the problem of maximum inner product search (MIPS), where given a static database v_1...v_n of n points, each in $\\mathbb{R}^d$, and a query point $q$, asks to find the point $v^*$ in the database with maximum inner product $v^*= argmax_{i\\in [n]} <q,v_i>$ with the query point. This is a practically important problem, with the trivial solution requiring $O(nd)$ computations. The key question here is can we speed up this search, i.e. identify the point $v^*$ in far fewer than $O(nd)$ operations. In this paper, the authors derive a scheme by reducing this problem to the best arm identification problem in stochastic bandits, by essentially treating each point in the static database as an arm, with mean reward of arm $i$ corresponding to the database vector $v_i$ effectively being $\\sum_{j=1}^d q_j\\cdot v_{ij}/d$. The \"stochastic\" component comes from the fact the we can obtain a noisy estimate of this quantity in $O(1)$ time by sampling a dimension $j\\in [d]$ uniformly at random (with replacement) and computing the product $q_jv_{ij}$. This problem then exactly becomes the best arm identification problem, with the total computational complexity of MIPS being the sample complexity of the corresponding best arm identification problem. Following standard results in the BAI literature, the authors prove that MIPS can be solved with high probability in $O(\\sum_{I=2}^n \\frac{1}{\\Delta_i^2}\\log (n/\\delta))$ computations, which is dimension invariant."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "None."
                },
                "weaknesses": {
                    "value": "I apologize for the harshness in this review, but I strongly believe it is needed with this submission. There is absolutely nothing technically interesting going on in this paper. The idea of using best arm identification to solve MIPS is very obvious and has already been explored before in the result of Liu et.al. AAAI 19, with the only difference being sampling with vs without replacement. The statement that they achieve dimension independent bounds is a huge overclaim -> the dependence on $1/\\Delta_i^2$ directly scales with the dimension, and you explicitly need well-separation assumptions in order to get around this (or settle for an $\\epsilon$-approximate solution which then directly bounds this quantity by $1/\\epsilon^2$). None of these ideas are at all novel, due to which for this result, I find it extremely difficult to recommend an accept at any venue, let alone one as competitive as ICLR."
                },
                "questions": {
                    "value": "What is novel in this result?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8860/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8860/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8860/Reviewer_hfLb"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8860/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699046127953,
            "cdate": 1699046127953,
            "tmdate": 1699637114244,
            "mdate": 1699637114244,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]