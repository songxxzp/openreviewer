[
    {
        "title": "SEE-OoD: Supervised Exploration for Enhanced Out-of-Distribution Detection"
    },
    {
        "review": {
            "id": "eZTlhQYupw",
            "forum": "MrslLZmkye",
            "replyto": "MrslLZmkye",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2761/Reviewer_8gYg"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2761/Reviewer_8gYg"
            ],
            "content": {
                "summary": {
                    "value": "The paper is concerned with the robust out-of-distribution (OOD) detection, while maintaing the same level of performance of in-distribution (IND) data. In order to overcome the case when the number of OOD samples is too smalll (which could lead to overfitting), the authors propose a generative adversarial approach that uses real OOD data for supervised generation of synthetic OOD samples and thus could better represent the OOD space. More concretely, they propose a Wasserstein-score-based generative adversarial training\nframework where the generator explores OOD space and synthesis virtual outliers with the feedback provided by the discriminator, while the discriminator exploits the generated outliers to separate IND and OOD data distributions. Extensive experiments demonstrates the superiority of the proposed approach in OOD detection when compared with other state-of-the-art approaches."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is well-documented, clearly written and easy to follow. The paper provides a theoretical insight in order to demonstrate the effectiveness of the proposed method. The related work section covers the most relevant papers in the field. Experimental validation is convincing and demonstrates the superiority of the proposed approach."
                },
                "weaknesses": {
                    "value": "The idea is not totally new, i.e. the usage of Wasserstein-based-score for OOD detection has been used before (see the WOOD method)."
                },
                "questions": {
                    "value": "- I understand that your approach is suitable for low-data regime (especially when the number of OOD samples is low). It would be interesting to visualize the curves in figures 2 and 3 also as a number of several ratios (IND/OOD). How many number of OOD samples do you need to generate in each case? \n- Why do you distinguish between two experimental scenarios (balanced vs imbalanced OOD classes)? It is assumed that OOD data is unlabeled. So, it does not matter how many data is in each class. Please clarify this aspect.\n- Another aspect which is not clear to me is how do you define the imbalanced regime for OOD, i.e. you mention 'only a few classes are observed'). I thought imbalance refers to different ratios between the samples of OOD classes or with respect to the samples in the IND classes. What is in each case the ratio between majority classes and minority classes?\n- If the generative adversarial approach is unconditional, why the case of imbalanced scenario is relevant? OOD data is unlabeled anyway.\n- How do you evaluate the quality of the synthetic OOD samples? Some quantitative and qualitative analysis is indicated."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2761/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698401747430,
            "cdate": 1698401747430,
            "tmdate": 1699636219062,
            "mdate": 1699636219062,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jPTIIIi06r",
                "forum": "MrslLZmkye",
                "replyto": "eZTlhQYupw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2761/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2761/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer 8gYg"
                    },
                    "comment": {
                        "value": "Dear Reviewer 8gYg, we are grateful for your detailed feedback. Please see our following point-to-point responses to address your comments.\n\n## Presentations of Figure 2. and Figure 3.\n\nThanks for your valuable suggestions about presenting the results. The reason why we choose to use numbers of OoD samples, instead of InD/OoD ratios, as X-axis is because, in practice, the OoD samples at hand are usually very scarce (ex, unseen manufacturing defects, rarely seen obstacles in autonomous driving), whereas the size of InD training data can grow easily. This makes the ratio metric not as informative as numbers. As for the number of OoD samples that we generate, we generate OoD samples in each iteration of the iterative training process and use those to regularize the model. For detailed information, we kindly refer the reviewer to Appendix D.2.2, where $B_G$ denotes the number of OoD samples generated in each iteration.\n\n## Differences between two regimes\n\nWe are glad that you point out that OoD data are unlabeled anyway. We totally agree with you. Although the OoD labels are not used in the model training, the inherent differences between OoD samples from different classes can affect the model performance. And there might be a distribution shift between observed and test OoD samples. The idea here is to control what has been observed by our method in the training time. Under the balanced sampling strategy in regime I, the testing OoD samples resemble part of training OoD samples. However, in practice, people only possess very limited knowledge about OoD samples so it is reasonable that some types of OoD samples are not observed. Under the imbalanced sampling strategy in regime II, the test OoD samples may be different from the observed OoD samples.\n\n## Further explanation of imbalanced regime\n\nIn the imbalanced regime, we deliberately leave one class (i.e., type) of OoD samples unobserved. For example, in the SVHN Within-Dataset experiment, classes 8 and 9 are considered OoD, but during training, only samples from class 8 are observed. We employ this setting to assess the generalizability of our method. For specific details regarding experimental setups and the number of samples included during training, we kindly refer the reviewer to Table 2 and Appendix E.\n\n## Evaluation of quality of generated outliers\n\nThank you for highlighting this crucial aspect. In our paper, Theorem 1 and Theorem 2 enable us to offer theoretical guarantees on the quality of generated outliers. We have demonstrated that, theoretically, the generated outliers will not be part of InD clusters. Regarding the experimental setup, we deliberately refrain from controlling the generation of outliers. This choice aligns with the primary goal and contribution of our method, which is to explore OoD spaces. As long as the generated outliers do not become part of InD, our objective is considered accomplished."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2761/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700261292184,
                "cdate": 1700261292184,
                "tmdate": 1700261292184,
                "mdate": 1700261292184,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "OTpnpPNzQa",
                "forum": "MrslLZmkye",
                "replyto": "eZTlhQYupw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2761/Reviewer_8gYg"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2761/Reviewer_8gYg"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Reviewer 8gYg"
                    },
                    "comment": {
                        "value": "After carefully analyzing authors' responses, I consider that my concerns have been satisfactorily addressed. Therefore, and despite other reviewers' opinions, I have decided to maintain my initial rating. Overall, I consider the paper has a contribution, the proposed approach is supported by a mathematical formalism (including proofs of threorems) and the experimental validation is convincing. I agree that including OOD samples in the training process limits somehow the generalization capability of the method, but it is still considered a valid setting."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2761/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700648135738,
                "cdate": 1700648135738,
                "tmdate": 1700648431216,
                "mdate": 1700648431216,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "X9qW4BYY95",
            "forum": "MrslLZmkye",
            "replyto": "MrslLZmkye",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2761/Reviewer_BP77"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2761/Reviewer_BP77"
            ],
            "content": {
                "summary": {
                    "value": "In the presented research, the authors introduce a novel generative adversarial training approach rooted in the Wasserstein-score-based\nframework. This method facilitates the generator in traversing Out-of-Distribution (OoD) spaces to produce virtual outliers, guided by feedback from the discriminator. Concurrently, the discriminator harnesses these outliers to distinguish between In-Distribution (InD) and OoD data within the designated Wasserstein score space. The study furnishes theoretical validations confirming the method's robustness, highlighting its capacity to seamlessly segregate InD and OoD data, including the synthesized virtual OoD samples. A unique experimental paradigm is unveiled, termed Within-Dataset OoD detection, which offers a more rigorous test for Deep Neural Networks (DNNs) compared to the conventional Between-Dataset OoD differentiation tasks. The efficacy of the proposed technique is further validated through extensive benchmark tests across varied image datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper introduces a novel generative adversarial training scheme that allows the generator to explore Out-of-Distribution (OoD) spaces and generate virtual outliers. This innovative approach enhances the traditional methods of OoD detection by leveraging the power of generative models.\n\n2. A standout feature of this paper is the provision of several theoretical results that back the proposed method. By demonstrating that the\ndiscriminator can achieve perfect separation between In-Distribution (InD) and OoD samples in the Wasserstein score space, the authors solidify the the credibility of their approach."
                },
                "weaknesses": {
                    "value": "1. Evaluation Metrics: The paper seems to overlook certain prevalent evaluation metrics. For instance, the Area Under the Curve (AUC) is a widely accepted metric in many domains, including OoD detection. It would be beneficial to understand the performance of the proposed method under such widely recognized metrics. Furthermore, the reliance on outlier exposure raises questions. Specifically, OoD detection typically aims to identify data points that deviate from the expected distribution, rather than simply identifying outliers. The distinction between these two is subtle but crucial.\n\n2. Generality of Proposed Setting: The proposition of the Within-Dataset OoD detection is undoubtedly a fresh perspective. However, its universal applicability remains a concern. This setting, which treats different classes within the same dataset as OoD with respect to one another, might not capture the diverse and multifaceted nature of real-world OoD scenarios. To many, this approach might appear as an analysis of variations within a single domain rather than a genuine OoD situation. \n\n3. Scalability Concerns: The scalability of the proposed method, especially when confronted with vast and diverse datasets , remains ambiguous."
                },
                "questions": {
                    "value": "Please refer to the above weakness part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2761/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698805348410,
            "cdate": 1698805348410,
            "tmdate": 1699636218974,
            "mdate": 1699636218974,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8Prvmih7an",
                "forum": "MrslLZmkye",
                "replyto": "X9qW4BYY95",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2761/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2761/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer BP77"
                    },
                    "comment": {
                        "value": "Dear Reviewer BP77, we are grateful for your detailed feedback. Please see our following point-to-point responses to address your comments.\n\n## Evaluation Metric\n\nWe kindly refer the reviewer to our general response.\n\n## Generality of Within-Dataset Detection Tasks\n\nWe would like to thank Reviewer BP77 for pointing this out. As you alluded, the primary objective of introducing this new setting is to assess OoD detection accuracy when InD and OoD samples closely resemble each other. The resemblance between InD and OoD samples introduces additional challenges compared to the conventional between-dataset detection setting.\n\nWe agree with your comment on the universal applicability of Within-Dataset detection tasks.\n\nHowever, in various real-world situations, InD and OoD samples may resemble each other. For instance, in anomaly detection, anomalies can manifest as small deviations from the InD samples (Sun et al., 2023). This insight motivated the Within-Dataset experiments, where OoD samples originate from classes within the same dataset. The goal was to create scenarios where InD and OoD samples come from the same dataset and emphasize our model's ability to effectively detect such cases.\n\nThat said, it is crucial to clarify that the within-dataset detection setting serves as an additional metric when compared to other methods. We have demonstrated that our method significantly outperforms baselines in the traditional Between-Dataset setting, particularly in terms of generalizability to test OoD samples not encountered during the training process. This also indicates that our method effectively leverages existing limited OoD samples and explores potential OoD spaces more efficiently compared to the baselines.\n\n## Scalability Concerns\n\nWe kindly refer the reviewer to our general response. Following the settings in Liu et al. (2020) we added one more Between-Dataset experiment, CIFAR10-Texture with more InD classes, and one more baseline OE (Hendrycks et al., 2018), to illustrate the scalability and effectiveness of our method.\n\nIn addition, we would like to communicate the following perspective with the reviewer.\n\n### Are the difficulties of OoD detection tasks determined by the complexities of datasets?\n\nIt is critical to point out that the complexity of the InD and OoD datasets is not the only factor that influences the difficulties of OoD detection tasks. According to Liang et al. (2020), Lee et al. (2018), and Liu et al. (2020), one of the central challenges for OoD detection tasks in classification models arises from the fact that DNN models are usually over-confident towards InD samples.\n\nFor example, OoD detection on a simple InD dataset like the FashionMNIST Within-Dataset experiment, where the classification accuracy can easily reach 97% (i.e. high predictive confidence for InD data), is not necessarily easier than CIFAR100-Texture Between-Dataset experiments done in Liu et al., 2020, where the classification accuracy is only about 79% (i.e. low predictive confidence). Indeed, this explains why the baseline methods, including OE (Hendrycks et al., 2018), Energy Finetuning (Liu et al. 2020), and VOS (Du et al., 2022) fail to achieve desirable performance on the simpler datasets but can achieve decent performance on those seemingly complex datasets like CIFAR100-Texture according to Liu et al. 2020.\n\nThat said, we have included another set of experiments on CIFAR10-Texture experiments to further highlight the benefits of our approach.\n\nFurthermore, from our experiments, we notice that another critical factor influencing the difficulties of OoD detection tasks is the proximity between InD and OoD samples. This observation motivated the Within-Dataset experiments, where OoD samples come from classes within the same dataset. The idea here was to create situations where InD and OoD samples highly resemble each other and highlight the capability of our model to effectively detect such cases.\n\nWhile in practice, this situation may not be universally applicable, it does represent various real-world situations, such as anomaly detection, where anomalies can manifest as small deviations from the InD samples or their features (Sun et al. 2023)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2761/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700261206562,
                "cdate": 1700261206562,
                "tmdate": 1700261206562,
                "mdate": 1700261206562,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "1q0YuZGfro",
            "forum": "MrslLZmkye",
            "replyto": "MrslLZmkye",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2761/Reviewer_cBKA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2761/Reviewer_cBKA"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a generative adversarial training method leveraging a Wasserstein-score to enhance Out-of-Distribution (OoD) detection accuracy. The approach simultaneously undertakes data augmentation and exploration using a limited set of OoD samples. Additionally, the study offers theoretical assurances, confirming that the optimal solutions derived from generative model can be statistically realized through adversarial training in empirical scenarios."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The method employs a unique exploration strategy to identify regions where the model lacks confidence. By focusing on uncertain regions, SEE-OOD achieves superior performance in detecting OOD samples compared to existing methods. The paper presents extensive experiments and benchmarks to validate the effectiveness of SEE-OOD against other state-of-the-art techniques."
                },
                "weaknesses": {
                    "value": "1. The paper does not provide visualizations of the generated outliers, which could offer more intuitive insights into the model's behavior and decisions.\n2. The evaluation metrics employed in the paper miss out on including the Area Under the Receiver Operating Characteristic (AUROC), which is crucial for understanding model performance in classification tasks, especially in OOD detection.\n3. While the paper presents results on certain datasets, it would benefit from testing on larger and more diverse datasets to ensure the method's generalizability and robustness."
                },
                "questions": {
                    "value": "Please address the weaknesses I've highlighted above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2761/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2761/Reviewer_cBKA",
                        "ICLR.cc/2024/Conference/Submission2761/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2761/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698841234966,
            "cdate": 1698841234966,
            "tmdate": 1700559556307,
            "mdate": 1700559556307,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0Uars7lKqh",
                "forum": "MrslLZmkye",
                "replyto": "1q0YuZGfro",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2761/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2761/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer cBKA"
                    },
                    "comment": {
                        "value": "Dear Reviewer cBKA, we are grateful for your detailed feedback. Please see our following point-to-point responses to address your comments.\n\n## Visualization of OoD samples\n\nThank you for your question on the interpretability of the generated outliers.\n\nGiven that our approach aims at the exploration of OOD spaces, the generated images need not look like observed OOD images. That said, one can add a distance regularization term within our objective to penalize the distance between OoD samples and the generated outliers. With such penalty, the generated images will resemble observed OoD samples. For your interest, we provided two generated images (for the MNIST experiment, where we treat classes 1 and 7 as OoD) with the distance regularization term. We can see meaningful images are generated in these cases, where interpretability is maintained.\n\n- [Example 1](https://github-production-user-asset-6210df.s3.amazonaws.com/82349855/283628983-99d1d7bc-c707-4f95-87bd-c758fb38f200.png)\n- [Example 2](https://github-production-user-asset-6210df.s3.amazonaws.com/82349855/283629133-beaa0b9f-d336-460c-bcef-10b8095d124f.png)\n\nHowever, by imposing the penalty term, the exploration of OoD spaces will be constrained. Indeed, we found that such a constraint will decrease generalization power. This observation also agrees with existing literature showing that such a regularization term led to reduced generalizability (Wang et al. 2021, Liu et al. 2020). Therefore, we decided to remove the penalty term in our final formulation.\n\n## Missing AUROC metrics\n\nWe kindly refer the reviewer to our general response.\n\n## Experiments are limited\n\nWe kindly refer the reviewer to our general response. In addition, we would like to communicate the following perspectives with the reviewer.\n\n### Are the difficulties of OoD detection tasks determined by the complexities of datasets?\n\nIt is critical to point out that the complexity of the InD and OoD datasets is not the only factor that influences the difficulties of OoD detection tasks. According to Liang et al. (2020), Lee et al. (2018), and Liu et al. (2020), one of the central challenges for OoD detection tasks in classification models arises from the fact that DNN models are usually over-confident towards InD samples.\n\nFor example, OoD detection on a simple InD dataset like the FashionMNIST Within-Dataset experiment, where the classification accuracy can easily reach 97% (i.e. high predictive confidence for InD data), is not necessarily easier than CIFAR100-Texture Between-Dataset experiments done in Liu et al., 2020, where the classification accuracy is only about 79% (i.e. low predictive confidence). Indeed, this explains why the baseline methods, including OE (Hendrycks et al., 2018), Energy Finetuning (Liu et al. 2020), and VOS (Du et al., 2022) fail to achieve desirable performance on the simpler datasets but can achieve decent performance on those seemingly complex datasets like CIFAR100-Texture according to Liu et al. 2020.\n\nThat said, we have included another set of experiments on CIFAR10-Texture experiments to further highlight the benefits of our approach.\n\nFurthermore, from our experiments, we notice that another critical factor influencing the difficulties of OoD detection tasks is the proximity between InD and OoD samples. This observation motivated the Within-Dataset experiments, where OoD samples come from classes within the same dataset. The idea here was to create situations where InD and OoD samples highly resemble each other and highlight the capability of our model to effectively detect such cases. While in practice, this situation may not be universally applicable, it does represent various real-world situations, such as anomaly detection, where anomalies can manifest as small deviations from the InD samples or their features (Sun et al. 2023)."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2761/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700261041236,
                "cdate": 1700261041236,
                "tmdate": 1700261041236,
                "mdate": 1700261041236,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rwA2FUy5Q9",
                "forum": "MrslLZmkye",
                "replyto": "0Uars7lKqh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2761/Reviewer_cBKA"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2761/Reviewer_cBKA"
                ],
                "content": {
                    "comment": {
                        "value": "After a comprehensive examination of the authors' responses to the raised questions and the feedback provided by other reviewers, I have made the decision to revise my initial score to \"reject.\" As I highlighted in my initial review, I continue to believe that the paper could significantly improve by incorporating more intuitive insights into the model's behavior and decision-making process, as well as by conducting testing on larger and more diverse datasets. At the moment, it is still uncertain whether the model demonstrates satisfactory performance."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2761/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700559525311,
                "cdate": 1700559525311,
                "tmdate": 1700559525311,
                "mdate": 1700559525311,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "cwzn3A7dLc",
            "forum": "MrslLZmkye",
            "replyto": "MrslLZmkye",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2761/Reviewer_Qajt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2761/Reviewer_Qajt"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies OOD detection relying on real OOD samples in training. It proposes a method to generate more OOD samples in training based on Wasserstein-score-based generative adversarial learning. Experiments show that the proposed method can achieve good OOD detection performance, given more OOD samples in training."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The method can achieve good performance on the experimented settings and datasets, which matches the assumptions that seeing real OOD samples can help OOD detection in testing. \n- The experiments studied the two settings with balanced or imbalanced OOD samples in training. \n- The paper is written clearly."
                },
                "weaknesses": {
                    "value": "- Some arguments and claims are the paper are impervious or unfaithful. \n    - The real OOD samples are not used in many methods because the OOD samples are unknown/unpredictable in training. Handling OOD detection without OOD samples in training is a more general and real setting, instead of a drawback. It is reasonable to use some OOD samples to perform \u201coutlier exposure\u201d. However, the related works are not discussed in the paper. \n\n- The experiments are limited.\n    - The experiments only cover the simple datasets and settings as shown in Table 2. The \u201cwithin-dateset\u201d setting and the used datasets are simple. And the dataset used in \u201cbetween-dataset\u201d setting are also not complex enough the validate the methods. That\u2019s also why the proposed method can easily achieve very high performance after seeing real OOD samples. More \u201cbetween-dataset\u201d settings should be considered as more recent OOD detection papers, such as (Liu et al., 2020).\n    - The compared methods are limited and unfair. Many OOD detection methods using OOD samples in training are not discussed and compared, such as the \u201coutlier exposure\u201d based methods (\u201cDeep Anomaly Detection with Outlier Exposure\u201d).\n    - Some recent strong OOD detection methods are not discussed or compared, such as\nNon-Parametric Outlier Synthesis, ICLR 2023.\nHow to Exploit Hyperspherical Embeddings for Out-of-Distribution Detection?, ICLR 2023.\n    - Many strong OOD detection do not use OOD samples in training (in the more general and real setting) but have strong modeling. But it is straightforward to introduce the known OOD samples in the training process easily. The authors should consider this case and conduct comparisons, especially considering the experimented settings and datasets are very simple."
                },
                "questions": {
                    "value": "Please address the questions mentioned in the weakness, especially those about experiments."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2761/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698905535568,
            "cdate": 1698905535568,
            "tmdate": 1699636218688,
            "mdate": 1699636218688,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9bKIJvyYcf",
                "forum": "MrslLZmkye",
                "replyto": "cwzn3A7dLc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2761/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2761/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer Qajt"
                    },
                    "comment": {
                        "value": "Dear Reviewer Qajt, we are grateful for your detailed feedback. Please see our following point-to-point responses to your comments.\n\n# Some arguments are impervious or unfaithful\n\nBased on your comments, we added more explanations to clarify our paper's goal and to justify the rationale and advantages of our method. We kindly refer the reviewer to our \"general response\".\n\n# Experiments are limited\n\n## 1. Datasets are simple\n\nWe address this question in our \"general response\". Specifically, we followed your suggestion and included one more Between-Dataset experiment on the CIFAR10 and Texture dataset introduced in Liu et al. 2020. In addition, we would like to communicate the following perspective with the reviewer.\n\n### Are the difficulties of OoD detection tasks determined by the complexities of datasets?\n\nIt is critical to point out that the complexity of the InD and OoD datasets is not the only factor that influences the difficulties of OoD detection tasks. According to Liang et al. (2020), Lee et al. (2018), and Liu et al. (2020), one of the central challenges for OoD detection tasks in classification models arises from the fact that DNN models are usually over-confident towards InD samples.\n\nFor example, OoD detection on a simple InD dataset like the FashionMNIST Within-Dataset experiment, where the classification accuracy can easily reach 97% (i.e. high predictive confidence for InD data), is not necessarily easier than CIFAR100-Texture Between-Dataset experiments done in Liu et al., 2020, where the classification accuracy is only about 79% (i.e. low predictive confidence). Indeed, this explains why the baseline methods, including OE (Hendrycks et al., 2018), Energy Finetuning (Liu et al. 2020), and VOS (Du et al., 2022) fail to achieve desirable performance on the simpler datasets but can achieve decent performance on those seemingly complex datasets like CIFAR100-Texture according to Liu et al. 2020.\n\nThat said, we have included another set of experiments on CIFAR10-Texture experiments to further highlight the benefits of our approach.\n\nFurthermore, from our experiments, we notice that another critical factor influencing the difficulties of OoD detection tasks is the proximity between InD and OoD samples. This observation motivated the Within-Dataset experiments, where OoD samples come from classes within the same dataset. The idea here was to create situations where InD and OoD samples highly resemble each other and highlight the capability of our model to effectively detect such cases.\n\n## 2. Baselines are missing\n\nWe kindly refer the reviewer to our \"general response\".\n\n## 3. Recent strong OoD detection methods are not compared\n\nWe want to thank the reviewer for pointing out these two excellent papers which came out in May 2023. However, we have to respectfully mention that it is a rare request to conduct a comparison study with the methods that are officially published four months prior to the submission deadline.\n\n## 4. It is straightforward to introduce OoD samples in the training process\n\nPlease refer to our responses in the \"general response\", where we reiterate the main contributions of this paper. Secondly, we respectfully disagree with Reviewer Qajt's comment suggesting that incorporating OoD samples into the training process is straightforward. It is, instead a very challenging task that needs to be done carefully. There are three primary reasons for this:\n\n- Methods that solely rely on existing OoD samples without exploring OoD spaces, such as Energy Finetuning (Liu et al., 2020), WOOD (Wang et al., 2021), and OE (Hendrycks et al., 2018), fail to detect OoD samples not encountered in the training process, leading to poor generalizability. The main pitch of our method is to effectively use observed OoD samples to perform iterative exploration of OoD spaces. Our experimental results in the imbalanced regime substantiate this claim.\n- Existing methods that exploit OoD samples are susceptible to overfitting when OoD samples are scarce in the training dataset, as demonstrated in our experiments. In such cases, augmenting the limited OoD samples is desirable, particularly in the original image space rather than the feature space. This is because feature spaces may exhibit high overlap, even for images that appear vastly different.\n- We agree with Reviewer Qajt that many methods that do not use OoD samples have strong modeling. However, their modeling approach is mainly based on operations (including exploration) within InD spaces (Du et al. 2022; Ming et al. 2022; Lee et al. 2017). In these cases, there is no straightforward method to incorporate OoD samples during the training stage. Introducing OoD samples naively using score regularization is likely to give rise to the aforementioned two problems."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2761/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700260758903,
                "cdate": 1700260758903,
                "tmdate": 1700260758903,
                "mdate": 1700260758903,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]