[
    {
        "title": "FairSeg: A Large-scale Medical Image Segmentation Dataset for Fairness Learning with Fair Error-Bound Scaling"
    },
    {
        "review": {
            "id": "TywQCUSi08",
            "forum": "qNrJJZAKI3",
            "replyto": "qNrJJZAKI3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7468/Reviewer_f8dv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7468/Reviewer_f8dv"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed a dataset for retinal disc/cup segmentation with several pre-defined attributes, which should be useful for studying the fairness problem in the medical domain. Furthermore, the authors set a baseline for the problem and define the evaluation metrics in this scenario. Overall, this work is sound and meaningful."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "[1] Providing a dataset for fairness-related research is meaningful for the current community, along with its baseline and evaluation setting.\n\n[2] Good writing and clear motivation"
                },
                "weaknesses": {
                    "value": "[1] ICLR might not be the best place for this paper. Other medical journals or conferences would be more suitable.\n\n[2] There are many evaluation ways to assess the fairness problem. The selected metrics might not be the most suitable one. Please elaborate more on the motivation of baseline setting and evaluation.\n\n[3] Some current works should be included to make the experiments sufficient. See: FairAdaBN: Mitigating unfairness with adaptive batch normalization and its application to dermatological disease classification\n\n[4] Since most of the attributes are only for the patient level, why use the pixel-wise weights?"
                },
                "questions": {
                    "value": "See the above weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Responsible research practice (e.g., human subjects, data release)"
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "This work proposed a retinal dataset with several attributes, which should be further checked from the ethics view."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7468/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7468/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7468/Reviewer_f8dv"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7468/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697507856167,
            "cdate": 1697507856167,
            "tmdate": 1699636900589,
            "mdate": 1699636900589,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ypMhyPJ6Be",
                "forum": "qNrJJZAKI3",
                "replyto": "TywQCUSi08",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7468/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7468/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer f8dv"
                    },
                    "comment": {
                        "value": "Thank you so much for your review and the insightful comments.\n\n\n**ICLR might not be the best place for this paper. Other medical journals or conferences would be more suitable.**\n\nOur primary contribution centers on fairness in machine learning, rather than on medical imaging itself. We regard medical imaging as a crucial area for studying fairness, given its human-centric nature and the potentially severe consequences of unfairness in medical deep learning systems in real-world scenarios.\n\n\n**There are many evaluation ways to assess the fairness problem. The selected metrics might not be the most suitable one. Please elaborate more on the motivation of baseline setting and evaluation.**\n\n\nWe introduced a novel metric for assessing fairness in medical segmentation, called Equity-Scaled Segmentation Performance (ESSP). ESSP offers a more direct and clinician-friendly evaluation compared to traditional fairness metrics like DPD and DEOdds. Unlike DPD and DEOdds, which may overlook overall performance, leading to a situation where a model with uniformly lower performance across all demographics could falsely appear fairer. This misalignment is particularly problematic in safety-critical medical applications, which demand high accuracy.  In contrast, our proposed ESSP addresses this issue. It evaluates not only the disparity across different demographic groups but also measures the extent to which overall segmentation accuracy is compromised to achieve a fairer model. A higher ESSP score indicates a model that achieves both fairness and high accuracy.\n\nAlongside ESSP, according to the reviewer\u2019s suggestion, we have also updated the DPD and DEOdds results in the supplementary material, providing a comprehensive fairness assessment of various segmentation approaches. As the table below illustrates, our FEBS (Fairness-Enhanced Biased Segmentation) approach outperforms previous methods in terms of DPD and DEOdds, highlighting its effectiveness in achieving fairer outcomes in medical imaging. From the table below, we show that our method achieves comparable DPD and DEodds performances when compared against other segmentation methods. \n\n|      | Method            | Overall DPD | Overall DEodds |\n|------|-------------------|-------------|----------------|\n| Cup  | SAMed             | 0.0085      | 0.0196         |\n|      | SAMed+ADV         | 0.0079      | 0.0071         |\n|      | SAMed+GroupDRO    | 0.0078      | 0.0154         |\n|      | Ours (SAMed)      | 0.0079      | 0.0020         |\n|      | TransUNet         | 0.0083      | 0.0430         |\n|      | TransUNet+ADV     | 0.0074      | 0.0389         |\n|      | TransUNet+GroupDRO| 0.0081      | 0.0317         |\n|      | Ours (TransUNet)  | 0.0085      | 0.0492         |\n| Rim  | SAMed             | 0.0005      | 0.0670         |\n|      | SAMed+ADV         | 0.0004      | 0.0657         |\n|      | SAMed+GroupDRO    | 0.0009      | 0.0792         |\n|      | Ours (SAMed)      | 0.0002      | 0.0715         |\n|      | TransUNet         | 0.0014      | 0.0877         |\n|      | TransUNet+ADV     | 0.0025      | 0.0708         |\n|      | TransUNet+GroupDRO| 0.0018      | 0.0699         |\n|      | Ours (TransUNet)  | 0.0014      | 0.0822         |\n\n\n\n**Some current works should be included to make the experiments sufficient. See: FairAdaBN: Mitigating unfairness with adaptive batch normalization and its application to dermatological disease classification.**\n\n\n\nFairAdaBN was originally proposed for classification tasks, not segmentation, and necessitated modifications to the backbone architectures of classification models. However, with the advent of recent large-scale segmentation models like Meta's SAM, these models require fine-tuning with pre-trained weights for optimal performance. Altering the architecture, as in the case of FairAdaBN, might hinder the loading of these pre-trained parameters, which are trained from extensive datasets, potentially leading to lower segmentation accuracy. Additionally, FairAdaBN was initially applied to a ResNet, and adapting it to Transformer-based segmentation models also presents challenges. Thus, we suggest that further investigation is needed before applying FairAdaBN to segmentation tasks. We have cited and discussed FairAdaBN in our related work section, and we aim to integrate the FairAdaBN approach into our future research.\n\n\n**Since most of the attributes are only for the patient level, why use the pixel-wise weights?**\n\nPatients from various demographic groups may exhibit different anatomical characteristics. For example, Black people often have a larger cup-to-disc ratio and cup area compared to other races. These anatomical differences can influence segmentation accuracy. To address this, we employ pixel-wise weights to accommodate these underlying anatomical variations within the fundus images."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7468/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700695957107,
                "cdate": 1700695957107,
                "tmdate": 1700695957107,
                "mdate": 1700695957107,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "uQKzOl8mxK",
            "forum": "qNrJJZAKI3",
            "replyto": "qNrJJZAKI3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7468/Reviewer_b2i2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7468/Reviewer_b2i2"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed a fundus image dataset for benchmarking the fairness of medical image segmentation methods, which is the first dataset and benchmark in this field. The authors also proposed to rescale the loss function with the upper training error-bound of each identity group to tackle the fairness issue."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Novel Dataset: The paper introduced FairSeg, a new dataset for medical image segmentation with a focus on fairness. The creation of such a dataset is valuable as it addresses a gap in the current availability of medical datasets with fairness considerations.\n\n- Fairness-Oriented Methodology: The authors proposed a fair error-bound scaling approach and an equity scaling metric. These methods represent an advanced effort to integrate fairness directly into the model training process, which could lead to more equitable healthcare outcomes.\n\n- Open Access: I like that the author released the dataset and code for reproducibility and further research, which is a strong aspect of this work."
                },
                "weaknesses": {
                    "value": "- Dice and IoU are equivalent (https://www.sciencedirect.com/science/article/pii/S1361841521000815), which are not necessary to be reported simultaneously. Instead, please add NSD which is suggested by metrics reloaded (https://arxiv.org/abs/2206.01653).\n\n- nnUNet is still the state-of-the-art in many segmentation tasks. It would be great to evaluate it on your dataset."
                },
                "questions": {
                    "value": "- The dataset was released as npz format. Could you please also release the original format?\n\n- It would be great if you could release the trained models as well.\n\n- Where do you plan to host this benchmark? CodaLab could be a good platform."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7468/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698784223461,
            "cdate": 1698784223461,
            "tmdate": 1699636900403,
            "mdate": 1699636900403,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oyxNTq56xr",
                "forum": "qNrJJZAKI3",
                "replyto": "uQKzOl8mxK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7468/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7468/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer b2i2"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the positive and encouraging review. \n\n**Please add NSD which is suggested by metrics reloaded.**\n\nDice and IoU are commonly used by previous research [1,2,3]. For the sake of future comparison and completeness, we will keep the Dice and IoU in the table, and add NSD as the additional metric. Furthermore, we have included the NSD results for race as table below. The table indicates that unfairness commonly exists in our proposed fair segmentation task, which further strengthens the contribution of our FairSeg dataset. We have added those results in the supplementary material.  \n\n|      |                       | **Overall NSD\u2191** | **Asian NSD\u2191** | **Black NSD\u2191** | **White NSD\u2191** |\n|------|-----------------------|------------------|----------------|----------------|----------------|\n| **Cup**|                     |                   |                  |                |                |\n| |SAMed                       | 0.7222            | 0.6825           | 0.6871         | 0.7338         |\n| |SAMed+ADV                   | 0.7405            | 0.7045           | 0.6954         | 0.7537         |\n| |SAMed+GroupDRO              | 0.7415            | 0.7093           | 0.6942         | 0.7547         |\n| |**Ours (SAMed)**            | 0.7399            | 0.7038           | 0.7015         | 0.7518         |\n| |TransUNet                   | 0.9314            | 0.8845           | 0.8908         | 0.9449         |\n| |TransUNet+ADV               | 0.9208            | 0.8819           | 0.8817         | 0.9331         |\n| |TransUNet+GroupDRO          | 0.9285            | 0.8768           | 0.8873         | 0.9426         |\n| |**Ours (TransUNet)**        | 0.9262            | 0.8796           | 0.8850         | 0.9397         |\n| **Rim**  |                   |                   |                  |                |                |\n| |SAMed                       | 0.7483            | 0.7313           | 0.7215         | 0.7556         |\n| |SAMed+ADV                   | 0.8063            | 0.7694           | 0.7686         | 0.8182         |\n| |SAMed+GroupDRO              | 0.8078            | 0.7760           | 0.7696         | 0.8191         |\n| |**Ours (SAMed)**            | 0.8043            | 0.7732           | 0.7704         | 0.8146         |\n| |TransUNet                   | 0.9601            | 0.9326           | 0.9326         | 0.9688         |\n| |TransUNet+ADV               | 0.9554            | 0.9245           | 0.9221         | 0.9656         |\n| |TransUNet+GroupDRO          | 0.9596            | 0.9322           | 0.9307         | 0.9685         |\n| |**Ours (TransUNet)**        | 0.9581            | 0.9306           | 0.9315         | 0.9666         |\n\n\n**Add nnUNet.**\n\nWe have included nnUNet in our segmentation benchmarks, which are detailed in the supplementary material. The table provided below presents results focusing on racial disparities. From the table, it is evident that nnUNet demonstrates marginally better performance compared to SAMed and TransUNet. However, it still exhibits significant performance disparities across different racial groups. This suggests that algorithmic unfairness is a pervasive issue in our proposed cup-disc segmentation, regardless of the choice of segmentation architectures.\n\n\n|       | Method | Overall ES-Dice\u2191 | Overall Dice\u2191 | Overall ES-IoU\u2191 | Overall IoU\u2191 | Asian Dice\u2191 | Black Dice\u2191 | White Dice\u2191 | Asian IoU\u2191 | Black IoU\u2191 | White IoU\u2191 |\n|-------|--------|------------------|---------------|-----------------|--------------|-------------|-------------|-------------|------------|------------|------------|\n| Cup   | nnUNet | 0.8625           | 0.8710        | 0.7704          | 0.7865       | 0.8675      | 0.8855      | 0.8697      | 0.7639     | 0.8035     | 0.7725     |\n| Rim   | nnUNet | 0.8003           | 0.8335        | 0.6959          | 0.7231       | 0.7930      | 0.7682      | 0.8490      | 0.6854     | 0.6639     | 0.7397     |\n\n\n**The dataset was released as npz format. Could you please also release the original format?**\n\nWe will release the dataset with the original format in addition to the existing npz format of our database. \n\n**It would be great if you could release the trained models as well.**\n\nThe trained checkpoints of our models have been released through our Github repository. \n\n**Where do you plan to host this benchmark? CodaLab could be a good platform.**\n\nWe will co-host our benchmark/dataset using both Google Drive and CodaLab. \n \n**Reference:**\n\n[1] Kirillov, Alexander, et al. \"Segment anything.\" arXiv preprint arXiv:2304.02643 (2023).\n\n[2] Zhang, Kaidong, and Dong Liu. \"Customized segment anything model for medical image segmentation.\" arXiv preprint arXiv:2304.13785 (2023).\n\n[3] Chen, Jieneng, et al. \"Transunet: Transformers make strong encoders for medical image segmentation.\" arXiv preprint arXiv:2102.04306 (2021)."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7468/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700695719511,
                "cdate": 1700695719511,
                "tmdate": 1700695745902,
                "mdate": 1700695745902,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "w9QoDjt3kw",
            "forum": "qNrJJZAKI3",
            "replyto": "qNrJJZAKI3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7468/Reviewer_5cUh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7468/Reviewer_5cUh"
            ],
            "content": {
                "summary": {
                    "value": "In this work, the authors introduced the new FairSeg dataset, designed to address fairness concerns in the domain of medical segmentation. Their innovative methodology centers on a fair error-bound scaling technique, which recalibrates the loss function by considering the upper error-bound within each identity group. Furthermore, they designed a new equity-scaled segmentation performance metric to facilitate fair comparisons between different fairness learning models for medical segmentation. Extensive experimentation underscores the efficacy of the fair error-bound scaling approach, demonstrating either superior or comparable fairness performance when compared to state-of-the-art fairness learning models. Furthermore, The related dataset and code are both made publicly accessible by the authors."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "+ The paper is well-written and easy to follow. \n+ The proposed framework is technically sound.\n+ The experiments are comprehensive."
                },
                "weaknesses": {
                    "value": "There is no visualization comparison between different methods."
                },
                "questions": {
                    "value": "1. In equation (1), a parenthesis is missing in the formula.\n2. The authors proposed a new the Dice loss with a novel Fair Error-Bound Scaling mechanism, however there are experiment results to show the differences between the new dice loss and common one."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7468/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698850170617,
            "cdate": 1698850170617,
            "tmdate": 1699636900064,
            "mdate": 1699636900064,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8iBvZ9YWy6",
                "forum": "qNrJJZAKI3",
                "replyto": "w9QoDjt3kw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7468/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7468/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 5cUh"
                    },
                    "comment": {
                        "value": "Thank you very much for your review and the insightful comments.\n\n\n**There is no visualization comparison between different methods.**\n\nWe have added a visualization comparison of segmentation results between our method and other competing approaches.\n\n**In equation (1), a parenthesis is missing in the formula.**\n\nWe have addressed the formatting issue in the paper. \n\n**The authors proposed a new Dice loss with a novel Fair Error-Bound Scaling mechanism, however, there are experiment results to show the differences between the new dice loss and the common one.**\n\nAs mentioned in Section 6.2 - \u201cTraining and Implementation Details\u201d, the original SAMed and TransUNet are trained using cross entropy and the common dice losses. Hence, in Tables 1-5,  the results between SAMed vs SAMed (Ours) / TransUNet vs. TransUNet (Ours) are the performance comparisons for the new proposed dice loss and the common one."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7468/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700695337348,
                "cdate": 1700695337348,
                "tmdate": 1700695337348,
                "mdate": 1700695337348,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "uYaRh16bmB",
            "forum": "qNrJJZAKI3",
            "replyto": "qNrJJZAKI3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7468/Reviewer_Suah"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7468/Reviewer_Suah"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a publicly available medical fairness segmentation dataset (FairSeg) that contains 10,000 subject samples of 2D SLO Fundus images. The paper also proposes equity-scaled segmentation performance metrics to facilitate fair comparisons."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1. The fairness concern is an important topic, especially in medical images and the lack of segmentation dataset is a big issue. The motivation of the proposed dataset is strong.\n\n2. The dataset contains a large amount of segmentation ground truths (10,000) and is well evaluated by authors with several SOTA learning algorithms.\n\n3. As described by the authors, the segmentation seems to undergo a rigorous process including a hand-graded annotation by a panel of five medical professionals after initial registration."
                },
                "weaknesses": {
                    "value": "1. The accuracy of the Nifty reg needs to be investigated since it might not be the SOTA for image registration."
                },
                "questions": {
                    "value": "1. Why validation set is not constructed/used in selecting models in training?\n\n2. It would be helpful to report Hausdorff distance and average surface distance along with Dice to better evaluate the methods.\n\n3. The details of how standard deviation is computed need to be elaborated. Is it computed across the mean of for each group?\n\n4. How is the training/testing split performed? Is it just randomly sampled without considering sensitive attributes at patient level?\n\n5. It would be helpful to discuss the importance of registration in preprocessing using NiftyReg."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7468/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7468/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7468/Reviewer_Suah"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7468/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699233898000,
            "cdate": 1699233898000,
            "tmdate": 1699636899772,
            "mdate": 1699636899772,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YOvmQcaYNl",
                "forum": "qNrJJZAKI3",
                "replyto": "uYaRh16bmB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7468/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7468/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Suah (Part 1)"
                    },
                    "comment": {
                        "value": "Thank you very much for the supportive comments and valuable suggestions!\n\n\n**The accuracy of the Nifty reg needs to be investigated since it might not be the SOTA for image registration.**\n\nIn Section 4, we mentioned that \u201cIt\u2019s noteworthy that this registration operation demonstrates considerable precision in real-world scenarios, as evident from our empirical observations that highlight an approximate 80% success rate in registrations.\u201d  During experiments, we have compared Niftyreg against the SOTA deep learning based approach [1] and a retinal image-based registration method [2]. We observed that NiftyReg is more robust than other registration methods. Upon further analysis, we have calculated that NiftyReg achieves an accuracy of roughly 82.4% in registration tasks. All the failed registration cases have been excluded by five professional clinician graders.\nAlthough there is a failure rate of about 20%, we are committed to ongoing exploration of state-of-the-art (SOTA) registration tools, including contemporary deep learning-based methods. Our aim is to enhance registration accuracy and, consequently, to release more images in our datasets during our future work.\n\n**Why validation set is not constructed/used in selecting models in training?**\n\nGiven that our model is selected based on the last epoch of training. The finetuning of foundation models like SAM could be computationally expensive for both training and inference. This makes computing the validation accuracy every few epochs and selecting the checkpoints based on the accuracy is infeasible.\n\nTo better facilitate future research, we have released an extra 500 images as the validation set in our codebase and dataset.\n\n**Report Hausdorff distance and average surface distance along with Dice.**\n\n\nPlease see the table below for Hausdorff distance (HD95) and average surface distance (ASD) for race. We have included such metrics across all sensitive attributes in the supplementary material. From table below, we observed that the disparity between different demographic groups commonly existed regardless of its evaluation metrics, which further strengthened the significance of our proposed FairSeg dataset.  \n\n\n|      | Method               | Overall HD95\u2193 | Asian HD95\u2193 | Black HD95\u2193 | White HD95\u2193 | Overall ASD\u2193 | Asian ASD\u2193 | Black ASD\u2193 | White ASD\u2193 |\n|------|----------------------|---------------|-------------|-------------|-------------|--------------|------------|------------|------------|\n| **Cup**  | SAMed                | 9.6231        | 11.0005     | 11.0142     | 9.1866      | 3.9650       | 4.6765     | 4.7743     | 3.7209     |\n|      | SAMed+ADV            | 9.4594        | 11.0170     | 11.1193     | 8.9479      | 4.0123       | 4.8623     | 4.9236     | 3.7321     |\n|      | SAMed+GroupDRO       | 9.4633        | 11.0891     | 11.0449     | 8.9603      | 3.9494       | 4.6462     | 4.8634     | 3.6855     |\n|      | Ours (SAMed)         | 9.4494        | 10.8376     | 11.1637     | 8.9453      | 3.9288       | 4.7042     | 4.8210     | 3.6606     |\n|      | TransUNet            | 4.7577        | 5.6983      | 5.5411      | 4.4937      | 2.0552       | 2.3692     | 2.4573     | 1.9382     |\n|      | TransUNet+ADV        | 5.0157        | 5.9379      | 5.8292      | 4.7476      | 2.1319       | 2.4693     | 2.4978     | 2.0198     |\n|      | TransUNet+GroupDRO   | 4.8195        | 5.6424      | 5.6753      | 4.5535      | 2.0615       | 2.3637     | 2.4952     | 1.9393     |\n|      | Ours (TransUNet)     | 4.9603        | 5.8818      | 5.7398      | 4.6992      | 2.1441       | 2.4641     | 2.5445     | 2.0268     |\n| **Rim**  | SAMed                | 9.9379        | 11.4859     | 11.5671     | 9.4337      | 3.9353       | 4.5013     | 4.5473     | 3.7476     |\n|      | SAMed+ADV            | 8.8316        | 10.5364     | 10.2364     | 8.3562      | 3.3523       | 3.9946     | 3.8975     | 3.1700     |\n|      | SAMed+GroupDRO       | 8.7609        | 10.4638     | 10.0592     | 8.3076      | 3.3473       | 3.8345     | 3.9499     | 3.1702     |\n|      | Ours (SAMed)         | 8.7930        | 10.3167     | 10.3407     | 8.3082      | 3.4174       | 4.0053     | 4.0608     | 3.2208     |\n|      | TransUNet            | 4.4404        | 5.4496      | 5.0893      | 4.1964      | 1.7534       | 1.9643     | 1.9941     | 1.6809     |\n|      | TransUNet+ADV        | 4.6301        | 5.6065      | 5.4390      | 4.3569      | 1.8110       | 2.1085     | 2.0885     | 1.7213     |\n|      | TransUNet+GroupDRO | 4.5268 | 5.4243 | 5.2290 | 4.2842 | 1.7498 | 1.9683 | 2.0017 | 1.6742 |\n|      | Ours (TransUNet)   | 4.5311 | 5.5251 | 5.2808 | 4.2682 | 1.8321 | 2.0642 | 2.0771 | 1.7564 |"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7468/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700694907560,
                "cdate": 1700694907560,
                "tmdate": 1700696121972,
                "mdate": 1700696121972,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yDrTsgKcWe",
                "forum": "qNrJJZAKI3",
                "replyto": "uYaRh16bmB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7468/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7468/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Suah (Part 2)"
                    },
                    "comment": {
                        "value": "**The details of how standard deviation is computed need to be elaborated. Is it computed across the mean of for each group?**\n\nThe computational cost of multiple runs with large segmentation foundation models is high. Previous studies  [3, 4]  typically evaluate these models only once, without standard deviation, rather than conducting multiple runs of evaluations.\n\n**How is the training/testing split performed? Is it just randomly sampled without considering sensitive attributes at patient level?**\n\nThe training and testing split are just randomly sampled, and our sample distribution of different sensitive attributes reflects the real-world clinical patient distribution.\n \n**It would be helpful to discuss the importance of registration in preprocessing using NiftyReg.**\n\nAs mentioned above and in Section 4/Figure 1, to obtain a large-scale fundus dataset with high-quality pixel-wise annotation, we need to use the OCT machine to generate the OCT fundus images and their corresponding cup-disc mask. However, OCT machines are fairly expensive and less prevalent in primary care, therefore, we propose to migrate those annotations from 3D OCT to 2D SLO fundus for potentially broader impact in early-stage glaucoma screening in the primary care domains. In order to transfer the annotations from 3D OCT fundus images to 2D SLO fundus images, we need to register the image to align the two imaging modalities by comparing the characteristic features between the two fundus imaging modalities of the same patient.  The computed alignment matrix is then applied to the disc-cup masks of the OCT fundus images, aligning them to the SLO fundus images. \n\t\t\t\t\n\t\t\t\n\t\t\n\n \n**Reference:**\n\n[1] Hoopes, Andrew, et al. \"Hypermorph: Amortized hyperparameter learning for image registration.\" Information Processing in Medical Imaging: 27th International Conference, IPMI 2021, Virtual Event, June 28\u2013June 30, 2021, Proceedings 27. Springer International Publishing, 2021.\n\n[2] https://github.com/tobiaselze/oct_fundus_registration/tree/main \n\n[3] Kirillov, Alexander, et al. \"Segment anything.\" arXiv preprint arXiv:2304.02643 (2023).\n\n[4] Zhang, Kaidong, and Dong Liu. \"Customized segment anything model for medical image segmentation.\" arXiv preprint arXiv:2304.13785 (2023)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7468/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700695100453,
                "cdate": 1700695100453,
                "tmdate": 1700695100453,
                "mdate": 1700695100453,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]