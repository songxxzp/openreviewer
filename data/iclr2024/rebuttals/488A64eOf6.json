[
    {
        "title": "Language Model Decoding as Direct Metrics Optimization"
    },
    {
        "review": {
            "id": "0CztOpBNOp",
            "forum": "488A64eOf6",
            "replyto": "488A64eOf6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3166/Reviewer_aJdn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3166/Reviewer_aJdn"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes to frame the decoding for natural language generation as a direct metric optimization problem, aiming to generate texts that can align with human texts. To achieves this, the authors select a set of evaluation metric that reflects the quality of generation as constraints and then find the optimal solution to the optimization problem. The authors evaluate their method on a bunch of tasks and report performance in several metrics. According to the results, the proposed method achieves better performance than other decoding strategies such as Greedy, Top-k, and Nucleus decoding."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is well-written and easy to follow.\n- The proposed method seems to be intuitive and effective. \n- The authors provide detailed proof of all the propositions, which is highly appreciated."
                },
                "weaknesses": {
                    "value": "- I don't have any big concerns about the paper. However, I have a question regarding the choice of the metric (see questions below)."
                },
                "questions": {
                    "value": "- Some evaluation metrics might contradict each other. For example, diversity and coherence are hard to achieve at the same time, as far as I know. I am wondering how the results will be if a different set of metrics is used."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3166/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3166/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3166/Reviewer_aJdn"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3166/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698005864729,
            "cdate": 1698005864729,
            "tmdate": 1699636264152,
            "mdate": 1699636264152,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "l9JuhNc9zk",
                "forum": "488A64eOf6",
                "replyto": "0CztOpBNOp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3166/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3166/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer aJdn"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the appreciation of our work!\n\nRegarding the question raised by the reviewer:\n\n>Q1. Some evaluation metrics might contradict each other. For example, diversity and coherence are hard to achieve at the same time, as far as I know. I am wondering how the results will be if a different set of metrics is used.\n\n1. We should clarify that our goal is **not** to **maximize** all these metrics simultaneously. Instead, our aim is to realize **alignment** with human texts, i.e., our method should generate texts that achieve the same level as human texts evaluated under different metrics. Compared with maximization, *the goal of alignment is achievable in principle*, as human texts themselves perform as a natural demonstration. And therefore, this principle is independent from what types of metrics are employed in our method.\n\n2. Coherence and diversity do not necessarily contradict with each other, but are two important aspects in evaluating text generation models [1]. Merely optimizing towards one metric will result in highly biased models [2]. Due to the limitation of model capacity and expressiveness, it is challenging for existing models to maximize both coherence and diversity, so that it might leave us the impression that these two metrics contradict each other. However, the goal of aligning to the coherence and diversity of human texts is achievable (mentioned by statement 1). As demonstrated in our empirical evaluations, our method is able to achieve **human-level** coherence and diversity (Figure 2 of our original manuscript).\n\n**References:**\n\n[1] Montahaei et al., Jointly Measuring Diversity and Quality in Text Generation Models. NAACL 2019.\n\n[2] Caccia et al., Language gans falling short. ICLR 2020."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3166/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700065273721,
                "cdate": 1700065273721,
                "tmdate": 1700065273721,
                "mdate": 1700065273721,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "B8oWaoFiSR",
                "forum": "488A64eOf6",
                "replyto": "l9JuhNc9zk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3166/Reviewer_aJdn"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3166/Reviewer_aJdn"
                ],
                "content": {
                    "comment": {
                        "value": "Dear authors,\n\nThank you for your response. My previous questions have been answered. \n\nI have a new question though regarding the added experiments in Appendix H. When one only optimizes for a single metric at decoding time, it seems the performance difference is small. One would expect that the score of, e.g., COH is higher when you optimize COH metric. But it seems it is not the case. Do you have any explanations or intuitions for this?"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3166/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700471547685,
                "cdate": 1700471547685,
                "tmdate": 1700471547685,
                "mdate": 1700471547685,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bEwXqLdy9X",
                "forum": "488A64eOf6",
                "replyto": "0CztOpBNOp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3166/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3166/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer aJdn"
                    },
                    "comment": {
                        "value": "We highly appreciate the reviewer\u2019s timely response and the new question for us to clarify the purpose and design of our newly reported experiments!\n\nAs noted in the first point in our previous response: our optimization goal is **not** to **maximize** all these metrics, but instead **align** with the performance of human texts on these metrics, simultaneously. As a result, when the COH metric is optimized, it is supposed to be the closest to the COH of the human reference, which is confirmed in our experiment. Please feel free to let us know if this helps resolve your concern!"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3166/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700475219688,
                "cdate": 1700475219688,
                "tmdate": 1700475547393,
                "mdate": 1700475547393,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wav1qBGKuV",
                "forum": "488A64eOf6",
                "replyto": "bEwXqLdy9X",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3166/Reviewer_aJdn"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3166/Reviewer_aJdn"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your reply. I think it is good work and I will keep my scores the same (8: accept, good paper)."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3166/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700519151987,
                "cdate": 1700519151987,
                "tmdate": 1700519151987,
                "mdate": 1700519151987,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "G7gEFoShEo",
            "forum": "488A64eOf6",
            "replyto": "488A64eOf6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3166/Reviewer_iYh2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3166/Reviewer_iYh2"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a decoding framework for language models that frames it as an optimization problem and performs decoding by optimizing towards desired dimensions. They prove that their method can improve the perplexity on human texts and also experimentally demonstrate that their method is effective on open-ended text generation tasks according to metrics such as repetition, coherence, and diversity."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The proposed framework makes sense and is technically sound. Based on their constructed framework, they propose a reasonable approximation that can work in practice.\n2. Experiments demonstrate good empirical results compared to many other decoding algorithms.\n3. Both automatic and human evaluations are conducted to provide insights into their method."
                },
                "weaknesses": {
                    "value": "1. Related works such as [1] are missing. It is worth discussing and comparing with these methods in the paper.\n2. The paper only conducts experiments in two open-ended text generation tasks, where both automatic and human evaluations are hard. On the other hand, evaluations on other text generation tasks such as machine translation and text summarization are more accurate and can better indicate if their method is indeed effective.\n3. Their method can be more computational than baselines.\n\n\n\n\n[1] Fernandes et al., Quality-Aware Decoding for Neural Machine Translation, NAACL 2022."
                },
                "questions": {
                    "value": "How efficient is your algorithm?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3166/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698727169145,
            "cdate": 1698727169145,
            "tmdate": 1699636264053,
            "mdate": 1699636264053,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fmWPyVyDsF",
                "forum": "488A64eOf6",
                "replyto": "G7gEFoShEo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3166/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3166/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer iYh2 (part 1)"
                    },
                    "comment": {
                        "value": "We are grateful to the reviewer for their feedback and suggestions, which will help improve our work.\n\nRegarding the weakness and questions raised by the reviewer:\n\n> W1. Related works such as [1] are missing. It is worth discussing and comparing with these methods in the paper.\n\nWe appreciate the reviewer for pointing out this related work. And we have provided our discussion about it in the latest version of our submission in Appendix B.3.\n\nAlthough the work suggested by the reviewer used evaluation metrics to improve generation, we have distinct differences from the following perspectives:\n\n1. On the theoretical guarantees:\n\nThe reranking approach proposed in the suggested paper cannot guarantee improving the distribution of the base generation model to resemble the underlying text distribution from humans. Their objective was to optimize the final outputs towards some pre-defined metrics, but unfortunately they did not provide further theoretical analysis of the resulting performance.\n\nWhile our method has the theoretical guarantee to obtain a better approximation to the text distribution from humans than the base language model. This is presented in Section 2.2 where we proved that the optimal decoding distribution has a lower perplexity on human texts than the perplexity of the base model distribution. In Section 3.5, we also empirically validated this perplexity improvement.\n\n2. On the optimization objectives:\n\nThe reranking approach proposed in the suggested paper focused on improving generation quality, where they tune the weights of different metrics to maximize a given reference-based metric.\n\nWhile we consider alignment with human texts in various aspects simultaneously, including but not limited to the quality of text. We believe that alignment with a wide range of aspects, such as coherence, diversity, and repetition, is necessary to achieve **human-like generation**.\n\nThe weights of different metrics are determined by exactly *matching the level of aspects of human texts*, instead of simply maximizing any particular metric. Therefore, we do not rely on any pre-defined reference-based metrics, as golden references with high quality and desired coverage are not always available in general text generation tasks.\n\n> W2. The paper only conducts experiments in two open-ended text generation tasks, where both automatic and human evaluations are hard. On the other hand, evaluations on other text generation tasks such as machine translation and text summarization are more accurate and can better indicate if their method is indeed effective.\n\nWe follow recent works on decoding methods [1,2] to adopt open-ended generation tasks in our experiment given that they encompass a broader range of linguistic complexity and diversity. These tasks also set challenges for current modern language models to align with humans with respect to a wide range of aspects. Moreover, the open-ended setting is more conformed with the trending and natural use case of large language models which is less constrained and more flexible compared with closed-ended generation tasks such as text summarization.\n\nNevertheless, to demonstrate the universability of our method, we conducted a new experiment on the standard summarization benchmark CNN/DailyMail using an off-the-shelf summarization model \"pegasus-cnn_dailymail\" from the [official release](https://huggingface.co/google/pegasus-cnn_dailymail) in Appendix I. \n\nCompared with the baseline methods, our method achieves better performance in alignment with various aspects like repetition, coherence, diversity, and information content (better when the score is closer to that of the reference), and ROUGE scores (better when the score is higher).\n\n| Model | seq-rep-3 | tok-rep-8 | coherence | diversity | $e^{ENT}$ | ROUGE-1  | ROUGE-2 | ROUGE-L |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| Reference | 0.10 | 2.93 | 80.1 | 99.1 | 31.2 | N/A | N/A | N/A |\n| Top-k | 0.15 | 3.10 | 79.6 | 99.2 | 35.0 | 38.7 | 15.0 | 35.6 |\n| Nucleus | 0.15 | 3.00 | 72.3 | 99.0 | 104.3 | 34.4 | 12.2 | 31.6 |\n| Typical | 0.11 | 2.71 | 76.3 | 99.2 | 81.8 | 34.3 | 12.1 | 31.5 |\n| Contrastive Search | 0.15 | 3.14 | 80.9 | 98.8 | 28.4 | 40.9 | 16.9 | 37.8 |\n| Daemon (Ours) | **0.10** | **2.98** | **80.1** | **99.2** | **29.7** | **41.9** | **18.4** | **38.9** |\n\n(continue in part 2)"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3166/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700064738004,
                "cdate": 1700064738004,
                "tmdate": 1700064738004,
                "mdate": 1700064738004,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "F4D9J9XdUf",
                "forum": "488A64eOf6",
                "replyto": "Pm6G2KnYRl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3166/Reviewer_iYh2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3166/Reviewer_iYh2"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response!\n\nCould you clarify:\n\n1. What's preventing Fernandes et al's method from using metrics such as repetition, coherence, diversity, and information content to improve their generation?\n\n2. Why are your reported ROUGE scores for pegasus-cnn_dailymail significantly worse than what they reported in the paper (https://proceedings.mlr.press/v119/zhang20ae/zhang20ae.pdf) and on hugginface (https://huggingface.co/google/pegasus-cnn_dailymail)?"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3166/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700524503338,
                "cdate": 1700524503338,
                "tmdate": 1700524503338,
                "mdate": 1700524503338,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tOZOK87hXN",
                "forum": "488A64eOf6",
                "replyto": "PPhgsMRYhB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3166/Reviewer_iYh2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3166/Reviewer_iYh2"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the response! I'd like to expand my previous comments just in case they are not clear:\n\n1. My point is that Fernandes et al's method is a general framework that can take reference-based and reference-free metrics (which they both experimented with), including the metrics you used in the paper (repetition, coherence, etc.). Therefore, I do not think there is a difference in this regard and a better way of differentiating your work from theirs is required.\n\n\n2. Beam search is a popular decoding method and is the standard decoding method in text summarization. I don't think you can exclude beam search from \"language model decoding.\"\n\nROUGE score, despite being imperfect, is still widely adopted and is one of the most important metrics in the summarization community that correlates with human evaluations. \n\nMy intention of testing your models on tasks such as machine translation and text summarization was that evaluations in open-ended generation tasks are hard and unreliable, whereas BLEU in machine translation and ROUGE in summarization are relatively reliable metrics for reflecting your generation quality. Therefore, the provided results on summarization does not address my concern that your method can be ineffective in this setting.\n\n3. A side note: ``human-like generation'' is a vague term, and I don't think your definition of this term can be applied to text summarization, especially considering previous works (e.g. [1]) have conducted human evaluations and have results contradicting your findings here.\n\n\n[1] Wiher, Gian, Clara Meister, and Ryan Cotterell. \"On decoding strategies for neural text generators.\" TACL 2022."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3166/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700600666168,
                "cdate": 1700600666168,
                "tmdate": 1700600666168,
                "mdate": 1700600666168,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "UCPbaJlfQS",
            "forum": "488A64eOf6",
            "replyto": "488A64eOf6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3166/Reviewer_3A4S"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3166/Reviewer_3A4S"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a parametric decoding method for generating text from probabilistic models. Essentially, samples from a model are reweighted according to the degree to which they satisfy particular constraints, where the importance of these different constraints is learned via numerical optimization using a small set of samples. These constraints are that the texts generated by the model match human-generated texts according to a variety of chosen metrics. In order to sample from the new (sequence-level) distribution, they make use of a sampling based approximation of the distribution over continuations (of a particular prefix). They show strong results in terms of empirical performance in comparison to standard baseline decoding methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The method is novel and provides a nice lightweight alternative to fine-tuning methods. It may thus be widely accessible to practitioners without the ability to tune larger language models\n* The empirical component of the paper is comprehensive, including nice ablation studies"
                },
                "weaknesses": {
                    "value": "* The mathematical motivations given by this paper are quite weakly supported/explained. In general, the language used by the authors with respect to this topic is confusing and informal. For example, they motivate their use of the reverse KL for choosing the parameters of q by stating \u201cKL(q || p\u03b8) restricts the decoding distribution q to deviate minimally from the LM distribution p\u03b8\u201d, but the same argument could be made for the forward variant of the divergence. Similar language is scattered across 2.1\n* The method requires sampling in order to approximate the new parametric distribution (via the WIS algorithm). The runtime of this algorithm, and hence the additional computational complexity incurred by this decoding method, is not discussed. Further, there is an additional sampling + renormalization step that must happen during decoding (algorithm 2). The lack of discussion of these costs is especially pertinent given that the authors point to the tuning required by other decoding methods as one of their downsides \u201cBut unlike those previous decoding methods that require heavy manual hyper-parameter tuning for trade-off among different metrics\u201d"
                },
                "questions": {
                    "value": "* The authors point out that they wish for the difference in the expected value of f under the model and under the data distribution to be 0. It\u2019s unclear to me how this is incorporated into the learning of the different \\mu. I see that the target expectation is used in the learning algorithm, but this is not very intuitive. Could some intuition be provided here?\n* \u201cMost existing decoding algorithms lead to deteriorated \u03b5-perplexity, comparing to directly sampling from the input LM distribution.\u201d It seems that [1] shows otherwise \n* In 2.2, I don\u2019t see why \u201cthe second result reveals the perplexity improvement over p\u03b8 due to the non-negativity of DKL(p\u03b8,\u03bc || p\u03b8)\u201d\n* The setup for human evaluation is not well explained. What do the numbers in table 3 mean?\n* I do not follow the last statement on page 5 \u201c...so that it can be directly plugged into Eq. (2) to calculate perplexity\u201d\n\n[1] Meister et. al. 2023. On the Efficacy of Sampling Adapters."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3166/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698936224333,
            "cdate": 1698936224333,
            "tmdate": 1699636263987,
            "mdate": 1699636263987,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lPXOd4h80X",
                "forum": "488A64eOf6",
                "replyto": "UCPbaJlfQS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3166/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3166/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 3A4S (part 1)"
                    },
                    "comment": {
                        "value": "We appreciate the comprehensive feedback and helpful recommendations provided by the reviewer that will enhance the quality of our work.\n\nRegarding the weaknesses and questions raised by the reviewer:\n\n> W1. The mathematical motivations given by this paper are quite weakly supported/explained. For example, they motivate their use of the reverse KL for choosing the parameters of q by stating \u201cKL(q || p\u03b8) restricts the decoding distribution q to deviate minimally from the LM distribution p\u03b8\u201d, but the same argument could be made for the forward variant of the divergence. \n\nOur motivation for using reverse KL instead of forward KL stems from the demand of high-quality texts when  decoding from a language model. We should note that as KL divergency is not symmetric, *forward KL and reverse KL measure the differences between two distributions quite differently* (Section 1.6.1 in [1]). And we have explained this in Section 2.1 of our original submission. To make it clearer, we further elaborate the differences between these two types of KL divergency in details below and connect them with our motivation. We also added the discussions to Appendix C of our updated manuscript. \n\nMinimizing the reverse KL, $KL(q || p_\\theta)$ is known to encourage **zero-forcing** behavior [2], as it forces $q(x)=0$ when $p_\\theta(x)=0$. This restricts $q$ to be **mode-seeking** and only explores the modes of the target distribution $p_\\theta$ which contains samples with high likelihood under the ground-truth model's distribution and thus ignores the outliers.\n\nWhereas, minimizing the forward KL, $KL(p_\\theta || q)$ encourages **zero-avoiding** behavior, i.e., it avoids $q(x)=0$ when $p_\\theta(x)>0$. This leads $q$ to be **mean-seeking** which spreads its support to cover all the non-zero density regions of $p_\\theta$. As the distribution $p_\\theta$ of language models is known to have unreliable long tails [3], the resulted $q$ can further overestimate those tails to produce low-quality samples [4].\n\nWe also added an intuitive visualization to illustrate the different behaviors of reverse and forward KL in Figure 4 of Appendix C of our updated manuscript.\n\nOverall, comparing to the forward KL, minimizing the reverse KL leads to a more focused distribution and ignores the long tail in the given language model distribution, which is more suitable for our decoding scenario that demands generation quality.\n\n> W2. The method requires sampling in order to approximate the new parametric distribution (via the WIS algorithm). The runtime of this algorithm, and hence the additional computational complexity incurred by this decoding method, is not discussed. Further, there is an additional sampling + renormalization step that must happen during decoding (algorithm 2). The lack of discussion of these costs is especially pertinent given that the authors point to the tuning required by other decoding methods as one of their downsides \u201cBut unlike those previous decoding methods that require heavy manual hyper-parameter tuning for trade-off among different metrics\u201d\n\nWe have updated the runtime analysis of Algorithm 1 (the WIS algorithm) in Appendix E of our updated manuscript, so as to justify our solution's benefit over previous decoding methods that count on manual hyper-parameter tuning. \n\nFirst, we have noted in Section 2.3.1 of our original submission that Algorithm 1 is only used on the development set to determine the parameters $\\\\{\\mu_i\\\\}^K_{i=1}$ defined in the energy function (**prior to** the decoding phase). Once settled, these parameters are fixed in the inference stage for decoding on the test set. As a result, Algorithm 1 **does not** incur additional computation at the decoding stage.\n\nSecond, the computational cost of Algorithm 1 is much lower than the manual hyper-parameter tuning methods employed in most of our decoding baselines. Specifically, the computational cost in Algorithm 1 consists of two parts. \n\n- The first part takes **one run** of unconditional sampling from the base language model (line 2 of Algorithm 1). We typically set the number of samples to be the same as the development set, so that this cost is equal to one time sampling on the development set.\n\n- The second part estimates the parameters $\\\\{\\mu_i\\\\}^K_{i=1}$ via iterative gradient descent (line 3-6 of Algorithm 1). As the number of parameters is small (equals to the number of constraints which is usually in the scale of dozens in practice), and the metric scores $\\\\{f_i(x)\\\\}^K_{i=1}$ can be precomputed. The total computational overhead here is very small. In our experiments, it takes less than 1 minute to perform thousands of gradient descent steps, which can be ignored comparing to the typical cost consuming when sampling from a language model.\n\n(continue in part 2)"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3166/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700062902079,
                "cdate": 1700062902079,
                "tmdate": 1700062902079,
                "mdate": 1700062902079,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cNHvUu5h2O",
                "forum": "488A64eOf6",
                "replyto": "DsXAVPNhwA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3166/Reviewer_3A4S"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3166/Reviewer_3A4S"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thank you for the detailed responses. At the moment, my score remains the same"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3166/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700472741161,
                "cdate": 1700472741161,
                "tmdate": 1700472741161,
                "mdate": 1700472741161,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "EKmW0Tmsad",
            "forum": "488A64eOf6",
            "replyto": "488A64eOf6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3166/Reviewer_MQ6q"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3166/Reviewer_MQ6q"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a decoding scheme (DAEMON) based on minimizing the divergence of the distribution over generated texts, $q$, with that of the base LM, $p$. They formulate as an optimization problem of this form with a KL objective, provide an approximation, and an efficient sampling scheme for use during decoding."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is well written and straightforward to follow. \n- The motivation is sound, the authors provide an approach for estimating $\\mu$, and for sampling 'efficiently' (although the time complexity of this approach is not given).\n- Strong experimental results:\n   - over a range of datasets\n   - against quite a few decoding approaches commonly used in practice\n   - ablation studies\n   - a range of metrics (Repetition, Coherence, Diversity, Information Content)\n- The problem is of great importance in the community."
                },
                "weaknesses": {
                    "value": "- Please provide complexity analysis of the sampling approach and compare to competing approaches (Greedy, Top-k, CD, CS, etc). While the experimental results are strong it is important to compare the runtime of this method to determine practical efficacy given the authors claim it is \"efficient\" in the conclusion. \n- Analysis on the convergence of $\\mu$ in Algorithm 1 and some sensitivity analysis to initialization would be helpful for practitioners.\n- Given that different metrics perform stronger for different # of candidates $M$ and $\\tau$, it would be helpful, in terms of robustness, to include some experimental results which show performance on different metrics if one optimizes for a single metric (i.e. coherence)."
                },
                "questions": {
                    "value": "See weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3166/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3166/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3166/Reviewer_MQ6q"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3166/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699827585842,
            "cdate": 1699827585842,
            "tmdate": 1699917604598,
            "mdate": 1699917604598,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3p5KRc8nTr",
                "forum": "488A64eOf6",
                "replyto": "EKmW0Tmsad",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3166/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3166/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer MQ6q"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the detailed feedback and valuable suggestions to further improve our work!\n\nRegarding the weakness and questions raised by the reviewer:\n\n> Please provide complexity analysis of the sampling approach and compare to competing approaches (Greedy, Top-k, CD, CS, etc). While the experimental results are strong it is important to compare the runtime of this method to determine practical efficacy given the authors claim it is \"efficient\" in the conclusion.\n\nFirst of all, we have to clarify that we did **not** emphasize efficiency as an advantage of our method, although the decoding latency of our method is still on par with vanilla greedy decoding. In conclusion and future work discussions (Section 4), we only suggested finding more efficient sampling methods for our decoding framework as an important future work, rather than claiming we have already done so.\n\nSecond, in our submitted manuscript, we reported the decoding latency of our method with different $M$ in Figure 3 (the right-most subfigure). The inference latency is relative to greedy decoding. In our main experiments, we set $M=25$ and the latency of Algorithm 2 was only 1.35 times of that from greedy decoding, while our method achieved significantly better performance in overall metric alignment than greedy decoding and outperformed it in Mauve score by nearly 30 points.\n\nWe have updated the computational complexity and practical runtime analysis of different sampling approaches in Appendix F. To summarize, the main complexity of our method comes from the candidate sampling step (line 1-2 in Algorithm 2), which increases the computational complexity of vanilla greedy decoding by a factor of $M$ (the number of candidates). However, as this step can be done in parallel, which is highly optimized by modern GPU hardware, the actual inference latency grows much slower in terms of $M$. According to the right-most subfigure of Figure 3, the latency is still below 2 when $M$ is set to 100.\n\n> Analysis on the convergence of $\\mu$ in Algorithm 1 and some sensitivity analysis to initialization would be helpful for practitioners.\n\nWe have updated the analysis about the convergence and sensitivity of $\\mu$ in Appendix G. We consider three common initializations of $\\mu$: \n(1) All-zero initialization.\n(2) Random initialization from a standard normal distribution.\n(3) Random initialization from a uniform distribution $U[0,1)$. \n\nWe took 5 runs with different random seeds in these three settings, and found that Algorithm 1 is quite stable across all these different initializations. To analyze the convergence of $\\mu$, we plot the optimization trajectory of $\\mu_i$ with different initializations in Figure 5 of Appendix G. The results suggest that the optimization of $\\mu$ is quite stable under different initializations and they almost converge to the same optimal value, which demonstrates the practicality of Algorithm 1.\n\n> Given that different metrics perform stronger for different # of candidates $M$ and $\\tau$, it would be helpful, in terms of robustness, to include some experimental results which show performance on different metrics if one optimizes for a single metric (i.e. coherence).\n\nWe appreciate the reviewer's suggestion. Firstly, we note that our choice of $M$ and $\\tau$ is already able to achieve strong performance in universal alignment on different metrics than existing baselines in the main results (Table 1).\n\nTo demonstrate the robustness of the alignment results regarding to the choice of $M$ and $\\tau$, we followed the reviewer's suggestion to include additional experiments in Appendix H of our updated manuscript, where we studied the performance of different metrics when one optimizes against a single metric. The results are presented in Table 5 of Appendix H. It shows that the performance on different metrics has a very small variance even when we optimize for a single metric, which indicates the robustness of our method.\n\n| Model | seq-rep-4 | tok-rep-32 | coherence | diversity | $e^{ENT}$ |\n| --- | --- | --- | --- | --- | --- |\n| Reference | 0.48  | 21.3  | 62.3  | 92.5  | 23.2 |\n| Opt. seq-rep-4 | 0.42  | 22.5  | 62.5  | 92.2  | 22.8 |\n| Opt. tok-rep-32 | 0.38  | 21.2  | 62.4  | 94.1  | 24.3 |\n| Opt. coherence | 0.38  | 21.2  | 62.4  | 94.1  | 24.3 |\n| Opt. diversity | 0.55  | 22.9  | 63.3  | 92.7  | 22.2 |\n| Opt. $e^{ENT}$ | 0.40  | 21.5  | 61.6  | 93.9  | 23.1 |"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3166/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700062139156,
                "cdate": 1700062139156,
                "tmdate": 1700062158461,
                "mdate": 1700062158461,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]