[
    {
        "title": "Variational Inference with Singularity-Free Planar Flows"
    },
    {
        "review": {
            "id": "fZ2ApNIOTm",
            "forum": "Gk75gOjtQh",
            "replyto": "Gk75gOjtQh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5682/Reviewer_ndCL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5682/Reviewer_ndCL"
            ],
            "content": {
                "summary": {
                    "value": "The work introduced a new reparameterization scheme for the training parameters of planar flows, effectively eliminating the initial singularity issues. This new approach ensures that the parameter $v$ does not escalate to infinity as $||w||$ approaches zero, potentially enhancing the stability during the training of Planar flow.  Empirical results demonstrate that the new parameterization scheme improves the performance of planar flows in variational inference applications."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This work delivers a concise and straightforward description of a well-defined problem, and the logic behind the proposed solution is easy to follow.\n\nThe solution itself, while simple, effectively addresses a known issue in planar flow, representing a practical contribution that the community is likely to find useful."
                },
                "weaknesses": {
                    "value": "- The primary concern with this work lies in the significance of the problem it addresses.  While the problem focused in the paper is very well-defined (as mentioned in the Strength section), the importance of this problem is hard to justify for the following 2 reasons:\n1. Planar flow, the focus of this work, is one of the earliest methods introduced in the normalizing flow literature, and numerous advanced normalizing flows such as affine coupling flows, neural spline flows, etc., have been developed, showcasing superior performance.  Given this context, the contribution of this work appears quite limited.  To justify its contribution,  it would be imperative to demonstrate that the modifications introduced significantly enhance the performance of planar flow. Ideally, it should now be on par with, or outperform, the more recent flow methods. This point leads to the second concern.\n\n2. The empirical experiments conducted in the study lack a comprehensive comparison with a variety of recent flow methods. Moreover, the paper only delves into variational inference applications, omitting performance evaluations on density estimation and the quality of synthetic data generation. To solidify the work's standing and importance, an expansion of the experimental section to include these aspects is necessary.\n\n- Furthermore, this work falls short in providing a thorough and rigorous exploration of the singularity issue. The connection between the presence of a singularity and its detrimental impact on the performance of planar flow remains unclear to readers. The paper asserts that the proposed approach enhances the stability of model training, setting the expectation for a detailed analysis. \n\nTo meet this expectation, the paper should ideally include a comparative analysis of the gradient variance in planar flow, employing both the original and the new parameterization schemes. Additionally, a theoretical examination of the training dynamics in a deep planar flow setup would contribute to a more comprehensive understanding. The paper should also offer a conclusive answer to whether issues such as gradient explosion or vanishing are effectively circumvented with the proposed modifications. Without these elements, the paper's exploration of the singularity issue feels incomplete, leaving readers with unanswered questions and a lack of clarity on the significance of the proposed solution."
                },
                "questions": {
                    "value": "no questions."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5682/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5682/Reviewer_ndCL",
                        "ICLR.cc/2024/Conference/Submission5682/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5682/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698279876459,
            "cdate": 1698279876459,
            "tmdate": 1700595050569,
            "mdate": 1700595050569,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "rBkpT7SinD",
                "forum": "Gk75gOjtQh",
                "replyto": "fZ2ApNIOTm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5682/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5682/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "# Response to Reviewer ndCL\n\nThank you for your review and recognizing the practicality of our solution. For your concern on the significance of the problem it addresses, we reply to all your comments below.\n\n> **Weakness 1**: Planar flow, the focus of this work, is one of the earliest methods introduced in the normalizing flow literature, and numerous advanced normalizing flows such as affine coupling flows, neural spline flows, etc., have been developed, showcasing superior performance. Given this context, the contribution of this work appears quite limited. To justify its contribution, it would be imperative to demonstrate that the modifications introduced significantly enhance the performance of planar flow. Ideally, it should now be on par with, or outperform, the more recent flow methods. This point leads to the second concern.\n\n**A1**: We agree that the more recent flow methods are powerful in specific tasks. However, the expressiveness and scalability of the these flow methods come with a price \u2014 they are more intricately designed and require extra attention on parameter tuning/training, which can be inefficient in solving some variational inference tasks. This inefficiency is more severe when they are run on CPU-only devices. \n\nWhile we agree that intricate models with fine-tuned parameters are powerful in specific tasks, we believe that simplicity can be a strength. Our objective was to provide a clear and accessible solution to general variational problems, where ease of implementation and computational efficiency are crucial, e.g., sampling from a customize distribution, posterior inference in Bayesian statistical regression, and low-dimensional VAE.\n\n\n> **Weakness 2**: The empirical experiments conducted in the study lack a comprehensive comparison with a variety of recent flow methods. Moreover, the paper only delves into variational inference applications, omitting performance evaluations on density estimation and the quality of synthetic data generation. To solidify the work's standing and importance, an expansion of the experimental section to include these aspects is necessary.\n\n**A2**: Thank you for your suggestion. We have conducted an extra comparison with a recent flow methods, neural spline flows (NSFs). The updated comparison reaffirms the parameter efficiency of the new planar flows. We have included the results of the NSFs experiment in Figure 6, and a table summarizing the parameter counts is now available in Appendix D in the updated version.\n\nAs indicated by our title, *Variational Inference with Singularity-Free Planar Flows*, our focus is solely on variational inference. One reason for this focus is that the inversion of the planar flow does not have a closed form, making it less attractive for density estimation and data generation."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5682/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700580576913,
                "cdate": 1700580576913,
                "tmdate": 1700580576913,
                "mdate": 1700580576913,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5TiXz9h8Qk",
                "forum": "Gk75gOjtQh",
                "replyto": "YGPGY5vThg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5682/Reviewer_ndCL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5682/Reviewer_ndCL"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your response"
                    },
                    "comment": {
                        "value": "I appreciate authors' response to my comments/questions and efforts for including additional experiments.  The additional comparison to NSF/sylvester flow does help to strengthen the usefulness of the method, because of which I'm willing to raise the score to 5. One caveat of this particular experiments conducted in Fig6 is that typically complicated flows such as NSF does not require large number of layers (for simple MNIST example, 10--20 layers would be more reasonable; the decaying performance of NSF with increasing flow length also confirms this), hence the comparison might be more insightful by also evaluating these flows at 5, 10, 20 layers.   \n\nHowever, I still think issues noted in my previous comments deserves a more careful investigation. \n\n- to A3 and A4:  The argument---\"The training instability and suboptimal convergence arising from the singularity are predominantly numerical issues. The presence of an unstable gradient around the singularity renders certain distributions within the variational family practically unattainable.\"---is intuitively correct but not grounded by any empirical evidence (as the author mentioned in A4---\"we did not find enough robust observations that can be included as a solid evidence\") or theoretical analysis. I personally appreciate the simple practical solution offered in this work, but rigorously analyzing the identified problem and developing in-depth understanding to the general issue leads to more significant impact.\n\n- to  A2: I understand that \"planar flow does not have a closed form, making it less attractive for density estimation and data generation\", but numerical inverse can be computed via root finders and works reliably in density estimation (see a julia implementation: https://github.com/TuringLang/Bijectors.jl/blob/04b79dd46eca8cea2f988348c47bd5e720a2b9a4/src/bijectors/planar_layer.jl#L112C1-L127C4).\nBecause the scope of this work is relatively small, it worth analyzing the usefulness of the proposed reparameterization in all aspects."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5682/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700595027780,
                "cdate": 1700595027780,
                "tmdate": 1700595027780,
                "mdate": 1700595027780,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MjX3LmZ0nr",
                "forum": "Gk75gOjtQh",
                "replyto": "fH3QgCzi0i",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5682/Reviewer_ndCL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5682/Reviewer_ndCL"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the ongoing discussion. However, I respectfully maintain my stance and have decided to retain the current score. Regardless, I wish you the best of luck with your submission."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5682/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687949708,
                "cdate": 1700687949708,
                "tmdate": 1700687949708,
                "mdate": 1700687949708,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "YuhMagot7w",
            "forum": "Gk75gOjtQh",
            "replyto": "Gk75gOjtQh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5682/Reviewer_seL3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5682/Reviewer_seL3"
            ],
            "content": {
                "summary": {
                    "value": "The authors proposed a new parameterization for planar flows that removes the singularity. Experiments on a range of problems validate the effectiveness of the proposed methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The observation of a singularity in the original parameterization of planar flows is new and important. The authors have done a nice job that motivates the new parameterization and the writing is clear."
                },
                "weaknesses": {
                    "value": "1. No theoretically justification why the new parameterization that removes the singularity would makes the approximation better.\n\n2. The experiments are all in relatively low dimensional space (the VAE example uss a latent dimension D=20). It is not clear if the benefit of the proposed method would extend to higher dimension problems."
                },
                "questions": {
                    "value": "1. It seems that SNF has similar issue in its parameterization. How did you implement it in your experiments?\n\n2. Figure 6 shows an interesting result. First, it is an unfair comparison between planar flows and IAF in terms of number of layers since each layer in IAF is more complicated and requires more parameters, and this makes the performance of planar flows even better. Second, it seems that the more powerful IAF does not do well in terms of posterior estimation in this case. Is it because the training is not long enough? Was the KL reported in the right plot the average over all test images? Can the author provide more direct posterior comparison (e.g., scatter plot of samples) to a ground truth MCMC run?\n\n3. It seems that the advantage of the new parameterization decreases as the number layers increase, any explanations? Also, for planar flows, a large number of layers are often used in practice which makes the benefit of new parameterization a bit less attractive."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5682/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698315332166,
            "cdate": 1698315332166,
            "tmdate": 1699636593407,
            "mdate": 1699636593407,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "eQV1owLWiY",
                "forum": "Gk75gOjtQh",
                "replyto": "YuhMagot7w",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5682/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5682/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "# Response to Reviewer seL3\n\nThank you for your thorough review and positive feedback. Your acknowledgment of the importance and the effectiveness of our proposed methods is encouraging. \n\nWe reply to all your comments below.\n\n\n> **Weakness 1**: No theoretically justification why the new parameterization that removes the singularity would makes the approximation better.\n\n**A1**: We understand your concern. While we don't have a formal theoretical proof, we believe our approach is logically grounded. We would like to highlight the logical coherence in our method, which, while not a formal theoretical proof, serves as a rational basis for the approximation improvement.\n\nThe training instability and suboptimal convergence arising from the singularity are predominantly numerical issues. The presence of an unstable gradient around the singularity renders certain distributions within the variational family practically unattainable. Consequently, this limitation restricts the expressiveness of planar flows. By eliminating the singularity, we can explore all distributions during training, which leads to better approximation in general.\n\n\n> **Weakness 2**: The experiments are all in relatively low dimensional space (the VAE example uss a latent dimension D=20). It is not clear if the benefit of the proposed method would extend to higher dimension problems.\n\n**A2**: We appreciate your insight into the potential limitations of low-dimensional experiments. We took your suggestion and run the VAE experiment with a higher dimension $D=40$. Similar results are observed. This consistency supports the robustness of our findings, suggesting that the observations are not merely circumstantial but hold in higher-dimensional spaces as well. We have included this experiment in Appendix G. \n\nNote that we did not run the IAF and NSF for $D=40$ as changing to a higher dimension necessitates a corresponding adjustment in the neural network size of IAF and NSF. Unfortunately, we did not have sufficient time to thoroughly test the neural network size to ensure comparable performance."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5682/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700582808565,
                "cdate": 1700582808565,
                "tmdate": 1700582808565,
                "mdate": 1700582808565,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gMC7G76qWo",
                "forum": "Gk75gOjtQh",
                "replyto": "tKv2TOb9yW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5682/Reviewer_seL3"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5682/Reviewer_seL3"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your response. I am still not sure the empirical findings are enough to fully convince the claim and hence would like to keep my score."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5682/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700637269892,
                "cdate": 1700637269892,
                "tmdate": 1700637269892,
                "mdate": 1700637269892,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "MnRQJvlahI",
            "forum": "Gk75gOjtQh",
            "replyto": "Gk75gOjtQh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5682/Reviewer_KdQZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5682/Reviewer_KdQZ"
            ],
            "content": {
                "summary": {
                    "value": "This paper identifies a non-removable singularity in the original planar flow's parameterization, and proposes an new parameterization that removes this singularity and stabilizes the flow training. Empirically, they have shown this new parameterization leads to faster training and superior performance against the original parameterization on several synthetic experiments. In addition, they apply their new planar flow to VAE training on MNIST and find that the planar flow with the proposed parameterization achieves competitive performance against more advanced flow methods like IAF and SNF."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- This method is simple and plausible. Despite its simplicity, the experiments in the paper do demonstrate the improved performance of the planar flow. Although it is not clear whether this method is comparable to the latest flow methods on density estimation, this method could be useful in certain variational inference problems where a simple flow model is needed.\n- The paper is well-written and easy to understand."
                },
                "weaknesses": {
                    "value": "- The particular choice of the $m(\\cdot)$ function seems a bit arbitrary. As argued in the paper, all we need is $m(x) = \\mathcal{O}(x)$ when $x \\to 0$. There are many functions that satisfy this condition. To confirm that the issue of the original parameterization is indeed the singularity, the authors should pick a few other $m(\\cdot)$ functions satisfying $m(x) = \\mathcal{O}(x)$ and check if they share similar performance.\n- The idea is so simple that it is merely a parameterization trick. I am not sure if something similar has been done before. However, this may not be an actual weakness of this paper, as the reviewer is not particularly familiar with the literature on the planar flow.\n- One advantage of the planar flow in this paper is that its performance is comparable to the IAFs and SNFs but the planar flow has fewer parameters. One experiment to further strengthen this point is to compare the wall-clock running time of each flow."
                },
                "questions": {
                    "value": "- Have the authors generated images from the trained VAEs on the MNIST as a sanity check?\n- Have the authors tried other function forms of $m(\\cdot)$ that satisfy the condition $m(x) = \\mathcal{O}(x)$?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5682/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5682/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5682/Reviewer_KdQZ"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5682/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698644102007,
            "cdate": 1698644102007,
            "tmdate": 1699636593309,
            "mdate": 1699636593309,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "cHVnUxdJqr",
                "forum": "Gk75gOjtQh",
                "replyto": "MnRQJvlahI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5682/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5682/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "# Response to Reviewer KdQZ\n\nThank you for your thorough and insightful comments. We are happy to see that you find our method useful and our paper well-written.\n\nWe reply to all the points below.\n\n\n> **Weakness 1**: The particular choice of the $m(\\cdot)$ function seems a bit arbitrary. As argued in the paper, all we need is when $m(x) = \\mathcal{O}(x)$ when $x \\rightarrow 0$. There are many functions that satisfy this condition. To confirm that the issue of the original parameterization is indeed the singularity, the authors should pick a few other $m(\\cdot)$ functions satisfying $m(x) = \\mathcal{O}(x)$ and check if they share similar performance.\n>\n> **Question 2**: Have the authors tried other function forms of $m(\\cdot)$ that satisfy the condition $m(x) = \\mathcal{O}(x)$?\n\n**A1**: We regret that we did not make it clear how we chose the function $m(\\cdot)$. The sufficient condition we stated was in the context of removing the singularity. There are other implicit conditions as well. The main role of $m(\\cdot)$ is to squeeze the unconstrained dot product to the required region $(-1, \\infty)$, which in turn reparameterizes the unconstrained $v'$ to the feasible values. \n\nWe chose $m(x)=x$ if $x \\ge 0$ and a simple continuously differentiable extension to $x<0$, so that a minimal reparameterization is imposed on the unconstrained $v'$. This choice aligns with our belief in simplicity and minimizes the computation required. \n\nCertainly, there are other more complicate functions satisfying all the conditions. However, they might just introduce unnecessary computation. We appreciate the reviewer for raising this question. We have modified the corresponding section to enhance clarity in the updated version (page 5).\n\n\n> **Weakness 2**: The idea is so simple that it is merely a parameterization trick. I am not sure if something similar has been done before. However, this may not be an actual weakness of this paper, as the reviewer is not particularly familiar with the literature on the planar flow.\n\n**A2**: We agree that it is a parameterization trick. To the best of our knowledge, our work is the first attempt to address this specific issue. Frankly, this work is not groundbreaking. Our objective is to provide a clear and accessible solution to general variational problems, particularly in scenarios where ease of implementation and computational efficiency are crucial.\n\n\n> **Weakness 3**: One advantage of the planar flow in this paper is that its performance is comparable to the IAFs and SNFs but the planar flow has fewer parameters. One experiment to further strengthen this point is to compare the wall-clock running time of each flow.\n\n**A3**: Thank you for your valuable suggestion. The planar flow is indeed faster and requires less computation resource than other flows due to its simplicity, especially with the minimal reparameterization we proposed. Based on our experiments, the new planar flows are approximately faster by a few hours than IAFs and SNFs for completing a replicate of the VAE experiment. We did not report this in the paper since the wall-clock running time we collected is not robust enough due to factors beyond our control.\n\nWe also note that the wall-clock running time is not the only metric and does not fully demonstrate the strength of the planar flow. For example, the planar flow is also trained on GPUs (to facilitate a fair control experiment), while it only requires small GPU usage, hence low power consumption. Additionally, it is possible to train planar flows efficiently on CPU-only devices.\n\n\n> **Question 1**: Have the authors generated images from the trained VAEs on the MNIST as a sanity check?\n\n**A4**: Thank you for pointing it out. We have performed the sanity check as you suggested. The images generated from the trained VAEs are reasonable, which indicates that our models are properly trained. We have included the generated images in Appendix F."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5682/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700584145734,
                "cdate": 1700584145734,
                "tmdate": 1700584145734,
                "mdate": 1700584145734,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bX5HjRirce",
                "forum": "Gk75gOjtQh",
                "replyto": "cHVnUxdJqr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5682/Reviewer_KdQZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5682/Reviewer_KdQZ"
                ],
                "content": {
                    "comment": {
                        "value": "Hi authors,\n\nThanks for clarifications. I think those comments make sense.\n\nThe generated images on MNIST show that (a) the model is properly trained (b) the sample quality of the new parameterization is marginally better than the old parameterization.\n\nI think the value of this paper is a simple and computationally cheap flow model which could be beneficial in certain settings -- a particular example is variational inference. I still lean towards acceptance. However, since I myself is not an expert in flow based model, I am less willing to increase the score further. I think the authors' priority is to convince the other reviewers."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5682/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700604005977,
                "cdate": 1700604005977,
                "tmdate": 1700604005977,
                "mdate": 1700604005977,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "VSWP5I6mQW",
            "forum": "Gk75gOjtQh",
            "replyto": "Gk75gOjtQh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5682/Reviewer_Z1xs"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5682/Reviewer_Z1xs"
            ],
            "content": {
                "summary": {
                    "value": "The authors consider the original formulation of normalizing flows parameterized by neural networks presented in the work by Rezende et al. They note that this parameterization has a deficiency (the function can become singular) that limits its expressivity/trainability. \n\nThey propose a patch to it and test it on standard benchmarks -- density estimation for challenging 2d densities, a Bayesian inference task, and the variational autoencoder formulation of the VI problem where an equivalent Evidence Lower Bound (ELBO) can be optimized."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "I am a believer that a paper does not need to be groundbreaking to be a meaningful contribution to the literature. This paper does not try to be groundbreaking or to sell itself as such. It notes a deficiency in a foundational method, and patches that deficiency, and it justifies it with experiments. \n\nThose experiments are thorough -- and for once it seems like the comparison they make to other methods is reproducible (often papers will make numerical comparisons to other works, claiming such and such number is better than such and such other number, but the experimental conditions leading to those discrepancies in numbers is not clearly causally related to the proposed method). While the experiments are simple and low dimensional, this can actually be a nice feature for a paper to suggest that things are indeed reproducible in a reasonable sense."
                },
                "weaknesses": {
                    "value": "The other perspective on the simplicity of the proposal is that it is not necessarily quite intellectually rich. I say this in the following sense - the related works points to many papers that choose different parameterizations for the coupling functions in normalizing flows. A pushback then is to say that changing a parameterization in the form they've done here is not that conceptually different from just proposing other transformations that don't have the original issue in the planar flows. The authors make a remark about the parameter efficiency of this method (which is true, it's a very simple function), but hopefully there'd be a bit more here.\n\nOf particular relevance is the Sylvester Flows paper, which presents itself as a generalization of the planar flows that this paper is addressing. \n\nSome related work that the authors should include:\n\n**Other works that lay the groundwork for flow-based variational inference in scientific computing:**\n- Boltzman Generators, *Frank No\u00e9, Simon Olsson, Jonas K\u00f6hler, Hao Wu*, 2019\n- Flow-based generative models for Markov chain Monte Carlo in lattice field theory, *Michaels S. Albergo, Gurtej Kanwar, Phiala E. Shanahan*, 2019."
                },
                "questions": {
                    "value": "- Can the authors explain if their patch is relevant to the generalization of planar flows (Sylvester flows)?\n- Can the authors justify their claim of parameter efficiency by providing parameter counts and pushing e.g. the number of parameters in the neural networks in the neural spline flows down to their minimum to maintain performance? Splines are for example clearly more expressive, the question is just what is the minimal network size that makes them competitive with the proposal here. This doesn't seem like that hard of an experiment to run either, but of course I am sympathetic to the overhead of more experimentation. \n- Are there any higher dimensional experiments that the authors could run? The downside of low-d is it's hard to understand if the observations are generic or circumstantial."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5682/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5682/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5682/Reviewer_Z1xs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5682/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698857684283,
            "cdate": 1698857684283,
            "tmdate": 1700683854964,
            "mdate": 1700683854964,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "zZK44nETXp",
                "forum": "Gk75gOjtQh",
                "replyto": "VSWP5I6mQW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5682/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5682/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "# Response to Reviewer Z1xs\n\nWe sincerely appreciate your progressive perspective on the nature of meaningful contributions to the literature. Your recognition that a paper doesn't necessarily need to be groundbreaking to make a significant impact resonates deeply with our intentions behind this work. \n\nWe reply to all your comment, suggestion, and questions below.\n\n> **Weakness 1**: The other perspective on the simplicity of the proposal is that it is not necessarily quite intellectually rich. I say this in the following sense - the related works points to many papers that choose different parameterizations for the coupling functions in normalizing flows. A pushback then is to say that changing a parameterization in the form they've done here is not that conceptually different from just proposing other transformations that don't have the original issue in the planar flows. The authors make a remark about the parameter efficiency of this method (which is true, it's a very simple function), but hopefully there'd be a bit more here.\n\n**A1**: We acknowledge that our approach is intentionally simple, and we understand the concern about its conceptual depth. In choosing simplicity, our intention was to provide a clear and accessible solution to general variational problems, particularly in scenarios where ease of implementation and computational efficiency are crucial.\n\n\n> **Suggestion 1**: Some related work that the authors should include:   \n> Other works that lay the groundwork for flow-based variational inference in scientific computing:\n>   - Boltzman Generators, Frank No\u00e9, Simon Olsson, Jonas K\u00f6hler, Hao Wu, 2019\n>   - Flow-based generative models for Markov chain Monte Carlo in lattice field theory, Michaels S. Albergo, Gurtej Kanwar, Phiala E. Shanahan, 2019.\n\n**A2**: Thank you for your valuable suggestion. We have diligently reviewed the papers you recommended, and incorporated references to these works in the updated version (page 2).\n\n\n> **Question 1**: Can the authors explain if their patch is relevant to the generalization of planar flows (Sylvester flows)?\n\n**A3**: The Sylvester flow is considered as the generalization of the planar flow since it has the same form, $f(z) = z + A h(Bz + b)$, but allows for matrix weights. Our patch to the planar flow does not change the dimension of the weight parameters, so it is different from the approach of the Sylvester flow. However, there are similar constraints on the parameters of the Sylvester flow, $r_{ii} \\tilde{r}_{ii} > -1$. Hence, it is possible to adapt our patch for the Sylvester flow to improve its expressivity/trainability.\n\n\n> **Question 2**: Can the authors justify their claim of parameter efficiency by providing parameter counts and pushing e.g. the number of parameters in the neural networks in the neural spline flows down to their minimum to maintain performance? Splines are for example clearly more expressive, the question is just what is the minimal network size that makes them competitive with the proposal here. This doesn't seem like that hard of an experiment to run either, but of course I am sympathetic to the overhead of more experimentation.\n\n**A4**: Thank you for your suggestion regarding the experimental design for neural spline flows (NSFs). Your experimental design for NSFs aligns with our treatment to IAFs. We promptly conducted this experiment; however, it's worth noting that the training for NSFs required a considerably longer duration compared to other flow methods. We apologize for the delayed response.\n\nThe updated comparison reaffirms the parameter efficiency of the new planar flows. We have included the results of the NSFs experiment in Figure 6, and a table summarizing the parameter counts is now available in Appendix D in the updated version.\n\n\n> **Question 3**: Are there any higher dimensional experiments that the authors could run? The downside of low-d is it's hard to understand if the observations are generic or circumstantial.\n\n**A5**: We appreciate your insight into the potential limitations of low-dimensional experiments. We took your suggestion and run the VAE experiment with a higher dimension $D=40$. Similar results are observed. This consistency supports the robustness of our findings, suggesting that the observations are not merely circumstantial but hold in higher-dimensional spaces as well. We have included this experiment in Appendix G. \n\nNote that we did not run the IAF and NSF for $D=40$ as changing to a higher dimension necessitates a corresponding adjustment in the neural network size of IAF and NSF. Unfortunately, we did not have sufficient time to thoroughly test the neural network size to ensure comparable performance."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5682/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700584643106,
                "cdate": 1700584643106,
                "tmdate": 1700584643106,
                "mdate": 1700584643106,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bnwndXv7WA",
                "forum": "Gk75gOjtQh",
                "replyto": "zZK44nETXp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5682/Reviewer_Z1xs"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5682/Reviewer_Z1xs"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your improvements"
                    },
                    "comment": {
                        "value": "Thanks for your improvements, I have raised my score accordingly to be over the threshold. It is an acceptable set of experiments."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5682/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700683841769,
                "cdate": 1700683841769,
                "tmdate": 1700683841769,
                "mdate": 1700683841769,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]