[
    {
        "title": "An Investigation of Representation and Allocation Harms in Contrastive Learning"
    },
    {
        "review": {
            "id": "6hblUiXMm5",
            "forum": "q4SiDyYQbo",
            "replyto": "q4SiDyYQbo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3736/Reviewer_F3P4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3736/Reviewer_F3P4"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on studying the issue of representation harm in contrastive learning (CL) that arises when some groups are underrepresented in the training corpora. In this case, the authors show that the underrepresented groups tend to collapse into semantically similar groups (that are not underrepresented). In a follow up theoretical analysis on graphs, the authors show that two groups of nodes tend to collapse as their connectivity increases. Finally, through a causal analysis, the authors show that the representation harms caused by CL cannot be mitigated for downstream tasks when training a probe on top of the CL representations."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper studies an important problem in self-supervised learning through contrastive objectives (that of representation collapse of groups that are underrepresented in the training data)\n2. It does so in a sound and systematic way, by providing evidence on controlled images (CIFAR10), imbalanced text (BiasBios) and a theoretical analysis with artificial graphs.\n3. The paper is well written, with a thorough discussion of results and potential insufficiencies of an existing class of algorithms in overcoming representation harm, showing how more work is needed in the area of CL to result in algorithms that are robust to underrepresentation of certain groups (which can be hard to identify at scale to begin with)."
                },
                "weaknesses": {
                    "value": "The main weakness I can find from this paper is the lack of a large-scale study. SSL, and CL in particular, are most effective when used on large amounts of data. The controlled studies in this paper allow us to analyze the existing representation harms. However, it can be seen that these values are generally much lower for BiasBios than for CIFAR10. On the other hand, this could be due to the different domain (text). A study on ImageNet (larger number of both samples and classes) could potentially disentangle this confound. In particular, it would be interesting to know whether having more diversity in the data alleviates learning spurious features (e.g. collapsing classes with similar background colors), and reduces collapse of underrepresented groups."
                },
                "questions": {
                    "value": "1. Typo \u201ca\u201d at the end of line 6 in page 2\n2. You could use diverging palettes (with a neutral color at 1.0) in the heatmaps, to clearly distinguish HR<1. Having a colorbar next to each heatmap figure would also improve readability.\n3. In Figure 2, do you have any idea why there\u2019s such a large difference (10%) between deer and horse collapsing?\n4. In line 4 of Sec 2.1.2, you can add \u201cof classes\u201d after \u201ca pair\u201d to help the reader understand better \n5. In Sec 2.2.2, when you define the GRH metric, I would have found it useful to have a sketch of a plane with boundaries that show what each region means. It\u2019s something you could consider adding when you get an extra page\n6. In Sec 4.2, why do you train on 75% of the Test set?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3736/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698474001745,
            "cdate": 1698474001745,
            "tmdate": 1699636329644,
            "mdate": 1699636329644,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "94q3mPaHxu",
                "forum": "q4SiDyYQbo",
                "replyto": "6hblUiXMm5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3736/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3736/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer F3P4"
                    },
                    "comment": {
                        "value": "Thank you for your valuable feedback and questions. Please see our responses for the other comments.\n\n**However, it can be seen that these values are generally much lower for BiasBios than for CIFAR10.** We would like to emphasize that the results from the CIFAR10 and BiasBios datasets are not directly comparable, as they are based on slightly different metrics. The metric for the CIFAR10 dataset is specific to our *controlled study* design, where we measure the degree to which the representations of two classes have collapsed with each other due to under-representation by comparing representations learned using balanced data to those learned using imbalanced data. In our experiments with the BiasBios dataset, we wish to demonstrate the potential harmfulness of collapse in a real data scenario where *underrepresentation occurs naturally*, which requires a slightly different measure of collapse. Specifically, we measure the ratio of the similarity of samples with the same gender and different occupations to the similarity of samples with different gender and the same occupation. This measure allows us to notice harmful cases of collapse, such as female surgeons being more similar to female dentists than to male surgeons. \n\n**Regarding ImageNet:** Thank you for the suggestion. We started looking into such an experiment, but realized that the `imagenet-1k` dataset used for training publicly available CL models is indeed pretty balanced. Most classes have 1300 samples, with the least frequent class being `black-and-tan_coonhound` with 732 samples. Therefore, it is not suitable for studying the effect of underrepresentation. Artificially subsampling the data and training our own CL model as we did on CIFAR10 is unfortunately computationally too challenging for our computational resources.\n\n**Large difference between deer and horse collapse:** Although we are not completely certain, a possible explanation is that the representations of `deer` are more dispersed compared to `horse` when undersampled, as seen in Figure 2 that the diagonal RH for `deer` ($1.126 \\pm 0.012$) is significantly higher than `horse` ($1.068 \\pm 0.009$). Since `deer` becomes more scattered, the representation harm metric between `deer` and `horse` is less compared to when `horse` is undersampled.   \n\n**Training on 75\\% of the test set:** The linear heads are trained with a randomly chosen 75\\% of the test dataset and evaluated with the *remaining* 25\\% to calculate the metrics in eq. (4.2). \n\n**Typos and figures** Thank you for your suggestions. We have corrected the typos, are updating the figures, and will update the manuscript soon. Current heatmaps already use a divergent heatmap (1 is light green, above one are cold colors like blue, and below 1 are warm colors like red), but are not \"centered\". We will center the 1 to be white to improve readability."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3736/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700105272398,
                "cdate": 1700105272398,
                "tmdate": 1700105272398,
                "mdate": 1700105272398,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xc2gDST6XV",
                "forum": "q4SiDyYQbo",
                "replyto": "94q3mPaHxu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3736/Reviewer_F3P4"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3736/Reviewer_F3P4"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the reply!\n\n**On ImageNet:** I think that having results on a sub-sampled version of ImageNet by the (potential) CR version would make the paper stronger.\n\n**Training on 75% of the test set:** I meant to ask, why don't you use a different split to begin with? And then test on 100% of the test set?"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3736/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700731357742,
                "cdate": 1700731357742,
                "tmdate": 1700731357742,
                "mdate": 1700731357742,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "pJoU3OqVVP",
            "forum": "q4SiDyYQbo",
            "replyto": "q4SiDyYQbo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3736/Reviewer_n65V"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3736/Reviewer_n65V"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the effect of under-representation on the performance of minority groups in the context of self-supervised learning (SSL), specifically contrastive learning (CL). They show that CL tends to collapse representations of minority groups with certain majority groups, leading to representation harms and downstream allocation harms even when labeled data is balanced. Theory and experiments are presented to support their results."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This is a well written paper that discusses an important topic that is well motivated. This rigorous analysis is likely of interest to practitioners and useful to mitigate the potential harm from CL methods.\n2. The empirical study is good and the theoretical study adds a solid foundation to the empirical results. Both empirical and theoretical findings are promising.\n3. Section 4 is also quite interesting, showing how representation harms can cause allocation harms."
                },
                "weaknesses": {
                    "value": "1. There needs to be an intuitive definition of allocative harms and representation harms when they are first mentioned in the intro, which matches the precise definition in section 2.\n2. Figure text is generally too small to see clearly.\n3. Why does this metric for representation harm make sense? It seems like an important decision critical for the rest of the paper, so needs better justification.\n4. The examples used in section 2 are not very useful - sure automobiles and trucks could collapse but is it the worst thing - are there more compelling real-world examples to illustrate these problems?\n5. Why are the metrics for representation harm in 2.1.2 and 2.2.2 different? This seems weird. Even if the exact distance (eg cosine vs l2 for image or word embeddings) are different - why are the metrics different?\n6. Why do sections 5 and 6 require a different data setup? Specifically, why is causal mediation analysis the right framework to study section 6 - this was not motivated.\n7. The empirical analysis is conducted only on CIFAR10 and BIASBIOS datasets - I would have liked to see more to further strengthen the results in the paper, such as including celebA which is quite standard for studying biases in vision models, or perhaps even with results on a CLIP model for results on image-text models."
                },
                "questions": {
                    "value": "see weaknesses above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3736/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3736/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3736/Reviewer_n65V"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3736/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698812390900,
            "cdate": 1698812390900,
            "tmdate": 1700715476893,
            "mdate": 1700715476893,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pFfcHcbGe7",
                "forum": "q4SiDyYQbo",
                "replyto": "pJoU3OqVVP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3736/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3736/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer n65V"
                    },
                    "comment": {
                        "value": "Thank you for your insightful comments and questions. Please see our responses below. \n\n\n**Intuitive definition of allocative harms and representation harms:** \nWe added an intuitive definition and an example of allocative harms in the first paragraph of the Introduction. *Allocation harm* refers to the demographic disparities in resource allocations, and this harm is easily traced back to the rate of misclassification of the underlying resource allocation mechanism. In our eq. (4.2) we use this difference miclassification rate to quantify the allocation harm caused by under-representation. \n\n\nWe also extended the second paragraph of the Introduction with an example of *representation harm* to facilitate the intuition behind it. In the third paragraph and in Figure 1 we also present an example using the CIFAR10 dataset, where an undersampling of the `automobile` images causes their representations to cluster with those of `trucks`. In Section 2.1.2, we measure this clustering by calculating the ratio of the average cosine distances between the representations of two groups when one of them is under-represented to the average distance between the same two groups when they are class-balanced. \n\n\n**Different representation harm metrics in Sections 2.1.2 and 2.2.2:** Although the exact quantification of representation harm metric may depend on specific instances of under-representation, the main idea behind the metrics are similar: they measure the collapse of the representations of an under-represented group with semantically similar groups. In our experiments with the CIFAR10 dataset in Section 2.1 we *control the undersampling* for each class and wish to demonstrate that the collapse grows/emerges when the underrepresentation occurs. In our experiments with the BiasBios dataset, we wish to demonstrate the potential harmfulness of collapse in a real data scenario where *underrepresentation occurs naturally*, which requires a slightly different measure of collapse. Specifically, we measure the ratio of the similarity of samples with the same gender and different occupations to the similarity of samples with different gender and the same occupation. This measure allows us to notice harmful cases of collapse, such as female surgeons being more similar to female dentists than to male surgeons. \n\n\n**Justification of the representation harm metric:** We reiterate that the key idea behind measuring representation harm is to measure *collapse* between groups in the data, while relevant measures of collapse, the definitions of groups, and the kinds of groups between which collapse is most problematic may vary across domains and applications.\n\n\n**Examples used in Section 2 are not very useful:** The collapse between `automobile` and `truck` representations (in the third paragraph of Section 1 and Section 2.1) is an example to illustrate the idea of representation harm. For a more realistic example, we refer to the Wall Street Journal article titled \"Google Mistakenly Tags Black People as 'Gorillas,' Showing Limits of Algorithms\" [3]. We have included this example in the second paragraph in the Introduction and in the first paragraph of Section 2.1.2. Additionally, we provide realistic examples in our experiments with the BiasBios dataset in Section 2.2.2, where the representations of under-represented female surgeons are closer to the representation of female dentists than they are to male surgeons. Similar harm is also observed between the `attorney` and `paralegal` professions. For a more detailed discussion, see our last paragraph in Section 2.2.2 named **Results**. \n\n**Why do sections 5 and 6 require a different data setup?** We assume that the reviewer meant Sections 3 and 4. If so, then we point out that the synthetic experiments in Section 3 are used to motivate and interpret our theoretical analysis (Section 3.2) and to draw its connections with our empirical studies in Section 2. On the other hand, the causal mediation analysis in Section 4 shows that in CIFAR10 the downstream allocation harm in the classification task is partly caused by the representation harm.  \n\n**Motivation for causal framework:** As we explain in the second line of the first paragraph of Section 4 and in Section 4.1, causal mediation analysis [1] is the statistically principled way to dissect total allocation harm (**TE**) and tease out the part caused by representation harm through the natural indirect effect (**NIE**)."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3736/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700105058850,
                "cdate": 1700105058850,
                "tmdate": 1700105058850,
                "mdate": 1700105058850,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iBcv3V428k",
                "forum": "q4SiDyYQbo",
                "replyto": "hPhMPbNlA5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3736/Reviewer_n65V"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3736/Reviewer_n65V"
                ],
                "content": {
                    "title": {
                        "value": "thanks for you response"
                    },
                    "comment": {
                        "value": "Thanks for the detailed explanation which addressed most of my concerns, so I raise my rating to marginally above. I would suggest clarifying the choices for definitions for different biases and keeping them consistent, leading with more informative examples for unfairness rather than trucks and cars, and better motivations for the causal framework in the updated paper, specifically, what other frameworks could one consider, and do they lead to the same theoretical results?"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3736/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700715461082,
                "cdate": 1700715461082,
                "tmdate": 1700715461082,
                "mdate": 1700715461082,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "oo8f5Jz3zD",
            "forum": "q4SiDyYQbo",
            "replyto": "q4SiDyYQbo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3736/Reviewer_X2wa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3736/Reviewer_X2wa"
            ],
            "content": {
                "summary": {
                    "value": "The study presented in this paper concentrates on examining how contrastive learning (CL) can cause representation harm, particularly when certain groups are not adequately represented in the training data. The researchers demonstrate that these underrepresented groups often merge into other semantically similar groups that are better represented. Further, through a theoretical analysis involving graphs, it is shown that increased connectivity between two groups of nodes leads to their convergence. Lastly, a causal analysis reveals that the detrimental effects on representation caused by CL are irreparable for subsequent tasks, even when a probe is trained using the CL representations."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.\tThe composition of the paper is clear and comprehensive, discussing results in depth and highlighting representational harm. The paper offers practical insights to diminish the adverse effects of CL techniques.\n2.\tSection 4 presents an intriguing analysis, exploring how representational biases can lead to allocation disparities.\n3.\tThe paper's empirical research is commendable, and its theoretical framework provides a robust underpinning for the empirical observations. The outcomes from both empirical and theoretical perspectives appear promising."
                },
                "weaknesses": {
                    "value": "1.\tThe text in the figures is too small for easy readability and needs enlargement for better clarity.\n2.\tA more thorough justification is needed for the chosen metric of representation harm, given its critical importance to the paper's analysis.\n3.\tThe necessity for different data setups in Sections 5 and 6, particularly the choice of causal mediation analysis for Section 6, lacks proper motivation and explanation.\n4.\tThe paper's primary limitation is the absence of a comprehensive large-scale study, especially in the realm of self-supervised learning (SSL)."
                },
                "questions": {
                    "value": "See weaknesses above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3736/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3736/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3736/Reviewer_X2wa"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3736/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1700501298047,
            "cdate": 1700501298047,
            "tmdate": 1700501298047,
            "mdate": 1700501298047,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "rNlIbrw98g",
                "forum": "q4SiDyYQbo",
                "replyto": "oo8f5Jz3zD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3736/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3736/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer X2wa"
                    },
                    "comment": {
                        "value": "Thank you for your insightful comments and questions. Please see our responses below. \n\n\n**Enlarge texts in figures:** Thank you for the suggestion. We have updated some of the figures in the main draft with a larger text and shall update our other figures (in the main and supplementary draft) shortly. If there are any figures remaining that you find difficult to read, let us know which ones and we will try to improve their readability.\n\n**Justification of the representation harm metric:** We reiterate that the key idea behind measuring representation harm is to measure *collapse* between groups in the data, while relevant measures of collapse, the definitions of groups, and the kinds of groups between which collapse is most problematic may vary across domains and applications.\n\n\n**Different data setups in Sections 5 and 6:** We assume that this was a typo, and you meant Sections 3 and 4. If so, then we point out that the synthetic experiments in Section 3 are used to motivate and interpret our theoretical analysis (Section 3.2) and to draw its connections with our empirical studies in Section 2. On the other hand, the causal mediation analysis in Section 4 shows that in CIFAR10 the downstream allocation harm in the classification task is partly caused by the representation harm.  \n\n\n**Motivation for causal framework:** As we explain in the second line of the first paragraph of Section 4 and in Section 4.1, causal mediation analysis [1] is the statistically principled way to dissect total allocation harm (**TE**) and tease out the part caused by representation harm through the natural indirect effect (**NIE**).\n\n**Absence of a comprehensive large-scale study:** We believe that the experiments conducted with the two datasets, the synthetic dataset, and the theoretical analysis were sufficient to demonstrate that under-representation can lead to representation and allocation harm in contrastive learning settings. In addition to various CL methods, such as SimCLR, SimSiam, and SimCSE, we have also included the *boosted contrastive learning* method [2] (in Section 5) to further strengthen our experimental results. Although we acknowledge that additional experiments would be beneficial, the current paper already consists of nine pages of main text and 11 pages of supplementary material, not including references.\n\n---\n# References\n\n[1] Pearl, J. (2022). Direct and indirect effects. In Probabilistic and causal inference: the works of Judea Pearl (pp. 373-392).\n\n[2] Zhou, Z., Yao, J., Wang, Y. F., Han, B., & Zhang, Y. (2022, June). Contrastive learning with boosted memorization. In International Conference on Machine Learning (pp. 27367-27377). PMLR."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3736/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700512629904,
                "cdate": 1700512629904,
                "tmdate": 1700512629904,
                "mdate": 1700512629904,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]