[
    {
        "title": "Residual Denoising Diffusion Models"
    },
    {
        "review": {
            "id": "sy6ZH02hBC",
            "forum": "aKx0RBUvFh",
            "replyto": "aKx0RBUvFh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1592/Reviewer_TatZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1592/Reviewer_TatZ"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes residual denoising diffusion models (RDDM), which decouples the traditional single denoising diffusion process into\nresidual diffusion and noise diffusion."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper compares various tasks."
                },
                "weaknesses": {
                    "value": "*The data provided for inpainting tasks is limited. I would like the authors to conduct quantitative comparisons, especially on the CelebA and Places2 datasets, and compare with state-of-the-art diffusion models (2,3), including considerations of efficiency and parameter count.\n\n*Residual diffusion has been explored and discussed extensively in the domain of image restoration (1,2). It should be discussed in detail and compared with them.\n\n*Please provide a comparison of the computational complexity, runtime, and parameter count for the methods being compared.\n\n*For the deraining task in Table 3, please compare it with Restormer using several standard datasets, including comparisons of runtime efficiency and parameter count.\n\n\n(1) Srdiff: Single image super-resolution with diffusion probabilistic models\n(2) Diffir: Efficient diffusion model for image restoration\n(3) Repaint: Inpainting using denoising diffusion probabilistic models\n(4) Restormer: Efficient transformer for high-resolution image restoration"
                },
                "questions": {
                    "value": "check weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1592/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1592/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1592/Reviewer_TatZ"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1592/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697522280961,
            "cdate": 1697522280961,
            "tmdate": 1699636087865,
            "mdate": 1699636087865,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "trBs5ncjUr",
            "forum": "aKx0RBUvFh",
            "replyto": "aKx0RBUvFh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1592/Reviewer_a71e"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1592/Reviewer_a71e"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces Residual Denoising Diffusion Models (RDDM), a dual diffusion process. The proposed RDDM decouples the diffusion process into residual diffusion and noise diffusion, which can unify the image restoration and generation process. The authors demonstrate the consistency of RDDM with the diffusion models DDPM and DDIM by transforming coefficient schedules. Additionally, they propose a partially path-independent generation process. Experiments demonstrate the effectiveness of RDDM."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The authors propose RDDM as a unified framework for image restoration and generation. It offers a versatile approach to these related tasks.\n2. The authors demonstrate the consistency of RDDM with DDPM/DDIM through coefficient schedule transformations.\n3. The proposed partially path-independent generation process decouples residuals and noise, and reasonably explains the role of the two branches.\n4. They provide the code, which shows the solidness of the work."
                },
                "weaknesses": {
                    "value": "The paper lacks perceptual metrics or a detailed comparison for some tasks, such as Low-light and Deraining, where RDDM performs better regarding PSNR and SSIM. It would be beneficial to provide more comprehensive comparisons, especially using perceptual metrics. Additionally, the paper evaluates the performance at 5 steps for shadow removal and deraining, and 2 steps for low-light and deblurring. Since step numbers affect performance, it is recommended to analyze the impact of different numbers of steps on performance."
                },
                "questions": {
                    "value": "1. In Table 1, RDDM performs better in different strategies for two restoration tasks, Low-light (LOL) and Deraining (RainDrop). It would be beneficial to explain this phenomenon.\n2. Provide more comparisons in terms of different metrics and evaluate the model's performance with more steps in Low-light and Deraining."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1592/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1592/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1592/Reviewer_a71e"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1592/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697529839232,
            "cdate": 1697529839232,
            "tmdate": 1699636087740,
            "mdate": 1699636087740,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "47YyfYot8w",
            "forum": "aKx0RBUvFh",
            "replyto": "aKx0RBUvFh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1592/Reviewer_JomK"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1592/Reviewer_JomK"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a unified model for image generation and restoration with the concept of residual. The proposed method is compatible with different diffusion models and sampling strategies. It can also extend to image restoration task."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This paper unified image generation and generation in a framework.\n2. This paper demonstrates its effectiveness on various image restoration task.\n2. This paper is well-writen and easy-to-understand."
                },
                "weaknesses": {
                    "value": "1. The novelty is limited. It seems more like a combination of two existing components. The concept of residual is not rare in diffusion models. Several previous works employ the same idea in image restoration task [1][2]. Method [1] already introduced the residual concept in restoration task and verified the effectiveness. Beseds, this paper didn't cite these methods.\n2. This method only mathetically combines image generation and restoration. In the experiments, it employ pretrained diffusion models for image generation with only coefficient transformation. While for image restoration, it needs to retrain the diffusion model for different restoration tasks.\n[1] Image restoration with mean-reverting stochastic differential equations\n[2] Resshift: Efficient diffusion model for image super-resolution by residual shifting."
                },
                "questions": {
                    "value": "Refer to the weakness and questions mentioned above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1592/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1592/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1592/Reviewer_JomK"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1592/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698470256500,
            "cdate": 1698470256500,
            "tmdate": 1699636087666,
            "mdate": 1699636087666,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "TwDqa7u7IW",
            "forum": "aKx0RBUvFh",
            "replyto": "aKx0RBUvFh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1592/Reviewer_vFvZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1592/Reviewer_vFvZ"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a novel framework for diffusion models named residual denoising diffusion models (RDDM), which is used for image restoration and image generation. RDDM decouples the diffusion framework into residual diffusion and noise diffusion. The former represents directed diffusion and the latter represents randomness in the diffusion process.  Qualitative and quantitative experiments showed the superiority of the method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The results in the paper show significant improvement in image generation and image restoration.\n2. The proposed architectural provides a new idea for the interpretability of diffusion models and more accurate results can be obtained with fewer sampling steps."
                },
                "weaknesses": {
                    "value": "1. Sampling speed in reverse process is an important factor that influences the quality of diffusion models. Compared with DDPM, DDIM, and other diffusion models, does RDDM have an advantage in sampling speed?\n\n2. In Eq.10 (reverse process), the author sets \\eta to 0, which represent a deterministic generation process. What is the advantage to set \\eta to 0?\n\n3. The author's approach to minimizing the loss function is minimizing the upper bound of Eq. 25, i.e. minimizing Eq. 26. However, it seems that in the derivation from Equation 25 to Eq.  26, the author did not explicitly consider the relationship of \\alpha_t and \\frac{\\beta_t^2}{\\overline{\\beta}} between Eq.25 and Eq.26. And the author only utilizes \\lambda_{res} and \\lambda_{\\varepsilon} as coefficients for the loss function. How can author ensure that Eq. 26 is indeed an upper bound for Eq. 25?"
                },
                "questions": {
                    "value": "Please refer to weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1592/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1592/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1592/Reviewer_vFvZ"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1592/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698859852246,
            "cdate": 1698859852246,
            "tmdate": 1699636087595,
            "mdate": 1699636087595,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]