[
    {
        "title": "Towards Aligned Layout Generation via Diffusion Model with Aesthetic Constraints"
    },
    {
        "review": {
            "id": "t7pWGSj6qI",
            "forum": "kJ0qp9Xdsh",
            "replyto": "kJ0qp9Xdsh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6682/Reviewer_w7ws"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6682/Reviewer_w7ws"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a novel unified continuous diffusion model, namely LAyout Constriant Diffusion modEl (LACE) for layout generation. To address the aesthetic issue of the diffusion model, the authors propose two differential constraints, including alignment constraint and overlap constraint, to address element arrangement and overlap issues. The experiments show that the proposed LACE makes a good performance on PubLayNet and Rico datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The paper is interesting, well-written and original, and my impression is positive.\n* The proposed framework for various generation tasks is smart and effective.\n* The quantitative experiment results show the superiority of the proposed method over existing approaches."
                },
                "weaknesses": {
                    "value": "* I would appreciate it if the authors give more details of the proposed framework given different conditions.\n* The ablation study can be extended to illustrate the contribution of two constraints. For example, Figure 3 only shows the visualization result of global alignment and overlap constraints. I would recommend studying the effectiveness of all sub-constraints, e.g., local and global alignment, quantitatively and qualitatively.\n* The limitations of the proposed method should be discussed. This can give good guidance for the application in real-world situations."
                },
                "questions": {
                    "value": "Please refer to the weakness part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6682/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698505176365,
            "cdate": 1698505176365,
            "tmdate": 1699636765781,
            "mdate": 1699636765781,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "33FwL1ZMl1",
                "forum": "kJ0qp9Xdsh",
                "replyto": "t7pWGSj6qI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6682/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6682/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "W1: I would appreciate it if the authors give more details of the proposed framework given different conditions.\n\nA: Thank you for your feedback. We have added detailed information about our model architecture, hyper-parameter settings, and training details in Appendix B.3. In short, our model is a four-layer transformer with a modified adaptive layer normalization for time variable injection. This architecture is adopted from the source code of LayoutDM. We added two FNNs to encode and decode element vectors. The model size remains comparable. We use only one set of parameters for different conditional tasks. Known entries are fixed throughout the generation process using a binary mask as described at the end of section 2.2. For refinement task, we treat given noisy layout as a noisy latent states at a certain time step and finish the generation process as described at the end of section 4.2.\n\nW2: The ablation study can be extended to illustrate the contribution of two constraints. For example, Figure 3 only shows the visualization result of global alignment and overlap constraints. I would recommend studying the effectiveness of all sub-constraints, e.g., local and global alignment, quantitatively and qualitatively.\n\nA: Thank you for your suggestion. We have added more results in our ablation study and Appendix A. We observe that global alignment constraint performs comparably to local alignment. However, in theory, it should be less effective because local alignment constraints directly minimize the alignment metric. In addition, the global constraint is needed in post-processing for better visual quality.\n\nW3: The limitations of the proposed method should be discussed. This can give good guidance for the application in real-world situations.\n\nA: Thank you for your suggestion. We have added the limitation in the revised conclusion section. The primary limitations include (some also apply to related methods): 1. It generates layouts as boxes, not segmentations. 2. the model is not background-aware or content-aware. 3. The maximum number of elements is limited. 4. It relies on a closed-vocabulary label set. \n\nDespite these limitations, the method shows promise in applications like layout-guided image generation, realistic scene text generation through TextDiffuser, and automated poster design, offering valuable contributions."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6682/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700455009483,
                "cdate": 1700455009483,
                "tmdate": 1700653970334,
                "mdate": 1700653970334,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wNlGtdeyO0",
            "forum": "kJ0qp9Xdsh",
            "replyto": "kJ0qp9Xdsh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6682/Reviewer_5Gyc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6682/Reviewer_5Gyc"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on the controllable layout generation tasks, and formulates them as conditional generation processes in continuous space for aesthetic quality optimization. Two aesthetic constraint losses are proposed for global alignment and minimizing overlap in the layout during the training and post-processing stages. The experimental results show that the proposed method achieves the state-of-the-art performances on several benchmarks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Compared to existing works that use discrete diffusion models, the proposed method based on continuous diffusion models can incorporate continuous aesthetic constraints in training. A new alignment loss is proposed to encourage the global alignment of elements. The proposed model can handle multiple generation tasks without retraining."
                },
                "weaknesses": {
                    "value": "1. The key idea of this paper is to enable constraint optimization by formulating layout generation as conditional generation processes in continuous space. However, a post-processing step is still conducted. I was wondering about the advantage of the proposed method compared to those that directly apply the post-processing algorithm to the discrete diffusion models.\n2. Several layout generation related works [1-3] are neither cited nor discussed in the paper.\n3. For the overlap constraint, the current loss pushes elements away from each other. However, in some cases, designers would intentionally use overlap to make the top element look closer to the viewer. For example, text elements are often located above the image elements in banner ads. The usefulness of such a constraint would be questionable by directly applying it to all elements in graphic designs.\n4. Why the evaluation metrics do not consider overlap, while the aesthetic constraints contain the overlap in layout?\n\n[1] Zheng, Xinru, et al. \"Content-aware generative modeling of graphic design layouts.\" ACM TOG, 2019.\n[2] Zhang, Junyi, et al. \"LayoutDiffusion: Improving Graphic Layout Generation by Discrete Diffusion Probabilistic Models.\" ICCV 2023.\n[3] Jiang, Zhaoyun, et al. \"LayoutFormer++: Conditional Graphic Layout Generation via Constraint Serialization and Decoding Space Restriction.\" CVPR 2023."
                },
                "questions": {
                    "value": "1. How to determine the time-dependent constraint weight and the threshold used in the post-processing stage?\n2. Are there any qualitative results that demonstrate diversity of the generated layouts?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6682/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6682/Reviewer_5Gyc",
                        "ICLR.cc/2024/Conference/Submission6682/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6682/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698675905116,
            "cdate": 1698675905116,
            "tmdate": 1700790992922,
            "mdate": 1700790992922,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AVPhgLW5MP",
                "forum": "kJ0qp9Xdsh",
                "replyto": "wNlGtdeyO0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6682/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6682/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "W1: The key idea of this paper is to enable constraint optimization by formulating layout generation as conditional generation processes in continuous space. However, a post-processing step is still conducted. I was wondering about the advantage of the proposed method compared to those that directly apply the post-processing algorithm to the discrete diffusion models.\n\nA: Thank you for your suggestion. Appendix A includes the required results and discussion, comparing our model with LayoutDM with post-processing. In addition, we include results of LayoutGAN++, which also uses constraints in training and applies post-processing. \n\nWe observe a noticeable FID increase after post-processing for the two competing methods. In contrast, LACE without post-processing outperforms LayoutDM with post-processing. Its performance further increases after post-processing while maintaining a stable FID. These differences are due to the challenge in post-processing, as discussed in section 2.3 of the main text, which is thresholding the misalignment in raw outputs. A small threshold for the alignment mask is insufficient to select severely misaligned pairs, while a large one damages the subtle layout structure, leading to a noticeable increase in FID. These additional results have further enhanced the quality of our paper. \n\nW2: Several layout generation related works [1-3] are neither cited nor discussed in the paper.\n[1] Zheng, Xinru, et al. \"Content-aware generative modeling of graphic design layouts.\" ACM TOG, 2019. [2] Zhang, Junyi, et al. \"LayoutDiffusion: Improving Graphic Layout Generation by Discrete Diffusion Probabilistic Models.\" ICCV 2023. [3] Jiang, Zhaoyun, et al. \"LayoutFormer++: Conditional Graphic Layout Generation via Constraint Serialization and Decoding Space Restriction.\" CVPR 2023.\n\nA: Thank you for your valuable feedback and the suggestion to include these recently published methods. We discuss the relationship between these methods and LACE and introduce and cite these methods in the revised related work section. \n\n1. LayoutDiffusion adopted a design similar to LDGM (Hui, Mude, et al. \"Unifying Layout Generation with a Decoupled Diffusion Model.\" CVPR 2023) significantly enhanced the visual quality in three tasks by using a more effective transformer backbone, particularly improving alignment and overlap metrics. In contrast, our method aims to enhance visual quality by applying constraint functions without scaling up or complicating the network architecture.\n2. LayoutFormer++ employs a novel decoding strategy for high-quality conditional generation. However, its backtracking mechanism can result in multiple rollbacks during the decoding process to address invalid outputs. Moreover, it requires retraining to adapt to various conditional tasks. In contrast, LACE aims to finish generation without rolling back and use one set of parameters to solve different tasks.\n3. The Content-aware Method in [1] solves a more challenging problem by incorporating image and text features into their layout generation model to achieve content-awareness.\n\nDue to the notable differences in model size and architecture between the methods we included in our experiment and that in LayoutDiffusion and LayoutFormer++, a quantitative comparison would be unfair. Consequently, our discussion of these methods is limited to the related work section."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6682/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700454860319,
                "cdate": 1700454860319,
                "tmdate": 1700653872338,
                "mdate": 1700653872338,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Msn3Zvxfuq",
                "forum": "kJ0qp9Xdsh",
                "replyto": "wNlGtdeyO0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6682/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6682/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "W3: For the overlap constraint, the current loss pushes elements away from each other. However, in some cases, designers would intentionally use overlap to make the top element look closer to the viewer. For example, text elements are often located above the image elements in banner ads. The usefulness of such a constraint would be questionable by directly applying it to all elements in graphic designs.\n\nA: We apologize for any confusion regarding the overlap constraint. As noted in the global response, we acknowledge that the overlap constraint is unsuitable for training on the Rico dataset. Thus, we exclude it in the training of the model for Rico, which was noted in section 4.2. However, our method provided a way to add differentiable constraint functions in the diffusion training. The constraint could be replaced or removed as needed.\n\nW4: Why the evaluation metrics do not consider overlap, while the aesthetic constraints contain the overlap in layout?\n\nA: We apologize for the confusion. As mentioned in our global response, we have added the requested alignment and overlap results in Appendix A. We believe these additional results have further enhanced the quality of our paper.\n\nQ1: How to determine the time-dependent constraint weight and the threshold used in the post-processing stage?\n\nA: We have now included a detailed explanation with a supporting figure in Appendix B.1 to demonstrate our empirical approach for determining the time-dependent constraint weights. This weight is empirically set to the point, as demonstrated in the figure, where the corruption process has not introduced too much overlap. Thus, in the reverse process, the coarse structure of the layout has emerged. \n\nThe post-processing threshold is empirically set to 1/64 of the scaled relative canvas size. This setting aligns with real dataset observations, where only ~0.5% of unaligned coordinate pairs has a smaller difference. We have included a more detailed explanation in Appendix B.2.\n\nQ2: Are there any qualitative results that demonstrate diversity of the generated layouts?\n\nA: In response to your query, we've included qualitative results in Appendix C, showcasing the diversity of layouts generated by our model, compared with real data and LayoutDM."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6682/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700454958804,
                "cdate": 1700454958804,
                "tmdate": 1700454958804,
                "mdate": 1700454958804,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FcihKpXyVD",
                "forum": "kJ0qp9Xdsh",
                "replyto": "wNlGtdeyO0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6682/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6682/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We apologize for the oversight in our initial explanation about the similarity between LayoutDiffusion and prior works. Specifically, LayoutDiffusion incorporates discrete Gaussian noise in its design, differing from the approach in LayoutDM and aligning with the method proposed by LDGM. We have corrected this in our revised response to Weakness 2. Additionally, we have cited and discussed these papers in the revised manuscript. We hope this revision adequately addresses your concerns."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6682/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700655544293,
                "cdate": 1700655544293,
                "tmdate": 1700678364778,
                "mdate": 1700678364778,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "F3czvhtdYy",
            "forum": "kJ0qp9Xdsh",
            "replyto": "kJ0qp9Xdsh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6682/Reviewer_6Y7v"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6682/Reviewer_6Y7v"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a novel diffusion model and training process for various conditional and unconditional layout generation tasks. Utilizing a continuous state-space design directly on the target attributes of elements in the layout, the proposed method incorporates both the standard diffusion training objective and novel aesthetic-based objectives (i.e., overlap, alignment) to improve the quality of generated layouts. These improvements lead to a new SoTA model across the majority of layout generation tasks in both the Rico and PubLayNet dataset."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Novel formulation and diffusion model for directly using a continuous state-space for geometric and class properties, which could opens up a new avenue of research for layout generation by exploring diffusion in this space\n\n- Unified framework for both unconditional generation and multiple conditional tasks\n\n- Achieved SoTA in the majority of conditional tasks in both Rico and PubLayNet\n\n- Novel formulation of Overlap and Alignment losses, and a time-dependent constraint schedule for effective optimization of aesthetic constraints during the diffusion process, which can independently benefit future research given the importance of these constraints in good layouts."
                },
                "weaknesses": {
                    "value": "- *Incomplete details for reproduction*: It appears that no training details of the models are reported in the paper and the appendix. It would be extremely helpful for future research for the author(s) the report details such as model architecture, noise schedule, loss schedule, constraint weights, etc, given that this continuous state-space of diffusion for layout generation was previously unexplored.\n\n- *Limited inclusion of qualitative results and human-rater experiments*: It would further improve the paper if the author(s) can provide more qualitative results that demonstrates the differences between the proposed method and existing SoTA, and preferably include a lightweight human-rating study given that the metrics might not fully reflect human preference for layout generation.\n\n- *Missing common metrics*: While FID and MaxIoU is quite representative and established in the layout generation literature, it will be helpful if the author(s) can include alignment and overlap indices, which can further show the effect of the proposed aesthetic constraints."
                },
                "questions": {
                    "value": "- Can the author(s) provide more details of model training (e.g., loss schedule, model architecture), given that the introduced method applied diffusion in a novel and complex state-space that is non-trivial?\n\n- Will the code be open-sourced if this paper is accepted?\n\n- Can you further discuss the importance of the time-dependent constraint weight (preferably empirically)? This appears to be a very important parameter in incorporating aesthetic constraints."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6682/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698884459720,
            "cdate": 1698884459720,
            "tmdate": 1699636765542,
            "mdate": 1699636765542,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "K5bEMiWmIc",
                "forum": "kJ0qp9Xdsh",
                "replyto": "F3czvhtdYy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6682/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6682/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "W1 & Q1: Incomplete details for reproduction: It appears that no training details of the models are reported in the paper and the appendix. It would be extremely helpful for future research for the author(s) the report details such as model architecture, noise schedule, loss schedule, constraint weights, etc, given that this continuous state-space of diffusion for layout generation was previously unexplored. Can the author(s) provide more details of model training (e.g., loss schedule, model architecture), given that the introduced method applied diffusion in a novel and complex state-space that is non-trivial?\n\nA: Thank you for your feedback. We have added detailed information about our model architecture, hyper-parameter settings, and training details in Appendix B.3 and Appendix B.4. In short, our model is a four-layer transformer with a modified adaptive layer normalization for time variable injection. This architecture is adopted from the source code of LayoutDM. We added two FNNs to encode and decode element vectors. The model size remains comparable.\n\nW2:  Limited inclusion of qualitative results and human-rater experiments: It would further improve the paper if the author(s) can provide more qualitative results that demonstrates the differences between the proposed method and existing SoTA, and preferably include a lightweight human-rating study given that the metrics might not fully reflect human preference for layout generation.\n\nA: Thank you for recommending a lightweight human-rating study. We acknowledge its significance and aim to incorporate it in the final version of our paper. We have included demo qualitative results in Appendix C, comparing our model with LayoutDM and real data, which could be used for future human-rating studies. However, due to the time constraints of the rebuttal process, it is hard for us to complete the participant recruitment and execution of the study in time.\n\nW3: Missing common metrics: While FID and MaxIoU is quite representative and established in the layout generation literature, it will be helpful if the author(s) can include alignment and overlap indices, which can further show the effect of the proposed aesthetic constraints.\n\nA: Thank you for your suggestion. As mentioned in our global response, we have incorporated the requested alignment and overlap indices results in Appendix A. We believe these additional results have further enhanced the quality of our paper.\n\nQ2: Will the code be open-sourced if this paper is accepted?\n\nA: Yes, we plan to include a GitHub link of the source code and trained checkpoints in the final version of the paper. And we have provided source code through an Anonymous GitHub link in the revised version.\n\nQ3: Can you further discuss the importance of the time-dependent constraint weight (preferably empirically)? This appears to be a very important parameter in incorporating aesthetic constraints.\n\nA: The time-dependent constraint weight is critical for effective model convergence and output quality. Without this weight, the model struggles to converge, leading to a high Fr\u00e9chet Inception Distance (FID) score, typically remaining above 100, which indicates poor layout quality. We determine the weight empirically as explained in Appendix B.1."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6682/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700454778272,
                "cdate": 1700454778272,
                "tmdate": 1700454778272,
                "mdate": 1700454778272,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Zku9dTQDUl",
                "forum": "kJ0qp9Xdsh",
                "replyto": "K5bEMiWmIc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6682/Reviewer_6Y7v"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6682/Reviewer_6Y7v"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for addressing my concerns. My rating remains unchanged and I am happy to support the acceptance of this paper."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6682/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700672339708,
                "cdate": 1700672339708,
                "tmdate": 1700672339708,
                "mdate": 1700672339708,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LKXHHcPcrE",
            "forum": "kJ0qp9Xdsh",
            "replyto": "kJ0qp9Xdsh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6682/Reviewer_DJP7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6682/Reviewer_DJP7"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a model for unconditional and conditional layout generation, and layout de-noising, where layout is defined as a set of rectangles of particular clas placed on the larger canvas, and conditioning can take form of number of rectangles of each class.The main contribution of the paper is modelling this process as continuous diffusion process, as opposed to the previous work which did it as a discrete diffusion process, after bining the rectangular coordinates. The method outperforms other layout generation models, as well as generic models such as MaskGIT, as measured by FID score and the IoU-related metric. The additional contribution is the introduction of a new aesthetic constraint, which further improves the results, used both as a loss during training, and during post-processing, where the rectangles are adjusted to reduce the object overlap."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Originality: While neither the method nor the application domain is new, it is novel to apply the continuous diffusion to the layout generation problem.\nClarity: The writing is sufficiently clear.\nQuality: The paper features an ablation study highlighting the most important design decisions, such as post-processing, and the use of aesthetic constraint to minimize the loss. The authors promise to make the code and model checkpoints available, but do not provide them together with the submission.\nSignificance: I believe the work has significance in exploring the use of continuous diffusion to layout generation task, but given the somewhat \"toy\" setup of the experiments, the practical applicability and the wider significance of layout generation when specified in this formulation (given only types of objects or initial layout, without any information about the textual content of text fields, or image contents of the image fields, with evaluation done through FID and not human studies) may be limited."
                },
                "weaknesses": {
                    "value": "There aren't significant drawbacks in the manuscript itself, with main potential weakness for me being the question of practicality of the proposed approach or its extensions to any practical application."
                },
                "questions": {
                    "value": "Do you envision any practical applications of the proposed approach? Do you believe it could be extended in a way that would be useful for applications? In which way?\n\nSec. 2.2, \"Conditional generation\": Typo \"We\" --> \"we\"\nPage 4, section \"Overlap constraint\": Typo \"is monotonically identify\" --> \"monotonically identifies\"\nPage 6, Sec. 4.1, \"Datasets\": Typo \"for both dataset\" --> \"for each dataset\" or \"for both datasets\""
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6682/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699034755158,
            "cdate": 1699034755158,
            "tmdate": 1699636765428,
            "mdate": 1699636765428,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4eiYAzyyH4",
                "forum": "kJ0qp9Xdsh",
                "replyto": "LKXHHcPcrE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6682/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6682/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "W1: There aren't significant drawbacks in the manuscript itself, with main potential weakness for me being the question of practicality of the proposed approach or its extensions to any practical application.\n\nA: Thank you for your feedback. Regarding potential applications, please refer to our detailed response to Question 1.\n\nQ1: Do you envision any practical applications of the proposed approach? Do you believe it could be extended in a way that would be useful for applications? In which way?\n\nA: Layout generation can facilitate the design of posters, websites, presentation slides, and mobile applications. For example, conditional layout generation can be applied to convert text files and images into well-organized reports. Additionally, unconditional generation can be integrated with large language models (like ChatGPT) and image generation models (such as Stable Diffusion) for complete automation, with text and image generation models filling empty layout elements.\n\nIn addition, layout generation could be used to assist other generative tasks, including layout-guided image generation [1] and visual text rendering [2]. However, future work is required to enable visual and text content awareness in layout generation.\n\n[1] Li, Yuheng, et al. \"Gligen: Open-set grounded text-to-image generation.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n\n[2] Chen, Jingye, et al. \"TextDiffuser: Diffusion Models as Text Painters.\" arXiv preprint arXiv:2305.10855 (2023).\n\nQ2: Sec. 2.2, \"Conditional generation\": Typo \"We\" --> \"we\" Page 4, section \"Overlap constraint\": Typo \"is monotonically identify\" --> \"monotonically identifies\" Page 6, Sec. 4.1, \"Datasets\": Typo \"for both dataset\" --> \"for each dataset\" or \"for both datasets\"\n\nA: Thank you for pointing out these errors. We have carefully corrected them in our manuscript. Additionally, we have conducted further proofreading to ensure its overall accuracy and clarity."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6682/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700454645997,
                "cdate": 1700454645997,
                "tmdate": 1700454645997,
                "mdate": 1700454645997,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]