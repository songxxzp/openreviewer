[
    {
        "title": "GraphGPT: Graph Learning with Generative Pre-trained Transformers"
    },
    {
        "review": {
            "id": "7K2FQbJt3O",
            "forum": "070DFUdNh7",
            "replyto": "070DFUdNh7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4990/Reviewer_kAz1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4990/Reviewer_kAz1"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces GraphGPT, a new model for graph learning using Generative Pre-training Transformers. By converting graphs or their subgraphs to token sequences via an Eulerian path and pre-training with next-token-prediction, GraphGPT outperforms or matches state-of-the-art methods on various datasets, for tasks at graph, edge, and node levels, including PCQM4Mv2, ogbl-ppa, and ogbn-proteins from OGB. Its generative pre-training allows training with 400M+ parameters with increasing performance, surpassing the capability of GNNs and previous graph transformers."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper presents a compelling and effective approach to converting graph learning problems into NLP problems, which is an innovative bridge between the domains of NLP and graph learning.\n- The method showcased state-of-the-art performance, specifically on the ogbl-ppa link prediction dataset."
                },
                "weaknesses": {
                    "value": "1. **Discussion on limitations**: The paper does not delve into potential limitations of the proposed method.\n2. **Reference gap**: Despite the extensive literature on graph transformers, like the works of Ramp\u00e1\u0161ek et al. 2022 and Chen et al. 2022, the paper cites only a few, leading to a lack of comprehensive context.\n3. **Computational concerns**: The proposed method, while achieving good performance on some datasets, appears to demand significant computational resources. There is a clear lack of discussion on the resources' requirements and the computation time compared to other graph models.\n4. **Transferability issues**: GraphGPT has to be re-trained for each specific dataset, raising concerns about its adaptability across diverse graph modalities or sizes. This constraint, paired with the computational burden of pre-training a large GraphGPT, casts doubts on its practical applicability.\n5. **Performance claims**: The paper might be overstating its model's performance. While it excels in the ogbl-ppa link prediction dataset, its performance appears mediocre in both graph and node-level prediction tasks when compared against similar scale GNN/GT baseline models.\n\n_References:_\n\n- Ramp\u00e1\u0161ek, Ladislav, et al. \"Recipe for a general, powerful, scalable graph transformer.\" NeurIPs 2022.\n- Chen, Dexiong, Leslie O\u2019Bray, and Karsten Borgwardt. \"Structure-aware transformer for graph representation learning.\" ICML 2022."
                },
                "questions": {
                    "value": "**Q1**: What factors contribute to the model's superior performance in the ogbl-ppa link prediction dataset, yet not replicating similar success in node and graph-level prediction tasks? Some intuitive explanation would be helpful.\n\nI will be happy to increase my rating if the authors can address all my concerns and questions"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4990/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698670948519,
            "cdate": 1698670948519,
            "tmdate": 1699636486562,
            "mdate": 1699636486562,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bJJurrl3ZL",
                "forum": "070DFUdNh7",
                "replyto": "7K2FQbJt3O",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4990/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4990/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Discussion on limitations and performance"
                    },
                    "comment": {
                        "value": "W1: Discussion on limitations: The paper does not delve into potential limitations of the proposed method.\n\nA: Thank you for pointing out. We will add the following discussion on limitations in the paper:\n1.\tTransferability: Due to the lack of shared semantics among different graph datasets, GraphGPT has to be pre-trained on target dataset itself and then fine-tuned. However, there are two exceptions. \n\na). Structure-understanding GraphGPT. Graph structures are shared across all the graph datasets, for example, node degrees, motifs, edge directions and etc. We can pre-train a structure-understanding GraphGPT using structure information only, i.e., removing all the semantics (node/edge attributes) in the graphs. This GraphGPT would be able to do any graph structure understanding related tasks, if trained with enough data and large model. Besides, it could be continued pre-trained later on specific dataset with semantics information.\n\nb). Domain specific GraphGPT. For example, small organic molecules datasets share the same semantics information, i.e., nodes (atoms) and edges (bonds). We can collect all available molecules datasets and pre-train a molecule-understanding GraphGPT. It would have a wide application in drug and material research.\n2.\tDataset size: When the graph dataset for pre-train and fine-tune is small or medium, GraphGPT might not perform well. For example, ogbn-proteins and ogbg-molpcba datasets. It could be overcome by collecting more data of the same semantics for pre-training/fine-tuning. Also, continue pre-training on above mentioned structure-understanding GraphGPT could also be a direction to explore.\n3.\tCompute budget: The pre-training on one big graph (ogbn-proteins and ogbl-ppa) and many small graphs (PCQM4M-v2) with large models (50M+ params) are very compute expensive. \n\nFor example, pre-train a GraphGPT-base (100M+) for PCQM4M-v2 with 25.6 B tokens will take about 240 V100 GPU hours (4 V100 trained with 60 hours). Fine-tune cost 20 V100-hours per epoch. \n\nFor small/medium dataset, the trade-off between compute budget and performance may imply that GraphGPT is not the first choice.\n\nHowever, to pursue superior performance given large amount of data, GraphGPT with large number of parameters is a very competitive candidate.\n\nMeanwhile, int8/int4-quantization techniques* has been developed to allow much faster inference, even training. Parallel training frameworks like DeepSpeed and Megatron enable fast mixed-precision and bf-16 precision training utilizing thousands of GPUs. Transformer-specific optimization techniques like FlashAttention-2** allows us to speed-up the training of transformer models. Last but not least, the development of tensor accelerator chips is very fast. As they are becoming much faster and cheaper, compute burden won\u2019t be a big problem.\n\n* 8-bit Optimizers via Block-wise Quantization\n* GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers\n** FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning\n\n\n4.\tContext window: The context window of transformer affects the compute burden very much, so it limits the efficiency of training large (sub)graphs. Besides relying on the development of efficient training of transformers (e.g., FlashAttention-2), finding short sequence representation of graphs, and exploring better ways to extract sequences from big graphs are interesting to study further.\n\nThese limitations worth further explorations, and might serve as potential research directions.\n\nW2: Reference gap\n\nA: Thank you for pointing out. We will add them in the reference.\n\nW3: Computational concerns\n\nA: Please refer to the above discussion on limitations about compute budget.\n\nW4: Transferability issues\n\nA: Please refer to the above discussion on limitations about transferability.\n\nW5: Performance claims\n\nA: Our performance on the large scale graph-level task PCQM4M-v2 is on par with the SOTA given the comparable number of parameters."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700647886767,
                "cdate": 1700647886767,
                "tmdate": 1700647886767,
                "mdate": 1700647886767,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VsnNVfaDmK",
                "forum": "070DFUdNh7",
                "replyto": "7K2FQbJt3O",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4990/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4990/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Analysis of performance gap among different graph tasks"
                    },
                    "comment": {
                        "value": "Q1: Performance gap among edge-/node-/graph-level tasks\n\nA: The performance of GraphGPT on edge-level dataset ogbl-ppa and graph-level dataset PCQM4M-v2 are good, while on node-level ogbn-proteins and ogbg-molpcba below SOTA. \n\n1. Dataset size: ogbl-ppa and PCQM4M-v2 are large for pre-train and fine-tune. For example, ogbl-ppa\u2019s pre-train and fine-tune data is actually very huge. The positive samples are 30M+ edges, and the negative samples are randomly sampled node pairs (i.e., negative edges) of scale 576,2892 ~ 332 B. This will allow the large model to be well trained without much over-fitting. At the same time, PCQM4M-v2 is pre-trained with 3.7M+ molecules, and fine-tuned with 3.38M.\n\nIn contrast, ogbn-proteins\u2019 fine-tune dataset is only about 87K, and ogbg-molpcba\u2019s pre-train and fine-tune dataset is only about 0.4M.\n\n2. Consistency: For ogbl-ppa, the pre-training and fine-tuning tasks are close. In pre-training, NTP predict next attributes and next nodes. Predicting next nodes can be regarded as link prediction, which is aligned with the fine-tune task. \n\nIn contrast, for ogbn-proteins, the NTP that predicts the node\u2019 attributes is similar to the fine-tune task of predicting node properties. However, the node attribute is the 8 species, which is simple so that model cannot learn enough information relevant to fine-tune task during pre-training.\n\n3. Please refer to the reply to Q1 and Q2 of reviewer `VKoy` for additional analysis."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700647933083,
                "cdate": 1700647933083,
                "tmdate": 1700647933083,
                "mdate": 1700647933083,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "NVyXWqo4cJ",
            "forum": "070DFUdNh7",
            "replyto": "070DFUdNh7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4990/Reviewer_VKoy"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4990/Reviewer_VKoy"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents GraphGPT, an adaptation of the Transformer network tailored for graph data. GraphGPT is adept at handling a wide range of graph datasets and various graph-related tasks, including node, edge, and graph prediction. A notable innovation in this work is the use of (semi-)Eulerian paths to transform graphs into sequences of tokens. This transformation is designed to be lossless and reversible, ensuring the integrity of the original graph data. GraphGPT is pre-trained on the NTP task and is fully compatible with the Transformer's decoding architecture. This compatibility allows GraphGPT to fully leverage the benefits of generative pre-training. Empirical results showcased in the paper highlight GraphGPT's performance, achieving near or on par with state-of-the-art results in tasks at graph level, edge-level, and node level."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is well-written and logically structured. The application of (semi-)Eulerian paths is a  novel idea, demonstrating considerable versatility in converting graph structures into decoding sequences. The diverse empirical results underscore the adaptability of GraphGPT, showcasing its ability to yield competitive performance across a range of traditional graph tasks."
                },
                "weaknesses": {
                    "value": "The empirical results highlight a critical aspect of GraphGPT, especially in terms of its performance relative to the number of parameters. While the approach is versatile and straightforward, making it adaptable for various tasks, I find its substantial size problematic. The graph-level and node-level task performances, in my opinion, don't seem to justify the significantly larger scale of GraphGPT compared to its competitors.\n\nI recognize the primary advantage of GraphGPT as its simplicity in application across different graph tasks. However, I question the rationale for preferring GraphGPT in scenarios other than edge-level tasks. While alternative methods may be more intricate and rely on \"tricks,\" they often prove to be more efficient and effective.\n\nMoreover, I am skeptical of the assertion that GraphGPT is immune to over-smoothing and over-squashing, based solely on the moderate performance improvements observed with increased parameter size. This claim demands further scrutiny, particularly when considering the relatively poor performance in node classification tasks.\n\nI believe that a more comprehensive investigation is required, especially focusing on how node parameters are represented. It's essential to determine whether the modest improvements in performance are indeed due to the avoidance of over-smoothing and over-squashing or whether other factors are at play."
                },
                "questions": {
                    "value": "see weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4990/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698724527291,
            "cdate": 1698724527291,
            "tmdate": 1699636486459,
            "mdate": 1699636486459,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xZR0wFOVQv",
                "forum": "070DFUdNh7",
                "replyto": "NVyXWqo4cJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4990/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4990/Authors"
                ],
                "content": {
                    "title": {
                        "value": "performance concerns and over-smoothing"
                    },
                    "comment": {
                        "value": "Q1: performance on graph/node-level tasks and scalability\n\nA: The performance of GraphGPT on large-scale graph-level dataset PCQM4M-v2 (3.7m) is on par with the SOTA with the similar number of parameters.\n\nThe performance on the medium-scale graph-level dataset ogbg-molpcba (0.4m) is below SOTA, the reason could be two:\n\n1.\tThe dataset is still `small`. Pre-trained on itself only cannot let the large model gains much knowledge of molecules before fine-tuning. In fine-tune stage, small training data + non-well-pre-trained large model, will easily overfit, and lead to below SOTA results. Practically, it has been demonstrated many times that handcrafted features + simple model usually outperforms large models given limited data.\n\n2.\tOptimization. Unlike NLP, transformer on molecule data is not well studied yet. So the best optimization strategies remain to be explored. For example, the optimizer and its hyper-parameters, the regularization methods and etc. Recently we found that gradient-clipping that commonly used in NLP hurts the performance of GraphGPT very much.\n\nBased on the practice of Graphormer, to perform well in ogbg-molpcba, it is pre-trained on the PCQM4M\u2019s 3.7m+ supervised samples. So, together with our preliminary experiments, we hypothesize that GraphGPT on ogbg-molpcba could be further improved when pre-trained with NTP on more molecules data, and better optimization hyper-parameters.\n\n\nQ2: over-smoothing and over-squashing \n\nA: Over-smoothing points out that GNN\u2019s nodes\u2019 output embeddings tend to be the same when the number of layers increases. It restricts GNN to be usually less than 10 layers and much less than 1m parameters. When go deeper, the performance of GNNs drops significantly.\n\n  In contrast, our GraphGPT-large has 24 layers and 400m parameters, much deeper and larger than GNNs. More importantly, our models\u2019 performance keeps increase, which is clearly not the sign of over-smoothing, although its performance is still below SOTA.\n\n   In addition, during pre-training with NTP, each node\u2019s output embedding will be used to calculate the cross-entropy loss with the embeddings of next node or attributes. If these embeddings are close, the training loss will not decrease and the model cannot be trained. From pre-train loss curve, we can see that large model yields lower training loss, and it is still decreasing after trained with billions of tokens.\n\nOver-squashing stats that long-range important information will diminish much due to the aggregating mechanism of GNNs. GraphGPT\u2019s global self-attention can easily overcome this limitation, which has been well studied in NLP and CV.\n\n   The main reasons of node-level task ogbn-proteins below SOTA could as follows:\n\n1.\tTraining data too small in fine-tune stage. This dataset has about 132k nodes, and 86.6k are used to training. It\u2019s very small compare to the model size, so it can be easily overfitting.\n\n2.\tInformation (feature) per-sample is too little. In GraphGPT, each node sample can only extract information from 9 neighbors when using context window 256 (Tab. 9 in App. A1). In contrast, SOTA GNNs partition the graph into 10, each partition contains 8.7k nodes, and the node can gather information from all the nodes in the same partition during training. The limited context window restrict GraphGPT attending many neighbor nodes, but it can be overcome as more efficient training techniques of transformer with larger context window are developed, for example, FlashAttention-2*.\n\n* FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700647274284,
                "cdate": 1700647274284,
                "tmdate": 1700652350244,
                "mdate": 1700652350244,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Xjab4F5vly",
                "forum": "070DFUdNh7",
                "replyto": "xZR0wFOVQv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4990/Reviewer_VKoy"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4990/Reviewer_VKoy"
                ],
                "content": {
                    "title": {
                        "value": "Responding the author's reply"
                    },
                    "comment": {
                        "value": "Thank you for providing explanations to my questions. However, I find the explanations unsatisfactory. Attributing the poor performance to the size of the dataset and the optimization scheme as excuses only further highlights the paper's lack of readiness. Moreover, using the size of GraphGPT to justify the absence of over-smoothing or over-squashing without the support of additional studies is highly naive. For these reasons, I will downgrade my initial assessment to a 3."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700676978865,
                "cdate": 1700676978865,
                "tmdate": 1700676978865,
                "mdate": 1700676978865,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "8ynkrbcL7A",
            "forum": "070DFUdNh7",
            "replyto": "070DFUdNh7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4990/Reviewer_2YEp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4990/Reviewer_2YEp"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes GraphGPT, a novel model for graph representation learning. The key ideas are: 1) Transform graphs into sequences of tokens via Eulerian paths to preserve structure information. 2) Pretrain the transformer decoder with next token prediction on the graph sequences. 3) Fine-tune on downstream supervised graph tasks by formatting them to be compatible with the decoder. Experiments on graph, edge and node classification tasks demonstrate strong performance and consistently improving results when scaling up GraphGPT."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The graph-to-sequence transformation using Eulerian paths is an elegant way to serialize graphs for the transformer. This avoids complex feature engineering.\n- Leveraging generative pretraining enables scaling up to hundreds of millions of parameters, overcoming limitations of GNNs.\n- GraphGPT consistently improves with more data and parameters, demonstrating generalization ability."
                },
                "weaknesses": {
                    "value": "- Performance on some node and edge tasks is not state-of-the-art.\n- Limited analysis of what properties are learned during pretraining and their utility.\n- Does not experiment with very large models in the billions of parameters range."
                },
                "questions": {
                    "value": "- For large graphs, how are the subgraph sampling parameters (depth, context size) chosen? Is there a principled way to set these?\n- What is the computational complexity of the graph-to-sequence transformation? How does it scale?\n- Is the decoder-only transformer architecture sufficient for graph tasks or would an encoder-decoder be beneficial?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4990/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4990/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4990/Reviewer_2YEp"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4990/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698925698888,
            "cdate": 1698925698888,
            "tmdate": 1699636486344,
            "mdate": 1699636486344,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tIlPoJ4MH1",
                "forum": "070DFUdNh7",
                "replyto": "8ynkrbcL7A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4990/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4990/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Performance concerns and billion-scale models"
                    },
                    "comment": {
                        "value": "W1: Performance on some node and edge tasks is not state-of-the-art.\n\nA: Although the performance on some tasks are not SOTA yet, we still present it in the paper, for 2 reasons.\n\n1. GraphGPT\u2019s potential. Although the results are not SOTA, they are already quite close. As proved in NLP and CV, pre-train with more data and large model can consistently improve the performance in downstream tasks. So we expect GraphGPT to archive SOTA when scaling up the data-size and model-size, given that it already attains close to SOTA results currently. In this work, we mainly show GraphGPT\u2019s promising potential in various graph tasks.\n\n2. GraphGPT\u2019s limitation. As we pointed out in the appendix, GraphGPT does not perform well in ogbl-ddi dataset. We present some intuitive analysis on its limitation. For example, when the graph is small and very dense, GraphGPT may not be a suitable choice. If the dataset is small, GraphGPT cannot learn much useful information from pre-training. And for very dense graph, the structure may not be able to provide enough information during pre-training. \n\nFor some additional analysis on why GraphGPT\u2019s results are not SOTA in these datasets, please refer to the reply to Q1 and Q2 of reviewer `VKoy`.\n\n\nW2: Limited analysis of what properties are learned during pretraining and their utility.\n\nA: Thank you for pointing out. In the paper, we pre-train the model with NTP task to generate the graphs, and together with the structure and semantics information. So the model is expected to learn the overall distribution of graphs, and their structures and semantics.\n\nThe fine details of pre-training, such as the different roles played by the structure and semantics information are not studied in this work, and it is indeed an interesting topic worth further studies. For example, we can pre-train models with graph\u2019s structure-information-only vs structure-semantics-info, and see how the fine-tuning results would be different. However, the overall usefulness of pre-training has been demonstrated in the ablation study, which is the main point that we want to emphasize.\n\n\nW3: Does not experiment with very large models in the billions of parameters range.\n\nA: There are several limitations that prevents us from scaling up to billion-scale in this work.\n\n1. Resource limitation: billion-scale model consumes huge amount of computing resources and very time-consuming. Before we have a better understanding of GraphGPT in relatively small scale and try to extrapolate to larger scale, we cannot afford the training budget. (We definitely will scale up to billion-scale in the future works.)\n\n2. Dataset limitation: current graph datasets cannot provide enough amount of diverse data to be feed to billion scale models.\n\n3. Optimization limitation: In NLP, before the emergence of billion-scale models, lots of work has been done to find suitable optimization settings, such as batch-size, lr, lr scheduler, dropout rate, optimizer and optimizer hps, tokenization methods, and etc. \n\nThe serialized graph data is analogous to text, but they are essentially different. For example, the molecular graphs have a vocabulary size about hundreds, while in NLP the vocab is usually above 30k (Llama\u2019s vocab is 32k). The tokens in GraphGPT are node-id, node/edge-attributes and etc, and they are quite different in natural. In NLP the tokens are word pieces. Therefore, the optimal optimization settings could be very different from NLP. \n\nAs the 1st worker to serialize graph using Eulerian path and pre-train with NTP, the optimal optimization strategy remains to be further studied before diving into billion-scale models."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700646926941,
                "cdate": 1700646926941,
                "tmdate": 1700646926941,
                "mdate": 1700646926941,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "48fYPE303v",
                "forum": "070DFUdNh7",
                "replyto": "8ynkrbcL7A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4990/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4990/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to questions of subgraph sampling, computational complexity and architecture"
                    },
                    "comment": {
                        "value": "Q1: For large graphs, how are the subgraph sampling parameters (depth, context size) chosen? Is there a principled way to set these?\n\nA: The parameters are mainly determined by the context window of transformer. For example, if we have large compute budget, we could set it to be 1024. Then we run 10k subgraph samplings with DFS to find the depth such that 90% of the resulting sequences are within the context window. We also tried BFS to find the appropriate number of neighbors (with depth fix to 1).\n\n Empirically, we experiment with DFS (with num_neighbors=1) and BFS (with depth=1) on ogbn-proteins, and doesn\u2019t obtain much different results. In principle, if given enough compute budget, larger subgraphs might yield better results. We preliminarily experiment with context window from 256 to 1024 in this dataset, but does not gain significant performance gains. It could be due to the ease of overfitting and small dataset size.\n\nFor edge-level dataset ogbl-ppa, previous works show that the neighbors play important role in the link prediction task, so we choose BFS to sample the immediate neighbors.\n\n\nQ2: What is the computational complexity of the graph-to-sequence transformation? How does it scale?\n\nA: The most time consuming part of the transformation is the Eulerization and Finding Eulerian paths. \n1.\tEulerization\u2019s time complexity is O(n3)*, where n is the number of nodes of odd degrees.\n2.\tFinding Eulerian paths\u2019 complexity is O(|E|)**, where |E| is the number of edges.\n\nWe use the implementation in `networkx` package. During the training and inference, the Eulerization and finding Eulerian paths are calculated on-the-fly. And it is not the bottle-neck.\n\n* https://cs.stackexchange.com/a/9129\n* https://en.wikipedia.org/wiki/Eulerian_path#Hierholzer.27s_algorithm\n\n\nQ3: Is the decoder-only transformer architecture sufficient for graph tasks or would an encoder-decoder be beneficial?\n\nA: In NLP, decoder-only (such as GPT-series) and encoder-decoder (such as T5) do not show significant difference as measured by various downstream tasks. So we hypothesize that they might behavior similarly in graph tasks, and due to the limitation of various resources, we finally do not study both of them in this work. \n\nHowever, it worth exploring their different behaviors in graph tasks. In addition, encoder-only architecture (such as Bert) usually out-performs decoder-only architecture when they are restricted to the small/medium-size dataset and same model size. So, comparing the 3 architectures under different datasets and model sizes settings would be interesting to explore, but it is out of the scope of this work."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700646990859,
                "cdate": 1700646990859,
                "tmdate": 1700647412279,
                "mdate": 1700647412279,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "atHoYRhAl2",
            "forum": "070DFUdNh7",
            "replyto": "070DFUdNh7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4990/Reviewer_v4XD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4990/Reviewer_v4XD"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes  a novel model for Graph learning by self-supervised Generative Pre-training Transformers. The proposed method includes: 1) transforming the (sub)graphs into a reversible sequence of tokens via the Eulerian path, 2) pre-training a transformer decoder using the NTP task, and 3) fine-tuning the transformer. The paper investigates various graph related tasks: graph-/edge-/node-level tasks"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper proposed an interesting angle for graph pretraining, which takes advantage of the great performance of the breakthrough of LLM (transformer) into graph learning. The idea of Eulerian path is also interesting. The paper has investigated various graph tasks, including graph-/edge-/node-level tasks; and also consider small/large graph"
                },
                "weaknesses": {
                    "value": "-- Due to high variance of graph benchmakrs, to prove the effectiveness of the proposed methods (graph pretraining & finetuning), I would experct the authors provide more benchmarks results. \n\n-- There are various graph pretraining methods proposed (i.e. either combined with transformer or not, use contrastive learning or not, etc). Can the author compared with various other pretraining methods? \n\n-- The ablation study of pretraining is helpful. i.e. table 5. Just curious, are their other ablation study on finetuning?"
                },
                "questions": {
                    "value": "See above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4990/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699157898001,
            "cdate": 1699157898001,
            "tmdate": 1699636486259,
            "mdate": 1699636486259,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "P6vOgpGqyV",
                "forum": "070DFUdNh7",
                "replyto": "atHoYRhAl2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4990/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4990/Authors"
                ],
                "content": {
                    "title": {
                        "value": "More benchmarks and pre-training methods comparison"
                    },
                    "comment": {
                        "value": "Q1: Due to high variance of graph benchmakrs, to prove the effectiveness of the proposed methods (graph pretraining & finetuning), I would expect the authors provide more benchmarks results.\n\nA: There are several reasons that we didn\u2019t experiment on more benchmarks.\n\n1.\tDataset size. Most graph datasets are very small, so large models are usually not applicable. As we see in NLP and CV, large models + pre-train & fine-tune paradigm excels mostly when the dataset is very huge.\n\n2.\tUnrelated semantics. In NLP or CV, different datasets share the same underlying semantics. So, Bert or GPT can just pre-train once and then fine-tune on many down-stream tasks. In graph datasets, the only common feature is the `graph structure\u2019, but their semantics are very different. Therefore, we cannot pre-train one GraphGPT on the collection of datasets and then fine-tune. GraphGPT has to be pre-trained and then fine-tuned on every benchmark individually. This is very time-/resource- consuming. (Molecular datasets are the exception, as they share the same semantics, i.e., the same atoms and bonds. But training a domain-specific GraphGPT is not the theme of this work.)\n\nAs the 1st work of this new direction, besides some SOTA results, we want to show GraphGPT\u2019s potential on solving various large-scale graph problems. Therefore, we have already chosen the popular graph-/edge-/node-tasks datasets that are very large in graph domain.\nHowever, these datasets are still small compare to datasets in NLP and CV.\n\n\nQ2: There are various graph pretraining methods proposed (i.e. either combined with transformer or not, use contrastive learning or not, etc). Can the author compared with various other pretraining methods?\n\nA: In the dataset we studied, the top performing models do not involve pre-training like contrastive learning. In contrast, some methods employs transfer learning, i.e., pre-trained with supervised signal from external data. For example, in ogbg-molpcba leaderboard, the top two methods HIG and Graphormer are trained using PCQM4M\u2019s datasets and its supervised tasks. Some methods in PCQM4M-v2 leaderboard are pre-trained with external 3D conformation data calculated by `rdkit`. Therefore, there might not be suitable pre-training methods to be compared for these datasets we stuidied.\n\n\nQ3: The ablation study of pretraining is helpful. i.e. table 5. Just curious, are their other ablation study on finetuning?\n\nA: In our setting, zero-shot is not applicable, so fine-tuning is necessary. In fine-tuning, we tried different hyper-parameters, such as drop-out rate, weight-decay rate, learning rate scheduler and etc. These are common techniques, so we didn\u2019t study them in ablation in the paper."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700646464175,
                "cdate": 1700646464175,
                "tmdate": 1700739785809,
                "mdate": 1700739785809,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]