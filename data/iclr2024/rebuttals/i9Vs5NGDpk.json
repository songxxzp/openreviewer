[
    {
        "title": "Asymptotically Free Sketched Ridge Ensembles: Risks, Cross-Validation, and Tuning"
    },
    {
        "review": {
            "id": "IQBL6hJy7N",
            "forum": "i9Vs5NGDpk",
            "replyto": "i9Vs5NGDpk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7125/Reviewer_GR2e"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7125/Reviewer_GR2e"
            ],
            "content": {
                "summary": {
                    "value": "This paper established consistency of generalized cross validation for estimating prediction risks of sketched ridge regression that enables it to fast tune ensemble parameters. The authors further proposed an resembling trick so that the risk for unsketched ridge regression can be estimated through GCV using small sketched ridge ensembles. Simulations are conducted to validate the theoretical results."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper gives asymptotic of squared risk and its GCF estimator for sketched ridge regression so that an it is intuitively understandable as the implicit unsketched ridge regression risk and an inflation term due to randomness of the sketch that is controlled by ensemble size. And this is exploited to provide a method to tune unsketched ridge regression using only sketched ensembles. None of the assumptions are very strong for these theoretical results."
                },
                "weaknesses": {
                    "value": "While the results in this paper is interesting, the authors failed to illustrate while tuning (ensembled) sketched ridge is preferred over tuning unsketched ridge regression. It would be better if they provide some intuition and explanation to the results, especially for readers who are not that familiar with sketching."
                },
                "questions": {
                    "value": "Because GCV and risk for sketched ensembles converge at rate 1/K to the equivalent ridge for sketched ensembles, does this imply the larger the K the faster the convergence and the better it is? It there a downside if K is too large?\nCould the authors why the result that tuning (ensembled) sketched ridge is equivalent to tuning unsketched ridge regression is useful?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7125/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7125/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7125/Reviewer_GR2e"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7125/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697764899877,
            "cdate": 1697764899877,
            "tmdate": 1699636843141,
            "mdate": 1699636843141,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TXKLcoHZ3q",
                "forum": "i9Vs5NGDpk",
                "replyto": "IQBL6hJy7N",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7125/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7125/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Specific response to the Reviewer GR2e"
                    },
                    "comment": {
                        "value": "Thank you for your constructive feedback and for acknowledging the strengths of our paper. \nWe appreciate the opportunity to clarify aspects of our work further. \nWe hope that these responses address your concerns and clarify the practical contributions of our work. \n\n> **The authors failed to illustrate while tuning (ensembled) sketched ridge is preferred over tuning unsketched ridge regression.**\n\nWe have now included a new Appendix H to clarify when one might prefer to tune ensembled sketched ridge regression over unsketched ridge regression from a computational perspective.\nAs we show, the sketched ensemble trick for tuning unsketched ridge often always offers a computational advantage if $q < p/2$, and can sometimes be preferable more generally. \n\nMoreover, from a statistical standpoint, GCV is preferable to traditional CV due to the absence of data splitting, which preserves the consistency of the risk estimator compared to CV.\n\n> **Does this imply the larger the $K$ the faster the convergence and the better it is? Is there a downside if $K$ is too large?**\n\nWhile a larger $K$ indeed means being closer to equivalent unsketched ridge risk, there is a trade-off due to increased computational demands. \nIn practice, we typically find a sweet spot where $K$ is large enough to yield a good approximation to the unsketched ridge (with a properly chosen sketch size), but not so large as to be computationally prohibitive. \nOur experiments suggest that $K$ between 10 and 50 is often sufficient, as long as the constant in the $1/K$ term is not excessively large. \nThis ensures that any inflation due to the randomness of the sketch is controlled by the predictive power of the response. \n\n> **Could the authors why the result that tuning (ensembled) sketched ridge is equivalent to tuning unsketched ridge regression is useful?**\n\nThe theoretical equivalence between the space of sketched and unsketched ridge predictors is not only of theoretical interest but also has practical implications. \nIt reassures practitioners that using a large enough ensemble of sketched predictors does not compromise statistical efficiency compared to unsketched ridge regression. \nThis means that one can benefit from the computational efficiencies (especially parallelization and reduced memory footprint) of sketching without a loss in statistical performance, which is particularly relevant for large-scale problems where computational resources or time are at a premium."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7125/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700343326478,
                "cdate": 1700343326478,
                "tmdate": 1700343326478,
                "mdate": 1700343326478,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CQCYhYYYK9",
                "forum": "i9Vs5NGDpk",
                "replyto": "TXKLcoHZ3q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7125/Reviewer_GR2e"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7125/Reviewer_GR2e"
                ],
                "content": {
                    "title": {
                        "value": "Reviewer response"
                    },
                    "comment": {
                        "value": "The authors' response is satisfactory and it would be great if some of those explanations could be put in the main text."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7125/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700632678873,
                "cdate": 1700632678873,
                "tmdate": 1700632678873,
                "mdate": 1700632678873,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "o8q2zT3LtY",
                "forum": "i9Vs5NGDpk",
                "replyto": "IQBL6hJy7N",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7125/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7125/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the comment! We have now squeezed in parts of the explanation above in the revised main paper. Please find pointers to Appendix H in Sections 2 and 5, and additional comments after Proposition 6. These are inked **blue** in the revision, as are all other changes indicated in the general response at the top."
                    },
                    "title": {
                        "value": "Follow-up specific response to the Reviewer GR2e"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7125/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700635637445,
                "cdate": 1700635637445,
                "tmdate": 1700713116782,
                "mdate": 1700713116782,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "E24jvCTIxO",
            "forum": "i9Vs5NGDpk",
            "replyto": "i9Vs5NGDpk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7125/Reviewer_WHDZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7125/Reviewer_WHDZ"
            ],
            "content": {
                "summary": {
                    "value": "The current paper considers generalized cross validation (GCV) for sketched ridge regression ensembles. Specifically, sketching is done across different features and ensembles are based on finite sketches. The paper first derives the asymptotics of squared risk and its GCV estimator (section 2) and then extends to more general subquadratic prediction risk functionals (section 3). The paper also proposes a method for estimating the risk of unsketched ridge regression using sketched ridge ensembles (section 4). All the theoretical results are illustrated using both synthetic and real datasets with CountSketch and subsampled randomized discrete cosine transforms."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Overall the paper is very well written and persuasive. The experimental results are very well summarized in the figures.\n\n2. It is impressive that the current paper considers all asymptotically free sketched ensembles and allows for zero or negative penalty \n in ridge regularization.\n\n3. Distributional consistency in Corollary 5 is nice: this allows for classification errors and construction of prediction intervals among other things.\n\n4. It is interesting to know that the finite ensembles by sketching observations do not have GCV consistency, as given in Proposition 7."
                },
                "weaknesses": {
                    "value": "It would be beneficial to provide more details regarding computational aspects in the main text. For example, I presume that it is not necessary to compute $\\hat{\\beta}_{\\lambda}^k$ alone in equation (1). \n\nIn other words,  it is only necessary to compute the predicted values \n$X \\hat{\\beta}_{\\lambda}^k$. \n\nThis seems important because it is not necessary to explicitly premultiply $S_k$ to $\\hat{\\beta}_{\\lambda}^{S_k}$ in equation (1). If I am correct, this point can be emphasized at the end of section 2 when it is discussed that matrix inversions are inexpensive after precomputing $X S_k$.\n\nGenerally speaking, it would be helpful to provide more details regarding computational aspects."
                },
                "questions": {
                    "value": "1. In figure 1, it would be good to indicate that SRDCT refers to subsampled randomized discrete cosine transform because SRDCT first appears toward the end of page 2.\n\n2. In proposition 6, $S_k^T S_k$ is assumed to be invertible. How strong is this assumption? Some further remarks might be helpful.\n\n3. The ensemble trick in section 5 seems very useful. However, there is no explicit discussion of computational gains over unsketched GCV. Especially, when $K$ is large as in proposition 6, one might need to rely on parallel computing to fully speed up computations. More discussions might be desirable in terms of computational complexity. \n\n4. Is there a known S-transform for CountSketch? Table 4 in the appendix does not include CountSketch."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7125/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7125/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7125/Reviewer_WHDZ"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7125/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698958550835,
            "cdate": 1698958550835,
            "tmdate": 1699636843040,
            "mdate": 1699636843040,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "A2swTxVvmB",
                "forum": "i9Vs5NGDpk",
                "replyto": "E24jvCTIxO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7125/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7125/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Specific response to the Reviewer WHDZ"
                    },
                    "comment": {
                        "value": "Thank you for the thorough review and for the positive comments about our paper. \nWe are pleased that you found our work to be well-written and the experimental results compelling. \n\nWe appreciate your insightful feedback, which has helped us improve the clarity and depth of our manuscript. \nYour input on the computational aspects has been particularly valuable, and we have made the appropriate enhancements to the text to better communicate these important details. \nThank you once again for your review and the positive assessment of our work. Below we respond to some of your specific points.\n\n> **Generally speaking, it would be helpful to provide more details regarding computational aspects.**\n\nWe agree with you and the other reviewers regarding this point and have now added a new Appendix H providing a detailed computational comparison between unsketched GCV, $k$-fold CV, and the ensemble trick, clarifying that the computational demands decrease for smaller sketch sizes. \nIndeed, as you have written, it is not necessary to \"broadcast\" $\\hat{\\beta}_\\lambda^{S_k}$ back to $p$-dimensional space, and all computation can (and should) be done only in the sketched domain; our presentation is simply made for mathematical convenience. \nIn fact, for sketches based on hash functions such as CountSketch, computing the adjoint of the sketching operator is in general intractable, so this point is critical in sketched machine learning practice.\n\n> **In figure 1, it would be good to indicate that SRDCT refers to subsampled randomized discrete cosine transform**\n\nWe have revised the caption of Figure 1 to include a definition for SRDCT, ensuring that it is clear on its first appearance in the text.\n\n> **In proposition 6, $S_k^\\top S_k$\nis assumed to be invertible. How strong is this assumption?**\n\nThe invertibility assumption for $\\mathbf{S}_k^\\top \\mathbf{S}_k$ is merely technical.\nIf it is not invertible, it is straightforward to verify that the sketched ridge regression problem is unchanged if we replace $\\mathbf{S}_k \\in \\mathbb{R}^{p \\times q}$ by its projection $\\widetilde{\\mathbf{S}} \\in \\mathbb{R}^{p \\times r}$ onto its right principal singular vectors, where $r = \\mathrm{rank}(\\mathbf{S}_k)$ takes the place of $q$. \nThus, Proposition 7 holds for any sketch if we replace $\\alpha$ by $r/p$, but we thought it would be better to tie into the same $\\alpha$ used in the rest of the paper. \nAdditionally, to use a rank-deficient sketch in practice would generally be wasteful, so we don't anticipate this to be a common case.\n\n> **Is there a known S-transform for CountSketch?**\n\nThe S-transform, or any other spectral properties as far as we are aware, for the CountSketch have not been studied in prior literature. One recent work [1] has considered a related sketch which they also call \"CountSketch\", but which uses only a single hash function, rather than standard CountSketch which uses a growing number of independent hash functions. \nAs they show, it is straightforward to see that with a single hash function, the spectrum of the sketch should follow a Poisson distribution; however, even in that case the S-transform is still not known. \n\nThus, understanding the spectral properties (including the S-transform) of CountSketch is an interesting direction for future work.\nBased on our empirical observations (in Figure A.1 and the new Figure A.2) and the fact that it combines many independent hash functions, we strongly suspect that CountSketch has a Marchenko\u2013Pastur spectrum like Gaussian sketches. We have added a new sentence in Appendix A.4 to re-emphasize this observation.\n\n[1] Fan Yang, Sifan Liu, Edgar Dobriban, David P. Woodruff. How to reduce dimension with PCA and random projections?\nhttps://arxiv.org/abs/2005.00511"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7125/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700343277595,
                "cdate": 1700343277595,
                "tmdate": 1700343277595,
                "mdate": 1700343277595,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PZQ1rTVMnF",
                "forum": "i9Vs5NGDpk",
                "replyto": "E24jvCTIxO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7125/Reviewer_WHDZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7125/Reviewer_WHDZ"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you so much for responding to my previous comments and revising the paper accordingly. I very much appreciate the addition of the new appendix section for computational complexity, which is quite informative. I also fully agree regarding the response saying that _\"Indeed, as you have written, ....; our presentation is simply made for mathematical convenience. In fact, for sketches based on hash functions such as CountSketch, computing the adjoint of the sketching operator is in general intractable, so this point is critical in sketched machine learning practice.\"_ I am wondering whether you have emphasized this fact in the revised version of the paper. Although it is common knowledge for the experts, it might be helpful to emphasize this in order to avoid any confusion for future readers."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7125/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700669776587,
                "cdate": 1700669776587,
                "tmdate": 1700669823670,
                "mdate": 1700669823670,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "crgV9Y6Hmi",
                "forum": "i9Vs5NGDpk",
                "replyto": "E24jvCTIxO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7125/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7125/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the suggestion! We have discussed along these lines in the supplement but we agree that this point should be emphasized in the main paper also. We have now squeezed in a line in the main paper right after defining the ensemble estimator (2). It is inked **blue**, as are all other changes in the revision."
                    },
                    "title": {
                        "value": "Follow-up specific response to the Reviewer WHDZ"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7125/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700712322644,
                "cdate": 1700712322644,
                "tmdate": 1700713088731,
                "mdate": 1700713088731,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "yeBUuaY2Nv",
            "forum": "i9Vs5NGDpk",
            "replyto": "i9Vs5NGDpk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7125/Reviewer_qfu6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7125/Reviewer_qfu6"
            ],
            "content": {
                "summary": {
                    "value": "Motivating by hyparameter tuning (size of the ensemble, size of the sketches), this paper studies the statistical properties of Generalized-Cross-Validation applied on an ensemble of sketched ridge regressors with skecthing applied to the feature space. First, the authors develop squared risk asymptotics and provide consistency results (Thoerem 2) and then, extend these results to subquadratic error functionals (Theorem 3). These findings hold for the general class of asymptotically free sketching matrices. At the origin of the study, is a key theorem (LeJeune et al. 2022), that states that the sketched inversion of a sketched regularized matrix corresponds to the inversion of the initial regularized matrix with another hyperparameter. This gives rise to Theorem 2 that nicely relates the quadratic risk of the ensemble-based estimator to the risk of the rigde estimator plus a randomness term depending on the sketch via Theorem 1 and the so-cllaed S-transform. Moreover, functional and distribution consistency for general error functional are also proved. Simulations on toy and real data shown in the main paper and appendix confirm the interest of the approach for tuning both the regularization level (or sketch size in fine) and the size of the ensemble."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "First of all, I would like to say that this is a very nice paper, very well written, solid and with a strong and insightful content. I have learned a lot when reading it.\nThe main strengths of the paper is its depth of view not only about GCV (which has a simple form) but also about the link between sketched ridge regression and regualrization in ridge regression, and the role of the ensemble trick. \nI appreciated the richness of the discussion and the comments all along the paper.\nOriginality is also present here, with the exploitation of very recent results (LeJeune et al. 2022) but with a special angle here (GCV)."
                },
                "weaknesses": {
                    "value": "* Improvment of clarity in Assumption 2 statement and explanation. \nThe paper has the merit to introduce elements of free probability theory useful in Assumption 2. I regret not to have more intuition here: I can easily imagine that a form of independence (I've read the appendix) between $X^TX$ and $SS^T$ is useful but the notion of limiting S-transform is not at all discussed at this stage (page 4) and Assumption 2 remains not clear at all when beginning to read what follows. Same thing for Theorem 1, describe the $|ambda^+$ function.\n* A simple analysis of the complexity in time and memory for the full aproach in constrat to other estimators (CV) would be welcome.\n* Bonus: Is it interesting to come back on other risk estimators (Bootstrap) and clearly identify what could be done with this estimator or not with ensemble of sketched ridge regression."
                },
                "questions": {
                    "value": "See my previous comments."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7125/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699208193769,
            "cdate": 1699208193769,
            "tmdate": 1699636842926,
            "mdate": 1699636842926,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0Mje4mvPYF",
                "forum": "i9Vs5NGDpk",
                "replyto": "yeBUuaY2Nv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7125/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7125/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Specific response to the Reviewer qfu6"
                    },
                    "comment": {
                        "value": "Thank you for your comprehensive review and the positive comments on our manuscript. \nWe are delighted to hear that you found the paper to be informative and original. \n\nYour insightful review has prompted us to refine our explanations and further clarify the assumptions and theorems within our paper. \nWe appreciate your suggestions and hope that these revisions will make our paper even more clear and impactful.\n\n> **The notion of limiting S-transform is not at all discussed at this stage (page 4) and Assumption 2 remains not clear at all when beginning to read what follows.**\n\nWe acknowledge that Assumption 2 (now Assumption A after our revision) and Theorem 1 could benefit from additional intuition, especially concerning the S-transform and its role in our results. \nWe have added a new footnote on page 4 to ground the assumption concretely with Gaussian and orthogonal sketches, which are commonly studied and proven to be asymptotically free.\nTo clarify regarding freeness, the independence between $\\mathbf{X}$ and $\\mathbf{S}$ is not the only requirement; what is crucial is a form of incoherence, often achieved through rotational invariance of the sketching matrix.\nThis incoherence is captured by the concept of asymptotic freeness in free probability theory.\n\nThe S-transform, another key concept from free probability theory, is indeed opaque and difficult to give intuition for. Despite this, it is a standard notion in free probability, and the main thing that matters for our results is that is a function only of the eigenvalue distribution of the sketching matrix $\\mathbf{S} \\mathbf{S}^\\top$.\nWe assume analyticity of the S-transform, which holds for both Gaussian and orthogonal sketches, but we do not know in general what requirements this places on sketching matrices.\n\n> **Same thing for Theorem 1, describe the $\\lambda^+$**\n\nAs we define immediately before Theorem 1, $\\lambda_{\\min}^+$ is the minimum non-zero eigenvalue of the matrix. \nThis arises because the multiplication by $\\mathbf{X}$ effectively nullifies the zero eigenvalues, leaving only the non-zero spectrum relevant for determining singular inversion, and enabling us to consider zero and negative regularization.\n\n> **A simple analysis of the complexity in time and memory for the full approach in contrast to other estimators (CV) would be welcome.**\n\nWe have now included a new Appendix H performing such a comparison. In particular, we demonstrate that the ensemble trick is always competitive with unsketched GCV (which is in turn generally more efficient than $k$-fold CV) as long as $q < p / 2$, and can be competitive even more generally in the right circumstances.\n\n> **Bonus: Is it interesting to come back on other risk estimators (Bootstrap) and clearly identify what could be done with this estimator or not with ensemble of sketched ridge regression.**\n\nWe agree that contrasting our approach with other risk estimators, such as the bootstrap, could be valuable. \nThe bootstrap, however, does not provide an estimator for prediction risk\ndirectly and has its computational challenges when dealing with large datasets. \nOur approach offers both computational efficiency and statistical consistency, which are crucial for practical applications."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7125/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700343225984,
                "cdate": 1700343225984,
                "tmdate": 1700343225984,
                "mdate": 1700343225984,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CuM0NrskPA",
                "forum": "i9Vs5NGDpk",
                "replyto": "0Mje4mvPYF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7125/Reviewer_qfu6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7125/Reviewer_qfu6"
                ],
                "content": {
                    "title": {
                        "value": "Feedback on rebuttal"
                    },
                    "comment": {
                        "value": "I've read the rebuttal and appreciate the efforts of the authors to clarify some points."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7125/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737389339,
                "cdate": 1700737389339,
                "tmdate": 1700737389339,
                "mdate": 1700737389339,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "tjVM4Bjk8B",
            "forum": "i9Vs5NGDpk",
            "replyto": "i9Vs5NGDpk",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7125/Reviewer_t4Ef"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7125/Reviewer_t4Ef"
            ],
            "content": {
                "summary": {
                    "value": "This paper is about the (asymptotic) consistency of generalized cross validation (GCV) for estimating prediction risks of sketched ridge regression ensembles using tools from random matrix theory. \n\nFor general subquadratic prediction risk functionals, they extend GCV to construct consistent risk estimators, and obtain distributional convergence of the GCV-corrected predictions in Wasserstein-2 metric.\n\nAlthough the consistency result seems intuitive and natural, they point out that GCV of the observation sketched ridge regression, is inconsistent, highlighting the subtlety of this subject."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper presents the theorems in a clear and rigorous way. All notations are presented again on a table in appendix. Theoretical result is supported by experimental result."
                },
                "weaknesses": {
                    "value": "No major weakness is spotted."
                },
                "questions": {
                    "value": "Asymtpotic freeness seems to be an essential assumption in the paper. Although this assumption is experimentally supported by artifical datasets, I wonder if one can observe similar matching on real-world dataset."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7125/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699214637341,
            "cdate": 1699214637341,
            "tmdate": 1699636842694,
            "mdate": 1699636842694,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FIhg4IkYc6",
                "forum": "i9Vs5NGDpk",
                "replyto": "tjVM4Bjk8B",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7125/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7125/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Specific response to the Reviewer t4Ef"
                    },
                    "comment": {
                        "value": "Thank you for the positive feedback. We appreciate it.\nWe are also happy that you enjoyed the clarity and rigor in our presentation.\n\n> **Although [asymptotic freeness] is experimentally supported by artificial datasets, I wonder if one can observe similar matching on real-world dataset.**\n\nGiven the importance of the asymptotic freeness assumption, we agree that it is crucial to verify this assumption in realistic settings, such as with real-world data and practical sketches.\n\nRecall that for Gaussian sketches and uniformly random orthogonal sketches, asymptotic freeness is theoretically guaranteed for any data matrix $X$ independent of $S$. For other types of sketches, such as CountSketch or SRDCT, the validation of the asymptotic freeness assumption is indeed more complex.\n\nHowever, as you suggest, we can employ further empirical tests to support our claims on real-world data. We have added a new experiment in Figure A.2 in Section A.3.2, where we showcase empirical subordination relations on the real-world datasets we use in Figure 2 (RCV1 and RNA-Seq), similar to the previous experiment in Figure A.1 on artificial data. These results show that the resolvent relation given in Theorem 1, which underpins our theoretical results, holds with good accuracy on real datasets as well.\n\nWe hope that these empirical validations, along with the theoretical underpinnings for more readily analyzable Gaussian and orthogonal sketches, offer a compelling argument for the practical relevance of our theoretical contributions."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7125/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700343174415,
                "cdate": 1700343174415,
                "tmdate": 1700343174415,
                "mdate": 1700343174415,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]