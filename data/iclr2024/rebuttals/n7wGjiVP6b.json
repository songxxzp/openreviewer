[
    {
        "title": "LLM2Labels: Zero-shot dataset summarizing and labeling using foundational LLM models"
    },
    {
        "review": {
            "id": "hTZHGlXXDM",
            "forum": "n7wGjiVP6b",
            "replyto": "n7wGjiVP6b",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3328/Reviewer_UakG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3328/Reviewer_UakG"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes to use LLMs and vison-language models to label a dataset automatically. The procedure includes the vocabulary proposal, filtering, and summarizing."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. This paper might be the first one to systematically analyze how to label a dataset automatically using large pre-trained models. \n2. The authors incorporate different models in different stages to benefit from their distinguished advantages."
                },
                "weaknesses": {
                    "value": "This paper is obviously below the requirements of a top conference for the following weaknesses. \n\nFormats\n1. This paper does not use the template for reviewing, the submitted version does not have line numbers. \n2. Figure 1 is not clear enough. \n3. Many typos like the use of \"\" in section 3.3. \n\nMethods\n1. The proposed pipeline is straightforward, I do not see any technical contributions. \n2. Models like BLIP2 and LLAMA might not be the best choices, I believe MLLM models like LlaVA, mini-GPT4, and KOSMOS-2 would give better performance. \n3. The authors pick the segmentation dataset as their demos. However, how to get the mask proposals and how to align each mask with labels are not solved, which is a key problem."
                },
                "questions": {
                    "value": "See the weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3328/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697892448190,
            "cdate": 1697892448190,
            "tmdate": 1699636282156,
            "mdate": 1699636282156,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "b4TwNcFXt9",
            "forum": "n7wGjiVP6b",
            "replyto": "n7wGjiVP6b",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3328/Reviewer_Het9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3328/Reviewer_Het9"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers to generate a label vocabulary tailored to image segmentation within a comprehensive image dataset and utilize LLM to empower the logical categorization of the meticulously filtered candidate labels"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper contains two stage. In First stage, LLM2Labels propose Label Proposal Module (LPM) and the Label Filtering Module (LFM). In second stage, LLM2Labels utilize LLM to empower the logical categorization of the meticulously filtered candidate labels."
                },
                "weaknesses": {
                    "value": "1. The novelty of this paper is limited. Many recent works research on generating vocabularies for images. (including fine-grained objects). (e.g., RAM, SegGPT and open-vocabulary detectors.). Authors do not clearly introduce the details of this paper and I do not see the obvious contributions.\n\n2. Formula in Sec 3.3.1 is not clear. What is the meaning of each symbol. It appears to be one of only three formulas in the paper."
                },
                "questions": {
                    "value": "As mentioned above in the weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "no"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3328/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698135991379,
            "cdate": 1698135991379,
            "tmdate": 1699636282052,
            "mdate": 1699636282052,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "gwsmQ4kVD7",
            "forum": "n7wGjiVP6b",
            "replyto": "n7wGjiVP6b",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3328/Reviewer_afgG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3328/Reviewer_afgG"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed LLM2Lables to handle closed-set image segmentation task and revisit open-set scenario as well. LLM2Labels contains two stages, i.e., per-image processing for image labels achieving and logical categorization of filtered candidate labels."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The task handled by this paper has been important in recent years.\n\nThe overall writing and organization are clear."
                },
                "weaknesses": {
                    "value": "The motivation of two-stage processing is not novel, i.e., it has been explored by other LLM-based methods. The proposed LPM and LFM are also not well motivated and more in-depth analysis should be given.  \n \nThis paper claims to use LLM and VLM, however, how to modulate these two sides are not well disscussed. This degrades the contribution. \n\nThis paper missed many relevant methods published in CVPR 2023, ICCV 2023, etc."
                },
                "questions": {
                    "value": "See above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3328/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3328/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3328/Reviewer_afgG"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3328/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1700638116513,
            "cdate": 1700638116513,
            "tmdate": 1700638180113,
            "mdate": 1700638180113,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "PZ0vUN4oSh",
            "forum": "n7wGjiVP6b",
            "replyto": "n7wGjiVP6b",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3328/Reviewer_VpyB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3328/Reviewer_VpyB"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces the \"LLM2Labels\" framework, designed for generating label vocabularies specifically for image segmentation tasks in extensive image datasets. The first stage involves per-image processing, where VLMs propose candidate labels for each image. The second stage uses LLMs, particularly Llama2, for logically categorizing these labels into coherent groups, similar to WordNet synonym sets. The framework is tested on segmentation datasets, showing promising results in ground truth segmentation labels, both in closed-set and open-set scenarios. It outperforms traditional zero-shot methods and even rivals trained close-set multi-label classification."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. The framework's two-stage process, comprising the per-image processing (label proposal and filtering) and a grouping stage, is promising. This structured approach ensures that the labels generated are not only contextually relevant but also logically organized, akin to WordNet synonym sets. \n\n2. Compared with some naiive baseline like BLIP and BLIP-VQA, this framework achieves better matching score compared to ground-truth label, showing a post-filtering LLM grounding is useful."
                },
                "weaknesses": {
                    "value": "My major concerns are two-folded:\n\n1. The implementation of the proposed framework is very unclear. Even after reading the paper for multiple iterations, I still didn't find which VLM is used for the per-image proposal stage; Also, how it is set to generate candidates, how many are generated, how they can be further filtered by LLM, are all very unclear to me. The authors shall include all implementation details (and better to include code) for easier re-implementation;\n\n2. Generally I like the summarization module that organize some candidates entities by VLM into a structured taxonomy. However, the current implementation looks a naiive clustering, without iterative refinement or constrained by some grammar. There's very likely that LLM simply ignore some provided entities. Also, though in Fig1 also shows a hierarchical tree as output, I didn't see how the introduced approach can be used to construct such taxonomy. Probably the authors could provide more explanations here.\n\n3. Why authors just use segmentation as evaluation task? Also how it can generalize to different datasets (with different requirement). I think it's very hard for BLIP model to generate correct candidates for different datasets as they are created with different purpose (say, a pathology dataset where all label are cell name). \n\nSmall typo: at the end of related work for image segmentation, it says: which leverage deep learning ... TODO"
                },
                "questions": {
                    "value": "How the approach is implemented and how it can generalize across datasets & tasks."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3328/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3328/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3328/Reviewer_VpyB"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3328/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1700969954486,
            "cdate": 1700969954486,
            "tmdate": 1700969954486,
            "mdate": 1700969954486,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]