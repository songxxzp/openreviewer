[
    {
        "title": "Training Diffusion Classifiers with Denoising Assistance"
    },
    {
        "review": {
            "id": "c3ZWU73P1t",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8287/Reviewer_JmSU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8287/Reviewer_JmSU"
            ],
            "forum": "mWxcEm7jIv",
            "replyto": "mWxcEm7jIv",
            "content": {
                "summary": {
                    "value": "The paper introduces Denoising-Assisted (DA) classifiers in the domain of classifier-guided diffusion models to enhance both conditional and unconditional generation tasks. The DA classifiers are trained using both noisy and denoised examples, unlike traditional diffusion classifiers trained only on noisy data. Through experiments on CIFAR10 and Imagenet datasets, the authors demonstrate that DA classifiers exhibit better generalization to unseen data and improved perceptual alignment of classifier-gradients, leading to enhanced image generation. The paper also theoretically analyzes the gradients of DA-classifiers to explain the observed improvements. Additionally, a semi-supervised framework is proposed to leverage the generalization strengths of DA-classifiers in scenarios with limited labeled data. The empirical and analytical discussions included in the paper provide a thorough understanding of the improvements DA-classifiers bring over noisy classifiers, showing promise in advancing the performance of generative models."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper unfolds an innovative notion of utilizing denoised samples as inputs to the classifier within a diffusion model framework. The simplicity of this idea is elegantly juxtaposed with its effectiveness, as substantiated by the authors through empirical evaluations and theoretical elucidations. The inner workings of the proposed method are also thoughtfully explained, shedding light on the mechanisms that contribute to its efficacy."
                },
                "weaknesses": {
                    "value": "1. The presentation of the paper could be improved for better readability. Specifically, the formatting of equations (5) and (6) spanning across three rows appears to be cluttered and may benefit from a more concise representation.\n  \n2. The paper primarily focuses on one-step denoising, which raises the question of why multi-step denoising to reach time step t=0 was not explored. Utilizing the sample at time step t=0 as input to the classifier could potentially offer additional insights or improvements, and it would be beneficial for the authors to discuss or explore this aspect.\n  \n3. The core contribution of employing the denoised sample as input to a classifier may come across as straightforward. The paper could benefit from a clearer articulation of the motivation behind this choice and the specific problems it aims to address. While the one-step denoised sample is utilized, the rationale behind not exploring [x, one-step denoised sample, two-step denoised sample] as inputs could use further clarification. Although the authors provide some explanations, a more robust justification could enhance the perceived significance of the work.\n  \n4. The discussion on the semi-supervised learning framework introduces an idea of selecting pseudo-label data based on confidence thresholds during the diffusion process. However, the motivation behind this choice could be better elucidated. It may be worth exploring or explaining why traditional uncertainty measures in the raw data space were deemed insufficient, and how the proposed method addresses any identified limitations."
                },
                "questions": {
                    "value": "See Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8287/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8287/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8287/Reviewer_JmSU"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8287/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697240861433,
            "cdate": 1697240861433,
            "tmdate": 1699637030739,
            "mdate": 1699637030739,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dOXxixhCTB",
                "forum": "mWxcEm7jIv",
                "replyto": "c3ZWU73P1t",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8287/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8287/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer JmSU"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their insightful and helpful comments for improving the paper. \n\n1) Presentation: Thank you for the feedback. We will fix the formatting in Eqs. (5,6), and we gladly welcome any other suggestions.\n\n2) Motivation for using single-step denoised examples. We use denoised example $\\hat{\\bf x_t} = {\\bf x_t}+\\sigma^{2}(t) s_\\theta({\\bf x_t},t)$\nas an additional input to the classifier network because (a) learning to classify denoised image is potentially easier than learning to classify noisy examples and (b) we have access to a pretrained score network $s_\\theta({\\bf x_t},t)$ that can help us estimate the additive gaussian noise contained in ${\\bf x}_t$. Beyond just simplifying the learning task, we observe that this simple change also helps address the following deficiencies of vanilla classifier guidance: 1) Generalisation in fully-supervised and semi-supervised settings, 2) Perceptual-alignment of Classifier-gradients, and 3) Image Generation Performance. We support these findings both theoretically and empirically. Additionally, we also show significant advantages of using denoised-images in semi-supervised training as opposed to simple gaussian-noise augmented images. We will clarify this motivation in the revised paper.\n\n3) Multi-step denoising. As described in Eq. (4), the unconditional score function estimated by $s_\\theta({\\bf x_t},t)$ is adjusted with the gradient of log-likelihood predicted by the classifier in classifier-guided diffusion sampling, as $s_\\Theta({\\bf x_t}, t|y) = \\nabla_{{\\bf x_t}} \\log p_\\phi(y|{\\bf x_t},t) + s_\\theta({\\bf x_t},t)$. Here, $\\theta$ refers to parameters of the unconditional score function, $\\phi$ refers to parameters of the classifier function and $\\Theta = \\\\{\\theta, \\phi\\\\}$. The suggestion of using the sample at $t-2$ or $t=0$ for estimating the score-function $s_\\Theta({\\bf x_t}, t|y)$ is indeed very interesting but requires separate theoretical and empirical investigation; in particular, it may require making appropriate modifications to the sampling algorithm. In this study, we consider using denoised example obtained at time $t$ as an additional input to the classifier for estimating $s_\\Theta({\\bf x_t}, t|y)$ and this does not require any modification to the sampling algorithm. \n\n3) Uncertainty measures for pseudo-label estimation. To train the diffusion classifier on partially-labelled data, we need to estimate the pseudo-labels of the unlabeled examples in each batch. As described in the paper, we follow FixMatch and use confidence-thresholding, a traditional measure of uncertainty, to estimate the pseudo-labels. In order to estimate the pseudo-labels, we use two types of data samples from forward diffusion to estimate the pseudo-labels \u2014 samples diffused to 1) $\\tau=0.01$ (i.e., with negligible gaussian noise) and 2) uniformly sampled time $s$. Since the samples diffused to time $\\tau=0.01$ have negligible gaussian noise, that is similar to estimating pseudo-labels from raw data using traditional uncertainty measures. In addition, we also use pseudo-labels from confident predictions on samples diffused to random uniform time $s$ as they could be more informative than raw data in the following cases:\n   * Additive gaussian noise in samples diffused to time $s$ could potentially help the noisy-classifier/DA-classifier better estimate the uncertainty in labels as compared to samples containing negligible gaussian noise. \n   * Denoised images obtained from unlabeled examples with additive gaussian noise could potentially help classification, even when the DA-classifier is not able to confidently classify the original raw image. \n\n   At each training step, we estimate pseudo-labels from confident predictions on samples diffused to both $\\tau$ and $s$ and use them for computing the cross-entropy loss. We do not resolve disagreements between these two pseudo-labels because we expect that the confident predictions on diffused samples should become consistent over training. We thank the reviewer for this comment and we will clarify this discussion in the revised text.\n\nWe look forward to addressing any outstanding concerns in the discussion period."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700186556155,
                "cdate": 1700186556155,
                "tmdate": 1700186556155,
                "mdate": 1700186556155,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7g4018C81s",
                "forum": "mWxcEm7jIv",
                "replyto": "dOXxixhCTB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8287/Reviewer_JmSU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8287/Reviewer_JmSU"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the feedback."
                    },
                    "comment": {
                        "value": "Thanks for the authors feedback. It clarified some concerns. Yet, I did not get the contribution of the \"4 SEMI-SUPERVISED CONDITIONAL SCORE MODELS\". What is the novelty here?"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700597859195,
                "cdate": 1700597859195,
                "tmdate": 1700597859195,
                "mdate": 1700597859195,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "tRyU4XsUBy",
            "forum": "mWxcEm7jIv",
            "replyto": "mWxcEm7jIv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8287/Reviewer_F98v"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8287/Reviewer_F98v"
            ],
            "content": {
                "summary": {
                    "value": "This manuscript proposed the denoising-assisted (DA) classifier that employs additional denoised image for better classification. The DA classifier has shown better performance on CIFAR-10 and ImageNet compared to original diffusion classifiers, and this imporvement is also verified by theoretical analysis."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. A new method of DA classifier is proposed by employing the denoised image for better classification;\n\n2. Emprical experiments on CIFAR-10 and ImageNet verifies the effectiveness of the proposed approach;\n\n3. Some insightful observations in terms of the classifier gradients are presented to analyse the imporvement of DA classifier."
                },
                "weaknesses": {
                    "value": "IMHO, the writing and organization of this manuscirpt can be greatly imporved for clearer illustration. For example, the motivation and the most related works w.r.t. diffusion classifiers are quilte unclear. Moreover, the writing are redundant and blunt, which blends the authors's contributions and existed works. Some technical questions are presented as below:\n\n1. What is the motivation to develop DA classifier?  What is the advantages of DA classifier compared to existed classifiers including conventional deep models (VGG, ResNet, etc.) or large models (CLIP, etc.)?\n\n2. What the authors do is to employ the denoised images as the additional input. To this end, the authors should provide more detail about how to get the denoised images and analysing the influence of different types of denoised images.\n\n3. Why Theorem 1 explain the improvements of DA classifier?\n\nMinors and typos:\n1. \"Cifar10\" -> \"CIFAR-10\"\n2. \"Imagenet\" -> \"ImageNet\"\n3. Page 3, Sec. 2.2: $y\\in [1,C]$ -> $y\\in =\\\\{1, ..., C\\\\}$\n\n4. Page 3, Sec. 3: \"propose to use as input both ...\" -> \"propose to use both ... as input\"\n5. To many long sentences."
                },
                "questions": {
                    "value": "See Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8287/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8287/Reviewer_F98v",
                        "ICLR.cc/2024/Conference/Submission8287/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8287/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698308949916,
            "cdate": 1698308949916,
            "tmdate": 1700712203011,
            "mdate": 1700712203011,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9Iv597nvB6",
                "forum": "mWxcEm7jIv",
                "replyto": "tRyU4XsUBy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8287/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8287/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer F98v"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their comments. We will incorporate the minor suggestions & typo corrections in our revision. We address the remaining points as follows:\n\n> What is the motivation to develop DA classifier?\n\nWe systematically expose several deficiencies  of vanilla classifier guidance,\n1) Generalization in fully-supervised and semi-supervised settings, \n2) Perceptual-alignment of Classifier-gradients,\n3) Image Generation Performance \n\nand we demonstrate how simply using denoised images as additional input can address all these deficiencies. We call these denoising-assisted (DA) classifiers.\n\n\n> What is the advantages of DA classifier compared to existed classifiers including conventional deep models (VGG, ResNet, etc.) or large models (CLIP, etc.)?\n\nWe believe that this question is asking for some overall context, so here is an overview: For classifier-guided diffusion, we train classifiers on images sampled from the forward diffusion, which generally contain additive gaussian noise. As described in the paper, a DA-Classifier refers to a classifier that takes both noisy and denoised images as simultaneous inputs, in contrast to a noisy-classifier that only receives noisy images as inputs. Noisy Classifier and DA-Classifier can be constructed with any backbone neural architecture: as described in the paper, we use WideResNet-28-2 for all CIFAR10, MNIST and SVHN experiments (following Song et al., 2021) while we use the downsampling-half of the UNET for ImageNet experiments (following Dhariwal and Nichol (2021b) ). The vanilla diffusion classifier and the corresponding denoising-assisted diffusion classifier have the same network architecture after the first layer and differ only in terms of the first convolution module: for example, if the first input-convolution of vanilla diffusion classifier takes an input volume of $(N, C_i, H_i, W_i)$ and gives an output volume of $(N, C_o, H_o, W_o)$, the DA-Classifier takes an input volume of $(N, 2C_i, H_i, W_i)$ and gives the same size output $(N, C_o, H_o, W_o)$.\n\n> \u201cthe authors should provide more detail about how to get the denoised images and analysing the influence of different types of denoised images\u201d\n\nAs described below Eq. 6, we obtain denoised images $\\hat{\\bf x}$ using the pretrained score-network $s_\\theta$ as $\\hat{\\bf x} = {\\bf x}+\\sigma^{2}(t) s_\\theta({\\bf x},t)$. We would be glad to provide additional details about this in an appendix, but we do not understand exactly what additional details would be helpful for this reader. We are also not sure what the reviewer means by \u201cdifferent types of denoised images\u201d; any clarification on this would also be welcome. As explained above, we are denoising images that have been corrupted with additive gaussian noise.\n\n> \u201cWhy Theorem 1 explain the improvements of DA classifier?\u201d\n\nAs written in Section 3, Theorem-1 \u201cexplains the improved perceptual alignment in Fig (3) and Fig (2), since multiplying a vector by $\\text{Cov}[{\\bf \\bar{\\bf x}}_t|{\\bf x}]$  *stretches* the vector along the principal directions of the conditional distribution $p({\\bf \\bar{\\bf x}}_t|{\\bf x})$.\u201d Intuitively, since the conditional distribution $p({\\bf \\bar{\\bf x}}_t|{\\bf x})$ corresponds to the distribution of candidate denoised images, the principal directions of variation are perceptually aligned and hence stretching the gradient along these directions will yield perceptually aligned gradients. We attribute the quantitative and qualitative improvements on the image generation task to 1) perceptually aligned classifier gradients and 2) improved generalisation to unseen examples. \n\nWe look forward to addressing any outstanding concerns in the discussion period."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700185579443,
                "cdate": 1700185579443,
                "tmdate": 1700185579443,
                "mdate": 1700185579443,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nQFl4uXcSl",
                "forum": "mWxcEm7jIv",
                "replyto": "9Iv597nvB6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8287/Reviewer_F98v"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8287/Reviewer_F98v"
                ],
                "content": {
                    "comment": {
                        "value": "Many thanks for the authors' response."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700712101880,
                "cdate": 1700712101880,
                "tmdate": 1700712101880,
                "mdate": 1700712101880,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "trGJvLnuHH",
            "forum": "mWxcEm7jIv",
            "replyto": "mWxcEm7jIv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8287/Reviewer_YWxN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8287/Reviewer_YWxN"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes an approach utilizing both noisy and denoised examples in the diffusion process as inputs for training a classifier (DA-classifier). Comparative analysis against the noisy classifier method demonstrates the effectiveness of the proposed approach. Additionally, by analyzing its generalization, gradients, and image generation quality, the study further explains the efficacy of the proposed approach."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper conducts both quantitative (generalization to test data) and qualitative (perceptually-aligned classifier gradients and generative modeling metrics) analyses, exhibiting the advantages of DA-classifiers. \n2. The study not only empirically examines the performance of DA-classifiers but also provides theoretical explanations for their gradient properties, theoretically supporting improved perceptual alignment. \n3. The proposed method, though quite simple, proves to be effective in empirical validation."
                },
                "weaknesses": {
                    "value": "1. The numerical results are not good. In Table 2, there are no significant differences between the two methods, especially P and R on the two datasets and all metrics on ImageNet. The visualization in Figures 2, 3, and 4 is impressive.\n2. The motivation behind using diffusion-based samples to train a classifier for semi-supervised learning is unclear and requires further clarification. It is okay to see that semi-supervised generative models perform much worse than those discriminative models. Can we see the comparisons in image generations under the semi-supervised settings? Table 5 only shows the results trained on labeled data."
                },
                "questions": {
                    "value": "1. Why the results of Tables 2 and 4 are not consistent.\n2. 'Cifar10' in abstract."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8287/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698680816767,
            "cdate": 1698680816767,
            "tmdate": 1699637030451,
            "mdate": 1699637030451,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "j34VyyFCXW",
                "forum": "mWxcEm7jIv",
                "replyto": "trGJvLnuHH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8287/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8287/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer YWxN"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their insightful comments and summary. We address the mentioned weaknesses and answer the questions as follows:\n\n1) Numerical results and consistency between metrics in Table 2 and Table 4: Thank you for asking about this. The Precision, Recall, Density and Coverage metrics compare between the manifold of generated distribution and manifold of the source distribution in terms of nearest-neighbours and can be computed conditionally (i.e., classwise) or unconditionally [1]. Table 2 shows the Precision and Recall metrics computed unconditionally while Table 4 shows the Precision, Recall, Density and Coverage metrics computed classwise. For CIFAR10, we do indeed observe significant improvements in terms of classwise Precision, Recall, Density and Coverage metrics (see Table 4). We also observe that using DA-Classifier instead of vanilla classifier improves FID/IS on both ImageNet and CIFAR-10 at similar precision and recall values \u2013 this suggests that both the classifiers have similar manifolds in the nearest-neighbours sense but the generated images with DA-Classifier are more realistic than vanilla-classifiers. In Fig. 5, we qualitatively observe that DA-Classifiers improve over Vanilla-classifiers in terms of overall coherence and since these improvements are generally subtle, we do observe slight but meaningful improvements of FID/IS over the baseline. We will incorporate this discussion into the revised text. Overall, we believe that the numbers are indeed consistent with strong performance, but if there is any remaining result or comparison that the reviewer sees as not being good, then if we failed to provide a clear explanation or interpretation of it, we would be grateful to have the opportunity to correct that. (Thank you!)\n\n   Also, thank you for appreciating the strength of our visualizations! While visualizations can be hard to quantify, we are very excited by these results and agree that they demonstrate a significant contribution of this work!\n\n2) Semi-supervised training: To clarify: the semi-supervised training is exactly analogous to the fully-supervised training in that the classifier is trained to classify samples from the forward diffusion (as described in section 2.2 and Eq. 5); the key difference between the two is that we use pseudo-labels for training over unlabeled examples. Table 5 summarises the image-generation performance of the semi-supervised Noisy-classifier and semi-supervised DA-Classifier trained on the same labeled and unlabeled portions of CIFAR-10: we observe that the semi-supervised DA-Classifier significantly outperforms semi-supervised vanilla-classifier in terms of the classwise Precision, Recall, Density and Coverage metrics. The FID/IS scores in the semi-supervised setting are similar to the fully-supervised case.\n\nWe look forward to addressing any outstanding concerns in the discussion period.\n\n[1] Naeem, M.F., Oh, S.J., Uh, Y., Choi, Y. and Yoo, J. Reliable fidelity and diversity metrics for generative models. ICML, 2020."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700184569994,
                "cdate": 1700184569994,
                "tmdate": 1700186597700,
                "mdate": 1700186597700,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wLC2hYLpCT",
            "forum": "mWxcEm7jIv",
            "replyto": "mWxcEm7jIv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8287/Reviewer_dXPD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8287/Reviewer_dXPD"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces Denoising-Assisted (DA) classifiers to improve the classifier guidance method in diffusion models. DA classifiers are time-dependent classifiers where the input includes denoised examples in addition to perturbed examples and timesteps. The effectiveness of DA classifiers is demonstrated through test classification results, gradient analysis, and the quality of the generated images. They also consider semi-supervised settings, and DA classifiers outperform noisy classifiers in terms of classification accuracy."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The proposed method is simple but effective. Incorporating denoised examples into the classifiers is a reasonable approach to improve performance. Additionally, it is worth noting that they address partial supervision settings, although they did not provide the result on image generation performance."
                },
                "weaknesses": {
                    "value": "1. Baseline\n\nThe paper lacks sufficient baseline comparisons. To strengthen their argument, the authors should compare their method with other relevant classifier guidance methods such as DLSM, ED, and Robust-Guidance. While they mention that these methods are complementary, it would be beneficial to present their performance results, similar to how standard semi-supervised discriminative models are presented in Table 3. In addition, the authors should extend the application of DA classifiers to these methods and report the results to demonstrate the orthogonal nature of their work.\n\n2. Missing generation results in semi-supervised settings\n\nThere is no FID and IS results for generated images in semi-supervised settings. They only said that \"FID and IS metrics are similar to the results described in Table 2\". Since the main task of this paper could be seen as conditional image generation, these experimental results are crucial evidence to assess the effectiveness of their method.\n\n3. Classifier-free guidance in semi-supervised training\n\nThe authors mentioned that semi-supervised training of a classifier-free model is not easy to implement, citing the original paper's recommendation for the supervised settings. It is important to empirically verify this claim, as there is a lack of evidence on for the feasibility and effectiveness of classifier-free models in partial label settings.\n\n4. Clarification of the sampling procedure\n\nSince the primary objective of this paper is image generation, it would be beneficial to provide a detailed procedure or algorithm for sample generation using the proposed method. Actually, the utilization of DA classifiers in sample generation is not straightforward, given the difference in gradient computation between $\\nabla_x \\log p(y|x,t)$ and $\\frac{d \\log p(y|x,\\hat{x},t)}{dx}$. A discussion of the implications of this difference would help clarify the approach."
                },
                "questions": {
                    "value": "1. Please check the issues in the Weaknesses section.\n\n2. Ablation study\n\nIt would be beneficial to include an ablation study to investigate the key factors contributing to the improvement of the DA classifier. Two specific experiments might be considered:\n* Changing $\\hat{x}$ to $s_\\theta (x,t)$ in the DA classifier inputs: this would help to identify the essential elements, such as denoised examples or information of data scores.\n* Use only denoised examples, i.e. $p_\\phi (y|\\hat{x}, t): this would evaluate the importance of using both perturbed and denoised examples.\n\n3. Minor points\n\n* Eq. (7) should explicitly state that this equation holds for the optimal score network.\n* The figure in the middle of page 5 lacks a caption.\n* In the paragraph \"Classifier Gradients (Empirical Observation)\", \"... classifiers trained only with uncorrupted samples...\" may be corrected to \"... classifiers trained only with corrupted samples...\".\n* \"Score-SSL\" does not appear in the manuscript, except in Table 3."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8287/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8287/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8287/Reviewer_dXPD"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8287/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698811188427,
            "cdate": 1698811188427,
            "tmdate": 1699637030305,
            "mdate": 1699637030305,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KqvYW0rPQY",
                "forum": "mWxcEm7jIv",
                "replyto": "wLC2hYLpCT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8287/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8287/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer dXPD (Part 1)"
                    },
                    "comment": {
                        "value": "We thank you for your detailed reviews and insightful questions. We will incorporate the minor corrections and suggestions in our revision along with elements of our response below. We address your concerns as follows:\n\n1) Baselines\n\nEven though DLSM-loss and DA-Classifier represent orthogonal improvements over vanilla classifier, as recognized by the reviewer, we directly compare between the two methods on CIFAR10 (trained on VE-SDE) based on the reviewer\u2019s request:\n||||||||\n|---|:---:|:---:|:---:|:---:|:---:|:---:|\n|  | FID  | IS  | CW Precision  | CW Recall  | CW Density  | CW Coverage  |\n| **DLSM** | 2.25 | 9.90 | 0.56 | 0.61 | 0.76 | 0.71 |\n| **Ours** | 2.33 | 9.88 | 0.63 | 0.64 | 0.92 | 0.77 |\n\nWhile the FID and IS scores are comparable (especially in relation to the typical FID/IS scores observed in the literature), we note that our class-wise Precision, Recall, Density and Coverage metrics are either comparable or demonstrate a significant improvement. Although we are very interested to analyse the fusion of each methodology, this is out of scope of this current paper: furthermore, a careful analysis of fusion in terms of generalisation, classifier-gradients and image-generation performance also requires specific experiments for finding optimal hyperparameters for each fusion -- for example, the hyper parameters controlling the adversarial attack in Robust-Guidance, the softmax temperature in Entropy-driven Training/Sampling, and so on. We are excited to present these kinds of studies in a thorough and systematic future work. But in the present paper, our focus is, rather, to comprehensively analyse the benefits of using denoised examples as an additional input to the classifier both empirically and theoretically while only using the cross-entropy loss objective. The suggested baseline methods such as DLSM, Robust-Guidance and Entropy-Driven Training/Sampling propose novel loss-objectives additional to the usual cross-entropy loss and are hence orthogonal to our method in which we propose using denoised images as additional inputs to the classifier; furthermore, while the baselines are focused on improving classifier-guidance in fully-supervised settings, we also consider semi-supervised settings. In our initial exploration, we tested to see if the DLSM loss objective can help in semi-supervised settings but did not observe any improvements over just using the cross-entropy loss. We agree that these comparisons strengthen the paper and we will add these results in our revision. \n\n2) Semi-supervised generation results\n\nWe thank the reviewer for mentioning this and giving us the opportunity to provide additional numerical evaluations. As mentioned in the paper, the FID and IS scores of images generated with semi-supervised classifiers are very similar to the FID/IS scores of images generated with fully-supervised classifiers: specifically, the FID/IS scores of semi-supervised vanilla classifier and semi-supervised DA-classifier are 2.82/9.61 and 2.35/9.86 respectively. We will include these in the revised version of the paper. The class-wise P/R/D/C values are, however, different for semi-supervised classifiers as compared to fully-supervised classifiers and we do include these in Table 5 (in Appendix B) \u2013 where, we can see that the DA-Classifier outperforms noisy-classifier in semi-supervised settings as well."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700183970200,
                "cdate": 1700183970200,
                "tmdate": 1700183970200,
                "mdate": 1700183970200,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4e5SHdSBoK",
                "forum": "mWxcEm7jIv",
                "replyto": "wLC2hYLpCT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8287/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8287/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer dXPD (Part 2)"
                    },
                    "comment": {
                        "value": "3) Provide empirical evidence that classifier-free guidance in a semi-supervised setting is hard: \n\nWe provide a two-part rebuttal to this comment: first, we argue that comparing between classifier-guidance and classifier-free guidance in fully-supervised settings is not straightforward to begin with. Then, we elaborate upon the challenges in implementation of classifier-free guidance in semi-supervised settings that further complicates comparison between the two methods in semi-supervised settings.\n\n(a) classifier-free guidance and classifier-guidance represent two main categories of guidance methods for diffusion models; classifier-guidance is modular, theoretically motivated and allows for flexible conditioning without requiring to retrain the unconditional score model while classifier-free guidance is a heuristic method that bakes the conditioning into the score-model and requires careful hyperparameter tuning [1]. Comparing between classifier-guidance and classifier-free guidance properly is challenging: for example, previous studies such as GLIDE [2] do this very well, but they rely upon extensive (and expensive) human evaluation of generated samples to show that classifier-guidance often qualitatively underperforms classifier-free guidance; this result is in contrast to the quantitative metrics they computed such as CLIP-scores that usually favoured classifier-guided samples over classifier-free samples. We therefore argue that establishing fair comparison criteria between the two methods would require dedicated research efforts that would be beyond the scope of this paper. Here, we focus on addressing the following deficiencies of vanilla classifier guidance by using denoised images as additional input: 1) Generalization in fully-supervised and semi-supervised settings, 2) Perceptual-alignment of Classifier-gradients, 3) Image Generation Performance. \n\n(b) Training a classifier-free diffusion model with partially labelled dataset is harder because the training relies heavily on labels, as described in our text: \u201c\u2026Ho and Salimans (2022) recommend training with class-label conditioning for 80-90% of each batch and null-token conditioning (i.e., no class label) for the remaining examples whereas we assume that the class-labels are available for less than 10% of the complete training dataset.\u201d If we directly follow the suggestion in that paper, it is easy to see that we will overfit to the labeled examples as we recycle examples from the labeled pool more often than the examples in the unlabeled pool: \n       \n>In the example of CIFAR10, we assume that 4K examples are labelled out of a total 50k samples. If we consider a batch-size of 512 and select the percentage of labeled examples in a batch to be 80%, we will need 410 labeled examples and 112 unlabeled examples for each gradient step. Overall, this implies that 1 epoch over the unlabeled examples corresponds to 41 epochs over the labeled examples (since, 10 gradient steps correspond to 1 epoch over the labeled data). \n\nThus, avoiding overfitting to the labelled pool would require separate research efforts\u2013again outside the scope of this paper\u2013-to identify reliable pseudo-labelling strategies that enable a feasible way to follow the recommendation in Ho and Salismans (2022) \u2014 in order to get good generative performance.\n\n[1] Bahjat Kawar, Roy Ganz, Michael Elad. Enhancing Diffusion-Based Image Synthesis with Robust Classifier Guidance. TMLR, 2023.\n\n[2] Nichol, A., Dhariwal, P., Ramesh, A., Shyam, P., Mishkin, P., McGrew, B., Sutskever, I. and Chen, M. GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models. ICML, 2022.\n\n4) Sampling procedure\n\nThank you for raising this point: this gives us an opportunity to highlight the fact that the implementation of sampling procedure with DA-Classifiers is indeed as straightforward as with vanilla-classifiers: the gradient of the log-probability estimated by the classifier is used as additional guidance in both cases. In our implementation, we simply concatenate the noisy and denoised example and use this as input to the classifier. In terms of the model architecture, we simply double the ```in_channels``` of the input convolution for DA-Classifiers and the remaining architecture is left unchanged: in fact, for the Imagenet experiments in the paper, we expanded the in-channels of the first convolution layer and continued training the pretrained model for 50k steps. We will incorporate this into the paper."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700184263201,
                "cdate": 1700184263201,
                "tmdate": 1700184335874,
                "mdate": 1700184335874,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "te5LlhR9c3",
                "forum": "mWxcEm7jIv",
                "replyto": "wLC2hYLpCT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8287/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8287/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer dXPD (Part 3)"
                    },
                    "comment": {
                        "value": "5) Ablations\n\nThank you for suggesting these ablations. As described in the paper, we evaluated the relative importance of noisy and denoised examples in DA-classifiers by zeroing out one of the input images and measuring its effect upon classification accuracies; we found that while removing either one of the inputs causes the accuracy to drop below the noisy classifier, the drop is higher when the denoised image is masked out. This demonstrates that the DA-classifier makes use of both noisy and denoised examples in the classification. In fact, the intention behind using both noisy and denoised images as input is to allow the model to use parts of both images as needed. Upon acceptance, we will also include an ablation study considering the recommended ablations in the appendix.\n\nWe look forward to addressing any outstanding concerns in the discussion period.\n\n[1] Bahjat Kawar, Roy Ganz, Michael Elad. Enhancing Diffusion-Based Image Synthesis with Robust Classifier Guidance. TMLR, 2023.\n[2] Nichol, A., Dhariwal, P., Ramesh, A., Shyam, P., Mishkin, P., McGrew, B., Sutskever, I. and Chen, M. GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models. ICML, 2022."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700184310017,
                "cdate": 1700184310017,
                "tmdate": 1700184310017,
                "mdate": 1700184310017,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "eCYfjsWKE1",
                "forum": "mWxcEm7jIv",
                "replyto": "wLC2hYLpCT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8287/Reviewer_dXPD"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8287/Reviewer_dXPD"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response. However, I still have the following concerns.\n\n1. Baselines\n\nThe authors only compare to the reported values of DLSM among the mentioned baselines. For example, for Table 1 in ED, it appears that they compare the ImageNet experiment with the same settings in the paper, and it seems to perform better than the DA classifier. A comparison and analysis with ED is also necessary.\n\n| | FID | sFID | IS | P | R |\n|:---:|:---:|:---:|:---:|:---:|:---:|\n|Noisy Classifier|5.44|5.32|194.48|0.81|0.49|\n|DA Classifier|5.24|5.37|201.72|0.81|0.49|\n|ED|4.67|5.12|235.24|0.82|0.47|\n\nAdditionally, the noisy classifier performance as reported in the manuscript also seems to be the same as the performance reported in the ED paper, so it seems to be extracted from that paper. If the values are reported in the previous work, it would be nice to clearly indicate that. \n\nAlso, the authors claim that the proposed method is orthogonal to existing methods, which needs to be supported. This is because it is possible, for example, that the existing methods simply reflect the effect that can be achieved with the Denoising Assistance in a different way. To avoid this concern, the fusion experiments mentioned by the authors are not out of scope, but would be very important to show the orthogonality of the proposed method.\n\n2. Semi-supervised generation results\n\nAs far as I know, a revised version can be posted during the discussion period, so I would like to recommend that the discussion mentioned in the author response be added to the revised version.\n\n3. Classifier-free guidance\n\nThe author claims that the classifier-free diffusion model could easily overfit in partially labeled datasets. As far as I know, there is no experimental evidence for this, and it would be very important to show this experimentally to support the author's opinion. As the author states, it is beyond the scope of this study to find and compare suitable techniques that do not overfit classifier-free guidance. However, I think it is necessary to show experimentally that the current intuitive application of classifier-free guidance leads to overfitting.\n\n4. Sampling procedure\n\nI understand that the practical implementation can be made not to differ much from the existing classifier guidelines, as the authors mentioned. However, the part I pointed out is that in the DA classifier, there is a noisy sample $x$ and a denoised sample $\\hat{x}$, and the denoised sample $\\hat{x}$ is computed from $x$. Therefore, I think the derivative for the DA classifier is expected to require a total derivative as I expressed above. I asked for a discussion of how the effect of a change in $x$ is reflected in the denoised sample, and if not, why it shouldn't be."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700469997812,
                "cdate": 1700469997812,
                "tmdate": 1700469997812,
                "mdate": 1700469997812,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BVKFtxZW0H",
                "forum": "mWxcEm7jIv",
                "replyto": "42gx6XZYaR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8287/Reviewer_dXPD"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8287/Reviewer_dXPD"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the detailed explanation. I understand that the comparison is need to be based on the same sampling method. It is beneficial to provide the DA-Classifier+EDS results.\n\nHowever, I'm still concerned about the orthogonality. In particular, the explanation of complementary is not sufficient because it does not guarantee that the expanded solution set has more good solutions than the original solution set. Moreover, this logic holds for any augmented classifier, not just for denoised examples. Therefore, I think this explanation is for the advantage of the additional input, but not for an advantage of the denoised assistant."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700642112399,
                "cdate": 1700642112399,
                "tmdate": 1700642112399,
                "mdate": 1700642112399,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "OI3ncaHzFX",
                "forum": "mWxcEm7jIv",
                "replyto": "wf1Tsd5KiS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8287/Reviewer_dXPD"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8287/Reviewer_dXPD"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the response. I will consider the orthogonality discussion you mentioned along with the other reviewers.\n\nFor 3, I want to know if the losses being compared are conditional or unconditional scores. Also, I think this comparison should include how the traditional CFG changes in train and validation loss.\n\nFor 4, in a practical implementation, do we need to calculate each term on the right-hand side of Eq. 8? If not, I'm wondering how we can get the total derivative, which is why I was curious about the sampling procedure for this in the first review."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700705525276,
                "cdate": 1700705525276,
                "tmdate": 1700705525276,
                "mdate": 1700705525276,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wAcuG1Z8io",
                "forum": "mWxcEm7jIv",
                "replyto": "An0pkfUHuF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8287/Reviewer_dXPD"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8287/Reviewer_dXPD"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response. Then, is there a time difference due to different classifier gradient calculation between noisy classifier and DA classifier?"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700707718651,
                "cdate": 1700707718651,
                "tmdate": 1700707718651,
                "mdate": 1700707718651,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2qggVjb9U2",
                "forum": "mWxcEm7jIv",
                "replyto": "7KlOk6nDHN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8287/Reviewer_dXPD"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8287/Reviewer_dXPD"
                ],
                "content": {
                    "comment": {
                        "value": "Could you provide the actual sampling time between the noisy classifier and the DA classifier? Additionally, I have a concern that they suggest the distilling diffusion models would be a solution to solve this problem, but these methods are focused on the iterative sampling procedure, not for additional time due to classifier gradient."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700722856897,
                "cdate": 1700722856897,
                "tmdate": 1700722856897,
                "mdate": 1700722856897,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]