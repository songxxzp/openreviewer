[
    {
        "title": "Enhancing Airside Monitoring: Multi-view Approach for Accurate Aircraft Distance-To-Touchdown Estimation in Digital Towers"
    },
    {
        "review": {
            "id": "EOeq86ih5V",
            "forum": "EjIKerYk1O",
            "replyto": "EjIKerYk1O",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2476/Reviewer_E31H"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2476/Reviewer_E31H"
            ],
            "content": {
                "summary": {
                    "value": "This paper propose a method to estimate the distance for aircraft in digital towers. Distance/depth estimation is an interesting topic in 3D vision."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Distance estimation is a challenging task.  \n2. This paper is easy to understand."
                },
                "weaknesses": {
                    "value": "1. The model design is not novel, which has limited technical learning.   \n2. The dataset is not available. Then it cannot be a part of contribution.  \n3. Calibaration network is a little strange. Why it can align two views without knowing the related position for the two cameras? If the two camera's position is changed, can this model still work?   \n4. The number of views in the dataset is only 2.  The statement of \"multi-view\" is unsoundness. Author should increase the view number.  \n5. The paper writing should be further improved. Besides, figure in the manuscript should be the vector figure (Most figures are blur)."
                },
                "questions": {
                    "value": "Refer to the weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2476/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698119061875,
            "cdate": 1698119061875,
            "tmdate": 1699636184135,
            "mdate": 1699636184135,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jFzeqhV47W",
                "forum": "EjIKerYk1O",
                "replyto": "EOeq86ih5V",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2476/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2476/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Discussion on the key contributions of the papers based on reviewer comments"
                    },
                    "comment": {
                        "value": "Thank you for your constructive comments and feedback.\n\n1. Calibration Network, Auxiliary Network, and Their Training:\nThe primary contribution of this work lies in proposing a framework that optimally utilizes multiple view camera streams in airport digital towers to estimate the distance to touchdown of landing aircraft. The approach is grounded in ensemble learning, where each view is processed independently, and their information is subsequently transformed into a shared space for ensemble prediction. The proposed framework is designed to provide flexible adaptation for different digital tower configurations. Depending on the available airport data and its corresponding challenges, the model for aircraft detection can be customized to maximize the system's performance. \n\nBesides, the calibration network plays a pivotal role in handling multiple cameras by converting input features from individual views into a shared feature space. Furthermore, an auxiliary network is shared and employed by all calibration networks to train their parameters.\n\nFurthermore, the current choice of the number of views (e.g., 2) aligns with the current operational constraints of digital towers. However, Algorithm 1 is designed to accommodate arbitrary N (> 1):\n\nAs depicted in Algorithm 1, lines 7 and 8, during each iteration, each calibration network in the list of optimizing views connects to the same auxiliary network for training, aiming to minimize the prediction loss for distance to touchdown values. Moreover, as shown in lines 12-14 of Algorithm 1, views with loss values exceeding the minimum current loss of the calibration network by the defined threshold are selected. These views are then utilized for training in the next iteration. If all losses fall within a certain range, all calibration networks undergo training.\n\n2. LSTM and Miss-Detection in Multi-Views:\n\nIn this study, Long Short-Term Memory (LSTM) is employed to combine inputs from multiple views for distance prediction, effectively handling variations in input size. The primary purpose of this model is to address situations where miss-detection occurs in one of the views. When YOLO fails to detect an aircraft or exhibits low confidence, the detected output is discarded, avoiding its use in subsequent prediction steps. This leads to variations in the input size during the inference step.\n\nIn cases of multiple aircraft in each view, even if the aircraft appearances are similar from a distance, their positions vary significantly based on their distance to touchdown. In these aircraft landing scenarios, all aircraft adhere to specific air traffic control procedures. Therefore, the aircraft from multiple views are matched based on their related positions on the screen and their estimated distance to touchdown from the auxiliary network. \n\n3. Dataset:\nThe simulated dataset featuring multiple aircraft will be made publicly available upon request. However, the dataset obtained from real airport environments is considered highly confidential and cannot be shared."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2476/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700653792477,
                "cdate": 1700653792477,
                "tmdate": 1700653792477,
                "mdate": 1700653792477,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "bdDXxooHor",
            "forum": "EjIKerYk1O",
            "replyto": "EjIKerYk1O",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2476/Reviewer_Z485"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2476/Reviewer_Z485"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes a multi-view deep learning approach for distance-touchdown (DTD) estimation. Yolov7 is utilized here to detect the aircraft in image. Input vecotrs from different views are further combined in an LSTM model, resulting the estimated distance."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. The experiments on simulated and real video data demonstrate that the proposed method can favorably extimate the distance of the aircraft."
                },
                "weaknesses": {
                    "value": "1. This manuscript sounds more like a technique report instead of a research paper. The proposed approach simply utilize an off-the-shelf detection model and an LSTM network to train a distance estimation model.\n2. The authors are encourged to evaluate the performance of baselines with different detection models and network structures."
                },
                "questions": {
                    "value": "When there are more than one aircrafts in the frame, how do you associate the aircrafts across different views?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2476/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2476/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2476/Reviewer_Z485"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2476/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698194091997,
            "cdate": 1698194091997,
            "tmdate": 1699636184043,
            "mdate": 1699636184043,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bTz3gsMUo4",
                "forum": "EjIKerYk1O",
                "replyto": "bdDXxooHor",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2476/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2476/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Discussion on the key contributions of the papers based on reviewer comments"
                    },
                    "comment": {
                        "value": "Thank you for your constructive comments and feedback.\n\n1. Calibration Network, Auxiliary Network, and Their Training:\nThe primary contribution of this work lies in proposing a framework that optimally utilizes multiple view camera streams in airport digital towers to estimate the distance to touchdown of landing aircraft. The approach is grounded in ensemble learning, where each view is processed independently, and their information is subsequently transformed into a shared space for ensemble prediction. The proposed framework is designed to provide flexible adaptation for different digital tower configurations. Depending on the available airport data and its corresponding challenges, the model for aircraft detection can be customized to maximize the system's performance. \n\nBesides, the calibration network plays a pivotal role in handling multiple cameras by converting input features from individual views into a shared feature space. Furthermore, an auxiliary network is shared and employed by all calibration networks to train their parameters.  During training, the calibration network is jointly trained with the auxiliary head, but it undergoes separate training sessions with other instances of the calibration network. Therefore after the training process, the weights of the calibration network become associated with the specific camera and its configuration, while the weight of the auxiliary head is general for every camera. The output of the calibration networks is considered as the shared feature space.\n\nFurthermore, the current choice of the number of views (e.g., 2) aligns with the current operational constraints of digital towers. However, Algorithm 1 is designed to accommodate arbitrary N (> 1):\n\nAs depicted in Algorithm 1, lines 7 and 8, during each iteration, each calibration network in the list of optimizing views connects to the same auxiliary network for training, aiming to minimize the prediction loss for distance to touchdown values. Moreover, as shown in lines 12-14 of Algorithm 1, views with loss values exceeding the minimum current loss of the calibration network by the defined threshold are selected. These views are then utilized for training in the subsequent iteration until their loss value is within a said threshold. If all losses fall within a certain range, all calibration networks undergo training.\n\n2. LSTM and Miss-Detection in Multi-Views:\n\nIn this study, Long Short-Term Memory (LSTM) is employed to combine inputs from multiple views for distance prediction, effectively handling variations in input size. The primary purpose of this model is to address situations where miss-detection occurs in one of the views. When YOLO fails to detect an aircraft or exhibits low confidence, the detected output is discarded, avoiding its use in subsequent prediction steps. This leads to variations in the input size during the inference step.\n\nIn cases of multiple aircraft in each view, even if the aircraft appearances are similar from a distance, their positions vary significantly based on their distance to touchdown. In these aircraft landing scenarios, all aircraft adhere to specific air traffic control procedures. Therefore, the aircraft from multiple views are matched based on their related positions on the screen and their estimated distance to touchdown from the auxiliary network. \n\n3. Dataset:\nThe simulated dataset featuring multiple aircraft will be made publicly available upon request. However, the dataset obtained from real airport environments is considered highly confidential and cannot be shared."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2476/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700653706816,
                "cdate": 1700653706816,
                "tmdate": 1700653706816,
                "mdate": 1700653706816,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "r15JRGPFEy",
            "forum": "EjIKerYk1O",
            "replyto": "EjIKerYk1O",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2476/Reviewer_kvrA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2476/Reviewer_kvrA"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a deep learning solution that uses images captured by cameras installed at airport runways to monitor aircraft traffic around an airport to estimate distance-to-touchdown for incoming (i.e., landing) aircrafts.  Distance-to-touchdown is an important piece of information that is used by airtraffic controllers to manage the air traffic.  The work proposed here develops a key enabling technology for the future digital (air taffic control) towers.  The proposed method is able to integrate information captured by multiple cameras in order to carry out the task at hand.  Each camera feed is processed independently to detect and segment the incoming aircrafts.  Camera network layers process features computed at each camera and the result is sent to an LSTM+inference network.  An auxiliary regression task is used to improve training.  The work is evalauted on both synthetic data, rendered using the popular X-Plane 11 flight simulator and on real data collected at the Singapore Changi airport."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper tackles an important problem in aircraft traffic management and control.  Clearly, vision-based automated schemes for detecting, identifying, and tracking air traffic in and around an airport is of immense value.  The paper cogently argues the need for such a system.  The paper also makes a clever use of synthetic data to train and evaluate the distance-to-touchdown estimation model.  The paper also makes use of TensorRT engine to speed up inference.  This is important due to the real-time nature of the task that the paper wants to solve."
                },
                "weaknesses": {
                    "value": "The work as presented suffers from a number of weaknesses.\n\nFirst off, majority of training and evaluation takes place in a setting that uses only two cameras.  This is unsatisfactory given that the multi-view analysis is one of the central claims of this work.\n\nIt is not immediately obvious how the architecture depicted in Figure 1 manages to integrate the information from multiple cameras.  It seems that the \"calibration network\" is tasked with transforming the features captured by multiple cameras into a shared space where these can be reasoned with jointly.  I feel that we need a lot more discussion around this \"calibration network\" and how it helps integrate information from multiple cameras. \n\nPart of the \"inference\" network contains an LSTM.  It is not clear to me if LSTM is needed to deal with a single frame from multiple cameras or if LSTM is needed to process video feeds.  It appears to me that temporal information may be helpful in regularizing the distance-to-touchdown estimates.  Does the system uses temporal information?\n\nWhat role does auxiliary network play?  And more importantly how does it play the said role?  What is a reversed network?  \n\nThe overall scheme seems rather ad hoc.  YOLO is used as an object detector here.  What if it fails to record a plane?  What if planes are mis-labelled in multiple views?  At a distance most planes look similar!  \n\nSome of the discussion around results raises questions.  On page 8, why does the system perform better in low-light conditions.  This is very counter-intuitive.  This is a safety critical application, so the bar of scientific rigour is very high.  It is not sufficient that the proposed system achieves good results.  It is also important that we understand the limits of this system.  We should be able to explain good (or bad) results.  Perhaps an ablative study will help explain the roles played by individual components of the system."
                },
                "questions": {
                    "value": "1. What happens if the N_views are set to more than 2 in Algorithm 1?\n2. Why max_epoches are set to 225K in Algorithm 1?  This seems an arbitrary number.\n3. Why does the system perform better in low-light conditions?    Do we know why?\n4. How does the system deal with the object association problem in multiple images?\n5. Not sure I can understand the second sentence in the Conclusions section.  It refers to stochastic number of input videos ...  What does it actually mean?\n6. The paper refers to TensortRT?  Do you mean TensorRT?\n7. What is a reversed network?\n8. Can you provide some details of the auxiliary regression network?\n9. Can you provide some details of the calibration network?  It may be useful to provide an ablative study on this, since it plays a central role in integrating information from multiple cameras.\n10. What role does LSTM play?  Is it used to combine information from multiple cameras?  Or it integrates information over time to provide better distance-to-touchdown estimates."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2476/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698771710182,
            "cdate": 1698771710182,
            "tmdate": 1699636183886,
            "mdate": 1699636183886,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "l7cfhvHJD9",
                "forum": "EjIKerYk1O",
                "replyto": "r15JRGPFEy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2476/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2476/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Discussion on the key contributions of the papers based on reviewer comments"
                    },
                    "comment": {
                        "value": "Thank you for your constructive comments and feedback.\n\n1. Calibration Network, Auxiliary Network, and Their Training:\nThe primary contribution of this work lies in proposing a framework that optimally utilizes multiple view camera streams in airport digital towers to estimate the distance to touchdown of landing aircraft. The approach is grounded in ensemble learning, where each view is processed independently, and their information is subsequently transformed into a shared space for ensemble prediction.\n\nAnd yes, the calibration network plays a pivotal role in handling multiple cameras by converting input features from individual views into a shared feature space. Furthermore, an auxiliary network is shared and employed by all calibration networks to train their parameters.\n\nFurthermore, the current choice of the number of views (e.g., 2) aligns with the current operational constraints of digital towers. However, Algorithm 1 is designed to accommodate arbitrary N (> 1):\n\nAs depicted in Algorithm 1, lines 7 and 8, during each iteration, each calibration network in the list of optimizing views connects to the same auxiliary network for training, aiming to minimize the prediction loss for distance to touchdown values.\n\nMoreover, as shown in lines 12-14 of Algorithm 1, views with loss values exceeding the minimum current loss of the calibration network by the defined threshold are selected. These views are then utilized for training in the next iteration. If all losses fall within a certain range, all calibration networks undergo training.\n\n2. LSTM and Miss-Detection in Multi-Views:\n\nIn this study, Long Short-Term Memory (LSTM) is employed to combine inputs from multiple views for distance prediction, effectively handling variations in input size. The primary purpose of this model is to address situations where miss-detection occurs in one of the views. When YOLO fails to detect an aircraft or exhibits low confidence, the detected output is discarded, avoiding its use in subsequent prediction steps. This leads to variations in the input size during the inference step.\n\nIn cases of multiple aircraft in each view, even if the aircraft appearances are similar from a distance, their positions vary significantly based on their distance to touchdown. In these aircraft landing scenarios, all aircraft adhere to specific air traffic control procedures.\n\n3. Dataset:\nThe simulated dataset featuring multiple aircraft will be made publicly available upon request. However, the dataset obtained from real airport environments is considered highly confidential and cannot be shared."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2476/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700642319373,
                "cdate": 1700642319373,
                "tmdate": 1700642319373,
                "mdate": 1700642319373,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]