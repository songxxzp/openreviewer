[
    {
        "title": "Rectifying Group Irregularities in Explanations for Distribution Shift"
    },
    {
        "review": {
            "id": "NSaBwWDi1F",
            "forum": "1qzUPE5QDZ",
            "replyto": "1qzUPE5QDZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8390/Reviewer_AAG5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8390/Reviewer_AAG5"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes Group-aware Shift Explanations (GSE) to address the group irregularities in explanations for distribution shift. The key idea is to optimize for the worst-group PercentExplained (PE). Experimental results justify the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The problem of group irregularities proposed is interesting."
                },
                "weaknesses": {
                    "value": "- The proposed method seems quite limited as it works under the assumption that the source and target are already partitioned into disjoint groups and the correspondence of the groups is available. While for many problems in practice (e.g., domain adaptation for semantic segmentation), such information is not available, which is a major challenge for many problems in CV and NLP.\n- The extension to image/language data is naive and is more similar to how to use existing methods or pre-trained models to convert such data into tabular data."
                },
                "questions": {
                    "value": "Please see weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8390/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698505164184,
            "cdate": 1698505164184,
            "tmdate": 1699637044590,
            "mdate": 1699637044590,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "sZgFDvY8mo",
                "forum": "1qzUPE5QDZ",
                "replyto": "NSaBwWDi1F",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8390/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8390/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for reading our paper and for the review. Our response is below:\n\n## Requirement of group annotations\nIn Section 4.1 of our initial submission, we briefly mention that our method can apply to scenarios without group labels and we included an experiment in Appendix E. We find that using KMeans to determine groups results in improving the feasibility and robustness of explanations similar to when we use prespecified groups. \n\n## Extension to image/language data as naive\nRegarding the point that the extension to image/language data was naive, we want to emphasize that the way of transforming image and language data into interpretable features in our method is just one way of generating human-understandable shift explanations. In the updated paper, we further expanded our framework by considering two additional methods of generating shift explanations for image and language data. These two methods are the following:\n\n1. Deriving shift explanations in a pre-trained model\u2019s embedding space and decoding the embedding into human-understandable explanations using a pre-trained vec2text [Morris et al, 2023] model.\n2. Using concepts (see [Koh et al, ICML 2020]) as the interpretable features for generating shift explanations for image data.\n\nWe performed additional experiments on language and image data with these two methods and included the results in Appendix H. The results again demonstrate the benefits of GSE in rectifying group irregularities and enhancing feasibility and robustness in generating shift explanations. In addition, to the best of our knowledge, other advanced techniques for generating shift explanations for image and language data do not yet exist. The only other work on shift explanations is from Kulinski et al. [Kulinski et al, ICML 2023] which also considered shift explanations over bag-of-word features for language.\n\nFinally, we emphasize that instead of proposing new methods for extracting interpretable features from different data modalities, we wanted to show that group irregularities exist when using shift explanations over different modalities and that our method is able to alleviate this issue. We hope that further research can use our framework to propose more sophisticated shift explanation methods for images and data.\n\n[Morris et al, 2023]: Morris, John X., et al. \"Text embeddings reveal (almost) as much as text.\" arXiv preprint arXiv:2310.06816 (2023).\n\n[Kulinski et al, ICML 2023]: Sean Kulinski and David I Inouye. Towards explaining distribution shifts. In International Conference on Machine Learning, pp. 17931\u201317952. PMLR, 2023.\n\n[Koh et al, ICML 2020] Koh, Pang Wei, Thao Nguyen, Yew Siang Tang, Stephen Mussmann, Emma Pierson, Been Kim, and Percy Liang. \"Concept bottleneck models.\" In International conference on machine learning, pp. 5338-5348. PMLR, 2020."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8390/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700282873592,
                "cdate": 1700282873592,
                "tmdate": 1700282873592,
                "mdate": 1700282873592,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "upfMqHGCnG",
            "forum": "1qzUPE5QDZ",
            "replyto": "1qzUPE5QDZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8390/Reviewer_LTxx"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8390/Reviewer_LTxx"
            ],
            "content": {
                "summary": {
                    "value": "For the explanation of distribution shift, e.g., between train and test datasets, existing methods often find optimal transport between two datasets to quantify the shift. This paper considers group-based optimization and proposes to consider the distance for the worst group to achieve a reasonable explanation (i.e., avoiding overall optimal but locally undesirable transport). Experiments with tabular, language, and image datasets show reasonable explanations of the proposed method using several metrics, including the feasibility metric."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ The explainability of domain shift is a core problem in machine learning that could be more actively studied.\n+ The idea of introducing group robustness to the explanation of domain shift is quite natural and reasonable.\n+ The experiment shows broad categories of datasets in which the proposed method is ready to use in practice."
                },
                "weaknesses": {
                    "value": "- Considering worst-case loss is quite a natural idea and is used in many contexts, as the paper also mentions in the related work section. This kind of loss can be easily plugged into the Wasserstein distance minimization. Readers may consider the proposed method a pure application of these methods to a specific method (i.e., the distribution shift explanation method by Kulinsky & Inouye, 2023).\n\n- I consider that penalizing the loss of the worst group would be a simple way of achieving distributionally robust optimization (DRO), as representative related papers using worst-case losses call their methods distributionally robust (e.g., Sagawa et al., 2019). In such a sense, it is unnatural that this paper does not discuss anything about DRO. Readers would want to see the discussions about how their method can be stated as a new method of DRO for optimal transport problems. \n\n- (Cont'd) In such a sense, we can easily find extensive studies regarding Wasserstein DRO (WDRO) such as:\n\n    - Kuhn, Daniel, et al. \"Wasserstein distributionally robust optimization: Theory and applications in machine learning.\" Operations research & management science in the age of analytics. Informs, 2019. 130-166.\n    - Kwon, Yongchan, et al. \"Principled learning method for Wasserstein distributionally robust optimization with local perturbations.\" International Conference on Machine Learning, 2020."
                },
                "questions": {
                    "value": "How is the proposed method related to Wasserstein distributionally robust optimization methods?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8390/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698589617045,
            "cdate": 1698589617045,
            "tmdate": 1699637044473,
            "mdate": 1699637044473,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "474Hnk70A6",
                "forum": "1qzUPE5QDZ",
                "replyto": "upfMqHGCnG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8390/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8390/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for reading our paper and for the helpful feedback. We respond to your comments and questions below:\n\n## Discussion of DRO\nThank you for the suggestion to discuss DRO, we added a short discussion to Section 5. Our formulation of the worst-group loss is a form of DRO for learning distribution shift explanations. While DRO is often used for reducing spurious correlations in a discriminative model, we use it for finding shift explanations that can alleviate the group irregularity issue and enhance feasibility and robustness at the same time. In our response to reviewer XuMW, we demonstrate that improving the feasibility of the shift explanations can be tied to mitigating spurious correlations. Furthermore, leveraging worst-group loss can not only contribute to reducing spurious correlations but also yield the additional benefit of enhancing the robustness of the  generated shift explanations. To substantiate these claims, we further provide theoretical analysis (Section 3.5 in the revision) and comprehensive empirical evaluations in the paper. \n\n## Connection to Wasserstein DRO\nRegarding the connection between our approach and Wasserstein DRO, despite the necessity of optimizing Wasserstein distance in both our setting and prior studies such as [Kuhn, Daniel, et al], we address an orthogonal problem from them. In those prior studies, Wasserstein DRO is a replacement for ERM which optimizes a risk over all distributions within a small Wasserstein ball for *learning a more robust model*. On the other hand, as pointed out in [Kulinski et al, ICML 2023], the goal of optimizing Wasserstein distance in our setting is for *generating explanations for understanding how distribution shift occurs*.  Plus, different from [Kulinski et al, ICML 2023], our primary focus is on investigating the group irregularity issues in shift explanations learned by optimizing reduction in Wasserstein distance. We added some more discussion concerning this point in Section 5 in the updated paper.\n\n[Kulinski et al, ICML 2023]: Sean Kulinski and David I Inouye. Towards explaining distribution shifts. In International Conference on Machine Learning, pp. 17931\u201317952. PMLR, 2023."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8390/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700282850083,
                "cdate": 1700282850083,
                "tmdate": 1700282850083,
                "mdate": 1700282850083,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qLvV0A1KAf",
            "forum": "1qzUPE5QDZ",
            "replyto": "1qzUPE5QDZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8390/Reviewer_3qo2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8390/Reviewer_3qo2"
            ],
            "content": {
                "summary": {
                    "value": "The manuscript addresses the problem of explainable distribution shifts. For distributions covering changeable and unchangeable properties,  computing the shift blindly will lead to infeasible solutions. This is avoided by grouping the samples, i.e, maintaining the unchangeable properties as constraints. The proposed method is evaluated on several datasets, most of which containing language data or based on language data."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "S1. The manuscript is well structured and illustrated.\n\nS2. The overall problem of infeasible distribution shifts is explained exhaustively.\n\nS3. An attempt is made to open up the method towards other types of data, e.g. images."
                },
                "weaknesses": {
                    "value": "W1. Strong statements in the manuscript frequently lack references. Examples: beginning of abstract (if references are to be avoided here, the wording should be repeated in the introduction together with proper references), first mentioning of \"shift explanation\", example in figure 1, percentages given on page 3 (bottom).\n\nW2. In many places, sentences are formed that do not make sense or are not sufficiently accurate. Examples: \"map a male close to a female by changing the age feature\", delineations between contributions 2 to 4, caption figure 2, explanation of setting for figure 3b.\n\nW3. Theorem 1 (and its proof) mixes general parameters alpha and beta and numbers (10) and the meaning of the parameters / 10 is not well-defined in the theorem.\n\nW4. The \"generalization to image data\" remains effectively a pure language problem. CLIP and stable diffusion are used as \"translators\" from image to text and back, at the text level no image-specific properties remain."
                },
                "questions": {
                    "value": "Q1. Why is it not possible to model the problem using conditional distributions and shifts between those?\n\nQ2. Why is sex considered unchangeable whereas age is changeable?\n\nQ3. Why using alpha = beta =10 in theorem 1?\n\nQ4. \"Robustness\" is defined in terms of changes of feasibility. Why is this aspect not covered by statistical variations over multiple runs?\n\nThe authors provided a good rebuttal and addressed most questions well, leading to an updated assessment."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "Not sure how serious this is: In the text examples for group membership, sex is considered to be a permanent feature and a change of sex as an infeasible solution. This is probably intended as a pedagogical example only, but the authors could have chosen a better one, avoiding the risk of some readers feeling discriminated."
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8390/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8390/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8390/Reviewer_3qo2"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8390/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698663337784,
            "cdate": 1698663337784,
            "tmdate": 1700813770969,
            "mdate": 1700813770969,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "cQmxylvY0q",
                "forum": "1qzUPE5QDZ",
                "replyto": "qLvV0A1KAf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8390/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8390/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the review! We respond to your points below:\n\n## Modeling the problem using shifts between conditional distributions\nWe model the problem as explaining shifts between distributions which also respect subgroups. A subgroup is a conditional distribution; for instance, a group can be the source distribution conditioned on age being over 30. We do not use the term conditional distribution since the term \u201cgroup\u201d is more common in fairness and robustness literature [Dwork et al, ITCS 2012; Sagawa et al, ICLR 2020].\n\n## Statements lacking references\nWe believe that everything mentioned was in fact cited. Everything mentioned in the abstract is cited in the beginning of the introduction. We are not aware of any ICLR papers with citations in the abstract. We also cite the Adult dataset in the introduction (last paragraph of page 1) before it is mentioned in the caption of Figure 1. The percentages at the end of page 3 explicitly refer to the explanation shown in Figure 3a which is cited in the same sentence with the percentage. If there are other places where you believe we are lacking references, please let us know and we will be happy to update the paper.\n\n## Confusing and imprecise sentences\nThe sentences mentioned are all well formed and accurate for their context. We updated the paper to further clarify these sentences or removed them if they were not necessary. The \u201cmap a male close to a female\u2026\u201d example appears in the introduction and explains a phenomenon at a high level, but it is still an accurate description. Since this caused confusion, we decided to remove it. For contributions 2-4, we clarified their differences in the paper, we explained \u201cquality\u201d in the caption of Figure 2, and we added a sentence to clarify the setting of Figure 3b.\n\n## Theorem\nWe removed all numbers and explained the parameters in Theorem 1 based on your suggestion. By removing the numbers, we generalized the Theorem. Also, as suggested by reviewer XuMW, we further provided additional theorems to prove that our method can enhance the feasibility and robustness of shift explanations.\n\n## Generalization to image data\nRegarding the generalization to image data remaining a pure language problem, we only introduce such a translation of image data to language data to produce interpretable explanations, but our method does not depend on this featurization technique. In addition, even though we are using language features, this does not mean that image properties are not represented. Language can capture many image-specific properties such as brightness, perspective, and style which are also used by the text-to-image model. For instance, in Figure 5 of the original submission, the generated caption includes \u201czoo photography\u201d which is an image style feature\n\nAppendix G of the initial submission also includes experiments where we learn an explanation directly over image pixels to show that our method is not dependent on this featurization step, but the resulting explanations are not interpretable. We have modified Section 3.4.2 to reference these additional experiments in Appendix H. We hope that future work proposes more sophisticated interpretable image featurization techniques so we can use them within our framework to get better image shift explanations.\n\n## Choice of feasible and infeasible features\nRegarding why we considered the sex feature unfeasible and age feasible, we made this choice based on existing work on feasibility of explanations [Poyiadzi et al, AAAI 20] where sex was treated as immutable and age was partially mutable. Therefore, we allowed age to be modified and deemed the sex feature as infeasible.\n\nWe also want to address the ethics issue. It was not our intention to make anyone feel targetted or discriminated against and we apologize if that happened. The choice of sex as infeasible comes from prior work on feasible explanations [Poyiadzi et al, AAAI 2020; Mothilal et al, FAT* 2020]. We do not consider sex as generally infeasible, but we acknowledge that there are cases where a user may not want an explanation to include the sex feature. For instance, [Salimi et al, ECAI 2023] conducted a user study on existing explanation techniques and a user commented that \u201cit is highly unethical to suggest someone changes their sex.\u201d The choice of infeasible features is entirely dependent on a user\u2019s intentions, and we chose to use sex as one example. Instead of sex as an infeasible feature, we can use race or age. In our revision, we currently replaced the example with one using race as an infeasible feature, but we also included an example with age as infeasible in Appendix F, and if the reviewer prefers age then we can swap the examples."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8390/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700282999479,
                "cdate": 1700282999479,
                "tmdate": 1700282999479,
                "mdate": 1700282999479,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GhmnHl7h0I",
                "forum": "1qzUPE5QDZ",
                "replyto": "qLvV0A1KAf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8390/Reviewer_3qo2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8390/Reviewer_3qo2"
                ],
                "content": {
                    "comment": {
                        "value": "Conditional distributions: the potential readers of the manuscript will have background from other areas as well and explaining once that \"group\" and \"conditional density\" can be used interchangeably will improve the readability significantly.\n\nReferences: It is the authors' responsibility to be accurate with citations. To this end, I commented examples where I found that citations were too inaccurately used. It is not sufficient to have a reference somewhere that could be the same statement as the first sentence in the abstract (note that I did not insist on adding a reference there but rather to repeat the sentence in the introduction with citation). Regarding the percentages (p. 3), it is not relevant that they are in the figure - it must be said where these numbers are from (= reference or own experiment).\n\nI appreciate the improved formulations in various places. However, I still don't get the understanding between contributions 2 and 3. Contribution 4 is just about the necessary experiments to confirm contribution 2.\n\nThe new formulation of the theorem is more relevant.\n\nImage-based generalization: Where does the proposed pipeline include image features (\"not interpretable\")? The hard part of image representation is the extraction of a descriptive text; however, there are also features that cannot be described by words. A proper image-based generalization should also be in the position to handle those non-textual features. To this end: consider including a brief version of the \"raw pixel\" experiment, including a short description and a comparison to the text-based version in the main paper.\n\nRegarding the feasible features: maybe a clarification had been sufficient to avoid a potential issue here; also not sure that the wording \"race\" is more appropriate in that respect."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8390/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700419056703,
                "cdate": 1700419056703,
                "tmdate": 1700419140780,
                "mdate": 1700419140780,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IWzQK4rd9l",
                "forum": "1qzUPE5QDZ",
                "replyto": "qLS23Vgmzq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8390/Reviewer_3qo2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8390/Reviewer_3qo2"
                ],
                "content": {
                    "comment": {
                        "value": "While I do agree that robustness and _stability_ (e.g. to noise / small perturbations) are different things, this does not mean that only stability can be evaluated as statistical variations. If a violation of an underlying assumption leads to an outlier of the prediction result, the model shows a lack of robustness. Outliers lead to statistical variations."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8390/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700420471190,
                "cdate": 1700420471190,
                "tmdate": 1700420471190,
                "mdate": 1700420471190,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "alhAt026PI",
                "forum": "1qzUPE5QDZ",
                "replyto": "RWNIxpU5bY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8390/Reviewer_3qo2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8390/Reviewer_3qo2"
                ],
                "content": {
                    "comment": {
                        "value": "Several of my concerns are now addressed. Regarding the last point, I understand (again) the use of terminology in a certain part of the community, but it is important to remember the wider audience of readers."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8390/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700470497180,
                "cdate": 1700470497180,
                "tmdate": 1700470497180,
                "mdate": 1700470497180,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "iqO1Rg7O7e",
            "forum": "1qzUPE5QDZ",
            "replyto": "1qzUPE5QDZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8390/Reviewer_XuMW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8390/Reviewer_XuMW"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes Group-aware Shift Explanations (GSE), a shift explanation method for understanding distribution shifts. The authors first identify group irregularities as a class of problems in existing shift explanation literature, and then introduce GSE, which utilizes worst-group optimization to rectify such group irregularities. A unified framework is also developed to generalize GSE from K-cluster transport to broad types of existing shift explanation methods, and from tabular data to language and image data. Experiments on tabular, language, and image datasets demonstrate that GSE preserves group structures and mitigates the feasibility and robustness of the state-of-the-art shift explanation approaches."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This work is the first shift explanation method that identifies group irregularities as a problem that negatively affects the distribution shift explanation ability of the existing approaches, both theoretically and empirically. \n\n2. To rectify the group irregularity issues in existing shift explanation approaches, the authors propose GSE, which leverages the worst-group optimization to optimize the worst-group PercentExplained (PE). GSE maintains group (subpopulation) structures and generates more feasible and robust shift explanations.\n\n3. The authors did a great job adapting the counterfactual explanation methods to the shift explanation setting, developing a general framework that applies GSE to optimal transport and counterfactual explanation methods for generating more reliable shift explanations.\n\n4. Extensive experiments on real-world tabular, language, and image datasets demonstrate the superior performance of GSE in producing more feasible and robust shift explanations while preserving group structures, both quantitatively and qualitatively."
                },
                "weaknesses": {
                    "value": "1. The background introduction should be more clear, especially the parts related to feasibility and robustness. The authors mention several times \"feasibility'' and \"robustness'' when introducing the significance of group irregularity issues in shift explanation and motivation, but the formal definitions of these two terms are not introduced until Section 3.4, which may lead to confusion about these two terms. I think it would be better if the authors discuss in detail about \"feasibility'' and \"robustness'' in the introduction and motivation parts. Further, Figure 1(a) (Figure 3(a)) is not clear in illustrating the group irregularities and GSE's solution compared to Figure 1(b) (Figure 3(b)).\n\n2. GSE rectifies the group irregularity issues by simply extending the optimization of PE to optimizing the worst-group PE. Such idea for tackling subpopulation shifts has already been proposed in [1], though it is not designed for shift explanations. Therefore, the idea of GSE is not very novel. Further, the authors only provide theoretical analysis in a simple 1D setting to illustrate the existence of group irregularities. Regarding the proposed GSE, there is no theoretical justification for why GSE generates a more feasible and robust shift explanation while maintaining group structures than the existing methods. It would be better if the authors could provide further theoretical analysis.\n\n3. GSE assumes that the group information is known in the training data, which is hard to satisfy for most real-world scenarios. \n\n4. The authors did a great job of introducing the works related to explaining distribution shift and worst-group robustness. However, for the works related to domain generalization and adaptation, it would be great if they could discuss connections between domain generalization and adaptation and shift explanations.\n\n[1] Sagawa, S., Koh, P. W., Hashimoto, T. B., \\& Liang, P. (2019). Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. arXiv preprint arXiv:1911.08731."
                },
                "questions": {
                    "value": "1. Please see the questions mentioned in Weaknesses.\n\n2. As GSE requires pre-specified groups in the training data to perform worst-case optimization, I wonder how to select the proper feature that divides the group. In the paper, it seems that using unactionable features (e.g., sex) might be an option. I wonder if the authors could discuss further how to divide data into groups.\n\n3. It is known that group imbalance (irregularity) will make the empirical risk minimization models learn spurious correlation, which is vulnerable under distribution shifts. Therefore, leveraging worst-case optimization can mitigate the spurious correlation issue. As GSE also utilizes worst-case optimization to rectify the group irregularities, I wonder if spurious correlations also cause infeasible or vulnerable shift explanations. It would be great if the authors could discuss further the connection between spurious correlations and feasible and robust shift explanations."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8390/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8390/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8390/Reviewer_XuMW"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8390/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698713231289,
            "cdate": 1698713231289,
            "tmdate": 1699637044235,
            "mdate": 1699637044235,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gmEb4ldgLl",
                "forum": "1qzUPE5QDZ",
                "replyto": "iqO1Rg7O7e",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8390/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8390/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for taking the time to read and provide feedback on our paper! Our response is below:\n\n## Regarding the novelty of the proposed method\nWe appreciate the pointer to prior work [1] which tackles subpopulation shifts with worst-group loss. The scope of our paper, however, is not to solve the classical subpopulation shift issue as in [1] where model performance on subpopulations is the primary focus. Instead, our goal is to reveal that poor performance on subgroups occurs in distribution shift explanations and propose to leverage worst-group loss to alleviate this issue. In our paper, instead of just extending the optimization of overall PE to the worst-group PE, we further provide theoretical analysis and extensive empirical evidence to demonstrate that optimizing worst-group PE can enhance the feasibility and robustness of distribution shift explanations. To our knowledge, this has not been explored by any prior works. We have expanded on the comparison with DRO in Section 5 and highlighted our theoretical analysis in Section 3.5 in the updated paper.\n\n## Use of \u201cfeasibility\u201d and \u201crobustness\u201d in the introduction and motivation\nThank you for the feedback on clarifying the discussion of feasibility and robustness. We added additional details to the high-level description of feasibility in Section 2.1 based on your feedback. Intuitively, feasibility measures the percentage of source samples that are modified in an actionable way by the explanation. For instance, if the explanation modifies the race feature (which we may consider as unactionable) for half of the source samples, then the feasibility is 0.5. Robustness measures the degree to which the shift explanation changes with respect to small perturbations to the source distribution. If there are other confusions caused by our high level definitions in Section 2.1, we will be happy to modify the text to make it clearer. \n\nWe also admit that the formal definitions of \u201cfeasibility\u201d and \u201crobustness\u201d given in Section 3.4 in the original submission came too late. To address this issue, we move Section 3.4 right after Section 3.1 so that the reader can immediately get familiar with these definitions after the motivating examples.\n\n## Clarity of Figure 1a and 3a\nBased on the feedback from reviewer 3qo2, we changed the example in Figure 1 to no longer use the sex feature. Figure 1a is meant to illustrate how the Vanilla explanation can change the proportions of Black and White people, shown as black and white figures respectively, while the GSE explanation is depicted as keeping the proportion the same. Figure 1a is a comparison of Vanilla and GSE explanations on the global level and we have added a subcaption to clarify this. The other part of the comparison happens with the annotated \u201cReduction in Wasserstein distance\u201d in Figure 1a where the GSE explanation is shown to have a total reduction in Wasserstein distance very similar to the reduction for the Black subpopulation while the Vanilla explanation has a larger gap between these two reductions. We explain this at the bottom of page 1.\n\n## Theoretical justification of GSE improving feasibility and robustness\nWe added two additional theorems to analyze robustness and feasibility in a 1D setting in Appendix J. Theorem 2 shows that robustness of a regular explanation scales with a parameter of the target distribution, which is worse than the robustness of a worst-group explanation which is 0. Theorem 3 shows that the feasibility of a regular explanation can be 0 while the feasibility of a worst-group explanation is 1. We have limited the theoretical analysis to the 1D setting since we wanted to validate that group irregularities occur even in the simplest 1D case and that worst-group optimization can mitigate the problem. More comprehensive theoretical analysis beyond 1D settings is left for future work.\n\n## Connection to domain generalization and adaptation\nWe added a short comparison of domain generalization and adaptation with shift explanations to the related work. Both domain generalization and adaptation are methods for learning models while shift explanations are concerned with explaining how data shifts when distribution shifts happen."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8390/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700282771443,
                "cdate": 1700282771443,
                "tmdate": 1700282771443,
                "mdate": 1700282771443,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jdafJXmcB0",
                "forum": "1qzUPE5QDZ",
                "replyto": "JcmZK3wjXE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8390/Reviewer_XuMW"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8390/Reviewer_XuMW"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Reviewer XuMW"
                    },
                    "comment": {
                        "value": "Thank you the authors for the response and efforts. I would like to keep my score as is."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8390/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700728696330,
                "cdate": 1700728696330,
                "tmdate": 1700728696330,
                "mdate": 1700728696330,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]