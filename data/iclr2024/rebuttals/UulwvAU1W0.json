[
    {
        "title": "Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D"
    },
    {
        "review": {
            "id": "fcy2uvPYyR",
            "forum": "UulwvAU1W0",
            "replyto": "UulwvAU1W0",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5759/Reviewer_vhc8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5759/Reviewer_vhc8"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces the fourier transporter, a neural architecture that explicitly captures the bi-equivariant relationships implicit in many pick and place tasks, that is, an object may exhibit rotational symmetry in both picking actions, and placing actions. The architecture first selects an appropriate pick pose using a network that outputs a distribution over picking actions (positions and orientations), with positions used to crop a region about the object to be placed.  This region is then lifted to form a stack of rotated features (a steerable filter) by a network to capture the rotational symmetry present in the picking action. The fourier transform of these features is applied, and used to perform cross-correlation (in the fourier domain, to allow for more efficient computation) with a feature map generated over the workspace observation to determine a distribution over placing positions.   A coarse to fine approach is used to refine the resolution of the pick and place actions, by sampling more rotations as required to refine the pick and place actions. Behaviour cloning experiments are conducted on a range of simulated 3D and 2D manipulation tasks (RLBench, Raven) and show improved success in terms of success rate as a function of training demonstrations. Ablations appear to indicate that most of the heavy work is done by the lifting operation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is well written and motivated, and does an excellent job of formalising the equivariance in robotic pick/place tasks, nicely mapping theory to practice.\n\nThe core contribution (applying the cross-correlation in the fourier domain) is a great way to reduce complexity and allow more lifting angles and finer resolution pick/place, particularly when combined with coarse to fine sampling.\n\nBi-equivariant networks provide a seemingly impressive boost in performance when compared to prior models that do not consider these symmetries."
                },
                "weaknesses": {
                    "value": "The core weakness of this work is the strength of the contribution when compared to the equivariant transporter network proposed in Huang 2022. As far as I can tell key differences include generalising to 3D, more empirical experiments in this domain, and the implementation of the cross correlation in the fourier domain. As mentioned in this work, it is true that the Huang 2022 paper only considers SO(2), and is a subset of the general theory presented here, but more needs to be done to justify why the extension to 3D is non-trivial, particularly when it comes to the major claims of this work, greater angular resolution, computational benefits of fourier implementation, and sample efficiency. \n\nAlong these lines, I would have liked to see an explicit experiment showing clear evidence of higher angular resolution performance (beyond the 15/7.5 degree results in table 2).\n\nNo error bars are provided in experiments (Tables 1/2), so we have no indication that the results are significant. I am sure they are, but this is important for the table 2 comparison with Huang 22.\n\nThe mapping between Figure 2 and the equations in Section 4 is incomplete, and not easily followed. Not all notation is clearly defined (eg. $Ind_{\\rho l}, \\rho_{irrep}, h$ etc.) and equations don't immediately use the network notations ($\\psi, \\phi$). I recognise that much of this notation is standard in group theory, but it is not in robot learning, so there would be value in defining this. This forces the reader to make assumptions/ spend significant time interpreting the mappings between text and figures, and hurts readability. I also recognise that this is out of a desire to formalise and explain the general problem before introducing the specifics of the architecture and approach taken to address this, but the current structure of this section/ group theory jargon made this difficult to follow.\n\nHaojie Huang, Dian Wang, Robin Walters, and Robert Platt. Equivariant Transporter Network. In Proceedings of Robotics: Science and Systems, New York City, NY, USA, June 2022."
                },
                "questions": {
                    "value": "What level of rotational variation is present in the demonstrations and experiments? Is it possible to share some data on the typical distributions and tolerances in pick/place angles the tasks here require?\n\nCould you explain table 3 in more detail - the  ablation here appears to undermine many of the choices this work makes. If a unet + data augmentation can capture many of the equivariance relations, and the lifting operation is the big contributor, then why do we need bi-equivariance? Is this simply an artifact of the test scenarios not adequately evaluating 3D equivariance symmetries?\n\nIn terms of the extension to 3D, it seems that the lifting operator introduces challenges around partial occlusions, that may be hard to learn regardless of the bi-equivariance structure. Could you comment on the general performance/ potential limitations in this regard?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5759/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698721948642,
            "cdate": 1698721948642,
            "tmdate": 1699636604515,
            "mdate": 1699636604515,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CJJBUV5vwu",
                "forum": "UulwvAU1W0",
                "replyto": "fcy2uvPYyR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5759/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5759/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer vhc8"
                    },
                    "comment": {
                        "value": "Thank you very much for the useful feedback.\n\n$\\textcolor{red}{ \\text{ Weaknesses: }} $\n\n**The core weakness of this work is the strength of the contribution when compared to the equivariant transporter network proposed in Huang 2022... more needs to be done to justify why the extension to 3D is non-trivial, particularly when it comes to the major claims of this work, greater angular resolution, computational benefits of Fourier implementation, and sample efficiency.**\n\nWe totally disagree that this paper is not significant relative to Huang et al. 2022. \n\n1. The generalization from the one-dimensional abelian group $SO(2)$ to the three-dimensional non-abelian group $SO(3)$ is highly non-trivial. The method proposed in (Huang 2022) cannot not be extended in three dimensions directly. (Huang 2022) requires the use of one rotation for every element of the group $G$. For subgroups of $SO(2)$, the complexity is O$(n)$, but for the case $SO(3)$, this complexity is O$(n^3)$ -- something that is totally intractable using 3D translational convolution. For example, consider that (Huang 2022) uses $C_{36}$ which has an angular resolution of $10$ degrees and requires $36$ copies of the input feature map to construct a steerable kernel. To achieve the same angular resolution in $SO(3)$, this would require copying the pick feature voxel map into $36^3/2=23228$ discrete orientations.\n\n2. Representing the action distribution with Fourier coefficients is a significant conceptual improvement from (Huang 2022). By utilizing the Fourier Transform on groups, we can sidestep the challenges described earlier and perform memory efficient and accurate computation in three-dimensional space. It allows us to compute and represent the pick/place distribution over continuous action space. To the best of our knowledge, we are the first to represent the pick-place action distribution with Fourier coefficients.\n\n3. The generalization into 3D is very important from a practical perspective. Many imitation learning methods reason in 3D and this paper is the first to design a Transporter-like model for this setting.\n\n**No error bars are provided in experiments (Tables 1/2), so we have no indication that the results are significant. I am sure they are, but this is important for the table 2 comparison with Huang 22**\n\nThe results reported in Tables 1 and 2 are averaged over 100 trials. We have added a note to this effect in the text. We will rerun experiments and include error bars in the final version of our work.\n\n**The mapping between Figure 2 and the equations in Section 4 is incomplete, and not easily followed... the current structure of this section/group theory jargon made this difficult to follow.** \nWe want our work to be readable to a wide audience, specifically researchers in robotic manipulation who are unfamiliar with group theory. For this reason, we have added additional section on mathematical background. We have added pseudocode (see new supplementary) that describes our algorithm on an intuitive level.\n\n$\\textcolor{red}{ \\text{ Questions: }} $\n\n**What level of rotational variation is present in the demonstrations and experiments? Is it possible to share some data on the typical distributions and tolerances in pick/place angles the tasks here require?**\n\nWe have added Figure.5 in appendix to plot the $SO(3)$ distribution of expert actions on two tasks. \n\n**Could you explain table 3 in more detail - the ablation here appears to undermine many of the choices this work makes... why do we need bi-equivariance? Is this simply an artifact of the test scenarios not adequately evaluating 3D equivariance symmetries?**\n\nThe ablation does not undermine our design, because both data augmentation and the lifting operation contribute to the bi-equivariance property of the network. In Proposition 1, we show three constraints that are needed for bi-equivariance; however, the second and third constraints can be implemented through different methods. Results in table 3 are not artifact of the test scenarios not adequately evaluating 3D equivariance; they evaluate different methods to achieve 3D equivariance.\n\n**In terms of the extension to 3D, it seems that the lifting operator introduces challenges around partial occlusions... Could you comment on the general performance/ potential limitations in this regard?**\n\nOcclusion in 3D is a challenge that all methods in this area must address. Our method does about as well as the baselines in this regard. Partial observation is common in 3D and affects the equivariance of our model to some extent. The crop centered at the pick location usually contains only part of the picked object (stack-wine, put-plate) and parts of neighboring objects. Our model lifts the dense feature map (dense descriptors) from the crop instead of the raw crop signal. Equivariance is built on the top of the 3D CNN and our model has the same robust reasoning and learning ability as CNN to deal with the partial observation."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5759/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700536964717,
                "cdate": 1700536964717,
                "tmdate": 1700536964717,
                "mdate": 1700536964717,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6PkntG9Eyk",
                "forum": "UulwvAU1W0",
                "replyto": "CJJBUV5vwu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5759/Reviewer_vhc8"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5759/Reviewer_vhc8"
                ],
                "content": {
                    "title": {
                        "value": "Thanks"
                    },
                    "comment": {
                        "value": "Thanks for the response to my feedback. Just a note re my core weakness point around relationship to Huang 22 - I understand and agree with all the points you make here - my main comment is that this wasn't communicated strongly or explicitly enough in the original draft. This is a very important point to emphasise, since it is central to your claims. I would encourage you be as explicit as you are in your response to me in the paper, to more strongly support the value of the contribution of this work."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5759/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700544380186,
                "cdate": 1700544380186,
                "tmdate": 1700544380186,
                "mdate": 1700544380186,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3YSSRQt8Lq",
                "forum": "UulwvAU1W0",
                "replyto": "fcy2uvPYyR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5759/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5759/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer vhc8"
                    },
                    "comment": {
                        "value": "Thank you for the quick response and clarification. Great point. We will definitely include the more explicit description of our contributions in the final draft!"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5759/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700623857366,
                "cdate": 1700623857366,
                "tmdate": 1700623937940,
                "mdate": 1700623937940,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5ljy2MbeMJ",
            "forum": "UulwvAU1W0",
            "replyto": "UulwvAU1W0",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5759/Reviewer_sjsh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5759/Reviewer_sjsh"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a novel approach for solving 2D and 3D pick and place tasks. The key innovation lies in leveraging Fourier transformation in fiber space to create a memory-efficient and sample-efficient bi-equivariant model. The paper provides theoretical analyses of the method and evaluates it in 2D and 3D simulation benchmarks. When compared to other methods on the RLBench (James et al. (2020)), this approach achieves a substantially higher success rate, and on the Ravens benchmark (Zeng et al., 2021), it demonstrates some improvements."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper shows novelty in the use of Fourier transformation in fiber space, leading to memory efficiency and enhanced sample efficiency for 3D pick and place tasks. Additionally, the proposed methods demonstrate superior performance compared to baseline approaches in select RLBench tasks."
                },
                "weaknesses": {
                    "value": "While the paper demonstrates strong results on RLBench tasks, it's important to note that some tasks like \"stack-blocks\" and \"stack-cups\" primarily operate in 2D space, which may not fully reveal the strengths of the methods in 3D. It would be valuable to include additional\ntasks that involve more 3D rotation angles, such as \u201cput books on bookshelf\u201d."
                },
                "questions": {
                    "value": "In section 5.3 2D Pick-Place results, the last line: \u201dIt indicates that the\nSO(2) \u00d7 SO(2) equivariance of FOURTRAN is more sensitive to rotations.\n\u201d. Does \u201csensitive\u201d means more precise or prone to noise? It would be interesting to conduct separate tests with high-resolution thresholds to distinguish the impact of position error and rotation error. For example, considering parameters like \u03c4 = 1cm and \u03c9 = 7.5&deg; as well as \u03c4 = 0.5cm and \u03c9 = 15&deg;. Additionally, a box plot of the rotation error would also provide more insight into the effect of the method.\n\n\nMinor issues and typos\n\n* The last line in 3 Background: Appendix C\n* The last line on page 4: \u201cHere the action on the base space rotates the pick location and the fiber action transforms the pick orientation.\u201d should it be: \u201cHere the action on the base space transforms the pick location and the fiber action rotates the pick orientation\u201d?\n* Page 7:  \u201cThe different 3D tasks are shown graphically in Figure 4\u201d should be Figure 3\n* Table 3: Success rate(%) of three......\n* Page 15: icosohedral -> icosahedral"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5759/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5759/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5759/Reviewer_sjsh"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5759/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698757024332,
            "cdate": 1698757024332,
            "tmdate": 1699636604414,
            "mdate": 1699636604414,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vKnlxoZF49",
                "forum": "UulwvAU1W0",
                "replyto": "5ljy2MbeMJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5759/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5759/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer sjsh"
                    },
                    "comment": {
                        "value": "We thank the reviewer for an especially detailed and thorough review. We provide a point-by-point response to the comments and questions below:\n\n$\\textcolor{red}{ \\text{ Weaknesses: }} $\n\n**While the paper demonstrates strong results on RLBench tasks, it's important to note that some tasks like stack-blocks and stack-cups primarily operate in 2D space, which may not fully reveal the strengths of the methods in 3D. It would be valuable to include additional tasks that involve more 3D rotation angles, such as put books on bookshelf.**\n\nNote that three of our benchmark tasks ( 'stack-wine', 'place-cups', 'put-plate') are fully 3D and require the ability to reason about the out-of-plane actions. Specifically, in the 'stack-wine' task, the agent must rotate the wine bottle from vertical to horizontal then place it in holder. In order to complete this task, the agent must be able to understand that objects can be rotated out of the plane. Furthermore, while we agree with the reviewer that the 'stack-blocks' and 'stack-cups' tasks do not require significant out-of-plane reasoning, our action space is still defined over all poses in $SE(3)$. These experiments are important because they indicate that our general $SO(3)$ method is competitive with purely $SO(2)$ methods. We will run an additional task which is similar to the 'put books on bookshelf' task.\n\n$\\textcolor{red}{ \\text{ Questions: }} $\n\n**In section 5.3 2D Pick-Place results, the last line: 'It indicates that the $SO(2) \\times SO(2)$ equivariance of FOURTRAN is more sensitive to rotations. \u201d. Does \u201csensitive\u201d means more precise or prone to noise?** \n\nIt means more precise.  By 'sensitive', we mean that $SO(2) \\times SO(2)$-equivariant model is better able to capture high resolution rotations. We have replaced sensitive by precise in the main text. This can be seen by noting that at $\\omega=7.5$ degrees our method still outperforms the 2d baselines.\n\n**It would be interesting to conduct separate tests with high-resolution thresholds to distinguish the impact of position error and rotation error. For example, considering parameters like $\\tau$ = 1cm and $\\omega$ = 7.5\u00b0 as well as $\\tau$ = 0.5cm and $\\omega$ = 15\u00b0. Additionally, a box plot of the rotation error would also provide more insight into the effect of the method.**\n\nThese are great suggestions that will will incorporate into the final version of the paper. We will include these results when they are finished."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5759/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700532965629,
                "cdate": 1700532965629,
                "tmdate": 1700532965629,
                "mdate": 1700532965629,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fIuoSa9FVm",
                "forum": "UulwvAU1W0",
                "replyto": "vKnlxoZF49",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5759/Reviewer_sjsh"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5759/Reviewer_sjsh"
                ],
                "content": {
                    "title": {
                        "value": "Thanks"
                    },
                    "comment": {
                        "value": "Thanks for the clear explanation. I look forward to the results of these additional experiments."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5759/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700661397362,
                "cdate": 1700661397362,
                "tmdate": 1700661397362,
                "mdate": 1700661397362,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "FVH7iATNrt",
            "forum": "UulwvAU1W0",
            "replyto": "UulwvAU1W0",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5759/Reviewer_n4JL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5759/Reviewer_n4JL"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a method for taking advantage of bi-equivariance found in some manipulation problems (equivariance with respect to both the pick and the place pose) for representing distributions over pick-place actions, which exist in $\\textrm{SE}(3) \\times \\textrm{SE}(3)$ and pose sample-efficiency challenges when represented without taking advantage of symmetry. The proposed method demonstrates very strong performance on a variety of imitation learning benchmarks, particularly those requiring fine-grained control."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The argument for a bi-equivariant policy is compelling. The use of Wigner D-matrices to represent an output distribution is very clever and (to my limited knowledge of the literature) seems novel. Their use in the place network to generate fast cross-correlations for bi-equivariance is definitely novel. All theory is well presented and seems well-backed, if a little dense at times to readers less versed in differential geometry and representation theory.\n\nEmpirical results are extremely compelling. The proposed method seems to strongly outperform some relatively strong baselines on very low-data BC tasks."
                },
                "weaknesses": {
                    "value": "Weaknesses mostly center around presentation: the paper contains a lot of dense jargon, which is understandable given the material but could be improved:\n - Given that the Wigner D-matrix representation and corresponding 3D Fourier transform is the key insight that allows this action representation to work, it would be worth spending some more time to describe them in more detail\n - Some pseudocode/method description would be welcome\n\nOtherwise, further analysis of the representations introduced would be nice:\n - $\\ell$\n - the number of rotations in the lifting operation"
                },
                "questions": {
                    "value": "Is it possible that $\\textrm{SO}(2)x\\mathbb{R}^3$-equivariance (2D rotational+translational) is actually more general if grasp dynamics are dependent on the object's orientation with respect to gravity?\n\nIt seems like $I_{60}$ is used in the lifting operation, but as far as I can tell there's no reason the set of rotations has to form a subgroup. Is this correct, e.g. could the granularity be increased by simply sampling more rotations (roughly evenly spaced in $\\textrm{SO}(3)$) in this step?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5759/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5759/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5759/Reviewer_n4JL"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5759/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698830710669,
            "cdate": 1698830710669,
            "tmdate": 1699636604305,
            "mdate": 1699636604305,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oCMpQcz2sF",
                "forum": "UulwvAU1W0",
                "replyto": "FVH7iATNrt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5759/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5759/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer  n4JL"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the detailed feedback. \n\n$\\textcolor{red}{ \\text{ Weaknesses: }} $\n\n**Given that the Wigner D-matrix representation and corresponding 3D Fourier transform is the key insight that allows this action representation to work, it would be worth spending some more time to describe them in more detail**\n\nThanks for pointing this out. We have added an additional section on mathematical background describing the Wigner-D matrices and non-abelian Fourier transform in more detail. A full exposition of representation theory would require a textbook, but we hope that our work can be intuitively understood by reader.\n\n**Some pseudocode/method description would be welcome**\nAgreed. We have added pseudocode to the supplementary material. \n\n$\\textcolor{red}{ \\text{ Questions: }} $\n\n**Is it possible that equivariance (2D rotational+translational) is actually more general if grasp dynamics are dependent on the object's orientation with respect to gravity?** \n\nThis is a great point. We have assumed that grasp dynamics do not play a large role in our specific settings and thus $SE(3)$ symmetry is the most relevant. In the context of a good grasp and with a sufficiently large gripper closing force, the object will not shift greatly under gravity and grasping will be $SO(3)$ invariant. In cases where gravity plays a large roll in grasp dynamics, gravity may break the full $SE(3)$ symmetry to $SO(2) \\ltimes R^3$ as you suggest.  A simple way to address this issue is to simply add the gravity vector as an additional input to the $SE(3)$-equivariant model as done in related work [1].\n\n[1] Fuchs, F., Worrall, D., Fischer, V., & Welling, M. (2020). Se (3)-transformers: 3d roto-translation equivariant attention networks. Advances in neural information processing systems, 33, 1970-1981.\n\n**It seems like $I_{60}$ is used in the lifting operation, but as far as I can tell there's no reason the set of rotations has to form a subgroup. Is this correct, e.g. could the granularity be increased by simply sampling more rotations (roughly evenly spaced in ) in this step?**\n\nCorrect. Randomly sampling a large number of rotations is exactly what we did in our experiments.  We consider the special case where the samples align with the subgroup $I_{60}$ in order to make a theoretical connection to previous work. When the lifting operation uses $I_{60}$, we prove that the resulting filters are an $I_{60}$--steerable kernel. When we sample random rotations uniformly, this produces an approximately $SO(3)$ steerable kernel.  We have clarified this point in the draft."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5759/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700530320852,
                "cdate": 1700530320852,
                "tmdate": 1700530320852,
                "mdate": 1700530320852,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "EY3K2bopfd",
            "forum": "UulwvAU1W0",
            "replyto": "UulwvAU1W0",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5759/Reviewer_DeU9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5759/Reviewer_DeU9"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a method called Fourier Transporter (FOURTRAN) to enhance the efficiency of training robotic agents in performing pick and place actions in 3D environments. By incorporating the bi-equivariant symmetry of the problem into a behavior cloning model, FOURTRAN utilizes a Fourier transformation to encode the symmetries of these actions independently, which enables memory-efficient construction and improves sample efficiency."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper proposes FOURTRAN for leveraging bi-equivariant structure in manipulation pick-place problems in 2D and 3D.\n- The paper presents a theoretical framework for exploiting bi-equivariant symmetry. It contains proofs for propositions that address the symmetry constraints and properties of the model."
                },
                "weaknesses": {
                    "value": "- The current model is limited in a single-task setting, while the baseline methods are designed for multi-task purposes. I'm concerned that the comparisons may not be fair.\n- It relies solely on open-loop control, disregarding path planning and collision awareness.\n- The paper is not well-written and some of the terms are difficult to understand. It uses a lot of notations, but many of them are not explained.\n- There are no real robot experiments."
                },
                "questions": {
                    "value": "- What is **fiber space** Fourier transformation?\n- In Figure 2, how do you crop the object in the scene? What if there are multiple objects?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5759/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5759/Reviewer_DeU9",
                        "ICLR.cc/2024/Conference/Submission5759/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5759/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699362825011,
            "cdate": 1699362825011,
            "tmdate": 1700697286563,
            "mdate": 1700697286563,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FmT2KlmU4p",
                "forum": "UulwvAU1W0",
                "replyto": "EY3K2bopfd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5759/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5759/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer DeU9"
                    },
                    "comment": {
                        "value": "Please find our point-by-point response below:\n\n$\\textcolor{red}{ \\text{ Weaknesses: }} $\n\n**The current model is limited to a single-task setting, while the baseline methods are designed for multi-task purposes. I'm concerned that the comparisons may not be fair.**\n\nThis is something we specifically addressed in Table 1 where we compared the performance of our method in the single-task setting with the baselines trained both ways, i.e. with the baselines trained in the single task setting (Baseline-Single in Table 1) and in the multi-task settings (Baseline-Multi). The single task setting gives an apples-to-apples comparison in that both methods have the same training. However, we also compare to Multi-task trained baselines since, as you point out, this was the setting they were designed for. Our method outperforms the baselines either way.\n\n\n**It relies solely on open-loop control, disregarding path planning and collision awareness.**\n\nThis is not a weakness of our method. The open loop setting which we use (also known as ``keypoint'' control) has become a standard paradigm in the literature on imitation learning for robotic manipulation. All the baseline methods, Robotic View Transformer [1], PerAct [2], and Coarse to Fine [3] are open loop control methods. Additionally all baseline methods use off-the-shelf path planning algorithms.\n\n\n[1] Ankit Goyal, Jie Xu, Yijie Guo, Valts Blukis, Yu-Wei Chao, and Dieter Fox. RVT: Robotic view transformer for 3d object manipulation. In 7th Annual Conference on Robot Learning, 2023\n\n[2] Mohit Shridhar, Lucas Manuelli, and Dieter Fox. Perceiver-actor: A multi-task transformer for robotic manipulation. In Conference on Robot Learning, pp. 785\u2013799. PMLR, 2023.\n\n[3] Stephen James, Kentaro Wada, Tristan Laidlow, and Andrew J Davison. Coarse-to-fine q-attention: Efficient learning for visual robotic manipulation via discretisation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022\n\n\n**The paper is not well-written and some of the terms are difficult to understand. It uses a lot of notations, but many of them are not explained.**\n\nWe acknowledge that the concepts could have been presented more clearly. We have tried to address this by adding a section on mathematical background and adding pseudocode to help the reader understand our method intuitively.\n\n**There are no real robot experiments.**\n\nWe agree that physical robot experiments would strengthen the paper and we are currently working on that. However, we would like to note that physical experiments are not a requirement for ICLR acceptance. Several ICLR papers [1-3] have been published without physical experiments. We are nevertheless working on physical experiments and we plan to include them in the final version of this paper. As evidence that our method works on physical hardware, we have included a video clip of our method running on a Panda robot in the real-world in the supplementary material.\n\n[1] Ryu, Hyunwoo, et al. \"Equivariant Descriptor Fields: SE (3)-Equivariant Energy-Based Models for End-to-End Visual Robotic Manipulation Learning.\" ICLR 2023\n\n[2] Yu, Albert, and Ray Mooney. \"Using Both Demonstrations and Language Instructions to Efficiently Learn Robotic Tasks.\" ICLR 2023\n\n[3] Li, Sizhe, et al. \"Contact Points Discovery for Soft-Body Manipulations with Differentiable Physics.\" ICLR 2022\n\n\n$\\textcolor{red}{ \\text{ Questions: }} $\n\n**What is fiber space Fourier transformation?**\nThe fiber space Fourier transformation computes the Fourier transformation (spectral decomposition) over the channels. This operation is performed separately at each voxel.  The use of the fiber space Fourier transform is a key component of our method and we have added an additional explanation in the mathematical background section.\n\n**In Figure 2, how do you crop the object in the scene? What if there are multiple objects?**\nWe crop a $24^{3}$ voxel box centered at the pick location.  The model does not rely on any object segmentation; it simply learns to crop around the object, since this is where the pick action occurs. Figure 2 is used to explain our idea. The crop usually contains part of the picked object and parts of the neighboring objects. [2] and [3] use similar crop approaches in the 2D case.\n\n[1] Ethan Chun, Yilun Du, Anthony Simeonov, Tomas Lozano-Perez, and Leslie Kaelbling. Local neural descriptor fields: Locally conditioned object representations for manipulation. arXiv preprint\narXiv:2302.03573, 2023\n\n[2] Haojie Huang, Dian Wang, Robin Walters, and Robert Platt. Equivariant Transporter Network.\nIn Proceedings of Robotics: Science and Systems, New York City, NY, USA, June 2022. doi:\n10.15607/RSS.2022.XVIII.007\n\n[3] Yen-Chen Lin, Pete Florence, Andy Zeng, Jonathan T Barron, Yilun Du, Wei-Chiu Ma, Anthony\nSimeonov, Alberto Rodriguez Garcia, and Phillip Isola. Mira: Mental imagery for robotic affordances. In Conference on Robot Learning, pp. 1916\u20131927. PMLR, 2023"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5759/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700528818349,
                "cdate": 1700528818349,
                "tmdate": 1700686126370,
                "mdate": 1700686126370,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iV0OHvpSz6",
                "forum": "UulwvAU1W0",
                "replyto": "FmT2KlmU4p",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5759/Reviewer_DeU9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5759/Reviewer_DeU9"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your reply. Most of my concerns have been addressed and I raised my rating."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5759/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700697263825,
                "cdate": 1700697263825,
                "tmdate": 1700697263825,
                "mdate": 1700697263825,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]