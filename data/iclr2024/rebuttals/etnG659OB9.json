[
    {
        "title": "Causal Disentangled Representation Learning with VAE and Causal Flows"
    },
    {
        "review": {
            "id": "0wNd2Lpj8o",
            "forum": "etnG659OB9",
            "replyto": "etnG659OB9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4445/Reviewer_Uibi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4445/Reviewer_Uibi"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the author adds a causal component to the autoregressive normalizing flow. The causal part follows SEM. The goal is to learn disentangled representations in the latent space."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The author shows the proposed method has better sample efficiency.\n\n2.  The technical details are well-listed in the paper."
                },
                "weaknesses": {
                    "value": "1.  The assumption is too strong and makes the problem less interesting. In this paper, the author requires knowledge of ground truth factors, then the problem degrades to binding predefined labels to latent variables. \n\n2. A lot of relevant works are not discussed in the related work session. Recent progress in unsupervised/ weakly-supervised causally disentangled representations is missing, also there are other works that also use additional information to encourage disentanglement is not included.\n\n3. The backbone of the method is similar to causalVAE (adding causal component with adjacency matrix A), but the author does not use causalVAE as a baseline and compare with it. \n\n4. The author only compares test accuracy but metrics in disentanglement in the experiment"
                },
                "questions": {
                    "value": "See weakness.\n\n1. What is the model's performance compared to causalVAE? \n\n2. What is the fundamental advantage of using causal flow except for sample efficiency?  The author does mention the identifiability claim. However, in the supervised setting, the problem reduces to the identifiability of VAE when binding labels to latent variables, and it has already been resolved in other methods. \n\n3. Why only accuracy but no other evaluation metrics are used in the experiments."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4445/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697871217863,
            "cdate": 1697871217863,
            "tmdate": 1699636419724,
            "mdate": 1699636419724,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "tpGZMwZ9FM",
            "forum": "etnG659OB9",
            "replyto": "etnG659OB9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4445/Reviewer_ZbnB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4445/Reviewer_ZbnB"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses the challenge of learning disentangled representations in the context of causal models. Disentangled representations have been of interest in the machine learning community due to their potential to uncover meaningful and interpretable factors of variation in data. However, most existing methods focus on statistical properties, often neglecting the causal structure of the data-generating process. The authors propose a novel approach that incorporates causal inference into the learning of disentangled representations. Their approach uses Structural Causal Models (SCMs) as a foundation and introduces a new objective function, which they term the CauF-VAE. This framework is an extension of the traditional Variational Autoencoder (VAE) but with an added causal structure. To achieve this, a novel regularizer for the VAE loss function is introduced, which encourages the learned representations to capture the underlying causal structure of the data. The authors conduct extensive experiments on synthetic and real-world datasets, demonstrating the superiority of their proposed method over traditional disentanglement techniques. They show that CauF-VAE not only captures more meaningful factors of variation but also exhibits better generalization and robustness properties."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThe paper addresses an intriguing research problem.\n\n2.\tThe authors design a new VAE model based on causal flows, named Causal Flows Variational Autoencoders (CauF-VAE), to learn causally disentangled representations.\n\n3.\tThe inclusion of diagrams and visual representations, particularly in the experimental results section, aids in comprehension and reinforces the paper's claims."
                },
                "weaknesses": {
                    "value": "1.\tOne major concern I have is the ambiguous definition of identifiability. While the paper distinguishes between the definitions of disentanglement and model identifiability from (Shen et al., 2022) and (Khemakhem et al., 2020a), the model description in Section 4 adopts the iVAE approach (where \"u\" is an additional observed variable). This area requires clearer exposition. I'm unclear on how the authors reconcile the two definitions. Their subsequent discussion on identifiability seems grounded in (Shen et al. 2022), prompting me to wonder about the authors' grasp of the differences in identifiability proposed by the two referenced papers. In essence, while the methodology from (Khemakhem et al., 2020a) is employed to attain identifiability, the rationale from (Shen et al. 2022) is used to substantiate it. Yet, there appears to be a discrepancy in the definitions of identifiability from these two sources.\n\n2.\tI question the novelty of this work. While the paper claims to introduce causal flow to discern genuine causal relationships between factors, the distinctions between various methods, as outlined in Chapter 5, seem insufficient to substantiate this claim of innovation. The CausalVAE is capable of learning causal relationships in representations via additional layers. How does this fundamentally differ from the causal flow technique presented here? From the experimental results in both this paper and the CausalVAE study, it appears that both methods can accurately discern the causal structure for the Pendulum and CelebA datasets. I strongly suggest including CausalVAE as a benchmark for comparison.\n\n3.\tThe Pendulum and CelebA datasets have been widely used for quite some time. Relying on these datasets without specific configurations may not sufficiently demonstrate the algorithm's advantages. I suggest that the authors employ a more contemporary and realistic dataset to validate the algorithm's efficacy, as exemplified in [1]. \n\n4.\tThe paper's writing requires refinement. I noticed several citation mistakes, and the reference details seem outdated. For instance, when introducing notations, the format '...following Shen et al. (2022).' is not consistent with the ICLR style. It should be parenthesized using \\citep{}. Please refer to the ICLR formatting guidelines. Additionally, 'Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.' was actually published at ICLR, so the citation should reflect the correct conference.\n\n[1] Sch\u00f6lkopf, B., Locatello, F., Bauer, S., Ke, N. R., Kalchbrenner, N., Goyal, A., & Bengio, Y. (2021). Toward causal representation learning. Proceedings of the IEEE, 109( 5), 612-634."
                },
                "questions": {
                    "value": "1.\tIn the model, \"u\" is denoted as an additional observed variable. Depending on the context, this variable \"u\" can embody different interpretations, be it a time index in time-series data, a class label, or another contemporaneously observed variable. Given the significance of \"u\" in the iVAE framework, it serves as a foundation for the model presented in this paper. I'm keen to understand: what specific role \"u\" plays in the experiments, particularly within the CelebA (Smile) and Pendulum datasets?\n\n2.\tWhat is the fundamental distinction between Causal Flows and the SCM layer when modelling the causally generative mechanisms of data? From the outcomes presented in both papers, it appears that each approach can accurately capture the causal structure. I believe a thorough discussion on this topic is warranted in the paper.\n\n3.\tThe issue of identifiability warrants closer scrutiny. Given that two distinct concepts are being employed, a detailed delineation of the differences between these concepts is essential for clarity."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4445/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4445/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4445/Reviewer_ZbnB"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4445/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698558787516,
            "cdate": 1698558787516,
            "tmdate": 1699636419626,
            "mdate": 1699636419626,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "TfqjOzoSo3",
            "forum": "etnG659OB9",
            "replyto": "etnG659OB9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4445/Reviewer_3AAm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4445/Reviewer_3AAm"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a VAE based model for learning causally disentangled representations. The problem studied in this work is interesting. But the evaluations should get significantly improved. And the technical contribution of this work is not high."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The problem studied in this work is interesting and important.\n2. The experiments were conducted on both synthetic and real data.\n3. This work presents a method to achieve causal disentanglement without relying on Structural Causal Models."
                },
                "weaknesses": {
                    "value": "1. For the evaluation:\n\n(i) Only one synthetic data and one real data have been used. More datasets should be employed to further demonstrate the effectiveness of the proposed method. e.g., Flow data from CausalVAE paper, 2D toy data or Causal3DIden from Weakly supervised causal representation learning;\n\n(ii) More baselines should be included, especially CausalVAE, LadderVAE, VQ-VAE-2, Weakly supervised causal representation learning, and On Causally Disentangled Representations;\n\n(iii) More evaluation metrics should be used especially the metrics for evaluating learned and true causal graph such as structural Hamming distance (SHD).\n\n2. For the related work, the authors should also discuss/compare the work on Causal Representation Learning other than Causally disentangled representation learning based on VAE. \n\n3. The technical novelties and contributions are limited. Autoregressive flows have been used to improve the inference capability of VAEs and learning causal orders. Thus, integrating causal flows into the VAE to help learn the disentangled representations is not novel. \n\n4. The introduction is not well-written. And for the method section, it is a little bit hard to follow. More intuitions and motivations would be helpful. \n\n5. For section 6.2.3, it is hard to be convinced by the current results and analysis that the proposed method has the potential to learn the structure of A."
                },
                "questions": {
                    "value": "1. How CauF-VAE scales with the size of the causal system?\n\n2. What are the SHD scores between learned and true causal graphs?\n\n3. What are the key technical novelties and contributions?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4445/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698706493137,
            "cdate": 1698706493137,
            "tmdate": 1699636419527,
            "mdate": 1699636419527,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "tPxckW2rI6",
            "forum": "etnG659OB9",
            "replyto": "etnG659OB9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4445/Reviewer_HG71"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4445/Reviewer_HG71"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a novel approach to exploit prior causal knowledge to learn disentangled representations. In order, the authors contribute with an extension of Autoregressive Causal Flows (Khemakhem et al., 2021) and a new model (CauF-VAE) for disentanglement learning. Experimental results are consistent with other disentanglement approaches."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper provides an original approach to disentanglement by injecting prior causal information in a normalizing flow. \n\nUsing an adjacency matrix representing causal relations between variables to introduce more fine-grained information is sound."
                },
                "weaknesses": {
                    "value": "The difference between Causal Flow and Autoregressive Causal Flows (ACF) by Khemakhem et al. (2021) is minimal. The authors replace the partial order of a DAG with an adjacency matrix representing parental relations. In this way, they are effectively requesting additional information compared to ACF. Further, their empirical analysis lacks a comparison with ACFs in place of causal flows. Therefore, the advantages of requiring the whole adjacency matrix instead of a partial order are unclear.\n\nThe formulation of the problem is not straightforward. In particular, the authors adopt the weakly supervised disentanglement setting from Shen et al. (2022), which required labels for part of the dataset. In this work, the authors assume the presence of context vectors for each data point, but they finally equate them to labels (Subsection 4.2). Overall, the methodological presentation deals with two distinct objects, but, in practice, the approach only uses one."
                },
                "questions": {
                    "value": "Q1) Causal Flows need a specification of the causal graph on the variables. On the other hand, using an Autoregressive Causal Flow would require defining a partial order only. Is there any advantage in requesting this further causal information?\n\nQ2) The authors claim to equate context vectors and labels; are these objects always present for each data point during training and inference? In particular, the encoder should reconstruct the latent factors $z$ to match the ground truth factors, given the observation $x$ and a context $u$. If the authors assume the context to be equal to the label, i.e., the ground truth factors, aren't they providing the ground truth to the encoder?\n\nQ3) Being weakly supervised, DEAR assumes that only a subset of the dataset contains labels. Has this been replicated for the empirical analysis?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4445/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698768849871,
            "cdate": 1698768849871,
            "tmdate": 1699636419438,
            "mdate": 1699636419438,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]