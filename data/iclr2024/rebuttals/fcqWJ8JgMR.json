[
    {
        "title": "AuG-KD: Anchor-Based Mixup Generation for Out-of-Domain Knowledge Distillation"
    },
    {
        "review": {
            "id": "ejYOLSTLZX",
            "forum": "fcqWJ8JgMR",
            "replyto": "fcqWJ8JgMR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3571/Reviewer_8qr9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3571/Reviewer_8qr9"
            ],
            "content": {
                "summary": {
                    "value": "This work proposed a new task of Out-of-Domain Knowledge Distillation (OOD-KD) extended from data-free knowledge distillation, which focused on the distribution shift between teacher domain and student domain. The main challenges are (1) the absence of teacher domain's data, (2) how to selectively transfer teachers' knowledge due to the distribution shift, and (3) how to balance OOD KD and domain-specific information learning. To tackle these three challenges, the method consists of a data-free learning generator, anchor learning module, and mixup learning module. Experiments on three datasets verified the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "+ This work proposed a new problem for knowledge distillation, Out-of-Domain Knowledge Distillation (OOD-KD), which is challenging and practical to solve.\n\n+ The presentation and organization of this paper is good. It is easy to figure out the main challenges and the solutions.\n\n+ The experimental results on Office-31, Office-Home, and VisDA-2017 reached state-of-the-art performance."
                },
                "weaknesses": {
                    "value": "- The class-specific mask is essential in anchor learning, but there lacks visualizations on masks to show whether they correctly captured class-specific information.\n\n- According to ablation study 5.3 (a), the contribution of anchor is not significant compared to mixup module, which doubts the effectiveness and necessity of anchor learning module. Here raises a question about why anchor learning is necessary and successfully selectively transfer teachers' knowledge.\n\n- A related work [1] shared the similar motivation on the invalid IID hypothesis and the gap between teacher domain and student domain. Although the research problem is different ([1] focused on conventional KD while this work proposed OOD-KD), it would be more comprehensive if the comparison between this work and [Niu et al., NeurIPS 2022] can be discussed, especially on the above mentioned similarities on motivations, and how to selectively transfer teachers' knowledge.\n\nReference\n[1] Respecting Transfer Gap in Knowledge Distillation. NeurIPS 2022."
                },
                "questions": {
                    "value": "Please see Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3571/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698464274497,
            "cdate": 1698464274497,
            "tmdate": 1699636312026,
            "mdate": 1699636312026,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SozlFe4yRu",
                "forum": "fcqWJ8JgMR",
                "replyto": "ejYOLSTLZX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3571/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3571/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 8qr9"
                    },
                    "comment": {
                        "value": "First and foremost, We would like to appreciate the insightful comments and advice provided by reviewer 8qr9. Guided by these recommendations, we have made several amendments to our work, which are **highlighted in red within the PDF**.\n\n> W1: The class-specific mask is essential in anchor learning, but there lacks visualizations on masks to show whether they correctly captured class-specific information.\n\nA1: Thanks for the suggestion. According to reviewer 8qr9's advice, we respectfully add visualization results (Figure 1 and Figure 2) on the mask by t-SNE in Appendix C.1.\n\nFigure 1 (original $z$) can be referred to https://p.ipic.vip/0btpbb.png\n\nFigure 2 (masked $z$) can be referred to https://p.ipic.vip/7riqhk.png\n\nWe quote it here:\n\n> **Appendix C.1  Visualization On Mask Provided by AnchorNet**\n>\n> In Module 2, AnchorNet integrates the mask operator $m$ and the mapping function $\\psi$ into a lightweight neural network. The mask is class-specific and **plays a crucial role in retaining domain-invariant knowledge in the latent space**. To vividly demonstrate the effectiveness of the mask, we conduct t-SNE on the latent variables and the masked version of them. To be specific, we use AnchorNet and Encoder trained under the setting AW$\\rightarrow$D in Office-31 and select 32 images for each class (31 classes in total). For each image $(x,y)$, we encode it to get the latent variable $z=E(x;\\theta_e)$, and obtain the class-specific mask $m(y;\\theta_a)$. Next, we obtain the masked latent variable $z'=(1-m(y;\\theta_a))\\odot z$. The t-SNE results on $z$ and $z'$ are displayed in Figure 1 and 2 Each displays a distribution of data points plotted against two t-SNE components. The points are colored and shaped differently to represent different classes within the latent space.\n>\n> In Figure 1, the distribution is quite mixed, with no distinct clusters or separation between the different classes. In contrast, in Figure 2, after applying mask operation on the latent variables, there appears to be a more distinct separation between different classes. Clusters of the same shapes and colors are more evident, indicating that the mask operation has enhanced the class-specific knowledge within the latent space.\n\n> W2: According to ablation study 5.3 (a), the contribution of anchor is not significant compared to mixup module, which doubts the effectiveness and necessity of anchor learning module. Here raises a question about why anchor learning is necessary and successfully selectively transfer teachers' knowledge.\n\nA2: Thanks for the question. **AnchorNet plays a crucial role in our proposed method.** We apologize for the ambiguity caused by the title of ablation results. According to the suggestions, we **eliminate the ambiguity** and **add one more ablation setting**.\n\nIn Section 5.3.1, we discuss the effectiveness of our modules. As we stated, without Module 1, the proposed method cannot work, we ignore the ablation result w/o Module 1.\n\n> Since the whole method is inapplicable without Module 1, we ignore it here.\n\nAs a result, conventional ablation studies would discuss the ablation result \"w/o Module 2\", \"w/o Module 3\", and \"w/o Module 2,3\". However, Module 2 is an auxiliary module for Module 3, as stated:\n\n> Module 2 helps Module 3 generate mixup samples for training\n\nIt is also meaningless to check the ablation result of \"w/o Module 3\". **Therefore, our ablation study should be conducted on \"w/o Module 2\" and \"w/o Module 2,3\", which in the text are  \"w/o Anchor\" and \"w/o Mixup\" individually.**\n\nActually, \"w/o Mixup\" is NOT verifying the effectiveness of Module 3: Mixup Leaning, but is **highlighting the harm of blindly adopting DFKD methods under domain shift**. As stated in the second paragraph in Section 5.3.1:\n\n> Given that w/o Mixup is a **simple process of DFKD**, the striking performance degradation **highlights the urgent need for solutions to OOD-KD**.\n\nTherefore, to eliminate ambiguity, we change the name of the ablation results from \"w/o Mixup\" to \"M1\" and from \"w/o Anchor\" to \"M1+M3\" accordingly.\n\nTo further increase the rigor of this ablation study, we **dive into Module 3 and add a new ablation setting: w/o Mixup, where the model trains solely on $D_s$ without mixup samples**:"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3571/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699948219277,
                "cdate": 1699948219277,
                "tmdate": 1700642336177,
                "mdate": 1700642336177,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cIBdOveUMZ",
                "forum": "fcqWJ8JgMR",
                "replyto": "y2FgJYlnbQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3571/Reviewer_8qr9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3571/Reviewer_8qr9"
                ],
                "content": {
                    "comment": {
                        "value": "Thank the authors for the detailed rebuttal, which addressed my concerns and I will keep my rating as 6."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3571/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687127823,
                "cdate": 1700687127823,
                "tmdate": 1700687127823,
                "mdate": 1700687127823,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "1yiIwf9K6u",
            "forum": "fcqWJ8JgMR",
            "replyto": "fcqWJ8JgMR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3571/Reviewer_5Sg9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3571/Reviewer_5Sg9"
            ],
            "content": {
                "summary": {
                    "value": "This work studies on a new but practical problem: Out-of-Domain Knowledge Distillation (OOD-KD). OOD-KD resembles Data-Free Knowledge Distillation (DFKD), which assumes the unavailability of teacher model\u2019s training data except for one significant difference: teacher models\u2019 training data and student models\u2019 test data are not IID distributed. To tackle OOD-KD, the authors propose AuG-KD to align student-domain data with the teacher domain and leverage a generative method to progressively evolve the learning process from OOD knowledge distillation to domain-specific information learning. Experimental results demonstrate its promise of the proposed methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.\tThe problem proposed is new but practical. With the development of ML techniques, most large-scale models are released in a black box or without access to their training data. Under this circumstance, OOD problems are unavoidable. This work focuses on this novel problem and offers a practical solution.\n\n2.\tThe writing is clear and sophisticated. To best clarify the problem and its solution, this work utilizes formulae, method framework, pseudocode, flow chart and visualization.\n\n3.\tThe experiments are extensive. This work conducts its experiments on 3 datasets and 8 settings in five times. Besides, 3 more ablation studies are designed to substantiate the effectiveness of each module of the method. In the appendix, 3 more baselines are taken into consideration. Quite a lot of DFKD methods pay little attention to the repeatability and stability, conducting each experiment with only one seed. This work considers more rigorously in the experiment settings.\n\n4.\tThe experiment analyses are detailed and convincing. Apart from analyzing the stability and superiority of their proposed method, this work steps further. They provide a clear explanation towards the high variance of each method in the data perspective, which lacks related analysis in previous studies. Besides, they provide visualization for the mixup samples generated by their methods."
                },
                "weaknesses": {
                    "value": "1.\tThe detail of the scheduler function is not released. Although the important characteristics of scheduler functions are provided in the main body, I cannot figure out the specific scheduler function used in the experiments.\n2.\tThe ablation study of the effectiveness of each component is not clear. The setting seems ambiguous and in need of further explanation."
                },
                "questions": {
                    "value": "1.\tThe same to weakness 1. To be specific, could you provide more details about which scheduler function you use and what kind of scheduler function would be preferred?\n\n2.\tThe same to weakness 2. More specifically, the ablation result of w/o Anchor has a great performance improvement compared to that of w/o Mixup. Could you further explain it?\n\n3.\tThis work provides detailed visualization on the mixup sample generated in the main body. We could see a gradual change as f increases. However, are there any relationships between the imgs at the same position with different f?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3571/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698732003291,
            "cdate": 1698732003291,
            "tmdate": 1699636311949,
            "mdate": 1699636311949,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LtPrCnz2XB",
                "forum": "fcqWJ8JgMR",
                "replyto": "1yiIwf9K6u",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3571/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3571/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 5Sg9"
                    },
                    "comment": {
                        "value": "First and foremost, We would like to appreciate the insightful comments and advice provided by reviewer 5Sg9. Guided by these recommendations, we have made several amendments to our work, which are **highlighted in red within the PDF**.\n\n> W1: The detail of the scheduler function is not released. Although the important characteristics of scheduler functions are provided in the main body, I cannot figure out the specific scheduler function used in the experiments.\n\nA1: Thanks for the question. For the sake of space, we did not release the details of the scheduler function we used in our experiments.  As stated in the main body, the scheduler function should follow 2 properties:\n\n1. $F(a\\cdot\\sharp{\\rm Epoch};a,b)=1$\n2. $F(0;a,b)=b$\n\nBesides, it should be monotonically non-decreasing within its domain. In our experiments, we only use the simplest scheduler function - linear function for all settings. When $a$ and $b$ are given, the scheduler function can be determined.\n\nIn fact, the idea of scheduler function draws inspiration from Curriculum Learning [1]. For the performance of different and more complex scheduler functions, we refer readers4 to [1] for further reading.\n\nThe discussion of scheduler functions we use has been added to **the end of Appendix A**.\n\n> W2: The ablation study of the effectiveness of each component is not clear. The setting seems ambiguous and in need of further explanation.\n\nA2: Thanks for the advice. We apologize for the ambiguity caused by the title of ablation results. According to the suggestions, we **eliminate the ambiguity** and **add one more ablation setting**.\n\nIn Section 5.3.1, we discuss the effectiveness of our modules. As we stated, without Module 1, the proposed method cannot work, we ignore the ablation result w/o Module 1.\n\n> Since the whole method is inapplicable without Module 1, we ignore it here.\n\nAs a result, conventional ablation studies would discuss the ablation result \"w/o Module 2\", \"w/o Module 3\", and \"w/o Module 2,3\". However, Module 2 is an auxiliary module for Module 3, as stated:\n\n> Module 2 helps Module 3 generate mixup samples for training\n\nIt is also meaningless to check the ablation result of \"w/o Module 3\". **Therefore, our ablation study should be conducted on \"w/o Module 2\" and \"w/o Module 2,3\", which in the text are  \"w/o Anchor\" and \"w/o Mixup\" individually.**\n\nActually, \"w/o Mixup\" is NOT verifying the effectiveness of Module 3: Mixup Leaning, but is **highlighting the harm of blindly adopting DFKD methods under domain shift**. As stated in the second paragraph in Section 5.3.1:\n\n> Given that w/o Mixup is a **simple process of DFKD**, the striking performance degradation **highlights the urgent need for solutions to OOD-KD**.\n\nTherefore, to eliminate ambiguity, we change the name of the ablation results from \"w/o Mixup\" to \"M1\" and from \"w/o Anchor\" to \"M1+M3\" accordingly.\n\nTo further increase the rigor of this ablation study, we **dive into Module 3 and add a new ablation setting: w/o Mixup, where the model trains solely on $D_s$ without mixup samples**:\n\n> Framework ablation studies traditionally involve masking parts of the proposed modules for experimental purposes. Yet, it is essential to recognize: 1. **Module 1 is fundamental to our method and is non-removable**; 2. Module 2 serves to support Module 3. **There is no need to test the results only with Module 1\\&2**. Hence, our investigation focuses on the outcomes absent Module 2, and absent both Module 2 and Module 3, denoted as M1+M3 and M1, respectively. Additionally, our analysis dives into Module 3, where **we omit the mixup samples to evaluate their critical role, denoted as M1+M2+M3 (w/o Mixup)**. It's worth noting that **there is no need to add one more setting w/o M2 \\& Mixup here** since it makes no difference to M1+M2+M3 (w/o Mixup). Consequently, we get three distinct ablation scenarios: **M1, M1+M3, and M1+M2+M3 (w/o Mixup)**. To be specific, in M1, we directly choose $S$'s best checkpoint in Module 1 and test it on $D_s$. In M1+M2+M3 (w/o Mixup), the model trains solely on $D_s$. In M1+M3, we mask AnchorNet by equating its output $z'$ with its input $z$ and then proceed with the method."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3571/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699947202662,
                "cdate": 1699947202662,
                "tmdate": 1699947202662,
                "mdate": 1699947202662,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dNMPDkFsOK",
                "forum": "fcqWJ8JgMR",
                "replyto": "7HXn36Wegj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3571/Reviewer_5Sg9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3571/Reviewer_5Sg9"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the detailed response. I have read the rebuttal and most of my concerns have been well addressed. Overall, I am towards acceptance and will maintain my score.\n\nBest,\nThe reviewer 5Sg9"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3571/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700702340184,
                "cdate": 1700702340184,
                "tmdate": 1700702340184,
                "mdate": 1700702340184,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "pVdp7CQTn4",
            "forum": "fcqWJ8JgMR",
            "replyto": "fcqWJ8JgMR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3571/Reviewer_hjEr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3571/Reviewer_hjEr"
            ],
            "content": {
                "summary": {
                    "value": "This paper explores a significant and practical problem, Out-of-Domain Knowledge Distillation (OOD-KD). The authors believe that adopting models derived from DFKD for real-world applications suffers significant performance degradation, due to the discrepancy between teachers\u2019 training data and real-world scenarios (student domain). Therefore, teachers\u2019 knowledge must be selectively transferred. So the authors proposed AuG-KD, which utilizes an uncertainty-guided and sample-specific anchor to align student-domain data with the teacher domain. Experiments illustrate the effectiveness of the method."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. It is valuable to explore the relationship between OOD and data-free distillation.\n\n2. Although experiments were conducted on multiple dataset settings, the scale was small."
                },
                "weaknesses": {
                    "value": "1. The motivation behind the setting of this paper is confusing. Why do we need to use out-of-distribution teachers when we have student domain data? Wouldn\u2019t it be better to directly train the teacher under the student domain?\n2. Lack of discussion with DFND[1], MosiacKD[2] and ODSD[3]. We think that since generation methods are known, sampling methods should also be compared.\n3. Why not conduct experiments with CIFAR10 and CIFAR100? This is the mainstream dataset in the DFKD. Furthermore, can this method generalize on ImageNet?\n\n[1] Learning Student Networks in the Wild, CVPR 2021\n\n[2] Mosaicking to Distill: Knowledge Distillation from Out-of-Domain Data, NIPS 2021\n\n[3] Sampling to Distill: Knowledge Transfer from Open-World Data, arxiv 2023"
                },
                "questions": {
                    "value": "See Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3571/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3571/Reviewer_hjEr",
                        "ICLR.cc/2024/Conference/Submission3571/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3571/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698743810466,
            "cdate": 1698743810466,
            "tmdate": 1700634447852,
            "mdate": 1700634447852,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "cOBmE2SfSx",
                "forum": "fcqWJ8JgMR",
                "replyto": "pVdp7CQTn4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3571/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3571/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer hjEr"
                    },
                    "comment": {
                        "value": "First and foremost, We would like to appreciate the insightful comments and advice provided by reviewer hjEr. Guided by these recommendations, we have made several amendments to our work, which are **highlighted in red within the PDF**.\n\n> W1: The motivation behind the setting of this paper is confusing. Why do we need to use out-of-distribution teachers when we have student domain data? Wouldn\u2019t it be better to directly train the teacher under the student domain?\n\nA1: Thanks for the question.\n\nFirst, **the problem of OOD-KD is ubiquitous**. For practical applications, **deploying large models directly onto users' devices**, such as using facial recognition at entry points or object detection in autonomous driving scenarios, often **isn't feasible** due to their size and resource requirements. Instead, we deploy a lightweight neural network (e.g. MobileNet) and train it with  i ts data and our large-scale teacher model. However, **their data are naturally OOD with each other and of course, the teachers' training data** (e.g. ethnicity, skin tone in facial recognition and operating environment and weather condition in autonomous) .\n\nIn this case, directly distilling the teacher into our model would lead to great performance degradation. To further improve our model's performance, we should address OOD-KD.\n\n* The reason why we need to use out-of-distribution teachers when we have student domain data is that **directly training the student under the student domain is  not good enough, especially when the amount of data is not sufficient**.\n\n  In our main experiments, we have a baseline \"w/o KD\":\n\n> One more baseline \"w/o KD\" is to train the student model S without the assistance of $T$, starting with weights pre-trained on ImageNet (Deng et al., 2009). \n\n\"w/o KD\" trains a model solely with student domain data, which is not good enough compared to other methods.\n\nDue to space limitations, We put part of the experiment results here. For more detailed results, we kindly refer readers to our original submission. In Office-31,\n\n| Setting | A,W$\\rightarrow$D |              |              | A,D$\\rightarrow$W |              |              | D,W$\\rightarrow$A |              |              |\n| ------- | ----------------- | ------------ | ------------ | ----------------- | ------------ | ------------ | ----------------- | ------------ | ------------ |\n| Metric  | Acc               | Acc@3        | Acc@5        | Acc               | Acc@3        | Acc@5        | Acc               | Acc@3        | Acc@5        |\n| w/o KD  | 63.5$\\pm$7.9      | 84.7$\\pm$4.5 | 90.2$\\pm$3.7 | 82.7$\\pm$5.4      | 96.0$\\pm$1.9 | 98.3$\\pm$0.7 | 52.9$\\pm$3.4      | 72.5$\\pm$3.6 | 79.9$\\pm$2.2 |\n| Ours    | 84.3$\\pm$3.1      | 94.9$\\pm$2.6 | 97.6$\\pm$0.8 | 87.8$\\pm$7.6      | 96.3$\\pm$1.8 | 99.5$\\pm$0.7 | 58.8$\\pm$3.7      | 73.7$\\pm$2.1 | 79.7$\\pm$1.5 |\n\nThe performance gap between \"w/o KD\" and our proposed method is nearly 5% in VisDA-2017, 4% in Office-Home, and 20% in Office-31.  The performance gap is larger and larger as the scale of student domain data decreases but is still significant with 280000 images (VisDA-2017).  **The performance gap underlines the importance of applying KD for better student-domain performance**, especially when the student domain data is not sufficient. \n\n* Usually,  **we CANNOT directly train the teacher under the student domain** for 2 main reasons.\n  1. **We may not be able to deploy a large-scale teacher model on our devices** like mobile phones, etc, due to resource limitations.\n  2. **Some large models are immutable to us due to patent restrictions or resource limitations, like GPT-4.**  It is NOT practical for us to finetune them for better performance.\n\nIn conclusion, addressing the problem of OOD-KD is **of great importance**, since it enables us to transfer knowledge from any teacher model we want and improve the performance of our own models."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3571/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699947826436,
                "cdate": 1699947826436,
                "tmdate": 1699947855915,
                "mdate": 1699947855915,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dTtxqZirdP",
                "forum": "fcqWJ8JgMR",
                "replyto": "7nwcuqvH57",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3571/Reviewer_hjEr"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3571/Reviewer_hjEr"
                ],
                "content": {
                    "comment": {
                        "value": "The response addresses our main concerns, so we increase the rating."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3571/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700634504246,
                "cdate": 1700634504246,
                "tmdate": 1700634504246,
                "mdate": 1700634504246,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Upm4LGWbqV",
            "forum": "fcqWJ8JgMR",
            "replyto": "fcqWJ8JgMR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3571/Reviewer_aobZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3571/Reviewer_aobZ"
            ],
            "content": {
                "summary": {
                    "value": "The study introduces a technique for knowledge distillation wherein a student model learns from a pre-trained teacher model, even when the domains differ. Assuming a consistent label space across both domains, the research addresses the inherent distribution shift. It suggests the development of an 'anchor network' designed to extract domain-neutral features within the latent space. These domain-agnostic images, generated via latent features, are then employed as samples, mixed with student domain data, to facilitate efficacious distillation."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The manuscript is articulated with clarity, ensuring effective comprehensibility to the readers.\n\n2. The authors masterfully contextualize their work in the introduction, clearly delineating their approach from conventional Generic KD and DFKD paradigms.\n\n3. Their introduction of the anchor-based mixup strategy not only showcases novelty but also delivers a marked improvement in knowledge distillation outcomes when benchmarked against prior DFKD techniques and selected source-free domain adaptation methods.\n\n4. The strategy to employ a mask for distinguishing between domain-specific and domain-neutral features is underpinned by a solid rationale, and its formulation and application are both commendably executed."
                },
                "weaknesses": {
                    "value": "Major:\n\n1. The proposed problem definition appears to closely resemble source-free domain adaptation (SFDA) [1]. The only distinction being that the target domain network is more lightweight compared to the pre-trained teacher network. As a result, the problem setup seems to simply be a specific instance of the broader source-free domain adaptation scenario. This raises concerns about the novelty of the problem statement.\n\n2. Given the dataset $D_{s}$, which consists of OOD student domain data with labels, I wonder about the performance of the student when trained solely on $D_{s}$  in a supervised manner. Did the authors conduct any initial tests to gauge baseline performance? Without such a baseline, I question how the authors determined the severity of the problem.\n\nMinor:\n\n1. In Equation 2, the left-hand side (LHS) includes $z_{0}$  in its argument, but $z_{0}$ is absent from the right-hand side (RHS). Clarification is needed regarding the functional operations. This inconsistency is observed in Equations 2 and 3 as well.\n\n2. For Equation 4, while the expectation is based on $z_{0}$, $z_{0}$ is not reflected in the RHS's loss combination. A similar issue is present in Equation 6.\n\n3. In Equation 4, the loss function $L_{generator}$ is introduced. However, it's unclear whether this loss is optimizing the generator weights, the latent space, or both. This lack of clarity persists in Equations 5, 6, and 10.\n\n[1] Kurmi, Vinod K., Venkatesh K. Subramanian, and Vinay P. Namboodiri. \"Domain impression: A source data free domain adaptation method.\" Proceedings of the IEEE/CVF winter conference on applications of computer vision. 2021."
                },
                "questions": {
                    "value": "See Weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3571/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3571/Reviewer_aobZ",
                        "ICLR.cc/2024/Conference/Submission3571/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3571/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698802316182,
            "cdate": 1698802316182,
            "tmdate": 1700681360704,
            "mdate": 1700681360704,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kXzBZAn6xL",
                "forum": "fcqWJ8JgMR",
                "replyto": "Upm4LGWbqV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3571/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3571/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer aobZ"
                    },
                    "comment": {
                        "value": "First and foremost, We would like to appreciate the insightful comments and advice provided by reviewer aobZ. Guided by these recommendations, we have made several amendments to our work, which are **highlighted in red within the PDF**.\n\n> Major 1: The proposed problem definition appears to closely resemble source-free domain adaptation (SFDA) [cite]. The only distinction being that the target domain network is more lightweight compared to the pre-trained teacher network. As a result, the problem setup seems to simply be a specific instance of the broader source-free domain adaptation scenario. This raises concerns about the novelty of the problem statement.\n\nA1: Thanks for the suggestion.  It is of great importance to distinguish OOD-KD from SFDA. We value this input and believe readers will find a more comprehensive exploration of this topic in **Appendix C.3**. I will quote some discussions below.\n\nTo clarify this concern, it is important to note that SFDA and OOD-KD are **fundamentally different in 2 aspects**:\n\n1. In OOD-KD, source and target model are **architecture-agnostic**. \n\n   To be specific,  in most scenarios, we need a lightweight model suitable for our data. Thus we train it with our data and improve its performance with the assistance of a large-scale teacher model. This is the common scenario of KD, where the source model (teacher) and the target model (student) are **naturally different in architecture**. However, **the inaccessibility of teachers\u2019 training data often leads to the problem of OOD-KD and we should address the domain shift problem (difference in distribution between teachers' training data and our data) for better performance**.\n\n   On the other hand, SFDA aims at **adjusting current model to fit a new domain, i.e, adapt source model to target domain**, where target model and source model share the same architecture and **base their methods on this assumption**.  \n\n   **The difference in motivation renders SFDA methods unsuitable for OOD-KD, as they operate under the assumption of architecture identity**. Therefore, even we have splendid DFDA methods, we need to address the problem of OOD-KD.\n\n2. In OOD-KD, source model is **immutable**. To be specific, the immutability of large-scale teacher model is quite common in real-world settings due to privacy or resource limitations. For example, it is not practical for us to finetune models like GPT-4.\n\nThese 2 properties are natural in the context of knowledge distillation but is usually neglected in SFDA methods. For example, SDDA[1]  (reviewer aobZ mentioned) consists of a Domain Adaptation Module, which **consists of a shared feature extractor for source and target domain datasets**. We also discuss some other SFDA methods in the **last second paragraph of Appendix C.3**.\n\n> **However, SFDA does its adaptation on the source model and assumes that the target model shares the same framework as the source model.** ... For example, approaches like SHOT (Liang et al., 2020) and SHOT++ (Liang et al., 2022) divide the backbone model into feature extractor and classifier, sharing the classifier across domains. ...... What\u2019s worse, some SFDA methods base their methodology only on ResNet series models (Yang et al., 2021; Kundu et al., 2022), which is inapplicable to most lightweight neural networks.\n> Major 2: Given the dataset $D_s$, which consists of OOD student domain data with labels, I wonder about the performance of the student when trained solely on $D_s$ in a supervised manner. Did the authors conduct any initial tests to gauge baseline performance? Without such a baseline, I question how the authors determined the severity of the problem.\n\nA2: Thanks for the suggestions. **Yes, we conduct some tests to gauge baseline performance.** The baseline of training solely on $D_s$ is necessary to demonstrate the urgent need for practical solutions to OOD-KD. We appreciate the insight on this matter, which has been detailed within the main text of our article, which is **the baseline w/o KD** in the initial submission:\n\n> One more baseline \"w/o KD\" is to train the student model S without the assistance of $T$, starting with weights pre-trained on ImageNet (Deng et al., 2009). \n\nAs stated in the **last second paragraph in Section 5.1**, \"w/o KD\" adopts the initialization pre-trained on ImageNet and is solely trained with $D_s$ without the help of teacher model. We also put part of the results here."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3571/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699947482318,
                "cdate": 1699947482318,
                "tmdate": 1699947482318,
                "mdate": 1699947482318,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fRbs19O5No",
                "forum": "fcqWJ8JgMR",
                "replyto": "WzIr2VW2Tr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3571/Reviewer_aobZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3571/Reviewer_aobZ"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the comprehensive rebuttal. It addresses most of my concerns, as well as those raised by other reviewers. As a result, I have decided to increase my rating for your submission.\n\nHowever, I would like to recommend an additional enhancement for clarity's sake. Given the multifaceted nature of the tasks in your method, it would be highly beneficial if the equations in your manuscript could be made more self-explanatory. Specifically, it would help readers to understand which parameters are being optimized by which objectives more clearly. This modification would significantly aid in comprehending the intricacies of your approach, especially considering the complexity arising from the multiple tasks being performed.\n\nThank you once again for your attention to these details."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3571/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700681333351,
                "cdate": 1700681333351,
                "tmdate": 1700681333351,
                "mdate": 1700681333351,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]