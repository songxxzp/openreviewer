[
    {
        "title": "Indeterminate Probability Theory"
    },
    {
        "review": {
            "id": "jzU7qTbBWa",
            "forum": "sSWGqY2qNJ",
            "replyto": "sSWGqY2qNJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4295/Reviewer_S3ce"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4295/Reviewer_S3ce"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes \"Indeterminate Probability Theory\", which is claimed as an extension of classical probability theory. Based on the proposed theory, the authors derive an analytical expression of general posterior, which has some applications such as IPNN and CIPNN. Experimental results validate the proposed theory."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "This paper claims to extend classical probability theory, which is very ambitious and is definitely important if this is true."
                },
                "weaknesses": {
                    "value": "The main contribution of this paper is the proposed \"Indeterministic Probability Theory\", but it is far from satisfaction to be a theory, especially when it is stated to be \"an extension of classical probability theory\". It is actually built on the axioms of classical probability theory, added with a specific generation process of random variables, and three proposed \"candidate axioms\", thus it at most becomes \"a special sub-field of classical probability theory\". \n\nEven worse, the paper claims that \"our most important contribution is that we propose a new **general analytical** and **tractable** probability equation\", but neither is theoretically validated: for **general analytical**, it is analytical, but it is not discussed enough why the proposed two-phase protocol is general; for **tractable**, it is also not verified the error of approximation via Monte Carlo methods. There are some experimental results to verify the effectiveness of Monte Carlo, but is over-simplified to validate it in such a general theory as is claimed, and more importantly, the effectiveness of Monte Carlo in this paper is not \"proved\" yet. \n\nTo be honest, section 3 is more like a section of \"problem formulation + proposed approach\": The two-phase protocol is more like the problem formulation, the axioms are more like some assumptions of independence, and the complexity reduction using Monte Carlo is more like the proposed approach."
                },
                "questions": {
                    "value": "What do you want to say in Section 2? It seems that the example does not go beyond classical probability theory, i.e., all definitions, quantities and calculations are consistent with definitions and axioms in classical probability theory.\n\nWhat is new in your indeterminate probability theory? Specifically, I am confused why eq. (4) must be 0 or 1 in classical probability theory. Could the authors give some references? The authors should give references, clear derivations or rigorous counter-examples when refuting something in classical probability theory, as it is based on rigorous mathematics. \n\nHow general your proposed theory is? For example, does your theory enable A and Y to be any kind of random variables, and can the two-phase protocol in your theory model any data-generation process? If not, then the generality of your theory should be discussed. \n\nIn page 5 the authors say \"...Otherwise, Candidate Axiom 2 and Candidate Axiom 3 cannot both be true\". In my opinion, it is strange to discuss the soundness of an axiom once it is proposed."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4295/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697617155207,
            "cdate": 1697617155207,
            "tmdate": 1699636397632,
            "mdate": 1699636397632,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fMiPsHaLy3",
                "forum": "sSWGqY2qNJ",
                "replyto": "jzU7qTbBWa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4295/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4295/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer S3ce"
                    },
                    "comment": {
                        "value": "Dear Reviewer S3ce,\n\nThank you very much for your detailed feedbacks.\n\n**Q1**: What do you want to say in Section 2? It seems that the example does not go beyond classical probability theory, i.e., all definitions, quantities and calculations are consistent with definitions and axioms in classical probability theory.\n\nA1: The example in Section 2 employs our proposed candidate axiom 3, which serves as a helpful introduction to our theory. Our intention is to provide readers with a seamless transition into our theory by using this example.\n\n**Q2**: What is new in your indeterminate probability theory?\n\nA2: We suggest that you take a look at the simple coin toss example in Appendix B. If you can solve it using other probability theories, then our theory would not offer anything new.\n\n**Q3**: Specifically, I am confused why eq. (4) must be 0 or 1 in classical probability theory. Could the authors give some references? \n\nA3: The point here is that Eq. (1) in the paper is only applicable when Eq. (4) is 0 or 1.\n\n**Q4**: The authors should give references, clear derivations or rigorous counter-examples when refuting something in classical probability theory, as it is based on rigorous mathematics.\n\nA4: Our proposed equation does not refute anything in classical probability theory. The classical probability Eq. (1) is a special case to our equation.\n\n\n**Q5**: How general your proposed theory is? For example, does your theory enable A and Y to be any kind of random variables, and can the two-phase protocol in your theory model any data-generation process?\n\nA5: The generalization of our theory is a conclusion from our proposed new candidate axioms. Therefore, if even a single exception is found, it would not be appropriate to assert that the theory is general.\nMoreover, we have applied our theory to thousand dimensional continuous latent spaces without any special requirements for the variables or datasets. That is why we say that the proposed equation is general.\n\n**Q6**: In page 5 the authors say \"...Otherwise, Candidate Axiom 2 and Candidate Axiom 3 cannot both be true\". In my opinion, it is strange to discuss the soundness of an axiom once it is proposed.\n\nA6: We have a differing opinion on this point. Since the axioms are newly proposed, readers should initially approach them with skepticism. The soundness of new axioms should not only be discussed, but also given the highest priority for verification, as they serve as the foundation for a new theory. (For example, it is wrong to claim na\u00efve Bayes independent assumption as an axiom.)\n\nBest regards\n\nAuthors"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4295/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700184690857,
                "cdate": 1700184690857,
                "tmdate": 1700184690857,
                "mdate": 1700184690857,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PEMLzSgMrk",
                "forum": "sSWGqY2qNJ",
                "replyto": "fMiPsHaLy3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4295/Reviewer_S3ce"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4295/Reviewer_S3ce"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the authors for the detailed response. I am writing to let the authors know that I have noticed the authors rebuttal. I promise to read the paper again with the help of authors' response, and will reply in one or two days, as soon as possible. Thanks again!"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4295/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700211681020,
                "cdate": 1700211681020,
                "tmdate": 1700211681020,
                "mdate": 1700211681020,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WySD8f7A8z",
                "forum": "sSWGqY2qNJ",
                "replyto": "fMiPsHaLy3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4295/Reviewer_S3ce"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4295/Reviewer_S3ce"
                ],
                "content": {
                    "comment": {
                        "value": "I agree with the authors on the answer to my quesion Q1 and Q6. For the rest, please refer to the following: \n\nTo be very honest, I still cannot get that what is really new in the proposed \"new theory\", especially when the authors place it with the celebrated field of probability theory. \n\n**About probability theory.** I would first apologize for my incorrect wording \"classical probability theory\": I'm actually referring to the field of probability theory based on measure theory (advanced probability theory, in some courses). Thus, I am very surprised when the authors claimed to have established a theory in several pages without taking limits and integrations, and even make the existing probability theory becoming its special case. I still do not find any expressions in the paper that cannot be written in existing definitions of probability theory, so I keep my concern on whether it is a new probability theory. There are massive textbooks and lessons on \"advanced probability theory\", so I would not list the definitions of it. The authors could also kindly refer to the first reply from Reviewer Xi4x, especially the first and the fourth points.\n\n**About the contribution of this paper.** Given that this paper actually does not extend the existing probability theory (I am not sure on this now), it would be more accepting if the main contribution is a new approach to estimate general posterior. If so, the authors must clearly discuss related works. \n\nThanks!"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4295/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700301929162,
                "cdate": 1700301929162,
                "tmdate": 1700301929162,
                "mdate": 1700301929162,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PIrOf6oCYg",
                "forum": "sSWGqY2qNJ",
                "replyto": "MDhNulqh78",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4295/Reviewer_S3ce"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4295/Reviewer_S3ce"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your response."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4295/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700540229369,
                "cdate": 1700540229369,
                "tmdate": 1700540229369,
                "mdate": 1700540229369,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ChRiYuwGYA",
            "forum": "sSWGqY2qNJ",
            "replyto": "sSWGqY2qNJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4295/Reviewer_Xi4x"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4295/Reviewer_Xi4x"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes to introduce a new theory of probability to cope with imperfect observations, in the sense that the reported value can be different from the true experimental result. This is done through the introduction of an \"observer\", which can be imperfect, in the sense that it is noisy. The theory is then applied to various case studies."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "I do not really perceive any strong point in the paper, other than the fact that modelling imperfect observational process is an interesting, yet arguably old topic."
                },
                "weaknesses": {
                    "value": "This paper is puzzling me in more than one ways, and I will focus on the main ones (some for which the authors can offer a rebuttal, mostly when it concerns the content and not the form of the paper). \n\nA first thing is that the paper is written in a very unusual way, at least for a paper of computer science and/or machine learning. It is very rare to directly start with a mathematical formulation, without making first an introduction (and possibly related work) positioning the proposal and its originality. \n\nA second thing is that the paper is very quick on some technical details, while being very verbose on rather basing thing such as classical applications of probabilistic conditioning. It is also a bit cryptic in terms of language as well as bit naive about some aspects. For instance, P2 top, it is not true that one cannot apply Bayes rule in continuous setting, and it has been numerous, numerous times. At this point, what means indeterminate is also quite obscure. Similarly, it is not clear for the naive Bayes what exactly means $P(A^j=a^j_{i_j}|Y=y_l)$ being not solvable? It can certainly be estimated from data, even in case of noisy observations or untrue assumptions (potentially leading to biased estimates, but it can nonetheless be estimated). \n\nA third thing is that it is unclear what authors really understand by \u201cindeterminate\u201d: is it that the observational process is noisy, or that the obtained probabilities are ill-known and hence that one should consider sets of possible probabilities? The paper suggests the first case, yet in such a situation I really do not see what is different between what is proposed in the paper and the consideration of noisy data where one does know or can estimate the noise process? Given that there is a huge literature on learning from noisy (and/or imprecise) data, at least a positioning with respect to those should be done. Indeed, if the main idea of the paper is to have $P(y_{obs}=y|y_{true}=y)<1$ ($y$ here can be either the output value or a feature value) and then to proceed from that, then I would argue that considering such a situation is not new at all. Similarly, if indeterminate means ill-defined, then there is a whole literature about that (see, e.g., work following the book on Peter Walley on imprecise probabilities and similar). Claiming to build a new theory of probability should be backed up by being very precise about why previous theories do not answer the considered problem. \n\nA fourth thing is that it is really unclear to me why the current experiments, that merely show accuracy results for standard problems, do show that the theory is \u201cvalid\u201d? I would equally question a statistical learning theory or more generally an uncertainty theory whose axioms cannot be the subject of tests and falsification? All theories of uncertainty I know of that are a bit serious in terms of operationally are subject to falsifiability, and this especially true for probabilistic theories (see the Ellsberg paradox for a good example of attempted falsification). Also, since Softmax does not enjoy peculiarly good properties from a theoretical perspective, I would not consider it as a strong baselines against which to test the axioms of a theory?"
                },
                "questions": {
                    "value": "See weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No ethical concerns"
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4295/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698589216177,
            "cdate": 1698589216177,
            "tmdate": 1699636397530,
            "mdate": 1699636397530,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tss9nPQUyL",
                "forum": "sSWGqY2qNJ",
                "replyto": "ChRiYuwGYA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4295/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4295/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Xi4x"
                    },
                    "comment": {
                        "value": "Dear Reviewer Xi4x,\n\nThank you very much for your detailed feedbacks.\n\n**Q1**: For instance, P2 top, it is not true that one cannot apply Bayes rule in continuous setting, and it has been numerous, numerous times.\n\nA1: We respectfully wish to remind you that you have misunderstood our point in P2 top. We merely stated that continuous variable is not applicable to Eq. (1), not Bayes rule.\n\n**Q2**: it is not clear for the naive Bayes what exactly means $P(A^j=a^j_{i_j}|Y=y_l)$ being not always solvable? \n\nA2: The coin toss example in Appendix B is an evidence to this point.\n\n**Q3**: is it that the observational process is noisy, or that the obtained probabilities are ill-known and hence that one should consider sets of possible probabilities? \n...\nif the main idea of the paper is to have $P(y_{obs}=y|y_{true}=y)<1$ ($y$ here can be either the output value or a feature value)?\n\nA3: Your formulation does not align with our theory. Hence, we will adopt your idea to frame our case as follows: $P(y_{obs}=y|x_{k})<1$ and $P(y_{true}=y|x_{k})=1$. Our focus is solely on the indeterminate observation for the $k^{th}$ random experiment. And our objective is to utilize $A_{obs}$ ($P(A_{obs}=a|x_{k})<1$) to infer $y_{obs}$. More details you can find in Q5 of Reviewer MWjN.\n\n\n**Q4**: Similarly, if indeterminate means ill-defined, then there is a whole literature about that (see, e.g., work following the book on Peter Walley on imprecise probabilities and similar).\n\nA4: Thank you for sharing Peter Walley's imprecise probabilities theory. From our limited understanding, this theory differs from ours in that it represents probabilities using sets or intervals of values, rather than a single point. \n\n**Q5**: I would equally question a statistical learning theory or more generally an uncertainty theory whose axioms cannot be the subject of tests and falsification?\n\nA5: To deny a new axiom, all you need is to find a single exception, even a simple toy example would suffice.\n\n**Q6**: All theories of uncertainty I know of that are a bit serious in terms of operationally are subject to falsifiability, and this especially true for probabilistic theories (see the Ellsberg paradox for a good example of attempted falsification).\n\nA6: Thank you for sharing the Ellsberg paradox with us. However, this example differs from our case. The reason why Axioms 1, 2, and 3 cannot be falsified is that they have no exceptions.\n\n**Q7**: since Softmax does not enjoy peculiarly good properties from a theoretical perspective, \n\nA7: We agree that softmax properties are not good enough. In our applications, softmax is only used for IPNN, and we have encountered local minimum problems with this function, as outlined in Appendix E.7. However, our CIPNN and MTS forecasting method rely on Gaussian distribution, not softmax function.\n\n\nBest regards\n\nAuthors"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4295/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700184558276,
                "cdate": 1700184558276,
                "tmdate": 1700184558276,
                "mdate": 1700184558276,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "OyZ0OxULTi",
                "forum": "sSWGqY2qNJ",
                "replyto": "ChRiYuwGYA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4295/Reviewer_Xi4x"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4295/Reviewer_Xi4x"
                ],
                "content": {
                    "title": {
                        "value": "A first reply to clarify some points"
                    },
                    "comment": {
                        "value": "Dear authors,\n\nThanks for your various replies to my questions. Before examining them and the paper again (two things I will only be able to do with the limited time I can allocate to discuss/review a specific ICLR paper), I would like to point out that my initial comments aimed at pointing out general problems of the paper, and what authors have provided are rather specific answers compared to this generality. My current opinion is that before being accepted, the paper would need to clarify many things:\n\n* First, being crystal clear about the mathematical statements made in the paper. This is especially important for axiomatic and theoretic studies. Such a thing as \"Not applicable if $A_j$ is continuous\" will not really make it, especially as frequentist interpretation of probabilities (one possible interpretation of Equation (1)) can perfectly deal with continuous spaces. \n\n* Second, and as the work intends to be axiomatic, be very clear about the terminology. As said in the review, the word \"indeterminate\" usually refers to coarse/missing/imprecise aspects, something that is not really discussed here. So there is a need at least to explain how the notion of indeterminacy here differs from the classical notions of indeterminacy. \n\n* Third positioning itself from other works that are very close to the presented idea, such as noisy observations (note that noise can be defined instance-wise as well). \n\n* Fourth, all of this (clear positioning, unanmbiguous mathematics for all critics/statements) are necessary elements of a paper advancing a new theory/framework, that should not be relegated to the appendices for the sake of space limitations. As authors indicate by referring very often to the appendix, this may be something that is not doable in a conference format, and rather than potentially making a fourth submission to any A/A* conference of their preference, maybe a full journal paper (or a book, if they really want to expose a new, full-fledged theory) would be more suitable. On one side it would at least give more time to reviewers to fully read the paper and enter into the examples, and on the other side it would allow the authors to make a full, complete exposure of their work. \n\n* Fifth and not last, I definitely remain wary of an uncertainty theory where \"Axioms 1, 2, and 3 cannot be falsified is that they have no exception\", at least for two reasons: this would suggest a \"perfect theory\", which arguably cannot exists, and also as I've said, I think a theory about uncertainty should be falsifiable to some extent, so as to know its limits and be open to criticism. \n\nTo be clear, I am not advancing that there is no value in the current paper (there may well be), but if there is, the current presentation does not allow me to assess them clearly (in particular in comparison to the very, very vast literature on probability foundations).\n\nBest"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4295/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700217202356,
                "cdate": 1700217202356,
                "tmdate": 1700304870579,
                "mdate": 1700304870579,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "4DdfJbqlyA",
            "forum": "sSWGqY2qNJ",
            "replyto": "sSWGqY2qNJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4295/Reviewer_MWjN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4295/Reviewer_MWjN"
            ],
            "content": {
                "summary": {
                    "value": "This is an extremely ambitious paper that attempts to construct a new theory called indeterminate probability theory. The key idea of Indeterminate probability theory is to introduce a new concept of auxiliary observers and to treat the results of each random experiment as an indeterminate probability distribution, while still preserving the assumption of mutual independence. As a result, the posterior probabilities of the system can be derived in a form that is easy to handle analytically, an important benefit in applications.\nThe authors demonstrate the applicability of this idea to regression and classification problems by combining it with neural networks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "I am very grateful to the authors for sharing their novel attempt at this paper. I enjoyed reading this paper very much.\n- The paper devotes a great deal of effort in its presentation to illustrate new ideas that are outside of the conventional wisdom. The paper is very well written and its organization is designed to appeal to a diverse audience. In particular, it is designed to be easily understood by explaining the core ideas by means of toy examples.\n- The practical contribution of this paper is very significant. Traditionally, posterior probabilities in statistical machine learning have been approximated by some kind of approximation method (e.g., Markov chain Monte Carlo or variational methods), but the ideas in this paper have the potential to be a new option to add to that."
                },
                "weaknesses": {
                    "value": "First of all, let me emphasize that I am trying to be very open minded in understanding the value of this paper. My grade on my first peer review may not be very high, but I am prepared to improve it as soon as I properly understand the value of this paper.\nMy concern is whether this paper could create a new system of probability theory (i.e., a major historical breakthrough) or whether it provides a new perspective on approximation and interpretation for the system in a form that is easy to handle in applications (i.e., a new alternative alongside MCMC and VB), a somewhat excessive Is it an appealing proposition? I would like to inquire in the question section for more details."
                },
                "questions": {
                    "value": "My question can be summarized very simply as to whether or not indeterminate probability theory can be expressed in terms of a definition of probability space using abstract probability space.\n\nFirst of all, I understand this new insightful strategy of the authors as follows (Perhaps this understanding of mine is incorrect. If I am wrong, I would be very grateful if you could correct me.) \n- The authors' system introduces uncertainty as an auxiliary variable for observers. If this were to be expressed in the context of a conventional standard Bayesian analysis, the observer could be represented as making an observation error according to the auxiliary random variable.\n- Next, since this auxiliary random variable is not needed to describe the system, we will try to eliminate it in some way. In a conventional standard Bayesian analysis, this can be done by eliminating the auxiliary random variable by marginalization. However, a problem arises here. If the auxiliary random variable is shared by all observers, the system loses observer independence (Axiom 2 of the proposed probability theory) when it is eliminated.\n- Therefore, the proposed probability theory simply ignores the auxiliary random variable while simultaneously assuming Axiom 2.\n\nIf we were to use such a strategy, it would certainly seem that we could view the system as different from classical probability theory (as mentioned in the paper, we could of course make special cases that are equivalent to classical probability theory in special circumstances).\n\nFollowing this intuition, my interest is in what the authors' system would look like if it were represented in an abstract probability space. That is, a situation where all randomness in the world is governed by an abstract space $\\Theta$, where all randomness is lost if the abstract space is determined at a point $\\theta\\in\\Theta$, and where all variables can be described deterministically. In the abstract space, random variables are represented as a projection of the world as a map to an object, e.g., $Y(\\theta), X(\\theta), A(\\theta)$ can be uniquely determined for a given source $\\theta$. Can the authors' system be represented using such a conventional abstract probability space? Or is it a deviation from that rule?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4295/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4295/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4295/Reviewer_MWjN"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4295/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698772236660,
            "cdate": 1698772236660,
            "tmdate": 1700388286660,
            "mdate": 1700388286660,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "S2VJ9dHnMI",
                "forum": "sSWGqY2qNJ",
                "replyto": "4DdfJbqlyA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4295/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4295/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer MWjN"
                    },
                    "comment": {
                        "value": "Dear Reviewer MWjN,\n\nWe sincerely appreciate your insightful comments, and we are excited to receive such in-depth feedbacks.\nWe appreciate your high-level discussion on this topic, as well as the new perspective in which you summarized the theory in the 'Questions' part. \nHere are our detailed responses to your questions.\n\n\n**Q1**: ... if it can be expressed as abstract probability space.\n\nA1: Yes, we will provide a detailed response starting from Q3.\n\n**Q2**: your own understanding ... the proposed probability theory simply ignores the auxiliary random variable while simultaneously assuming Axiom 2.\n\nA2: We are surprised by your new understanding of this theory, and we agree with you.\nWe will provide further details to support this understanding.\n\n$$\n\\underset{\\text{(a)}}{\\underbrace{{\\color{Red}P^{\\mathbb{A}}\\left ( y_{l}\\mid x_{n+1}   \\right ) }}}\n= \\underset{\\text{(b)}}{\\underbrace{\\sum_{\\mathbb{A}}P\\left ( y_{l},\\mathbb{A}\\mid x_{n+1}   \\right )}}\n=\\underset{\\text{(c)}}{\\underbrace{\n    \\sum_{\\mathbb{A}}\\left (P\\left ( y_{l}\\mid \\mathbb{A} \\right )\n\\cdot P(\\mathbb{A}\\mid x_{n+1}) \\right )}}\n=\\underset{\\text{(d)}}{\\underbrace{\n    \\sum_{\\mathbb{A}}\\left (\\frac{ {\\textstyle \\sum_{k=1}^{n}\\left ( \n    {\\color{Red} P(y_{l}\\mid x_{k})}\\cdot  P(\\mathbb{A}\\mid x_{k}) \\right ) } } {{\\textstyle \\sum_{k=1}^{n}P(\\mathbb{A}\\mid x_{k})  } }\n\\cdot P(\\mathbb{A}\\mid x_{n+1}) \\right )}}\n= \\underset{\\text{(e)}}{\\underbrace{\\text{Eq. (15)}}}\n$$\n\nFrom (a) to (b): marginalization.  \nFrom (b) to (c): candidate axiom 3.  \nFrom (c) to (d): candidate axiom 2.  \nFrom (d) to (e): candidate axiom 1.\n \nWhere superscript $\\mathbb{A}$ serves only as an indicator to distinguish the two red terms. For continuous random variables, we change $\\sum_{\\mathbb{A}}$ to $\\int_{\\mathbb{z}}$.\n\nAs you have mentioned, if the auxiliary (or latent) random variables $\\mathbb{A}$ is eliminated through marginalization, the system loses observer independence. On the other hand, if we do not eliminate it, the current probability theory stops at step (b). (Of course, approximation methods or analytical solutions for special datasets can handle it further.)\n\n**Q3**: a situation where all randomness in the world is governed by an abstract space $\\Theta$, where all randomness is lost if the abstract space is determined at a point $\\theta \\in \\Theta$ , and where all variables can be described deterministically.\n\nA3: We like your point and also such kind of high-level discussion. However, we are concerned that the point may have problem at the microscopic level according to 'quantum uncertainty'.  \n\nOur further opinion is that the world can be very good predicted if we have sufficient multivariate latent variables $\\mathbb{A}$ (or $\\mathbb{z}$).\nThis can be expressed as:\n$$P^{\\mathbb{A}}\\left ( Y\\mid x_{n+1}   \\right ) $$\n\nWhere $\\mathbb{A}$ is latent variables and $Y$ is our interested variables. By utilizing a sufficient number of historical observations of $\\mathbb{A}$ adn $Y$, we can use this equation to make a prediction. Although this calculation is very complex, it is of polynomial complexity rather than exponential. Additionally,  this theory can be applied to time series forecasting.\n\n**Q4**: In the abstract space, random variables are represented as a projection of the world as a map to an object, e.g. $Y(\\theta),X(\\theta),A(\\theta)$, can be uniquely determined for a given source $\\theta$.\n\nA4: Firstly, $X$ is a very special random variable, conditioning on $X$ is only used to indicate which random experiment is being referred to.\nWe'd like to express the probability space as abstract variables $\\mathbb{A}$ (or $\\mathbb{z}$) and $Y$, and $P_{\\theta}(\\mathbb{A}|x_{k})$ and $P_{\\theta}(Y|x_{k})$ can be uniquely determined for a given source $\\theta$.\nOur applications of IPNN, CIPNN and CIPAE serve as good illustrations of this point.\n\n**Q5**: Not your question but you may have interest. Why the auxillary observers are general?\n\nA5: The world is understood through observers. In the case of a coin toss, the outcome cannot be known unless observed. That is, the ground truth is not able to be known, we only know the observations.\n\nGiven that the use of observers is unavoidable, and the imperfect observations maybe more general in the real world? (Perfect observations are the special case.)\n\nAdditionally, we do not need to restrict the observers, as they may have different ways of understanding the world. For example, in our coin toss example in Appendix B, Observer$_3$ understands the outcome as a Gaussian distribution.\n\nThe questions now is: what truly matters?\n\nThe Change! While different observers may have different understandings of the world, the Change still follows the Ground Truth (albeit with some errors). Our proposed equation is designed to evaluate this Change.\n\n\n\nFinally, we are willing to have more discussion with you and look forward to your feedback.\n\n\nBest regards\n\nAuthors"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4295/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700184262695,
                "cdate": 1700184262695,
                "tmdate": 1700184262695,
                "mdate": 1700184262695,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3oBhNK2KHw",
                "forum": "sSWGqY2qNJ",
                "replyto": "S2VJ9dHnMI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4295/Reviewer_MWjN"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4295/Reviewer_MWjN"
                ],
                "content": {
                    "title": {
                        "value": "A quick thank you for authors' response"
                    },
                    "comment": {
                        "value": "I appreciate the authors' very enlightening response. I am getting a much more correct understanding of the value of this paper thanks to the authors' response. In particular, A2 is very clear in its phrasing, which expresses the new ideas of this paper in a straightforward manner, and A5 does a good job of explaining the novelty of the paper conceptually.\n\nI believe I should raise my rating for this paper. To that end, I would like to take some time this weekend to read the paper again. I am contacting the authors first only to thank you, to let you know that I have indeed received and read the authors' response."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4295/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700193384747,
                "cdate": 1700193384747,
                "tmdate": 1700193384747,
                "mdate": 1700193384747,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "K6o4KTk8ss",
                "forum": "sSWGqY2qNJ",
                "replyto": "lqWYzZAPnw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4295/Reviewer_MWjN"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4295/Reviewer_MWjN"
                ],
                "content": {
                    "title": {
                        "value": "Update after rereading the manuscript"
                    },
                    "comment": {
                        "value": "I have once again read the paper over with reference to the author's response and the comments of the other reviewers. Once again, I thank the authors for their kind responses and the reviewers for their important comments.\n\nIn conclusion, my thoughts on this paper have been updated as follows:\n- *Does this paper offer new and interesting ideas?*\n\nWithout a doubt. I am convinced that this paper provides a new outlook and perspective on how to handle posterior probabilities. I think the ideas are worth sharing with the community and discussing often.\n- *Does this paper build a new probability theory?*\n\nI believe that the manuscript, at least in its current form, is inadequate as a systematic theory and has room for major improvement.\n\nThese impressions are due to my subjective perceptions as follows:\n- Ideas are easy to understand when they are explained using concrete examples or special cases.\n- On the other hand, I expect that a theory should be a generalization of a core idea.\n\nFrom this point of view, I think this paper is a very important contribution in explaining that new idea. So, is there sufficient generality to make it a new theory compared to the long-established probability theory (which is a very general theory with a very high degree of freedom)? I am unable to read sufficient generality into the manuscript at this time.\nOne important example, as other reviewers have pointed out, is whether the author's idea would work successfully in a measure-theoretic probability theory where classical (fractional form) conditioning does not work (a situation where conditioning is expressed by conditional expectation). If it works, does it require any new assumptions other than axioms 1-3? Another example (again, an extension of the measure-theoretic probability perspective) is whether it can be defined using an abstract probability space, as in my first comment.\nIf this paper provides a sufficiently generalized theory, one would expect to find these simple questions resolved, for example. These are only a few examples, and I suspect that the actual theory would require an enormous amount of work (especially if the opponent is probability theory, which has a long history).\n\nIn summary, I expect that it would be very useful for the community to narrow the scope of this paper and present it with the granularity of new ideas, perspectives, and prospects. On the other hand, if this paper is presented as an innovative theory-building paper, I suspect that it will need to be generalized and comprehensive. And if the latter is the place to present an innovative theory-building paper, I think a journal with more mathematicians, statisticians, and theorists than a major machine learning conference would be more appropriate.\n\nOnce again, I would like to thank the authors for sharing their great ideas and for their thoughtful responses. I hope this research is published where it deserves to be and that many more people will learn of its importance in the near future."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4295/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700388513445,
                "cdate": 1700388513445,
                "tmdate": 1700388513445,
                "mdate": 1700388513445,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]