[
    {
        "title": "Gradual Optimization Learning for Conformational Energy Minimization"
    },
    {
        "review": {
            "id": "23OgQ8yqRK",
            "forum": "FMMF1a9ifL",
            "replyto": "FMMF1a9ifL",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9224/Reviewer_RbRE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9224/Reviewer_RbRE"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose an active learning approach to train neural network potentials by employing a cheap surrogate oracle before querying the much more expensive genuine oracle."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is very well written with clear insight and motivation. The method is very neat and the results are promising. I am excited to see more work that follows these mixed genuine and surrogate oracle approach."
                },
                "weaknesses": {
                    "value": "Additional baselines and metrics could make the result stronger.\n\nIn terms of the baseline, the true innovation of the framework is the \"active learning\" component, and not \"conformer generation\" itself. Therefore, the baseline conversation probably should focus on other active learning approaches such as Kulichenko et al (2023) or Chem et al. (2019). While these methods require OG, the author can still compare to these methods by contrasting the OG query budget to the same amount, but use random selection instead of SG estimates as proposed by GOLF. The comparison to TD/ConfOpt, while interesting, the problem setup and training data requirement are very different from what the authors are trying to demonstrate here.\n\nIn terms of the metrics, it would be very helpful if the authors can provide more context about why \"percentage of minimized energy\" is a meaningful metric, and why >98% is considered solving the optimization. If >98% is broadly considered as solving the optimization, can the authors report what percentage of targets in the test set is \"solved\" under different experiment setup?"
                },
                "questions": {
                    "value": "I would consider raising my score if the authors can address my concerns around baselines and metrics as mentioned in the Weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9224/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9224/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9224/Reviewer_RbRE"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9224/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698806276584,
            "cdate": 1698806276584,
            "tmdate": 1699637160818,
            "mdate": 1699637160818,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "E9EXk3HuNC",
                "forum": "FMMF1a9ifL",
                "replyto": "23OgQ8yqRK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9224/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9224/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "- **Weakness 1**\n\n> In terms of the baseline, the true innovation of the framework is the \"active learning\" component, and not \"conformer generation\" itself. Therefore, the baseline conversation probably should focus on other active learning approaches such as Kulichenko et al (2023) or Chem et al. (2019). While these methods require OG, the author can still compare to these methods by contrasting the OG query budget to the same amount, but use random selection instead of SG estimates as proposed by GOLF.\n\nThe method (UDD) presented in Kulichenko et al. (2023) is designed for the exploration of the configuration space of a\u00a0**single**\u00a0molecule. The method generates new data by running molecular dynamics from a set of initial conformations. To better explore the space, the energy in molecular dynamics is augmented with a $E_{\\text{bias}}$ term that encourages the MD to sample conformations from regions of configuration space where the ensemble of NNPs is uncertain. In theory, this approach may also improve the atomic forces prediction, which would help the solution of the optimization task, but it remains to be studied. However, the UDD requires training a new NNP ensemble for each new molecule, which is a completely different problem setup compared with the one in our study. While it is an interesting task to adjust the UDD for the multi-molecule setup, we believe it is out of the scope of the current study.\n\nIf we understood you correctly, by Chem et al.(2019) you meant Chan et al. (2019) - \"Bayesian optimization for conformer generation\". While interesting, this approach requires DFT calculations during the inference, whereas GOLF only interacts with the oracle during the training phase and thus is more efficient.\n\n- **Weakness 2**\n\n> The comparison to TD/ConfOpt, while interesting, the problem setup and training data requirement are very different from what the authors are trying to demonstrate here.\n\nWe agree that the generative setting is sufficiently different from the iterative optimization one. However, it is possible to formulate the problem of finding optimal geometries as a generative task. If it is possible to generate optimal geometries directly (e.g., without further relaxation), our framework would be superfluous. Contrary to this, our experiments show that it is still unclear if the generative models can achieve comparable performance.\n\n- **Weakness 3**\n\n> In terms of the metrics, it would be very helpful if the authors can provide more context about why \"percentage of minimized energy\" is a meaningful metric, and why >98% is considered solving the optimization. If >98% is broadly considered as solving the optimization, can the authors report what percentage of targets in the test set is \"solved\" under different experiment setup?\n\nThank you very much for pointing this out! Generally accepted chemical precision is 1 kcal/mol [1]. The average total optimized energy is 43.2 kcal/mol therefore 2% is about the chemical precision. We removed the \"2%\" from the manuscript as it is indeed more correct to reason about being \u201c*on par*\u201d with the optimizer in terms of chemical precision. Following your suggestion, we decided to add the percentage of \u201csolved\u201d conformations (we call it $\\operatorname{pct}\\_{\\text{solved}}$) as one of the metrics for all the experiments. We found that it helps to better demonstrate the superiority of the GOLF compared to the baseline approaches.\n\n[1] Helgaker, T., Ruden, T. A., J\u00f8rgensen, P., Olsen, J., & Klopper, W. (2004). A priori calculation of molecular properties to chemical accuracy.\u00a0*Journal of Physical Organic Chemistry*,\u00a0*17*(11), 913-933."
                    },
                    "title": {
                        "value": "Answer to Official Review of Submission9224 by Reviewer RbRE"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9224/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700733942096,
                "cdate": 1700733942096,
                "tmdate": 1700740351456,
                "mdate": 1700740351456,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Be7tgWcJ1A",
            "forum": "FMMF1a9ifL",
            "replyto": "FMMF1a9ifL",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9224/Reviewer_HQch"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9224/Reviewer_HQch"
            ],
            "content": {
                "summary": {
                    "value": "In the paper, the authors present Gradual Optimization Learning Framework (GOLF), a framework for improving the efficiency of generating low-energy molecular conformation prediction models, a crucial technology used in computer-aided drug discovery and materials design.\n\nOverall, the paper is well written and presents some valuable insights into applying active learning efficiently for the discovery of energy minimized conformations. Traditional approaches, such as Density-functional theory (DFT) models, use high-fidelity physics-based numerical quantum chemistry simulators whose computational costs are exponential with respect to the complexity of the molecule under study. Unfortunately, this limits their applicability to simple molecules with few atoms or electrons. To address computational complexity and to scale conformal optimization to more complex molecules, researchers have explored various alternatives based on lower fidelity linear models and, more recently, neural network models that leverage the availability of computed quantum property molecular databases. Sadly, these alternate approaches lead to inaccurate predictions and suffer from distribution shift. To scale conformal energy prediction to larger molecules while addressing computational cost, the authors propose GOLF, an automated data augmentation scheme and a hybrid computational approach that combines the use of both high and low-fidelity simulators as well as neural networks.\n\nIn Section 1, the authors present the concept of low-energy molecular conformations and their uses. This section is well written and provides an adequate background of the approach and the insights that motivate the solution. The authors indicate that the fundamental problem with traditional approaches, such as DFT, to obtain optimal conformations is their high computational cost. These approaches, which are based on numerical quantum chemistry simulations that calculate anti-gradients representing molecular forces, are iterative by nature and, when given a sufficiently complex molecule or physical system, may fail to complete even a single iteration. For this reason, the authors claim that \u201creducing the number of interactions with the physical simulator\u201d is crucial for efficiency. The authors then go on to describe current methods that apply Neural Network Potentials (NNP), a form of deep neural networks, to the problem. NNP-based techniques significantly reduce computational complexity by using the gradients inherent to neural networks to model the molecular forces, thereby obviating the need for expensive simulations. Unfortunately, the NNP approach suffers from distribution shift resulting in inaccurate predictions. The authors then introduce GOLF, which employs a data augmentation active learning scheme to improve the diversity of the training dataset, thereby alleviating the distribution shift. By doing so, GOLF achieves energy minimized conformation prediction accuracy comparable with that of high-fidelity simulations while retaining the intrinsic efficiencies gained by using neural networks. A novel framework for data-efficient training of NNPs, GOLF comprises three components: 1) a computationally expensive high-fidelity simulation that is a genuine oracle (GO) used to calculate the ground truth energies and forces; 2) an optimizer that uses the NNP gradients to produce optimization trajectories that constitute the additional training dataset; and 3) a computationally inexpensive low-fidelity simulation that is a surrogate oracle (SO) used to augment the training dataset. Finally, the authors then conclude this section by summarizing their contributions.\n\nHowever, there are various weaknesses in this section as well that can be addressed to improve the quality of the paper. 1) The statement that \u201creducing the number of interactions with the physical simulator\u201d is unclear and the reviewer assumes the efficiency objective is attained by reducing the number of iterations required to produce optimal low-energy conformations. 2) The authors state that they augment the dataset with \u201coptimization trajectories\u201d without explaining what such a trajectory is and how the trajectories address distribution shift. At a minimum, providing a reference to the discussion of augmented data in Section 5 would be useful. 3) Moreover, as GOLF requires running the high-fidelity simulation, GO, to produce the anti-gradients, it is unclear whether GOLF can be successful when GO fails to complete a single iteration. This is a serious flaw in the paper and needs to be addressed. 4) In addition, the \u201cAb initio property\u201d phrase is used without a definition or description and seems rather superfluous to the narrative. 5) The adequacy of the requirement for 5 X 105  \u201cadditional oracle interactions\u201d, which presumably means optimization trajectories that augment the training dataset, is likely anecdotal based on the molecules selected for the experiments. If that is not the case, an explanation of why it is generally applicable should be articulated.\n\nIn the \u201cRelated Works\u201d section (Section 2), the authors describe a variety of contemporary approaches to conformation generation. The benefits and drawbacks of these methods are discussed. However, it is not clear to the reviewer how GOLF addresses the drawbacks of these approaches. Successfully addressing the drawbacks could demonstrate GOLF\u2019s superiority. Also, form the exposition in this section, it is not clear how significantly different the GOLF approach is to the active learning technique presented by Kulichecnko et al. (2023). Finally, the phrase \u201cwe believe it is necessary to explore further the ability \u2026\u201d is confusing. Are the authors proposing future work or teeing up the discussion in the remainder of the paper?\n\nIn the \u201cNotations and Preliminaries\u201d section (Section 3), the authors summarize the theoretical foundation of their approach. Although informative, the notation is somewhat cryptic and can benefit from slightly greater verbosity or additional graphics. Also, mentioning GOLF models in this section, without any discussion as to what they are or how they differ from ftraj, seems premature and confusing. At the very least, there should be a forward reference to Section 5 that articulates how GOLF intelligently identifies the datasets that promote diversity, which enhances prediction performance. Moreover, a small discussion of the NNP architecture used in the experimentation would be useful for the sake of completeness.\n\nSection 4 presents \u201cConformation Optimization\u201d. This section is well written and the both the graphic, Figure 1, and the table, Table 1, provide valuable insight. The Figure 1 graphic clearly depicts the distribution shift, in terns of Mean Square Error (MSE), increasing as the optimization progresses. The graphic also depicts that the prediction accuracy improves \u2013 MSE decreases \u2013 when augmenting the training dataset with GO produced optimization trajectories. This is an important result but without highlighting it, the reader can easily miss that it is one of the contributions of the paper. Table 1 seems to be highlighting precision of the approach, but the word is not used in the discussion. It is unclear to the reviewer as to the innovativeness of the approach, which may be construed as a weakness. Moreover, using the GO to provide the baseline training dataset may limit the scalability of the approach.\n\nThe authors present a sound argument in Section 5 where they present the GOLF algorithm and discuss using a high-performance low-cost surrogate oracle to make the data generation computationally tractable. The \u201cExperiments\u201d section, Section 6 is reasonably complete though much of the discussion seems anecdotal. The reviewer is unable to determine how many of the experimental results were achieved through a fortuitous selection of the molecules under study. Also, the authors report that the GOLF technique can produce \u201ca high percentage of diverged conformations\u201d. This is not surprising as the training dataset is likely to be much noisier as a result of the choice to use a low-cost simulation. It would be nice to get better characterization of the noise and its effects, including the loss in efficiency resulting from these unusable conformations.\n\nSections 7, 8, and Appendices conclude the paper. An explicit tie back to the goals and contributions identified in the Introduction would be beneficial."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Overall, the paper is well written and informative. It seems relevant to improving the computational tractability of conformational energy minimization. The insight to use active learning to address the distribution shift and improve accuracy is valuable. Also, the approach to active learning by using low-cost simulation to augment the training data set without impacting the quality of the subsequent model is somewhat innovative."
                },
                "weaknesses": {
                    "value": "The various weaknesses are already detailed above. Here I summarize the most important ones. Using GO to generate the baseline dataset may limit the scalability of the approach. It is unclear why the authors do not use the molecular databases they mention in the \u201cIntroduction\u201d section to extract the baseline dataset. Some of the discussion is somewhat cryptic and can benefit from some additional discussion or graphics. The results seem anecdotal, tied to the selected dataset and molecules, and thus may not generalize particularly well."
                },
                "questions": {
                    "value": "Suggestions:\n1) Clean up the use of \"interactions with the physical simulator\" and the \"number of iterations\" in several locations in the paper. They seem to imply the same concept. If they are, just use a single phrase for both.\n2) Additional references early on in the paper to the results later on in the paper will help the reader question many of the seemingly unsupported statements.\n3) A better tie-in to how GOLF addresses the drawbacks of the \"Related Works\" section will improve the quality of  the paper.\n4) Reduce the amount of mathematical notation in the \u201cNotations and Preliminaries\u201d section (Section 3) to simplify the narrative and improve understandability.\n5) The main result in Section 4, the decrease in MSE by augmenting the dataset, should be highlighted and tied-in to the wording of the contributions listed in the introduction section of the paper.\n\nQuestions:\n1) GOLF requires running the high-fidelity simulation, GO, to produce the anti-gradients initial training data. In a different section of the paper, the claim is that for a sufficiently complex system, the physical simulation may not succeed in completing even a single iteration in a reasonable amount of time. Taken together, these two statements seem to suggest that GOLF is atomic complexity scale limited. How do the authors claim to address this apparent limitation?\n2) In the Experiments section (Section 6), how much of the results are related to the selection of the molecules under study? Stated differently, how do the authors plan to address the generalizability of the approach?\n3) The additional data generated for Active Learning are selected based only on errors. Without some sort of approach to balance the introduction of new data, does the approach bias the dataset distribution causing the learned distribution to fail to generalize to other molecules?\n4) How different is the GOLF approach from the active learning technique presented by Kulichecnko et al. (2023)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9224/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9224/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9224/Reviewer_HQch"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9224/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698807888969,
            "cdate": 1698807888969,
            "tmdate": 1699637160701,
            "mdate": 1699637160701,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "W1pF4L5BZd",
                "forum": "FMMF1a9ifL",
                "replyto": "Be7tgWcJ1A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9224/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9224/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to Official Review of Submission9224 by Reviewer HQch (1/4)"
                    },
                    "comment": {
                        "value": "We appreciate your suggestions on improving the writing of the introduction. We found them very useful and incorporated the proposed modifications in the revised manuscript. We summarize the changes below:\n\n## Introduction\n\n> The statement that \u201creducing the number of interactions with the physical simulator\u201d is unclear\n> \n\nWe replaced this sentence with the following: \u201cTherefore, it is crucial to develope alternative approaches (such as Neural Networks-based) that reduce the computational complexity of iterative optimization.\u201d\n\n> The authors state that they augment the dataset with \u201coptimization trajectories\u201d without explaining what such a trajectory is and how the trajectories address distribution shift.\n> \n\nWe added a reference to Section 4.\n\n> Moreover, as GOLF requires running the high-fidelity simulation, GO, to produce the anti-gradients, it is unclear whether GOLF can be successful when GO fails to complete a single iteration.\n> \n\nWe reworked this sentence: \u201cHowever, for large molecules even a single iteration may take up several hours of CPU-compute.\u201c\n\nConsidering your question, refer to the answer to Question 1.\n\n> In addition, the \u201cAb initio property\u201d phrase is used without a definition or description and seems rather superfluous to the narrative.\n> \n\n\u201c*Ab initio*\u201d is a latin term that means \u201cfrom first principles\u201d. It is widely used in quantum chemistry literature implying that the only inputs into an\u00a0*ab initio*\u00a0calculation are\u00a0physical constants.\n\n> The adequacy of the requirement for $5 \\times 10^5$ \u201cadditional oracle interactions\u201d, which presumably means optimization trajectories that augment the training dataset, is likely anecdotal based on the molecules selected for the experiments. If that is not the case, an explanation of why it is generally applicable should be articulated.\n\nWe agree that this constant may not hold on another dataset. However, we believe that the reduction in the amount of required oracle interactions will still be significant. We decided to remove $5 \\times 10^5$ from the abstract and the intro, replacing it with a more appropriate statement.\n\n## Notation and preliminaries\n\n> The notation is somewhat cryptic and can benefit from slightly greater verbosity or additional graphics.\n\nWe reworked the notation in the revised version of the manuscript.\n\n> Also, mentioning GOLF models in this section, without any discussion as to what they are or how they differ from ftraj, seems premature and confusing.\n\nWe added a reference to Section 5.\n\n> Moreover, a small discussion of the NNP architecture used in the experimentation would be useful for the sake of completeness.\n\nWe listed all the hyperparameters in Appendix.\n\n## Conformation Optimization with NNPs\n\n> This is an important result but without highlighting it, the reader can easily miss that it is one of the contributions of the paper.\n\nWe referenced Figure 1 in the contributions section.\n\n> It is unclear to the reviewer as to the innovativeness of the approach, which may be construed as a weakness. Moreover, using the GO to provide the baseline training dataset may limit the scalability of the approach.\n\nWhile working on the topic of molecular optimization, we found that this area is severely under-researched. To the best of our knowledge, there are no papers that present the idea of enriching the training dataset with optimization trajectories. However, in this year Open Catalyst challenge [https://opencatalystproject.org/challenge.html], a similar dataset of optimization trajectories for adsorbate-catalyst pairs has been published. We will cite the OCP23 challenge in the revision."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9224/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700738848350,
                "cdate": 1700738848350,
                "tmdate": 1700739316009,
                "mdate": 1700739316009,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "texfaWRGz1",
                "forum": "FMMF1a9ifL",
                "replyto": "Be7tgWcJ1A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9224/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9224/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to Official Review of Submission9224 by Reviewer HQch (2/4)"
                    },
                    "comment": {
                        "value": "## Experiments\n\n> The \u201cExperiments\u201d section, Section 6 is reasonably complete though much of the discussion seems anecdotal. The reviewer is unable to determine how many of the experimental results were achieved through a fortuitous selection of the molecules under study.\n\nIn our experiments, we use a randomly selected subset $\\mathcal{D}_0$ of the nablaDFT dataset. The conformations in the nabla DFT dataset are generated based on SMILES representations of molecules from the MOSES dataset. The MOSES dataset consists of a large number of druglike molecules and is considered to be representative.  To ensure reasonable computational cost of DFT computations, the subset  $\\mathcal{D}_0$ is limited to molecules with number of atoms < 36. However, apart from the increased computational cost we do not forsee any issues with using GOLF with bigger molecules.\n\nTherefore we significantly extended the main evaluation dataset (10x) by sampling more conformations with less than 35 atoms from the nablaDFT dataset. The extended evaluation dataset contains 20k conformations for X molecules. It contains  $\\mathcal{D}\\_{\\text{test}}$ as its subset.\nMoreover, we selected 1828 molecules (1 conformation per molecule) from the SPICE dataset, optimized them with $\\mathcal{O}\\_G$ to get the optimal energy. We evaluated all non-generative models from our paper on this new SPICE test set $\\mathcal{D}\\_{\\text{test}}^{\\text{SPICE}}$.\nWe provide the results in the table below. We understand that the size of the $\\mathcal{D}\\_{\\text{test}}^{\\text{SPICE}}$ may raise similar concerns, but we were unable to collect a larger dataset during the rebuttal due to the need for an expensive $\\mathcal{O}\\_G$ optimizations. We will extend the $\\mathcal{D}\\_{\\text{test}}^{\\text{SPICE}}$ to ~20k conformations and provide results for generative models in the camera-ready version.\n\n### SPICE test (1828 conformations)\n|  | OpenFF | RDKit | $f^{baseline}$ | $f^{traj-10k}$ | $f^{traj-100k}$ | $f^{traj-500k}$ | $f^{GOLF-1k}$ | $f^{GOLF-10k}$ | $SPICE-f^{baseline}$ | $SPICE-f^{GOLF-10k}$ |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| $\\overline{\\operatorname{pct}}\\_{100}$ | 61.14 | 77.58 | 72.71 | 73.22 | 77.06 | 80.25 | 80.31 | 82.41 | 79.76 | 86.59 |\n| $\\operatorname{pct}\\_{\\text{div}}$ | 5.38 | 8.15 | 27.73 | 17.45 | 16.02 | 12.80 | 13.56 | 12.41 | 23.08 | 15.09 |\n| $\\overline{E^{\\text{res}}\\_{100}}$ | 12.58 | 8.42 | 13.62 | 9.63 | 8.09 | 6.88 | 6.63 | 6.06 | 6.06 | 4.19 |\n| $\\operatorname{pct}\\_{\\text{solved}}$ | 0.05 | 10.72 | 6.35 | 5.17 | 15.90 | 25.65 | 17.53 | 27.73 | 8.91 | 19.41 |\n\nThe OpenFF is a non-neural force field used in the original SPICE paper [1]. $SPICE-f^{baseline}$ was trained on ~10000 conformations (2.5 conformations per molecule) from the SPICE dataset. $SPICE-f^{GOLF-10k}$ was trained with the same hyperparameters as $f^{GOLF-10k}$ and used $SPICE-f^{baseline}$ to initialize the NNP. These preliminary results show that models trained on nablaDFT and SPICE datasets demonstrate comparable performance on $\\mathcal{D}\\_{\\text{test}}^{\\text{SPICE}}$. \n\n### Extended test (19477 conformations)\n\n|  | RDKit | $f^{baseline}$ | $f^{rdkit}$ | $f^{traj-10k}$ | $f^{traj-100k}$ | $f^{traj-500k}$ | $f^{GOLF-10k}$ |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n| $\\overline{\\operatorname{pct}}\\_{100}$ | 85.47 | 77.88 | 93.04 | 95.08 | 96.15 | 98.75 | 98.78 |\n| $\\operatorname{pct}\\_{\\text{div}}$ | 0.62 | 7.46 | 4.43 | 4.50 | 2.77 | 1.99 | 2.98 |\n| $\\overline{E^{\\text{res}}\\_{100}}$ | 5.50 | 8.58 | 2.77 | 1.96 | 1.50 | 0.53 | 0.51 |\n|  $\\operatorname{pct}\\_{\\text{solved}}$ | 4.05 | 8.18 | 35.42 | 37.01 | 52.71 | 73.41 | 77.26 |\n\nThese results show that all conclusions made in the first version of the paper hold on an extended evaluation dataset.\n\n[1] Eastman, P., Behara, P. K., Dotson, D. L., Galvelis, R., Herr, J. E., Horton, J. T., ... & Markland, T. E. (2023). Spice, a dataset of drug-like molecules and peptides for training machine learning potentials. Scientific Data, 10(1), 11."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9224/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700739028912,
                "cdate": 1700739028912,
                "tmdate": 1700739307039,
                "mdate": 1700739307039,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5S0NadmiT2",
                "forum": "FMMF1a9ifL",
                "replyto": "Be7tgWcJ1A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9224/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9224/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to Official Review of Submission9224 by Reviewer HQch (3/4)"
                    },
                    "comment": {
                        "value": "> Also, the authors report that the GOLF technique can produce \u201ca high percentage of diverged conformations\u201d. This is not surprising as the training dataset is likely to be much noisier as a result of the choice to use a low-cost simulation. It would be nice to get better characterization of the noise and its effects, including the loss in efficiency resulting from these unusable conformations.\n> \n\nFirst, we would like to stress that we do not use the low-cost simulation neither to estimate energies/forces for the newly collected data, nor to generate conformations for training. To estimate energies and forces, we use DFT. Additional conformations for training are generated during the optimization with the NNP. The low-cost simuator is used to select a single conformation from the optimization trajectory. This selected conformation is then evaluated with the DFT-based oracle and added to the training set.\n\nSecond, the \u201chigh percentage of diverged conformations\u201d refers to the experiment in Section 6.4 (applying NNP trained with GOLF  to larger molecules than in the training dataset). In our code, the optimization is considered diverged either when the initial energy is lower than the final energy or when the DFT-worker is timed out. For small molecules in $\\mathcal{D}_0, \\mathcal{D}_{\\text{test}}$ this happens when the resulting conformation is poor, but we found that for larger molecules this can also happen with reasonable near-optimal conformations. We also found that increasing the timeout value solves this problem (see updated table in section 6.4). \n\nWe extended the $\\mathcal{D}_{\\text{LM}}$ to 2000 molecules (1 conformation per molecule) and re-evaluated NNPs with the increased timeout value. We updated section 6.4 in the revision. As it can be seen from the updated Table 3, $f^{\\text{GOLF-10k}}$ on large molecules experiences a small performance drop, while retaining the same percentage of diverged optimizations.\n\n## Weaknesses\n\n- **Weakness 1**\n\n> Using GO to generate the baseline dataset may limit the scalability of the approach. It is unclear why the authors do not use the molecular databases they mention in the \u201cIntroduction\u201d section to extract the baseline dataset.\n\nFirst, the limited scalability of this approach is stated as the main motivation for our proposed GOLF framework. Second, we would like to note that we are not aware of any molecular databases that contain optimization trajectories. In our paper, we identify enriching the training dataset $\\mathcal{D}_0$ with optimization trajectories as a crucial step to overcome the distribution shift. In Figure 1, we illustrate that enriching the training dataset with optimization trajectories helps alliviate the distribution shift. We agree, that in theory, datasets containing both near-optimal and sub-optimal conformations can be used to improve the optimization quality of NNPs. To test that, we trained a baseline model $\\operatorname{SPICE}-f^{\\text{baseline}}$ on a subset of SPICE dataset and showed that it suffers from the similar issues (see answer to \u201cExperiments\u201d section).\n\n- **Weakness 2**\n\n> Some of the discussion is somewhat cryptic and can benefit from some additional discussion or graphics.\n\nWe appreciate your suggestions on improving the writing of our paper! Following various ideas proposed by the reviewers we have reworked the manuscript and uploaded a corrected version as a revision. If you still have any concerns or suggestions, please let us know. We will be happy to improve the writing further.\n\n- **Weakness 3**\n\n> The results seem anecdotal, tied to the selected dataset and molecules, and thus may not generalize particularly well \n\nIn order to resolve this concern, we decided to provide additional experiments both on a bigger subset of nablaDFT dataset and a subset of SPICE dataset. See answer to \u201cExperiments\u201d section for more details."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9224/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700739167157,
                "cdate": 1700739167157,
                "tmdate": 1700739275368,
                "mdate": 1700739275368,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7fDXHfPUSM",
            "forum": "FMMF1a9ifL",
            "replyto": "FMMF1a9ifL",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9224/Reviewer_bemc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9224/Reviewer_bemc"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a gradual optimization learning framework (GOLF) for molecular conformation minimization. The framework is designed to improve the training of Neural Network Potentials (NNP). The authors first claim that NNPs trained on existing datasets suboptimal in energy minimization due to the distribution shift and perform experiments to show (a large amount of) additional data from the optimization trajectories can help improve the NNP's performance.  The GOLF framework uses a surrogate oracle (MMFF) to evaluate the conformation energy and expand the training data by selecting the incorrect prediction and re-evaluating with the genuine oracle (DFT), which reduces the required additional data. The experiments on the nablaDFT dataset demonstrate the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The proposed method sounds reasonable and the experiments shows its effectiveness.  The method also looks easy to implement, which can improve the conformation energy minimization performance at a small cost."
                },
                "weaknesses": {
                    "value": "- The writing is not very clear, especially in the introduction section. It takes me a while to understand simply enriching the training dataset is actually a preliminary baseline method the authors want to compare with. Also, lots of experiment details are mixed with the method, which makes the paper not very easy to read. \n- The calculation of COV and MAT looks problematic. It seems the authors optimize **one conformation per molecule** and take them of the entire test set as the generation set. However, in the conformation generation setting, models generate **multiple conformations per molecule** to construct the generation set, and then COV and MAT are calculated per molecule,  and finally the average / median of them on the entire test set is reported."
                },
                "questions": {
                    "value": "- Are the conformations in nablaDFT dataset equilibrium ones or the intermediate state sampled from the optimization process? How large is the training set D0? More description about this dataset is needed. \n- ConfOpt and TorsionDiff are designed to generate equilibrium low-energy conformers, and not guaranteed to achieve a lower energy by repeatedly applied. Thus, I think it's unfair to compare these models with GOLF in terms of pct. \n- The statement of \"We hypothesize that in the case of ConfOpt, the main problems are the choice of the architecture and the fact that the model generates optimal conformations from SMILES and does not use initial geometries. \" doesn't make sense to me. ConfOpt takes the 2D molecular graph as input and also utilizes initial 3D conformations. \n- Does $f^{traj-10k /100k }$ keep the total number of updates equal to $5 \\times 10^5$? If so, please provide more training details, otherwise, the comparison between them and $f^{GOLF}$ is unfair."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9224/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698812513822,
            "cdate": 1698812513822,
            "tmdate": 1699637160597,
            "mdate": 1699637160597,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HYxLJjfF5a",
                "forum": "FMMF1a9ifL",
                "replyto": "7fDXHfPUSM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9224/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9224/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## Weaknesses\n\n- **Weakness 1**\n\n> The writing is not very clear, especially in the introduction section. It takes me a while to understand simply enriching the training dataset is actually a preliminary baseline method the authors want to compare with. Also, lots of experiment details are mixed with the method, which makes the paper not very easy to read.\n\nWe agree that some additional context regarding the use of $f^{\\text{traj-*}}$ as a baseline is needed. We added clarifying sentences in the revision of the manuscript. Unfortunately, we do not see a way to separate the method from some experiment details, as the GOLF is mainly motivated by the empirical results obtained in section 4. We believe that introducing our framework without a preliminary discussion of experimental details and results will be more confusing for the reader. We will be happy to consider any suggestions on improving the writing of the manuscript.\n\n- **Weakness 2**\n\n> The calculation of COV and MAT looks problematic. It seems the authors optimize one conformation per molecule and take them of the entire test set as the generation set. However, in the conformation generation setting, models generate multiple conformations per molecule to construct the generation set, and then COV and MAT are calculated per molecule, and finally the average / median of them on the entire test set is reported.\n\nWe agree that such metrics are indeed not ideal for the conformation optimization task due to the problem you described above. However, we decided to compute these metrics to provide a fair comparison with ConfOpt and Torsional Diffusion, as the main results in these papers are reported in terms of COV and MAT.\n\n## Questions\n\n- **Question 1**\n\n> Are the conformations in nablaDFT dataset equilibrium ones or the intermediate state sampled from the optimization process? How large is the training set D0? More description about this dataset is needed. \n\nThe conformations in the nablaDFT are generated using the following procedure:\n\n1. First, several thousand different conformations per molecule are sampled using Rdkit's ETKG [1] based on a SMILES representation of the molecule.\n2. Second, these conformations are clustered using Butina [2].\n3. The authors then identify the smallest number of clusters needed to cover 95% of generated conformations.\n4. Centroids of these identified clusters are chosen and evaluated with a DFT-based oracle.\n\nThe training dataset contains 4000 molecules and 10000 conformations (~2.5 conformations per molecule). We apologize for not providing this information in the first version of the paper. We added this information in the revision. We also added a brief description of the nablaDFT dataset in the appendix of the revised manuscript.\n\n- **Question 2**\n\n> ConfOpt and TorsionDiff are designed to generate equilibrium low-energy conformers, and not guaranteed to achieve a lower energy by repeatedly applied. Thus, I think it's unfair to compare these models with GOLF in terms of pct.\n\nWe would like to clarify that in our experiments, these models are trained to generate a single optimal conformation from an initial random conformation. We use these models in the intended way and do not repeatedly apply any of them. The training dataset for these models consists of optimal conformations obtained with $\\mathcal{O}_G$ and, thus, we expect them to generate optimal conformations, altough the inference of these models is different to $f^{\\text{GOLF-*}}$, we think it is still valuable to compare the generative approach (ConfOpt, TorsionDiff) with an iterative optimization approach.\n\n- **Question 3**\n\n> The statement of \"We hypothesize that in the case of ConfOpt, the main problems are the choice of the architecture and the fact that the model generates optimal conformations from SMILES and does not use initial geometries. \" doesn't make sense to me. ConfOpt takes the 2D molecular graph as input and also utilizes initial 3D conformations.\n\nWe follow the original implementation [https://github.com/guanjq/confopt_official], which takes the 2D molecular graph, generates a random conformation with Rdkit\u2019s ETKG, and optimizes it with MMFF. This implementation does not provide any means to supply the model with an initial conformation of our choice.\n\n[1] [Wang, S., Witek, J., Landrum, G. A., & Riniker, S. (2020). Improving conformer generation for small rings and macrocycles based on distance geometry and experimental torsional-angle preferences.\u00a0*Journal of chemical information and modeling*,\u00a0*60*(4), 2044-2058.] \n\n[2] Barnard, J. M., & Downs, G. M. (1992). Clustering of chemical structures based on two-dimensional similarity measures.\u00a0*Journal of chemical information and computer sciences*,\u00a0*32*(6), 644-649."
                    },
                    "title": {
                        "value": "Answer to Official Review of Submission9224 by Reviewer bemc (1/2)"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9224/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700735666421,
                "cdate": 1700735666421,
                "tmdate": 1700740145888,
                "mdate": 1700740145888,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "C3U2D8w3Hf",
            "forum": "FMMF1a9ifL",
            "replyto": "FMMF1a9ifL",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9224/Reviewer_DBvP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9224/Reviewer_DBvP"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces GOLF, a framework for improving molecular conformation optimization with neural networks. GOLF addresses distribution shift issues, enhancing energy prediction and optimization. It outperforms traditional methods and reduces the need for physical simulator interactions by 50 times."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The development of the proposed GOLF is clear.\n2. Demonstrated outstanding performance in conformation optimization tasks.\n3. Generalization to larger molecules."
                },
                "weaknesses": {
                    "value": "1. Dataset Limitation: The paper may be limited by the availability and diversity of datasets used for testing, potentially impacting the generalizability of the results.\n2. Complexity: It seems that the complexity of GOLF is not clearly discussed in the paper.\n3. Practical Implementation: Though the algorithm is not very complicated, this paper does not release code, which leaves me cautious about the practical implementation and complexity of the algorithm.\n\nOverall, while the paper presents valuable contributions, addressing these weaknesses could enhance its overall impact and relevance in the field of molecular conformation optimization."
                },
                "questions": {
                    "value": "Same with the 'weaknesses' part:\n1. Why not use more datasets besides nablaDFT?\n2. What's the complexity of GOLF? It seems that you only show experiment results on subsets of nablaDFT. Is it because the computational complexity of the method is very high?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9224/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699164231877,
            "cdate": 1699164231877,
            "tmdate": 1699637160488,
            "mdate": 1699637160488,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fGaDFiShwJ",
                "forum": "FMMF1a9ifL",
                "replyto": "C3U2D8w3Hf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9224/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9224/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to Official Review of Submission9224 by Reviewer DBvP (1/ 2)"
                    },
                    "comment": {
                        "value": "## Weaknesses\n\n- **Weakness 1**\n\n> Dataset Limitation: The paper may be limited by the availability and diversity of datasets used for testing, potentially impacting the generalizability of the results.\n\nWe agree that the experimental section could benefit from a more diverse evaluation dataset. Therefore we significantly extended the main evaluation dataset (10x) by sampling more conformations with less than 35 atoms from the nablaDFT dataset. The extended evaluation dataset contains 20k conformations for X molecules. It contains  $\\mathcal{D}\\_{\\text{test}}$ as its subset.\nMoreover, we selected 1828 molecules (1 conformation per molecule) from the SPICE dataset, optimized them with $\\mathcal{O}\\_G$ to get the optimal energy. We evaluated all non-generative models from our paper on this new SPICE test set $\\mathcal{D}\\_{\\text{test}}^{\\text{SPICE}}$.\nWe provide the results in the table below. We understand that the size of the $\\mathcal{D}\\_{\\text{test}}^{\\text{SPICE}}$ may raise similar concerns, but we were unable to collect a larger dataset during the rebuttal due to the need for an expensive $\\mathcal{O}\\_G$ optimizations. We will extend the $\\mathcal{D}\\_{\\text{test}}^{\\text{SPICE}}$ to ~20k conformations and provide results for generative models in the camera-ready version.\n\n### SPICE test (1828 conformations)\n|  | OpenFF | RDKit | $f^{baseline}$ | $f^{traj-10k}$ | $f^{traj-100k}$ | $f^{traj-500k}$ | $f^{GOLF-1k}$ | $f^{GOLF-10k}$ | $SPICE-f^{baseline}$ | $SPICE-f^{GOLF-10k}$ |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| $\\overline{\\operatorname{pct}}\\_{100}$ | 61.14 | 77.58 | 72.71 | 73.22 | 77.06 | 80.25 | 80.31 | 82.41 | 79.76 | 86.59 |\n| $\\operatorname{pct}\\_{\\text{div}}$ | 5.38 | 8.15 | 27.73 | 17.45 | 16.02 | 12.80 | 13.56 | 12.41 | 23.08 | 15.09 |\n| $\\overline{E^{\\text{res}}\\_{100}}$ | 12.58 | 8.42 | 13.62 | 9.63 | 8.09 | 6.88 | 6.63 | 6.06 | 6.06 | 4.19 |\n| $\\operatorname{pct}\\_{\\text{solved}}$ | 0.05 | 10.72 | 6.35 | 5.17 | 15.90 | 25.65 | 17.53 | 27.73 | 8.91 | 19.41 |\n\nThe OpenFF is a non-neural force field used in the original SPICE paper [1]. $SPICE-f^{baseline}$ was trained on ~10000 conformations (2.5 conformations per molecule) from the SPICE dataset. $SPICE-f^{GOLF-10k}$ was trained with the same hyperparameters as $f^{GOLF-10k}$ and used $SPICE-f^{baseline}$ to initialize the NNP. These preliminary results show that models trained on nablaDFT and SPICE datasets demonstrate comparable performance on $\\mathcal{D}\\_{\\text{test}}^{\\text{SPICE}}$. \n\n### Extended test (19477 conformations)\n\n|  | RDKit | $f^{baseline}$ | $f^{rdkit}$ | $f^{traj-10k}$ | $f^{traj-100k}$ | $f^{traj-500k}$ | $f^{GOLF-10k}$ |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n| $\\overline{\\operatorname{pct}}\\_{100}$ | 85.47 | 77.88 | 93.04 | 95.08 | 96.15 | 98.75 | 98.78 |\n| $\\operatorname{pct}\\_{\\text{div}}$ | 0.62 | 7.46 | 4.43 | 4.50 | 2.77 | 1.99 | 2.98 |\n| $\\overline{E^{\\text{res}}\\_{100}}$ | 5.50 | 8.58 | 2.77 | 1.96 | 1.50 | 0.53 | 0.51 |\n|  $\\operatorname{pct}\\_{\\text{solved}}$ | 4.05 | 8.18 | 35.42 | 37.01 | 52.71 | 73.41 | 77.26 |\n\nThese results show that all conclusions made in the first version of the paper hold on an extended evaluation dataset.\n\n- **Weakness 2**\n\n> Complexity: It seems that the complexity of GOLF is not clearly discussed in the paper.\n\nInference: GOLF uses NNPs that rely on Message Passing [2]. In the worst case, the computational complexity is quadratic in terms of the number of atoms in the molecule. We provide average inference time for baselines and NNPs and compare them with the average $\\mathcal{O}_G$. All the measurements were made on the same machine with a 16-core Intel(R) Xeon(R) Gold 6278C and a single Tesla V100 GPU. The results are in the table below.\n\n| Model | Iterative Optimization with NNP (100 steps) | ConfOpt (single step) | Torsional Diffusion (single step) | UniMol+ (single step) | Iterative Optimization with $\\mathcal{O}_G$ (until convergence, ~25 steps on average) |\n| --- | --- | --- | --- | --- | --- |\n| Average Inference time (seconds) | 1.312 | 0.005 | 0.48 | 0.002 | 2634.787 |\n\nTraining: around 2/3 of the computational complexity during training comes from various NN operations. We use DFT-based oracle, which complexity is $O(N^4)$ [3]. For example, the training of the GOLF-10k on our machine with 120 workers for DFT calculations takes approximately 20 hours .\n\n[1] Eastman, P., Behara, P. K., Dotson, D. L., Galvelis, R., Herr, J. E., Horton, J. T., ... & Markland, T. E. (2023). Spice, a dataset of drug-like molecules and peptides for training machine learning potentials. Scientific Data, 10(1), 11.\n\n[2] Gilmer, J., Schoenholz, S. S., Riley, P. F., Vinyals, O., & Dahl, G. E. (2020). Message passing neural networks.\u00a0*Machine learning meets quantum physics*, 199-214.\n\n[3] Kohn, W., & Sham, L. J. (1965). Self-consistent equations including exchange and correlation effects.\u00a0*Physical review*,\u00a0*140*(4A), A1133."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9224/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700734989184,
                "cdate": 1700734989184,
                "tmdate": 1700738947991,
                "mdate": 1700738947991,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aROx25qVpq",
                "forum": "FMMF1a9ifL",
                "replyto": "C3U2D8w3Hf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9224/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9224/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to Official Review of Submission9224 by Reviewer DBvP (2/ 2)"
                    },
                    "comment": {
                        "value": "## Questions\n\n- **Question 1**\n\n> Why not use more datasets besides nablaDFT?\n\nWe have not considered datasets such as QM9 and GEOM as they contain equilibrium conformations. We have not considered MD17 and other similar datasets due to the low diversity of the molecules.\n\nAdditionally, to answer your first question, we trained the $f^{\\text{baseline}}$ and the $f^{\\text{GOLF-10k}}$ on a subset of SPICE dataset. For the SPICE training set $\\mathcal{D}^{\\text{SPICE}}\\_{\\text{train}}$, we collected 4000 molecules with roughly 2.5 conformations per molecule resulting in approximately 10k conformations (the same size as $\\mathcal{D}\\_{\\text{train}}$). We evaluated these models both on the $\\mathcal{D}\\_{\\text{test}}^{\\text{SPICE}}$ and the extended $\\mathcal{D}\\_{\\text{test}}$. The results are in the table below.\n\n| NablaDFT | $f^{GOLF-10k}$ | $\\operatorname{SPICE}-f^{GOLF-10k}$ |\n| --- | --- | --- |\n| $\\overline{\\operatorname{pct}}_{100}$ | 98.78 | 91.71 |\n| $\\operatorname{pct}_{\\text{div}}$ | 2.98 | 12.69 |\n| $\\overline{E^{\\text{res}}\\_{100}}$ | 0.51 | 3.27 |\n| $\\operatorname{pct}\\_{\\text{solved}}$ | 77.26 | 17.27 |\n\n| SPICE | $f^{GOLF-10k}$ | $\\operatorname{SPICE}-f^{GOLF-10k}$ |\n| --- | --- | --- |\n| $\\overline{\\operatorname{pct}}_{100}$ | 82.41 | 86.59 |\n| $\\operatorname{pct}_{\\text{div}}$ | 12.41 | 15.09 |\n| $\\overline{E^{\\text{res}}\\_{100}}$ | 6.06 | 4.19 |\n| $\\operatorname{pct}\\_{\\text{solved}}$ | 27.73 | 19.41 |\n\nThe main take-away from these tables is that the percentage of optimizations solved is larger for the $f^{\\text{GOLF-10k}}$ trained on NablaDFT. This is likely due to the presence of near-optimal conformations in SPICE which can in theory result in collecting highly correlated training samples.\n\n- **Question 2**\n\n> What's the complexity of GOLF? It seems that you only show experiment results on subsets of nablaDFT. Is it because the computational complexity of the method is very high?\n\nThe high computational complexity of the evaluation procedure is tied to the need to optimize every conformation with $\\mathcal{O}_G$. Estimating the percentage of optimized energy and other reported metrics requires running a minimization procedure with a DFT-based oracle. For example, it takes ~593 CPU days to calculate optimal energies for 19477 conformations in the extended evaluation dataset. While the optimization of 19477 conformation with GOLF-10k takes ~7.1 hours on a single V100 GPU."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9224/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700735464563,
                "cdate": 1700735464563,
                "tmdate": 1700737176139,
                "mdate": 1700737176139,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]