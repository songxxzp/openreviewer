[
    {
        "title": "ConR: Contrastive Regularizer for Deep Imbalanced Regression"
    },
    {
        "review": {
            "id": "s189PXizzW",
            "forum": "RIuevDSK5V",
            "replyto": "RIuevDSK5V",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2927/Reviewer_Yj3F"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2927/Reviewer_Yj3F"
            ],
            "content": {
                "summary": {
                    "value": "For imbalanced regression, the authors propose ConR, which uses\nsupervised contrastive loss as part of the loss function.  They define\nSim(label1,label2) > omega, a threshold hyperparameter, as similar\nlabels.  For each of the input instances, it generates two augmented\ninstances.  If the actual labels of two augmented instances are\nsimilar, they form a positive pair.  If the predicted labels of two\ninstances are similar, but the actual labels are not, they form a\nnegative pair.  For an augmented instance, a set of positive samples\nand a set of negative samples are found.  Augmented instances with at\nleast one negative sample are called anchors, which participate in\ncontrastive loss.  For each anchor, the fraction in the regular\ncontrastive loss is summed over all positive samples.  For the\nnegative samples in the denominator, they have a \"pushing weight\" S,\nwhich is a function of the density-based weight of the anchor and the\nSim(anchor_label, negative_sample_label).  L_conR is an average of the\ncontrastive loss of up to 2N anchors. The overall loss is a weighted\nsum of the regular regression loss and L_conR.\n\nConR was evaluated on 4 datasets, one of which has\nmulti-dimensional labels, and compared with 4 recent techniques.\nEmpirical results indicate adding ConR generally improves performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Imbalanced regression is an interesting problem.\nThe proposed technique adapts supervised contrastive loss from\nclassification to regression.  Particularly, they added a pushing\nfactor for the negative samples based on similarity in labels and density, \nwhich is interesting.  Also, negative samples have not just\ndifferent labels but also similar predictions.  Empirical results\nindicate adding ConR generally improves performance."
                },
                "weaknesses": {
                    "value": "The proposed contrastive loss, Eq 1, could be further explained and\njustified.  Empirical evaluation could be improved by adding \"ConR\nonly\" and representations of RankSim and Balanced MSE, which are more\nrecent techniques.  The similarity threshold omega seems to be an\nimportant parameter, further insights could be explored.\n\nMore details are in questions below."
                },
                "questions": {
                    "value": "1. Eq 1, the outermost summation: Summing over i's implies j's with more\n   positive samples would have more contribution.  Is that desirable?  If so,\n   what is the main reason?\n\n2. L_R is on the original instances, while L_conR is on 2\n   augmentations of each of the original instances.  That is, the\n   original instances are not directly involved in L_conR--is that\n   correct?  If so, what is the main reason?\n\n3. Similarity threshold omega between labels dependent on\n   applications and range of the labels (1-100 vs 1-10^6), any\n   further insights?  It seems to be trial and error as a\n   hyperparameter.\n\n4. How does ConR alone, not inconjunction with another technique,\n   perform?  Including it in Tables 1-3, would be beneficial.\n\n5. How do the representations from Balanced MSE and RankSim, which are\n   more recent, compare with ConR.  Including them in Fig 4 would be\n   important.\n\n6. In Fig 5, why 1/omega, instead of omega, is used?  In the approach\n   section, 1/omega was not discussed. \"Fig. 5b, choosing a higher\n   similarity threshold\"--it seems similarity threshold omega is\n   smaller at 1 (1/omega is higher).\n\n7. p9: Could you further explain: \"sharing feature statistics to an\n   extent that is not in correspondence with the heterogeneous\n   dynamics in the feature space\"?\n\n8. Sec 3.2.1: how are the instances augmented?  It seems to be not\n   discussed in the approach or experiments.\n\nComments:\n\nSec 3.2.2: for completeness, f_S could have more description (it seems\nto be a simple product in the appendix)\n\nminor:\n\nEq 3: 1/2N assumes all 2N augmented instances are anchors, but some\nmight not be anchors (if I understand correctly).\n\nKang et al. 21 and Khosla et al. 20 have duplicated entries in\nReferences."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "n/a"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2927/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697919822760,
            "cdate": 1697919822760,
            "tmdate": 1699636236481,
            "mdate": 1699636236481,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bwbrvwB8n1",
                "forum": "RIuevDSK5V",
                "replyto": "s189PXizzW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Yj3F - part 1"
                    },
                    "comment": {
                        "value": "Thank you very much for your thorough review and insightful feedbacks. Here we address your valuable comments:\n## The outermost summation in Eq. 1\nThank you very much for highlighting this point. In the design of ConR the summation over j\u2019s is divided by the number of positive samples so that for each anchor, the average of contribution of the positive pair is incorporated into ConR. It is mistakenly dropped from Eq. 1, and has been fixed in the updated manuscript.\n## Input augmentations for regression loss and ConR\nWe appreciate your careful examination of the objective functions. Data augmentation is an indispensable component of contrastive learning and also deep visual models because it boosts robustness and generalization by bringing representational invariance to the learned models [1]. Moreover, an essential feature of ConR's design is its inherent ease of integration and orthogonality with the targeted regression baseline for regularization. Whether the regression baseline augments inputs before feeding them to L_R, our approach mirrors this process. Consequently, the incorporation of ConR requires minimal adjustments and can be seamlessly integrated without necessitating substantial considerations.\nConcerning L_R in our evaluation process, in all baselines and for all benchmarks, each input sample undergoes one augmentation before being incorporated into L_R. This aligns with the common practice observed in baseline methodologies. This highlights the straightforward integration of ConR into existing frameworks.\\ \n## Similarity Threshold selection\nThe determination of the similarity threshold is task-dependent. For instance, in the context of age estimation, employing a yearly measure is intuitively relevant. In our efforts to optimize this parameter, we conducted an ablation study (\"Similarity threshold analysis\" in section 4.2 of the paper and section A.5 of the appendix) to explore the impact of varying the number of years considered as the distance threshold for defining the similarity threshold. Our ablation study shows that a high similarity threshold leads to bias toward majority samples and a low similarity threshold will lead to disagreements with label relationships. This systematic examination enhances the robustness and applicability of ConR across different tasks.\n## Performance of ConR-only\nThank you for highlighting the importance of additional report in the experiment section. In response to your comment, in the updated manuscript we have added the performance of ConR independently, referred to as \"ConR-only,\" in the first row of tables 1-4. This allows for a clear and comprehensive understanding of ConR's effectiveness in isolation, without the influence of additional techniques.\n## Representations of Balanced MSE and RankSim\nThank you for your attention. Due to space constraints, we omitted the visualizations of Balanced MSE and RankSim in Figure 4. For the representations of Balanced MSE[2] and RankSim, as well as their respective analyses, please refer to Figure 13 and \"Feature visualization\" in the updated manuscript appendix.\\ \nFigure 13 shows that RanKSim by imposing order relationships encourages high relative spread while Balanced MSE suffers from low relative spread. Both RankSim and Balanced MSE have high occurrences of collapses and noticeable gaps in their feature space.  Comparing the representations of Balanced MSE and RankSim with the one of ConR shows that ConR learns the most effective representations.\n## $1/\\omega$ instead of $\\omega$\nFigure 5 presents the ablation study on the age estimation task. To facilitate a more intuitive comparison, we employed $1/\\omega$ as it represents the distance, and in the context of age estimation, the distance corresponds to age difference. The figure illustrates the optimal choice for the age difference. Moreover, to maintain consistency, we have used this notation for the ablation study on the similarity threshold for other tasks as well.\n## Figure 5-b: similarity threshold omega is smaller at 1 \nThank you very much for raising this valid concern. It is fixed in the updated manuscript.\n\n### References\n[1] Cui, Jiequan, et al. \"Parametric contrastive learning.\", ICCV 2021.\\\n[2] Ren et al., \"Balanced MSE for Imbalanced Visual Regression\", CVPR 2022."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700648912717,
                "cdate": 1700648912717,
                "tmdate": 1700648912717,
                "mdate": 1700648912717,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "49z3LIMBkK",
                "forum": "RIuevDSK5V",
                "replyto": "C1iW5oFyIg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2927/Reviewer_Yj3F"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2927/Reviewer_Yj3F"
                ],
                "content": {
                    "title": {
                        "value": "comments on authors' response"
                    },
                    "comment": {
                        "value": "\"ConR only\" seems to have better performance than LDS and FDS, but not necessarily RankSim.\n\nRepresentation of ConR vs RankSim in Figure 4d and Figure 13a.   ConR seems to have a larger spread for the same/similar age/color than RankSim.\n\nFurther explanation on what  \"feature statistics\" and \"heterogeneous dynamics\" are would be helpful.  It seems your response is the selection of similarity threshold omega, which affects how well \"positive\" and \"negative\" pairs are selected, and hence the learned feature space.  What are the \"feature statistics\"?  What are the \"heterogeneous dynamics\"?\n\nSince f_S is a simple product, I suggest discussing it in the main paper, not appendix."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700682779705,
                "cdate": 1700682779705,
                "tmdate": 1700682779705,
                "mdate": 1700682779705,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IWQN2lal9d",
                "forum": "RIuevDSK5V",
                "replyto": "tkXBc1I14B",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2927/Reviewer_Yj3F"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2927/Reviewer_Yj3F"
                ],
                "content": {
                    "title": {
                        "value": "comments on authors response"
                    },
                    "comment": {
                        "value": "What do you consider as \"feature space collapses\" and \"expected patterns in the learned representations\" in the age dataset?\n\nIf there are \"heterogeneous dynamics\" in the feature space as described, is a constant similarity threshold omega appropriate for all ages?  If so, what is the main reason?"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700690073629,
                "cdate": 1700690073629,
                "tmdate": 1700690073629,
                "mdate": 1700690073629,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "EfRyM7PuIt",
            "forum": "RIuevDSK5V",
            "replyto": "RIuevDSK5V",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2927/Reviewer_M28F"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2927/Reviewer_M28F"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses the problem of imbalanced problem in real-world data. To tackle the imbalance in continuous label spaces, the authors introduce a contrastive regularization technique named ConR, which is based on infoNCE. This technique simulates both global and local similarities between labels in the feature space, preventing the features of minority samples from being overshadowed by those of majority samples. ConR primarily focuses on discrepancies between the label space and the feature space and penalizes these differences. Indeed, this is also an augmentation method rather than re-weighted method in DIR.\n\nHowever, this work contains several weakness, which is discussed below."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. ConR presents a novel auggmentation approach to handle the imbalanced problem in continuous label spaces, whose problem is important.\n\n2. The methods of regularizing process of **ConR** by pulling together positive pairs and relatively repelling negative pairs seems solid.\n\n3. The results seem to indicate that the proposed method can be seamlessly integrated with other models and exhibits improvements over existing baselines."
                },
                "weaknesses": {
                    "value": "1. While the author claims that **ConR** reduces prediction error, are there any theoretical insights or guarantees supporting the idea that **ConR** can achieve a lower generalization bound? Relying solely on empirical results might not suffice to attest to the superiority of the proposed methods.\n\n2. I am curious about complexity. When performing augmentation on large-scale datasets, sampling might increase the complexity. This leads to a prevalent question: Why not leverage reweighting methods which can attain comparable (or potentially superior) results without the significant memory and time overhead associated with the augmentation step? [1,2] \n\n3. While AgeDB-DIR, IMDB-WIKI-DIR, and NYUD2-DIR are structured in DIR [3], and MPIIGaze-DIR is a creation of the authors, a comprehensive description of each dataset should be included in the Appendix. Moreover, given the variety of metrics in NYUD2-DIR, the rationale behind selecting only two needs clarification.\n\n4. The experiments did not surpass all baselines. For instance, in Table 2, the combination of **LDS + FDS + RankSim** posts the best results in terms of GM in few-shot case.\n\n5. For larger datasets like IMDB and NYUD2, **ConR** doesn't consistently outperform other models. However, it seems to excel with smaller datasets such as AgeDB and MPIIGaze.\n\n6. Examining Table 1, the reported results are as follows:\n\n| model | few |\n| :---------: | :------: |\n|FDS + RankSim|  9.68 |\n|FDS + RankSim + **ConR**| 9.43 |\n|LDS + FDS + RankSim| 9.92 |\n|LDS + FDS + RankSim + **ConR**| 9.21 |\n|||\n\nFurther analysis is warranted. For instance, why does **LDS + FDS+RankSim** underperform compared to **FDS + RankSim**? Yet, with the addition of **ConR**, it achieves superior results. This observation hints that **ConR** might enhance outcomes when paired with **LDS + FDS + RankSim**. However, this theory doesn't hold when assessed on IMDB-WIKI-DIR. A more detailed analysis of the experimental results is recommended.\n\n[1] Wang et al., Variational Imbalanced Regression: Fair Uncertainty Quantification via Probabilistic Smoothing. NeurIPS 2023\n\n[2] Ren et al., Balanced MSE for Imbalanced Visual Regression, CVPR 2022\n\n[3] Yang et al., Delving into Deep Imbalanced Regression. ICML 2021"
                },
                "questions": {
                    "value": "See Above. Overall, this work is novel, and interesting. The problem they try to solve is imporant, and results seems good. Nonetheless, I strongly recommend the authors to delve deeper by: \n\n(1) **theoretical insights or guarantees** supporting the efficacy of the proposed method, and \n\n(2) **thorough empirical analysis of the experimental outcomes**."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2927/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2927/Reviewer_M28F",
                        "ICLR.cc/2024/Conference/Submission2927/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2927/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698492415939,
            "cdate": 1698492415939,
            "tmdate": 1700704420029,
            "mdate": 1700704420029,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "U8fYHFQWnW",
                "forum": "RIuevDSK5V",
                "replyto": "EfRyM7PuIt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer M28F - part 1"
                    },
                    "comment": {
                        "value": "Thank you for your thorough review and constructive comments. Below, we provide responses to your valuable feedback:\n## Theoretical Insights\nWe appreciate your emphasis on the importance of theoretical analysis. In response to your comment, we have added Section B in the Appendix of the revised manuscript. In the added section, we derive a upper bound on the probability of mislabelling:\n\n$\\frac{1}{4N^2}\\sum_{j, x_j \\in A}^{2N} \\sum_{q=0}^{K^-_j} \\log \\mathcal{S}\\_{j,q} \\ p(\\hat Y\\_j | x\\_q) \\le \\mathcal{L}\\_{ConR} + \\epsilon, \\quad \\epsilon \\overset{N\\rightarrow \\infty}{\\rightarrow} 0$,\\\nwhere $A$ is the set of selected anchors and $x_q$ is a negative sample. $p(\\hat Y_j|x_q)$ is the likelihood of sample $x_q$ with an incorrect prediction $y_q \\in \\hat Y_j = (\\hat y\\_j - \\omega, \\hat y\\_j + \\omega)$. $\\hat y\\_j$ is the prediction of the $j^{th}$ anchor that is mistakenly similar to the prediction of its negative pairs $x\\_q$. We refer to $p(\\hat Y_j|x_q)$ as the probability of collapse for $x_q$. The left-hand side presents this probability for all the negative samples. \nThe left-hand side is the probability of all collapses during the training and regarding the equation above, Convergence of $\\mathcal{L}\\_{ConR}$ tightens the upper bound for it. Minimizing the left-hand side can be explained with two non-disjoint scenarios: either the number of anchors or the degree of collapses is reduced. In addition, each collapse probability is weighted with $\\mathcal{S}\\_{j,q}$, leading to penalizing the incorrect predictions with regard to their severity. In other words, ConR penalizes the bias probabilities with a re-weighting scheme, where the weights are defined based on the agreement of the predictions and labels. This inequality illustrates that optimizing ConR will decrease the probability of mislabelling in proportion to their mislabeling degree, with a specific emphasis on minority samples. Integrating ConR into a regression task penalizes biases, resulting in a more balanced feature space. \n\n## Leveraging reweighting methods for DIR\nThank you for highlighting the significance of the complexity analysis. As it is a valid concern, we have addressed it by providing an evaluation of the time consumption of ConR in comparison to the baselines (Please refer to Section 4.1 of the paper, titled \"Time Consumption Analysis\u201d). Our analysis show that ConR is considerably more efficient compared to FDS which explicitly aligns the feature space. Moreover, time consumption of ConR is comparable to other baselines while providing considerable performance gain.\n\nRegarding re-weighting, the empirical observations in [1] and highlighted in VIR [2], demonstrate that using empirical label distribution does not accurately reflect the real label density in regression tasks, unlike classification tasks. Thus, traditional re-weighting techniques in regression tasks face limitations. Consequently, LDS [1] and the concurrent work, VIR propose to estimate effective label distribution. Despite their valuable success, two main issues arise, specifically for complicated label spaces. These approaches rely on binning the label space to share local statistics. However, while effective in capturing local label relationships, they disregard global correspondences.\nFurthermore, in complex and high-dimensional label spaces, achieving effective binning and statistics sharing demands in-depth domain knowledge. Even with this knowledge, the task becomes intricate and may not easily extend to different label spaces.\nFor instance, in age estimation, where the label space is one-dimensional, methods like LDS and VIR can manage the task. However, when examining the code-base of [1] for depth estimation on the NYUD2-DIR benchmark, we observe that they meticulously define buckets and carefully consider various factors to make LDS feasible in that particular context.\nAdditionally, VIR is evaluated on datasets with one-dimensional label space, and the challenges and effectiveness of their method for high-dimensional label spaces are not discussed in their study. In contrast, ConR smoothly extends to high-dimensional label spaces.\n## Comprehensive description of datasets\nThank you for emphasizing the importance of a detailed explanation of the datasets. For comprehensive details on the AgeDB-DIR, IMDB-WIKI-DIR, NYUD2-DIR, and the creation process of MPIIGaze-DIR, we have added information to section A.2, and dataset creation details in the Appendix of the updated manuscript.\n\n### References\n[1] Yang, Yuzhe, et al. \"Delving into deep imbalanced regression.\" ICML 2021.\\\n[2] Wang et al., Variational Imbalanced Regression: Fair Uncertainty Quantification via Probabilistic Smoothing. NeurIPS 2023."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700646013703,
                "cdate": 1700646013703,
                "tmdate": 1700646013703,
                "mdate": 1700646013703,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "J5UsiUgCdi",
                "forum": "RIuevDSK5V",
                "replyto": "EfRyM7PuIt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2927/Reviewer_M28F"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2927/Reviewer_M28F"
                ],
                "content": {
                    "title": {
                        "value": "comments on authors response"
                    },
                    "comment": {
                        "value": "Thanks for the authors' comprehensive responses and updates to the manuscript. I would like to suggest the following:\n\n1. The theoretical insights presented at the end of the appendix are surprising and significant. I recommend incorporating the main theory or conclusion from this insight into the main body of the paper. There is a concern regarding the integration of this material and its impact on the paper's structure and presentation.\n\n2. The authors offer a detailed comparison between ConR and both [DIR and VIR]. This should be included in the related works section of the main paper, as it provides a clear distinction between these methodologies."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700694287970,
                "cdate": 1700694287970,
                "tmdate": 1700694287970,
                "mdate": 1700694287970,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "r4Fi52K4LX",
                "forum": "RIuevDSK5V",
                "replyto": "EfRyM7PuIt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2927/Reviewer_M28F"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2927/Reviewer_M28F"
                ],
                "content": {
                    "title": {
                        "value": "comments on authors response"
                    },
                    "comment": {
                        "value": "Thank you to the authors for their thorough responses and revisions to the manuscript. In light of these changes, I have increased my scores for **Soundness**, **Presentation**, and **Contribution** as my concerns have been satisfactorily addressed.\n\nHowever, I would advise the authors to:\n\n**1.** Ensure that concerns raised by other reviewers are also fully addressed. It is important to engage with and resolve these points to strengthen the paper further.\n\n**2.** Regarding the theoretical insights in the appendix, I found no errors or doubts upon review. Nonetheless, I strongly encourage the authors to re-verify the accuracy and completeness of these sections to ensure the robustness of the paper."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700704857431,
                "cdate": 1700704857431,
                "tmdate": 1700704857431,
                "mdate": 1700704857431,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "t3YMUz95bc",
            "forum": "RIuevDSK5V",
            "replyto": "RIuevDSK5V",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2927/Reviewer_ECg6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2927/Reviewer_ECg6"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses the imbalanced regression problems where the label space is continuous. The proposed contrastive regularizer is to model global and local label similarities in feature space and prevent the features of minority samples from being collapsed into their majority neighbours. The proposed ConR consolidates essential considerations into a generic, easy-to-integrate, and efficient method that effectively addresses deep imbalanced regression. The empirical study shows that ConR significantly boosts the performance of SoTA methods on four large-scale deep imbalanced regression benchmarks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This paper is well-written and easy to understand.\n2. The novelty of this paper is good. To my knowledge, applying contrastive learning to imbalance regression is novel.\n3. The authors provide a new dataset with 2-dimentional label space by using MPIIGaze, which could be useful to the imbalance regression community."
                },
                "weaknesses": {
                    "value": "1. The proposed objective in Eq. (4) is relative hasty, without the reason of introducing the ordinary regression loss. Also, the definition of the introduced loss should be clearly provided.\n2. No deviation measure in the experimental results.\n3. No experimental result for the ConR-only case. All the results for the proposed ConR are with respect to the combination with existing methods as a regularized. Due to supervised information is already used in the loss of ConR, its preformation should be provided as a baseline.\n4. Some references are missing, e.g., Page 16."
                },
                "questions": {
                    "value": "1. In the selection of anchor, if an example without any negative example, it will not be chosen as an anchor. What is the main reason for this selection? Do you consider the contrastive learning method without negative pairs, such as BYOL and SimSiam?\n2. The empirical label distribution is needed to determine the pushing weight for the negative pair. In addition, the authors suggest using the inverse frequency to compute the pushing weight, so that the minority samples will obtain harder force to be repelled from the anchor. How can we determine the continuous weight with the discrete frequency? Do we need any kernel density estimation technique?\n3. Please explain the specific reason for combining the proposed loss with the ordinary regression loss in Eq. (4) with more details and evidence.\n4. I notice some failure case in Table 1, Table 2, and Table 3, when adding the ConR loss as the regularization term. It is strange that you can down-weight of $\\beta$ to avoid this situation. I understand that the main goal is to improve the performance on *Few* case, however, there are still some cases that the performance on *Few* case drops. Also, there are some cases that the performance on *All* case drops. Hence, please provide the explanation for this phenomenon and what is the specific metric for a good imbalanced regression in your paper. I think the *Few* case should be much more important.\n5. Why the results on the *Few* case of Balanced MSE in Figure 3 is inconsistent to that in Table 3?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2927/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2927/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2927/Reviewer_ECg6"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2927/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698584776098,
            "cdate": 1698584776098,
            "tmdate": 1699636236339,
            "mdate": 1699636236339,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "UDfgeviZdw",
                "forum": "RIuevDSK5V",
                "replyto": "t3YMUz95bc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ECg6 - part 1"
                    },
                    "comment": {
                        "value": "Your comprehensive review and insightful comments are greatly appreciated. Here we address your comments as follows:\n## Combining ConR with the ordinary regression loss \nThank you very much for your attention to the details of the objective function. We acknowledge that we should provide more information. First, Eq. 4 emphasis that ConR is orthogonal to deep regression methods and can be used in any regression framework with any regression objective function.  Secondly, to clarify the objective, let's delve into the optimization process in the DIR task. When modeling inter-label relationships in the feature space, two crucial factors come into play: correct similarities and correct directions [1]. Taking the age estimation task as an example, consider a scenario with a 20-year-old, a 15-year-old, and a 25-year-old person. Both the 15-year-old and 25-year-old individuals have the same label similarity with the 20-year-old (i.e., a 5-year age difference); however, one is younger, and one is older. ConR imposes proper similarities, with a focus on minority samples, while ordinary regression boosts the direction signals and result in the best performance for ConR. Furthermore, RankSim [2] is also a regularizer, assuming order relationships and optimizing their proposed loss function alongside the regression loss function. \n## Deviation measure in the experimental results\nWe appreciate your valid concern. To maintain clarity in the dense tables of DIR evaluations, we opted not to include deviations directly, aiming to prevent the tables from becoming overwhelming. Instead, we have visualized the standard deviations using error bars in Figure 3 and Figure 11. We can add a detailed table of standard deviations to the supplementary material if desired. \n## Performance of ConR-only as a baseline\nThank you very much for highlighting this. We value your concern and added ConR-only to the tables.\n## Missing reference\nThank you for highlighting the missing reference. This is fixed in the updated manuscript.\n## Main reason for anchor selection\nWe appreciate your inquiry regarding the rationale behind the proposed anchor selection. \nYes, ConR does not select the input sample without any negative pair as an anchor. But the selected anchors have both negative and positive pairs dissimilar to BYOL and SimSiam.\nThe motivation of this design is multifaceted. First, as discussed in the manuscript, for categorical contrastive learning, the anchors are predefined, and it serves as a prior knowledge in addressing imbalanced distribution. However, in contrastive learning for regression, defining anchors is not feasible, especially for complicated and high-dimensional label spaces. \nSecondly, treating each training sample as an anchor overlooks the imbalanced distribution, resulting in a bias towards majority labels. Empirical observations, as detailed in [3], highlight a phenomenon in deep imbalanced regression where minority samples tend to collapse towards their neighboring majority samples. This occurs even when their labels are dissimilar; for instance, in the age estimation task, features representing the age range of 0 to 6 years may exhibit similarities with those of age 30. This situation leads to confusions within certain areas of the feature space. Thus, we propose to use the correspondences between label similarities and prediction similarities to identify the confusion regions during the training. These areas of confusion are selected as anchors and push the samples that mistakenly have similar features to these anchors. The reason is that due to the skewed distribution, if we select all samples as anchors and repel all negative pairs, the learning will be biased toward majority samples. Therefore, ConR uses the anchor selection as a treatment to the biases in deep imbalance regression task without any prior knowledge about the anchors or any explicit assumption about the inter-label relationships. \nIn summary, for each training sample $x_i$ with label $y_i$ and prediction $\\hat y_i$, other training samples with a label different to $y_i$ and a prediction close to $\\hat y_i$ are considered as collapses due to imbalanced distribution and serve as negative samples for $x_i$. If $x_i$ has no negative pair, it means there are no confusion around $(x_i,y_i)$ to be addressed; thus $x_i$ is not considered as an anchor and does not contribute to ConR. Otherwise, $x_i$ is an anchor and ConR pushes away samples collapsed to $x_i$ relative to label similarities to address these confusions.\n\n### References\n[1] Li, Wanhua, et al. \"Bridgenet: A continuity-aware probabilistic network for age estimation.\" CVPR 2019.\\\n[2] Gong, et al. \"RankSim: Ranking similarity regularization for deep imbalanced regression.\" ICML 2022.\\\n[3] Yang, Yuzhe, et al. \"Delving into deep imbalanced regression.\" ICML 2021."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700642812862,
                "cdate": 1700642812862,
                "tmdate": 1700642812862,
                "mdate": 1700642812862,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "2H5qxq2OJ5",
            "forum": "RIuevDSK5V",
            "replyto": "RIuevDSK5V",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2927/Reviewer_viAu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2927/Reviewer_viAu"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a contrastive learning approach to address the issue of imbalanced regression. This method is orthogonal to existing solutions and has demonstrated promising experimental results."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Data imbalance and the fairness of machine learning algorithms are practical issues that warrant significant attention.\n2. The method is reasonably designed and has shown good experimental results."
                },
                "weaknesses": {
                    "value": "1. While the paper presents a contrastive learning paradigm adapted for regression, it does not appear to directly address the issue of data imbalance. It would enhance the paper if the authors could clarify how the method specifically tackles this challenge or consider adapting the technique to more explicitly focus on imbalanced datasets.\n2. Comparisons should be made with other contrastive regression learning methods (e.g., [a]).\n3. The manuscript could be strengthened by providing some theoretical analysis and insights to support the empirical findings. \n4. It would be beneficial if the authors could provide the pseudocode for the algorithm to facilitate the readers' comprehension of the algorithm's details.\n\n[a] [Rank-N-Contrast: Learning Continuous Representations for Regression](https://arxiv.org/pdf/2210.01189.pdf)"
                },
                "questions": {
                    "value": "Given the distinct advantages of data augmentation under the contrastive learning framework, are the baseline methods utilizing their typical data augmentation strategies, or those consistent with contrastive learning? If it's the former, a comparison showcasing results after aligning the augmentation techniques would be valuable."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2927/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2927/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2927/Reviewer_viAu"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2927/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698731762551,
            "cdate": 1698731762551,
            "tmdate": 1700711256585,
            "mdate": 1700711256585,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PNiX2scTJe",
                "forum": "RIuevDSK5V",
                "replyto": "2H5qxq2OJ5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2927/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2927/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer viAu - part 1"
                    },
                    "comment": {
                        "value": "Thank you sincerely for your comprehensive review and invaluable insights. In the following we provide the response to your comments:\n## Effectiveness of ConR for Deep Imbalanced Regression\nWe appreciate your attention to the contribution of ConR to the imbalanced learning. Here we provide clarifications as follows:\nContrastive learning techniques have shown promising potentials in learning semantically rich representations by effectively disentangling essential variations from irrelevant ones. Emphasizing contrastive optimization in favor of minority samples to encourages balanced feature space is a common practice in imbalanced classification[1]. These approaches employ predefined anchors and statistical priors that are not extendible to the regression tasks.\nBy incorporation continuity into the contrastive learning, the variations in the feature space will be modeled according to the continuity in the label space. Consequently, each sample is accurately mapped to the feature manifold in agreement with its label region on the label manifold, making it easier for the model to traverse the regions where data might be scarce due to imbalanced distribution. \nIn addition, ConR emphasizes on modeling continuous relationships for minority samples via dynamically selecting the region of confusion (The anchor selection and negative pair selection in ConR) in the feature space to enforce variations in accordance with the label similarities (The relative pushing in ConR).\nMoreover, in section B of appendix (Added to the updated manuscript), as theoretical analysis shows, by optimizing ConR, the probability of incorrect labeling specifically for minority samples is reduced and ConR helps regularizing the regression process.\n## Comparison with Rank-N-Contrast\nThank you for your valuable suggestion regarding the comparison with Rank-N-Contrast [2].  We added Rank-N-Contrast as a concurrent work in our updated manuscript (Please refer to our latest manuscript). Their code became available in October, which is after our ICLR 2024 submission deadline, making a direct comparison infeasible. We acknowledge the importance of comprehensive comparisons; however, providing comparative results takes longer than the short timeframe of the Discussion period. Nonetheless, we plan to include 'Rank-N-Contrast' as a concurrent baseline and provide the necessary comparison results.\nAdditionally, 'Rank-N-Contrast' is designed based on the order assumption in the label space, similar to RankSim[3]. As mentioned in our paper, this assumption is not universally valid for all label spaces. For instance in depth estimation task, 'Rank-N-Contrast' and RankSim cannot be used.  However our proposed method, ConR, does not make any assumptions about inter-label relationships.\n## Theoretical Insights\nWe appreciate your emphasis on the importance of theoretical analysis. In response to your comment, we have added Section B in the Appendix of the revised manuscript. In the added section, we derive a upper bound on the probability of mislabelling:\n\n$\\frac{1}{4N^2}\\sum_{j, x_j \\in A}^{2N} \\sum_{q=0}^{K^-_j} \\log \\mathcal{S}\\_{j,q} \\ p(\\hat Y\\_j | x\\_q) \\le \\mathcal{L}\\_{ConR} + \\epsilon, \\quad \\epsilon \\overset{N\\rightarrow \\infty}{\\rightarrow} 0$,\\\nwhere $A$ is the set of selected anchors and $x_q$ is a negative sample. $p(\\hat Y_j|x_q)$ is the likelihood of sample $x_q$ with an incorrect prediction $y_q \\in \\hat Y_j = (\\hat y\\_j - \\omega, \\hat y\\_j + \\omega)$. $\\hat y\\_j$ is the prediction of the $j^{th}$ anchor that is mistakenly similar to the prediction of its negative pairs $x\\_q$. We refer to $p(\\hat Y_j|x_q)$ as the probability of collapse for $x_q$. The left-hand side presents this probability for all the negative samples. \nThe left-hand side is the probability of all collapses during the training and regarding the equation above, Convergence of $\\mathcal{L}\\_{ConR}$ tightens the upper bound for it. Minimizing the left-hand side can be explained with two non-disjoint scenarios: either the number of anchors or the degree of collapses is reduced. In addition, each collapse probability is weighted with $\\mathcal{S}\\_{j,q}$, leading to penalizing the incorrect predictions with regard to their severity. In other words, ConR penalizes the bias probabilities with a re-weighting scheme, where the weights are defined based on the agreement of the predictions and labels. This inequality illustrates that optimizing ConR will decrease the probability of mislabelling in proportion to their mislabeling degree, with a specific emphasis on minority samples. Integrating ConR into a regression task penalizes biases, resulting in a more balanced feature space. \n ### References\n[1] Cui, Jiequan, et al. \"Parametric contrastive learning.\", ICCV 2021.\\\n[2] Zha, Kaiwen, et al. \"Rank-N-Contrast: Learning Continuous Representations for Regression.\" Neurips 2023.\\\n[3] Gong, et al. \"RankSim: Ranking similarity regularization for deep imbalanced regression.\" ICML 2022."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700636765390,
                "cdate": 1700636765390,
                "tmdate": 1700636765390,
                "mdate": 1700636765390,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6sn5Q7EqX4",
                "forum": "RIuevDSK5V",
                "replyto": "aKD4pLYE6B",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2927/Reviewer_viAu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2927/Reviewer_viAu"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the response. After reading the comments and other reviewer's comments, my major concerns have been addressed. I will increase the score accordingly.\n\nBest,\n\nThe reviewer viAu"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2927/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700711236282,
                "cdate": 1700711236282,
                "tmdate": 1700711236282,
                "mdate": 1700711236282,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]