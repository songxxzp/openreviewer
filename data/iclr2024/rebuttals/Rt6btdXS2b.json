[
    {
        "title": "Continuous Indeterminate Probability Neural Network"
    },
    {
        "review": {
            "id": "tUJo03RlgI",
            "forum": "Rt6btdXS2b",
            "replyto": "Rt6btdXS2b",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1578/Reviewer_7gbu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1578/Reviewer_7gbu"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces Continuous Indeterminate Probability Neural networks, which applies Indeterminate Probability Theory to define neural networks with latent variables for classification.\nThe authors also present a related auto-encoding variant of the model, which can be used to visualize the latent variable of the model."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The ideas presented in the paper are interesting and novel, to the best of my knowledge. These ideas could inspire future research.\n\n* Due to the usage of the latent variables in the CIPNN, the proposed model is less black-box than other architectures"
                },
                "weaknesses": {
                    "value": "**General comments**\n\nThere are 2 major issues with this paper, regarding clarity and experiments.\n\nCLARITY\n\nOverall, I found the paper hard to understand, mostly because it relies heavily on the unpublished work in (Anonymous, 2024), and assumes that the reader is knowledgeable of its content.\nWhile there is a high level description of (Anonymous, 2024) in section 2.2, this description is rushed and confusing (see detailed comments below).\n\nBeing a conference paper, this paper should instead be self-contained: the reader/reviewer should not have to read in full (Anonymous, 2024) to understand the proposed method (especially keeping in mind that the other paper could be rejected from the conference and be therefore unpublished if this work gets accepted).\nAs is, this paper looks more like an appendix to (Anonymous, 2024), rather a paper by itself. I suggest that the authors read and rewrite this work with the eyes of someone that knows nothing about (Anonymous, 2024).\n\nConsidering the classification/auto-encoding applications of Indeterminate Probability Theory, there are also several points in the paper that need to be clarified/improved.\n\nEXPERIMENTS\n\nThe experimental section is also quite confusing, and lacks proper baselines to understand the real performances of the model. \n\n\n\n**Detailed comments**\n\nBelow I describe the main points of confusion in each section.\n\n_Abstract_\n\nYou write \"pushed this classification capability to infinity\" -> what does this mean?\n\n_Introduction_\n\nThe motivation for this work in the introduction is based on the IPNN, which is however a model the reader knows nothing about at this point in the paper.\n\n_Section 2.1_\n\nYou write \"VAE uses neural network as the approximate solution of decoder\"\n -> What does this mean? In a VAE the decoder is defined as a modelling choice, and the encoder is used to approximate the posterior probability.\n\n_Section 2.2_\n\nOverall this section is hard to understand, and needs a better example/toy problem to help the reader (you could focus on the classification task from Figure 1 for example). \n\nWhen you say \"introducing Observers and treating the outcome of each random experiment as indeterminate probability distribution,\"\n- What are Observers? They are no longer mentioned in the rest of the section\n- how do you define an \"indeterminate\" probability distribution?\n\nThese definitions are missing:\n- what does $m$ represent in $y_m$\n- what does $l$ represent in $y_l$\n- what does $t$ represent in $x_t$\n\n \n_Section 3_\n\nWhy do you need to introduce both Observer 2 and Observer 3? What is the difference? Observer 2 seems not to be relevant for the subsequent discussion.\nDue to the confusion in Section 2.2, I am not really sure what you are trying to achieve in this section, and how exactly this relates to the rest of the paper.\n\n\n\n_Section 4.2_\n\n- Why did you choose that specific distribution in the right-hand side of the KL divergence?\n\n_Section 5_\n\nYou refer to details in (Anonymous, 2024) in the footnote, but they are needed in this paper as well to understand it.\n\n\n_Section 6_\n\n\"In this section, we will focus on the training strategy of Gaussian distribution\" -> \nCan you clarify what this means?\n\n\n_Section 7.1_\n\n1. This section misses baselines for other classification models (even simple neural networks)? The classification performances of your model on MNIST look quite poor for example.\n1. In Table 3 you compare against \"Simple-Softmax\", which is not defined, and which performs significantly better than the proposed model \n1. The advantages of this model vs other architectures are not well described\n1. What's the scalability of this method? What are the training times?\n1. The dataset names are not even mentioned in the main text, so one needs to guess which dataset the authors are talking about while reading this section. Only captions in the Figures mention the dataset.\n1. In the paragraph \"Results of classification tasks on large latent spaces\" - are you talking about table 2? It is not mentioned\n\n\n_Section 7.2_\n\n1. The difference between CIPAE and VAE is not clear from the paper\n1. \"As shown in Figure 5, the results of\nauto-encoder tasks between CIPAE\nand VAE are similar, this result further verifies that CIPAE is the analytical solution.\" -> What does this mean? Why can you make this statement from looking at a Figure?\n\n_Conclusion_\n\n\"Although our proposed model is derived from indeterminate probability theory, we can see Determinate\nfrom the expectation form in Eq. (11). Finally, we\u2019d like to finish our paper with one sentence:\nThe world is determined with all Indeterminate!\" -> not sure what this means."
                },
                "questions": {
                    "value": "See the questions in the above section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1578/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697905222794,
            "cdate": 1697905222794,
            "tmdate": 1699636086478,
            "mdate": 1699636086478,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kFHRViSzWM",
                "forum": "Rt6btdXS2b",
                "replyto": "tUJo03RlgI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1578/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1578/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 7gbu"
                    },
                    "comment": {
                        "value": "Dear Reviewer 7gbu,\n\nWe sincerely appreciate your very insightful and detailed feedbacks. Here are our detailed responses to your questions.\n\n**Q1**: You write \"pushed this classification capability to infinity\" -> what does this mean?\n\nA1: It means that the model is very flexible to classification tasks, we can use the same neural network without changing the number of output nodes to classify arbitrary categories. For example, in Fig. 9, we used two random variables (4 nodes in the last layer) to classify into 2 or 10 categories. And we can also use same model to classify a very large number of categories without limitation.\n\n**Q2**: The motivation for this work in the introduction is based on the IPNN, which is however a model the reader knows nothing about at this point in the paper.\n\nA2: We apologize for the additional reference to our other paper, which may have disrupted your reading.\n\n**Q3**: You write \"VAE uses neural network as the approximate solution of decoder\" -> What does this mean? \n\nA3: It means that the decoder of VAE is a model, but the decoder of our CIPAE is a probability equation, that means we do not need to design the decoder.\n\n**Q4**: Overall Section 2.2 is hard to understand, and needs a better example/toy problem to help the reader.\n\nA4: Actually, the toy example in Section 3 is a very good toy example to CIPNN.\n\n\n**Q5**: What are Observers? Why do you need to introduce both Observer 2 and Observer 3? What is the difference?. \n\nA5: In CIPNN, the label can be understood as Observer 1, the model output can be understood as Observer 3.\n(Observer 2 is the case for IPNN.)\n\nIn addition, we'd like to answer this question from a high-level.\n\nThe world is understood through observers. In the case of a coin toss, the outcome cannot be known unless observed. That is, the ground truth is not able to be known, we only know the observations.\n\nGiven that the use of observers is unavoidable, and the imperfect observations maybe more general in the real world? (Perfect observations are the special case.)\n\nAdditionally, we do not need to restrict the observers, as they may have different ways of understanding the world. For example, in our coin toss example in Section 3, Observer$_3$ understands the outcome as a Gaussian distribution.\n\nThe questions now is: what truly matters?\n\nThe Change! While different observers may have different understandings of the world, the Change still follows the Ground Truth (albeit with some errors). Our proposed equation is designed to evaluate this Change.\n\n**Q6**: Why did you choose that specific distribution in the right-hand side of the KL divergence?\n\nA6: As we written in the paper, KL divergence is for solving over-fitting problem, and our modification is according to the analysis results in Fig. 8.\n\n**Q7**: \"In this section, we will focus on the training strategy of Gaussian distribution\" -> Can you clarify what this means?\n\nA7: It means that using a distribution other than Gaussian, such as a uniform distribution or others, is also acceptable.\n\n**Q8**: This section misses baselines for other classification models (even simple neural networks)?The classification performances of your model on MNIST look quite poor for example.\nIn Table 3 you compare against \"Simple-Softmax\", which is not defined, and which performs significantly better than the proposed model\n\nA8: Our proposed model is not for a performance improving, as you can see its performance is even poor than the most simple neural networks, so it doesn't need to compare it with other better models.\n\n**Q9**: \"As shown in Figure 5, the results of auto-encoder tasks between CIPAE and VAE are similar, this result further verifies that CIPAE is the analytical solution.\" -> What does this mean? Why can you make this statement from looking at a Figure?\n\nA9: CIPAE is the analytical solution is a theoretical analysis results, and the results in Fig. 5 is an evidence.\n\n\n**Q10**: \"Although our proposed model is derived from indeterminate probability theory, we can see Determinate from the expectation form in Eq. (11). Finally, we\u2019d like to finish our paper with one sentence: The world is determined with all Indeterminate!\" -> not sure what this means.\n\nA10: This is an abstract understanding of Eq. (11).\n\nBest regards\n\nAuthors"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1578/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700562583619,
                "cdate": 1700562583619,
                "tmdate": 1700562583619,
                "mdate": 1700562583619,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aSAgGCGOWK",
                "forum": "Rt6btdXS2b",
                "replyto": "kFHRViSzWM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1578/Reviewer_7gbu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1578/Reviewer_7gbu"
                ],
                "content": {
                    "title": {
                        "value": "Unchanged score"
                    },
                    "comment": {
                        "value": "Thanks for the response to my comments.\n\nWhile some of the points were clarified in my response, overall I believe that the required changes to the paper in terms of clarity will need a new review cycle. Hopefully by then (Anonymous, 2024) will be published, and it will be much easier for you to describe the motivation for this work (as also noted by reviewer EMUS) and the CIPNN model.\n\nFor now I will then leave the score unchanged, but will be open to increase it in case other reviewers convince me during the reviewer discussion phase."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1578/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700670206141,
                "cdate": 1700670206141,
                "tmdate": 1700670206141,
                "mdate": 1700670206141,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "bgsw94EcPI",
            "forum": "Rt6btdXS2b",
            "replyto": "Rt6btdXS2b",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1578/Reviewer_Vwsb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1578/Reviewer_Vwsb"
            ],
            "content": {
                "summary": {
                    "value": "The paper \u201cContinuous indeterminate\u2026\u201d proposes a continuous extension of the \u201cIndeterminate \u2026\u201d model by the same authors, correctly referenced as Anonymous. The paper describes this extension, accompanied by definitions of the classification and auto-encoder models, together with training, inference procedures and simple experiments. The resulting models are only a bit less accurate than well known models. The author's main goal is to theoretically describe and show the benefits from its use.\n\nIn my opinion, the paper may be accepted, provided the authors answer the above doubts."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The model shown is interesting and shows, perhaps not very illuminating but still explainable to the input \u2014> latent \u2014> classification, and input \u2014> latent \u2014> reconstruction problems in theoretical way.\n2. There is a good introductory to the theory in section 3.\n3. The proposed model aims at providing more explainable solutions to classification, although there is some way before the model may accomplish that.\n4. The performed experiments prove, or at least show, the hypothesis clearly stated by the authors."
                },
                "weaknesses": {
                    "value": "1. I guess the whole paper should start with a deeper explanation of differences between the proposed approach and a VAE model.\n2. An ablation study concerning the complexity is missing. The authors say that the C hyperparameter can be set to 1 \u201cas long as the batch size is high enough\u2026\u201d (page 7, bottom), but still they use C=2 in the experiments.\n3. The derivation for the continuous probability mathematical formulae is complex, and lacks intuition, instead giving intricate formulas and variables.\n4. Although the authors correctly reference to their own paper as written by Anonymous, but not yet published. The authors do it all through the paper referencing the reader to find details over there. The paper can easily be found by the title. On the other hand, this is unavoidable."
                },
                "questions": {
                    "value": "1.  Add some introduction to differences between the proposed model and VAE-like approaches, or perhaps accompany the whole sequence should be accompanied by comparisons to corresponding steps in a VAE-type model?\n2. Equation (21), being the basis for training, needs a deeper explanation. Why use the max functions both in numerator and denominator? \n3. When comparing the proposed CIPAE with VAE, section 7.2, the visualizations of the latent space become somehow different, with parts of the R^2 latent for VAE empty. Does it come from different latent definition in both cases? Or is it just a result of showing only the [-20, 20]x[-20,20] square? This might not seem to be a fair comparison unless explained.\n4. From a practical point of view: what is the training and inference comparison between VAE (as well as other WAE, etc.) approach and the proposed ones?\n5.  What is the impact of C value and the batch size on quality, trading and inference time, etc.? Could you provide some ablation study?\n6. In conclusion the authors state, that the proposed model is actually composed of two parts: first detects attributes, and the second (i.e. classification?) is a probabilistic model which may be used for reasoning. A 1-D example shown in figure 3, that the authors refer to, shows that the first part performs a kind of clustering, is that so? Please elaborate on that, since it would greatly enlarge the readability of the paper.\n7. Several language errors should be corrected. E.g. a) on page 1 the sentence \u201cHowever, IPNN need to predefine the \u2026\u201d should probably be \u201cHowever, IPNN needs to be predefined\u2026\u201d; b) just above Eq. 1 instead \u201cbellow\u201d should be \u201cbelow\u201d; c) what is the word \u201ccomplexer\u201d at the bottom of page 3? Perhaps the authors meant to say \u201cmore complex? \u201cComplexer\u201d might be used in French. I would suggest checking the whole text with some native speaker. These errors are usually tiny, but disturb reading.\n8. Please, if possible, make the figures a bit larger, just to make them somehow more readable. This refers particularly to figures 1, 3, and perhaps 2 and 4 too.\n9. In section 7.1 you claim that the CIPNN tends to put 1, 4, 7, 9 MNIST numbers in one cluster \u2014 this is hardly visible in the figures. How is that model used for classification? Which inputs were used in each round? Could you elaborate on that a bit? \n10. Equations are sometimes complex (lots of variables and indices), e.g. Sequence from (9) to (14). Could you, please, make them easier to follow?\n11. Some small editing errors, e.g. subsection 7.2 title starts as an orphan."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1578/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1578/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1578/Reviewer_Vwsb"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1578/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698670677861,
            "cdate": 1698670677861,
            "tmdate": 1699636086396,
            "mdate": 1699636086396,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lE8Oenbuzb",
                "forum": "Rt6btdXS2b",
                "replyto": "bgsw94EcPI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1578/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1578/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Vwsb (1/2)"
                    },
                    "comment": {
                        "value": "Dear Reviewer Vwsb,\n\nWe sincerely appreciate your very insightful and detailed feedbacks, and we also thank you very much for your understanding of the unavoidable reference to our other paper. Here are our detailed responses to your questions.\n\n**Q1**: Add some introduction to differences between the proposed model and VAE-like approaches\n\nA1: OK. The framework of CIPAE and VAE are very similar, but the two models are derived from different theories.\n1. The KL regularization term is an irremovable part in ELBO. Our KL regularization term is additional for over-fitting problem, and it is allowed to use other regularization method for CIPAE.\n2. If we use a model as the decoder for CIPAE (not Eq. (1) in the paper), here is the detailed difference:\n\n**VAE**:\n\n$$ ELBO =-D_{KL}(q_{\\phi}(\\mathbf{z}\\mid x^{(i)}) \\parallel p_{\\theta}(\\mathbf{z})) + E_{q_{\\phi}(\\mathbf{z}\\mid x^{(i)})} \\left[\\log p_{\\theta}(x^{(i)}\\mid \\mathbf{z}) \\right] \\text{   (a)}$$\n\n\n**Approximate CIPAE** (Not the original CIPAE):\n$$\n\\underset{\\text{(b}}{\\underbrace{\\log P^{\\mathbf{z}}(y \\mid x_{t})}}\n=\\underset{\\text{(c)}}{\\underbrace{\\log \\int\\limits_{\\mathbf{z}}P(y,\\mathbf{z}\\mid x_{t})}}\n=\\underset{\\text{(d)}}{\\underbrace{\\log \\int\\limits_{\\mathbf{z}}\\left ( P_{\\theta}(y\\mid\\mathbf{z}) \n\\cdot P_{\\phi}(\\mathbf{z}\\mid x_{t}) \\right )}}\n= \\underset{\\text{(e)}}{\\underbrace{\\log E_{P_{\\phi}(\\mathbf{z}\\mid x_{t})}\n\\left[P_{\\theta}\\left(y\\mid \\mathbf{z}\\right)\\right] }}\n$$\nFrom (b) to (c): marginalization.  \nFrom (c) to (d): according to axiom 3 that given $\\mathbf{z}$, $x$ and $y$ (image pixels) is mutual independent.   \nFrom (d) to (e): the decoder is approximated with a model $\\theta$.  \n\nIf we set the regularization term of CIPAE to be the same as that of VAE, our loss will be almost identical to that of VAE. The only difference is that the $\\log$ term is outside of the expectation term $\\mathbb{E}$. For the case where the Monte Carlo number C = 1, the losses of VAE and approximate CIPAE will be exactly the same.\n\nThis analysis results are quite interesting, that VAE and approximate CIPAE are derived from very different theory, however their final code implementations can be same in a special case (C=1).\n\n**Q2**: Equation (21), being the basis for training, needs a deeper explanation. Why use the max functions both in numerator and denominator?\n\nA2: Actually, the max functions are not important, because we usually set $\\epsilon=10^{-20}$. Therefore, the max functions are not activated for the importantsample space.\n\n**Q3**: ...the visualizations of the latent space become somehow different, with parts of the R^2 latent for VAE empty.\n\nA3: You can get a sense of the difference by comparing Fig. 4a and Fig. 4b. In Fig. 4a, the effective points are confined to a small space, whereas the valid space of CIPNN is larger, as shown in Fig. 4b.\nSimilarly, for CIPAE, although it is valid in a larger space, the values of Eq. (22) and Eq. (23) are very small, and the test or train points will not fall within that region.\n\n**Q4**: From a practical point of view: what is the training and inference comparison between VAE and CIPAE?\n\nA4: We are afraid that we cannot finished it during rebuttal. Maybe after rebuttal?"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1578/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700289847363,
                "cdate": 1700289847363,
                "tmdate": 1700289847363,
                "mdate": 1700289847363,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "i7T3tmPgGS",
            "forum": "Rt6btdXS2b",
            "replyto": "Rt6btdXS2b",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1578/Reviewer_EMUS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1578/Reviewer_EMUS"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a general model called CIPNN - Continuous Indeterminate Probability Neural Network using a group of reference variables $z$."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "This paper focuses on the explainability of probabilistic models and neural networks, which is an interesting and important topic."
                },
                "weaknesses": {
                    "value": "1. I find the motivation of this paper unclear. I had difficulty following the progression from Section 2.2 to Section 3 and then to the CIPNN model.\n\n2. The indeterminate probability theory is not surprising to me, and I believe it can be easily derived via the definition of conditional probability. Equations (1) and (2) hold for any $z$, but it's not clear to me which specific type of $z$ we are expecting in the learning process.\n\n3. I find Proposition 1 to be weak from my perspective. Specifically, Proposition 1 states, ''If $P(y_l | z^1, ... , z^N) \\to \\infty$, CIPNN converges to the global minimum.'' This is equivalent to saying that successful classification depends on our ability to learn a set of favorable variables, namely $z^1, ... , z^N$. However, the main challenge lies in determining the existence of these 'good' variables and how we can identify and obtain such $z^1, ... , z^N$ with theoretical guarantees.\n\n4. I did not find the comparison with existing approaches. Also, the numerical results did not indicates the improved performance is indeed from the introduction of $z^1, ... , z^N$."
                },
                "questions": {
                    "value": "see weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1578/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1578/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1578/Reviewer_EMUS"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1578/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698776160023,
            "cdate": 1698776160023,
            "tmdate": 1699636086327,
            "mdate": 1699636086327,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qTkGYhWUwp",
                "forum": "Rt6btdXS2b",
                "replyto": "i7T3tmPgGS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1578/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1578/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer EMUS"
                    },
                    "comment": {
                        "value": "Dear Reviewer EMUS,\n\nWe sincerely appreciate your insightful feedbacks. Here are our detailed responses to your questions.\n\n**Q1**: I find the motivation of this paper unclear. I had difficulty following the progression from Section 2.2 to Section 3 and then to the CIPNN model.\n\nA1: We apologize for the additional reference to our other paper, which may have disrupted your reading.\n\n**Q2**: The indeterminate probability theory is not surprising to me, and I believe it can be easily derived via the definition of conditional probability. Equations (1) and (2) hold for any \n, but it's not clear to me which specific type of z we are expecting in the learning process.\n\nA2: At the very least, CIPAE has a very special property:: The famous VAE model requires a decoder model, whereas the decoder of CIPAE is a probability equation, and therefore does not require a model. Have you ever seen an image auto-encoder whose decoder does not require a model?\n\n**Q3**: I find Proposition 1 to be weak from my perspective. Specifically, Proposition 1 states, ''If $P(y_l | z^1, ... , z^N) \\to 1$, CIPNN converges to the global minimum.'' This is equivalent to saying that successful classification depends on our ability to learn a set of favorable variables, namely $z^1, ... , z^N$. However, the main challenge lies in determining the existence of these 'good' variables and how we can identify and obtain such $z^1, ... , z^N$ with theoretical guarantees.\n\nA3: Your understanding is correct, the classification depends on our ability to learn a set of favorable variables, namely $z^1, ... , z^N$. Firstly, through experimentation, we can see that our models are able to learn these 'good' variables. Additionally, the main loss in Eq. (15) is an application of maximum likelihood which serves as a theoretical guarantee.\n\n\n**Q4**: I did not find the comparison with existing approaches. Also, the numerical results did not indicates the improved performance is indeed from the introduction of $z^1, ... , z^N$.\n\nA4: Our proposed model is not for a performance improving, as you can see its performance is even poor than the most simple neural networks, so it doesn't need to compare it with other better models.\n\n\nBest regards\n\nAuthors"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1578/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700562448569,
                "cdate": 1700562448569,
                "tmdate": 1700614900457,
                "mdate": 1700614900457,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]