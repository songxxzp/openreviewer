[
    {
        "title": "A Private Watermark for Large Language Models"
    },
    {
        "review": {
            "id": "56nypSpCFR",
            "forum": "gMLQwKDY3N",
            "replyto": "gMLQwKDY3N",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5040/Reviewer_kypk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5040/Reviewer_kypk"
            ],
            "content": {
                "summary": {
                    "value": "With the rapid development of Large Language Models (LLMs), these models are capable of generating human-like text, posing various risks such as the proliferation of false information on the Internet and the infringement of copyrights on creative works. Therefore, texts generated by LLMs need to be detectable and taggable. Existing watermarking algorithms are mostly public, requiring the detector to use the secret key employed in the watermark generation process, which exposes the method to vulnerabilities as attackers can easily remove and forge the text watermarks. To address these shortcomings, the authors propose a novel private watermarking algorithm designed specifically for LLMs. The approach uses two separate neural networks for watermark generation and detection, eliminating the dependency on a single secret key across both stages. The security of this method is enhanced through computational asymmetry, making it significantly more challenging to reverse-engineer the watermark generation algorithm from the detector. To reduce the complexity of training, the authors also introduced a technique to share token embedding parameters between the detector and the generator. Extensive experiments validate the efficacy of the proposed method, demonstrating nearly equivalent performance to public watermark algorithms while proving its resilience against two mentioned attacks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The authors successfully identify the limitations inherent in existing public watermarking methods. They introduce a novel private watermarking approach that employs separate generation and detection models. This design transition from a public key to a private key significantly enhances the security of the watermarking process.\n2. The authors offer a suitable explanation in Section 4.3, \"Watermark Detection,\" to address the limitation of deep learning models in maintaining a static watermarked token ratio \u03b3. The empirical validation of this explanation is provided in Section 5.6, \"Watermark Generation Network Analysis.\"\n3. While the performance of the proposed method under different datasets and models does not exceed that of public watermarking methods, the authors provide a plausible explanation for this discrepancy. Despite this, their method achieves competitive performance.\n4. Regarding the strategy of shared embedding, the authors have validated its effectiveness through comprehensive ablation experiments in Section 5.3, \"Analysis of Shared Embedding.\""
                },
                "weaknesses": {
                    "value": "1. While the authors have identified the security flaws in public watermark methods, the discussion lacks specific references or examples of existing attack methods. To further bolster the superiority of their proposed approach, the authors might need to include comparative assessments against how public watermark methods fare against the two types of attacks discussed in Section 4.5, \"Analysis of Privacy.\"\n2. The last paragraph in Section 4.4, \"Watermark Detection Network,\" regarding the construction of a cyclic document, is somewhat vague. A more detailed explanation, ideally supplemented with concrete examples, would enhance the clarity of this segment."
                },
                "questions": {
                    "value": "1.& 2. The first two points are as mentioned in the weaknesses section.\n\n3. It would be informative if the authors could elucidate the reasoning behind choosing LSTM networks for the Detection Network, especially when more advanced models are available."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5040/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5040/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5040/Reviewer_kypk"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5040/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698158943951,
            "cdate": 1698158943951,
            "tmdate": 1699636493640,
            "mdate": 1699636493640,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5SKs27CgqG",
                "forum": "gMLQwKDY3N",
                "replyto": "56nypSpCFR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5040/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5040/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## About the privacy of public watermark methods \n\nThank you for your question. \n\nFirstly, please refer to first response in \"Responses to all reviewers\". We appreciate the concerns raised by reviewers seaW and CjAu regarding the definition of 'private watermark'. Indeed, we acknowledge the potential confusion in using this term to describe our method. Consequently, we have renamed our approach from 'A private watermark' to 'An Unforgeable Publicly Verifiable Watermark for Large Language Models'. It means that our proposed watermarking method could be publicly verified by a third-party detector, and even under this scenario, the watermark cannot be easily forged by an untrustworthy detector.  In other words, the previous concept \"privacy\" is interpreted more clearly as \"unforgeablity\" under third-party detection. \n\nMoreover, previous work that used shared key in both watermarking and detection process are referred to as key-based method, while our detection approach is named as network-based method. All related concepts in the updated version of our paper have been revised accordingly.\n\nUnder this concept, the question \"about the privacy of public watermark method\" will be interpreted as \"about the unforgeability of key-based methods\". In a third-party detection scenario, the shared key used in key-based methods are exposed to the public.  Therefore, the key could be used to directly forge the watermark with no need of any attacks. That is, the key-based methods have no unforgeability.\n\nYou might get confused about why we leverage spoofing attack and reverse engineering attack to test unforgeability of our watermarking method. That is because, by using our network-based detecting method, there is no watermark generation details (such as the watermark key) exposed to public. Therefore, if an attacker wants to acquire the watermark generation details and then use it to forge watermark, they could only try using sophisticated analysis such as spoofing attack and reverse engineering attack mentioned in our paper.\n\nWe greatly appreciate your query and have clarified these issues in the updated version of our PDF.\n\n# About the cyclic document\n\nConsider a sentence $t$ with tokens $A B C D E F$. When the window size is 3, the labeling of each token is as follows: $C: \\mathcal{W}(ABC) = \\text{watermarked(green)}$, $D:  \\mathcal{W}(BCD) = \\text{not watermarked(red)}$, $E:  \\mathcal{W}(CDE) = \\text{watermarked(green)}$, $F:  \\mathcal{W}(DEF) = \\text{watermarked(green)}$. However, without using a cyclic document, tokens A and B remain unlabeled, potentially creating a system vulnerability. For instance, if a user continuously alters the last token (here, F) and observes the detection confidence $\\mathcal{D}(t = ABCDE?)$ of the network, a clear score distinction between watermarked and unwatermarked tokens emerges. If the user tests four characters and finds $\\mathcal{D}(t = ABCDEA) \\approx \\mathcal{D}(t = ABCDEB) > \\mathcal{D}(t = ABCDEC) \\approx \\mathcal{D}(t = ABCDED)$, it's easy to infer that with DE as a prefix, A and B are watermarked tokens, while C and D are not.\n\nTo address this vulnerability, we set the entire document as a cyclic document. We label the beginning token A as $\\mathcal{W}(EFA)$ and B as $\\mathcal{W}(FAB)$, ensuring each token has a corresponding label and thereby avoiding the aforementioned vulnerability.\n\nThank you for your question. We have updated our PDF with the above content in its updated version (appendix F).\n\n\n# The selection of LSTM network\n\nThe primary reason for selecting LSTM is that the input to the watermark detector is a variable-length sequence, and LSTM is a relatively classic RNN structure capable of processing such sequences. Although models like Transformer could be considered, we did not pursue further selection or optimization in this direction because the performance of LSTM was already satisfactory for our purposes. This lack of deliberate choice and optimization in network architecture also suggests that there is still room for improvement in our method.\n\n\n## Reference\n\nKirchenbauer, et al. \"A watermark for large language models.\""
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5040/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699955873588,
                "cdate": 1699955873588,
                "tmdate": 1700120924334,
                "mdate": 1700120924334,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "NNlcF2i0t2",
            "forum": "gMLQwKDY3N",
            "replyto": "gMLQwKDY3N",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5040/Reviewer_seaW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5040/Reviewer_seaW"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a new watermarking scheme for LLMs using two separate neural networks. The proposed watermarking method preserves the privacy of the secret key since watermark detection does not require the secret key used in watermark generation. The authors show via empirical results that the watermark detection method achieves a high detection rate."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper has the following strengths: \n+ The authors propose a new private watermarking scheme that disentangles watermark generation and watermark detection. This addresses the privacy concern of requiring the secret key in watermark detection. \n+ Empirical results show that it's difficult to reverse watermark generation from watermark detection, and also the proposed detection method achieves high detection rate."
                },
                "weaknesses": {
                    "value": "The paper has the following weaknesses:\n- The contribution of the private watermarking scheme is not clearly justified. If the designer wants to protect the secret key, he can use a public key encryption scheme to design the watermarking scheme. Particularly, they can use a secret key in watermark generation, and a public key for watermark detection. It's not clear why the designer has to use two neural networks for watermark generation/detection.  \n- There is no clear discussion about how watermark generation and the watermark detection model are trained. There is no explanation about the loss function used either. Alg.1 assumes watermark generation network W as input while it's not clear how W is trained in the first place.  \n- The results shown in Section 5 are not comprehensive. It's not clear whether watermark generation has negative impacts on the main task of the LLM and this is not measured. For existing DL watermarking schemes, there is a fidelity requirement on the watermark embedding which shall be measured as part of performance evaluation. Please consider define the criteria for LLM watermarking and report the results in the paper."
                },
                "questions": {
                    "value": "Please address the weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5040/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5040/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5040/Reviewer_seaW"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5040/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698627617852,
            "cdate": 1698627617852,
            "tmdate": 1699636493536,
            "mdate": 1699636493536,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hGv4VaUQXa",
                "forum": "gMLQwKDY3N",
                "replyto": "NNlcF2i0t2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5040/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5040/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## The contribution of the private watermarking\n\nPlease refer to first response in \"Responses to all reviewers\".\n\nWe acknowledge the potential confusion in using \"private watermark\" to describe our method. Consequently, we have renamed our approach from 'A private watermark' to 'An Unforgeable Publicly Verifiable Watermark for Large Language Models.' All related concepts in the updated version of our paper have been revised accordingly. Next, we will thoroughly explain the contribution of our \"unforgeable publicly verifiable watermark\".\n\nYou have mentioned that a public key encryption algorithm could easily achieve the public verifiability. We assume the \"public key encryption\" refers to integrating methods like asymmetric encryption or digital signatures, which employ public-private keys into watermark algorithms. While these methods sound promising, its implementation in the context of large model watermarks is not straightforward. And most importantly, it is hard to design a public key encryption algorithm that can make the watermark unforgeable.  \n\nFor example, in a recent work, Fairoze et al. (published after the ICLR submission deadline) use digital signature technology to achieve public verifiability. However, in the watermark detection process, they still require extracting the watermark features first and then use the public key to verify them. Therefore, under a third-party public detection scenario, the extracted watermark features are exposed to public,  which can be directly used to forge watermark. \n\nOur method, however, has unique advantages. Users can only get from our detection network whether a text contains a watermark, without knowing the specific generation details of the watermark. Thus, while the method you propose is an admirable vision, integrating this idea into the watermarking domain is highly challenging, and currently, no feasible solutions exist. \n\nWe believe our approach remains irreplaceable in the unforgeable publicly verifiable watermark domain, contributing uniquely to this field.\n\nWe welcome further discussion on this topic.\n\n\n## Training detail of watermark generation and detection network\n\nThank you very much for your detailed question. Indeed, we did not elaborate on all the training details of the watermark generation and detection networks in the original text. However, we have thoroughly described the network architecture, input, and output in the original text. Moreover, the hyperparameters related to network training have already been introduced in  section 4.\nOverall, the training of both networks does not involve any particularly unique tricks. We will provide a detailed introduction here, and this information has already been added to the updated version of the PDF.\n\nRegarding the watermark generation network, firstly, for a token within a window size, an embedding network is used to generate its representation. This embedding network is a fully connected network. Then, all tokens within that window size are concatenated and passed through another fully connected network, which performs a binary classification. This involves first using a sigmoid function followed by binary cross-entropy loss. The formula can be represented as follows:\n\n$$ L_g = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\cdot \\log(\\sigma(W(x_{n-w+1:n}))) + (1 - y_i) \\cdot \\log(1 - \\sigma(W(x_{n-w+1:n}))) \\right] $$\n\nFor the watermark detection network, the process is quite similar. The representation of each token to be detected is generated using an embedding network. Then, all these representations are fed into an LSTM network. The output of this network undergoes a binary classification. The formula for this is:\n\n$$ L_d= -\\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\cdot \\log(\\sigma(D(x)_i)) + (1 - y_i) \\cdot \\log(1 - \\sigma(D(x)_i)) \\right] $$\n\n\n## Impact of watermark on text quality\n\nPlease refer to forth response in \"Responses to all reviewers\".\n\n## Reference\n\nKirchenbauer, et al. \"A watermark for large language models.\"\n\nFairoze, et al. \"Publicly Detectable Watermarking for Language Models.\""
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5040/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699955831490,
                "cdate": 1699955831490,
                "tmdate": 1700120421525,
                "mdate": 1700120421525,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "I8Xl7ftmeS",
            "forum": "gMLQwKDY3N",
            "replyto": "gMLQwKDY3N",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5040/Reviewer_CjAu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5040/Reviewer_CjAu"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a private watermarking method for large language models that allows the public verification of a watermark by using two verification keys, one of which can be released publicly. The authors propose an algorithm involving an LSTM to generate the watermarked text and show that their watermark is effective and difficult to reverse-engineer."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The experimentation section is thorough, although it could be explained better\n\n* The authors tackle an important and timely problem of watermarking language models.\n\n* The idea of splitting the generation and verification watermarking key is interesting"
                },
                "weaknesses": {
                    "value": "**Unclear Definition of Private Watermarking** \n\nSome statements are confusing. For example, on p1, the authors write the following. \n> However, current watermarking algorithms are all public, which means the detection of watermarks requires the key from the watermark generation process. \n\nBut then, the authors state that any watermarking method can be made private by limiting who has access to this detection key (also p1).\n\n> Although Kirchenbauer et al. (2023) have suggested that the watermark detection process could be placed\nbehind the web API to achieve the effect of private watermarking, this approach requires substantial\nserver resources and robust designs against hacking (even social engineering). \n\nHence, there is a trivial method to make watermarking algorithms private, meaning that not all watermarking methods are public. I am confused by the author's definition of a private and public watermark. I understand the general idea of separate keys for generating and verifying a watermark, but could the authors please elaborate on their definition of a private watermark? Why is their method not public (as the definition used by Kirchenbauer [A] suggests: A watermark is public if anyone can detect a watermark in text). \n\n**Imprecise Language**\n\n* What does \"cracking the watermarking rules\" mean? Are the authors referring to the integrity of their watermarks? \n* What does it mean to \"implement watermarking in a privacy-preserving manner\"? \n* What are \"definite labels\" (p9)? \n\n**Robustness**\n\nThe authors' focus appears to be on the effectiveness and privacy of their watermark, and they do not study its robustness. An attacker who can verify a watermark in any text sequence should be much more capable of removing the watermark. Why did the authors not evaluate robustness? What good is a watermark that is not robust? Even if the watermark is not robust, I would appreciate it if the authors included these experiments showing their watermark's limitations. \n\n\n**Minor Questions**\n\n* What does FFN stand for in EQ 2?\n\n* How many parameters does the LSTM have?\n\n* In EQ 3, is \"P\" supposed to be the probability? Earlier, it was defined to be the logit score.\n\n* In EQ 8, what is $f$? \n--------\n[A]\u00a0Kirchenbauer, J., Geiping, J., Wen, Y., Katz, J., Miers, I., & Goldstein, T. (2023). A watermark for large language models. arXiv preprint arXiv:2301.10226."
                },
                "questions": {
                    "value": "* Please clarify the motivation and definitions of \"privacy\". Why are existing watermarking methods not private? \n\n* How robust is your watermark?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5040/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5040/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5040/Reviewer_CjAu"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5040/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698786386068,
            "cdate": 1698786386068,
            "tmdate": 1700685837204,
            "mdate": 1700685837204,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "zYWIrJ7Q8Y",
                "forum": "gMLQwKDY3N",
                "replyto": "I8Xl7ftmeS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5040/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5040/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## Unclear Definition of Private Watermarking\n\nPlease refer to first response in \"Responses to all reviewers\".\n\nThe objective of the private watermark is to detect of the watermark without revealing watermark generation details.  This is valuable because if the key is exposed, others can forge the watermark.  \n\nAlthough Kirchenbauer et al. (2023) claim that the key can be concealed within an API for subsequent services, this approach still relies on the generation key for detection, disqualifying it as a true private watermark algorithm.  Furthermore, it's important to note that hiding watermark generation details at the algorithmic level does not contradict to additional system design (API).\n\nA relatable analogy is with asymmetric encryption algorithms like RSA, where encryption is done with a private key, but decryption uses a public key. In contrast, symmetric encryption algorithms might employ a key for encryption and offer an API service using the same key for decryption, mimicking asymmetric decryption. However, this is not genuine asymmetric encoding, as decryption still requires the encryption key.\n\nHosting the decryption or watermark detection process on servers introduces additional complications, such as costly API fees, the need to secure servers against hacking, and trust issues with the service provider. For instance, consider a scenario where an entity accused of generating inappropriate texts is brought to court. It would be unreasonable to rely on the same entity to verify the texts through watermark detection.\n\nWe welcome further discussion on this topic.\n\n## Explain the \"cracking the watermarking rules\"\n\nThe watermarking rules essentially provides rules on how watermarking is generated.  For instance, in the algorithm of Kirchenbauer et al. (2023), watermarking is implemented by dividing the vocabulary into green (watermarked) and red (unwatermarked) lists, then increasing the probability of tokens from the green list at each generation step. The rule here refers to the partition of the green and red list. For example, in Kirchenbauer et al. (2023), for a window size of 2, determining which tokens follow the prefix token 'there' and belong to the green list constitutes a rule.\n\n'Cracking the watermarking rules' fundamentally means inferring these specific rules directly, rather than obtaining the watermark's key.  For example, in Sadasivan et al. (2023), a spoofing attack could deduce a specific watermark rule by analyzing word frequency within watermarked texts. If a watermarking algorithm's rules can be easily deduced by such methods, it is essentially not a private algorithm. \n\nA good private watermark algorithm could not hide the generation key but also robust to the attacks that try to crack the watermarking rules.\n\n## About the \"implement watermarking in a privacy-preserving manner\"\n\nThank you for your question. \"Privacy-preserving manner\" refers to the ability to detect watermarks without needing the key used in the watermark generation process. Indeed, we acknowledge that the original statement was somewhat confusing. We have clarified this point in the revised PDF provided.\n\n## What are \"definite labels\" (p9)?\n\nIn our context, 'definite labels' refer to labels with high confidence levels, where the label here refers to whether a text contains a watermark. The corresponding z-scores for data with 'definite labels' significantly deviate from the threshold value used in the public z-score based detection.  \n\n## About robustness\n\nPlease refer to third response in \"Responses to all reviewers\" and the table5 in the updated PDF version.\n\n## What does FFN stand for in EQ 2?\n\nThe term \"FFN\" here refers to a fully connected classification network. We apologize for any confusion caused and have provided a revised explanation in the updated version of the PDF.\n\n## How many parameters does the LSTM have?\n\nOur LSTM only comprises five layers, with an input dimension of 64 for each unit, an intermediate output dimension of 128, and a final output dimension of 1 for the output logits. \n\nTherefore, the parameters of LSTM are negligible compared to those of large language models.\n\n## In EQ 3, is \"P\" supposed to be the probability? Earlier, it was defined to be the logit score.\n\nP indeed represents probability, and P_n was previously used to denote a special probability symbol. However, considering potential confusion, we have now adopted L_n to represent logits. This change has been clarified in the updated version of our PDF.\n\n## In EQ 8, what is f ?\n\nIn this context, 'f' represents an ideal generation network, corresponding to the 'g' function mentioned in EQ9, where 'g' refers to an ideal detection network. Our aim here is to demonstrate that training 'g' using 'f' is significantly simpler than the reverse process of training 'f' using 'g', which forms the basis of our algorithm's privacy. Thank you for your question; we have addressed this point in the revised version of our PDF."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5040/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699955761999,
                "cdate": 1699955761999,
                "tmdate": 1699955796564,
                "mdate": 1699955796564,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "R2E6VodmYn",
                "forum": "gMLQwKDY3N",
                "replyto": "zYWIrJ7Q8Y",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5040/Reviewer_CjAu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5040/Reviewer_CjAu"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your rebuttal."
                    },
                    "comment": {
                        "value": "Thank you for addressing my questions in your rebuttal. Your answers clarified the paper a lot! I still have some questions left. \n\n> The objective of the private watermark is to detect of the watermark without revealing watermark generation details. This is valuable because if the key is exposed, others can forge the watermark.\n\nI have some problems with this definition. First, it only specifies the objective of \"private\" watermarking, but does not define it. Second, it is potentially confusing, because the term \"watermark generation details\" is not clearly defined. What are watermark generation details? What are \"watermark rules\"? I do not want to sound pedantic, but this has confused me when I first read the paper and I think it will also confuse other readers. \n\nAs stated in my review, Kirchenbauer et al.'s definitions make sense to me: A watermark is public if anyone can invoke the watermark detection functionality, and it is private if that access is restricted. The fact that an attacker cannot generate their own watermarked text is an interesting property of your method that arises from the use of two separate keys. In that sense, I still believe your watermark should be called a \"public\" watermark. Also, the paper that you linked by Fairoze et al. refer to their watermark as \"public verifiable\", which makes sense to me. They refer to a \"public\" and a \"private\" key, inspired by asymmetric encryption and their notation avoids confusion with the already existing term of \"private watermarking\". \n\n## Threat Model \n\nI think the paper needs a proper threat model section describing the attacker's and defender's capabilities and goals. That would clarify the claims made. Does the attacker have access to similar performing open-source models? Is the attacker limited in the number of queries they can make to the watermarked model? When do you consider your method \"broken\", i.e., when does it lack robustness (attacker can remove the watermark) or integrity (attacker can generate watermarked text)? When do you consider two texts to be \"different\"? All these questions have to be answered in the paper. \n\n## Robustness \n\nThank you for providing results on the robustness of your method. It is interesting to see that your watermark has robustness, but in a public detectable watermark, an attacker has more capabilities than \"just\" paraphrasing it. A simple extension would be to extend this attack to \"K\" paraphrasings and then select the best paraphrase. I do not ask the authors to evaluate all these untested attacks, as this would likely extend beyond the scope of this work, but please add this to your limitation section.\n\n## Distillation \n\nRegarding the size of the LSTM, I was wondering whether a small LSTM size makes the model susceptible to distillation-type attacks? Without using the public key, an attacker could sample the model N times and fine-tune a public model to generate watermarked data. Do you have any insights of this attack?"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5040/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700058046329,
                "cdate": 1700058046329,
                "tmdate": 1700058046329,
                "mdate": 1700058046329,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DwfgyM6f2y",
                "forum": "gMLQwKDY3N",
                "replyto": "ZtqhCmQrKk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5040/Reviewer_CjAu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5040/Reviewer_CjAu"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the changes."
                    },
                    "comment": {
                        "value": "Thank you for all the changes that you made to the paper. I believe it is much better already. I still have two concerns.\n\n### Threat Model \n\nI read your threat model in Appendix - G, but it does not answer all of the questions that I raised. Please rewrite the threat model for clarity and ensure that all questions are given an answer. I think the threat model should go into the main part of the paper since it essentially defines the rules of the game. Could you include a proper threat model in Section 3 - Problem Definition? \n\n### Distillation\n\nAs far as I understand,reverse training is different from distillation. For distillation, I would expect to see a graph that shows the number of watermarked samples (obtained from the provider's model) versus the detection accuracy (for some z-score threshold). The attacker simply uses supervised fine-tuning to forge the watermark given many examples. \n\n### Minor\n\n* Please, whenever you refer to the Appendix make sure to refer to the specific subsection.\n* At this point, the number of changes applied to the paper gets to a point where I would encourage the authors to please highlight all changes in some color (not with latexdiff, but just highligh them). This will also make it easier for the other reviewers to see what has changed at a glance."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5040/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700325295959,
                "cdate": 1700325295959,
                "tmdate": 1700325295959,
                "mdate": 1700325295959,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ciFZJAheQf",
                "forum": "gMLQwKDY3N",
                "replyto": "Jz0XFlC8D1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5040/Reviewer_CjAu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5040/Reviewer_CjAu"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your reply"
                    },
                    "comment": {
                        "value": "Thank you for all these modifications. I like the paper and idea and will increase my score."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5040/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700685787783,
                "cdate": 1700685787783,
                "tmdate": 1700685787783,
                "mdate": 1700685787783,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZRLrE2qKi2",
            "forum": "gMLQwKDY3N",
            "replyto": "gMLQwKDY3N",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5040/Reviewer_PMgN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5040/Reviewer_PMgN"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a method for LLM watermarking. It can handle the security breaches and counterfeiting problems of existing LLM watermarking methods caused by secret key, through using two different neural networks for watermark generation and detection. Experiments on two datasets verify the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. LLM watermarking is a very important problem.\n\n2. The proposed method can handle the security breaches and counterfeiting problems of existing LLM watermarking methods.\n\n3. The proposed method is effective according to the reported results."
                },
                "weaknesses": {
                    "value": "1. Please correct me if I am wrong. It seems that there is no comparison with baseline methods in terms of both watermarking effectiveness and text generation quality.\n\n2. It is not clear whether text edit methods like paraphrase can make the proposed method invalid."
                },
                "questions": {
                    "value": "Are your methods robust to text edit methods like paraphrase?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5040/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5040/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5040/Reviewer_PMgN"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5040/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698841318330,
            "cdate": 1698841318330,
            "tmdate": 1699636493357,
            "mdate": 1699636493357,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PvvTcDYGJF",
                "forum": "gMLQwKDY3N",
                "replyto": "ZRLrE2qKi2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5040/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5040/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## About Baseline Comparison\n\nRelated responses: please refer to the second and forth responses in \"Responses to all reviewers\".\n\nThe key-based detection method in Table1 is the same to the KGW watermark algorithm by Kirchenbauer et al. (2023).\n\nThis implies that Table 1 compares the watermark detection accuracy of Kirchenbauer et al. (2023) (denoted as 'key-based') with our unforgeable watermark algorithm.  And due to the lack of alternative unforgeable watermark algorithms, we did not conduct direct comparisons with other unforgeable watermark methods.\n\nMoreover, since our watermark generation method is almost identical to that of Kirchenbauer et al. (2023), the impact on text quality should be exact the same to Kirchenbauer et al. (2023).\n\nDespite this, we have demonstrated in Figure 2(b) the variation of detection F1 score and PPL with changes in the $\\delta$ parameter. In our method, the $\\delta$ hyperparameter is set to 2, indicating that our approach achieves high detection accuracy without significantly affecting text quality.\n\nWe have also conducted analysis of text quality changes in machine translation task, affirming that our watermarking method does not significantly impact text quality. More details in the forth response in \"Responses to all reviewers\".\n\nThe updated PDF version now includes additional clarifications and descriptions.\n\n## About robustness to paraphrase attack\n\nPlease refer to third reply in \"to all reviewers\" and the table4 in the updated PDF version.\n\n## Reference\n\nKirchenbauer, et al. \"A watermark for large language models.\""
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5040/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699955693118,
                "cdate": 1699955693118,
                "tmdate": 1700120379265,
                "mdate": 1700120379265,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]