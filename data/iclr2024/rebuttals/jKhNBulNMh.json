[
    {
        "title": "Rethinking Branching on Exact Combinatorial Optimization Solver: The First Deep Symbolic Discovery Framework"
    },
    {
        "review": {
            "id": "ExpSiXmB9r",
            "forum": "jKhNBulNMh",
            "replyto": "jKhNBulNMh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5144/Reviewer_hTDx"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5144/Reviewer_hTDx"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces Symb4CO, the first symbolic discovery framework, to learn high-performance symbolic policies on the branching task in CO solvers. Symb4CO's CPU-based strategies match the performance of top GPU-based methods. With efficient training, quick inference, and clear interpretability, Symb4CO offers a promising way to integrate machine learning into modern CO solvers."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The problem the paper is trying to address is important. Indeed, we should have a light-weight machine learning approach to facilitate CO solvers. The directions that the author tries to improve, including requiring less training data and producing interpretable policies, are reasonable to me. \n2. The authors of Symb4CO apply reinforcement learning to make training efficient with much less data needed."
                },
                "weaknesses": {
                    "value": "1. Symb4CO, although data efficient during the training, requires feature extraction by human. I have concerns about if the extracted features are expressive enough, and how much efforts does it take for these feature extractions. Does it really the so-called training efficient?\n2. From the experimental results, I can observe that GPU based GNN approach can make CO solvers perform faster than CPU based Symb4CO. The overall goal is to facilitate CO solvers in efficiency, if GPU based approach can facilitate it more, than why not prefer GPU based approach? Besides, today\u2019s machine can make very fast GPU-CPU interactions. I think we should be open to bringing in machine learning models inside CO solvers (not just adding the learned interpretable policies inside CO solvers) and making use of GPU\u2019s high computation to facilitate logical reasoning tools."
                },
                "questions": {
                    "value": "Please refer to the questions in the weakness section"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5144/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5144/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5144/Reviewer_hTDx"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5144/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698628000835,
            "cdate": 1698628000835,
            "tmdate": 1699636508207,
            "mdate": 1699636508207,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "G8X1zfmrLw",
                "forum": "jKhNBulNMh",
                "replyto": "ExpSiXmB9r",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5144/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5144/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer hTDx (Part 1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the positive and insightful comments. **We are actively improving our paper by your valuable comments**. We respond to each comment as follows and sincerely hope that our rebuttal could properly address your concerns. If so, **we would deeply appreciate it if you could further raise your score**. If not, please let us know your further concerns if any, and we will continue actively responding to your comments and improving our submission.\n\n## Q1: How about the human effort for feature extractions?\n\nVery insightful question! The question is also asked by Reviewer z5TX. We think the effort for feature extractions is affordable in the branching task (and in many other tasks in the field of combinatorial optimization) due to the extensive existing research in combinatorial optimization (CO) solvers. Human-designed features are *widely* used in learning-based approaches in tasks like branching [1], node selection [2], and cut selection [3]. Even the bipartite graph states employed in the branching task contain 25 human-designed features in the constraints, variables, and edges [4]. \n\nIn fact, during our approach design, we did consider generating features automatically from bipartite graphs based on symbolic models for graph neural networks (GNNs) [5,6]. However, we found three challenges that make the task *non-trivial*:\n- First, processing bipartite graphs via symbolic models requires complex computation by traversing the entire graph, and the complexity grows linearly with the number of layers we consider. This might be extremely expensive for inference on purely CPU-based devices compared with human-designed features. \n- Second, existing approaches learn such symbolic models by symbolize the components in GNN one by one, which results in very high training overhead compared to the lightweight Symb4CO (see Table C11 in our Appendix for the training overhead of Symb4CO). \n- Finally, most experiments conducted in previous research [5,6] implicitly assume the message flow passed by GNN carries a specific physical mechanism, which ensures that the message-passing function is sparse enough for symbolizing. However, the message flow in the branching task might not satisfy this assumption. \n\nWe note that our approach is the *first* step towards automated algorithm discovery on modern solvers. Based on your insight question, we fully agree the automated design of input features for different tasks (e.g., branching, cut selection, and primal heuristics)  is an *exciting avenue* for future work!\n\n## Q2: Are the extracted features expressive enough?\n\nThank you for the question. These features have been proved expressive in previous research [1,7]. The features are first proposed in [1] based on the domain knowledge and previous research in [8,9,10]. These features include static ones describing the input MILP problem and dynamic ones representing the status of the solver at current node, both of which contain human-designed structural information about the bipartite graph. Previous research uses these features to train support vector machines [1] and hybrid deep learning models [7] and achieves high performance on purely CPU-based devices. The bipartite graph features, though contain rich information, require graph neural networks (GNNs) to embed it via time-consuming message passing. Previous research [7] uses the embedded features at root nodes as the input of the hybrid model, but introducing these features might reduce the interpretability of the learned symbolic policies in our paper.\n\n## Q3: Is it really so-called training efficient?\n\nThank you for the question. As we compared in Figure 1(a) and Table 2 in our main paper, Symb4CO is significantly more efficient for training than all the other learning-based approaches. We use only *1\u2030* MILP instances to achieve performance comparable to previous state-of-the-art approaches. This is mainly because the symbolic policies are highly lightweight and the use of symbolic operators can be regarded as enforcing strong regularizations. We believe this feature of Symb4CO will *significantly* facilitate its application to real-world tasks."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700318690209,
                "cdate": 1700318690209,
                "tmdate": 1700319917106,
                "mdate": 1700319917106,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Hj5xwCZ1Oq",
                "forum": "jKhNBulNMh",
                "replyto": "ExpSiXmB9r",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5144/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5144/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer hTDx (Part 2/2)"
                    },
                    "comment": {
                        "value": "## Q4: Further discussions on deploying ML models with GPU.\n\nVery thoughtful suggestion! We fully agree that researchers in this field should be open to the newest models and hardware, and there are many interesting recent papers aiming to do that [11,12,13,14]. In this paper, two reasons make symbolic policies necessary:\n\n-   Ease for real-world applications. There are two ways to distribute the learning-based CO solvers, while neither of them are GPU-friendly:\n    -   For deployment to personal users, we can not assume their accessibility to high-end GPU devices, especially for users from the field of traditional mathematical optimization. \n    -   For deployment to cloud services, we note that the inference in branching is taken at significantly high frequency. Thus, when multiple MILPs are solved in parallel, instead of packing the inputs into a batch, we have to initialize independent neural networks for each separate job to avoid the severe blocking (see Table below and results reported in [8]), which results in high cost for cloud services.\n-   The goal of automatical algorithm/principle discovery. Though the idea of incorporating ML to modern CO sovlers is widely accepted in recent years, research that simply replaces the hard-coded components in CO solvers to \"black-box\" neural networks struggles to help us understand these tasks from the perspective of combinatorial optimization research. However, symbolic policies help us further understand what matters in these tasks, and thus, help researchers to further discover new algorithms/principles for these problems.\n\nOther reasons why symbolic policies without GPU are necessary are reported in our main paper. In conclusion, compared to previous research, our work provides an entirely *new perspective* of the research in machine learning for combinatorial optimization (ML4CO). We believe our work will strongly contribute to the *wide* application of learning-based approaches to modern CO solvers.\n\n| Number of Parallel Tasks | Inference Time (ms) via Initializing Seperated GNNs on a Tesla V100 GPU | Inference Time (ms) via Batch on a Tesla V100 GPU |\n| ------------------------ | ------------------------------------------------------------ | ------------------------------------------------- |\n| 1| 5.4| 5.4|\n| 4| 7.3| 6.1|\n| 9| 12.6| 6.1|\n| 16| 15.3| 6.2|\n| 25| 19.0| 6.3|\n\n\n## References\n\n[1] Khalil, Elias, et al. \"Learning to branch in mixed integer programming.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 30. No. 1. 2016.\n\n[2] He, He, Hal Daume III, and Jason M. Eisner. \"Learning to search in branch and bound algorithms.\" Advances in neural information processing systems 27 (2014).\n\n[3] Huang, Zeren, et al. \"Learning to select cuts for efficient mixed-integer programming.\" Pattern Recognition 123 (2022): 108353.\n\n[4] Gasse, Maxime, et al. \"Exact combinatorial optimization with graph convolutional neural networks.\" Advances in neural information processing systems 32 (2019).\n\n[5] Cranmer, Miles, et al. \"Discovering symbolic models from deep learning with inductive biases.\" Advances in Neural Information Processing Systems 33 (2020): 17429-17442.\n\n[6] Shi, Hongzhi, et al. \"Learning Symbolic Models for Graph-structured Physical Mechanism.\" The Eleventh International Conference on Learning Representations. 2022.\n\n[7] Gupta, Prateek, et al. \"Hybrid models for learning to branch.\" Advances in neural information processing systems 33 (2020): 18087-18097.\n\n[8] Achterberg, Tobias, and Timo Berthold. \"Hybrid branching.\" Integration of AI and OR Techniques in Constraint Programming for Combinatorial Optimization Problems: 6th International Conference, CPAIOR 2009 Pittsburgh, PA, USA, May 27-31, 2009 Proceedings 6. Springer Berlin Heidelberg, 2009.\n\n[9] Marcos Alvarez, Alejandro, Quentin Louveaux, and Louis Wehenkel. \"A supervised machine learning approach to variable branching in branch-and-bound.\" (2014).\n\n[10] Patel, Jagat, and John W. Chinneck. \"Active-constraint variable ordering for faster feasibility of mixed integer linear programs.\" Mathematical Programming 110 (2007): 445-474.\n\n[11] Wang, Zhihai, et al. \"Learning Cut Selection for Mixed-Integer Linear Programming via Hierarchical Sequence Model.\" The Eleventh International Conference on Learning Representations. 2022.\n\n[12] Fan, Zhenan, et al. \"Smart Initial Basis Selection for Linear Programs.\" International conference on machine learning. PMLR, 2023.\n\n[13] Paulus, Max B., and Andreas Krause. \"Learning To Dive In Branch And Bound.\" *Thirty-seventh Conference on Neural Information Processing Systems*. 2023.\n\n[14] Li, Yang, et al. \"From distribution learning in training to gradient search in testing for combinatorial optimization.\" *Thirty-seventh Conference on Neural Information Processing Systems*. 2023."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700319779680,
                "cdate": 1700319779680,
                "tmdate": 1700319931125,
                "mdate": 1700319931125,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1Xr82UH1r2",
                "forum": "jKhNBulNMh",
                "replyto": "Hj5xwCZ1Oq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5144/Reviewer_hTDx"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5144/Reviewer_hTDx"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response. I think the future directions would be 1) improving the efficiency of GPU based inference, such as lightweight ML model, less frequent online inference or even offline inference, etc; 2) automating the feature extraction without human efforts. I suggest incorporating the content of your reply into the discussion section of your upcoming paper revision. I would like to keep my current score."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700586943510,
                "cdate": 1700586943510,
                "tmdate": 1700586943510,
                "mdate": 1700586943510,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "CocO36fJkU",
            "forum": "jKhNBulNMh",
            "replyto": "jKhNBulNMh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5144/Reviewer_dfwS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5144/Reviewer_dfwS"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces an approach that combines the advantages of using machine learning (ML) and human-designed policies in solving combinatorial optimization (CO) problems. Symb4CO leverages deep symbolic optimization to learn interpretable symbolic expressions, transforming complex ML models into compact and efficient decision-making policies. The key strengths of Symb4CO lie in its efficiency, both in terms of training and inference, making it suitable for practical deployment on CPU-based devices. The paper shows that Symb4CO outperforms existing ML-based and human-designed policies. \n\nNovelty:\nThe paper introduces the concept of using deep symbolic optimization for solving CO problems, specifically focusing on the branching task. This is a novel approach that combines symbolic representations with optimization tasks, making it distinct from traditional machine learning techniques applied to CO problems.It is designed to be highly efficient, particularly in terms of training and inference, and the learned symbolic policies are interpretable. The paper highlights the importance of these features for practical deployment in real-world applications. Symb4CO's ability to perform well on purely CPU-based devices is quite practical. Most previous ML approaches for CO problems require GPU acceleration, but Symb4CO demonstrates that it can achieve comparable performance with CPU-based resources. The paper explores the concept of using compact symbolic policies for CO tasks. This is in contrast to complex machine learning models, which are often resource-intensive. Symb4CO's approach leads to concise, one-line mathematical expressions for decision-making.\n\nImpact:\nThe impact of this work is significant, especially within the field of combinatorial optimization and machine learning. Symb4CO's ability to achieve competitive performance on CPU-based devices with limited training data can make it accessible to a broader range of real-world applications. The emphasis on interpretability in Symb4CO's learned policies addresses a critical concern. Symb4CO's success on CPU-based devices reduces the need for GPU resources. \n\nQuality of writing and experiments:\nThe quality of writing in the paper needs improvement. Here are some detailed comments:\n- Section 4.3 talks about the fitness function, which is a crucial part of the training pipeline. So, it would be helpful to expand on the explanation of Equation 2. \n- Since the authors use an FSB-based fitness function, why does the FSB model perform so poorly (Table 1) compared to their tool?\n- Table 2 mentions the use of one training instance. How was this training instance chosen? How do the results vary if a different training instance was chosen? Providing a standard deviation in Table 2 would be helpful. Similarly, how were the ten instances chosen (Section 5.1)?\n- Authors mention discovering more complex working flows like RPB can be an interesting future work. Since RPB is compared against in Table 1, why do the authors think RPB performs so poorly compared to Symb4CO?\n- In Section 5, what is the reason for using 1-shifted geometric mean?\n- The interpretability claim in Section 5.2 needs some clarity. E.g., \"RPB ... uses a scoring function with human-designed features and expressions rather than vanilla pseudocosts.\" Why is this relevant to the interpretability claim?\n- How do the authors ensure the output expression from the RNN (Figure 2) is syntactically correct?\n- Providing a concrete example and comparing the results with some of the other tools might be helpful to improve clarity.\n- RNNs are usually not considered suitable for long-term sequences. How did the authors tackle that problem? How long are the output expressions from the RNN model?\n- Part 3 in Figure 2 is challenging to understand. The fitness measure can include concrete values to improve clarity. \n\nAblation studies explore the choice of mathematical operators and constants. Nevertheless, I believe it is important to address the following questions as well:\n- Section 4.2 briefly mentions applying constraints during the training process. How is the length constraint implemented? Do the authors allow only a fixed length? Was there any ablation performed for the use of this constraint?\n- Section 3.2 talks about 80% masking, but Section 4.1 mentions using all 91 features. How is the masking performed during training and evaluation across different benchmarks? Were any ablation studies performed on a different subset of features?\n- How sensitive is the approach to different hyperparameter choices for the sequential model?\n- Comment on the scalability of the approach. Do medium and hard problems have significantly larger search spaces? \n\nAdditional comments:\n- Out of curiosity, did the authors explore the extent to which the learned symbolic policies generalize across different problem domains within combinatorial optimization? For example, test the policies trained on one benchmark on a different but related benchmark to assess their transferability.\n- The paper discusses the efficiency and interpretability of Symb4CO. Can the authors provide insights into any trade-offs when prioritizing efficiency and simplicity over complex but potentially more accurate models?\n\nMinor nitpick - Expand FSB in Figure 2 as it has not been used till page 3\n\nReview summary:\nThe paper introduces Symb4CO, a novel approach for solving combinatorial optimization problems by combining machine learning and interpretable symbolic expressions. It leverages deep symbolic optimization to generate efficient and interpretable decision-making policies. Symb4CO is highly efficient for inference, making it suitable for CPU-based devices. The paper provides a comprehensive experimental evaluation, demonstrating its superiority over existing methods. The key strengths include its innovative use of deep symbolic optimization, efficiency, interpretability, and the potential for real-world applications. However, the paper could benefit from improved clarity, expanded related work discussion, and addressing potential limitations. The ablation studies exploring mathematical operators and constants are valuable, but additional questions and considerations should be addressed for a more comprehensive understanding."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Symb4CO is shown to be efficient, both in terms of training and inference, making it suitable for deployment in real-world scenarios on CPU-based devices.\n\n- The paper emphasizes the interpretability of Symb4CO's learned symbolic expressions.\n\n- The paper presents a thorough experimental evaluation, comparing Symb4CO with various baselines and showcasing its superior performance in terms of training efficiency, inference efficiency, and overall effectiveness."
                },
                "weaknesses": {
                    "value": "- The paper could benefit from improved clarity and organization. I will expand more on this in the following few sections.\n\n- The discussion of related work is quite brief and could be expanded to provide a more comprehensive overview of existing approaches and how Symb4CO differentiates itself.\n\n- While the paper discusses the limitations of previous ML approaches, it needs to address the potential limitations of Symb4CO. A dedicated section on drawbacks or areas for future improvement would enhance the paper's completeness."
                },
                "questions": {
                    "value": "- Out of curiosity, did the authors explore the extent to which the learned symbolic policies generalize across different problem domains within combinatorial optimization? For example, test the policies trained on one benchmark on a different but related benchmark to assess their transferability.\n- The paper discusses the efficiency and interpretability of Symb4CO. Can the authors provide insights into any trade-offs when prioritizing efficiency and simplicity over complex but potentially more accurate models?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5144/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5144/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5144/Reviewer_dfwS"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5144/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698816016836,
            "cdate": 1698816016836,
            "tmdate": 1699636508106,
            "mdate": 1699636508106,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "QFgId01E1V",
                "forum": "jKhNBulNMh",
                "replyto": "CocO36fJkU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5144/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5144/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer dfwS (Part 1/5)"
                    },
                    "comment": {
                        "value": "We deeply appreciate your very positive and insightful comments. **We are actively improving our paper by your valuable feedback**. We respond to each comment as follows and sincerely hope that our rebuttal could properly address your concerns. If so, **we would deeply appreciate it** **if you could further raise your score**. If not, please let us know your further concerns if any, and we will continue actively responding to your comments and improving our submission.\n\n## Q1: Please provide detailed explanations of the fitness function and include concrete values to improve clarity in Figure 2 Part 3.\n\nThank you for the constructive suggestion! We have revised the Part 3 of Figure 2 and the explanation of Equation (2) in our main paper to provide more details. Specifically, the fitness measure is simply defined as: if the branching variable selected by the symbolic policy has the highest full strong branching (FSB) score, then its fitness is $1$ on this sample. Otherwise, the fitness of this symbolic policy is $0$ on this sample. Then, the fitness of this symbolic policy is its average fitness over the given expert dataset $\\mathcal{D}$. We found this simple fitness measure works well enough in this paper.\n\n## Q2: Why does the full strong branching (FSB) policy perform so poorly?\n\nThank you for the question. The main reason is that FSB need to branch and solve child nodes on all branching variables to calculate their FSB scores before selecting the best one, which usually produces small B&B trees [1] but suffers a significantly high computational cost. The FSB score in SCIP is typically defined as $v=\\max (q^{-},\\epsilon)\\cdot\\max(q^{+},\\epsilon)$ [2], where $q^{-}, q^{+}$ are the dual bound changes of the two children compared to their parent and $\\epsilon=10^{-6}$. Thus, it has to calculate $q^{+}, q^{-}$ for *each* branching variable at each B&B node repeatedly by solving the child nodes of each branching variable. The FSB policy is usually used as a strong but extremely slow policy to generate expert demonstrations.\n\n## Q3: How was the single training instance chosen in Table 2 and how were the ten training instances chosen in Table 1? Please provide a standard deviation in Table 2.\n\nThank you for the question. A similar question is also raised by Reviewer z5TX. We generate 10,000 Easy instances per benchmark using the official instance generation code provided in [1] to train the other ML baselines, and we randomly sample ten to train Symb4CO in Table 1 and randomly sample one to train Symb4CO-1 in Table 2. We report the performance of Symb4CO trained with only one instance sampled via three different random seeds and the corresponding learned policies in table below. Results show that Symb4CO *consistently* outperforms the human-designed state-of-the-art (SOTA) branching policy reliability pseudocost (RPB). Furthermore, we found the symbolic policies trained with only one instance, though still maintain high performance, have more complex forms than that trained with ten instances. A potential reason is that learning a sparse policy with only key features and operators is challenging when the training data is extremely insufficient.\n\n| Model           | Time (s)      | Nodes           | Expression                                                   |\n|-|-|-|-|\n| RPB| 3.00| 26.2||\n| Symb4CO-1-Seed0 | 1.72| 116.1| $$(2s_{89}+s_9 s_{17} s_{54} + s_9 + \\exp(s_{16} s_{65} s_{89}))^{s_{85}}$$ |\n| Symb4CO-1-Seed1 | 2.05| 167.0| $$s_{84} + \\exp(s_{89} (s_{86} + s_{89}s_{34} (s_{17} + s_{86} (s_{89} +   (s_{85} + s_{85} s_{89} ^ {2s_{85}} ) )) ))$$ |\n| Symb4CO-1-Seed2 | 1.67| 131.5| $$ s_{33}(s_{89} + s_{89} (s_{89} + \\exp(s_{50} + s_{90} + s_{90}(s_{9}   s_{45} + s_{89}))^{s_{89}}) )^{s_{35}} $$ |\n| Average| 1.81$\\pm$0.17 | 138. 2$\\pm$21.3 ||\n\n## Q4: Why does RPB perform so poorly compared to Symb4CO?\n\nThoughtful question! Intuitively, the RPB policy is an enhanced version of the pseudocost branching (PB) policy, which warm started with strong branching when a variable is regarded as \"unreliable\" due to the insufficient updates of its pseudocost. However, this warm start is typically time-consuming as it needs to branch and take simplex iterations on child nodes for the unreliable branching variables. Instead, the learned symbolic policies are warm started in advance via historical data, and no strong branching is required during its execution. Thus, Symb4CO significantly outperforms RPB due to its high branching accuracy and the avoidance of the overhead for strong branching during the solving process."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700321466894,
                "cdate": 1700321466894,
                "tmdate": 1700321466894,
                "mdate": 1700321466894,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RDU4M2BynP",
                "forum": "jKhNBulNMh",
                "replyto": "CocO36fJkU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5144/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5144/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer dfwS (Part 2/5)"
                    },
                    "comment": {
                        "value": "## Q5: What is the reason for using 1-shifted geometric mean?\n\nThank you for the question. The 1-shifted geometric mean is *widely* used to evaluate solvers due to its two distinct advantages [2]. First, compared with the arithmetic mean (i.e., $\\text{Mean}(v_1, \\ldots, v_k)=\\frac{1}{k} \\sum_{i=1}^k v_i$), it prevents the hard instances from dominating the results. Second, compared with the vanilla geometric mean (i.e., $\\text{Mean}(v_1, \\ldots, v_k)=(\\prod_{i=1}^k \\max \\{v_i, 1\\}t)^{\\frac{1}{k}}$), it reduces the strong influence of very small values. Thus, it is widely used for the performance evaluation in classical mathematical optimization research [2], learning-based approaches [1,3], the famous LP and MILP benchmarks [4] released by Hans Mittelmann, etc.\n\n## Q6: The interpretability claim in Section 5.2 needs some clarity.\n\nThank you for the constructive suggestion! We have revised Section 5.2 in our main paper to provide more clarity. Specifically, the classical RPB policy employs the *pseudocost* as the scoring function to sort the branching variables and employs the strong branching to warm start \"unreliable\" variables [2]. However, SCIP 6.0 employs a complex *human-designed* scoring function rather than the vanilla pseudocost function, whose input features include the pseudocost, the conflict score, the cutoff score, the inference score, and etc (see Line 373 in branch_relpscost.c in the source codes of SCIP 6.0). We observe that the intuition behind the design of this scoring function is highly similar to that in our paper, while our symbolic policies are learned automatically without any human design. Thus, we believe the learned symbolic policies in this paper can further help researchers to refine the scoring function in RPB and other human-designed working flows in modern CO solvers.\n\n## Q7: How to ensure the RNN outputs are syntactically correct?\n\nInsightful question! We employ multiple constraints to ensure the correctness of RNN outputs [5]. Detailed descriptions of these constraints can be found in Section 4.2, including the length constraints, the inverse operator constraints, and the non-trivial expression constraints. These constraints are enough to ensure the correctness of RNN outputs syntactically, but generally, they do not provide any guarantee of mathematical correctness. For example, we can not guarantee that the expression $\\log(\\boldsymbol{s}_0)$ is always mathematically correct, as the range of the input feature $\\boldsymbol{s}_0$ can not be inferred by the RNN in advance. However, during the training process, these types of expressions always appear only in initial iterations, as they can not select enough correct branching variables on the training set $\\mathcal{D}$ when they are mathematically incorrect.\n\n## Q8: Please provide a concrete example and compare the results with other tools.\n\nThank you for the suggestion. In our main paper, the illustrations on the challenges, the motivations, and the ablations are *consistently* based on the concrete benchmark combinatorial auction (Cautions). Specifically, the results in Figure 1 on Cauctions show the limitations of current learning-based approaches on training, inference, and interpretability; the results in Figure 1.(c) on Cauctions indicate the existence of compact branching policies; and the ablations in Table 6 on Cauctions show that Symb4CO is relatively stable to the different choices of mathematical operators and constants. We choose Cauctions for all illustrations since both the training (see Table C9) and the evaluation (see Table 1 and Table 2) on this benchmark is very fast.\n\n## Q9: How long are the learned symbolic policies? Is RNN suitable for long-term expressions?\n\nThis is a very thoughtful question! The lengths of the learned symbolic policies are 45, 19, 55, and 49 on benchmarks Setcover, Cauctions, Facilities, and Indset, respectively. These lengths are slightly longer than the simplified versions reported in Table 5, as expressions like $x+x+x+x+x$ can be simplified to $5x$. \n\nConsistent to the thoughtful question, recent research in the field of symbolic regression employs advanced sequential models like Transformer to learn complex expressions [6,7]. However, in this paper, we empirically found that a simple RNN performs well enough. A key result to support this claim is that the imitation learning accuracy of the symbolic policies learned by RNN is very close to that of MLP models (Table 3). Moreover, we note that rather than employing complex symbolic regression models, the main contribution of our submission is the first symbolic-based automated algorithm discovery framework on exact combinatorial optimization (CO) solvers. We fully agree refining the sequential model for more complex tasks is an *exciting avenue* for future work!"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322266310,
                "cdate": 1700322266310,
                "tmdate": 1700322266310,
                "mdate": 1700322266310,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MSBLWlVaFE",
                "forum": "jKhNBulNMh",
                "replyto": "CocO36fJkU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5144/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5144/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer dfwS (Part 3/5)"
                    },
                    "comment": {
                        "value": "## Q10: How is the length constraint implemented? Do the authors allow only a fixed length? Was there any ablation performed for the use of this constraint?\n\nThank you for raising this point. The hyperparameters used for the length constraints are reported in Table  C8 in Appendix. We further revised Appendix C to provide more details about the implementation.  Specifically, there are two types of length constraints implemented in our paper following the implementations in previous research [5,7].\n\n-   The *hard* length constraints limit the output expressions to a specific range by zeroing out the probabilities of tokens that would violate the constraint. Specifically, it sets the probabilities of leaf nodes (i.e., tokens of variables and constants whose degree of children is zero) to zero if the output expression is shorter than the minimal length and sets the probabilities of non-leaf nodes (i.e., tokens of mathematical operators) to zero if the output expression is longer than expected. We set the minimal and the maximal length to 4 and 64, respectively, in this paper.\n-   The *soft* length prior limits the lengths of the initial outputs of RNN not to concentrate at extreme points by adding a priori distribution to the outputs [7]. This priori distribution encourages non-leaf nodes when the expression is shorter than the soft length (i.e., $\\lambda=20$) and encourages leaf nodes when the expression is longer than the soft length. Intuitively, the motivation of the soft prior is somewhat similar to the entropy regularizer widely used in reinforcement learning [9]. \n\nWe set these hyperparameters empirically without grid search, and they worked well enough in our experiments. Based on your insightful suggestion, we further conducted ablations on the maximal hard length constraint and the soft length prior and report the results below (and to our Appendix C). Results show that Symb4CO is relatively *insensitive* to the soft length prior, while too short hard length constraint could cause decreased performance.\n\n| Hyperparameters   (on Setcover) | Imitation Learning Accuracy |\n|-|-|\n| Default| 47.7|\n| Maximal Length = 16| 43.3|\n| Maximal Length = 32| 45.1|\n| Maximal Length = 128| 47.4|\n| Soft Length = 10| 47.4|\n| Soft Length = 40| 47.7|\n\n## Q11: How is the masking performed during training and evaluation across different benchmarks?\n\nSorry for the misunderstanding. The masking technique is only used in Section 3.2 as a preliminary experiment to analyse the underlying structure of the mapping between inputs and decisions, which motivates us to employ symbolic optimization to learn a simple and compact branching policy. Symb4CO proposed in Section 3 uses a *complete* set of branching features designed in [8] for all benchmarks, and it can select input features that are effective in different benchmarks automatically.\n\n## Q12: How sensitive is the approach to different hyperparameter choices for the sequential model?\n\nThank you for the question. The hyperparameters used in the sequential model are all listed in Table C8 in Appendix. They are set to the default ones employed in [5,6] without additional tuning, as we believe that the underlying branching policies are simple and compact. These default hyperparameters work well enough in our experiments, as it achieves comparable imitation learning accuracy to MLP models. These results also indicate that Symb4CO is insensitive to the hyperparameter choices of the sequential model.\n\n##  Q13: Is Symb4CO scalable? Do medium and hard problems have significantly larger search spaces?\n\nThank you for the question. Yes, Symb4CO is scalable to larger instances based on the experiments provided in Table 1 in our main paper. Specifically, we train Symb4CO only on Easy datasets and directly transfer them to Medium and Hard datasets. The end-to-end evaluation on time in Table 1 shows that the policies learned on Easy datasets keep high performance on larger datasets. \n\nThe search space for problems of different sizes is the same, as the learned symbolic branching policy is just a scoring function for each branching variable. Different sizes of the problem only affect the number of branching variables at each B&B node, but do not affect the search space of the symbolic policies."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700324067593,
                "cdate": 1700324067593,
                "tmdate": 1700324067593,
                "mdate": 1700324067593,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "I8G4SUYqtc",
                "forum": "jKhNBulNMh",
                "replyto": "CocO36fJkU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5144/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5144/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer dfwS (Part 4/5)"
                    },
                    "comment": {
                        "value": "## Q14: How about the generalization ability of the symbolic policies across different benchmarks?\n\nVery **constructive** question! We did not conduct this experiment since the learned symbolic policies in Table 5 in our main paper seem to be totally different, and it is widely recognized that learning-based approaches tend to fail at out of distribution data. \n\nHowever, we surprisingly found that symbolic policies trained on one benchmark can usually generalize well to another benchmark! See the bold values in the table below (time: $s$), and we also added these new results to Appendix E. A potential reason is that the learned symbolic policies are very compact and their parameters are very sparse, which effectively improves the generalization ability of these policies.\n\nBased on these results and your constructive question, we *highly* believe that training a cross-benchmark symbolic policy---though might not achieve the best learning accuracy on specific data distributions---to replace the SOTA human-designed scoring function in the RPB policy, is a *very promising avenue* for future work!\n\n| Benchmark\\Policy From | SetCover  | Cauctions | Facilities | Indset    | RPB (Default) |\n| - |-|-|-|-|-|\n| Setcover| **7.10**| 21.90| **9.13**| 12.10| 11.40|\n| Cauctions| **1.81**| **1.57**| **1.82**| **2.36**| 3.00|\n| Facilities| **46.44** | 65.07| **37.76**| **38.40** | 54.05|\n| Indset| **22.28** | **22.16** | 66.08| **29.21** | 42.69|\n\n## Q15: How about the trade-off between simple and efficient models and complex but more accurate models?\n\nThis is a very insightful question! A similar question is also raised by Reviewer z5TX. As described in Appendix C, we deploy the learned symbolic policies to the CO solver at depths 0-16 and switch back to the default RPB policy when depth is larger than 16 to accelerate performance on hard instances. The main reason for such implementation is the trade-off between efficiency and accuracy. Specifically, we found:\n\n-   The accuracy of pseudocost gradually increases to comparable to the learned ones at the deep layers of the tree. This is mainly because: a) the pseudocost in deep layers is *fully* updated after enough node expansions; b) the number of branching candidates is monotonically decreasing with the depth, making the task easier in deep layers. \n-   The deep layers of the B&B tree contain a large number of nodes, thus the inference efficiency is more crucial in these layers. We note that RPB policy is faster than symbolic policies in these layers as it reduces to almost purely pseudocost branching (PB) policy. In contrast, learned-based approaches still require extracting features for each branching variable. GNN&GPU-based approaches do not implement such technique due to their higher learning accuracy achieved by complex neural networks together with their faster inference speed achieved by high-end GPUs.\n\nTo further illustrate these observations, we report on Setcover: a) the decision time and the normalized full strong branching (FSB) score of these policies in different depths in Table 1 below; b) the end-to-end performance of Symb4CO when employed for all layers (Symb4CO-AllLayers) in Table 2 below; c) the curve of the normalized FSB scores v.s. different depths in Figure C3 in our Appendix.\n\n| Model:| Symb4CO|| RPB||\n|-|-|-|-|-|\n| Depth/Max Number of B&B Nodes | Normalized FSB score | Decision Time (ms) | Normalized FSB score of the PB function | Decision Time (ms) |\n| 0/1| 0.728| 56.8000| 0.144| 1300.5199|\n| 4/16| 0.766| 26.3000| 0.154| 571.3723|\n| 8/256| 0.853| 14.1000| 0.262| 52.0601|\n| 12/4096| 0.888| 12.8486| 0.309| 27.8487|\n| 16/65536| 0.667| 9.9025| 0.667| 8.5889|\n\n| Setcover:| Easy| | Medium| | Hard| |\n|-|-|-|-|-|-|-|\n| Model| Time| Nodes| Time| Nodes| Time| Nodes|\n| RPB| 11.40| **212.5** | 100.32| 6116.0| 1911.32| 117450.0|\n| Symb4CO| 7.10| 304.7| **86.92** | 5623.2| **1894.38** | 129231.6|\n| Symb4CO-AllLayers | **6.96** | 297.4| 93.40| **5587.6** | 1943.41| **113149.5** |\n\nThus, simply switching the symbolic policy to RPB is a very *simple and efficient* way to address this trade-off! \n\nA one-step further idea to address this trade-off is to employ GNNs, MLPs, and our symbolic policies together and deploy different models at different layers of the B&B tree. However, rather than employing complex implementations to achieve higher performance, our submission mainly focuses on the ease of deployment and the high interpretability. Thus, we simply employ the technique mentioned above in our paper for this trade-off.\n\n## Q16: The abbreviation of FSB in Figure 2 Part 1.\n\nThank you for pointing it out. We have revised this in Figure 2 of our main paper. We are improving our paper with your valuable suggestions!"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700325002023,
                "cdate": 1700325002023,
                "tmdate": 1700325002023,
                "mdate": 1700325002023,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GRmhb9ccUL",
                "forum": "jKhNBulNMh",
                "replyto": "CocO36fJkU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5144/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5144/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer dfwS (Part 5/5)"
                    },
                    "comment": {
                        "value": "## Q18: A dedicated section on drawbacks and future work.\n\nThank you for this very constructive suggestion! We briefly discussed the limitations and the future work in Section 6 (Conclusion and Future Work) in our main paper. Based on the analysis in our submission and the insightful suggestions from all the reviewers, we further provide more discussions in Appendix E. Specifically, we conclude three exciting challenges and their corresponding exciting future work as follows:\n\n-   Automated feature generation. Though the features used in this paper are simple to obtain and effective in practice, the automated feature generation is still promising future work to further help us reduce the domain knowledge for feature design, understand the underlying characteristics of this task, and deploy Symb4CO to more tasks in the field of mathematical optimization.\n-   Cross-benchmark symbolic policy for general CO problems. Based on the results in Q14, we highly believe that training a cross-benchmark symbolic policy---though might not achieve the best learning accuracy on specific data distributions---to replace the human-designed general-purpose scoring function in the RPB policy, is a very promising avenue for future work.\n-   Graph inputs and GPU-based symbolic policies. Bipartite graph is widely used to formulate a series of combinatorial optimization (CO) problems, handling these inputs is a further step towards general algorithm discovery system for CO problems. Deploying symbolic policies on high-end GPUs (when available) can further accelerate the inference speed of these policies.\n\n\n\n## References\n\n[1] Gasse, Maxime, et al. \"Exact combinatorial optimization with graph convolutional neural networks.\" *Advances in neural information processing systems* 32 (2019).\n\n[2] Achterberg, Tobias. \"Constraint integer programming.\" (2007).\n\n[3] Gupta, Prateek, et al. \"Hybrid models for learning to branch.\" *Advances in neural information processing systems* 33 (2020): 18087-18097.\n\n[4] \u201cASU Benchmark Page.\u201d Plato.asu.edu. Accessed 13 Nov. 2023. https://plato.asu.edu/bench.html.\n\n[5] Petersen, Brenden K., et al. \"Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients.\" *International Conference on Learning Representations*. 2020.\n\n[6] O\u2019Neill, Michael. \"Riccardo Poli, William B. Langdon, Nicholas F. McPhee: A Field Guide to Genetic Programming: Lulu. com, 2008, 250 pp, ISBN 978-1-4092-0073-4.\" (2009): 229-230.\n\n[7] Landajuela, Mikel, et al. \"Discovering symbolic policies with deep reinforcement learning.\" *International Conference on* *Machine Learning*. PMLR, 2021.\n\n[8] Khalil, Elias, et al. \"Learning to branch in mixed integer programming.\" *Proceedings of the AAAI Conference on* *Artificial Intelligence*. Vol. 30. No. 1. 2016.\n\n[9] Haarnoja, Tuomas, et al. \"Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor.\" *International conference on* *machine learning*. PMLR, 2018."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700325307650,
                "cdate": 1700325307650,
                "tmdate": 1700325307650,
                "mdate": 1700325307650,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "67nZdZlZ0z",
            "forum": "jKhNBulNMh",
            "replyto": "jKhNBulNMh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5144/Reviewer_z5TX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5144/Reviewer_z5TX"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduce a neural-symbolic approach to discover branching heuristics for MILP solving. Instead of directly using a neural network as the branching heuristics, they propose to use a neural network to predict a symbolic expression, which is more efficient to invoke online."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The idea of not directly using a neural network for branching prediction, but rather using it to produce a symbolic expression is quite interesting and plausible.\n- The paper shows a substantial performance gain over the other methods."
                },
                "weaknesses": {
                    "value": "- The paper relies on manual feature extraction. This leaves open the question what are useful features, which is difficult to answer. Presumably the choice of the features are dependent on the particular benchmarks and can have significant impact on the performance. I get that the alternative deep representation makes the inference more expensive though.\n- It is unclear how the training instances are selected and how similar to the test/validation instances the training instances are."
                },
                "questions": {
                    "value": "- In the experiments, are the proposed branching heuristics invoked at each node, or only the top node?\n- What is the cost of the training?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5144/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699257994941,
            "cdate": 1699257994941,
            "tmdate": 1699636507936,
            "mdate": 1699636507936,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "z8W2Oplw6b",
                "forum": "jKhNBulNMh",
                "replyto": "67nZdZlZ0z",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5144/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5144/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer z5TX (Part 1/3)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the positive and insightful comments. **We are actively improving our paper by your valuable comments**. We respond to each comment as follows and sincerely hope that our rebuttal could properly address your concerns. If so, **we would deeply appreciate it if you could further raise your score**. If not, please let us know your further concerns if any, and we will continue actively responding to your comments and improving our submission.\n\n## Q1: Discussions on the feature selection.\n\nThank you for the insightful question! The question is also raised by Reviewer hTDx. In fact, human-designed features are widely used in learning-based approaches in tasks like branching [1], node selection [2], and cut selection [3]. Even the bipartite graph states in the branching task contain 25 human-designed features in the nodes and edges [4]. Thanks to the extensive classical research in combinatorial optimization (CO) [5,6,7,8,9], designing useful features for each task are not so challenging, and previous learning-based research [1,10] have proved the effectiveness of the features employed in our paper. As expected by the reviewer, the useful features depend on particular benchmarks, but an appealing feature of Symb4CO is that it can automatically select a subset of useful features in its learned expressions (as reported in Table 5 in our main paper). \n\nDuring our approach design, we did consider generating features automatically from bipartite graphs based on symbolic models for graph neural networks (GNNs) [11,12]. However, we found three challenges that make the task *non-trivial*:\n- First, processing bipartite graphs via symbolic models requires complex computation by traversing the entire graph, and the complexity grows linearly with the number of layers we consider. This might be extremely expensive for inference on purely CPU-based devices compared with human-designed features. \n- Second, existing approaches learn such symbolic models by symbolize the components in GNN one by one, which results in very high training overhead compared to the lightweight Symb4CO. \n- Finally, most experiments conducted in previous research [11,12] implicitly assume the message flow passed by GNN carries a specific physical mechanism, which ensures that the message-passing function is sparse enough for symbolizing. However, the message flow in the branching task might not satisfy this assumption. \n\nOur approach is the *first* step towards automated algorithm discovery on modern solvers. Based on your insight comment, we fully believe that the automatic design of input features for different tasks (e.g., branching, cut selection, and primal heuristics) is an *exciting avenue* for future work!\n\n## Q2: How are the training instances selected and what is the similarity between the training and test data?\n\nThank you for the question. The instances are selected following the same setting in previous work [4, 10], and these training and test (Easy) datasets are widely recognized as independent and identically distributed. Moreover, for each of these benchmarks, we establish three distinct difficulty levels: Easy, Medium, and Hard, which are generated via different hyperparameter settings used in the instance generation code [4]. You can find detailed information about these hyperparameters in Table D9, Appendix D. During training, we generate 10,000 Easy instances per benchmark to train the ML baselines and randomly select ten to train Symb4CO. During validation, we generate an additional 2,000 Easy instances for the ML baselines and randomly choose four for Symb4CO. During evaluation, we generate 80 instances for each difficulty level (Easy, Medium, and Hard) in each benchmark, resulting in a total of 240 instances per benchmark. In summary, the training, validation, and evaluation instances of the same benchmark all belong to the same problem families and are generated using the same algorithm with different hyperparameters to control the levels of difficulty."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700317543253,
                "cdate": 1700317543253,
                "tmdate": 1700317543253,
                "mdate": 1700317543253,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aVQ7dyKbDB",
                "forum": "jKhNBulNMh",
                "replyto": "z8W2Oplw6b",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5144/Reviewer_z5TX"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5144/Reviewer_z5TX"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarifications. I'd like to keep my score."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700581178702,
                "cdate": 1700581178702,
                "tmdate": 1700581178702,
                "mdate": 1700581178702,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]