[
    {
        "title": "Out-of-Distribution Detection by Leveraging Between-Layer Transformation Smoothness"
    },
    {
        "review": {
            "id": "58wLTdimwQ",
            "forum": "AcRfzLS6se",
            "replyto": "AcRfzLS6se",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3628/Reviewer_ELpL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3628/Reviewer_ELpL"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed a white-box OOD detection method: BLOOD, by using the fact that the tendency of between-layer representation transformations of ID data is smoother than the corresponding transformations of OOD data for Transformer network.\n\n-Hypothesis: During the model\u2019s training, smooth transformations between DNN layers are learned, which corresponds to natural and meaningful progressions between abstractions for ID data. And these progressions will not match OOD data, so the transformations will not be smooth.\n\n-The smoothness is defined as the difference of the mapping between the current representation its infinitesimally close neighbourhood's representation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Looking at the smoothness of the layer is novel and hasn't been explored in prior research for OOD detection.\n\n2. An unbiased estimator for the smoothness is proposed to reduce the computation.\n\n3. BLOOD demonstrates superior performance over various OOD detection methods for RoBERTa and ELECTRA in text classification datasets."
                },
                "weaknesses": {
                    "value": "1. The experiments exclusively focus on Transformer-based models and text classification. I am curious about the performance of BLOOD when applied to image classification datasets and Convolutional Neural Networks (CNNs). Additionally, the study lacks a comparison with the latest state-of-the-art methods for out-of-distribution (OOD) detection in CNNs, such as ASH (Extremely Simple Activation Shaping for Out-of-Distribution Detection, ICLR23), ReAct (ReAct: Out-of-distribution Detection With Rectified Activations, NeurIPS21), and DICE (DICE: Leveraging Sparsification for Out-of-Distribution Detection, ECCV2022). Furthermore, there is no analysis provided to explain why the concept of BLOOD is restricted to text classification and not applicable to other domains.\n\n2. While Figure 1 qualitatively illustrates the smoothness difference, the author did not offer an explanation for the observed difference between in-distribution (ID) and out-of-distribution (OOD) data. I wonder whether there is an analysis or understanding of this phenomenon, specifically why the learned progressions on ID data do not align with OOD data and how to define this misalignment."
                },
                "questions": {
                    "value": "Please see the weaknesses section, I am willing to raise my rating if the author can addresses those issues."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3628/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3628/Reviewer_ELpL",
                        "ICLR.cc/2024/Conference/Submission3628/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3628/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698659261701,
            "cdate": 1698659261701,
            "tmdate": 1700708060321,
            "mdate": 1700708060321,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6Y4spA5bH6",
                "forum": "AcRfzLS6se",
                "replyto": "58wLTdimwQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3628/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3628/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 4"
                    },
                    "comment": {
                        "value": "Thank you for your constructive and helpful comments. We are glad you took notice of the novelty of our work and the usefulness of the estimator we proposed. We will be addressing your comments below in the order they appear in the review:\n\n**1) CV experiments** - Please see our General Response and Updates to the Paper.\n\n**2) More SOTA baselines** - Please see our General Response and Updates to the Paper.\n\n**3) Explanation of difference in smoothness** - On the operational level, BLOOD works because the learning algorithm learns the smooth transitions for the data it was trained on, while the rest of the representation space is either left largely unchanged (if the task was simple enough) or sharpened as the byproduct of trying to fit the more complex data, as we showed in the paper.\nWe introduced the intuition and motivation for our method in subsection 3.2. Our intuition is based on the phenomenon known from the literature that different Transformer layers model features at different levels of abstraction. Since the model learns on the ID training data, it should learn the natural progression between the layers of abstractions inherent to the task, i.e., ID data. However, the unseen OOD data will likely have different features in a given level of abstraction than the ID data since the nature of the data is different, so the model is not familiar with them or their progression. Because the model has not learned how to handle the mismatch in the transition between the levels of abstraction, it exhibits sharper between-layer transformations of those representations, i.e., there is a more considerable difference between how OOD representations get mapped onto the next layer and how its infinitesimally small neighborhood gets mapped.\n\nWe hope you find our response helpful. If there are any other questions you would like to ask, we would be glad to answer them."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3628/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700413474956,
                "cdate": 1700413474956,
                "tmdate": 1700416016020,
                "mdate": 1700416016020,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EQ19CV7p98",
                "forum": "AcRfzLS6se",
                "replyto": "6Y4spA5bH6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3628/Reviewer_ELpL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3628/Reviewer_ELpL"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your rebuttal. It addresses some of my concerns. I have revised my score to 6. In the additional experiments, I notice that BLOOD loses its effectiveness when combined with CNNs, but preserves its effectiveness on Transformer.  It would be good if the authors can provide some analysis on discrepancies in the smoothness metric for CNNs and Transformers."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3628/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700708040195,
                "cdate": 1700708040195,
                "tmdate": 1700708040195,
                "mdate": 1700708040195,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5dMEXlwkPP",
            "forum": "AcRfzLS6se",
            "replyto": "AcRfzLS6se",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3628/Reviewer_woCv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3628/Reviewer_woCv"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new OOD detection method called BLOOD, designed for a white-box setting where only pre-trained weights and model architectures are accessible, but without access to training data. It leverages the smoothness of between-layer representation transformations in ID data compared to OOD data. The method is evaluated using datasets for text classification tasks, demonstrating its superior performance over other methods with comparable resource requirements."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The authors propose a novel and effective scoring method for OOD detection based on the smoothness between Transformer layers that is applicable to pretrained models without access to training data. They provide a detailed performance analysis, including both strengths and limitations. The paper also presents an interesting finding regarding the relationship between smoothness and the complexity of the training dataset. The paper is well-organized and clearly written overall."
                },
                "weaknesses": {
                    "value": "The proposed method does not perform competitively on simpler datasets, such as those with fewer classes in ID, or semantic shift as OODs. This inconsistency in performance across different datasets and settings suggests that relying solely on the smoothness of the representation may not be fully optimal for general OOD detection tasks. \n\nIn Table 2, the calculated effect size is greater in the \u201cMean\u201d approach than in the \u201cLast\u201d approach, which appears to contradict the results in Table 1."
                },
                "questions": {
                    "value": "- In Section 4.3, there are certain inconsistencies in the presented results (e.g., RoBERTa model on the MG and NG datasets), which seem to challenge the hypotheses by the authors. Given the variations in performance, can you provide additional evidence or discussion, such as whether certain architectures or settings are preferred by the proposed method? \n- I\u2019m curious if BLOOD can be extended to open-box settings. \n- Is it possible to apply BLOOD to OOD detection tasks in computer vision? Any insights or preliminary findings on this would be valuable. \n- Could you provide more detailed explanation of how the CLES measurements in Tables 2 and 3 were computed?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3628/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698660406422,
            "cdate": 1698660406422,
            "tmdate": 1699636318231,
            "mdate": 1699636318231,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XHAx7dUgUr",
                "forum": "AcRfzLS6se",
                "replyto": "5dMEXlwkPP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3628/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3628/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 3 (1/2)"
                    },
                    "comment": {
                        "value": "Thank you for showing interest in our paper with many thought-provoking questions. We are glad you enjoyed the thorough analysis of our method and our findings on smoothness in DNNs. We respond to your questions and comments in order of how they appear in the review:\n\n**1) There are scenarios in which BLOOD is outperformed by other OOD methods** - It is true that in certain scenarios BLOOD is outperformed by other popular OOD detection methods, e.g., for simpler training datasets or semantic shifts. However, the performance boosts in the scenarios suitable for BLOOD are significant (e.g., 12.09 percentage points AUROC better than the second-best white-box method for BigPatent dataset with ELECTRA). That is precisely why we carried out an extensive analysis of when BLOOD outperforms other methods and why it outperforms them when it does. Researchers and engineers must be able to make an educated choice when deciding on the suitable OOD detection method for their problem, and that is why we believe it is essential to showcase both the strengths and limitations of our work.\n\n**2) Table 2 contradicts Tabe 1** - No, that is as expected. A lower CLES implies a higher AUROC because the learning algorithm has sharpened the OOD region of representation space along with the smoothening of the ID region instead of just smoothening the ID region. That emphasizes the difference in smoothness between ID and OOD data. And since the learning algorithm had to \u201cinvest more work\u201d in the last layers (as seen in Table 1), it sharpened the OOD region of representation space as a byproduct, leading to lower CLES for the last layer and higher AUROC when using the last layer.\nThe reasoning behind the CLES of lower vs. higher layers is parallel to the reasoning behind the CLES of simpler vs. more complex datasets. If a dataset is more complex, the learning algorithm changes the model more during training, which, instead of just focusing on the ID region of the representation space, also makes changes to the OOD region of the representation space as a byproduct. Similarly, in higher layers, which are more influenced by the learning algorithm, there are more changes in the OOD region of space.\n\nBecause of that, the only instances where CLES in the last layer is larger than the CLES_mean for RoBERTa is for theMG and NG datasets, which are exactly the datasets on which BLOOD_{mean} outperforms BLOOD_{L-1} on RoBERTa.\n\n**3)  Relationship between BLOOD_mean and BLOOD_{L-1}** - Please see our General Response and Updates to the Paper.\n\n**4) BLOOD in an open-box setting** - While we focused on the white-box scenarios because of the wider useability of our method, we are thankful for this great suggestion. \nWe experimented with extending BLOOD by using a small sample of OOD examples to learn the optimal parameters for OOD detection (as is done by many popular OOD methods), e.g., learn the optimal weights for the weighted average of scores in different layers. We used a validation set of 5% of original training sets and fitted a logistic regression to learn the optima weights for a weighted sum of BLOOD values in different layers. This approach generally outperforms the open-box versions of our method. We provide results (AUROC) of this experiment below. We will be adding the results in the Appendix of our paper:\n\n\n| Model   | SST   | SUBJ  | AGN   | TREC  | BP    | AR    | MG    | NG    |\n|---------|-------|-------|-------|-------|-------|-------|-------|-------|\n| RoBERTa | 73.94 | 82.98 | 81.39 | 91.73 | 93.47 | 96.25 | 92.46 | 89.97 |\n| ELECTRA | 77.67 | 77.30 | 82.76 | 98.73 | 96.54 | 91.97 | 90.92 | 85.19 |"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3628/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700415427514,
                "cdate": 1700415427514,
                "tmdate": 1700415427514,
                "mdate": 1700415427514,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "1ZQMYzbZQd",
            "forum": "AcRfzLS6se",
            "replyto": "AcRfzLS6se",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3628/Reviewer_Bnog"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3628/Reviewer_Bnog"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces an out of distribution detection method called BLOOD which measures the transformation smoothness between layers by using the frobenius norm on the jacobian matrix. The proposed approach is then evaluated across several text classification dataset for OOD detection task."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed method is simple and can be easily applied on different tasks and network architectures, where OOD detection is required.\n- The paper is easy to read and overall the paper is well written.\n- The proposed method has been shown to perform well across different text classification datasets in comparison to standard OOD methods."
                },
                "weaknesses": {
                    "value": "- The experimental results are not very strong or convincing. I would have expected some experiments on vision datasets as there has been a significant amount of OOD detection work focussing on vision datasets. Also, this approach can be easily applied on those tasks and will give better understanding how well this approach works.\n- Most of the baselines considered in the comparisons are very old for OOD detection. There has been a significant amount of work focusing on last layer contributions to OOD detection similar to this paper (for eg. [a,b]). The authors should show comparisons against SOTA OOD baselines.\n\n\n\nReferences:\n- [a] Sun et. al. React: Out-of-distribution detection with rectified activations. Neurips, 2021.\n- [b] Djurisic et al. Extremely simple activation shaping for out-of-distribution detection. arXiv preprint arXiv:2209.09858, 2022"
                },
                "questions": {
                    "value": "Please address the weakness mentioned above.\n\nWhy does BLOOD_mean performance significantly worse than the baselines in most of the cases? Whereas in some case it performs better than BLOOD_{L-1}. Can the authors explain that?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3628/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698722875749,
            "cdate": 1698722875749,
            "tmdate": 1699636318148,
            "mdate": 1699636318148,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gJnbhK9sLB",
                "forum": "AcRfzLS6se",
                "replyto": "1ZQMYzbZQd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3628/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3628/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 2"
                    },
                    "comment": {
                        "value": "Thank you for your time and effort in reviewing our paper. We appreciate you finding our paper well-written and our results strong. All other reviewers shared your suggestions, so we acknowledged them in our General Response and Updates to the paper. We provide the summary of our answers below, but please see General Response for more detailed answers:\n\n**1) CV experiments** - BLOOD is competitive and all of the conclusions of our paper hold when applied to vision datasets paired with Vision Transformer. However, when paired with CNNs, BLOOD behaves differently, likely due to differences in how the two architectures process data.\n\n**2) More SOTA baselines** - We expanded our experiments with the suggested methods (ASH and ReAct), however those methods did not retain their SOTA status on the text classification task.\n\n**3) Relationship between BLOOD_mean and BLOOD_{L-1}** - BLOOD_mean introduces noise to the method because it includes BLOOD scores from the lower layer that did not change much during training and thus retain their BLOOD scores from the pre-trained models where there is no difference between ID and OOD data. And since BLOOD scores in the low layers have higher magnitudes, they take over the average. However, for datasets MG and NG on RoBERTa, BLOOD_mean works better than BLOOD_{L-1}. The reasoning behind that is the same (BLOOD scores are kept the same as before training in low layers), but in these scenarios, there exists a priori difference in BLOOD score between ID and OOD data, as seen from Figures 9 and 10.\n\nWe hope you find our answers helpful. If you have any other questions, we would be happy to hear them."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3628/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700412893308,
                "cdate": 1700412893308,
                "tmdate": 1700412893308,
                "mdate": 1700412893308,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "xgTDo14e2j",
            "forum": "AcRfzLS6se",
            "replyto": "AcRfzLS6se",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3628/Reviewer_Txyj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3628/Reviewer_Txyj"
            ],
            "content": {
                "summary": {
                    "value": "This paper tackles OOD detection problems by analyzing the smoothness of the feature transformation between intermediate layers in a network in a pre-trained network. The idea behind the notion of smoothness in this paper extends from Liptischitz continuity. The method is evaluated on popular pre-trained models such as RoBERTa and ELECTRA on multiple texts analysing data sets such as SST, SUBJ, AGN etc. The results are compared with competitive baselines, which demonstrates its effectiveness in most of the cases."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "OOD detection is an important research problem that plays a significant role in developing trustworthy AI. Hence, the paper addresses the problem which can be of interest to a larger audience. \n\nThe method itself relies on the transformation features between the layers, which are estimated from the pre-trained models. Hence, this method does not require labelled examples from downstream tasks which is another strength of this method."
                },
                "weaknesses": {
                    "value": "In the paper, it is mentioned that the method is robust to complex tasks and less competitive for easy tasks. However, the explanations are just based on empirical performance, lacking clear insight and understanding behind such outcomes.  \n\nThis is a similar line of work on OOD detection employing variance of gradients [a], which play a direct role in the smoothness feature transformation in the intermediate roles. \nIt is better this paper acknowledges such works and argues how such methods differ from their proposed method. \n\n[a] Agarwal, Chirag, Daniel D'souza, and Sara Hooker. \"Estimating example difficulty using variance of gradients.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022."
                },
                "questions": {
                    "value": "Please see the weakness.\n\nI wonder how this method would work in vision tasks."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3628/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698866562530,
            "cdate": 1698866562530,
            "tmdate": 1699636318080,
            "mdate": 1699636318080,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "i8HD1a0dgd",
                "forum": "AcRfzLS6se",
                "replyto": "xgTDo14e2j",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3628/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3628/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1"
                    },
                    "comment": {
                        "value": "Thank you for your constructive comments and questions, we are glad you find our work important. We address your questions below, as introduced in your review:\n\n**1) Insights on why BLOOD works better on complex datasets** - In subsection 4.4, we test the hypothesis that BLOOD works better on simpler datasets by simplifying the more complex datasets. In that section, we show that reducing the dataset's complexity leads to an increase in CLES of the change in representations. This implies that the model can fit the data by only focusing on the parts of the representation spaces populated by the ID training data. However, for more complex datasets, the model has to undergo more radical changes during training to fit the data, sharpening the OOD part of the representation space as the byproduct. Because BLOOD compares the smoothness of the ID region and OOD region of the representation space, sharpening the OOD region of the space, along with smoothening the ID region of the space, emphasizes the difference in smoothness.\n\n**2) Acknowledge the \"Estimating example difficulty using variance of gradients (VoG)\"** - Thank you for drawing our attention to this paper. It is an exciting work with slight similarities to our work. However, there are also crucial differences.\nOne conceptual difference is that VoG considers the gradient of the inputs w.r.t. the logit of the true/predicted class (measuring how much the model's predictions vary with small changes in the input), while BLOOD is analyzing the Jacobians of neighboring intermediate layers (quantifying the stability of the intermediate representations during inference).\nAnother practical difference is that VoG calculates the variance of the gradients \u2013 for which it needs the gradients at different timesteps during training. VoG requiring access to the model's training process makes it an open-box method, while BLOOD is a post-hoc white-box method, allowing it to be more widely used.\n\n**3) CV experiments** - Please see our General Response and Updates to the Paper.\n\nWe hope we have addressed all of your questions. If there is anything else you would like to know about our work, please do not hesitate to ask."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3628/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700412799305,
                "cdate": 1700412799305,
                "tmdate": 1700412799305,
                "mdate": 1700412799305,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]