[
    {
        "title": "Disentanglement Learning via Topology"
    },
    {
        "review": {
            "id": "xGgF6MfB2r",
            "forum": "23OEmHVkpq",
            "replyto": "23OEmHVkpq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9426/Reviewer_T3Gf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9426/Reviewer_T3Gf"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors propose a method, named TopDis (Topological Disentanglement), for learning disentangled representations via adding a multi-scale topological loss term. The experiments results show that the proposed TopDis loss improves disentanglement scores such as MIG, FactorVAE score, SAP score and DCI disentanglement score with respect to state-of-the-art results while preserving the reconstruction quality."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This paper is the first to introduce the use of a topological regularization term in the field of disentangled representation learning.\n- The topological regularization term is shown to be effective across multiple VAE models and metrics.\n- The regularization term proposed in this paper is also demonstrated to be effective for discovering pre-trained StyleGAN models."
                },
                "weaknesses": {
                    "value": "- The paper lacks a clear reasonable explanation as to why topological constraints are meaningful/effective for disentanglement representation learning.\n- The new loss function was already proposed in a 2022 ICML paper [a]. The main contribution of this work is applying it to disentanglement, making the explanation of the above issue crucial for this paper.\n- The experiments focus on models with some disentanglement capabilities, but the effectiveness of this regularization term on vanilla VAEs has not been studied.\n- The performance of vanilla VAEs presented in this paper show high DCI performance, but other papers [b] report poor performance instead. A reasonable explanation is needed, and it would be helpful to include evaluation code in the supplementary materials.\n\n[a] Representation Topology Divergence: A method for comparing neural network representations.\n\n[b] \u03b2-VAE: LEARNING BASIC VISUAL CONCEPTS WITH A CONSTRAINED VARIATIONAL FRAMEWORK\n\n[c] Disentangling by Factorising"
                },
                "questions": {
                    "value": "See weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9426/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9426/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9426/Reviewer_T3Gf"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9426/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698576965814,
            "cdate": 1698576965814,
            "tmdate": 1699637187503,
            "mdate": 1699637187503,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4bEM3dPYKa",
                "forum": "23OEmHVkpq",
                "replyto": "xGgF6MfB2r",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9426/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9426/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Review T3Gf #1"
                    },
                    "comment": {
                        "value": "Thank you for your time and the thorough review. We will improve the presentation according to the suggestions. Below we address specific concerns one by one.\n\n__W1__: _The paper lacks a clear reasonable explanation as to why topological constraints are meaningful/effective for disentanglement representation learning._\n\n__A__: Thank you for the feedback. We are adding a clarification deducing the smallness of RTD from the  disentanglement conditions and topological properties of symmetry action.\nHere is the principal explanation.  The Lie group(oid) symmetry $G$ action on the support of data distribution is continuous and invertible. This implies that for any subset of the support of data distribution, the image of the subset under symmetry  $g\\in G$ has the same homology or the same group of topological features. The preservation of topological features at multiple scales can be tested with the help of the representation topology divergence (RTD). If RTD is small between a sample from $X$ and its symmetry shift, then the groups of topological features at multiple scales under such symmetry $G$ action are preserved. \n\nAlso the smallness of RTD implies the smallness of the disentanglement topological measure from (Zhou et al 2021) based on the geometry scores of data subsets conditioned to a fixed value of a latent code. Such subsets for different fixed values of the latent code are also related via the symmetry shift action, and if RTD between them is small, then the distance between their persistence diagrams and hence the metric from loc cit is small as well. \n\n__W2__: _The new loss function was already proposed in a 2022 ICML paper [a]. The main contribution of this work is applying it to disentanglement, making the explanation of the above issue crucial for this paper._\n\n__A__: Thank you for the remark. As we mentioned in Appendix, the paper [a]  describes briefly an application  of topological metric to evaluation of interpretable directions in a simple synthetic dataset. They compare topological dissimilarity in data submanifolds corresponding to slices in the latent space conditioned by a fixed latent code value.\nIn our work, we propose the new differentiable loss function TopDis (Eqn. 3), which measures the topological discrepancy, as evaluated by RTD, between an arbitrary data sample from decoder and its symmetry shift obtained via group(oid) action shifts preserving the Gaussian distribution.\n\n__W3__: _The experiments focus on models with some disentanglement capabilities, but the effectiveness of this regularization term on vanilla VAEs has not been studied._\n\n__A__: Thank you for the valuable feedback. Here are the results for VAE+TopDis.\nAs these results demonstrate,  VAE+TopDis outperformed VAE as measured by the 4 disentanglement metrics.\n\n| Method                                |    FactorVAE score |  MIG              |  SAP                  | DCI, dis.            |\n|--------------------------------------|--------------------------|-------------------|-----------------------|----------------------|\n| dSprites | | | | |\n| VAE                           | 0.781 \u00b1 0.016 | 0.170 \u00b1 0.072 | 0.057 \u00b1 0.039 | 0.314 \u00b1 0.072 |\n| VAE + TopDis (ours) | **0.833 \u00b1 0.068**  | **0.200 \u00b1 0.119**  | **0.065 \u00b1 0.009**  | **0.394 \u00b1 0.132** |\n| 3D Shapes | | | | |\n| VAE                 | 1.0 \u00b1 0.0 | 0.729 \u00b1 0.070 | 0.160 \u00b1 0.050 | 0.952 \u00b1 0.023 |\n| VAE + TopDis (ours) | **1.0 \u00b1 0.0** | **0.835 \u00b1 0.012** | **0.216 \u00b1 0.020** | **0.977 \u00b1 0.023** |\n| 3D Faces | | | | |\n| VAE                 | 0.96 \u00b1 0.03 | 0.525 \u00b1 0.051 | 0.059 \u00b1 0.013 | 0.813 \u00b1 0.063 |\n| VAE + TopDis (ours) | **1.0 \u00b1 0.0** | **0.539 \u00b1 0.037** | **0.063 \u00b1 0.011** | **0.831 \u00b1 0.023** |\n\nWe had also described the experiments for VAE vs VAE+TopDis-C models in Appendix in Table 6.\n\n(cont'd below)"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9426/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700712875978,
                "cdate": 1700712875978,
                "tmdate": 1700713287567,
                "mdate": 1700713287567,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UFjATdE0tK",
                "forum": "23OEmHVkpq",
                "replyto": "45O5KpOpsD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9426/Reviewer_T3Gf"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9426/Reviewer_T3Gf"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response, some of the concerns are addressed. However, I still have the following questions:\n1. Eqn. 3 is defined as the RTD between the sampled images between the original data and the shifted data, what is the difference between RTD in this paper and in [1]?\n2. The DCI performance of the vanilla VAE on 3D Shapes is very high (0.95), which outperforms most of the method proposed recently. I have concern in the evaluation of DCI metric.\n3. Does the clarification:\n> A: Thank you for the feedback. We are adding a clarification deducing the smallness of RTD from the disentanglement co...\n\nadd in the main paper? I think it is important to add this part into the main paper."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9426/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700726774265,
                "cdate": 1700726774265,
                "tmdate": 1700726774265,
                "mdate": 1700726774265,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lyORozMJZK",
                "forum": "23OEmHVkpq",
                "replyto": "xGgF6MfB2r",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9426/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9426/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Review T3Gf"
                    },
                    "comment": {
                        "value": "Thank you for your valuable feedback. \n\n1. In [1], the topological metrics is measured between samples whose latent codes necessarily belong to a hyperplane conditioned on the fixed value of one of $z_i$. During the training, the latent codes of data points obtained from the encoder never lie on a hyperplane, so this approach is not applicable for the optimization of the topological loss term. Instead, we work with an arbitrary data points sample obtained from the encoder on which acts the symmetry group(oid) shift. \n2. For DCI calculation, we used the evaluation code from the commonly used disentanglement lib: https://github.com/google-research/disentanglement_lib .\nWe note that we trained the models for 1 million iterations compared to 300k iterations used in several other works which can be a possible source of disagreement.\nAlso, in most recent papers only more advanced methods were compared but not the vanilla VAE baseline.\n3. We have added this and other improvements to the main text, the additions are highlighted by yellow in the revision. We are also adding, as a byproduct, the proposition clarifying the relation between the two approaches to the definition of disentanglement, the factor-independence based and the symmetry based.  \n\n _Concluding remark_. Please respond to our post to let us know if the clarifications above suitably address your concerns about our work. We are happy to address any remaining points; if the responses above are sufficient, we kindly ask that you consider raising your score."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9426/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737328191,
                "cdate": 1700737328191,
                "tmdate": 1700739438754,
                "mdate": 1700739438754,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "OtNzsmJtSr",
            "forum": "23OEmHVkpq",
            "replyto": "23OEmHVkpq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9426/Reviewer_2nX5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9426/Reviewer_2nX5"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed a novel Topological Disentanglement loss (TopDis loss) that can be added to any VAE-type loss to improve the disentanglement by encouraging the preservation of topological similarity in the generated samples with shifted latent space. Experiments demonstrated the proposed TopDis loss increases the disentanglement performance of several SOTA methods for various disentanglement metrics and datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "(1) Inspired by [1], the proposed differentiable Representation Topology Divergence (RTD) as a loss for the VAE-framework looks promising to improve the disentanglement.\n\n(2) Rich experiments are conducted to evaluate the performance of the proposed TopDis loss for various VAE-based methods.\n\n[1] Barannikov, Serguei, et al. \"Representation topology divergence: A method for comparing neural network representations.\" ICML 2022."
                },
                "weaknesses": {
                    "value": "(1) It is unclear how the hyper-parameters in Eqn (4) affect the performance. There are \u03b3_1 and \u03b3_2 in Table 9 (appendix N), but there is only one \u03b3 in Eqn (4). \n\n(2) In Table 1, it seems that some advanced disentanglement methods performed significantly worse than the vanilla VAE (e.g. FactorVAE on 3dshapes, and \u03b2-TCVAE on MPI3D, etc), making it a little suspicious for the experimental results and/or the model selections of baselines. Besides, two important evaluations of VAE+TopDis and \u03b2-TCVAE+TopDis are missing. \n\n(3) The evaluation of how the proposed methods handle the tradeoff between disentanglement and reconstruction is limited. Besides Table 4 and Table 8, the authors are encouraged to report the reconstruction errors of the proposed method with and without \"gradient orthogonalization\" for a complete comparison with the baselines. Did the \"gradient orthogonalization\" apply to the baselines as well?"
                },
                "questions": {
                    "value": "(1) The authors are encouraged to respond to the concerns above.\n\n(2) How the \u03b3 should be selected for different VAE-based methods? Does TopDis improve disentanglement when \u03b2 is already very large? How does the TopDis loss affect the optimization of the original disentanglement loss in those baselines (like the total correction in TC-VAE and FactorVAE)?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9426/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9426/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9426/Reviewer_2nX5"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9426/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698690713594,
            "cdate": 1698690713594,
            "tmdate": 1699637187390,
            "mdate": 1699637187390,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MERq4RhNyw",
                "forum": "23OEmHVkpq",
                "replyto": "OtNzsmJtSr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9426/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9426/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Reviewer 2nX5, #1"
                    },
                    "comment": {
                        "value": "__W1__: _It is unclear how the hyper-parameters in Eqn (4) affect the performance. There are \u03b3_1 and \u03b3_2 in Table 9 (appendix N), but there is only one \u03b3 in Eqn (4)._ \n\n__A__: Thank you for your remark. The sensitivity w.r.t. to $\\gamma$ in Eqn (4) is provided in Appendix Q.\nIn Appendix Q, $\\gamma_1$ denotes the weight for Total Correlation loss from the FactorVAE model while $\\gamma_2$ denotes the weight for TopDis loss from the equation (4). We have added the necessary clarification to the Appendix Q and renamed $\\gamma_1$ to $\\gamma_{TC}$ (stands for Total Correlation) and $\\gamma_2$ to $\\gamma_{TD}$ (stands for TopDis) as more suitable ones.\n\n__W2__: _In Table 1, vanilla VAE performed better than some other methods (e.g. FactorVAE on 3d Shapes, and \u03b2-TCVAE on MPI3D, etc), evaluations of VAE+TopDis and \u03b2-TCVAE+TopDis are not included in Table 1._\n\n__A__:  Thank you for your remarks.\n1. We provide evaluations of \u03b2-TCVAE+TopDis and we have updated Table 1 accordingly.\nAddition of TopDis improves \u03b2-TCVAE as measured by the 4 disentanglement metrics.\n\n| Method                                |    FactorVAE score |  MIG              |  SAP                  | DCI, dis.            |\n|--------------------------------------|--------------------------|-------------------|-----------------------|----------------------|\n| dSprites | | | | |\n| \u03b2-TCVAE                           | 0.810 \u00b1 0.058 | 0.332 \u00b1 0.029 | 0.045 \u00b1 0.004 | 0.543 \u00b1 0.049 |\n| \u03b2-TCVAE + TopDis (ours) | **0.821 \u00b1 0.034**  | **0.341 \u00b1 0.021** | **0.051 \u00b1 0.004** | **0.556 \u00b1 0.042** |\n| 3D shapes | | | | |\n| \u03b2-TCVAE                          | 0.909 \u00b1 0.079 | 0.693 \u00b1 0.053 | 0.113 \u00b1 0.070  | 0.877 \u00b1 0.018 |\n| \u03b2-TCVAE + TopDis (ours) | **1.0 \u00b1 0.0**   | **0.751 \u00b1 0.051**  | **0.147 \u00b1 0.064** | **0.901 \u00b1 0.014** |\n| 3D Faces | | | | |\n| \u03b2-TCVAE                           | 1.0 \u00b1 0.0 | 0.568 \u00b1 0.063 | 0.060 \u00b1 0.017 | 0.822 \u00b1 0.033 |\n| \u03b2-TCVAE + TopDis (ours) | 1.0 \u00b1 0.0 | **0.591 \u00b1 0.058**  | **0.062 \u00b1 0.011** | **0.859 \u00b1 0.031** |\n| MPI 3D | | | | | \n| \u03b2-TCVAE                           | 0.365 \u00b1 0.042 | 0.174 \u00b1 0.018  | 0.080 \u00b1 0.013 | 0.225 \u00b1 0.061 |\n| \u03b2-TCVAE + TopDis (ours) | **0.496 \u00b1 0.039**  | **0.280 \u00b1 0.013** | **0.143 \u00b1 0.009** | **0.340 \u00b1 0.055** |\n\n2. Also, we are running experiments with VAE+TopDis, please find the results below.\nWe see that VAE+TopDis outperformed VAE as measured by the 4 disentanglement metrics.\n\n| Method                                |    FactorVAE score |  MIG              |  SAP                  | DCI, dis.            |\n|--------------------------------------|--------------------------|-------------------|-----------------------|----------------------|\n| dSprites | | | | |\n| VAE                           | 0.781 \u00b1 0.016 | 0.170 \u00b1 0.072 | 0.057 \u00b1 0.039 | 0.314 \u00b1 0.072 |\n| VAE + TopDis (ours) | **0.833 \u00b1 0.068**  | **0.200 \u00b1 0.119**  | **0.065 \u00b1 0.009**  | **0.394 \u00b1 0.132** |\n| 3D Shapes | | | | |\n| VAE                 | 1.0 \u00b1 0.0 | 0.729 \u00b1 0.070 | 0.160 \u00b1 0.050 | 0.952 \u00b1 0.023 |\n| VAE + TopDis (ours) | **1.0 \u00b1 0.0** | **0.835 \u00b1 0.012** | **0.216 \u00b1 0.020** | **0.977 \u00b1 0.023** |\n| 3D Faces | | | | |\n| VAE                 | 0.96 \u00b1 0.03 | 0.525 \u00b1 0.051 | 0.059 \u00b1 0.013 | 0.813 \u00b1 0.063 |\n| VAE + TopDis (ours) | **1.0 \u00b1 0.0** | **0.539 \u00b1 0.037** | **0.063 \u00b1 0.011** | **0.831 \u00b1 0.023** |\n\n3. Indeed, vanilla VAE performed better than some other methods in some cases. This is consistent with actual papers: superiority of Vanilla VAE w.r.t beta-VAE for MPI3D was also observed by Locatello et al, 2020 (see Figure 7, bottom row). We have decided to double-check them and will report results in Appendix, as in most recent papers only more advanced methods were used but not the vanilla VAE baseline. Also we trained the models for 1 million iterations compared to 300 000 iterations used in several other works which can be a possible source of disagreement.\n\nWe would like to emphasize that our main objective was to improve the SOTA methods, and that is what we achieved. The TopDis loss have consistently improved the performance of \u03b2-VAE, \u03b2-TCVAE, ControlVAE, FactorVAE and DAVA models in terms of disentanglement scores (MIG, FactorVAE score, SAP score, DCI disentanglement score) while preserving the reconstruction quality."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9426/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700670524526,
                "cdate": 1700670524526,
                "tmdate": 1700678869110,
                "mdate": 1700678869110,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qwDrFsZs6k",
                "forum": "23OEmHVkpq",
                "replyto": "OtNzsmJtSr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9426/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9426/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Reviewer 2nX5, #2"
                    },
                    "comment": {
                        "value": "__W3__: _The evaluation of how the proposed methods handle the tradeoff between disentanglement and reconstruction is limited. Besides Table 4 and Table 8, the authors are encouraged to report the reconstruction errors of the proposed method with and without \"gradient orthogonalization\" for a complete comparison with the baselines. Did the \"gradient orthogonalization\" apply to the baselines as well?_\n\n__A__: Thank you for your question and remark. Figure 17 in Appendix illustrates the positive effect of gradient orthogonalization on reconstruction error during training. We do not apply gradient orthogonalization in each experiment but only when the proposed loss can slightly hinder the reconstruction objective.. In our experiments, we orthogonalize the gradient of the proposed TopDis loss w.r.t. the reconstruction loss. Since there is a known tradeoff between reconstruction quality and disentanglement, our primary goal is to develop an additional loss that would enhance the underlying base model but would not result in increase of reconstruction error. While in our experiments we do not apply gradient orthogonalization separately for the baseline models, it is possible to apply the gradient orthogonalization of disentanglement-promoting loss (e.g. Total Correlation for FactorVAE, additional KL-divergence for BetaVAE, etc.) for the baseline model. While a similar technique is known, to the best of our knowledge, it has not been used in the context of learning disentangled representations before. \n\n__Q2__: _How the \u03b3 should be selected for different VAE-based methods? Does TopDis improve disentanglement when \u03b2 is already very large?_\n\n__A__: Thank you for your questions.\n1. In our experiments, we used the following greedy procedure to tune the weight $\\gamma$ of the TopDis loss. First, we tune hyperparameters of baseline approaches (i.e. beta-VAE, FactorVAE, ControlVAE, etc.), by selecting ones having both high disentanglement quality and reasonable reconstruction error. A minor exception is the DAVA model, where the hyperparameters are tuned adaptively during training. Then, we select the best $\\gamma$ from the range [1, 6] by the disentanglement quality. We observe that optimal $\\gamma$ often coincide for different datasets.\n\n2. High values of $\\beta$ typically lead to high reconstruction error, we do not explore this setup in our experiments. Our goal is to enhance the underlying model to provide both good disentanglement and reconstruction quality.\n\n_Concluding remarks_. Please respond to our post to let us know if the clarifications above suitably address your concerns about our work. We are happy to address any remaining points during the discussion phase; if the responses above are sufficient, we kindly ask that you consider raising your score."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9426/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700670690104,
                "cdate": 1700670690104,
                "tmdate": 1700670690104,
                "mdate": 1700670690104,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "JJaPaIjUli",
            "forum": "23OEmHVkpq",
            "replyto": "23OEmHVkpq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9426/Reviewer_VGnt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9426/Reviewer_VGnt"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposed a disentanglement regularization term based on topology, to constrain the manifold relation between the latent points of original images and shifted images. The authors provided extensive experiments on VAE-based methods and showed the effectiveness of the proposed methods."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tIt is important to explore the constrain in the manifold of latent space for disentanglement, due to the statistical arguments of Locatello et al. (2019). The paper explored a way from topology and proposed a regularization term, which can be easily optimized. \n\n2.\tThe paper provided a good formulation of the TopDis loss and how to optimize it in the VAE framework."
                },
                "weaknesses": {
                    "value": "1.\tThe relation between the constrain on latent space and disentanglement is still unclear, the TopDis is based on VAE-framework, which is based on Probability, and the paper referred to the definition of disentanglement based Group. And the paper failed to connect the above two framework, and making the proposed TopDis only kind of an intuitive necessary condition, as shown in Figure 3. \n\n2.\tFrom Appendix L, the best performance hyperparameters are quite different across different methods and different datasets, is there any guidance or criterion to choose the hyper-parameter?"
                },
                "questions": {
                    "value": "1.\tMy main concern is the relation between the proposed TopDis and disentanglement, is there any theoretical guarantee or deduction?  \n2.\tThe authors applied the proposed TopDis to infer disentangled directions in a pretrained style-GAN, is there some quantitative results? Then dose the method can be applied to other disentangled methods?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9426/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698720685980,
            "cdate": 1698720685980,
            "tmdate": 1699637187279,
            "mdate": 1699637187279,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "E8M3D8EtgT",
                "forum": "23OEmHVkpq",
                "replyto": "JJaPaIjUli",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9426/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9426/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Reviewer VGnt, #1"
                    },
                    "comment": {
                        "value": "Thank you for your time and thorough review. We will improve the presentation according to the suggestions. Below we address specific concerns one by one.\n\n\n__W1__: _The relation between the constrain on latent space and disentanglement is still unclear, the TopDis is based on VAE-framework, which is based on Probability, and the paper referred to the definition of disentanglement based Group. And the paper failed to connect the above two framework,and making the proposed TopDis only kind of an intuitive necessary condition,as shown in Figure3._  \n__A__: Thank you for the valuable feedback.   \n1.We are adding a clarification on the relation of the probability based definition of disentanglement and the group based definition. Let $q(z)$ be the  aggregate posterior distribution over a latent space, aggregated over the whole dataset $X$. And let $q(z_i)$ be the similar aggregate distribution over the latent code $z_i$. The formula (1) is  valid and defines symmetry group(oid) shifts if we replace the standard normal distribution by any distribution over the real line, we use it with the distribution $q(z_i)$ over the $i-$th latent codes.  \n\n_Proposition._ a) If the distribution $q(z)$ is factorized into product $q(z)=\\prod_i q(z_i)$, then the shift defined by the formula (1) and acting on a single latent code $z_i$ and leaving other latent codes fixed,  preserves the latent space distribution $q(z)$. This defines the $G_i$ groupoid action on $z$ for any $i$, whose action is then extended to points of the initial dataset $X$ with the help of the decoder-encoder.  b) Conversely, if $q(z)$ is preserved for any $i$ by the shifts acting on $z_i$ and defined via formula (1) from the distribution $q(z_i),$ then $q(z)=\\prod_i q(z_i)$.   \n_Proof._ a) The shift defined by (1) for the distribution $q(z_i)$ acting on the latent space, preserves also any $q(z_j)$ for $ j\\neq i$. b) The result follows from the case of an arbitrary distribution over a pair of random variables $z_1, z_2$. For two variables, it follows from the Bayes formula that the shifts of $z_1$ preserve the conditional $q(z_2\\vert z_1)$. Since the group(oid) action is transitive it follows that the conditional does not depend on $z_1$, and hence $q(z_1,z_2)=q(z_1)q(z_2)$. \n\nTo the best of our knowledge, we are the first to impose the preservation of the distributions under the symmetry groupoid action condition in the standard normal distribution variational autoencoder   framework. On the one hand, this implies that such symmetry action is necessarily defined not by a group but by the groupoid and also using the specific shifts as in equation (1). On the other hand, this distribution preservation by groupoid is the main ingredient making the two definitions of disentanglement compatible. \nWe are adding this result clarifying the correspondence between the two definitions to the paper.  \n\n2.We are adding a clarification deducing the smallness of RTD from the disentanglement conditions and properties of symmetry action on manifolds.Briefly, the Lie group(oid) symmetry $g$ action on the support of data distribution is continuous and invertible. This implies that for any subset of the support of data distribution, the image of the subset under $g$ has the same homology or the same group of topological features. The preservation of topological features at multiple scales can be tested with the help of the representation topology divergence (RTD). If RTD is small between a sample from $X$ and its symmetry shift, then the groups of topological features at multiple scales are preserved. \n\nAlso the smallness of RTD implies the smallness of the disentanglement measure from (Zhou et al. 2020) based on the geometry scores of data subsets conditioned to a fixed value of a latent code. Such subsets for different fixed values of the latent code are also related via the symmetry shift action, and if RTD between them is small, the distance between their persistence diagrams and hence the metric from loc cit is small as well. \n \n__W2__: _From Appendix L, the best performance hyperparameters are quite different across different methods and different datasets, is there any guidance or criterion to choose the hyper-parameter?_  \n\n__A__:  In our experiments, we used the following greedy procedure to tune the weight $\\gamma$ of the TopDis loss. First, we tune hyperparameters of baseline approaches (i.e. beta-VAE, FactorVAE, ControlVAE, etc.), by selecting ones having the high disentanglement quality while keeping reasonable reconstruction error. A minor exception is the DAVA model, where the hyperparameters are tuned adaptively during training. Then, we select the best $\\gamma$ weight for TopDis from the range [1, 6] by the disentanglement quality. We observe that optimal $\\gamma$ often coincide for different datasets.  \n\n(cont'd below)"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9426/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700733661542,
                "cdate": 1700733661542,
                "tmdate": 1700734453626,
                "mdate": 1700734453626,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wrN2LcXuXF",
                "forum": "23OEmHVkpq",
                "replyto": "JJaPaIjUli",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9426/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9426/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Reviewer VGnt, #2"
                    },
                    "comment": {
                        "value": "__Q1__: _My main concern is the relation between the proposed TopDis and disentanglement, is there any theoretical guarantee or deduction?_\n\n__A__: Thank you for the question. (See the answer to W1.)  Firstly, we add the proposition establishing the relation of the probability based definition of disentanglement and the group based definition. Secondly, we add the clarification deducing the TopDis minimization from the disentanglement conditions and properties of symmetry groupoid action, see the answer to W1.\n\n__Q2__: _The authors applied the proposed TopDis to infer disentangled directions in a pretrained style-GAN, is there some quantitative results? Then dose the method can be applied to other disentangled methods?_\n\n__A__: Comparison of methods dedicated to the unsupervised discovery of disentangled directions in StyleGAN is qualitative since the FFHQ dataset doesn't have labels. Our goal is to demonstrate the applicability of the TopDis loss for this problem. See section 5.3 for details.  \n\n _Concluding remarks_. Please respond to our post to let us know if the clarifications above suitably address your concerns about our work. We are happy to address any remaining points during the discussion phase; if the responses above are sufficient, we kindly ask that you consider raising your score."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9426/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700733706568,
                "cdate": 1700733706568,
                "tmdate": 1700734971787,
                "mdate": 1700734971787,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "8CzSIMq0YG",
            "forum": "23OEmHVkpq",
            "replyto": "23OEmHVkpq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9426/Reviewer_1sM8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9426/Reviewer_1sM8"
            ],
            "content": {
                "summary": {
                    "value": "The authors of this paper present TopDis, which is a regularizer based on Representation Topology Divergence (RTD). In this approach, the objective to be optimized is a combination of \u201cclassic\u201d VAE loss and TopDis loss. Unlike the preceding approaches, topDis does not assume statistical independence between the factors of variations. Generally, introducing this loss term appears to further improve the current SOTA values for several disentanglement metrics (FactorVAE, MIG, SAP and DCI) across several different datasets (dSprites, 3D Shapes, 3D Faces, MPI 3D)."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is clearly written and easy to follow. In detail:\n\na. The authors explain the task of disentanglement rather clearly by providing a succinct overview of previous works.\n\nb. The motivation and contribution of the paper are also clearly defined with an intuitive explanation of the designed methodology.\n\n2. The authors provide a variety of experiments and ablations, helping to evaluate their proposed disentanglement regularization loss practically. In detail:\n\na. The experiments (Table 1) appear comprehensive (except for the vanilla VAE; we will explain in the weakness section our concerns).\n\nb. The authors also provide enough qualitative examples, comparing models trained with TopDis regularizer and without.\n\nc. The architecture is succinctly described in the Appendix\n\n3. Computational complexity is also discussed in the Appendix, which is crucial for ML algorithms nowadays."
                },
                "weaknesses": {
                    "value": "1. One of the contributions the authors mention is: \u201cWe improve the reconstruction quality by applying gradient orthogonalization;\u201d - however, this contribution is only briefly mentioned in the conclusion and analyzed in the Appendix in greater detail. We suggest the authors to \u201cmove\u201d the gradient orthogonalization part to the main paper.\n\n2. As the authors explained, the RTD was defined in a previous work, but we believe it is important to be defined in the main paper.\n\n3. In section 4.1, bullets (2-4). In (2), g\\inG appears to be applied to both pixel and latent space. Later in (3,4), where decomposition G is defined, it seems that it can be applied only in the latent space. We believe the authors should re-write this part, clarifying how G can be applied in the pixel space or, if that is not the case remove from (2) the application of g in the pixel space.\n\n4. In equation (4) regularization parameter /gamma is defined. Later in the appendix Q, \\gamma_1, and \\gamma_2 are used in the ablation table. Does this correspond, instead, to the loss: \\gamma_1 L_{VAE-based} + \\gamma_2 L_{TD}.\n\n5. In page 5 footnote, the authors state that RPT can be computed in latent space instead of pixel space. Can the authors provide ablations in the appendix exploring this direction? Do the authors have insights into how this change can affect the final trained model?\n\n6. Finally, our main concern is whether the proposed regularizer contributes to the learning of the disentangled representation or the used base models (i.e., \\beta-VAE, Factor-VAE). Since, in the main paper, only the models with already disentanglement remedies are explored and not the vanilla VAE. More concerning in the ablation, VAE+TopDis is explored, but it seems that the training is not the same as the VAE reported in the main paper. Our guess is that the models in the ablation were trained for less number of iterations. We encourage the authors to include in the main paper VAE+TopDis trained under the same conditions (i.e. same number of iterations) as the reported VAE in Table 1. This will help readers understand to what extent the TopDis regularizer helps learn disentangled representations"
                },
                "questions": {
                    "value": "See above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9426/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698783831422,
            "cdate": 1698783831422,
            "tmdate": 1699637187167,
            "mdate": 1699637187167,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NOeknVYmF7",
                "forum": "23OEmHVkpq",
                "replyto": "8CzSIMq0YG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9426/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9426/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Review 1sM8"
                    },
                    "comment": {
                        "value": "Thank you for your time and thorough review highlighting strengths of our paper. We will improve the presentation according to the suggestions. Below we address specific concerns one by one.\n\n__W1__: _We suggest the authors to \u201cmove\u201d the gradient orthogonalization part to the main paper._   \n__A__: Thank you for the suggestion, we have moved the details on gradient orthogonalization to the main part.  \n\n__W2__: _Move more details on formal definition of RTD to the main paper_  \n__A__: Thank you for the suggestion. We are adding more details on the formal definition to the discussion of the RTD definition in Section 3.1. \n\n__W3__: _Clarify how $G$ can be applied in the pixel space._  \n__A__: Thank you for your question. The equation $f(g(z))=g(f(z))$ concerns the outcome of the learning process, which consists, in particular, in finding a priori unknown symmetries in the data. Given the decoder map $f$, this equation defines the symmetry action on $X$ preserving the data distribution. \n\n__W4__: _Clarify notations \\gamma_1 and \\gamma_2 in the ablation table in Appendix Q._  \n__A__: Thank you for your remark. In Appendix Q, \\gamma_1 denotes the weight for Total Correlation loss from the FactorVAE model while \\gamma_2 denotes the weight for TopDis loss from the equation (4). We have added the necessary clarification to the Appendix Q and renamed \\gamma_1 to \\gamma_TC (stands for Total Correlation) and \\gamma_2 to \\gamma_TD (stands for TopDis) as more suitable ones.\n\n__W5__: _Can RTD be applied in latent space instead of pixel space?_  \n__A__: Thank you for your question. In the footnote on page 5, we mean that it is possible to compute TopDis loss either between the images (i.e. in pixel space) or between their representations (for example, produced by another pretrained model). It can be beneficial for different reasons to compare the multiscale topology of data in a representation space. For example, common disentanglement datasets have typical image resolution 64x64. However, in case of significantly higher image resolution, it could be beneficial to utilize representations instead of images. As a proof of concept, in the subsection 5.3 and Appendix H, we provide the results on unsupervised discovery of disentangled directions in StyleGAN where we compute the RTD in the representation space instead of pixel space. With these experiments, we illustrate that RTD finds meaningful directions using the representation space as well. \n\n\n__W6__: _Clarification on VAE+TopDis_  \n__A__: Thank you for the question.  We are now running the experiments for VAE+TopDis.  Here are the results for VAE+TopDis vs VAE : \n\n\n| Method                                |    FactorVAE score |  MIG              |  SAP                  | DCI, dis.            |\n|--------------------------------------|--------------------------|-------------------|-----------------------|----------------------|\n| dSprites | | | | |\n| VAE                           | 0.781 \u00b1 0.016 | 0.170 \u00b1 0.072 | 0.057 \u00b1 0.039 | 0.314 \u00b1 0.072 |\n| VAE + TopDis (ours) | **0.833 \u00b1 0.068**  | **0.200 \u00b1 0.119**  | **0.065 \u00b1 0.009**  | **0.394 \u00b1 0.132** |\n| 3D Shapes | | | | |\n| VAE                 | 1.0 \u00b1 0.0 | 0.729 \u00b1 0.070 | 0.160 \u00b1 0.050 | 0.952 \u00b1 0.023 |\n| VAE + TopDis (ours) | **1.0 \u00b1 0.0** | **0.835 \u00b1 0.012** | **0.216 \u00b1 0.020** | **0.977 \u00b1 0.023** |\n| 3D Faces | | | | |\n| VAE                 | 0.96 \u00b1 0.03 | 0.525 \u00b1 0.051 | 0.059 \u00b1 0.013 | 0.813 \u00b1 0.063 |\n| VAE + TopDis (ours) | **1.0 \u00b1 0.0** | **0.539 \u00b1 0.037** | **0.063 \u00b1 0.011** | **0.831 \u00b1 0.023** |\n\nThe reconstruction loss for VAE+TopDis: 9.54\u00b10.19 (dSprites), 3489.533\u00b11.502 (3DShapes), 1376.218\u00b10.316 (3DFaces) \n\nAs we see, VAE+TopDis outperformed VAE as measured by the 4 disentanglement metrics. \n\nIn the experiments in Table 6 in Appendix G the training procedure was identical to that of Table 1 in the main paper, except that we have used a slightly smaller architecture in Table 6 for dSprites for both VAE and VAE+TopDis-C compared with the experiments from Table 1. For this reason, the metrics values differed in Table 1 and Table 6 for VAE at dSprites dataset. However, we highlight that the experimental setup for 3D Shapes is identical in both Table 1 and Table 6. And that our setup is always consistent when we compare a base model with and without TopDis loss. \n\nAlso, our main objective was to improve the SOTA methods, and that is what we achieved. The TopDis loss  have consistently improved the performance of \u03b2-VAE, \u03b2-TCVAE, ControlVAE, FactorVAE and DAVA models in terms of disentanglement scores (MIG, FactorVAE score, SAP score, DCI disentanglement score) while preserving the reconstruction quality. \n\n_Concluding remarks_. Please respond to our post to let us know if the clarifications above suitably address your concerns about our work. We are happy to address any remaining points during the discussion phase; if the responses above are sufficient, we kindly ask that you consider raising your score."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9426/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700595095425,
                "cdate": 1700595095425,
                "tmdate": 1700672970827,
                "mdate": 1700672970827,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]