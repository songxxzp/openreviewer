[
    {
        "title": "Adaptive Regularization of Representation Rank as an Implicit Constraint of Bellman Equation"
    },
    {
        "review": {
            "id": "s6OnWIqpL3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1504/Reviewer_ef2F"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1504/Reviewer_ef2F"
            ],
            "forum": "apXtolxDaJ",
            "replyto": "apXtolxDaJ",
            "content": {
                "summary": {
                    "value": "This paper studies an important issue of representation rank in deep reinforcement learning (DRL).  To tackle this problem, the authors propose BEER, which leverages the Bellman equation to derive an upper bound on the cosine similarity between consecutive state-action pair representations. This bound is then used as a regularizer to adaptively control the representation rank during training. The empirical studies on DeepMind control tasks validate the high efficiency of the proposed algorithm."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is well written and easy to follow. The proposed adaptive regularization is new and effective.\n\nThe empirical results clearly validate the high efficiency of BEER, which is impressive. Since I am not an expert in this specific area and haven't followed this line of recent literature, I will refer to others reviewers' opinions on the experiments."
                },
                "weaknesses": {
                    "value": "I have some minor questions:\n\n1. The authors intuitively explained the intrinsic similarity between the cosine similarity and the representation rank with examples. I am curious about if there is some formal statement or proof on this topic, since it serves as a very important property of your paper. There is some parameter in the definition of the representation rank (e.g. $\\epsilon$) in Definition 1, but I didn't see it in the following discussion.\n\n2. When the authors transform the constraint in Eqn. (11) to the penalty regularizer with ReLU in Eqn.(12), is there any theoretical support for this transformation? And also is there any theoretical analysis on how to choose the value of $\\beta$? I check the ablation study on this hyperparameter on Appendix, but I feel its choice is still quite important but unclear in practice.\n\nFor the Eqn. (5), should the $\\phi$ be $\\Phi$?"
                },
                "questions": {
                    "value": "Please refer to the above Weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1504/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1504/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1504/Reviewer_ef2F"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1504/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697263726469,
            "cdate": 1697263726469,
            "tmdate": 1699636079180,
            "mdate": 1699636079180,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "E0uYQHqtC6",
                "forum": "apXtolxDaJ",
                "replyto": "s6OnWIqpL3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1504/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1504/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ef2F"
                    },
                    "comment": {
                        "value": "Dear Reviewer ef2F:\n\nWe are grateful for your time in reviewing our paper and appreciate your positive remarks about the clarity of our writing and the effectiveness of our adaptive regularization. We address your concerns as follows.\n\n> Q1.1: The authors intuitively explained the intrinsic similarity between the cosine similarity and the representation rank with examples. I am curious about if there is some formal statement or proof on this topic since it serves as a very important property of your paper. \n\n**A1.1**: \n- To the best of our knowledge, there is currently no established formal statement or proof directly correlating cosine similarity with representation rank in the DRL literature. Our work is theoretically motivated. \n- Theoretically, rank cannot strictly bound the cosine similarity without making more further information (e.g. Bellman equation and neural network in our paper). \n- Empirically, researchers [1,2,3] could use cosine similarity to affect the rank. In our work, we explore the influence of cosine similarity on the rank, as detailed in Appendix D. \n- On the one hand, several practices and algorithms in the field [1,2,3] manipulate representation vectors to affect the rank, which is aligned with our approach. For example, [1] maximizes representation rank by aligning learned representation vectors with their initial counterparts.\n- On the other hand, existing theoretical research [4,5,6] about representation rank cannot inherently bound the cosine similarity of the representation vectors.\n\n\n> **Q1.2**: There is some parameter in the definition of the representation rank (e.g. $\\epsilon$) in Definition 1, but I didn't see it in the following discussion.\n\n**A1.2**: The parameter $\\epsilon$ in Definition 1 aims to filter out small singular values, thereby focusing on vectors that mainly contribute to the rank. We selected $\\epsilon=0.01$ for our experiments, as detailed in Tables 2, 3, and 4. This value aligns with the default setting in prior literature (referenced in section C.2 of [1]), providing a standardized basis for comparison and analysis in our work.\n\n\n> Q2.1: When the authors transform the constraint in Eqn. (11) to the penalty regularizer with ReLU in Eqn. (12), is there any theoretical support for this transformation?\n\n**A2.1**:\n- The primal-dual method, typically used for some convex optimization problems, is not feasible here due to the non-convex nature of the original problem in Eqn. (11).  The original problem in Equation 11 involves optimizing $\\phi$ and $w$ separately inside. The primal-dual method is still not guaranteed to convergence. \n- Our work is theoretically motivated. Our use of the ReLU function in the regularizer ensures the optimizer does not maximize the representation rank once the upper bound holds. Specifically, when the left-hand side of Equation (11) is less than its right-hand side, the gradients of our regularizer remain consistently zero due to the properties of $\\nabla_x \\text{ReLU}(x)=0$ for $x<0$.\n- Empirically, according to our analysis in Figure 6 (Appendix E), the $C$ values of BEER empirically ensure the constraint is satisfied. Our method aligns with general practices in DRL literature [1,2,3], where adding a regularizer to the original optimization objective is a common method.\n\n\n> Q2.2: And also is there any theoretical analysis on how to choose the value of $\\beta$? I check the ablation study on this hyperparameter on Appendix, but I feel its choice is still quite important but unclear in practice.\n\n**A2.2**:\n- Theoretical insights: The choice of $\\beta$ determines the relative impact of the two losses (primary optimization and regularization) on parameter gradients. To avoid undermining the primary optimization objective, the regularizer's loss should be considerably smaller than the primary loss. \n- Empirically, our experiments in Appendix F indicate that a relatively small $\\beta$ works well. $\\beta$ varying over a small domain of values ([0.0005,0.001] in our experiments) results in equally good performance.\n- P.S. One of the reasons why we selected a consistent, fixed $\\beta$ across all the experiments is to fairly evaluate our algorithm considering the recent crisis in the model evaluation [7].\n\n\n> Q3: For the Eqn. (5), should the $\\phi$ be $\\Phi$?\n\n**A3.** Thank you for highlighting this typographical error. We have modified it in the revised manuscript, where $\\phi$ is now correctly denoted as $\\Phi$.\n\nWe hope our responses provide clarity on the issues raised. We appreciate your feedback and believe that it will greatly enhance the quality and impact of our paper. Thanks for considering our response.\n\nSincerely,\nAuthors of submission 1504."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1504/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700120097111,
                "cdate": 1700120097111,
                "tmdate": 1700123469534,
                "mdate": 1700123469534,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CKM7pTZtR9",
                "forum": "apXtolxDaJ",
                "replyto": "kmiu4lFs8I",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1504/Reviewer_ef2F"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1504/Reviewer_ef2F"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your response"
                    },
                    "comment": {
                        "value": "Thank you for your detailed response to all my questions. After reading the rebuttal and feedbacks from other reviewers, I feel the paper is on the borderline, and hence I'd like to keep my score."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1504/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700631803763,
                "cdate": 1700631803763,
                "tmdate": 1700631803763,
                "mdate": 1700631803763,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fJ4vwRUKYZ",
                "forum": "apXtolxDaJ",
                "replyto": "s6OnWIqpL3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1504/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1504/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your reply!"
                    },
                    "comment": {
                        "value": "Dear Reviewer ef2F,\n\nThank you for acknowledging our detailed responses to your insightful comments.  We would respectfully appreciate it if you could reevaluate the confidence score, considering the points highlighted below:\n\n- Addressing your concerns. We provide comprehensive responses to address the concerns raised in your review. Our revised manuscript and responses reflect a thorough consideration of your insightful feedback. Your insightful comments have significantly strengthened our work.\n\n- Contribution to the community. Our work introduces a novel adaptive method to control the representation rank in deep reinforcement learning, potentially offering new directions for future research. We believe this aspect enhances the paper's value to the community.\n\nWe hope these points might offer a new perspective on the potential impact of our paper. Thanks for your reply again.\n\nSincerely,\n\nAuthors of Submission 1504"
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1504/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700633098437,
                "cdate": 1700633098437,
                "tmdate": 1700633276994,
                "mdate": 1700633276994,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Gi4FpM8avH",
            "forum": "apXtolxDaJ",
            "replyto": "apXtolxDaJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1504/Reviewer_dvZZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1504/Reviewer_dvZZ"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies an implicit regularization of representation rank in deep RL. The authors draw the intuition between the representation rank and the cosine similarity between adjustment state-action pairs."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This paper is well written and easy to follow\n- The experiment shows a good performance and backup the theoretical insights"
                },
                "weaknesses": {
                    "value": "- The argument that the cosine similarity of the ** adjustment** state-action pairs $(s, a)$ and $(s', a')$ does not rigorously lead to the rank. This is because one can only control the similarity between limited state-action pairs, instead of all possible state-action pairs. Think of an extreme case that the representation in adjustment state-action pairs is iterating between $(0, 1, 0, \\cdots, 0)$ and $(1, 0, 0, \\cdots, 0)$, the implicit regularization will fail.\n- It seems that in the experiment (Figure 1), the representation rank of the proposed method is dropping. It would be beneficial if the authors can provide some explanation on this"
                },
                "questions": {
                    "value": "- Maximizing the representation rank has always been an important part of the literature. Several theoretical works [1, 2, 3] show that as long as all the representations are in the span of the covariance matrix (i.e. $x \\in E[xx^\\top], the diversity assumption in [1] or the UniSOFT assumption in [2]), the performance can be improved. It would be beneficial for authors to comment on the relationship between this paper and these theoretical results, e.g. will the cosine similarity be well-bounded under these assumptions?\n\n[1] Papini, Matteo, et al. \"Leveraging good representations in linear contextual bandits.\" International Conference on Machine Learning. PMLR, 2021.\n[2] Papini, Matteo, et al. \"Reinforcement learning in linear mdps: Constant regret and representation selection.\" Advances in Neural Information Processing Systems 34 (2021): 16371-16383.\n[3] Zhang, Weitong, et al. \"Provably efficient representation selection in low-rank Markov decision processes: from online to offline RL.\" Uncertainty in Artificial Intelligence. PMLR, 2023."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1504/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698623920463,
            "cdate": 1698623920463,
            "tmdate": 1699636079095,
            "mdate": 1699636079095,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PcggJBGTu4",
                "forum": "apXtolxDaJ",
                "replyto": "Gi4FpM8avH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1504/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1504/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer dvZZ (1/2)"
                    },
                    "comment": {
                        "value": "Dear Reviewer dvZZ:\n\nWe are grateful for your comprehensive review and constructive feedback on our submission. Your recognition of the clarity of our writing and the effectiveness of our experimental results is highly appreciated. We address your concerns as follows.\n\n> Q1: The argument that the cosine similarity of the ** adjustment** state-action pairs $(s,a)$ and $(s',a')$ does not rigorously lead to the rank. This is because one can only control the similarity between limited state-action pairs, instead of all possible state-action pairs. Think of an extreme case that the representation in adjustment state-action pairs is iterating between $(0,1,0,\\cdots,0)$ and $(1,0,0,\\cdots,0)$, the implicit regularization will fail.\n\n**A1.** We thank you for pointing out this critical aspect! Our design indeed aims to access the entire spectrum of possible state-action pairs. As highlighted in [2], \"In RL, the reachability of a state plays a fundamental role. For example, representation of states that are not reachable by any policy are irrelevant\". The unreachable state-action pairs are irrelvant for the numerical representation rank (in Definition 1) because they cannot be sampled. We humbly hope to draw your attention to our sampling process as detailed in Algorithm 1, lines 7 to 10.\n\n- **Sampling mechanism allows access to all possible (s,a) pairs.**: BEER employs a uniform sampling strategy from the replay buffer, which theoretically allows access to the entire spectrum of state-action pairs. This strategy is a fundamental aspect of our methodology, ensuring a comprehensive representation of the state-action pairs. Additionally, the exploration tricks in BEER, which introduce noise to actions, further ensure the agent covers as many state-action pairs as possible.\n\n\n- **Practical Implementation**: We implement this with substantial sampling iterations \u2013 one million \u2013 with each batch comprising 256 samples. This extensive sampling framework significantly enhances the likelihood of covering all possible state-action pairings, thereby mitigating concerns about limited coverage.\n\nWe have added more details in our revised manuscript (Appendix J) to clarify these points and highlight the robustness of our sampling process.\n\n\n\n\n>Q2: It seems that in the experiment (Figure 1), the representation rank of the proposed method is dropping. It would be beneficial if the authors can provide some explanation on this.\n\n\n**A2.**  The representation rank in Figure 1 is indicative of BEER's adaptive regularization capability. A constant high or low rank is impractical for different tasks. Our method adaptively adjusts the rank to balance the model, preventing overfitting and underfitting. The criterion for evaluating rank is the approximation error \u2013 the absolute difference between estimated and true values. BEER's lower approximation error compared to other algorithms in Figure 1 demonstrates its effectiveness in achieving a preferable rank. This adaptive regularization is important to BEER's performance improvement."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1504/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700119719895,
                "cdate": 1700119719895,
                "tmdate": 1700120250490,
                "mdate": 1700120250490,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "HVDcXsy9h4",
            "forum": "apXtolxDaJ",
            "replyto": "apXtolxDaJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1504/Reviewer_Joqj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1504/Reviewer_Joqj"
            ],
            "content": {
                "summary": {
                    "value": "This work studies how to learn a low-rank representation in reinforcement learning (RL). Following several previous works, the authors claimed that RL favors a representation with moderate rank, and they proposed a new regularization method based derived from the Bellman equation. In detail, such a regularization method controls the complexity of the learned representation, and it encourages the rank of the representation to be small empirically. Combined with the regularization method, several baseline methods such as DQN and DDPG outperform existing baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The presentation of this paper is clear. \n2. The experiment setup is described very clear. \n3. The literature review is complete."
                },
                "weaknesses": {
                    "value": "There are several things that can improve the paper. For instance, \n1. On page 4, the definition of $\\bar{\\phi}(s',a')$ seems not clear since $(s',a')$ serves as both the input of $\\bar{\\phi}$ and the random variable which is going to be integrated. \n2. On page 5, what is the exact definition of $\\mathbb{SG}$? \n\nI do not quite get why the authors need to design the regularization term as in (12). It seems more natural to me to set the regularization term as in (19), which avoids a calculation of the gradient of an inverse term $1/|\\phi(s,a)|$ which might hurt the stability of the optimization process. \n\nThe logic behind the superior performance of BEER is not clear to me. The authors tried to claim that 'representation rank affects the model performance (approximation error), while BEER explicitly controls the rank, thus BEER outperforms other baseline methods'. However, according to figure 2, InFeR has a similar representation rank as BEER, while it performs worse than BEER. Is there any explanation why such a phenomenon happens? Meanwhile, in simpler tasks (Grid World), the rank of BEER is higher than other baselines, while in complex tasks (Lunan radar), the rank of BEER is lower than other baselines. Due to the inconsistency, it is doubtful whether the performance gain is due to the better control of representation rank. If so, it indeed deserves more explanation."
                },
                "questions": {
                    "value": "See Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1504/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698693705001,
            "cdate": 1698693705001,
            "tmdate": 1699636079010,
            "mdate": 1699636079010,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "WigBbWwW0G",
                "forum": "apXtolxDaJ",
                "replyto": "HVDcXsy9h4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1504/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1504/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Joqj (1/2)"
                    },
                    "comment": {
                        "value": "Dear Reviewer Joqj,\n\nThank you for your insightful feedback and the time you have invested in reviewing our paper. Your comments significantly improve the quality of our paper. We appreciate your acknowledgment of the clear presentation, detailed experimental setup, and comprehensive literature review in our work. We address your concerns as follows.\n\n\n> **Q1**: On page 4, the definition of $\\bar{\\phi}(s',a')$ seems not clear since $(s',a')$ serves as both the input of $\\bar{\\phi}$ and the random variable which is going to be integrated.\n\n**A1**. Thank you for pointing out this! We have revised the notation from $\\bar{\\phi}(s',a')$ to $\\overline{\\phi(s',a')}$, where $\\overline{\\phi(s',a')} = \\mathbb{E}_{s',a'} \\phi(s',a')$. This modification does not affect the theoretical correctness and rigor of the original text.\n\n\n> **Q2**: On page 5, what is the exact definition of $\\mathbb{SG}$?\n\n\n**A2**. The term $\\mathbb{SG}$, denoting 'Stop Gradient', is a concept from the semi-gradient nature of the Bellman backup, as discussed in Section 9.3 of [1].\n\nTo provide a more precise understanding, $\\mathbb{SG}$ can be defined as follows:\n\n$\\textbf{Definition 2: Stop Gradient.}$ The $\\mathbb{SG}$ operator is applied to a differentiable function $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ within the context of gradient-based optimization. When this operator is applied, it generates a new function $\\mathbb{SG}(f)$, such that for any input vector $\\mathbf{x} \\in \\mathbb{R}^n$, the output during the forward computation remains the same as that of $f$, i.e., $\\mathbb{SG}(f)(\\mathbf{x}) = f(\\mathbf{x})$. However, during the backward computation phase, where gradients are typically calculated through backpropagation, the gradient of $\\mathbb{SG}(f)$ with respect to $\\mathbf{x}$ is explicitly set to zero. This is irrespective of the actual gradient of $f$ at $\\mathbf{x}$. Formally, this concept is encapsulated by the following equation\n\n$$\n\\forall \\mathbf{x} \\in \\mathbb{R}^n, \\quad \\mathbb{SG}(f)(\\mathbf{x}) = f(\\mathbf{x}) \\quad \\text{and} \\quad \\nabla_{\\mathbf{x}} \\mathbb{SG}(f)(\\mathbf{x}) = \\mathbf{0}.\n$$\n\nWe have included this analysis in Appendix I of our revised manuscript.\n\n\n> **Q3**: I do not quite get why the authors need to design the regularization term as in (12). It seems more natural to me to set the regularization term as in (19), which avoids a calculation of the gradient of an inverse term $1/\\phi(s,a)$ which might hurt the stability of the optimization process.\n\n\n**A3**. We apologize for the unintentional missing of a $\\mathbb{SG}$ symbol in Eq 12. The corrected equation should read as follows: \n\n$$\n\\mathcal{R}(\\theta) = \\text{ReLU}\\Big( \\cos(\\phi(s,a),\\mathbb{SG}\\overline{\\phi(s',a')})  -  \\mathbb{SG}\\big((\\| \\phi(s,a) \\|^2 + \\gamma^2\\| \\overline{\\phi}(s',a') \\|^2 - \\frac{\\|r\\|^2}{\\|w\\|^2} )\\frac{1}{2\\gamma \\| \\phi(s,a) \\| \\| \\overline{\\phi(s',a')} \\| } \\big)\\Big),\n$$\n\nwhere the $\\mathbb{SG}$ operation is applied to the derived upper bound. Note that our experimental results are based on this corrected equation (demonstrated by the submitted code) rather than the original Eq. (12). As a result of the $\\mathbb{SG}$ operation, the gradient of $1/\\phi(s,a)$ is not computed, thereby preserving the stability of the optimization process."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1504/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700119479054,
                "cdate": 1700119479054,
                "tmdate": 1700119479054,
                "mdate": 1700119479054,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9iqA4bzklx",
            "forum": "apXtolxDaJ",
            "replyto": "apXtolxDaJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1504/Reviewer_ykJX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1504/Reviewer_ykJX"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a novel method to control the representation rank of neural networks in deep reinforcement learning (DRL), which measures the expressive capacity of value networks. They argue that existing methods either ignore or unboundedly maximize the representation rank, which can lead to overfitting or underfitting problems."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The proposed method is well-founded. The authors establish an upper bound on the cosine similarity between the representations of consecutive state-action pairs, using the Bellman equation1. They demonstrate that this bound indirectly restricts the rank of the representation and offers a criterion for adaptive control."
                },
                "weaknesses": {
                    "value": "It is recommended to thoroughly investigate the computational overhead of the proposed method."
                },
                "questions": {
                    "value": "See Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1504/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698894368950,
            "cdate": 1698894368950,
            "tmdate": 1699636078946,
            "mdate": 1699636078946,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HuSdq3JSYd",
                "forum": "apXtolxDaJ",
                "replyto": "9iqA4bzklx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1504/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1504/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ykJX"
                    },
                    "comment": {
                        "value": "Dear Reviewer ykJX,\n\nThank you very much for your detailed review and insightful comments on our manuscript. Your feedback has been instrumental in enhancing the quality of our work.  We appreciate your recognition of the foundational aspects of our method and its capability in controlling the representation rank in DRL.\n\nIn response to your concerns about the computational overhead of BEER, we would like to offer the following clarification. \n\n> **Q1.** It is recommended to thoroughly investigate the computational overhead of the proposed method.\n\n\n**A1.** BEER introduces an additional loss term but maintains the original network architecture. This significantly mitigates the increase in computational burden. To provide a more detailed evaluation, we have conducted two key analyses:\n\n\n1. **The number of learnable parameters**. BEER operates as a regularizer without introducing any new learnable parameters to the base algorithm. This contrasts with methods like InFeR, which incorporates multiple additional heads to the value networks and significantly increases the number of learnable parameters.\n\n2. **Runtime analysis.** BEER\u2019s runtime is competitive with other algorithms and, in some cases, even more efficient. We have carefully compared the runtime of BEER with other algorithms focusing on representation rank, including SAC, using the same standard evaluation protocol. The experiments were executed on a GPU server equipped with an Intel(R) Xeon(R) Gold 6240 CPU @ 2.60GHz and NVIDIA GeForce RTX 2080 Ti GPUs. Each task was run sequentially to ensure a fair comparison. The results are as follows (H=hours). \n\n\n\nTable 1. Runtime comparison of BEER and other algorithms. The runtime of BEER is competitive with other algorithms.\n\n| Env                | BEER  | INFER | TD3   | SAC   | DR3   |\n|--------------------|-------|-------|-------|-------|-------|\n| pendulum-swingup   | 1.43H | 1.79H | 1.20H | 1.68H | 1.34H |\n| acrobot-swingup    | 1.46H | 1.83H | 1.20H | 1.71H | 1.36H |\n| hopper-hop         | 1.48H | 1.83H | 1.18H | 1.74H | 1.30H |\n| finger-spin        | 1.48H | 1.81H | 1.25H | 1.85H | 1.29H |\n| **Average Time**   | 1.47H | 1.81H | 1.21H | 1.74H | 1.32H |\n\n\nThese results show that BEER's runtime is competitive with other algorithms.\n\nWe have included this analysis in Appendix H of our revised manuscript for a comprehensive understanding.\n\nWe hope this response addresses your concerns and further supports the feasibility of our approach. We remain open to any additional queries and are committed to continually improving our work. Thank you for considering our response.\n\n\nSincerely,\nAuthors of Submission 1504.\n\nReferences\n\n[1] Lyle C, Rowland M, Dabney W. Understanding and Preventing Capacity Loss in Reinforcement Learning[C]//International Conference on Learning Representations. 2021."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1504/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700119336157,
                "cdate": 1700119336157,
                "tmdate": 1700119336157,
                "mdate": 1700119336157,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]