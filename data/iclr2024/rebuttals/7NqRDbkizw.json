[
    {
        "title": "DIA: Diffusion based Inverse Network Attack on Collaborative Inference"
    },
    {
        "review": {
            "id": "eSodsVfaXH",
            "forum": "7NqRDbkizw",
            "replyto": "7NqRDbkizw",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4538/Reviewer_wMLT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4538/Reviewer_wMLT"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a diffusion-based inverse network attack called DIA for collaborative inference systems. DIA employs a feature map awareness conditioning mechanism and outperforms previous attacks in terms of SSIM, PSNR, and MSE, particularly on CNN, ResNet, and ViTs. The study identifies the vulnerability of ViTs in collaborative inference, raising concerns about deploying transformer-based models in such systems. The paper presents improved reconstruction results and insights into the vulnerability of ViT models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed feature map awareness conditioning mechanism appears to be novel to best of my knowledge\n- The authors present superior performance to the compared methods\n- The paper is easy to follow."
                },
                "weaknesses": {
                    "value": "- The results in Figure 1 for BBA and EINA look relatively weak. The literature [1] indicates that it shouldn't be an issue to retrieve the original image from intermediate layers. Especially for relatively early splits. \n- The authors did not compare previous methods for Table 5,6,7. Why not? \n- The distribution of the \"different\" datasets seems to remain close (CIFAR 10, Tiny ImageNet). Could the authors choose more disjoint datasets, such as Tiny ImageNet and FairFace (or similar)? \n- Could the authors also compare the retrieval performance of a simple autoencoder network?\n- The paper misses ablation studies to justify the design choices behind the awareness conditioning mechanism. \n\n[1] Noisy adversarial representation learning for effective and efficient image obfuscation; UAI 2023"
                },
                "questions": {
                    "value": "Please address the points mentioned in the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4538/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4538/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4538/Reviewer_wMLT"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4538/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698133829388,
            "cdate": 1698133829388,
            "tmdate": 1699636430934,
            "mdate": 1699636430934,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "SoSi1M6QUe",
            "forum": "7NqRDbkizw",
            "replyto": "7NqRDbkizw",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4538/Reviewer_9V3L"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4538/Reviewer_9V3L"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a novel diffusion-based inverse network attack (DIA) designed for collaborative inference systems, emphasizing the increasing importance of evaluating privacy and security in resource-constrained computing environments where large neural networks are deployed. The study provides extensive empirical results, demonstrating the effectiveness of DIA in significantly improving image quality metrics when applied to various neural network architectures, particularly Vision transformers (ViTs), highlighting their substantial vulnerability. As a result, the paper raises a red flag regarding the deployment of transformer-based models in collaborative inference systems, underscoring the necessity for heightened security considerations in such settings."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThe paper highlights the critical issue of evaluating the privacy and security aspects of collaborative inference systems, suggesting that as these systems become more widespread, understanding their potential vulnerabilities is essential.\n2.\tThe paper introduces a novel attack method called \"DIA\" (Diffusion-based Inverse Network Attack) designed specifically for collaborative inference systems. DIA leverages a unique feature map awareness conditioning mechanism to guide the diffusion model."
                },
                "weaknesses": {
                    "value": "The paper provides an overview of the DIA attack but lacks in-depth methodological details. Readers may find it challenging to understand the attack's intricacies, as the paper does not delve deeply into the specifics of how the attack works. A more detailed explanation of the attack mechanism, algorithms, and technical intricacies would enhance the paper's comprehensibility and its potential for replication by other researchers."
                },
                "questions": {
                    "value": "1.\tIn section 3.2, do the authors contemplate a situation where the server needs to make multiple requests to the client for acquiring the intermediary feature output to train the inversion model? Is this assumption feasible?\n2.\tThe process of training high-performance diffusion models can be costly. What is the additional training burden associated with the Companion Net?\n3.\tThe Companion Net directs the diffusion model using channel concatenation, resembling established image guidance techniques (where the lightweight network functions akin to the CLIP image encoder). Could you provide a more detailed explanation of the significance of this method?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4538/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698452960661,
            "cdate": 1698452960661,
            "tmdate": 1699636430832,
            "mdate": 1699636430832,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "twESZ4M9w4",
            "forum": "7NqRDbkizw",
            "replyto": "7NqRDbkizw",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4538/Reviewer_ZM8C"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4538/Reviewer_ZM8C"
            ],
            "content": {
                "summary": {
                    "value": "The paper delves into Inverse Network Attacks in Deep Learning, mainly focusing on collaborative inference systems within resource-constrained computing environments. A significant highlight of the study is the introduction of a \"diffusion-based inverse network attack,\" abbreviated as DIA, designed specifically for the image task in collaborative inference systems. This technique innovates with a feature map awareness conditioning mechanism that steers the diffusion model. The paper sets itself apart by presenting empirical results that showcase the proposed attack's efficacy, indicating substantial improvement percentages with different deep learning networks compared to previous methodologies. The paper concludes experimentally that the ViT model is more vulnerable."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tScenario: The paper proposes a critical scenario, the collaborative inference system within a resource-constrained computing environment. As deep learning models get larger (e.g. LLMs), collaborative inference would be common. Therefore, exploring attacks in this scenario is necessary.\n2.\tSystem: The paper provides a complete system, including the training and inference details.\n3.\tNovelty: The paper has a Feature Map Awareness Conditioning Mechanism, which is an extra companion net added on a Unet. By concatenating the intermediate outputs of Unet with those of the Companion Net, the model can predict the inputs of the target model more accurately."
                },
                "weaknesses": {
                    "value": "1.\tDataset: The paper provides two different scenarios for the experiments: the same dataset and a different dataset. However, both scenarios use the same image size. It is too ideal to assume the target model and attack model have the same input image size. Moreover, the resolution of an image is 32 * 32, which is tiny and limited performance for a realistic environment.\n2.\tTarget Model: The paper provides three target models: CNN, ResNet, and ViT. The model size of the target models is tiny, especially the CNN. It only has six convolutional layers and two fully connected layers. Commonly, it does not need a collaborative inference system to handle. The author mentions the LLMs and the resource-constrained computing environments in the introduction, which is inconsistent with the target model size. Using this attack on such a small model is not convincing.\n3.\tVulnerability of ViT: The paper uses an empirical method to evaluate the vulnerability of ViT. However, the paper uses a tiny ViT, which only has three heads and 12 attention blocks. It cannot represent all ViT-based models."
                },
                "questions": {
                    "value": "please respond to the weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4538/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698834822353,
            "cdate": 1698834822353,
            "tmdate": 1699636430758,
            "mdate": 1699636430758,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]