[
    {
        "title": "Quadratic models for understanding neural network dynamics"
    },
    {
        "review": {
            "id": "2rm13ZSK4P",
            "forum": "PvJnX3dwsD",
            "replyto": "PvJnX3dwsD",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6138/Reviewer_5b1y"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6138/Reviewer_5b1y"
            ],
            "content": {
                "summary": {
                    "value": "This work shows that quadratic models exhibit the catapult phase of neural networks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The strength of the work lies in the soundness of the theory and that the topics covered by the paper are all pertinent problems to the contemporary deep learning theory."
                },
                "weaknesses": {
                    "value": "There are quite a few fatal weaknesses in my opinion.\n\n1. The paper covered too many topics that it feels that it does not achieve any point satisfactorily. For example, the paper feels mistitled. The main focus of the paper is the catapult mechanism -- which does appear in deep learning but cannot represent all types of \"neural network dynamics.\" In my opinion, the catapult mechanism is a rather special / specific type of dynamics and the title is an overclaim. If the authors change the title to a more proper one, the paper could be much easier to evaluate.\n\n2. Lack of discussion of a highly relevant problem. Essentially, within the framework of quadratic models, it appears to me that the catapult mechanism is nothing but what the academia traditionally calls \"chaos.\" For example, consider a width-1 quadratic model, and compare the dynamics of GD to that of a logistic map -- the dynamics is essentially identitical -- the loss of local stability leads to chaos in the logistic map, and the same here in the quadratic model. The authors need to discuss this point in my opinion."
                },
                "questions": {
                    "value": "See weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6138/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698037858487,
            "cdate": 1698037858487,
            "tmdate": 1699636665196,
            "mdate": 1699636665196,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "j0qvQVSteD",
                "forum": "PvJnX3dwsD",
                "replyto": "2rm13ZSK4P",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6138/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6138/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the comments. We will address your concerns and questions below.\n\n*W1: The paper covered too many topics that it feels that it does not achieve any point satisfactorily. For example, the paper feels mistitled. The main focus of the paper is the catapult mechanism -- which does appear in deep learning but cannot represent all types of \"neural network dynamics.\" In my opinion, the catapult mechanism is a rather special / specific type of dynamics and the title is an overclaim. If the authors change the title to a more proper one, the paper could be much easier to evaluate.*\n\nWe feel the title should not preclude the evaluation of the paper.  Nevertheless, we have changed the title to \"Quadratic models for understanding catapult dynamics of neural networks\" to emphasize connections to catapult dynamics. We hope this addresses your concern and will result in a more favorable evaluation and score.  \n\n*W2: Lack of discussion of a highly relevant problem. Essentially, within the framework of quadratic models, it appears to me that the catapult mechanism is nothing but what the academia traditionally calls \"chaos.\" For example, consider a width-1 quadratic model, and compare the dynamics of GD to that of a logistic map -- the dynamics is essentially identitical -- the loss of local stability leads to chaos in the logistic map, and the same here in the quadratic model. The authors need to discuss this point in my opinion.*\n\nThe catapult dynamics considered in our paper is not chaotic, and as such does not seem to be connected with the dynamics of the logistic map.  Would you be able to share a reference so we understand your point better?"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6138/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700368666823,
                "cdate": 1700368666823,
                "tmdate": 1700368666823,
                "mdate": 1700368666823,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jE2MINGXaw",
                "forum": "PvJnX3dwsD",
                "replyto": "j0qvQVSteD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6138/Reviewer_5b1y"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6138/Reviewer_5b1y"
                ],
                "content": {
                    "title": {
                        "value": "Reply"
                    },
                    "comment": {
                        "value": "The new title feels much better.\n\nFor chaos, consider the simplest type of quadratic model with width 1: $f(x)=w^2$ where $w$ is a trainable parameter, on a simple MSE loss: $L= (w^2 -1)^2$. This problem is not completely identical to logistic map, but very similar to it.\n\nOne way to see chaos is this: expand the loss function around the local minimum $w=1$, we obtain the dynamics of the quantity $q_t:=w_t-1$:\n$$\\Delta q_t = - \\eta (4q_t + 8 q_t^2) + O(q_t^3),$$\nwhich implies that \n$$q_{t+1} = (1 - 4 \\eta) q_t + 8 \\eta q_t^2  + O(q_t^3).$$\nNow, compare this dynamics with the dynamics of the logistic map, they are not identical, but qualitatively the same. At a small $\\eta$ the dynamics is approximated by gradient flow, and there is no jump. When $\\eta> 1/2$, we have the onset of chaos (due to the loss of stability), and one begins to observe limit cycles and bifurcations (if one plot the distribution of $q_t$). When $\\eta$ is larger than $1$ (I did not check this value, but I think it is a close estimate), the dynamics diverges due to global instability. Compare what I said with figure 1b in the paper\n\nIn fact, in this type of deterministic dynamics on a nonquadratic energy function, chaos almost always appears when the local stability in a local minimum is lost, which is given by the $\\eta_{crit}$ in the theory proposed by the authors."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6138/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700709704101,
                "cdate": 1700709704101,
                "tmdate": 1700709704101,
                "mdate": 1700709704101,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Qi1Zkpmvn3",
                "forum": "PvJnX3dwsD",
                "replyto": "32TnFYoefU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6138/Reviewer_5b1y"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6138/Reviewer_5b1y"
                ],
                "content": {
                    "title": {
                        "value": "Reply"
                    },
                    "comment": {
                        "value": "Thanks for the nice reference.\n\nThis raises another question. Naively, I expect the problem studied in the present manuscript has a chaos phase. This reference (arXiv:2310.01687) also shows that there is a chaos phase in the related problems. However, the authors claim that there is no chaos in the problem in the manuscript. Why is this case? I think the authors ought to study, discuss the reason and compare with this reference they mentioned."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6138/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700731082424,
                "cdate": 1700731082424,
                "tmdate": 1700731082424,
                "mdate": 1700731082424,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "FEM3AOCjJx",
            "forum": "PvJnX3dwsD",
            "replyto": "PvJnX3dwsD",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6138/Reviewer_JHXp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6138/Reviewer_JHXp"
            ],
            "content": {
                "summary": {
                    "value": "I was asked to review this paper at the last minute, so although I did not get the chance to work carefully through the proofs, I can comment on the broad content and contributions\n\nThe paper analyzes optimization and generalization properties of neural networks using quadratic models. It shows theoretically and empirically that quadratic models exhibit the \"catapult phase\" with large learning rates, explaining a property of neural networks not captured by linear models. The quadratic model and its (changing) tangent kernel is studied analytically for the case of a single training example and multiple uni-dimensional training samples. Three regimes are identified. When catapault effects occur, better generalization is observed in quadratic models. Experiments demonstrate quadratic models parallel neural networks better than linear models in generalization with large learning rates."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper rigorously analyzes the catapult phase in NQMs theoretically. Prior works have attempted similar analyses, but the presentation here is particularly readable. The experiments validating theory and demonstrating applicability are thorough. They successfully demonstrate that NQMs better capture neural network behavior than linear models. The experiments in the appendix in particular provides good additional support. The mathematical analysis appears solid."
                },
                "weaknesses": {
                    "value": "The architectures and datasets used are still relatively limited. It would also be good to highlight what the incremental value of this paper is over prior work on quadratic models. A CNN and transformer experiment would be particularly welcome. \n\nFrom a cursory literature review, I have found this paper which has relatively substantial overlap in topic, and I believe should at least be cited (Meltzer and Liu https://arxiv.org/abs/2301.07737). A more thorough set of references on recent work around the catapult effect and edge of stability would also benefit the paper. If these changes are incorporated and a more thorough related works section is added, I will likely raise my score.\n\nFrom empirical work, I've also seen that quadratic model's validation curve only tracks the NN's curve in the early stages of training, but then diverges from it. It would be nice to give an example of the limitations of the quadratic model for understanding generalization. Being clear about potential limitations of quadratic models to fully model neural networks would be welcome."
                },
                "questions": {
                    "value": "Have you analyzed how the Hessian evolves during catapult phase? This could shed some light onto the phase transition.\n\nIt may be interesting to consider explicitly varying the feature learning parameter (e.g. $\\alpha$ in Chizat et al) and see how the quadratic model differs from the linear one. This would be related to going into $\\mu$ parameterization as in Yang. \n\nCan you relate observed properties of trained NQMs to improvements in generalization, perhaps through the lens of something like kernel-target alignment for the after-kernel of the quadratic model?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6138/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6138/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6138/Reviewer_JHXp"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6138/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698719757377,
            "cdate": 1698719757377,
            "tmdate": 1699636665084,
            "mdate": 1699636665084,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Mg3XZZy3wC",
                "forum": "PvJnX3dwsD",
                "replyto": "FEM3AOCjJx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6138/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6138/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the positive feedback and insightful comments. We will address your concerns and questions below.\n\n*W1.a: The architectures and datasets used are still relatively limited... A CNN and transformer experiment would be particularly welcome.*\n\n Indeed we have experiments with CNNs as shown in Figure 4 and 16.  We experimented with various datasets, including vision (CIFAR10, SVHN, MNIST), speech (FSDD) and language (AG NEWS). As a primarily theoretical paper, we believe this is a good scope of experiments.\n\n*W1.b:  It would also be good to highlight what the incremental value of this paper is over prior work on quadratic models.*\n\nThe related paper [1] introduced and analyzed the NQM (called quadratic models in their book), but our work analyzed the training dynamics with large learning rates, which was not discussed in [1].\n\n1. Roberts, Daniel A., Sho Yaida, and Boris Hanin. The principles of deep learning theory. Cambridge, MA, USA: Cambridge University Press, 2022.\n\n*W2: From a cursory literature review, I have found this paper which has relatively substantial overlap in topic, and I believe should at least be cited (Meltzer and Liu https://arxiv.org/abs/2301.07737). A more thorough set of references on recent work around the catapult effect and edge of stability would also benefit the paper.*\n\nThanks for pointing out this related work. In fact, the first version of our work was prior to [Meltzer and Liu], and we weren't aware of it. We added a discussion in the updated draft.\n\nAs for the Edge of Stability (EoS), we have not seen a clear connection between EoS and catapult dynamics. Although there seems to be some similarities between Edge of Stability (EoS) and catapult dynamics at first glance, we noticed a few key differences between the two: 1) the training loss can increase to a large value,  a order of $\\Theta(m)$ with $m$ being the network width, in the catapult dynamics, while it does not observed to increase significantly in EoS, 2) there is a single loss spike in the catapult dynamics of full-batch gradient descent, while there are often multiple loss oscillations in EoS, 3) the catapult phase phenomenon often improve generalization across various tasks [Lewkowycz et al. 2020], while it is unclear if EoS has any effect on the generalization. \nThe original EoS paper [1] conjectures that the training loss oscillations could be micro-catapults, however, there is no direct evidence for the connection between EoS and catapult dynamics.\n\n1. J. Cohen,  et al. \"Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability.\" International Conference on Learning Representations. 2020.\n\n*W3: From empirical work, I've also seen that quadratic model's validation curve only tracks the NN's curve in the early stages of training, but then diverges from it. It would be nice to give an example of the limitations of the quadratic model for understanding generalization. Being clear about potential limitations of quadratic models to fully model neural networks would be welcome.*\n\nIn our experiments, the generalization performance of neural networks seems to perform better than their corresponding NQMs when the learning rate is large, i.e., catapult occurs. One possible reason is that  NQMs are the second-order approximation of neural networks, while they can exhibit the catapult phase phenomenon the same as the neural networks, they may not be able to learn the same features as the neural networks. That is to say, to learn certain features, higher-order terms are needed. This is a complex question and a direction for future work."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6138/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700368348731,
                "cdate": 1700368348731,
                "tmdate": 1700368365304,
                "mdate": 1700368365304,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LWP3q1SbQE",
            "forum": "PvJnX3dwsD",
            "replyto": "PvJnX3dwsD",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6138/Reviewer_F9oB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6138/Reviewer_F9oB"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes using neural quadratic models -- second order taylor expansion of any function f around initial parameters $w_0$ -- as a way to study neural network dynamics. The authors start by explaining that linear dynamics perspective of neural networks falls short in explaining some of the behaviors in neural network dynamics; specifically, catapult phase of learning rate. They approximate a two layer neural network using its second order expansion. They first show that for a single training example, where tangent kernel reduces to a scalar, monotonic convergence, catapult phase, and divergence are separated based on learning rate and inverse of kernel value at random initialization. They further extend their analysis to uni-dimensional multiple example setting where the analysis is driven by the eigenvectors of the kernel matrix. Finally, the authors empirically show that for wide neural networks, catapults happen in the top eigenspace of the kernel -- similar to the multiple example setting. Experimental results suggest that catapult phase results in lower test error compared to error with sub-critical learning rate for the quadratic model, mimicing the dynamics of neural networks more closely."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is written well and in general easy to follow. Empirical results on top eigenspace of tangent kernel for analyzing general wide neural networks is convincing."
                },
                "weaknesses": {
                    "value": "Several assumptions about underlying the theory are not clear and different from the practice.\n\n1. The neural network in Eq (9) is initialized as $u_i \\sim \\mathcal{N}(0, I_d)$ and $v_i \\sim Unif(-1, 1)$. Can you explain why $v_i$ is initialized different from $u_i$, also different from the typical inverse fanin/fanout initialization in practice?\n\n2. The assumption that width (m) is larger than data size (n) which is assumed to be a small constant is unrealistic. While in the limit where width goes to $\\inf$, this would be the case but for any finite width network, this does not hold in practice. Is this assumption crucial, can you still assume that $n/m$ does not necessarily go to zero?\n\n3. $p_1(t)$ is the top eigenvector of $K(t)$. Given that $p_1(t)$ is not necessarily equal to $p_1(t+1)$, it is not clear how you derived $\\lambda_1(t+1)=\\lambda_1(t)-p_1(t)^TR_K(t)p_1(t)$. Could you please explain in more detail?\n\n4. In Eq(12), $R_\\lambda(t)$ is defined without the minus sign. In the following paragraph, you mention that \"$R_\\lambda(t)$ stays positive and results in monotonic decrease of kernel\" which makes sense since $\\lambda(t)=\\lambda(t-1)-R_\\lambda(t)$. But in the next paragraph, you write down $\\lambda(t)=\\lambda(0)+\\sum_{\\tau=0}^{t} R_\\lambda(\\tau)$ which suggests that $R_\\lambda(t)$ should include the minus sign. Please clarify.\n\n5. Related to above, I think it should be $\\lambda(t+1)=\\lambda(0)+\\sum_{\\tau=0}^{t} R_\\lambda(\\tau)$ or $\\lambda(t)=\\lambda(0)+\\sum_{\\tau=0}^{t-1} R_\\lambda(\\tau)$\n\n6.  You mention in the decreasing phase section in page 6 that decrease in $v(t)$ would cause a decrease in $\\kappa(t)$. But in Eq (13), reducing $v(t)$ would increase inside of square which should lead to an increase in $\\kappa(t)$; unless, $u(t)+w(t)<0$ which is not clear if it holds. Please clarify.\n\n7. In Eq (10), $1/\\sqrt(d)$ is missing from $\\sigma(u_{0,i}^Tx)$. It is present in Appendix A.\n\n8. Page 27 in the Appendix, it should be $\\Pi_1 \\mathcal{L}(t)=K_1(t)\\Pi_1 \\mathcal{L}(t-1)$"
                },
                "questions": {
                    "value": "Please see above for related questions as they are more meaningful within their respective contexts."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6138/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698797629545,
            "cdate": 1698797629545,
            "tmdate": 1699636664940,
            "mdate": 1699636664940,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "063iwyhlo7",
                "forum": "PvJnX3dwsD",
                "replyto": "LWP3q1SbQE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6138/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6138/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the insightful comments. We will address your concerns and questions below.\n\n*W1: The neural network in Eq (9) is initialized as $u_i \\sim \\mathcal{N}(0,I)$ and $v_i \\sim Unif(-1,1)$. Can you explain why $v_i$ is initialized different from $u_i$, also different from the typical inverse fanin/fanout initialization in practice?*\n\nThis initialization/parameterization strategy adopted in our paper is the so-called NTK parameterization [1]. It is standard in theoretically analyzing neural networks with large width, e.g., [1,2,3].  In the \"typical inverse fan-in/fan-out initialization in practice\", NTK scales as $O(m)$, which blows up for large width. However, in the NTK parameterization, NTK scales as $\\Theta(1)$.\n\nThe reason why we use the uniform distribution of $v_i$, instead of the normal distribution $\\mathcal{N}(0,1)$, is to make sure $v_i$ is bounded, which simplifies the analysis. In the case of  $v_i \\sim \\mathcal{N}(0,1)$, similar results will hold with extra $log(m)$ factors in some $O$ terms, with a high probability that depends on $m$. \n\nDrawing $v_i$ from a bounded distribution is a common setting in literature, for example, [2,3].\n\n1. A. Jacot, et al. \u201cNeural tangent kernel: Convergence and\ngeneralization in neural networks\u201d. NeurIPS, 2018.\n\n2.  S. Du S., et al. \"Gradient Descent Provably Optimizes Over-parameterized Neural Networks.\" International Conference on Learning Representations. 2018.\n\n3. Z. Ji, and T. Matus. \"Polylogarithmic width suffices for gradient descent to achieve arbitrarily small test error with shallow ReLU networks.\" International Conference on Learning Representations. 2019.\n\n*W2: The assumption that width ($m$) is larger than data size ($n$) which is assumed to be a small constant is unrealistic. While in the limit where width goes to $inf$, this would be the case but for any finite width network, this does not hold in practice. Is this assumption crucial, can you still assume that $n/m$ does not necessarily go to zero?*\n\nHaving $m>n$, i.e., over-parameterization is a common setting in theoretical research of recent years. For example, [1] assumes $m = \\Omega(n^6)$, [2] assumes $m = \\Omega(n^4)$, [3] assumes $m = \\Omega(n^{24})$. Many interesting findings and results in this large width setting can often be experimentally observed in practical settings. In practice, the catapult dynamics still occur when the width and the size of datasets are comparable. For example, in our experiment for FSDD dataset, the catapult still occurs when the width is $1,000$ and the size of the dataset is $256$.\n\n1. S. Du S., et al. \"Gradient Descent Provably Optimizes Over-parameterized Neural Networks.\" International Conference on Learning Representations. 2018.\n2. S. Du S., et al. \"Gradient descent finds global minima of deep neural networks.\" International conference on machine learning. PMLR, 2019.\n3. Z. Allen-Zhu, et al. \"A convergence theory for deep learning via over-parameterization.\" International conference on machine learning. PMLR, 2019.\n\n*W3: Given that $p_1(t)$ is not necessarily equal to $p_1(t+1)$, it is not clear how you derived $\\lambda_1(t+1) = \\lambda_1(t) - p_1(t)^T R_K(t) p_1(t)$...*\n\nWe suppose you were referring to Appendix N.3. This is a typo: the equation should be $p_1(t)^T K(t+1)p_1(t) = \\lambda_1(t) - p_1(t)^T R_K(t) p_1(t)$. The experiments in Appendix N.3 show that the training dynamics confined to the top eigenspace of the tangent kernel i.e., $p_1(t)$ can almost capture the catapult dynamics.  We have fixed it in the revision.\n\n*W4: In Eq(12), $R_\\lambda(t)$ is defined without the minus sign....which suggests that $R_\\lambda(t)$ should include the minus sign.*\n\n*W5: Related to above, I think it should be $\\lambda(t) = \\lambda(0) - \\sum_{\\tau = 0}^{T-1} R_\\lambda(\\tau)$ ...*\n\n\nThanks for pointing it out. We have fixed the typo.\n\n*W6: You mention in the decreasing phase section in page 6 that decrease in $v(t)$ would cause a decrease in  $\\kappa(t)$. But in Eq (13), reducing \n$v(t)$ would increase inside of square which should lead to an increase in  $\\kappa(t)$; unless $u(t) + w(t)<0$ which is not clear if it holds. Please clarify.*\n\nNote that at initializaiton $v(0) > 2$ and $u(0) + w(0) = O(1/m)$. Therefore $\\kappa(0) = (1-v(0) + O(1/m))^2 >1$ since $1-v(0) < -1$. As $v(t)$ decreases, $|1-v(t)|$ will also decrease therefore $\\kappa(t)$ decreases. \n\nAdditionally, the fact that $u(t) + w(t)>0$ and keeps increasing will further make $\\kappa(t)$ decrease. \n\n*W7: In Eq.(10), $1/\\sqrt{d}$ is missing from $\\sigma(u_{0,i}^T x).$ It is present in Appendix A*\n\nIn the theoretical analysis, we only consider ReLU activation function which is homogenous, hence we can extract the scaling factor $1/\\sqrt{d}$ out of the function $\\sigma(\\cdot)$.\n\n*W8: Page 27 in the Appendix, it should be $\\Pi_1 L_1(t) = K_1(t) \\Pi_1 L(t-1$*\n\nWe denote the scaling factor by $\\kappa_1(t)$, consistent with the notation used in the single training sample scenario."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6138/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700368162190,
                "cdate": 1700368162190,
                "tmdate": 1700377573483,
                "mdate": 1700377573483,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5LDCetm5Rb",
            "forum": "PvJnX3dwsD",
            "replyto": "PvJnX3dwsD",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6138/Reviewer_e4J5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6138/Reviewer_e4J5"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the \"catapult phase\" during training models with large learning rates.\nImportantly, it proposes Neural Quadratic Models (NQMs) as a tool to study it and proves that when large learning rates are used they exhibit a similar catapult phase as modern neural networks, which is not the case of other tools such as linear models, a popular theoretical tool to analysis the learning of neural networks.\nThe paper presents these findings with proofs and suggests that NQMs can be useful tools to analyze neural networks in the future."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "**originality** The finding of the paper seems to be novel and the proposal of using NQMs can be new as well.\n\n**quality** The finding and theory from the paper seems to be sound.\n\n**clarity** The paper is overall well-written but can be hard to follow for people who are not very familiar with the field.\n\n**significance** The contribution of the paper seems to be significant and can enable many future work on analysis with NQMs, which could lead to more useful findings than the catapult phase."
                },
                "weaknesses": {
                    "value": "The proposed term Neural Quadratic Models seems to be unnecessary as for linear models we don't call them Neural Linear Models."
                },
                "questions": {
                    "value": "Some recent findings such as the deep double descent are high-dependent on the size of the neural networks and other hyper-parameters.\nIs the \"catapult phase\" here sensitive to other hyper-parameters apart from learning rates?\nI don't see many conditions for the theorem presented in the paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6138/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698811435234,
            "cdate": 1698811435234,
            "tmdate": 1699636664818,
            "mdate": 1699636664818,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XHXQp8IH4s",
                "forum": "PvJnX3dwsD",
                "replyto": "5LDCetm5Rb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6138/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6138/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the positive feedback and insightful comments. We will address your concerns and questions below.\n\n*W1: The proposed term Neural Quadratic Models seems to be unnecessary as for linear models we don't call them Neural Linear Models.*\n\nThe term \"quadratic model\" can refer to any model that generically has a quadratic form. In this paper, we study the special instance: the quadratic model that best approximates the neural network. Hence, we think the term \"Neural Quadratic Model\u201d describes this specific model the best. This is similar to the situation of \"Neural tangent kernel\" (NTK). NTK is a specific kernel associated with neural networks}\n\nWe believe it is important to highlight the close relation between the quadratic models and neural networks since they are the second-order Taylor expansion of the networks. \n\nSome works, e.g., [1] indeed refer to the linear approximation of neural networks as neural tangent models, to highlight their close relation.\n\n1. B. Ghorbani, et al. (2019). Limitations of lazy training of two-layers neural network. NeurIPS.\n\n*Q1: Some recent findings such as the deep double descent are high-dependent on the size of the neural networks and other hyper-parameters. Is the \"catapult phase\" here sensitive to other hyper-parameters apart from learning rates? I don't see many conditions for the theorem presented in the paper.*\n\nThe width $m$ of the network affects the magnitude of the catapult dynamics. As we have shown in the paper, the loss value at the peak of the catapult scales as $O(m/\\log m)$. We don't observe dependence on other hyper-parameters."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6138/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700367319067,
                "cdate": 1700367319067,
                "tmdate": 1700367319067,
                "mdate": 1700367319067,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WQiJOpysS4",
                "forum": "PvJnX3dwsD",
                "replyto": "XHXQp8IH4s",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6138/Reviewer_e4J5"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6138/Reviewer_e4J5"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks the authors for their clarification. I acknowledge that I've read the response."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6138/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700684201062,
                "cdate": 1700684201062,
                "tmdate": 1700684201062,
                "mdate": 1700684201062,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "96Jf9BNAIo",
            "forum": "PvJnX3dwsD",
            "replyto": "PvJnX3dwsD",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6138/Reviewer_Unww"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6138/Reviewer_Unww"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies a quadratic approximation of two-layer neural networks to understand optimization behaviours that cannot be captured by linear models. More precisely they theoretically evidence the so-called catapult dynamics for respectively one and multiple training points, ie they show the existence of two critical values for the learning rate which delimits respectively exponential convergence to the minimum, catapult dynamics (ie first increase of the loss then convergence to low loss) and finally divergence. Finally they provides experiments evidencing catapult dynamics as well as the fact that the quadratic approximation of a neural networks shows similar behaviours that the neural network above the critical learning rate."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper is well-written with clear figures and a good explanation of the setting and the results. This paper studies a very interesting phenomenon about the optimization of neural networks and has to deal with non-linear phenomena which are usually not well understood. They are able to evidence theoretically the catapult dynamics and the existence of two critical learning rates when dealing with neural quadratic models.\n\nEmpirical results shed light on the similarity of behaviours in terms of generalization between the NQM and the neural network function, evidencing the coherence of the quadratic model."
                },
                "weaknesses": {
                    "value": "I find the proofs a bit hard to understand because of the use in the proofs of O,o, $\\Omega$ notations. Hiding constants behind such notations makes the proofs a bit cloudy to me. \n\n1)Especially I have some concerns about the proof of lemma 1 in appendix D: you use a proof by induction, and still use O,o notations. But summing $O$ terms remains $O$ only when the number of iterations is controlled. To still have $O$ in the end of the summation with respect to m, it should be checked that the summation index T is itself $O(1)$. However I am not sure such a result is proved (correct me if I'm wrong).\nEspecially it seems to me that it might not be the case by considering the fact that T must satisfy a relation of the form $(1+\\delta)^T\\sim \\log(m)$ with $\\delta \\sim \\frac{\\log(m)}{\\sqrt{m}}$. Indeed $u(t)$ goes from $O(1/m)$ to $O(\\log(m)/m)$. In that case, $T\\sim \\frac{\\log(\\log(m))\\sqrt{m}}{\\log(m)}$ which is not $O(1)$.\n\n2) Another ambiguity about the $O$ notation is for example when it is stated: $\\kappa(0)>(1+\\delta-O(1/m))^2>(1+\\delta-O(\\delta^2/\\log(m)))^2$ in appendix D. In full generality it seems wrong for general sequences as it depends on the constants in the $O$ itself and their sign. For example $(1+\\delta))^2<(1+\\delta-(-3\\delta^2/\\log(m)))^2$. I think this statement in its current form would perhaps need an additional study of the constants, their sign or if they are zero.\n\n3) The non-linearity that is used in this paper is a ReLU: it allows to compute easily the second derivative of the neural network function (it deletes the diagonal terms of the hessian of the neural network function). My only concern is regarding the generalization to non-linearities that are not piecewise linear and hence which make another term appear in the Hessian of the neural network function, which corresponds to the second derivative of the non-linearity (correct me if I'm wrong). Could the author comment about how to handle this and if they expect the analysis to be the same and the results to still hold?"
                },
                "questions": {
                    "value": "1) I am curious if you could clarify the links, if they exist, between catapult dynamics and recent works on edge of stability analysis of neural networks (cf the paper \"Second-order regression models exhibit progressive sharpening to the edge of stability\" that is not cited but seems to me very related to your setting). It seems interesting because both studies explore the influence of a non-linear quadratic term on the coupled dynamics of the sharpness and the learning rate.\n\n2) It is written in the text that the results hold with high probability over initialization but I'm not sure if this is written in the statement of the theorems. Perhaps it could be added in the theorems themselves.\n\n3) I find the results interesting and they provide good contribution. I would increase my score if the authors address my concerns about the clarity of $O,o,\\Omega$ notations in the proof, especially the proof by induction."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "This paper is mostly theoretical and does not present ethics concerns."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6138/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6138/Reviewer_Unww",
                        "ICLR.cc/2024/Conference/Submission6138/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6138/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699565558735,
            "cdate": 1699565558735,
            "tmdate": 1700683996020,
            "mdate": 1700683996020,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mpmyBvEL72",
                "forum": "PvJnX3dwsD",
                "replyto": "96Jf9BNAIo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6138/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6138/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the insightful comments. We will address your concerns and questions below.\n\n*W1: I have some concerns about the proof of lemma 1 in appendix D ... But summing $O$ terms remains $O$ only when the number of iterations is controlled. To still have $O$ at the end of the summation with respect to $m$, it should be checked that the summation index $T$ is itself $O(1)$. However I am not sure such a result is proved (correct me if I'm wrong). Especially it seems to me that it might not be the case by considering the fact that T must satisfy a relation of the form $(1+\\delta)^T \\sim \\log m$ with $\\delta \\sim \\log m/\\sqrt{m}$. Indeed $u(t)$ goes from $O(1/m)$ to $O(\\log m /m)$. In that case, $T \\sim \\log (\\log m)\\sqrt{m}/\\log m$ which is not $O(1)$.*\n\nIn the proof of Lemma 1, $u(t)$ grows geometrically from $O(1/m)$ to $O(\\log m /m)$ with rate $\\kappa(t) \\geq (1+\\delta - O(\\delta^2/\\log m))^2>1$ for large enough $m$. Note that  the summation of a sequence that grows geometrically with a ratio $(1+\\delta)^2>1$ can be controlled by the last term, i.e., $\\sum_{t=1}^T u(t) = \\Theta(u(T)/\\delta)$.\nHence, even if $T$ is not $O(1)$, our results still hold. We updated the draft to clarify this point. \n\n*W2: Another ambiguity about the $O$ notation is for example when it is stated: $\\kappa(0)>(1+\\delta - O(1/m))^2 > (1+\\delta - O(\\delta^2/\\log m))^2$ in appendix D.  In full generality it seems wrong for general sequences as it depends on the constants in the $O$ itself and their sign. I think this statement in its current form would perhaps need an additional study of the constants, their sign or if they are zero.*\n\nWe apologize for the confusion. In our analysis, the $O$-terms are always positive, and we explicitly write out their sign before $O$. For this inequality $\\kappa(0)>(1+\\delta - O(1/m))^2 > (1+\\delta - O(\\delta^2/\\log m))^2$, we have $m$ large enough to make sure that each term within the brackets is positive. We have updated the draft to clarify this.\n\n*W3: My only concern is regarding the generalization to non-linearities that are not piecewise linear... Could the author comment about how to handle this and if they expect the analysis to be the same and the results to still hold?*\n\n While our analysis is specific to ReLUs, our experiments for tanh and swish activation functions in Appendix N.8 also verify that our results extend to such smooth activation functions. In the literature, the analysis for smooth non-linear activation functions is often handled differently from ReLUs.\n\n\n\nIn addition, ReLU is so widely used in both theory and practice that many important theoretical results are specific to neural networks with ReLU activations.  See for example:[1,2,3]\n\n1. S. Du S., et al. \"Gradient Descent Provably Optimizes Over-parameterized Neural Networks.\" International Conference on Learning Representations. 2018.\n2. Z. Ji, and T. Matus. \"Polylogarithmic width suffices for gradient descent to achieve arbitrarily small test error with shallow ReLU networks.\" International Conference on Learning Representations. 2019.\n3. D. Zou, et al. (2020). Gradient descent optimizes over-parameterized deep ReLU networks. Machine learning, 109, 467-492.\n\n*Q1. I am curious if you could clarify the links, if they exist, between catapult dynamics and recent works on edge of stability analysis of neural networks...*\n\nAlthough there seem to be some similarities between Edge of Stability (EoS) and catapult dynamics at first glance, we noticed a few key differences between the two: 1) the training loss can increase to a large value, an order of $\\Theta(m)$ with $m$ being the network width, in the catapult dynamics, while it is not observed to increase significantly in EoS, 2) there is a single loss spike in the catapult dynamics of full-batch gradient descent, while there are often multiple loss oscillations in EoS, 3) the catapult phase phenomenon often improve generalization across various tasks [Lewkowycz et al. 2020], while it is unclear if EoS has any effect on the generalization. \nThe original EoS paper [1] conjectures that the training loss oscillations could be micro-catapults, however, there is no direct evidence for the connection between EoS and catapult dynamics. \n\n1. J. Cohen, et al. \"Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability.\" International Conference on Learning Representations. 2020.\n\n*Q2: It is written in the text that the results hold with high probability over initialization but I'm not sure if this is written in the statement of the theorems. Perhaps it could be added in the theorems themselves.*\n\nThanks for the suggestion. We have updated it in our revision."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6138/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700367207556,
                "cdate": 1700367207556,
                "tmdate": 1700367248034,
                "mdate": 1700367248034,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BEfi3O5AKA",
                "forum": "PvJnX3dwsD",
                "replyto": "mpmyBvEL72",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6138/Reviewer_Unww"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6138/Reviewer_Unww"
                ],
                "content": {
                    "title": {
                        "value": "Response to the authors about remaining concerns"
                    },
                    "comment": {
                        "value": "I thank the authors for the clarifications. However I feel that my concerns were not completely solved:\n\nW1: I get your explanation but I don't think that it answers my concern. My concern is about the method itself, which is an inductive proof by induction to show that $\\kappa(t)=(1+\\delta-O(\\frac{\\delta^2}{\\log(m)})^2$. \n\nI agree both 1) that it is true at initialization 2) with your previous argument on the summation $\\sum u(t)$ terms: you indeed get that the inductive property propagates: $\\kappa(t+1)=(1+\\delta-O(\\frac{\\delta^2}{\\log(m)})^2$. \nHowever my point is that it is valid only for $O(1)$ iterations because at each step you sum $O$ terms and group them inside one single $O$. You should ensure that the total number of $O$ terms that are summed is itself $O(1)$, i.e. that the number of iterations is itself $O(1)$, ie $T=O(1)$ which doesn't seem to be true. \nMore generally I don't think it is right to do a proof by induction with $O$ notations, without controlling the constants. For example, it is trivial that using such methods, one would have $O(m)=O(1)$ by induction (true at initialization and the property propagates one by one because $m+1=m+1=O(1)+O(1)=O(1)$). Therefore I remain unconvinced by using such a notation without properly controlling the constants.\n\nW2: I don't think this solves the problem: $(1+\\delta-\\frac{1}{m})^2<(1+\\delta)^2$ seems to be a counter example. \n\nFinally I thank the authors for their answers to the other questions I had and would be thankful if they could clarify my remaining concerns."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6138/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700424954059,
                "cdate": 1700424954059,
                "tmdate": 1700424954059,
                "mdate": 1700424954059,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YbBrlq3hNn",
                "forum": "PvJnX3dwsD",
                "replyto": "96Jf9BNAIo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6138/Reviewer_Unww"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6138/Reviewer_Unww"
                ],
                "content": {
                    "title": {
                        "value": "Response to the authors"
                    },
                    "comment": {
                        "value": "I thank the authors for their response which I have the feeling make me now understand better theorem 4 and lemma 1.\n\nI thank them for having also changed the proof of theorem 4 with explicit constants which makes it more understandable in my point of view. However I have still concerns on the proof of proposition 3 still partly because of the the $O,o,\\Theta,\\Omega$ notations.\n\nMinor concerns:\n1) there is a different definition of $\\delta$ before the \"increasing phase\" in the main paper as in the proof of lemma 2 in the appendix. Could you clarify?\n\n2) I get the intuition but do not understand the meaning of proposition 1,2,3 because I feel there lacks something of the form \"for m large enough...\". For example in proposition 3, you state \"v(t) keeps increasing...\". I feel it would be good to specify it. (or correct me if I am wrong)\n\nBigger concerns:\n3) I think that T_2 and T_1 depend both on m. I think it is important to recall it, or else I would be happy if the authors could explain me why it does not depend on m. Following this remark, I do not understand the sentence \"Therefore, for $t\\geq T_2$ such that u(t) is of the order greater than $O(1/m)$. Indeed, you cannot work with fixed $t$ if you set the condition $t\\geq T_2$ with $t$ depending on $m$. Perhaps it would be good to specify this point.\n\n4) I do not understand the proof of Proposition 2 in part H.2, starting \"decreasing. Specifically...\". Could your reformulate this part a bit? Especially: first what is meant by \"order at least O(.)\". Do you mean \"order at least $\\Omega$\" or \"order at most $O(.)$\"? Second, are you sure about $O(1/\\sqrt{log(m})$? it seems strange to me since this order is actually bigger than $1/\\log(m)$ that you were discussing before. Shouldn't it be $O(1/log(m)^2)$\n\n5) I will probably seem very attached to details but the proof by contradiction of proposition 2 is troubling me: you prove that the following statement is wrong: \"$\\forall t \\geq T_1, v(t)=4-o(1)$\". My concern is in terms of the mathematical statement of the contradiction of this. To me, the correct statement would be: \"$\\exists t \\geq T_1, 4-v(t)$ is not $o(1)$\" However, it seems not possible here since $T_1$ depends on $m$ and therefore $t$ cannot be defined. \nFurthermore I would like if the authors could clarify the following point: it seems to me that you use that the contradiction of being $o(1)$ is being $\\Omega(1)$ but I think that it it is only true for a subsequence.\n\n6) In the proof of proposition 2 it is written $u(T_1)=\\Omega(\\frac{1}{\\log(m)})$. Could the authors explain more why it is true as it seems in contrast with the statement above proposition 2: $T_1=inf (t, u(t)=\\Theta(\\frac{\\delta^2}{\\log(m)}))$ with $\\delta$ small."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6138/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700603718011,
                "cdate": 1700603718011,
                "tmdate": 1700603930424,
                "mdate": 1700603930424,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TijAIG7j6G",
                "forum": "PvJnX3dwsD",
                "replyto": "96Jf9BNAIo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6138/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6138/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the reply. We have revised the statements of propositions and proofs to get rid of $O,\\Omega,o$ by using explicit constants. And we will address your specific concerns below.\n\n*Concern 1: there is a different definition of $\\delta$\n before the \"increasing phase\" in the main paper as in the proof of lemma 2 in the appendix. Could you clarify?*\n\n This is a typo. We have fixed it.\n\n*Concern 2: I get the intuition but do not understand the meaning of proposition 1,2,3 because I feel there lacks something of the form \"for m large enough...\". For example in proposition 3, you state \"v(t) keeps increasing...\". I feel it would be good to specify it. (or correct me if I am wrong)*\n\nWe have revised the statements of propositions and used explicit constants in the proof. Now there is an explicit lower bound for $m$ for the propositions to hold.\n\n*Concern 3: I think that $T_2$ and $T_1$ depend both on m. I think it is important to recall it, or else I would be happy if the authors could explain me why it does not depend on m. Following this remark, I do not understand the sentence \"Therefore, for  $t\\geq T_2$ such that $u(t)$ is of the order greater than  $O(1/m)$. Indeed, you cannot work with fixed $t$ if you set the condition $t \\geq T_2$ with $t$ depending on $m$. Perhaps it would be good to specify this point.*\n\nWe have clarified it in the proof that $T_1,T_2$ depend on $m$.\n\nWe have revised the statements, and now the proposition becomes under certain conditions, there exits $T_2$ such that $v(T_2) <3$ (see Proposition 3 in the updated draft). \n\n*Concern 4: I do not understand the proof of Proposition 2 in part H.2, starting \"decreasing. Specifically...\". Could your reformulate this part a bit? Especially: first what is meant by \"order at least $O()$\". Do you mean \"order at least $\\Omega$\n\" or \"order at most $O$\n\"? Second, are you sure about $O(1/\\sqrt{\\log m})$\n? it seems strange to me since this order is actually bigger than $1/\\log m$\n that you were discussing before. Shouldn't it be $1/\\log^2 m$?*\n\n We have revised the proof by using explicit constants. Specifically, we added Proposition 2 to clarify when $u(t)$ is larger than $\\frac{4C}{m (4-v(t))^2}$,  $v(t)$ will decrease. \n\n*Concern  5: I will probably seem very attached to details but the proof by contradiction of proposition 2 is troubling me: you prove that the following statement is wrong: \"$\\forall t\\geq T_1, v(t) = 4-o(1)$\n\". My concern is in terms of the mathematical statement of the contradiction of this. To me, the correct statement would be: \" $\\exists t\\geq T_1$,$ 4-v(t)$ is not $o(1)$\n\" However, it seems not possible here since $T_1$ \n depends on $m$\n and therefore $t$\n cannot be defined. Furthermore, I would like if the authors could clarify the following point: it seems to me that you use that the contradiction of being \n$o(1)$ is being $\\Omega(1)$\n but I think that it it is only true for a subsequence.*\n\nWe have revised the Proposition and used explicit constants in the proof. Now we show that there exists $T_2 \\geq T_1$ ($T_2$ depends on $m$) such that $v(T_2)<3$. Note that this statement is more explicit than \" $\\exists t\\geq T_1$,$ 4-v(t)$ is not $o(1)$\".  The idea of the proof is similar: $v(t)$ will keep decreasing if $v(t)\\geq 3$ therefore $v(t)$ will be less than $3$ at a certain iteration.\n\n*Concern 6: In the proof of proposition 2 it is written  $u(T_1) = \\Omega(1/\\log m)$\n. Could the authors explain more why it is true as it seems in contrast with the statement above proposition 2: \n $T_1 = \\inf_t\\{u(t) = \\Theta(\\delta^2\\log m)\\}$\n with $\\delta$\n small.*\n\n\nThe proposition shows that there exits $T_2$ such that $v(T_2)$ is not so close to $4$. For the case where $\\delta$ is small, i.e., $v(T_1)$ close to $2$, we can just let $T_2 = T_1$. For the case $v(T_1)$ is close to $4$, we have $\\delta >1$. We have clarified it in the updated draft."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6138/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700675092667,
                "cdate": 1700675092667,
                "tmdate": 1700675294484,
                "mdate": 1700675294484,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pMD6VFBGqg",
                "forum": "PvJnX3dwsD",
                "replyto": "TijAIG7j6G",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6138/Reviewer_Unww"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6138/Reviewer_Unww"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their answer and the improvement in the proofs that was done, by using explicit constants and getting rid of the (in my opinion) a bit \"approximate\" notations $O,o$... I unfortunately couldn't get through all the proofs by lack of time especially  of the result with multiple training points.\n\nI increased a bit my score because of the improvement in the proofs that was done and because I think that the results shown are interesting and hard, but decrease my confidence as I am unable to judge of the fully correctness of the remainding proofs."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6138/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700684027305,
                "cdate": 1700684027305,
                "tmdate": 1700684027305,
                "mdate": 1700684027305,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]