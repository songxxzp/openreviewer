[
    {
        "title": "Beyond Linear Spherical Interpolation: Noise Correction for Image Interpolation with Diffusion Models"
    },
    {
        "review": {
            "id": "Ewwz9jSuEQ",
            "forum": "6O3Q6AFUTu",
            "replyto": "6O3Q6AFUTu",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3634/Reviewer_A19z"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3634/Reviewer_A19z"
            ],
            "content": {
                "summary": {
                    "value": "A new approach to image interpolation with diffusion models is presented, where a new image is interpolated from two other images (in contrast to interpolating pixels within a single image).  While exisitng methods work reasonably well with images generated by a diffusion model, they do not work well with natural images not generated from the diffusion model.  Resulting interpolated images exhibit considerable artefacts.  Theory is introduced to explain the reason for the failure and suggest how to mitigate it.  A novel approach is presented to add appropriate noise to the natual images considered but at the same time ensure the interpolated image is faithful to the two images it is generated from.  A number of experiments are presented that demonstrate the improvement in interpolated image quality compared to the standard spherical interpolation approach."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "The paper is clear and well written.  The background and existing approaches are clearly explained, highlighting the tradeoff between realsim (i.e. avoiding artefacts) and faithfulness (i.e. ensuring consistency with the source images).  \n\nThe reason for the existing failure for natural images is related the mismatched noise levels, which arises due to the concentration of probability in high dimensions.  A numerical experiment (Fig. 3) is performed to support this hypothesis and Theorem 1 is presented to provide further support.  I believe Theorem 1 is a fairly well-known result.  Nevertheless, a proof is presented in Appendix A (I initially did not appreciate a proof was provided; in the main body of the article the reader should be pointed to Appendix A for the proof).\n\nFurther theory is presented in Theorem 2 to guide a solution to the problem (again, in the main body the reader should be pointed to the proof of Theorem 2 in Appendix B).  Based on the provided theory a novel diffusion-based image interpolation approach is presented, combining an SDEdit-like stage, followed by interpolation in latent space, followed by denoising with the diffusion model.  The interpolation approach introduces a number of free parameters to address contrast issues and trade-off consistence with each source image.  Standard spherical interpolation and linear interpolation combined with SDEdit are recovered as special cases for specific parameter choices.\n\nThe resulting interpolation method is simple but appears to work well.  I expect it to be of considerable practical use."
                },
                "weaknesses": {
                    "value": "While a number of supporting experiments are presented, these could be more compelling.  Experiments are performed to demonstrate the impact of different parameter choices, which are helpful.  In terms of overall interpolation quality in comparison to existing techniuqes, a number of examples a presented where the proposed method is demonstrated to be visually superior to existing approaches.  While further examples are presented in the appendices, in total just a handful of images are considered.  Given the artefacts that arise with existing techniques, I don't doubt that the proposed method is superior.  However, to further support this it would be useful to have some metric to summarize performance over a large test data-set.  I appreciate this may not be trivial but I wonder if the authors have any thoughts on how they could assess performance over a large test-set?\n\nBoundary control methods are introduce in Section 4.4 but are not explained.  The appendix is referenced but that only contains an additional figure of results.  The boundry control methods should be discussed somewhere.  In general Appendix B feel incomplete.  While I appreciate papers should stand on their own, without Appendices, if that is the case then further detail needs to be provided in the main body.\n\nThere seem to be a number of minor typos throughout where spaces a missing, typically following a period or comma."
                },
                "questions": {
                    "value": "Could the authors propose a summary metric to qualtify the performance of their approach over a large test-data set?  At present results are presented for just a handful of test images.  While is seems very likely the improved performance of the proposed method will generalize to other data it would be more compelling if the authors could demonstrate this quantitatively."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3634/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3634/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3634/Reviewer_A19z"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3634/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698666483421,
            "cdate": 1698666483421,
            "tmdate": 1699636319047,
            "mdate": 1699636319047,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GmxWJivNfU",
                "forum": "6O3Q6AFUTu",
                "replyto": "Ewwz9jSuEQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3634/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3634/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your valuable comments and constructive feedback on our manuscript. We appreciate the time and effort you have dedicated to reviewing our work. In response to your insightful suggestions, we have made several revisions to address the key concerns raised during the review process.\n\n**Q.1**: Propose a metric to quantify the performance on a large test dataset.\n> However, to further support this it would be useful to have some metric to summarize performance over a large test data-set.I appreciate this may not be trivial but I wonder if the authors have any thoughts on how they could assess performance over a large test-set?\nCould the authors propose a summary metric to qualtify the performance of their approach over a large test-data set? At present results are presented for just a handful of test images. While is seems very likely the improved performance of the proposed method will generalize to other data it would be more compelling if the authors could demonstrate this quantitatively.\n> \n***Ans for Q.1***:\n\nThank you for your constructive suggestions. Accordingly, we have conducted more experiments using difference models and datasets. These results are reported and discussed in our revision.\n\n\n- We have conducted experiments on Stable Diffusion model with datasets like  eagle, lion-tiger, peach and so on. The high quality results are reported in the Appendix C.2, which shows that our method can consistently achieve good performance under different settings.Specifically, we have tested not only the scenarios where the drift coefficient of the model is zero and non-zero but also tested whether the model's variance explodes, which was done to determine whether the diffusion process belongs to a Variance Exploding SDE(VE-SDE) or a Variance Preserving SDE(VP-SDE)[1]. This indicates that our approach may be useful in almost all diffusion models.\n\n-  We agree that an appropreate quantitative metric is crucial for compare difference methods. However,  as you mentioned, designing such a metric is challenging  since it should not only be based on pixels but also consider the semantic aspect to assess the quality of the interpolated images. The challenge may be the reason why previous methods in the literature did not involve such a metric. In this context, we would like to enhance the persuasiveness of our results by reporting additional results in the appendix. We will leave it as our future work to explore methods for quantifying the quality of interpolated images. \n\n**Q.2**: Boundary control are not explained.\n>Boundary control methods are introduce in Section 4.4 but are not explained. The appendix is referenced but that only contains an additional figure of results. The boundry control methods should be discussed somewhere. In general Appendix B feel incomplete. \n\n***Ans for Q.2***:\n\nWe apologize for missing the introduction of the boudary control. Following your valuable suggestion, we have highlighted the definition and explanation of boudary control in our revision of Chapter 4.5. Specifically,combining the \"68\u201395\u201399.7 rule\" and considering our analysis of how noise above the denoising threshold impacts images, data points exhibiting significant deviations from the mean are considered potential sources of image artifacts.Therefore, we control the boundary of noise.\n\n\n\n**Q.3**: Writing problem.\n>There seem to be a number of minor typos throughout where spaces a missing, typically following a period or comma.\n>\n***Ans for Q.3***:\n\nThanks for your kind suggestion. In respect to your careful reviewing, we have re-examined the entire paper and fixed all typos. Meanwhile, following your advice, we have added the citation of our theorem to the main text.\n\n[1]Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B. Score-based generative modeling through stochastic differential equations. In International Conference on Learning Representations, 2021."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3634/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700288176237,
                "cdate": 1700288176237,
                "tmdate": 1700296940885,
                "mdate": 1700296940885,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DS6zhbiRbj",
                "forum": "6O3Q6AFUTu",
                "replyto": "Ewwz9jSuEQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3634/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3634/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Welcome for more discussions"
                    },
                    "comment": {
                        "value": "Thanks for your valuable time in reviewing and insightful comments. Following your comments, we have tried our best to provide responses and revise our paper. Here is a **summary of our response** for your convenience:\n- (1) **Metric to quantify the performance on a large test dataset**: As you mentioned, designing such a metric is challenging since it should not only be based on pixels but also consider the semantic aspect to assess the quality of the interpolated images. We would like to enhance the persuasiveness of our results by reporting additional results in the appendix. And We will leave it as our future work to explore methods for quantifying the quality of interpolated images.\n- (2) **Boundary control**: We highlighted the definition and explanation of boudary control in our revision of Chapter 4.5.\n- (3) **Typo error**: We have re-examined the entire paper and fixed all typos and added the citation of our theorem to the main text.\n\n\nWe humbly hope our repsonse has addressed your concerns. If you have any additional concerns or comments that we may have missed in our responses, we would be most grateful for any further feedback from you to help us further enhance our work."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3634/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700452006035,
                "cdate": 1700452006035,
                "tmdate": 1700452006035,
                "mdate": 1700452006035,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5oL9jdb1gL",
                "forum": "6O3Q6AFUTu",
                "replyto": "DS6zhbiRbj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3634/Reviewer_A19z"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3634/Reviewer_A19z"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the response and revisions to the manuscript.  My original accept recommendation stands."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3634/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700700288262,
                "cdate": 1700700288262,
                "tmdate": 1700700288262,
                "mdate": 1700700288262,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "dsMwHasVZz",
            "forum": "6O3Q6AFUTu",
            "replyto": "6O3Q6AFUTu",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3634/Reviewer_YU98"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3634/Reviewer_YU98"
            ],
            "content": {
                "summary": {
                    "value": "The paper explores and discusses the limitations of linear spherical interpolation in the context of image interpolation, particularly when applied to images not generated by diffusion models. It investigates how inappropriate noise introduction and estimation (overestimation and underestimation of noise level) affects image quality, leading to artifacts and loss of original style in the interpolated images. The study aims to address these limitations by proposing a novel interpolation approach that strategically imposes boundary constraints (i.e. clipping) on the introduced noise (at inversion steps), aligning with the hypersphere centered around the Gaussian distribution. This approach aims to mitigate noise artifacts and improve image quality, preserving the essential characteristics of the original image while efficiently removing artifacts. Additionally, the paper explores the integration of different interpolation methods, such as linear spherical interpolation and SDEdit, to overcome the identified limitations and achieve satisfactory results in both training and natural image domains."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "\u2022 Identifies and addresses limitations in current linear spherical interpolation techniques, particularly in handling natural images (not generated by diffusion models).\n\n    \u2022 Offers an approach to enhance image interpolation quality and address noise-related issues (i.e. noise artifacts and loss of style dues to a mismatch between the actual noise strength and its estimation) through and imposing a clipping constraint on the noise components."
                },
                "weaknesses": {
                    "value": "INITIAL REVIEW:\n\n\u2022 The paper's contribution heavily relies on specific parameter selection (e.g., parameters in eq.(14), boundary values in section 3.5, and the interpolation coefficient $\\lambda$ in slerp), yet practical guidance for selecting these parameters remains unclear.\n\n    \u2022 Computational overhead and potential limitations of implementing the proposed method in practical scenarios lack detailed explanation. The experiments are conducted under a simplified scenario where the drift coefficient $\\mu(x_t,t)$ is set to zero.\n\n    \u2022 Further exploration is needed to assess the level of improvement and applicability in diverse domains or image types, as seen in Figure 6.\n\n    \u2022 The paper lacks explicit discussion on the generalizability of the method to various image sets.\n    \u2022 The previous works referenced (e.g., SDEdit) should be briefly described for reader convenience, without necessitating an external search for the referenced paper.\n\n    \u2022 There's a deficiency in the literature review concerning image generation based on diffusion probabilistic models, requiring more depth and exploration in this area.\n-------------------------------------------------------------------------------------------------------------------------------------\nPOST-REBUTTAL ASSESSMENT:\nThe concerns have been addressed in the revised paper."
                },
                "questions": {
                    "value": "INITIAL REVIEW:\n\n\u2022 Correct the typo on page 2 after equation (1) where $g$ should be replaced with $\\sigma\".\n\n    \u2022 The rationale behind introducing the methods in section 2.1 needs clarification, establishing their relevance to the current work. Additionally, references for the methods introduced in this section are missing.\n\n    \u2022 Define $\\bm{\\epsilon}_t$ (as observed in equation (4)) since it hasn't been explicitly defined in the paper.\n\n    \u2022 Provide further clarification on whether \"Gaussian noise\" is i.i.d. (independent and identically distributed) or simply refers to AWGN (Additive White Gaussian Noise).\n\n    \u2022 Maintain consistency in the use of spaces after full stops and commas.\n\n-------------------------------------------------------------------------------------------------------------------------------------\n\nPOST-REBUTTAL ASSESSMENT:\nThe questions have been addressed in the revised paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3634/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3634/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3634/Reviewer_YU98"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3634/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699228920668,
            "cdate": 1699228920668,
            "tmdate": 1700596612333,
            "mdate": 1700596612333,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZancmFnMaB",
                "forum": "6O3Q6AFUTu",
                "replyto": "dsMwHasVZz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3634/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3634/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q.1**: Practical guidance for selecting these parameters remains unclear.\n> The paper's contribution heavily relies on specific parameter selection (e.g., parameters in eq.(14), boundary values in section 3.5, and the interpolation coefficient  in slerp), yet practical guidance for selecting these parameters remains unclear.\n\n***Ans for Q.1***:\n\nThank you for pointing out the problem. \n\n- We agree with your point that the performance of our method is heavily related to the introduced hyperparameters. In this context, we would like to note that these hyperparameters are selected from a relatively stable range in our experiments. Specifically,$\\gamma$ is within the range $[0, 0.1]$, $\\mu$ and $\\nu$ are within the range $[0.8, 1]$, the boundary is within the range $[2.0, 2.4]$. Users only need to set $\\alpha$ and $\\beta=\\sqrt{1-\\alpha^2-\\gamma^2}$ can be automatically calculated.\n\n- We appologize for the missing strategy to select hyperparameters. In our experiments, we select hyperparameters from a subset of images (less than 20 images) and apply these hyperparameters to the remaining images.\n\n\n\n**Q.2**: Computational overhead and potential limitations.\n> Computational overhead and potential limitations of implementing the proposed method in practical scenarios lack detailed explanation.\n\n***Ans for Q.2***:\n\nThanks for your constructive suggestions. Accordingly, we have added the following explanation and discussion to our revision.\n\n- Our method involves an extra step compared to using SDEdit for interpolation, which is the mapping of the image to the latent variable. This extra overhead will double our processing time compared to interpolate images using SDEdit. As a result, this extra overhead leads to better feature preservation, as the noise and image information are quite balanced in this case.\n- Regarding potential application limitations, our paper mainly focus on image data. Thus, its effectiveness in other modalities has not been validated, which a potential limitation of our work. We will explore the posibility of our method on different modalities in our future work.\n\nThanks again for your constructive suggestions, and we believe the above discussion could significantly improve the quality of our paper.\n\n**Q.3**: Further exploration to assess with diverse settings.\n>The experiments are conducted under a simplified scenario where the drift coefficient $\\mu(x_t,t)$ is set to zero. Further exploration is needed to assess the level of improvement and applicability in diverse domains or image types, as seen in Figure 6. The paper lacks explicit discussion on the generalizability of the method to various image sets.\n\n***Ans for Q.3***:\n\n Thank you very much for your valuable suggestions. Following your advice, we have conducted supplementary experiments and provide explanation to our revision.\n\n- We set $\\mu(x_t,t)=0$ following the defaul setting of previous work [1], while overlooking the potential limitation of this experimental setting. Inspired by your valuable comments, we have conducted more experiments using Stable Diffusion, and reported the results in Appendix C.2. Specifically, Stable diffusion is built upon DDPM, and the drift coefficient of DDPM is non-zero. The results demonstrate that our approach performs quite well under various settings.\n- Follwing your valuble suggestion, we further verify the effectiveness of the proposed method on more datasets, including tiger-lion, peach and so on. The results are listed in Apendix C.2 demonstrating that our method can consistently achieve excellent results.\n\nThanks again for your constrctive suggestions. We have added the above discussion to our revised paper.\n\n[1]Karras, T., Aittala, M., Aila, T., and Laine, S. Elucidating the design space of diffusion-based generative models. In Proc. NeurIPS, 2022."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3634/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700288603898,
                "cdate": 1700288603898,
                "tmdate": 1700296395237,
                "mdate": 1700296395237,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "eiTAlnc1Ho",
                "forum": "6O3Q6AFUTu",
                "replyto": "dsMwHasVZz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3634/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3634/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Supplemental"
                    },
                    "comment": {
                        "value": "**Q.4**: Writing problem\n>\u2460The previous works referenced (e.g., SDEdit) should be briefly described for reader convenience, without necessitating an external search for the referenced paper.\n>\u2461There's a deficiency in the literature review concerning image generation based on diffusion probabilistic models, requiring more depth and exploration in this area.\n\u2462Correct the typo on page 2 after equation (1) where  should be replaced with $\\sigma$\".\n\u2463The rationale behind introducing the methods in section 2.1 needs clarification, establishing their relevance to the current work. Additionally, references for the methods introduced in this section are missing.\n\u2464Provide further clarification on whether \"Gaussian noise\" is i.i.d. (independent and identically distributed) or simply refers to AWGN (Additive White Gaussian Noise).\n\u2465Define ${\\epsilon}_t$ (as observed in equation (4)) since it hasn't been explicitly defined in the paper.\n\n***Ans for Q.4***: \n\nThanks for your kind suggestions. Accodingly, we have revised the paper and added explanations as follows.\n\n- Following your valuable suggestion, we have added the brief introduction of the mentioned SDEdit for reader convenience.\n\n  **supplementary content**: The SDEdit accomplishes image modifications by overlaying the desired alterations onto the image, introducing noise, and subsequently denoising the composite. This process ensures that the resulting image maintains a high level of quality.\n\n- We have discussed more works about diffusion probabilistic models in our revision.\n\n  **supplementary content**: Diffusion models generate data by progressively perturbing data into noise through Gaussian perturbations and then creating samples from the noise using sequential denoising steps. To date, diffusion models have also been applied to various tasks, such as image generating(Rombach et al., 2022; Song & Ermon, 2020; Nichol et al., 2021; Jiang et al., 2022), image super-resolution(Saharia et al., 2022c; Batzolis et al., 2021; Daniels et al., 2021), image inpainting(Esser et al., 2021), image editing(Meng et al., 2021), and image-to-image translation(Saharia et al., 2022a). Specifically, latent diffusion models(Rombach et al., 2022) stand out in generating text-conditioned images, garnering widespread acclaim for their ability to produce highly realistic visual images.\n\n\n- We have fixed the typos.\n- We have highlighted the rationale behind the proposed method as follows.\n\n  **supplementary content**: Here we first introduce how to describe the diffusion model's noise injection and denoising process in the form of Stochastic Differential Equations (SDEs). Building upon this, we provide a brief overview of how diffusion models are used for image interpolation and image editing. Through image editing, we can implement an interpolation method that doesn't require latent variables. These methods form the foundation for the approach we propose.\"\n- We have unified the expression of the utilized noise with independent and identically distributed Gassian noise following Denoising Diffusion Probabilistic Models(DDPM).\n\n  **supplementary content**: The  noise added to the two images can be either the same or different i.i.d Gaussian noise, and we will demonstrate shortly that they exhibit only minor distinctions.\n\n- We have supplemented the definition of $\\epsilon_t$.\n\n  **supplementary content**: In this context, we denote the original image as $x_0^{(i)}$, and $x_t^{(i)}$ represents the noised image, corresponding to the variable of the images in the latent space with noise level $\\epsilon_t$. Utilizing the probability flow ODE for its stability and unique encoding capabilities, we encode $x_0$ into the latent space by integrating Eq. 3, and we denote this encoding process as a function $f$."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3634/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700289605246,
                "cdate": 1700289605246,
                "tmdate": 1700311100872,
                "mdate": 1700311100872,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vRtkHiVFF3",
                "forum": "6O3Q6AFUTu",
                "replyto": "dsMwHasVZz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3634/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3634/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Welcome for more discussions"
                    },
                    "comment": {
                        "value": "Thanks for your valuable time in reviewing and insightful comments. Following your comments, we have tried our best to provide responses and revise our paper. Here is a **summary of our response** for your convenience:\n- (1) **Practical guidance for selecting these parameters**: In this context, we would like to note that these hyperparameters are selected from a relatively stable range in our experiments. Specifically,$\\gamma$ is within the range $[0, 0.1]$, $\\mu$ and $\\nu$ are within the range $[0.8, 1]$, the boundary is within the range $[2.0, 2.4]$. Users only need to set $\\alpha$ and $\\beta=\\sqrt{1-\\alpha^2-\\gamma^2}$ can be automatically calculated.\n- (2) **Computational overhead and potential limitations**: \u2460Our method involves an extra step compared to using SDEdit for interpolation, which is the mapping of the image to the latent variable. This extra overhead will double our processing time compared to interpolate images using SDEdit and this extra overhead leads to better feature preservation. \u2461Regarding potential application limitations, our paper mainly focused on image data. Thus, its effectiveness in other modalities has not been validated.\n- (3) **Further exploration to assess with diverse settings**: We have conducted supplementary experiments and provide explanation to our revision.\n- (4) **Writing problem**: \u2460We have added the brief introduction of the mentioned SDEdit for reader convenience. \u2461We have discussed more works about diffusion probabilistic models in our revision. \u2462We have fixed the typos. \u2463We have unified the expression of the utilized noise with independent and identically distributed Gassian noise following Denoising Diffusion Probabilistic Models(DDPM). \u2464We have supplemented the definition of $\\epsilon_t$.\n\n\nWe humbly hope our repsonse has addressed your concerns. If you have any additional concerns or comments that we may have missed in our responses, we would be most grateful for any further feedback from you to help us further enhance our work."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3634/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700452138070,
                "cdate": 1700452138070,
                "tmdate": 1700452594280,
                "mdate": 1700452594280,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VEQOZEruP6",
                "forum": "6O3Q6AFUTu",
                "replyto": "dsMwHasVZz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3634/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3634/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks a lot for your time in reviewing and reading our response and the revision. We sincerely understand you\u2019re busy. But as the window for responsing and paper revision is closing, would you mind checking our response (a brief summary, and details) and confirm whether you have any further questions? We are looking forward to your reply."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3634/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700558660433,
                "cdate": 1700558660433,
                "tmdate": 1700558885189,
                "mdate": 1700558885189,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "51W1O9L5AX",
                "forum": "6O3Q6AFUTu",
                "replyto": "dsMwHasVZz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3634/Reviewer_YU98"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3634/Reviewer_YU98"
                ],
                "content": {
                    "title": {
                        "value": "Post-rebuttal Decision"
                    },
                    "comment": {
                        "value": "Thank you for your thorough responses. I've reviewed your replies to my questions and the revised paper. It's evident that you've diligently addressed the issues/ambiguities, and the changes made in the revised paper have contributed to a better understanding of your work and strengthened the paper. Since I'm satisfied with the changes made, I am inclined to reassess the paper positively and recommend acceptance."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3634/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700595798393,
                "cdate": 1700595798393,
                "tmdate": 1700595798393,
                "mdate": 1700595798393,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "bqxz63h7zj",
            "forum": "6O3Q6AFUTu",
            "replyto": "6O3Q6AFUTu",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3634/Reviewer_h8PS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3634/Reviewer_h8PS"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses image interpolation based on diffusion models; it shows the limitation of the linear spherical interpolation (Song 2020), and then proposes a novel method. Specifically, the proposed method integrates the linear spherical interpolation and the linear spherical interpolation combined with SDEdit; it denoises the linear combination of the latent variables, the original images, and Gaussian noise. The performance of the proposed method is compared with those of the linear spherical interpolation and the linear spherical interpolation combined with SDEdit on bedroom and cat images."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "First of all, the experimental results qualitatively demonstrate that the proposed method works better than both the linear spherical interpolation and the linear spherical interpolation combined with SDEdit. Second, the proposed method generalizes the linear spherical interpolation and the linear spherical interpolation combined with SDEdit so that it includes both the methods in special cases. Third, the theoretical backgrounds are interesting; the limitation of the linear spherical interpolation is explained by Theorem 1, and the proposed method is supported by Theorem 2."
                },
                "weaknesses": {
                    "value": "First, the proposed method has a number of empirical parameters (alpha, beta, gamma, mu, nu, and boundary). It would be difficult to appropriately set those parameters in practice, although the effects of each parameter is experimentally demonstrated. Second, the experimental evaluation is limited: only qualitative evaluation on small number of images. Third, the presentation of this paper could be improved.\nIn my opinion, Introduction is too short and the number of references are too small."
                },
                "questions": {
                    "value": "I would be happy to receive your feedback to the comments on Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3634/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3634/Reviewer_h8PS",
                        "ICLR.cc/2024/Conference/Submission3634/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3634/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699285401559,
            "cdate": 1699285401559,
            "tmdate": 1700714301619,
            "mdate": 1700714301619,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MEIIMdesa4",
                "forum": "6O3Q6AFUTu",
                "replyto": "bqxz63h7zj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3634/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3634/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank you for taking the time to review.  According to your comments, we provide detailed feedback below and also add them into the revision. We believe that these changes could significantly improve the overall quality of our work:\n\n**Q.1**: It would be difficult to  set the parameters.\n> First, the proposed method has a number of empirical parameters (alpha, beta, gamma, mu, nu, and boundary). It would be difficult to appropriately set those parameters in practice, although the effects of each parameter is experimentally demonstrated.\n\n***Ans for Q.1***:\n\nThanks for pointing out this potentially confusing problem. Accordingly, we have supplemented the relevant explanations in the revision. \nThe introduced hyperparameters are listed as follows. Although our method introduces several hyperparameters, we would like to note that it is relatively effortless to tune the parameters.\n- i) Boundary determines the extent of noise constraint. In our experiments, the boundary is within the range $[2.0, 2.4]$.\n- ii) $\\gamma$ determines the strength of the added noise. In our experiments, $\\gamma$ is within the range $[0, 0.1]$.\n- iii) $\\mu$ and $\\nu$ supplement the information lost in the generation process (by introduing the information from the original image). In our experiments, $\\mu$ and $\\nu$ are within the range $[0.8, 1]$.\n\nIn addition, our method involves a user-determined parameter $\\alpha$.\n- $\\alpha$ is set by users, since it controls the degree of interpolation bwteen two images, where larger $\\alpha$ means the generated image is more similar to the first image. In this context, $\\beta = \\sqrt{1-\\alpha^2-\\gamma^2}$.\n\n\n**Q.2**: The experimental evaluation is limited.\n> Second, the experimental evaluation is limited: only qualitative evaluation on small number of images.\n\n***Ans for Q2***:\n\nThank you for your constructive comments. Accordingly, we have added the following experiments and explanations to our revisoin.\n\n- We have conducted experiments using more models and datasets. Specifically, we evaluate our method using Stable Diffusion model on  eagle, tree, car and other datasets. The results are reported in the Appendix C.2. These reults show that our method can consistently achieve good performance under various settings.\n\n- We agree that an appropreate quantitative metric is crucial for comparing difference methods. However, designing such a metric is challenging in the literature, since it should not only be based on pixels but also consider the semantic aspect to assess the quality of the interpolated images. The challenge may be the reason why previous methods in the literature did not involve such a metric. In this context, we would like to enhance the persuasiveness of our results by reporting additional results in the appendix. We will leave it as our future work to explore methods for quantifying the quality of interpolated images.\n\nWe believe these results and discussion would make our work more solid. Thanks again for your valuable comments.\n\n**Q.3**: The introduction and the references is too short.\n> Third, the presentation of this paper could be improved. In my opinion, Introduction is too short and the number of references are too small.\n\n***Ans for Q.3***:\n\nThanks for your kind suggestion. Accodingly, we have modified the paper to provide a detailed introduction and added more references. The corresponding content will be placed in the next response box."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3634/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700286168907,
                "cdate": 1700286168907,
                "tmdate": 1700296073137,
                "mdate": 1700296073137,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "meCPM0YkYo",
                "forum": "6O3Q6AFUTu",
                "replyto": "bqxz63h7zj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3634/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3634/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Supplemental information for the introduction content."
                    },
                    "comment": {
                        "value": "**supplementary content**:\n\nImage interpolation is an exceptionally fascinating task, not only for generating analogous images but also for igniting creative applications, especially in domains like advertising. At present, state-of-the-art generative models showcase the ability to produce intricate and captivating visuals, with many recent breakthroughs deriving from diffusion models. (Ho et al., 2020; Song et al., 2020a; Rombach et al., 2022; Saharia et al., 2022b; Ramesh et al., 2022). The potent of diffusion models is widely acknowledged, but to our knowledge, there has been relatively little research on image interpolation with diffusion models.(Croitoru et al., 2023) \n\nWithin the realm of diffusion models, the prevailing technique for image interpolation is linear spherical interpolation(Song et al., 2020a;b). This approach shines when employed with images generated by diffusion models. Nonetheless, when extrapolated to images not originating from diffusion models, the quality of interpolation outcomes might fall short of expectations and frequently introduce substantial artifacts. \n\nWe initially analysed the image interpolation process and attributed subpar interpolation results to the introduction of noise with image-related information. This particular noise was not aligned with the level of denoising, resulting in artifacts in the final interpolated images. Directly manipulating the mean and variance of noise through translation and scaling is a very straightforward approach to bring them closer to the desired distribution. However, this not only fails to improve the quality of the image but also results in the loss of a significant amount of original image information. Based on this analysis, we integrated the SDEdit(Meng et al., 2021) method, proposing the substitution of this noise component with random Gaussian noise. While this approach improves image quality, it comes at the expense of introducing additional information. \n\n\nAfter that, we further devised an innovative interpolation technique that leverages the strengths of both methods. This approach retains valuable noise while introducing subtle Gaussian noise to enhance the quality of interpolation. Furthermore, we\u2019ve introduced a new constraint on the noise component responsible for generating artifacts and incorporated original image to supplement missing information. These improvements not only enhance interpolation results for images within the training domain but also extend the capability to interpolate with natural images outside the training domain, yielding the best interpolation results achieved to date. In light of the limited exploration in this domain in previous studies(Croitoru et al., 2023), we aspire that our research can serve as a source of inspiration for fellow researchers."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3634/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700287681690,
                "cdate": 1700287681690,
                "tmdate": 1700295593463,
                "mdate": 1700295593463,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "W3J96fwiKw",
                "forum": "6O3Q6AFUTu",
                "replyto": "bqxz63h7zj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3634/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3634/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Welcome for more discussions"
                    },
                    "comment": {
                        "value": "Thanks for your valuable time in reviewing and insightful comments. Following your comments, we have tried our best to provide responses and revise our paper. Here is a **summary of our response** for your convenience:\n- (1) **The setting of the parameter**: It is relatively effortless to tune the parameters. For users, it is only necessary to set the parameter $\\alpha$ and ensure that other parameters are within the selected range to generate high-quality images\n- (2) **Experimental evaluation**: We have conducted experiments using more models and datasets. And designing a metric is challenging, since it should not only be based on pixels but also consider the semantic aspect to assess the quality of the interpolated images. \n- (3) **The introduction and the reference**: We have modified the paper to provide a detailed introduction and added more references.\n\nWe humbly hope our repsonse has addressed your concerns. If you have any additional concerns or comments that we may have missed in our responses, we would be most grateful for any further feedback from you to help us further enhance our work."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3634/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700451900560,
                "cdate": 1700451900560,
                "tmdate": 1700452514375,
                "mdate": 1700452514375,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Toj9oxNiHt",
                "forum": "6O3Q6AFUTu",
                "replyto": "W3J96fwiKw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3634/Reviewer_h8PS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3634/Reviewer_h8PS"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for your response and revision. Because the response is convincing to me, I would like to change my rating from 6 (marginally above the acceptance threshold) to 8 (accept, good paper)."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3634/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700714672504,
                "cdate": 1700714672504,
                "tmdate": 1700714672504,
                "mdate": 1700714672504,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]