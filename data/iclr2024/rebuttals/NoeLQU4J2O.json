[
    {
        "title": "Soon Filter: Advancing Feed-Forward Neural Architectures for Inference at the Edge"
    },
    {
        "review": {
            "id": "yoXPBu6AB3",
            "forum": "NoeLQU4J2O",
            "replyto": "NoeLQU4J2O",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3884/Reviewer_fhaz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3884/Reviewer_fhaz"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a set of technique to realize an implementation of neural networks that are as simple as binary neural networks. Rather than binarization, the authors use hashing functions, inspired from earlier works that have considered filtering techniques. The novelty proposed by the authors is to slightly modify the gradient formulation for back-propagation. A problem with regular STE convergence is identified when using ULEEN, whereby the use of minimum function causes a bottleneck. As an alternative, the authors propose to use the sum function for approximating AND resulting in an always 1 gradient. Experimental results on tiny datasets are provided."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is well written, and the exposition of the problem is clear. The presented analysis is clear to follow, and interesting."
                },
                "weaknesses": {
                    "value": "Several issues with this paper can be noted:\n\n-- The main objective of the paper is to reduce the complexity of implementation using hashing and filtering. However, very little is done to measure this complexity. Only the model size is reported, as proxy to complexity. But what about the overhead of implementing hashing and filtering? How does that compare to regular binarization where values are simply clipped to +/-1? How does that compare to low bit width implementation (e.g., 4-bit or 8-bit)? I found the discussion on hardware benefits and limitations of the method very weak.\n\n-- The utilized benchmarks are extremely trivial. The authors have only tested their work on tiny models and datasets. Does the method work on models more relevant to the community in this day and age? E.g., large vision and language models? Even for those tiny datasets, the accuracy is not even close to the state-of-the-art, such as for CIFAR-10 where the authors report accuracies close to 50%."
                },
                "questions": {
                    "value": "Please address questions provided in the above section. Specifically:\n\n-- More nuanced discussion on the hardware implications of the method.\n\n-- More relevant empirical results on typical baselines employed in the ML community in 2023."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3884/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698358199427,
            "cdate": 1698358199427,
            "tmdate": 1699636347139,
            "mdate": 1699636347139,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TNkcbbSYuX",
                "forum": "NoeLQU4J2O",
                "replyto": "yoXPBu6AB3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3884/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3884/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer fhaz"
                    },
                    "comment": {
                        "value": "Thank you for reviewing our paper, providing valuable feedback and helping improve our paper. \n\n**Weakness 1 and Question 1:**\n\n> The main objective of the paper is to reduce the complexity of implementation using hashing and filtering. However, very little is done to measure this complexity. Only the model size is reported, as proxy to complexity. But what about the overhead of implementing hashing and filtering?\n\nWe appreciate your feedback and have revised our paper accordingly to clarify its main objective. Contrary to what may have been implied, our goal is not to reduce implementation complexity through hashing and filtering. This aspect was already addressed by the BloomWiSARD paper and further advanced in ULEEN, as detailed in the Weightless Neural Network paragraph of the Background section. ULEEN extensively investigates the overhead of hashing and filtering, demonstrating its superiority over BNN in terms of latency, memory consumption, and energy efficiency. We direct readers to the ULEEN paper for more detailed insights into these aspects.\n\nThe primary focus of our paper is to address a gradient bottleneck in the BloomFilter's continuous relaxation. Our proposed solution, the SoonFilter, is detailed in the Methodology Section. It specifically targets this bottleneck, contributing a significant advancement in the field.\n\n> How does that compare to regular binarization where values are simply clipped to +/-1?\n\nRegular binarization, where values are simply clipped to +/- 1, is known as Binary Neural Networks (BNN). We compare against this model thoroughly in the experiments section. Please take a look at Section 4.1 of our revised paper.\n\n> How does that compare to low bit width implementation (e.g., 4-bit or 8-bit)?\n\nThe comparison of multiplication-free models with traditional models, as well as with quantized (4-bit, 8-bit, etc) and sparse models, is already well covered in the literature. Therefore, we chose to focus our comparison on the state-of-the-art multiplication-free methods in our experiments. This approach allows us to provide a more direct and relevant assessment of the advancements our Soon Filter brings to this specific category of models.\n\n> I found the discussion on hardware benefits and limitations of the method very weak.\n\nFor deployment on edge devices, our work builds upon the ULEEN framework with minimal modifications to its model, as detailed in the methodology section. This strategic choice ensures that our model inherits ULEEN's hardware performance characteristics, which were thoroughly explored in the ULEEN paper. Our model achieves significantly smaller sizes at the same accuracy levels as ULEEN, necessitating fewer filters for comparable accuracy. This efficiency allows us to set ULEEN's hardware performance as an upper bound for our method. Given our inheritance of ULEEN\u2019s hardware characteristics, we chose to focus more on the theoretical development of our proposed method in our paper, as the hardware aspects were already well covered in the ULEEN work.\n\n**Weakness 2 and Question 3:**\n\nIn response to your feedback, we have updated our paper to better articulate our benchmark selection. The benchmarks we employed are standard in the edge inference community. This includes MLPerf Tiny, a subset of the MLPerf benchmark suite specifically designed for low-power, edge devices. It focuses on tasks like image classification, keyword spotting, and anomaly detection, crucial for models in resource-constrained environments. MLPerf Tiny offers a standardized framework for consistent and comparable benchmarking across different models and platforms, demonstrating the practical applicability of our approach in edge computing scenarios.\n\nAdditionally, we included a collection of UCI datasets, targeting edge applications that use structured data, and included MNIST as it is consistently used in all other papers we compare against, ensuring a relevant and direct comparison. The results for comparison models on MNIST are sourced directly from their respective papers.\n\nFor a detailed explanation of our benchmark choices, please refer to the Subsection 4.1 of our revised paper.\n\nWe hope that these updates and clarifications adequately address your concerns. If you have any further issues or need additional clarification, we are more than happy to assist or make necessary revisions as needed."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3884/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700435469306,
                "cdate": 1700435469306,
                "tmdate": 1700435815739,
                "mdate": 1700435815739,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yAspOkWiKr",
                "forum": "NoeLQU4J2O",
                "replyto": "TNkcbbSYuX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3884/Reviewer_fhaz"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3884/Reviewer_fhaz"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "I acknowledge having read the response by the authors. I am keeping my original review and score."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3884/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700503477100,
                "cdate": 1700503477100,
                "tmdate": 1700503477100,
                "mdate": 1700503477100,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "szuCnUBqjH",
            "forum": "NoeLQU4J2O",
            "replyto": "NoeLQU4J2O",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3884/Reviewer_aeHv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3884/Reviewer_aeHv"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a multiplication-free neural network based on bloom filters, making it suitable for deployment on ultra-constrained edge/IOT devices. In fact, the paper focuses on a specific optimization to bloom filters and prior work (ULEEN) by replacing a non-differentiable logic function (AND) with a summation operation. This helps gradient flow and trainability making the NN achieve higher accuracy on an assortment of tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper is clearly-written and well-motivated and the empirical improvements are consistent on a number of tasks."
                },
                "weaknesses": {
                    "value": "This paper is interesting and I learned something new about multiplication-free circuits. However, the proposed modification is very small (compared to ULEEN), the application is quite niche and not well demonstrated, the improvements are very small, and the evaluation is inadequate. This work is promising but there are more questions that need to be answered to provide a compelling argument for the presented approach."
                },
                "questions": {
                    "value": "- How does your performance compare to CNNs?\n- How general is your approach? Can it be applied to CNNs, attention, other tasks, other NN sizes?\n- DId you deploy this on a challenging edge device? how does end-to-end performance compare to alternatives?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3884/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698688211394,
            "cdate": 1698688211394,
            "tmdate": 1699636347064,
            "mdate": 1699636347064,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vw4pHYbdO8",
                "forum": "NoeLQU4J2O",
                "replyto": "szuCnUBqjH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3884/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3884/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer aeHv"
                    },
                    "comment": {
                        "value": "Thank you for reviewing our paper, providing valuable feedback and helping improve our paper. \n\n**Weakness:** Concerning the perceived smallness of our contribution, we understand that replacing the AND operation with a SUM in Bloom Filters might seem minor. However, we argue that this is a non-trivial change. Such a substitution is counterintuitive in Bloom Filters as it increases the false positive rate, which is typically undesirable. This alteration is grounded in a robust theoretical framework of gradient maximization, as elaborated in our methodology section. Our work, drawing inspiration from the developments in resnets, mirrors a similar pattern. At first glance, adding a skip connection in resnets might also appear a small contribution. Yet, their work became a cornerstone for many modern deep neural network (DNN) models. We contend that our contribution is significant and impactful, as evidenced by the results we achieved. Notably, our Soon Filter consistently halves the model size of ULEEN, marking a substantial advancement in multiplication-free models. For comprehensive evidence, please refer to the **MLPerf Tiny Results** and **MNIST Results** paragraphs in the experiments section in the revised paper. This size reduction facilitates the deployment of much more efficient models at the edge.\n\n**Questions 1 and 2:** Weightless neural networks (WNNs) hold significant potential for operating with extremely low computational resources. However, they encounter a major challenge that must be addressed to make them applicable in more complex scenarios: their inability to achieve greater depth due to the discrete nature of the RAM indexing, which lacks a derivative, akin to embeddings. As a result, constructing deep models and convolutional models with WNNs is currently unfeasible. This limitation presents a substantial opportunity for future research. Overcoming this challenge could lead to groundbreaking advancements in deep learning, paving the way for the development of even more efficient and effective models. Consequently, future research efforts should concentrate on devising algorithms capable of facilitating back-propagation with discrete operations such as RAM indexing.\n\n**Question 3:** For deployment on edge devices, our work builds upon the ULEEN framework with minimal modifications to its model, as detailed in the methodology section. This strategic choice ensures that our model inherits ULEEN's hardware performance characteristics, which were thoroughly explored in the ULEEN paper. Our model achieves significantly smaller sizes at the same accuracy levels as ULEEN, necessitating fewer filters for comparable accuracy. This efficiency allows us to set ULEEN's hardware performance as an upper bound for our method. Given our inheritance of ULEEN\u2019s hardware characteristics, we chose to focus more on the theoretical development of our proposed method in our paper, as the hardware aspects were already well covered in the ULEEN work.\n\nWe hope that these updates and clarifications adequately address your concerns. If you have any further issues or need additional clarification, we are more than happy to assist or make necessary revisions as needed."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3884/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700435329542,
                "cdate": 1700435329542,
                "tmdate": 1700435822629,
                "mdate": 1700435822629,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zsZNHGOqvK",
                "forum": "NoeLQU4J2O",
                "replyto": "vw4pHYbdO8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3884/Reviewer_aeHv"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3884/Reviewer_aeHv"
                ],
                "content": {
                    "title": {
                        "value": "keeping my score"
                    },
                    "comment": {
                        "value": "Thanks for your response.\n\nI am keeping my score. While the author's comments make sense, I am not convinced that replacing AND with SUM is as impactful as skip connections in ResNet. Skip connections were key to gradient flow and training deeper CNNs thus unlocking a huge design space. In the case of Uleen and the presented work, the impact is much smaller and the evaluation still lacks depth, and the contributions (while solid) are somewhat minor, warranting more work before publication in this reviewer's opinion."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3884/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700533511101,
                "cdate": 1700533511101,
                "tmdate": 1700533511101,
                "mdate": 1700533511101,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vZJgVPjN01",
            "forum": "NoeLQU4J2O",
            "replyto": "NoeLQU4J2O",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3884/Reviewer_N6Ny"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3884/Reviewer_N6Ny"
            ],
            "content": {
                "summary": {
                    "value": "This study primarily aims to reveal a noteworthy bottleneck in the gradient back-propagation process of ULEEN. This bottleneck is attributed to the continuous relaxation of Bloom filters, which hinders the learning process. Drawing inspiration from the principles emphasized in ResNet, which stress the benefits of fine-tuning network architecture to enhance gradient flow, this study introduces a solution known as the \"Soon filter.\" Theoretical and empirical results demonstrate that this proposed solution substantially enhances the smooth back-propagation of gradients to filter locations. Consequently, it establishes a new state-of-the-art benchmark for multiplication-free feed-forward models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is well-structured and easy to follow.\n\n2. The primary goal is to set a new state-of-the-art benchmark for multiplication-free feed-forward models.\n\n3. The introduction of the \"Soon filter\" addresses the gradient flow issue."
                },
                "weaknesses": {
                    "value": "1. Incorporating additional visual aids and illustrations within the section on related work would greatly enhance the clarity and comprehensibility of the paper. These visuals can provide readers with a more comprehensive understanding of the prior research landscape in the field.\n\n2. While the central contribution of the paper revolves around the introduction of the \"Soon Filter,\" it is essential to consider augmenting this with supplementary contributions or by providing more extensive exploration and insights to enrich the overall content and scholarly impact."
                },
                "questions": {
                    "value": "1. Based on Figure 1 and the main content, is the primary distinction between these methods solely attributable to the replacement of the OR operation with the SUM operation?\n\n2. Regarding the VWW dataset, have you evaluated the performance of these methods on smaller models like MCUNetV1 [1] and MCUNetV2 [2]? Such an analysis could provide insights into the accuracy reduction when transitioning from multiplication-based models and offer valuable insights.\n\n\n[1] MCUNet: Tiny Deep Learning on IoT Devices \n\n[2] MCUNetV2: Memory-Efficient Patch-based Inference for Tiny Deep Learning"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3884/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3884/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3884/Reviewer_N6Ny"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3884/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698837123270,
            "cdate": 1698837123270,
            "tmdate": 1699636346955,
            "mdate": 1699636346955,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "h5SxP2It4H",
                "forum": "NoeLQU4J2O",
                "replyto": "vZJgVPjN01",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3884/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3884/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer N6Ny"
                    },
                    "comment": {
                        "value": "Thank you for reviewing our paper, providing valuable feedback and helping improve our paper. \n\n**Weakness 1:** In response to your observation, we have added a new Figure in our manuscript. The new figure now offers a more detailed and descriptive visual representation, enhancing the clarity and understanding of the prior work. We believe this adjustment will significantly improve readers' comprehension of the context and background of our study.\n\n**Weakness 2:** Our primary focus is indeed on the introduction of the Soon Filter. We argue that this represents a high-impact contribution, as demonstrated by the results we have obtained. Notably, our Soon Filter consistently reduces the model size of ULEEN by half, a significant advancement. For detailed evidence of this, please refer to the **MLPerf Tiny Results** and **MNIST Results** paragraphs in the experiments section in the revised paper. This reduction enables the deployment of far more efficient models at the edge, a contribution we believe to be of considerable scholarly significance.\n\n**Question 1:** Yes, the distinction between the Bloom Filter and the Soon Filter is solely attributable to the substitution of the AND operation with the SUM operation. This key difference is thoroughly detailed in our methodology section. Furthermore, in our experiments, we have ensured that the training regime for both ULEEN and our proposed SULEEN remains the same, with the only difference being the use of the Bloom Filter and the Soon Filter, respectively. Please refer to the  **Hyperparameter Tuning**, **Preprocessing**, and **Training** paragraphs in the experiments section in the revised version of our paper for further details.\n\n**Question 2:** The comparison of multiplication-free models with traditional models, as well as with quantized and sparse models, is already well covered in the literature. Therefore, we chose to focus our comparison on the state-of-the-art multiplication-free methods in our experiments. This approach allows us to provide a more direct and relevant assessment of the advancements our Soon Filter brings to this specific category of models.\n\nWe hope that these updates and clarifications adequately address your concerns. If you have any further issues or need additional clarification, we are more than happy to assist or make necessary revisions as needed."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3884/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700435259975,
                "cdate": 1700435259975,
                "tmdate": 1700435829490,
                "mdate": 1700435829490,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]