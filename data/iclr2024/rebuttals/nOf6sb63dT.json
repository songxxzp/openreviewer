[
    {
        "title": "Generative Models are Self-Watermarked: Intellectual Property Declaration through Re-Generation"
    },
    {
        "review": {
            "id": "c815SEj3tf",
            "forum": "nOf6sb63dT",
            "replyto": "nOf6sb63dT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9219/Reviewer_Eg4r"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9219/Reviewer_Eg4r"
            ],
            "content": {
                "summary": {
                    "value": "This paper utilizes the intrinsic characteristics of the generative models as the inherent fingerprints for intellectual property protection. This new method requires no addtional modifications on the training data or the model parameters. The evaluation results on both text generation and image generation tasks demonstrate the effectiveness of this method."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Trendy topic\n- New perspective for designing fingerprints\n- Good verification performance"
                },
                "weaknesses": {
                    "value": "- Limited application scenarios\n- Lack of robustness evaluation\n- Exceed the page limit"
                },
                "questions": {
                    "value": "This paper proposes a novel fingerprinting methods via utlilizing the intrinsic characteristics of the generative models. The fingerprint difference could be strengthened by the re-generation process. The authors provide both theoretical analysis and empirical evaluations to prove the effectiveness of this method. The evaluation results on both text generation and image generation tasks demonstrate the good performance of this method. \n\nHowever, I still have the following concerns.\n\n- Though the proposed method is a good trial to implement fingerprints without any modifications on the training data or the model parameters, the application scenarios for this method are limited. This paper implicitly assumes that there is no information loss during the generation process, which allows for the multi-round re-generation process. In the experiments for text generation, the authors also merely consider the translation task which is consistent with this assumption. However, for other text generation tasks like summarization, this method might not be applicable. Moreover, even for the image generation task, the authors also implicitly assume that the model owner knows the text prompts used by the suspicious generated images. Then what if the text prompt is unknown? I would suggest the authors elaborate more on this in their paper. \n\n- This paper lacks robustness evaluation. For instance, for the image generation task, will image transformations or pixel perturbations on the generated images affect the verification performance? I would suggest the authors add some experiments to evaluate the robustness of their method under various perturbations. \n\n- In Table 2, when increasing $k$ from 3 to 5, the performance for the Cohere authentic model with the M2M contrast model decreases. This result is weird. I hope the authors can add some explanations here. \n\n- The main text of this paper (before citation) has exceeded 9 pages, which violates the page limit for ICLR submission. I am afraid that this will lead to a desk rejection."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9219/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698243545318,
            "cdate": 1698243545318,
            "tmdate": 1699637160231,
            "mdate": 1699637160231,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kqk2OEiaKL",
                "forum": "nOf6sb63dT",
                "replyto": "c815SEj3tf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9219/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9219/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Eg4r (1/2)"
                    },
                    "comment": {
                        "value": "**[Q1.1]**:Limited application scenarios for NLP (clarifying \u2018re-generation process\u2019, \u2018translation task\u2019 and other tasks like \u2018summarization, this method might not be applicable\u2019)\n\n**[A1.1]**: **Re-generation** can be done through various methods, including but not limited to round-trip translation and prompt-based paraphrasing. Round-trip translation is utilized as one method of re-generation step in our work, as described in Section 4.2. Furthermore, we would like to emphasize that the **target generation task** within our framework may encompass any NLG task within the scope of typical LLMs, with translation being one pertinent example.\n\nTo demonstrate the generalization of our approach, we further examine two popular text generation tasks (as *target generation tasks*): paraphrasing and summarization. Upon these tasks, prompt-based paraphrasing is employed as a means of *re-generation step*. We set k to 5 because of its superior performance. The results are presented in the following tables. \n\nParaphrasing as generation task:\n|      Models         | GPT-3.5-turbo  | | Zephyr  |  | Mistral | |\n| :---------------- | :------: | :------: |:------: | :------: |:------: | :------: |\n|  | Acc  | Mis | Acc  | Mis | Acc  | Mis |\n|GPT-3.5-turbo | - | - | 75.0 | 20.0 | 69.0 | 24.0 |\n|Zephyr | 84.0 | 10.0 | - | - | 69.0 | 23.0 |\n| Mistral | 74.0 | 19.0 | 76.0 | 10.0 | - | -|\n\nSummarization as generation task: \n|      Models         | GPT-3.5-turbo  | | Zephyr  |  | Mistral | |\n| :---------------- | :------: | :------: |:------: | :------: |:------: | :------: |\n|  | Acc  | Mis | Acc  | Mis | Acc  | Mis |\n|GPT-3.5-turbo | - | - | 92.0 | 6.0 |68.0 | 24.0 |\n|Zephyr | 88.0 | 10.0 | - | - | 67.0 | 26.0 |\n| Mistral | 86.0 | 12.0 | 86.0 | 12.0 | - | -|\n\nAccording to these results, our approach can effectively distinguish between authentic models and contrast models in the context of both paraphrasing and summarization (as the target tasks) with prompt-based paraphrasing (as re-generation steps).\n\n---\n\n**[Q1.2]**: Moreover, even for the image generation task, the authors also implicitly assume that the model owner knows the text prompts used by the suspicious generated images. Then what if the text prompt is unknown?\n\n**[A1.2]**: This is a great point towards understanding our approach. The re-generation and verification do not need a task-specific prompt to regenerate the original image or to paraphrase the original text, as inpainting and paraphrasing are deterministic tasks (as outlined in Sec 4.3). Only the initial generation of images/texts may require prompts to specify the target tasks but our regeneration method does not require any prompts.\n\n---\n\n**[Q2]**: Lacks Robustness\n\n**[A2]**: We fully recognise the robustness evaluation. As suggested, we have applied Gaussian noise on a random subset of pixels (r) on the published image before regeneration. Due to time limitations, our experiments currently utilized the Stable Diffusion v2.1 as the authentic model, however, we plan to extend our analysis to other models in our revision.  The Gaussian noise is fixed with mean (\u03bc = 0) and large standard deviation (\u03c3=25).\n\nRe-generation steps(k=5), Perturbation rate (r)\n\n| r                  | SDv2.1B Acc | SDv2.1B Mis | SDXL 1.0 Acc | SDXL 1.0 Mis |\n|--------------------|-------------|-------------|--------------|--------------|\n| 0%                  |  97.5        | 1.0         | 94.0         | 5.0          |\n| Gaussian Noise (0, 25) |      |             |              |              |\n| 1%               |  95.5        | 3.5         | 86.0         | 10.0         |\n| 2%               | 72.0        | 22.0        | 36.5         | 53.0         |\n| 3%               |  70.5        | 22.5        | 21.5         | 61.5         |\n| 5%               |  31.5        | 63.0          | 56.0         | 33.5         |\n\nThe misclassifications in the case of a few models remain low but the accuracy notably decreases with Gaussian noise, highlighting an area for improvement. Further testing is still needed to fully evaluate verification under more adversarial conditions and other perturbation types."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9219/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700437804012,
                "cdate": 1700437804012,
                "tmdate": 1700438544016,
                "mdate": 1700438544016,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "brXZPHKdGY",
            "forum": "nOf6sb63dT",
            "replyto": "nOf6sb63dT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9219/Reviewer_66tW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9219/Reviewer_66tW"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a method to verify whether an image or text is generated by a protected model. This method can be useful for IP protection for the model owner."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The proposed method seems interesting. Instead of using watermarks and training-based methods, this method propose a \"re-generation\" strategy, which is novel to existing methods."
                },
                "weaknesses": {
                    "value": "1. The paper is poorly written, which misses many necessary introductions and clarifications. For example, in the introduction section, the paper is written to be motivated to provide IP protection for the model owner. However, in the illustrative figure in Figure 1, it is more like to protect the artists (data owner)'s IP. \n\n2. Besides, it is not clear the reason of Algorithm 2, because it is also different from the introduction in Eq. (1) and Figure 1. In Eq. (1) and Figure 1, they both use the protected model for re-generalization. Thus, there is no clues on the reason to also use $G_\\times$ for re-generation. \n\n3. For the theory part, no motivation or clarification on the meaning and use of these theories. \n\n4. The basic assumption of the proposed method also seems problematic. For example, in the image generative models, the paper never discusses how to input the image samples to the model for re-generate. Based on my understanding, the Stable Diffusion models are text to image models. Therefore, how to input images to these models? \n\n5. The paper should also discuss how similar or how different of the re-generation process and the traditional generation process. In practice, there is no way for the ''verifier'' to know how are the original samples are generated. In this way, whether the shift of generation process from re-generation can cause and compromise verification performance should also be discussed."
                },
                "questions": {
                    "value": "Plz see the above question."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9219/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9219/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9219/Reviewer_66tW"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9219/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698694226507,
            "cdate": 1698694226507,
            "tmdate": 1699637160107,
            "mdate": 1699637160107,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HTMPxJrEIW",
                "forum": "nOf6sb63dT",
                "replyto": "brXZPHKdGY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9219/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9219/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 66tW"
                    },
                    "comment": {
                        "value": "**[Q1]**: The paper is poorly written, which misses many necessary introductions and clarifications. For example, in the introduction section, the paper is written to be motivated to provide IP protection for the model owner. However, in the illustrative figure in Figure 1, it is more like to protect the artists (data owner)'s IP.\n\n**[A1]**: There is no difference in protecting the IP by *human* or *artificial* artists in our framework. We use artefacts by Van Gogh and Picasso because i) it enhances the paper's visual appeal and ii) it circumvents potential IP infringement issues associated with commercial generative models (which is actually what we propose to protect). In addition, it is pertinent to conceptualize the artist as a *model* capable of embedding their unique style, functioning as a watermark, into their creations.\n\n---\n\n**[Q2]**:  There are no clues on the reason to also use $G_{\\times}$ for re-generation.\n\n**[A2]**:  $G_{\\times}$ is used in the verification process, as it is essential to compare the distance from the authentic model $d(G_{a}(x_a), x_a)$ against those by a different (unauthentic) model $d(G_{\\times}(x_a), x_a)$. This gives a margin $\\delta$ to decide how confident we can claim the IP (see more discussion in Table 2). \n\n----\n\n**[Q3]** For the theory part, no motivation or clarification on the meaning and use of these theories.\n\n**[A3]**: The motivation lies in two parts: (1) Intuitively, the authentic model should be easier to re-generate the samples previously generated by itself (formulated in Equation 1); (2) Iterative re-generation can reduce the \"*self-edit*\" distance (reflected by Fixed-Point Theorem in Section 3.2) and it can be utilised in verification (in Algorithm 2).\nWe have highlighted and added the motivation and connection of the theories in Section 3 (see red texts). We hope our verification and answer have solved your concern.\n\n---\n\n**[Q4]**: The paper never discusses how to input the image samples to the model for re-generate. Based on my understanding, the Stable Diffusion models are text to image models. Therefore, how to input images to these models?\n\n**[A4]**: Image re-generation is achieved by inpainting masked pixels.  The Stable Diffusion Inpainting pipeline provided by HuggingFace allows taking and masking an input image for generating specific parts of the image, conditioned on the unmasked portion of the input image. Text prompt is set to an empty string [\u201c\u201d] on re-generation. Please find more information about Stable Diffusion and Inpainting in HuggingFace (with an example https://huggingface.co/runwayml/stable-diffusion-inpainting). We have further revised Appendix B.1. which we hope provides more clarity. Please let us know if you would like any further clarification. \n\n---\n\n\n**[Q5.1]**: The paper should also discuss how similar or how different the re-generation process and the traditional generation process. \n\n**[A5.1]**: We take CV tasks as an example, the target generation tasks could be any existing image generation tasks, e.g., text to image, text+image to image, etc. The re-generation process is basically generating an image `similar\u2019 to the original input (similar to paraphrasing in NLG). \n\n**[Q5.2]**: In practice, there is no way for the ''verifier'' to know how are the original samples are generated. In this way, whether the shift of the generation process from re-generation can cause and compromise verification performance should also be discussed.\n\n**[A5.2]**:  We agree that the \"verifier\" may not have knowledge of the images/sentences generation process, but our verification process works on various re-generation steps $k$. Nonetheless, this study focuses on determining whether re-generation aids in the identification of IP as outlined in Section 3.1. According to Tables 2, 5, and 6, our approach demonstrates efficacy in IP identification, with further improvements achievable through iterative re-generation.\n\n---\n\nWe hope our responses have solved your concerns. We are pleased to answer additional questions."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9219/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700437416859,
                "cdate": 1700437416859,
                "tmdate": 1700437938627,
                "mdate": 1700437938627,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vNjJNqDnYB",
                "forum": "nOf6sb63dT",
                "replyto": "brXZPHKdGY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9219/Reviewer_66tW"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9219/Reviewer_66tW"
                ],
                "content": {
                    "comment": {
                        "value": "I acknowledge that I receive and thank for the authors' response. \n\nAlthough the authors provide brief clarifications, I could still not clearly understand the basic problem setup and detailed algorithm. In detail, it is not clear that the protection subject is the model or the user's data, although the authors claim there is not difference between these two. I suggest the authors provide explicit problem definition before introducing the solutions in the future versions. \n\nBesides, the theorems and algorithms are still briefly introduced. For example, the \"re-generation\" process is a very important component in the algorithm, and it could still be very different in different generative models. However, a detailed introduction is not provided. \n\nBased on these reasons, I tend to keep my original rating."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9219/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700587847626,
                "cdate": 1700587847626,
                "tmdate": 1700587847626,
                "mdate": 1700587847626,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5TGN5GEOMo",
                "forum": "nOf6sb63dT",
                "replyto": "brXZPHKdGY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9219/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9219/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Clarification"
                    },
                    "comment": {
                        "value": "Thank you for your reply. We want to clarify that:\n1. Our framework can authenticate the IP of data samples produced by either AI models or human contributors. The crux of this verification lies in ascertaining that the IP of the data is a direct result of the IP inherent in the models or the human creators involved. To illustrate, consider the example of authoring a book. The fundamental aim in such a scenario is to assert the IP of the book, underscoring that it is human\u2019s or model\u2019s creation. This analogy serves to explain our primary goal in this research.\n2. The re-generation process is as simple as $x'=f(x; \\theta)$, where $f(\\cdot; \\theta)$ is a `paraphrase-style` or `inpainting-style` generator. It is widely supported by AGI models such as ChatGPT, Stable Diffusion and their successors. The detailed descriptions are provided in Sections 4.2 and 4.3.\n3. Our method gives insight in how to enhance and verify the IP by using the simplest re-generation process without (1) manipulating the generative models and their outputs or (2) additional classification models which require training."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9219/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700627858243,
                "cdate": 1700627858243,
                "tmdate": 1700628095271,
                "mdate": 1700628095271,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "XrmIn2azj6",
            "forum": "nOf6sb63dT",
            "replyto": "nOf6sb63dT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9219/Reviewer_Bepi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9219/Reviewer_Bepi"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a method for verifying data authorship in generative models without conventional watermarking. It discovers latent fingerprints inherent in deep learning models by comparing original data samples with their re-generated counterparts. It introduces a framework for generating and verifying these model fingerprints and establishes a practical protocol to authenticate data ownership in generative models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The approach of uncovering latent fingerprints through regeneration is novel. The observation of distance convergence is straightforward and interesting.\n\n2. The method is easy to implement. It uses standard generative models without requiring complex modifications to the model or additional tools."
                },
                "weaknesses": {
                    "value": "1. In the neural language generation experiments, the paper used round-trip translation as re-generation. Since this is a relatively easy task, the same method might not generalize well to other, more demanding text generation tasks, such as creative writing which is more prevalent in real-world applications.\n\n2. The method\u2019s design, focused on distinguishing outputs between specific models, may not be adept at confirming if a piece of content is exclusively generated by a particular model. This is especially pertinent in scenarios where it\u2019s critical to ascertain whether content originated from a specific source, and not just differentiate it from another known model.\n\n3. The method is less effective for certain models as shown in Figure 3 and Appendix D.2.  \n\n4. The theoretical analysis looks good. One concern is that the Lipschitz constant could be larger than 1 for complex/deep models. Thus, the assumption may not hold for real-world generative models. This is not a major issue. Could authors mention this?\n\n5. The description of the method is not very clear. The subsection 3.3 is very short, which makes it very hard to understand. I suggest the authors to give some examples when describing the method. Otherwise, it is very challenging to understand the method after reading Section 3.\n\n6. The cost is very large because we need to repeat it k times to generate an output. Also, from Section 3.3, it is not clear how exactly the re-generation is done for text and image, e.g., line 33 in Algorithm 1. \n\n7. The robustness is not considered, e.g., an attacker could slightly change the words in a text. Will the proposed method still be effective in this case? I would suggest authors to conduct some adaptive attacks to study the robustness of the verification."
                },
                "questions": {
                    "value": "See above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9219/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698801766554,
            "cdate": 1698801766554,
            "tmdate": 1699637159909,
            "mdate": 1699637159909,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "eriM5CCYZB",
                "forum": "nOf6sb63dT",
                "replyto": "XrmIn2azj6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9219/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9219/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Bepi (1/2)"
                    },
                    "comment": {
                        "value": "Thank you for appreciating the novelty and simplicity of our framework.\n\n---\n\n**[Q1]**:  Round-trip translation is relatively easy,  the same method might not generalize well to others.\n\n**[A1]**: **Re-generation** can be done through various methods, including but not limited to round-trip translation and prompt-based paraphrasing. Round-trip translation is utilized as one method of re-generation step in our paper, as described in Section 4.2. Furthermore, we would like to emphasize that the **target generation task** within our framework may encompass any task within the scope of LLMs, with translation being one pertinent example.\n\nTo demonstrate the generalization of our approach, we further examine two popular text generation tasks using prompting: *paraphrasing* and *summarization*. In these tasks, *prompt-based paraphrasing* is employed as the re-generation step. We set k to 5 because of its superior performance. The results are presented in the following tables. \n\n\nParaphrasing as generation task:\n\n |      Models         |  **GPT-3.5-turbo**  | | **Zephyr**  |  | **Mistral** | |\n| :---------------- | :------: | :------: |:------: | :------: |:------: | :------: |\n|  | Acc  | Mis | Acc  | Mis | Acc  | Mis |\n|GPT-3.5-turbo | - | - | 75.0 | 20.0 | 69.0 |24.0 |\n|Zephyr | 84.0 | 10.0 | - | - | 69.0 | 23.0 |\n| Mistral | 74.0 | 19.0 | 76.0 | 10.0 | - | -|\n\n\nSummarization as generation task: \n|      Models         | **GPT-3.5-turbo**  | | **Zephyr**  |  | **Mistral** | |\n| :---------------- | :------: | :------: |:------: | :------: |:------: | :------: |\n|  | Acc  | Mis | Acc  | Mis | Acc  | Mis |\n|GPT-3.5-turbo | - | - | 92.0 | 6.0 |68.0 |24.0 |\n|Zephyr | 88.0 | 10.0 | - | - | 67.0 | 26.0 |\n| Mistral | 86.0 | 12.0 | 86.0 | 12.0 | - | -|\n\nAccording to these results, our approach can effectively distinguish between authentic models and contrast models in the context of both paraphrasing and summarization (as the target tasks) with prompt-based paraphrasing (as re-generation steps).\n\n---\n\n**[Q2]**: The method may not reliably confirm the source model, since it focuses on differentiating between models rather than identifying unique sources.\n\n**[A2]**: We would like to emphasize that the proposition of IP detection is typically initiated by the model owners. This means that should the owners suspect an IP infringement, they can utilize our approach to substantiate that the images or sentences in question are outputs of their authentic models, rather than those generated by any other models (claimed by the opposing party). This assertion has been corroborated through our experimental findings, as illustrated in Figures 3 and 4. Consequently, we contend that our approach is efficacious in asserting IP claims.\n\n\n---\n\n**[Q3]**: The method is less effective for certain models as shown in Figure 3 and Appendix D.2.\n\n**[A3]**: We acknowledge the question regarding the effectiveness of our method on NLP models. Firstly, M2M, mBART and GPT are clearly distinguished from each other and such a conclusion is also supported in Tables 2 and 7. Secondly, different versions of GPT (1) are slightly more challenging to differentiate and (2) have no requirement of discrimination as they belong to the same company."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9219/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700437083440,
                "cdate": 1700437083440,
                "tmdate": 1700437083440,
                "mdate": 1700437083440,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Wjwy9GCpgg",
                "forum": "nOf6sb63dT",
                "replyto": "XrmIn2azj6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9219/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9219/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Bepi (2/2)"
                    },
                    "comment": {
                        "value": "**[Q4]**: One concern is that the Lipschitz constant could be larger than 1 for complex/deep models. Thus, the assumption may not hold for real-world generative models. This is not a major issue. Could authors mention this?\n\n**[A4]**: We add an empirical estimation of the Lipschitz constant $L$ of Stable Diffusion models. We use all pairs of images ($x$ and $y$) from Polo dataset, representing them as inputs and applying the regeneration function $f(\\cdot)$. We measure their distances using $\\mathbb D$, i.e. Euclidean and LPIPS. The ratio below is the transformation of Equation 4:\n$$L \\triangleq \\frac{D(f(x), f(y))}{D(x,y)}$$\n\n| Model     | **LPIPS** | **(L)** | **Euclidean** | **(L)** |\n|-----------|--------------|-------------|------------------|-----------------|\n|| Mean | Std | Mean | Std | \n| SD v2.1   | 0.976        | 0.015       | 1.000            | 0.001           |\n| SDXL 1.0  | 0.943        | 0.21        | 1.000            | 0.004           |\n| SD v2     | 0.975        | 0.016       | 1.000            | 0.001           |\n| SD v2.1B  | 0.970        | 0.023       | 1.000            | 0.002           |\n| SDXL 0.9  | 0.946        | 0.020       | 0.999            | 0.005           |\n\nOur analysis adds several insights to our work:\n1. The mean L values are consistently less than for LPIPS, which explains the superior performance using LPIPS and the reason that Euclidean distance does not work in our study. \n2. Usually, better (latest) models exhibit better (lower) L constant. \n\nNote that our framework focuses on empowering the watermarking property for models that **CAN** be verified. For those models that currently have not worked under our framework, we suggest targeting better model performance considering our observation and analysis (item 2).\n\nWe believe these additional experiments would add confidence to the assumption used in the theory.\n\n---\n\n**[Q5]**: The subsection 3.3 is very short, which makes it very hard to understand. I suggest the authors give some examples when describing the method. Otherwise, it is very challenging to understand the method after reading Section 3.\n\n**[A5]**: Thank you for your suggestion on the clarity of our methodology section. Imagine artists refining their distinct writing or painting styles during each artwork replication. Similarly, a generative model's unique `style' becomes more defined during image re-generation, as deviations reduce. This mirrors iterative functions which converge to fixed points. In our case, each re-generation brings the image closer to the model's inherent style, and the distinct fingerprint facilitates AI authorship verification. We have incorporated this clarification into our revision (please see the red text pieces in Section 3.3).\n\n---\n\n**[Q6]**: The cost is very large because we need to repeat it k times to generate an output.\n\n**[A6]**: We believe the cost is affordable for the additional watermark property.\n\n1. The cost is arguably not *very* large, as it is linearly correlated to the original target generative task, i.e. $\\Theta(T)$ to $\\Theta(kT)=\\Theta(T)$ where k is a constant and our watermark is empirically effective when $k \\in [1, 5]$.\n2. It is worth noting that the samples can be verified by even 1-step re-generation, see Tables 2, 6 and 7 (k=1).\n\n---\n**[Q7]**: The robustness is not considered, e.g., an attacker could slightly change the words in a text. Will the proposed method still be effective in this case?\n\n**[A7]**: Thank you for the suggestion! We have added experiments to test the robustness against \u2018slightly change the words\u2019.  We conduct perturbation (i.e. replacing some words with random ones) on each input prior to a one-step re-generation process. The perturbation rate is varied ranging from 10% to 50%. Due to the time limitation, our experiments currently utilise the GPT-3.5-turbo as the authentic model (therefore the corresponding column is left empty), however, we plan to extend our analysis to other models in our revision. \n\n|      k=5         | M2M  | | mBART  |  | GPT3.5-|turbo | Cohere | |\n| :---------------- | :------: | :------: |:------: | :------: |:------: | :------: |:------: | :------: |\n| Perturbation rate (r) | Acc  | Mis | Acc  | Mis | Acc  | Mis |Acc  | Mis |\n|0% | 90.0  | 6.0 | 94.0 | 2.0 | -  | - | 95.0  |3.0|\n|10% | 91.0 | 6.0 | 91.0 | 3.0 | -  | - | 97.0 | 2.0|\n| 20% | 84.0 | 12.0 | 84.0 | 11.0 | -  | - | 95.0 | 4.0|\n|30% | 84.0 | 12.0 | 74.0 | 15.0 | - | - | 94.0 | 3.0|\n| 40% | 79.0 | 17.0 | 75.0 | 16.0 | - | - | 93.0 | 5.0|\n| 50% | 69.0 | 22.0 | 65.0 | 22.0 | -  | - | 92.0 | 6.0 |\n\nAccording to the Table above, as the perturbation rate increases, there is a corresponding gradual decrease in the accuracy of our method. The overall capability of watermark verification is reasonably positive. Nonetheless, we argue that 30-50% perturbation has already significantly harmed the quality of the generated texts and attackers can hardly get much benefit from this."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9219/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700437263075,
                "cdate": 1700437263075,
                "tmdate": 1700437356122,
                "mdate": 1700437356122,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "OHAOp8OpkE",
            "forum": "nOf6sb63dT",
            "replyto": "nOf6sb63dT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9219/Reviewer_XHuY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9219/Reviewer_XHuY"
            ],
            "content": {
                "summary": {
                    "value": "The topic of intellectual property in Generative Adversarial Networks has been studied for quite some time. In this paper, the authors introduce an iterative re-generation method to enhance the fingerprints within current state-of-the-art generative models. The paper is well-organized and easy to follow, with a simple yet effective main contribution. The proposed method can be easily implemented to protect intellectual property without requiring any white-box settings, making it a lightweight and easily verifiable solution."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ The proposed method is easy yet effective. The experiments are conducted comprehensively on both NLP and CV generative models. The proposed method can be easily implemented to protect intellectual property without requiring any white-box settings, making it a lightweight and easily verifiable solution."
                },
                "weaknesses": {
                    "value": "- I am still unclear about how to verify the convergence of the distance between one-step re-generation (Distance Convergence). In Equation 2, the distance converges to 0, given that L \u2208 (0, 1). However, how can we guarantee that L is less than 1? Is this only confirmed through experiments?"
                },
                "questions": {
                    "value": "Is the value of \\epsilon sensitive in the experiments? Since many LLM or MLM models are black-box, how can one select a sensible \\epsilon?\nIn the Appendix, as k increases, the accuracy does not seem to increase significantly. The experimental results may not be entirely consistent with the analyses in Equation 2. Is this discrepancy due to the presence of some other bad case samples, or is it because the distances are not larger enough?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9219/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698837819318,
            "cdate": 1698837819318,
            "tmdate": 1699637159799,
            "mdate": 1699637159799,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XUxUoQhjBo",
                "forum": "nOf6sb63dT",
                "replyto": "OHAOp8OpkE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9219/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9219/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer XHuY (1/2)"
                    },
                    "comment": {
                        "value": "We would like to take this opportunity to highlight some significance of our work compared with previous work. \n1. **[Model performance]**: Our approach does not rely on additional post-processing and model training/manipulation, which means no harm to the performance of the generative models.\n2. **[Verification Advantage]**: Our approach is independent of additional classifiers for verification. This means it avoids the potential robustness issues of domain adaptation for classifiers, considering verifying samples generated by new models (new company, new training dataset, new architecture etc.).\n3. **[Scenario]**: (a) In future, generative models are not required to add additional watermarks for verification. (b) For previously published AI-generated samples, our approach manages to trace back the IP infringement (considering many generative models in various applications have not yet seriously considered embedding watermarks to their systems).\n4. **[Simplicity]**: Our approach is simple and effective. It means many generative AI models, CV and NLP as examples in our paper, can benefit from our research.\n\n---\n\n**[Q1]**: how to verify the convergence of the distance between one-step re-generation (Distance Convergence)\n\n**[A1]**: As demonstrated in Figures 2 and 4, the one-step re-generation distance will converge regarding various metrics for both NLP and CV generative models. In Algorithm 1, the generator has already finished $k$ steps re-generation, $k \\in \\mathbb Z^{+}$, and the distance derived in the verification process (in Algorithm 2) is equivalent to the $k+1$-th step. Therefore, the $k+1$-th step re-generation distances (in verification) theoretically converge to small values and be empirically verifiable.\n\n\n---\n\n\n**[Q2]**: How can we guarantee that L is less than 1?\n\n**[A2]**: Thank you for your question. We add an empirical estimation of the Lipschitz constant $L$ of Stable Diffusion models. We use all pairs of images ($x$ and $y$) from Polo dataset, representing them as inputs and applying the regeneration function $f(\\cdot)$. We measure their distances using $\\mathbb D$, i.e. Euclidean and LPIPS. The ratio below is the transformation of Equation 4:\n$$L \\triangleq \\frac{\\mathbb D(f(x), f(y))}{\\mathbb D(x,y)}.$$\n\n\n| Model     | L_LPIPS Mean | L_LPIPS Std | L_Euclidean Mean | L_Euclidean Std |\n|-----------|--------------|-------------|------------------|-----------------|\n| SD v2.1   | 0.976        | 0.015       | 1.000            | 0.001           |\n| SDXL 1.0  | 0.943        | 0.21        | 1.000            | 0.004           |\n| SD v2     | 0.975        | 0.016       | 1.000            | 0.001           |\n| SD v2.1B  | 0.970        | 0.023       | 1.000            | 0.002           |\n| SDXL 0.9  | 0.946        | 0.020       | 0.999            | 0.005           |\n\nOur analysis adds several insights to our work:\n1. The mean L values are consistently less than for LPIPS, which explains the superior performance using LPIPS and the reason that Euclidean distance does not work in our study. \n2. Usually, better (latest) models exhibit better (lower) L. \n\nIt is worth noting that our framework focuses on empowering the watermarking property for models that **CAN** be verified, instead of enforcing that every model is verifiable. For those models that currently have not worked under our framework, we suggest targeting better model performance considering our observation and analysis (item 2).\n\n---\n\n\n**[Q3]**: Sensitivity of $\\epsilon$ \n\n**[A3]**: $\\epsilon$ has not been employed  in our paper. We assume you were inquiring about the $\\delta$, a critical hyper-parameter used in Algorithm 2. We set $\\delta$ to 0.05, as it yields optimal results for NLP experiments according to Table 1. We observe the same trend for CV experiments below.\n\nThe accuracy of differentiating contrast models from the authentic model SDv2.1 using different $\\delta$.\n\n| $\\delta$ | SD v2.   | SD v2.1B | SDXL 0.9 | SDXL 1.0 |\n|----------|----------|----------|----------|----------|\n| 0.05     | 0.990    | 1.00     | 1.00     | 1.00     |\n| 0.10     | 0.985    | 1.00     | 1.00     | 1.00     |\n| 0.20     | 0.960    | 1.00     | 1.00     | 1.00     |\n| 0.40     | 0.895    | 1.00     | 0.995    | 0.985    |"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9219/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700436691168,
                "cdate": 1700436691168,
                "tmdate": 1700436691168,
                "mdate": 1700436691168,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hmiAxxDv1L",
                "forum": "nOf6sb63dT",
                "replyto": "OHAOp8OpkE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9219/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9219/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer XHuY (2/2)"
                    },
                    "comment": {
                        "value": "**[Q4]**: In the Appendix, as k increases, the accuracy does not seem to increase significantly. The experimental results may not be entirely consistent with the analyses in Equation 2. Is this discrepancy due to the presence of some other bad case samples, or is it because the distances are not large enough?\n\n**[A4]**: We assume you are referring to Table 5 regarding the minimal performance increase when k increases. We would like to highlight that the overall performance of our approach across all models improves given higher $k$ regarding both Avg Acc. and Avg Mis. The row average and overall average scores for Table 2 and Table 5 are calculated and presented as follows:\n\nk=3:\n\n| Models   | Avg Acc. | Avg Mis. |\n|----------|----------|---------|\n| SDv2.1   | 90.125   | 7.875   |\n| SDv2     | 89.625   | 7.625   |\n| SDv2.1B  | 78.000   | 17.50   |\n| SDXL 0.9 | 90.750   | 8.000   |\n| SDXL 1.0 | 93.250   | 4.875   |\n| **Overall Avg** | **88.350** | **9.175** |\n\nk=5:\n\n| Models   | Avg Acc. | Avg Mis. |\n|----------|----------|---------|\n| SDv2.1   | 88.5     | 8.625   |\n| SDv2     | 88.375   | 8.625   |\n| SDv2.1B  | 80.875   | 14.375  |\n| SDXL 0.9 | 96.625   | 2.25    |\n| SDXL 1.0 | 93.125   | 5.25    |\n| **Overall Avg** | **89.5** | **7.825** |\n\n\nNLP:\nk=3\n| Models   | Avg Acc. | Avg Mis. |\n|----------|----------|---------|\n|M2M | 96.3 | 1.3\n|mBART | 91.7\t| 3.7 | \n|GPT3.5-turbo\t| 93.0\t| 5.0 |\n|Cohere | 70.3\t| 24.0 | \n|**Overall Avg** | **87.8** | **8.5** |\n\nk=5\n\n| Models   | Avg Acc. | Avg Mis. |\n|----------|----------|---------|\n| M2M | 95.7 | 1.3 |\n| mBART | 93.0\t| 3.3 |\n| GPT3.5-turbo | 93.0 | 3.7|\n| Cohere | 74.3 | 19.7|\n|**Overall Avg** | **89.0** | **7.0** |\n\n---\nWe hope our clarification and additional experiments have solved your concerns. We are pleased to take additional questions."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9219/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700436789136,
                "cdate": 1700436789136,
                "tmdate": 1700436789136,
                "mdate": 1700436789136,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]