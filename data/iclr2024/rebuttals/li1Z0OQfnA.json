[
    {
        "title": "On Local Equilibrium in Non-Concave Games"
    },
    {
        "review": {
            "id": "HxYrvVV9zU",
            "forum": "li1Z0OQfnA",
            "replyto": "li1Z0OQfnA",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8732/Reviewer_J78b"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8732/Reviewer_J78b"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a notion of \u201clocal correlated equilibrium\u201d for non-concave games, and show that variants of GD converge to this solution concept."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "Some of the algorithms require careful analysis? I'm not sure..."
                },
                "weaknesses": {
                    "value": "At a high level, I\u2019m concerned about the motivation. The authors introduce a new solution concept and design algorithms, but don\u2019t really stop to motivate their solution concept. The way I understand, in practice GAN training with OGD has limited success because it gets stuck in cycles. Now you\u2019re basically telling me that the path of this training satisfies some new solution concept. What should I learn from that? By analogy, in Game Theory correlated equilibrium has a natural interpretation with a correlating device, and is known to satisfy some good properties (\u201cPrice of Anarchy\u201d). What can I do with the fact that the trajectory of my GAN training algorithm is an approximate \u201clocal correlated equilibrium\u201d?"
                },
                "questions": {
                    "value": "[These are more writing comments - but feel free to answer my questions from \"weaknesses\" section]\n\n\n\nThe paper is motivated by a hardness result from [DSZ21] for the stronger notion of local Nash equilibrium. But the hardness result in [DSZ21] holds *only* in a non-standard setting where the feasible domain is not a product. In contrast, your work seems to rely on having a product domain. \n\n\nI think your solution concept should be called \u201clocal *coarse* correlated equilibrium\u201d: You consider a single deviation rule and want to apply it to all x\u2019s in the distribution. This also explains why you can find it by minimizing external regret.\n\nThe title should absolutely be updated to say something about (coarse) correlated.\n\n\nThere are two definitions (2 and 4) called \u201clocal correlated equilibrium\u201d"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8732/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697816051024,
            "cdate": 1697816051024,
            "tmdate": 1699637095600,
            "mdate": 1699637095600,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "poKB6yW76J",
                "forum": "li1Z0OQfnA",
                "replyto": "HxYrvVV9zU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8732/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8732/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q**: *At a high level, I\u2019m concerned about the motivation. The authors introduce a new solution concept and design algorithms, but don\u2019t really stop to motivate their solution concept. The way I understand, in practice GAN training with OGD has limited success because it gets stuck in cycles. Now you\u2019re basically telling me that the path of this training satisfies some new solution concept. What should I learn from that? By analogy, in Game Theory correlated equilibrium has a natural interpretation with a correlating device, and is known to satisfy some good properties (\u201cPrice of Anarchy\u201d). What can I do with the fact that the trajectory of my GAN training algorithm is an approximate \u201clocal correlated equilibrium\u201d?*\n\n**A**: Thank you for the comment on the motivation of our proposed solution concepts. We appreciate the opportunity to further elucidate our goals. Our primary objective is to introduce a new solution concept for non-concave games that satisfies  the following three requirements: game theoretic meaningfulness, universality, and computational tractability. Our notion of local correlated equilibrium is meaningful as it generalizes the notion of correlated equilibrium and coarse correlated equilibrium to non-concave games. Additionally, as we argue in the paper, this solution concept always exists, hence its universality. Finally, for the two instantiations, we show that these solution concepts are computationally tractable.\n\nAs highlighted by the reviewer, correlated equilibrium is a useful concept when there is a signaling device that could be used to correlate different agents\u2019 actions. However, in the context of non-concave games, finding a correlated equilibrium is computationally intractable. We believe our solution concept serves as a useful alternative in these non-concave games where a signaling device is available, which includes many multi-agent systems such as market dynamics (see the respones to Review oLqg (Q1) for an example), cooperative strategies among self-driving cars, and interactions within social networks. \n\nFinally, it\u2019s important to note that the training GANs is a min-max optimization problem where the goal is to identify the minimax strategy for the min-player (controlling the generator network). Our focus on finding a local correlated equilibrium is very different from the pursuit of a minimax strategy, and as such, doesn\u2019t inherently guarantee high performance of the generator.\n\n**Q**: *The paper is motivated by a hardness result from [DSZ21] for the stronger notion of local Nash equilibrium. But the hardness result in [DSZ21] holds only in a non-standard setting where the feasible domain is not a product. In contrast, your work seems to rely on having a product domain.*\n\n**A**: Thanks for pointing this out! The result from [DSZ21] shows that local Nash equilibrium is intractable even in two-player **zero-sum** games with coupled domain. Thus whether local Nash equilibrium in two-player zero-sum games can be efficiently computed with product domain is still open. However, we study the more general multi-player non-concave games that include two-player **general-sum** games as a special case. Note that in a two-player general-sum bimatrix game, since the loss function is linear in each player\u2019s strategy, it is not hard to see that every local Nash equilibrium is also a Nash equilibrium, and, therefore, is PPAD-hard to compute [DGP09, CDT09]. The intractability of local Nash equilibrium in general-sum games motivates our new local solution concepts that is universal for multiplayer non-concave smooth games.\n\n[DSZ21] Daskalakis, Constantinos, Stratis Skoulakis, and Manolis Zampetakis. \"The complexity of constrained min-max optimization.\" STOC, 2021\n\n[DGP09] Daskalakis, Constantinos, Paul W. Goldberg, and Christos H. Papadimitriou. \"The complexity of computing a Nash equilibrium.\" SICOMP, 2009\n\n[CDT09] Chen, Xi, Xiaotie Deng, and Shang-Hua Teng. \"Settling the complexity of computing two-player Nash equilibria.\" JACM, 2009"
                    },
                    "title": {
                        "value": "Response to Reviewer J78b-Part 1"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8732/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700333576790,
                "cdate": 1700333576790,
                "tmdate": 1700333604388,
                "mdate": 1700333604388,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "M4Sp0wmEnu",
                "forum": "li1Z0OQfnA",
                "replyto": "HxYrvVV9zU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8732/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8732/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer J78b-Part 2"
                    },
                    "comment": {
                        "value": "**Q**: *I think your solution concept should be called \u201clocal coarse correlated equilibrium\u201d: You consider a single deviation rule and want to apply it to all x\u2019s in the distribution. This also explains why you can find it by minimizing external regret.*\n\n**A**: We would like to clarify that both coarse correlated equilibrium (CCE) and correlated equilibrium (CE) consider a single strategy modification (deviation rule) that is applied to all strategies. The core difference between CCE and CE is that CCE allows only constant strategy modification that maps any strategy to a fixed strategy, while CE allows all possible linear transformations over the strategy space (i.e., the simplex). In the context of normal-form games, both CCE and CE are special cases of $\\Phi$-equilibria: a CCE is a $\\Phi_{ext}$-equilibrium where $\\Phi_{ext}$ contains only constant strategy modifications; a CE is a $\\Phi_{swap}$-equilibrium where $\\Phi_{swap}$ contains all linear transformations $\\phi: \\Delta \\rightarrow \\Delta$. \n\nThe solution concept we propose, $(\\epsilon, \\Phi(\\delta))$-local correlated equilibrium, is determined by the set of strategy modifications $\\Phi(\\delta)$. In general, $\\Phi(\\delta)$ could include all possible (local) strategy modifications, not only constant strategy modifications. The two specific instantiations considered in the paper, $\\Phi_{int}(\\delta)$ and $\\Phi_{proj}(\\delta)$, also allow non-constant strategy modifications. That is why we choose to call it local correlated equilibrium instead of local coarse correlated equilibrium. Additionally, we have showed in the paper that $Reg_{proj}(\\delta)$ is incomparable with the external regret and minimizing external regret does not always lead to a $\\Phi_{proj}(\\delta)$-local correlated equilibrium (Example 1 and 2 in section 5).\n\n**Q**: There are two definitions (2 and 4) called \u201clocal correlated equilibrium\u201d\n\n**A**: Thanks for pointing out! We have changed Definition 4 to \"Two Instantiations of Local Correlated Equilibrium\"."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8732/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700333788286,
                "cdate": 1700333788286,
                "tmdate": 1700334081528,
                "mdate": 1700334081528,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xGEwc6FhWC",
                "forum": "li1Z0OQfnA",
                "replyto": "hw0Vh89tM8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8732/Reviewer_J78b"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8732/Reviewer_J78b"
                ],
                "content": {
                    "title": {
                        "value": "Confused about authors' reply to Q1: why not just focus on regret?"
                    },
                    "comment": {
                        "value": "I'm confused about your response to this reviewer's Q1 about the (lack) of motivation for the new solution concept that you introduce, which you also cited in your response to my review:\nYou propose to motivate your solution concept in that if the no-regret dynamics converge to it, then each player would have low regret. But if all you're trying to achieve is low regret, why talk about equilibria at all? I.e. why not just analyze the performance of no-regret algorithms in non-concave games?"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8732/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700506934026,
                "cdate": 1700506934026,
                "tmdate": 1700506934026,
                "mdate": 1700506934026,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "V8LEMIvyJv",
                "forum": "li1Z0OQfnA",
                "replyto": "poKB6yW76J",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8732/Reviewer_J78b"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8732/Reviewer_J78b"
                ],
                "content": {
                    "title": {
                        "value": "DZS vs DGP vs CDT"
                    },
                    "comment": {
                        "value": "Your current version is still citing the hardness result of DSZ without mentioning that it doesn't apply at all to the setting you're considering.\n\nNote that DGP only proved hardness against 1/exp(n)-approximate Nash equilibrium, while your regret-based algorithms only give 1/poly-approximate local \\Phi-correlated equilibrium, so it is not particularly relevant.\n\nYou are right that CDT proved hardness of 1/poly-approximate Nash equilibrium which trivially extends from bilinear to general non-concave games. But you don't cite CDT at all in your paper!"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8732/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700507422930,
                "cdate": 1700507422930,
                "tmdate": 1700507422930,
                "mdate": 1700507422930,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "i3JKeSpLM9",
                "forum": "li1Z0OQfnA",
                "replyto": "M4Sp0wmEnu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8732/Reviewer_J78b"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8732/Reviewer_J78b"
                ],
                "content": {
                    "title": {
                        "value": "Correlated vs Coarse Correlated equilibrium"
                    },
                    "comment": {
                        "value": "I agree that for certain choices of $\\Phi$ you *could* get something that could be honestly called local correlated equilibrium.\n\nBut the choices of $\\Phi$ that you actually analyze in your paper, while they don't perfectly align with either classical notions of external or internal, are much closer in spirit to external regret in the sense that the allowed transformations are defined by a single strategy in the domain. I guess you could call it local $\\Phi$-correlated or something like that. But just \"local correlated\" is inaccurate, borderline misleading."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8732/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700507899043,
                "cdate": 1700507899043,
                "tmdate": 1700507899043,
                "mdate": 1700507899043,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "c7p7CU75NV",
                "forum": "li1Z0OQfnA",
                "replyto": "suNdlFgF7l",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8732/Reviewer_J78b"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8732/Reviewer_J78b"
                ],
                "content": {
                    "comment": {
                        "value": "Correction: no player would have an incentive to apply a *fixed* deviation that increases/decreases the recommended price by the same amount regardless of the recommendation. \n\n1. I think your paper desparately needs to include a discussion of such a motivating example\n\n2. It would help to motivate the computational complexity question if the motivating example is high dimensional"
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8732/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700590160005,
                "cdate": 1700590160005,
                "tmdate": 1700590160005,
                "mdate": 1700590160005,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ewsutPVHB8",
            "forum": "li1Z0OQfnA",
            "replyto": "li1Z0OQfnA",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8732/Reviewer_oLqg"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8732/Reviewer_oLqg"
            ],
            "content": {
                "summary": {
                    "value": "The authors try to shed light on a new chapter of algorithmic game theory -- i.e., nonconcave games. Nonconcave games are simply games where the utility function of each player is nonconcave with respect to their individual strategy.\n\nSuch games have come to the attention of theoreticians due to the advent of an array of machine learning applications. Traditional notions of individual rationality such as the Nash equilibrium need not exist in these games while relaxed notions of equilibria designed for nonconvex games can be intractable. Namely, local $\\epsilon$-approximate Nash equilibria is a strategy profile in which no agent can improve their utility more than $\\epsilon$ by only considering strategy deviations of distance $\\delta$ from the initial strategy. Yet, $(\\epsilon, \\delta)$-local NE are either trivial to compute, PPAD-hard, or NP-hard (corresponding to the magnitude of $\\delta$ compared to the natural parameters of the game). The latter two cases are known as the *local* and the *global regime*.\n\nTo this end, the authors propose the notion of a *local correlated equilibrium* as to alleviate the intractability of local-NE in the local regime. After they define this new notion of equilibrium they review the notion of $\\Phi$-regret. Briefly, $\\Phi$-regret unifies various notions of regret (e.g., external regret, swap regret) under an umbrella definition; it is defined as the difference between in utility at the end of the online optimization process where the best strategy in hindsight is selected using a family of function $\\Phi$.\n\nThe latter notion is crucial not only for the purpose of an algorithmic solution as well as the notion of the equilibrium itself. An $(\\epsilon, \\Phi(\\delta))$-correlated equilibrium is roughly a correlated strategy profile that achieves small $\\Phi(\\delta)$-regret for each agent. $\\Phi(\\delta)$-regret is the $\\Phi$-regret where the family of modification functions only allow deviations in a radius of length $\\delta$.\n\nThe authors note that, to date, there does not exist an efficient algorithm for $\\Phi$-regret minimization for general sets $\\Phi$. As such, two families of $\\Phi$ are considered:\n* Interpolations between current strategies from fixed strategies\n* Deviations towards a given direction $v$ in a distance of length $\\delta$.\n\nThen, the authors utilize the existing online convex optimization framework (the gradient descent and optimistic gradient descent algorithms) to straightforwardly design algorithms that lead to $(\\epsilon, \\Phi(\\delta))$-correlated equilibria.\n\nAs a takeaway, the authors propose that solution concepts in nonconcave games should be *meaningful, universal, and tractable*.  I suspect these notions would take the place of rationality. Nevertheless, there is not an explicit discussion as to why their proposal attains these favorable properties."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The motivation is clear and is guided by both existing applications and contemporary theoretical advances.\n* The paper introduces algorithmic solutions and equilibrium concepts for a nascent family of games that arguably can be proven of great importance in the future.\n* The algorithmic framework is quite versatile and able to fit different instances of no-regret algorithms and $\\Phi$ function families.\n* The computational complexity issues are discussed and explained with clarity."
                },
                "weaknesses": {
                    "value": "* One has to be fair and recognize the novelty of the paper and the absence of pre-existing criteria for its assessment; nevertheless, it would be rational to ask for some justification of the proposed equilibrium notion other than computational complexity arguments. In a sense, what are real-world examples where the proposed notions of equilibria are already established as desirable states of a game?\n\n* A more precise meaning of what a meaningful and universal equilibrium is remains unclear from the text. It would be nice if the authors could elaborate on those concepts and what makes the particular $\\epsilon, \\Phi(\\delta)$-correlated equilibria attain these properties."
                },
                "questions": {
                    "value": "* What kinds of $\\Phi(\\delta)$ families would the authors consider as important for future study and of game-theoretic importance?\n* What is the connection of $\\Phi(\\delta)$-regret minimization and bounded rationality? Putting the computational theoretic aspects aside, we in a sense assume agents to be as rational as their first-order derivative dictates. Would assuming bounded rationality for the agents lead to tractable notions of equilibria as well?\n* What would qualitatively change if we assumed access to second-order information?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8732/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8732/Reviewer_oLqg",
                        "ICLR.cc/2024/Conference/Submission8732/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8732/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698800585009,
            "cdate": 1698800585009,
            "tmdate": 1699683104026,
            "mdate": 1699683104026,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hw0Vh89tM8",
                "forum": "li1Z0OQfnA",
                "replyto": "ewsutPVHB8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8732/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8732/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer oLqg-Part 1"
                    },
                    "comment": {
                        "value": "Thank you for your very detailed review and insightful questions! We address your questions below\n\n**Q1**: *One has to be fair and recognize the novelty of the paper and the absence of pre-existing criteria for its assessment; nevertheless, it would be rational to ask for some justification of the proposed equilibrium notion other than computational complexity arguments. In a sense, what are real-world examples where the proposed notions of equilibria are already established as desirable states of a game?*\n\n**A**: We appreciate your recognition of the novelty of our work and your interest in the practical relevance of our proposed equilibrium notion. We will use the dynamics of pricing in a competitive market as an example to illustrate the applicability of our $\\Phi_{proj}(\\delta)$-local correlated equilibrium concept in a real-world scenario. \n\nThe market has multiple agents selling identical goods. Each agent sets a price $p^i_t$ for their goods at day $t >=1$. The reward everyday depends on the agent\u2019s price: a high price decreases the demand of the goods but increases revenue per unit; while a low price could increase demand but decreases revenue per unit. In a complex market environment, the utility function in terms of $p_t^i$ could be non-concave so that even computing the optimal price given the knowledge of the utility functions is intractable. If each player adjusts their price using the online gradient descent algorithm, then our results show that their pricing strategy converges to a $\\Phi_{proj}(\\delta)$-local correlated equilibrium. In such equilibrium, each player would not regret to be more conservative (i.e., posting a slightly lower price $p_t- \\delta$ everyday) or to be more aggressive (i.e., posting a slightly higher price $p_t + \\delta$ everyday). This scenario demonstrates the equilibrium's relevance: in a market where agents have bounded rationality and make decisions based on localized price adjustments, our proposed equilibrium notion provides a stability guarantee. More generally, the proposed solution concepts may have practical implications, especially in multi-agent systems where agents encounter complex, non-concave utility functions and operate under the constraints of bounded rationality.\n\n**Q2**: *What kinds of $\\Phi(\\delta)$ families would the authors consider as important for future study and of game-theoretic importance?*\n\nA: This is a great question!  One family of $\\Phi(\\delta)$ that is important is a generalization of $\\Phi_{int}(\\delta)$. Recall that $\\Phi_{int}(\\delta)$ contains strategy modifications that interpolates between current strategy $x$ and a fixed strategy $x^*$. One can consider a strategy modification that interpolates between current strategy $x$ and a modified strategy $\\phi(x)$ for $\\phi \\in \\Phi\u2019$ where $\\Phi'$ is a set of (possibly not local) strategy modifications. $\\Phi_{int}(\\delta)$ then becomes a special case where $\\phi(x) = x^*$ is a constant strategy modification. By a similar proof to that in section 4, it is easy to show that regret minimization under the new set reduces to $\\Phi\u2019$-regret minimization. We think obtaining a more fine-grained understanding of the complexity of $\\Phi\u2019$-regret minimization for more general classes of strategy modifications $\\Phi\u2019$ is an interesting future direction. For instance, is it possible to define a meaningful complexity measure of a set $\\Phi\u2019$ that characterizes the computational / oracle complexity of $\\Phi\u2019$-regret minimization."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8732/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700332888451,
                "cdate": 1700332888451,
                "tmdate": 1700332888451,
                "mdate": 1700332888451,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "D93z77jUOK",
                "forum": "li1Z0OQfnA",
                "replyto": "ewsutPVHB8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8732/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8732/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer oLqg-Part 2"
                    },
                    "comment": {
                        "value": "**Q3**: *What is the connection of $\\Phi(\\delta)$-regret minimization and bounded rationality? Putting the computational theoretic aspects aside, we in a sense assume agents to be as rational as their first-order derivative dictates. Would assuming bounded rationality for the agents lead to tractable notions of equilibria as well?*\n\n**A**: This is a great question! We believe $\\Phi(\\delta)$-regret minimization is a model of  bounded rationality. In this context, we refer to bounded rationality as the idea that agents have limitations in their decision-making processes, particularly in terms of the information they consider and the computational resources they have.\n\nIn $\\Phi(\\delta)$-regret minimization, the set $\\Phi(\\delta)$ only contains local deviations that are bounded by $\\delta$. Thus agents are not fully rational as they ignore global deviations that might be more beneficial. Moreover, as you pointed out, assuming agents to be as rational as their first-order derivative dictates is a choice of bounded rationality. Furthermore, the cardinality and complexity of the set of $\\Phi(\\delta)$ reflect a degree of an agent\u2019s rationality: A more rational agent, within the bounds of their capabilities, might consider a larger and more complex set of potential deviations compared to a less rational agent. Our results demonstrate that two sets of $\\Phi(\\delta)$ lead to tractable notions of local correlated equilibrium. This suggests that by assuming bounded rationality, agents can achieve stable outcomes even in complex non-concave environments. \n\nExploring other models of bounded rationality, different equilibrium concepts, and learning dynamics that converge to these equilibria are very interesting future directions.\n\n**Q4**: *What would qualitatively change if we assumed access to second-order information?*\n\n**A**: We remark that by assuming access to second-order information, [DGSZ23] developed a second-order algorithm that converges to local Nash equilibrium although without concrete convergence rates. This result improves over first-order methods which usually get stuck in limit cycles and shows the power of second-order methods. If we assume access to second-order information, it is possible that we can develop algorithms with faster convergence to local correlated equilibrium than first-order algorithms. This is a very interesting future direction. \n\n[DGSZ23] Daskalakis, C., Golowich, N., Skoulakis, S., & Zampetakis, E. STay-ON-the-Ridge: Guaranteed Convergence to Local Minimax Equilibrium in Nonconvex-Nonconcave Games. COLT, 2023"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8732/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700333125070,
                "cdate": 1700333125070,
                "tmdate": 1700333125070,
                "mdate": 1700333125070,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "suNdlFgF7l",
                "forum": "li1Z0OQfnA",
                "replyto": "ewsutPVHB8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8732/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8732/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q**: *I'm confused about your response to this reviewer's Q1 about the (lack) of motivation for the new solution concept that you introduce, which you also cited in your response to my review: You propose to motivate your solution concept in that if the no-regret dynamics converge to it, then each player would have low regret. But if all you're trying to achieve is low regret, why talk about equilibria at all? I.e. why not just analyze the performance of no-regret algorithms in non-concave games?*\n\n**A**: There seems to be some misunderstanding regarding the example's purpose. It was intended to illustrate the kind of guarantee our solution concept offers. To rephrase: If a correlating device (mediator) suggests prices to each player according to an $(\\epsilon, \\Phi_{proj}(\\delta))$-local correlated equilibrium, then no player would have more than $\\epsilon$-incentive to deviate slightly from the recommended price, either by increasing or decreasing it.  This example serves to motivate the  $(\\epsilon, \\Phi_{proj}(\\delta))$-local correlated equilibrium by showing its ability to provide stability guarantees under a certain form of bounded rationality assumption.\n\nAn additional feature of our solution concept is that it is computationally tractable. Indeed, they can be computed if all players employ simple no-regret learning algorithms. Guaranteed convergence by decentralized learning dynamics is an appealing feature of our solution concept, and this property holds for (coarse) correlated equilibrium in concave games and for Nash equilibrium in two-player zero-sum bimatrix games."
                    },
                    "title": {
                        "value": "Response to \"Confused about authors' reply to Q1: why not just focus on regret?\""
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8732/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700546010696,
                "cdate": 1700546010696,
                "tmdate": 1700546043904,
                "mdate": 1700546043904,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wUxVvH7DZ9",
            "forum": "li1Z0OQfnA",
            "replyto": "li1Z0OQfnA",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8732/Reviewer_kZP2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8732/Reviewer_kZP2"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new solution concept called $\\phi$-local correlated equilibrium for non-concave games with smooth utilities. The authors show that this concept captures the convergence guarantees of Online Gradient Descent and no-regret learning in such games for two specific initializations of $\\phi$. They also provide a new algorithm for computing local correlated equilibria that is based on a variant of Online Gradient Descent. The paper concludes with experimental results that demonstrate the effectiveness of this algorithm in practice."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "The paper provides important mathematical characterizations for the limit point of multiagent learning algorithms in non-convex game settings and answers important open question posed by Daslakakis et al. [1]"
                },
                "weaknesses": {
                    "value": "This is relatively minor but the organization of the paper in my opinion makes the paper hard to read. A few suggestions:\nAdding a mathematical description of the problem (i.e., games) to the introduction\nMoving some parts of the local correlated equilibrium section on page 2 above the contributions section and tie it in with this mathematical description\nAdding more intuition and background on intractability of approximate local Nash to intro together with a mathematical description"
                },
                "questions": {
                    "value": "Minor comments and questions:\nAren\u2019t part 1) of assumption 1 redundant given part 3? And part 2) redundant given part 1 and compactness of strategy sets?\n\nThe local Nash definition that is studied in the paper considers only *pure* strategies, however, local correlated equilibrium is studied in correlated **mixed** strategies (logically). This begs the questions, can mixed local Nash equilibria be efficiently computed or is that out of reach as well? It seems like that would be out of reach since the randomization would reduce the problem to a multilinear game (albeit infinite dimensional) for which computation of Nash is PPAD. I think a description of this point is important to understand the jump from pure strategies to mixed strategies\n\nDoes Lemma 1 assume Lipschitz smoothness/continuity on the convex regrets or no?\n\nHow does part 2 of Lemma 1 relate to Hazan et al\u2019s [2] results and in general how do the authors\u2019 result relate to your results on projected \\phi regret ?\n\n\nNaive regret bound in section 3.1 seems meaninglessly loose. That is, having an additive Lipschitz continuity constant G suggests that the algorithm might make no progress at all?\n\n\nReg_proj does not have a learning rate in the step it takes this seems to affect the notion that projected and external regret can in general be unrelated? \n\n\nWriting: For large enough \u03b4, Definition 1 captures global Nash equilibrium as well >> For large enough \u03b4, Definition 1 captures global $\\varepsilon$-Nash equilibrium as well\n\n\nI would love to hear answer to my questions above, but otherwise I think the authors have written an interesting and illuminating paper which deserves acceptance.\n\n\n\n\n\n[1] Daskalakis, Constantinos, Stratis Skoulakis, and Manolis Zampetakis. \"The complexity of constrained min-max optimization.\" Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing. 2021.\n\n[2] Hazan, Elad, Karan Singh, and Cyril Zhang. \"Efficient regret minimization in non-convex games.\" International Conference on Machine Learning. PMLR, 2017."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "10: strong accept, should be highlighted at the conference"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8732/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8732/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8732/Reviewer_kZP2"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8732/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699169847114,
            "cdate": 1699169847114,
            "tmdate": 1699637095353,
            "mdate": 1699637095353,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9QvTa2pfrx",
                "forum": "li1Z0OQfnA",
                "replyto": "wUxVvH7DZ9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8732/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8732/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer kZP2-Part 1"
                    },
                    "comment": {
                        "value": "Thank you for your very positive review and constructive comments! We will incorporate your suggestions in the next version of the paper. We address the questions below.\n\n**Q1**: *Aren\u2019t part 1) of assumption 1 redundant given part 3? And part 2) redundant given part 1 and compactness of strategy sets?*\n\n**A**: Thank you for your thoughtful observations regarding the structure of Assumption 1.\n\nRegarding your first point, we agree that Part 1 of Assumption 1 is implied by Part 3. Part 1 should be the definition of differentiable games while smooth games are differentiable games with additional smoothness assumptions. For clarity, we have removed Part 1 and added the definition of differentiable games in the paragraph above. \n\nConcerning Part 2, your insight is correct that it could be inferred from the combination of the former Part 1 and the compactness of strategy sets. Nevertheless, we have chosen to retain this part for explicitness, particularly to specify the Lipschitz constant $G$. This explicit specification is useful for some of our subsequent analyses and results. We have rephrased it in the revised version of the paper to clarify its role.\n\nThese changes, along with the revised introduction of differentiable and smooth games, are highlighted in the updated version of our paper. \n\n**Q2**: *The local Nash definition that is studied in the paper considers only pure strategies, however, local correlated equilibrium is studied in correlated mixed strategies (logically). This begs the questions, can mixed local Nash equilibria be efficiently computed or is that out of reach as well? It seems like that would be out of reach since the randomization would reduce the problem to a multilinear game (albeit infinite dimensional) for which computation of Nash is PPAD. I think a description of this point is important to understand the jump from pure strategies to mixed strategies*\n\n**A**: Thank you for your insightful question on the complexity of mixed local Nash equilibria, which indeed warrants further discussion in our paper.\n\nTo address your question: Computing mixed local Nash equilibria is PPAD-hard for general-sum normal-form games, which are concave games. Since the agents have multi-linear utility functions, every local mixed Nash equilibrium is also a Nash equilibrium. Computing a Nash equilibrium in general-sum normal-form games is known to be PPAD-hard [DGP09, CDT09], so computing a mixed local Nash equilibrium is also PPAD-hard. [DSZ21] indeed considers pure local Nash equilibria, but they show that this is PPAD-hard even in two-player zero-sum games with non-concave utility functions. \n\nWe will expand upon these points in the revised version of our paper, providing a clearer bridge between the concepts of pure and mixed strategies and their respective computational implications. \n\n**Q3**: *Does Lemma 1 assume Lipschitz smoothness/continuity on the convex regrets or no?*\n\n**A**: Thanks for this question.  Lemma 1 holds when there exists an online learning algorithm that has $\\Phi$-regret against convex loss functions. In the context of lemma 1, we do not need other assumptions. $G$-Lipschitzness is required to achieve sublinear regret for specific algorithms like GD / OG, . But Lemma 1 still holds if there exists a no-$\\Phi$-regret algorithm that does not require such assumptions."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8732/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700332116628,
                "cdate": 1700332116628,
                "tmdate": 1700332116628,
                "mdate": 1700332116628,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dYoAFZMxWQ",
                "forum": "li1Z0OQfnA",
                "replyto": "wUxVvH7DZ9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8732/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8732/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer kZP2-Part 2"
                    },
                    "comment": {
                        "value": "**Q4**: *How does part 2 of Lemma 1 relate to Hazan et al\u2019s [2] results and in general how do the authors\u2019 result relate to your results on projected \\phi regret?*\n\n**A**: Firstly, it's important to clarify that Part 2 of Lemma 1 and the results by Hazan et al. [HSZ17] study very different notions of regret (See examples below for an illustration), leading to distinct local equilibrium concepts. As such, they are not directly comparable. Moreover, we've included a detailed discussion in the related works section of Appendix A. The discussion is as follows.\n\n#### The work most closely related to ours is [HSZ17]. The authors propose a notion of *$w$-smoothed local regret* against non-convex losses, and they also define a local equilibrium concept for non-concave games. They use the idea of *smoothing* to average the loss functions in the previous $w$ iterations and design algorithms with optimal $w$-smoothed local regret. The concept of regret they introduce suggests a  local equilibrium concept. However, their local equilibrium concept is very non-standard in that its local stability is not with respect to a distribution over strategy profiles sampled by this equilibrium concept. Moreover, the path to attaining this local equilibrium through decentralized learning dynamics remains unclear. The algorithms provided in [HSZ17] require that every agent $i$ experiences (over several rounds) the average utility function of the previous $w$ iterates, denoted as $F^t_{i,w}:=\\frac{1}{w} \\sum_{\\ell=0}^{w-1} u_i^{t-\\ell}(\\cdot,x_{-i}^{t-\\ell})$. Implementing this imposes a significant coordination burden on the agents. In contrast, we focus on a natural concept of local correlated equilibrium, which is  incomparable  to that of [HSZ17], and we also show that efficient convergence to this concept is achieved via decentralized gradient-based learning dynamics.''\n\nThe following two examples shows that the $w$-smoothed local regret and $\\Phi_{proj}(\\delta)$ (we will refer to it as $\\delta$-projected regret) are incomparable. A sequence of actions may suffer linear $w$-smoothed local regret but constant $\\delta$-projected regret (Example 1), and vise versa (Example 2).  \n**Example 1**:\n1. Loss sequence: $f^t(x) = |x|$ for every $t \\in [T]$ over $X = [-1,1]$.\n2. Action sequence: $x^t = 1/2$ for odd $t$; $x^t = -1/2$ for even $t$\n3. Regret: For any $\\eta < 1/2$ and $w \\ge 1$, the $w$-local regret is at least $\\Omega(T / w)$; For $\\delta > 0$,  the $\\delta$-projected regret of $\\{x^t\\}$ is at most $\\delta$.\n\n**Example 2**: \n1. Loss sequence: $f^t(x) = -x^2$ for every $t \\in [T]$ over $X = [-1,1]$.\n2. Action sequence: $x^t = 0$ for all $t \\in [T]$\n3. Regret: For any $\\eta > 0$ and $w \\ge 1$,  the $w$-local regret is $0$; For any $\\delta < 1$,  the $\\delta$-projected regret of $\\{x^t\\}$ is at least $\\delta^2 T.$\n\n**Q5**: *Naive regret bound in section 3.1 seems meaninglessly loose. That is, having an additive Lipschitz continuity constant G suggests that the algorithm might make no progress at all?*\n\n**A**: The regret bound of naive $\\Phi$ regret minimization is $O(\\delta G\\sqrt{T \\log|\\Phi^\\gamma|} + \\gamma G T)$. By setting $\\gamma = 1/T$ we can get a regret bound that is sublinear in $T$. However, as we mentioned in the paper, this approach leads to a regret bound that depends on $ \\log|\\Phi^\\gamma|$ while the per-iteration complexity depends on $|\\Phi^\\gamma|$, which is prohibitively high.\n\n**Q6**: *Reg_proj does not have a learning rate in the step it takes. This seems to affect the notion that projected and external regret can in general be unrelated?*\n\n**A**: Reg_proj (we will refer to it as projected regret) is parameterized by $\\delta$, which is the largest $\\ell_2$ norm of a possible deviation. As we demonstrated in the paper (example 1 and 2), projected regret is indeed incomparable with external regret in the sense that (1) a sequence of actions could have linear external regret but 0 projected regret; (2) a sequence of actions could have linear projected regret but 0 external regret. Despite the difference, we show that the online gradient descent algorithm achieves sublinear regret bounds for both notions of regret.\n\n[HSZ17]  Hazan, Elad, Karan Singh, and Cyril Zhang. \"Efficient regret minimization in non-convex games.\" ICML, 2017\n\n[DSZ21]  Daskalakis, Constantinos, Stratis Skoulakis, and Manolis Zampetakis. \"The complexity of constrained min-max optimization.\" STOC, 2021\n\n[DGP09]  Daskalakis, Constantinos, Paul W. Goldberg, and Christos H. Papadimitriou. \"The complexity of computing a Nash equilibrium.\" SICOMP, 2009\n\n[CDT09] Chen, Xi, Xiaotie Deng, and Shang-Hua Teng. \"Settling the complexity of computing two-player Nash equilibria.\" JACM, 2009"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8732/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700332624318,
                "cdate": 1700332624318,
                "tmdate": 1700332624318,
                "mdate": 1700332624318,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BhTZvqN06e",
                "forum": "li1Z0OQfnA",
                "replyto": "dYoAFZMxWQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8732/Reviewer_kZP2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8732/Reviewer_kZP2"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you to the authors for their thorough answers! This is very helpful!\n\nI am extremely curious to also hear of a comparison between your local-correlated equilibrium solution concept which is both universal and tractable, and other potential-function based solution concepts (e.g., local minima of the exploitability) which are also universal and tractable. Can you please comment on what would be the advantages vs. disadvantages of computing a local minimum of the exploitability vs. a local correlated equilibrium. See for instance [1] for how a stationary point of the exploitability can be computed in all smooth games.\n\n[1] Goktas, Denizalp, and Amy Greenwald. \"Exploitability minimization in games and beyond.\" Advances in Neural Information Processing Systems 35 (2022): 4857-4873."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8732/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700461176069,
                "cdate": 1700461176069,
                "tmdate": 1700461176069,
                "mdate": 1700461176069,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "34WfDnE1B0",
                "forum": "li1Z0OQfnA",
                "replyto": "UY2YCmM5wM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8732/Reviewer_kZP2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8732/Reviewer_kZP2"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you this is a great summary. I think that the paper triggering such an extensive discussion amongst the AC and reviewers, whether if the contributions of the paper will be impactful or not, suggests that it would allow the community to reflect and have healthy debates on issues of universal solution concepts and tractability. This, in my opinion, is enough of a contribution for publication on its own. I remain positive on the paper."
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8732/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700640109346,
                "cdate": 1700640109346,
                "tmdate": 1700640109346,
                "mdate": 1700640109346,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "6JPlkjpeE2",
            "forum": "li1Z0OQfnA",
            "replyto": "li1Z0OQfnA",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8732/Reviewer_Ge5S"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8732/Reviewer_Ge5S"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the problem of learning equilibria in non-concave (smooth) games. It introduces a new notion of local equilibrium, coined local correlated equilibrium, which is a variation of the correlated equilibrium in which only bounded (local) deviations are allowed. The paper shows that such an equilibrium always exists and it shows that classical no-regret algorithms such as online gradient descent and optimistic gradient efficiently converge to some special cases of such an equilibrium in non-concave (smooth) games."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "I found the problem studied in the paper really interesting. Understanding which equilibria can be learned efficiently in non-concave games is an important step towards applying game-theoretical solution concepts in modern machine learning problems. \n\nThe results presented in the paper are not incredibly complicated from a technical viewpoint, but they nevertheless provide a neat novel analysis of some existing algorithms, shedding the light on what these algorithms actually learn in settings beyond basic games with concave utilities."
                },
                "weaknesses": {
                    "value": "I found that the paper writing is not sufficiently neat in some parts. While all the concepts and results are introduced and adequately explained, there are some issues with terminology and notation, which is not coherent across different sections. For example, in Section 3 the paper talks about differential games, but these have never been introduced in the previous sections (only the definition of smooth game is provided).\n\nMy score reflects the weakness above. I strongly encourage the authors to carefully proof read the paper in order to improve it, and I am willing to increase my score if they do so."
                },
                "questions": {
                    "value": "No questions."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8732/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699268854756,
            "cdate": 1699268854756,
            "tmdate": 1699637095219,
            "mdate": 1699637095219,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "23Zf9vcqJW",
                "forum": "li1Z0OQfnA",
                "replyto": "6JPlkjpeE2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8732/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8732/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Ge5S"
                    },
                    "comment": {
                        "value": "**Comment**: *I found that the paper writing is not sufficiently neat in some parts. While all the concepts and results are introduced and adequately explained, there are some issues with terminology and notation, which is not coherent across different sections. For example, in Section 3 the paper talks about differential games, but these have never been introduced in the previous sections (only the definition of smooth game is provided). My score reflects the weakness above. I strongly encourage the authors to carefully proofread the paper in order to improve it, and I am willing to increase my score if they do so.*\n\n**A**: Thank you for your feedback. We acknowledge the issues you've pointed out regarding our writing, particularly in the use of terminology and notation across different sections. We have conducted a thorough review of the paper for clarity and consistency. Specifically, we revised the introduction of differentiable games and smooth games in Section 2, ensuring a more coherent flow into Section 3. The updated version of the paper, with these changes highlighted, has been uploaded for your review.\n\nWe appreciate your willingness to reconsider your score upon improvements. We are committed to continuing our proofreading efforts to ensure consistency. If you find any further issues or have additional suggestions in the revised version, please do not hesitate to inform us. Your feedback is invaluable in helping us refine our work."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8732/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700331836123,
                "cdate": 1700331836123,
                "tmdate": 1700331836123,
                "mdate": 1700331836123,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]