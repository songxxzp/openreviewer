[
    {
        "title": "Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets"
    },
    {
        "review": {
            "id": "shRPd8uu46",
            "forum": "Zc2aIcucwc",
            "replyto": "Zc2aIcucwc",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8594/Reviewer_43gK"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8594/Reviewer_43gK"
            ],
            "content": {
                "summary": {
                    "value": "This manusript proposed a curated dataset containing three subsets with different sizes. The whole datasets contains approximately 100 million molecules with more than 13 billion labels combining graph-level and node-level ones. Each molecules is accompanied with quantum mechancial properties calculated using either DFT or semi-emperical methods. A Python library called Graphium is built to facilitate the access and utilization of the proposed dataset for machine learning applications. Some tools such as handling missing data and label normalization in Graphium are designed to reduce the friction for users. Lastly, the authors provides benchmark results on the proposed dataset using common GNN models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed dataset is large and inclusive. In each one of the subset (ToyMix, LargeMix, and UltraLarge), at least one of the dataset contains 3D conformer of molecules and QM properties. As the 3D GNN models (e.g. Equivariant GNNs) are becoming increasingly important in the molecular machine learning community, 3D molecular conformer and corresponding labels are valuable.\n\n2. The Graphium library can be handy for researchers who wants to join the molecular machine learning community but are halted by lack of experience with data processing and model training. With all datasets curated in this work included in the Graphium library, users can easily focus on innovating model architectures. \n\n3. Many node-level labels are included in this dataset. Most conventional tasks in molecular machine learning are graph-level tasks such as molecular property prediction because of the scarcity of node-level labels."
                },
                "weaknesses": {
                    "value": "1. One minor weakness is that the potential noise in the bioassay data. For the PCBA1328 dataset of LargeMix, the authors curated the data from PubChem by collecting molecules and their properties with regard to different bioassays. Due to the inherent noise associated with the data generation process with bioassay, model training (especially multitask training) can be difficult."
                },
                "questions": {
                    "value": "1. For the PM6_83M, the authors mention that the QM properties of molecules are calculated using semi-empirical methods as reported in the original paper of PM6 paper. However, in secion D.4, the authors state that \"Using the 3D conformation optimized by the DFT, we further computed the following 3D descriptors as labels\". Can the authors confirm if they run DFT on top of the PM6 dataset or not? If they do run DFT, can they briefly discuss the DFT method they use here?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8594/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698624804369,
            "cdate": 1698624804369,
            "tmdate": 1699637075302,
            "mdate": 1699637075302,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LoBlX3jokw",
                "forum": "Zc2aIcucwc",
                "replyto": "shRPd8uu46",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8594/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8594/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the review"
                    },
                    "comment": {
                        "value": "We are happy to see that the Reviewer found the datasets and library useful, and allow users to \"easily focus on innovating model architectures\". Below, we hope to answer the concerns and questions.\n\n\n### W1. Noise in PCBA1328\n>One minor weakness is that the potential noise in the bioassay data. For the PCBA1328 dataset of LargeMix, the authors curated the data from PubChem by collecting molecules and their properties with regard to different bioassays. Due to the inherent noise associated with the data generation process with bioassay, model training (especially multitask training) can be difficult.\n\n**Answer**\n\nWe thank the reviewer for pointing out this issue. Indeed, due to the nature of the data, there will be a base level of noise in the bioassay data. In this work, we curate the bioassays from existing data and utilize the reported flags from original authors. To denoise the data, the active and inactive labels from the original data are treated as 1 and 0 respectively while everything else is considered as NaN thus ignored rather than relying on the specific measured values which are more subject to experimental noise. Lastly, performing classification tasks on bioassay data helps reduce the noise by simplifying the labels to be binary though some effect of mislabeling might still be present. \n\n\n### Q1. DFT or semi-empirical minimization\n>For the PM6_83M, the authors mention that the QM properties of molecules are calculated using semi-empirical methods as reported in the original paper of PM6 paper. However, in section D.4, the authors state that \"Using the 3D conformation optimized by the DFT, we further computed the following 3D descriptors as labels\". Can the authors confirm if they run DFT on top of the PM6 dataset or not? If they do run DFT, can they briefly discuss the DFT method they use here?\n\n**Answer**\n\nWe thank you for reporting this error, we will correct it. The PCQM4M dataset has conformations minimized by DFT methods, with the labels also being computed using the same DFT. However, the PM6_83M dataset minimizes the conformations with semi-empirical PM6 method, and uses the same semi-empirical method to compute the labels."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700627667090,
                "cdate": 1700627667090,
                "tmdate": 1700627667090,
                "mdate": 1700627667090,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "V4tGKbjMFD",
                "forum": "Zc2aIcucwc",
                "replyto": "LoBlX3jokw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8594/Reviewer_43gK"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8594/Reviewer_43gK"
                ],
                "content": {
                    "title": {
                        "value": "Response to revision"
                    },
                    "comment": {
                        "value": "Thank you for your effort in clearing my concerns. My rating will remain as accept for this manuscript."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700680501382,
                "cdate": 1700680501382,
                "tmdate": 1700680501382,
                "mdate": 1700680501382,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Hzy2uRPXHN",
            "forum": "Zc2aIcucwc",
            "replyto": "Zc2aIcucwc",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8594/Reviewer_BQyU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8594/Reviewer_BQyU"
            ],
            "content": {
                "summary": {
                    "value": "The authors have developed an extensive data repository and designed a graph learning library, \u201cgraphium\u201d that supports the training of foundational models for molecular modeling. Authors have combined molecular datasets from various sources with labels for tasks targeting graph and node-level properties. The evaluation shows that training graph-based models on large amounts of quantum mechanical data improves the downstream performance of the model in resource-starved contexts, for example, modeling biological molecules."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "+ The paper provides an extensive description of all the datasets that have been used and how they relate to each other in terms of what tasks they model and the labels provided. Particularly, the paper provides an in-depth explanation of (in the supplementary resources) how chemical and structural properties might relate to biological function, which can explain how properties learned in a quantum mechanical setting might help in a biological context. \n\n+ Authors have made their work publicly available, including the datasets and the graph learning library, and providing multi-level, multi-label, and multi-task learning mechanisms. This form of modeling, as shown, is crucial in developing foundational models that generalize well to tasks with limited amounts of data available.  \n\n+ The authors discuss the positional encodings and distill the literature on relative and global positioning into their \u201cgraphium\u201d data modeling pipeline."
                },
                "weaknesses": {
                    "value": "+ The work is an important contribution to the ML and molecular learning communities. However, it restricts itself to data curation and performance results for different GNN-based models. The paper is missing crucial insights that might help inform the researchers interested in developing foundational models. For example, does the new dataset help improve other existing methods? Why the multi-task setting does not work well for all the datasets, and what are the data properties resulting in different performances for different datasets? How does this work translate into applications for the real-world setting? \n\n+ The paper does not show a comparison against any other existing pre-trained molecular models. Moreover, it would also be helpful to highlight the performance against supervised SOTAs.\n\n+ Although the paper mentions transformer-based models, such as Graphormer or GPS [1,2], in the supplementary section, it does not provide any results for them in the evaluation section. Showing results for them may be an essential consideration because they would show potentially better scaling to data than standard message passing, which tends to suffer from the problem of over-smoothing when the number of layers goes beyond three. Although the paper mentions this limitation and plans to do the comparison in the future, it's crucial to define how transformer-style models scale with the data that has been curated. \n\n+ Continuing on the previous point, it would be nice to see a scaling curve that shows how increasing model complexity improves performance as we provide more data to it.\n\n\nReferences:\n[1] Benchmarking Graphormer on Large-Scale Molecular Modeling Datasets arXiv:2203.04810\n[2] Recipe for a General, Powerful, Scalable Graph Transformer arXiv:2205.12454"
                },
                "questions": {
                    "value": "+ Authors mention that due to resource constraints, they only use a small fraction of the data to train the ULTRALARGE models; can they discuss how would the results change if the entire dataset is used? As mentioned by the authors, there is a skew towards the QM tasks. \nWould the model overfit those tasks when trained with larger datasets and show degradation in performance for biological tasks? \n\n+ It's unclear if the paper shows that the model can generalize to unseen tasks in the downstream setting. \n\n+ Minor point: I am curious to see how the newer equivariant GNNs [3, 4] (specifically in the molecular modeling space) interact with having more data available to them.\n\n\nReferences\n\n[3] E(3)-Equivariant Graph Neural Networks for Data-Efficient and Accurate Interatomic Potentials https://arxiv.org/pdf/2101.03164.pdf\n[4] Equivariant Graph Attention Networks for Molecular Property Prediction https://arxiv.org/pdf/2202.09891.pdf"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8594/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8594/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8594/Reviewer_BQyU"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8594/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698785584651,
            "cdate": 1698785584651,
            "tmdate": 1700681234950,
            "mdate": 1700681234950,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5p5bDup21M",
                "forum": "Zc2aIcucwc",
                "replyto": "Hzy2uRPXHN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8594/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8594/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your thourough review"
                    },
                    "comment": {
                        "value": "### W1. Better understanding of how and why\n>The work ... restricts itself to data curation and performance results for different GNN-based models. The paper is missing crucial insights ... For example, does the new dataset help improve other existing methods? Why the multi-task setting does not work well for all the datasets, and what are the data properties resulting in different performances for different datasets? How does this work translate into applications for the real-world setting?\n\n**Answer**\n\nWe thank you for these very important points. First, we want to reiterate that as part of the contributions of this work we do not just provide the curated datasets, but also Graphium, a library to enable large-scale training for molecules with various hardware. The Graphium library supports many SOTA models and positional encodings, mup for zero-shot scaling, and TDC for fine-tuning. The library being very modular, it allows to easily swap architectures, datasets, positional encodings, metrics, and benchmarks specifically to help study the very questions you are proposing. \n\nHowever, most of these questions are left for future work, as our paper proposes the first step to bring us there.\n\n**Why multi-task does not always work well**\n\nRegarding the question on why multi-task doesn\u2019t work well on all datasets, we believe the main cause is underfitting, as a 10M parameter model is used to train on >3000 tasks jointly. This is supported by the reported results below, on single task, the test set is between 11% and 30% **worse** than train, but on multi-task, the test set is between 5% and 9% **better**. Again, looking at the scaling results, we can see that the performance on the PCBA_1328 goes up very significantly despite the multi-tasking.\n\nThese points were clarified in the paper to better explain the disparity between the single-task and multi-task for PCBA_1328.\n\n|  | Train BCE Single task | Train BCE Multi-Task | Test BCE Single task | Test BCE Multi-Task |\n|--|--|--|--|--|\n| GCN | 0.0284 \u00b1 0.0010 | 0.0382 \u00b1 0.0005 | 0.0316 \u00b1 0.0000 | 0.0349 \u00b1 0.0002 |\n| GIN | 0.0249 \u00b1 0.0017 | 0.0359 \u00b1 0.0011 | 0.0324 \u00b1 0.0000 | 0.0342 \u00b1 0.0001 |\n| GINE | 0.0258 \u00b1 0.0017 | 0.0361 \u00b1 0.0008 | 0.0320 \u00b1 0.0001 | 0.0341 \u00b1 0.0001 |\n\n \n### W2. Comparison to existing pre-trained models\n>The paper does not show a comparison against any other existing pre-trained molecular models. Moreover, it would also be helpful to highlight the performance against supervised SOTAs.\n\n**Answer**\n\nThis is an important suggestion, but the aim of our current work is not to provide pre-trained models, but rather the datasets and library required to build foundational GNNs and benchmark them on TDC. Hence, our current baselines are not meant to be used for fine-tuning, and cannot be compared directly to self-supervised models.\n\n\n### W3. Scaling Transformer models\n>Although the paper mentions transformer-based models, such as Graphormer or GPS [1,2], in the supplementary section, it does not provide any results for them in the evaluation section. ...\n\n**Answer**\n\nReferring to the general comment, we have shown some great scaling trends of up to 1B parameters with continuously improving results using MPNN++, the backbone behind the GPS++ winner of the OGB-LSC competition. We also aim to provide some baseline Transformers at the 10M parameter scale. However, in-depth comparison of the scaling laws of MPNN vs Transformer vs Hybrid is left for future work.\n\nFurther, there are multiple literature showing that positional and structural encodings are more important than the GNN models itself, such as GPS[1], GPSE[2], LSPE[3], etc., and all models tested in the baseline use eigenvectors and random-walk encodings that are again behind the OGB-LSC competition win.\n\n[1] Ramp\u00e1\u0161ek, Ladislav, et al. \"Recipe for a general, powerful, scalable graph transformer.\" Advances in Neural Information Processing Systems 35 (2022): 14501-14515.\n\n[2] Liu, Renming, et al. \"Graph Positional and Structural Encoder.\" arXiv preprint arXiv:2307.07107 (2023).\n\n[3] Dwivedi, Vijay Prakash, et al. \"Graph neural networks with learnable structural and positional representations.\" arXiv preprint arXiv:2110.07875 (2021).\n\n### W4. Model scaling laws\n> ... it would be nice to see a scaling curve that shows how increasing model complexity improves performance as we provide more data to it.\n\n**Answer**\n\nWe thank you for this suggestion, but we leave scaling laws analysis for the data for future work. In the general comment, we provided scaling laws for the model sizes."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700627321993,
                "cdate": 1700627321993,
                "tmdate": 1700664161519,
                "mdate": 1700664161519,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6wm1njaKxm",
                "forum": "Zc2aIcucwc",
                "replyto": "nD0usIj8WP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8594/Reviewer_BQyU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8594/Reviewer_BQyU"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the response"
                    },
                    "comment": {
                        "value": "Thank you to the authors for the detailed responses to all my comments. While I still think that presenting some key insights from this work to the user community is important, I also agree that the contribution of this work is relevant. Therefore, I will raise my score to a \"weak accept\""
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700681204795,
                "cdate": 1700681204795,
                "tmdate": 1700681204795,
                "mdate": 1700681204795,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "urQMwpeHS3",
            "forum": "Zc2aIcucwc",
            "replyto": "Zc2aIcucwc",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8594/Reviewer_qFVJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8594/Reviewer_qFVJ"
            ],
            "content": {
                "summary": {
                    "value": "Having access to a free and open database of chemical compounds with their quantum features and biological activities. The main issue with the existing ones is the shortage of enormous data over various tasks, with many of them lacking experimental measures, or quantum and chemical properties. One know fact is that a little change in these properties can cause a major bioactivity behavior change. To end this, authors has collected a multiple number of datasets over molecules that will be a great help to build foundation models on this literature, e.g., models that are trained over multi-task and multi-level molecular datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1. The contribution of this paper has been successfully delivered to the general audience. It will open doors to having more robust and representative models with the help of pre-training. \n2. Advantages over non supervised methods for pre-training the model, such as contrastive learning, is important because of the \"activity cliffs\" phenomenon. \n3. Many intricacies are considered into this, such as having both quantum and bioactivity features which are important for the future research. \n4. Graphium library provides a reliable and tidy tool that gives a better pace to doing research."
                },
                "weaknesses": {
                    "value": "1. It's not clear what are exact labels collected for each sample and how they can be useful."
                },
                "questions": {
                    "value": "1. Please provides more samples of each dataset category for the sake of better illustration."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8594/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698875644467,
            "cdate": 1698875644467,
            "tmdate": 1699637075088,
            "mdate": 1699637075088,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GMJseiaMWZ",
                "forum": "Zc2aIcucwc",
                "replyto": "urQMwpeHS3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8594/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8594/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the feedback!"
                    },
                    "comment": {
                        "value": "We thank you for your feedback, for highlighting the importance of supervised learning for activity cliffs, of the combined quantum/bio tasks, and for finding the Graphium library \"reliable and tidy\".\n\nBelow, we hope to answer your remaining concerns.\n\n### W1. Labels description\n> It's not clear what are exact labels collected for each sample and how they can be useful.\n\n**Answer**\n\nDescription of the labels are in `Appendix D DEEPER DIVE INTO THE LARGEMIX AND ULTRALARGE DATASETS`. For the PCBA_1328, it is impossible to provide a description of all 1328 labels, but the pubchem assay ID is still available in the column header of the CSV file so they are all traceable.\n\nIf you have any specific questions on any specific dataset or label that Appendix D does not answer, please let us know.\n\nQ1. More illustrations\n>Please provides more samples of each dataset category for the sake of better illustration.\n\n**Answer**\n\nIn Figure 2 of Appendix C, we provide 6 molecules per dataset. But to answer your request, we will re-do the figure to provide 24 molecules per dataset and span it across 2 pages."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700626696880,
                "cdate": 1700626696880,
                "tmdate": 1700626696880,
                "mdate": 1700626696880,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "DdjcChUWWu",
            "forum": "Zc2aIcucwc",
            "replyto": "Zc2aIcucwc",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8594/Reviewer_jQ36"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8594/Reviewer_jQ36"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents seven novel datasets that push the boundaries in both the scale and diversity of supervised labels for molecular learning. The authors also introduce the Graphium graph machine learning library to simplify the process of building and training molecular machine learning models. The paper argues that building effective foundational models for molecular modeling requires supervised training with both quantum mechanical (QM) descriptions and biological environment-dependent data. Overall, this paper aims to explore the possibilities of foundational models in molecular machine learning."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper presents seven novel datasets that are orders of magnitude larger than the current state of the art, covering nearly 100 million molecules and over 3000 sparsely defined tasks, totaling more than 13 billion individual labels, currently the largest of their kind.\n\n- The datasets are designed for the supervised training of foundation models by combining labels representing quantum and biological properties acquired through both simulation and wet lab experimentation. The diversity of labels facilitates efficient transfer learning and enables the construction of foundational models by improving their generalization ability for a wide range of downstream molecular modeling tasks.\n\n- The paper introduces the Graphium graph machine learning library to facilitate efficient training on these extensive datasets. This library simplifies the process of building and training molecular machine learning models.\n\n- The paper provides an anonymized repo for reproducibility commitment."
                },
                "weaknesses": {
                    "value": "- The evaluated baselines are too simple/out-of-date in some sense. Since this paper is providing a data-driven platform for accelerating the research of molecular foundation models, it would be better to have included more SOTA baselines for comparison, which can help analyze the usefulness and effectiveness of this database better.\n\n- It would be better to have a well-organized website with readable documents that can help understand the details and setups of different datasets/components better.\n\n- More data splitting settings (e.g. mofit-based, system-based, scaffold-based, etc.) should be further studied. Now the OOD generalizability of GNNs across different molecule datasets still seem to be unclear."
                },
                "questions": {
                    "value": "- I would be curious about how the models trained on larger datasets perform on smaller datasets (using the same task or different tasks). Also the performance of applying a well-trained model on a small dataset to larger datasets would be interesting to study to understand the few-shot learning ability of those models over these datasets."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8594/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699133130094,
            "cdate": 1699133130094,
            "tmdate": 1699637074981,
            "mdate": 1699637074981,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YZNgIZ8FKI",
                "forum": "Zc2aIcucwc",
                "replyto": "DdjcChUWWu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8594/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8594/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the review"
                    },
                    "comment": {
                        "value": "We would like to thank Reviewer jQ36 for their thorough review, and for highlighting the strengths related to dataset sizs and library building. We hope to answer their questions and concerns below.\n\n### W1. More SOTA baselines\n>The evaluated baselines are too simple/out-of-date in some sense. Since this paper is providing a data-driven platform for accelerating the research of molecular foundation models, it would be better to have included more SOTA baselines for comparison, which can help analyze the usefulness and effectiveness of this database better.\n\n**Answer**\n\nWe would like to point the reviewer to the general comment. We have added a baseline for MPNN++ (the backbone of the GPS++ and winner of the OBG-LSC competition), and aim to provide results for graph Transformer. Further, there are multiple literature showing that positional and structural encodings are more important than the GNN models itself, such as GPS[1], GPSE[2], LSPE[3], etc., and all models tested in the baseline use eigenvectors and random-walk encodings that are again behind the OGB-LSC competition win.\n\n[1] Ramp\u00e1\u0161ek, Ladislav, et al. \"Recipe for a general, powerful, scalable graph transformer.\" Advances in Neural Information Processing Systems 35 (2022): 14501-14515.\n\n[2] Liu, Renming, et al. \"Graph Positional and Structural Encoder.\" arXiv preprint arXiv:2307.07107 (2023).\n\n[3] Dwivedi, Vijay Prakash, et al. \"Graph neural networks with learnable structural and positional representations.\" arXiv preprint arXiv:2110.07875 (2021).\n\n\n### W2. Well-organized website\n>It would be better to have a well-organized website with readable documents that can help understand the details and setups of different datasets/components better.\n\n**Answer**\nWe thank the reviewer for this proposition, and would like to mention that we do have a website! The website contains different tabs (Overview, Baseline, API, Tutorials, Design, Datasets, Pretrained Models, CLI, Contribute, License).\n\nFor anonymity reasons, we cannot share the website but invite you to build it locally:\n\n- Install mkdocs package `pip install mkdocs`\n- Go to the main graphium directory\n- Run it on a local server `mkdocs serve`\n- CTRL+Click on the link given after the compilation\n\n\n### W3. More data splitting settings\n>More data splitting settings (e.g. mofit-based, system-based, scaffold-based, etc.) should be further studied. Now the OOD generalizability of GNNs across different molecule datasets still seem to be unclear.\n\n**Answer**\n\nWe thank the reviewer for this proposition, but would like to reiterate that the objective of the dataset is to pre-train a large model, not to test the OOD. However, we do support direct finetuning on TDC to test the generalizability of the model, but this is left for future work. A tutorial on how to finetune on TDC is available in the file graphium/notebooks/finetuning-on-tdc-admet-benchmark.ipynb. \n\n### Q1. Scaling data and few-shot learning\n>I would be curious about how the models trained on larger datasets perform on smaller datasets (using the same task or different tasks). Also the performance of applying a well-trained model on a small dataset to larger datasets would be interesting to study to understand the few-shot learning ability of those models over these datasets.\n\n**Answer**\n\nWe agree with the reviewer here, but leave this question for future work. \n\nAt the moment, we provide the datasets, the library with support for zero-shot scaling thanks to mup, show some very interesting scaling trends in the general comment, and provide support for downstream fine-tuning on TDC."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700626403148,
                "cdate": 1700626403148,
                "tmdate": 1700626453834,
                "mdate": 1700626453834,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vNfOxPuCr3",
                "forum": "Zc2aIcucwc",
                "replyto": "YZNgIZ8FKI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8594/Reviewer_jQ36"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8594/Reviewer_jQ36"
                ],
                "content": {
                    "title": {
                        "value": "Thanks"
                    },
                    "comment": {
                        "value": "Thank you for addressing my concerns. I'll keep my rating as it is."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700682098979,
                "cdate": 1700682098979,
                "tmdate": 1700682098979,
                "mdate": 1700682098979,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LjHoqbxCuk",
            "forum": "Zc2aIcucwc",
            "replyto": "Zc2aIcucwc",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8594/Reviewer_Zdj5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8594/Reviewer_Zdj5"
            ],
            "content": {
                "summary": {
                    "value": "This paper present seven novel datasets with different sizes, to facilitate the application and development of molecular foundation model. Multiple baselines are conducted and some experimental results and analysis are provided on several downstream tasks. Furthermore, Graphium graph machine learning library is proposed to offer more convenient implementations of multi-task and multi-level machine learning methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This paper compiles a comprehensive benchmark for the evaluation of molecular models. The dataset covers a large variety of molecules and labels at different levels, with particularly comprehensive and complete data for quantum-related tasks.\n2. The Graphium library appears promising as a convenient tool for researchers or developers to perform fine-tuning on various tasks using different backbones."
                },
                "weaknesses": {
                    "value": "1. The diversity of this benchmark remains a problem. For example, most of the contribution comes from the quantum related property data, which cover a limited part in molecular property prediction.\n2. The paper just collected existing data instead of creating new data, which limits the significance.\n3. Baselines and discussions are not thorough, leading to unconvincing results.\n4. Some empirical settings are not clear or strict, making the comparison or benchmark not solid."
                },
                "questions": {
                    "value": "1. Although the molecular numbers reach the million scale, it appears that the majority of the contribution comes from quantum data. The tasks lack diversity, and there is an imbalance among the three scales of data (toymix, largemix, ultralarge). For instance, the largest ultralarge dataset solely comprises quantum tasks. It would be more comprehensive if it included more biological tasks, such as ADMET properties.\n2. Seems that this paper did not create any new data, instead, they only collected some existing data to organize to different levels or merge different datasets, right? In this case, the novelty and contribution is limited. \n3. From Table 1, we observe that training on multitasks aids in improving the performance of ZINC12k and Tox21, but it doesn't yield the same benefit for Quantum tasks (QM9). What could be the reason behind this phenomenon?\n4. If adding the Quantum tasks enhances the performance of biological tasks, why does the multitask performance for the PCBA_1328 dataset in the largemix dataset at Table 2 not surpass that of the single task setting? The data size may not be the final answer and further analysis may be necessary.\n5. The baselines are too simplistic, as they only include three different types of GCNs. More models involving various types of self-supervised methods, which are essential for a foundation model, should be included in the experiments as baselines for discussion.\n6. If this dataset is aimed at the foundation model, it could potentially achieve the best performance on various tasks(both quantum and bio-related tasks) across different scales. However, this paper only tests various networks on data of different scales dataset, and it lacks related experiments or discussions.\n7. More sophisticated split functions beyond random, such as scaffold, can be explored, as the out-of-distribution (OOD) problem is common in large models and requires careful study."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8594/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699195596883,
            "cdate": 1699195596883,
            "tmdate": 1699637074879,
            "mdate": 1699637074879,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jb0Tbic3pN",
                "forum": "Zc2aIcucwc",
                "replyto": "LjHoqbxCuk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8594/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8594/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to clarify that the goal of this paper is to construct the largest public collection of molecular data, as well as an optimized library consisting of SOTA GNNs, for building foundational models for molecular learning (as stated in the abstract). \n\nFrom reviewer\u2019s Zdj5 response, we believe that they perceived our work as a paper focusing on benchmarking different GNN architecture for molecular learning, which is not the case, hence there is a disagreement between the review and the work\u2019s intention, which we hope to clarify better in our response.\n### W1. Benchmark Diversity\n>The diversity of this benchmark remains a problem. For example, most of the contribution comes from the quantum related property data, which cover a limited part in molecular property prediction.\n\n**Answer**\n\nWe respectfully disagree with the reviewer. We believe our **curated** datasets are highly diverse in the non-quantum tasks as well. For instance, the PCBA_1328 dataset combines 1328 assays covering a vast task space and the L1000 data combines 998 gene perturbations across 2 cell lines. Hence, there\u2019s a total of 3324 bio-assays in the LargeMix dataset, which we curated ourselves into ML ready format fitting for GNNs.  To the best of our knowledge, these alone are more diverse than any public 2D molecular learning datasets in the literature.\n\nIt is also worth noting that due to the time intensive nature of results derived from experimental, rather than computational sources, such datasets are significantly smaller than their computational counterparts. While the reviewer is absolutely correct that if more experimental / biological data were available it would be preferable, we argue that the combination of large quantum datasets augmented with a smaller portion of high quality experimental data allows a model to learn suitably general embeddings, and believe the results presented show this. \n\n### W2. Only Collects Existing Data\n>The paper just collected existing data instead of creating new data, which limits the significance.\n\n**Answer**\n\nFirst, we note that the datasets are only one of the contributions, as we also propose an open-source *Graphium* library that contains the SOTA graph network models for molecules and positional/structural encodings.\n\nSecond, in the field of molecular learning, collecting novel data, especially for non-quantum tasks is extremely expensive and often involves costly real-world experiments. In addition, available data is often not in a ML ready format and requires extensive data processing with domain experts to prepare them for training in graph neural networks. In this work, we curated 3 datasets for the LargeMix and 1 dataset for the Ultra-large, with labeled features as a starting point for building foundational models on molecules. The datasets cover nearly 100 million molecules and over 3000 sparsely defined tasks totaling more than 13 billion individual labels. There is significant value in the curation of these data in simple tabular formats. \n\n### W3. Not Enough Baselines\n>Baselines and discussions are not thorough, leading to unconvincing results.\n\n**Answer**\n\nThe focus of this work is to construct the largest public collection of molecular data and the Graphium library which supports graph ML on the proposed dataset. Our objective is not for building a benchmark to compare many GNN architectures.\nThe baselines provided are intended to demonstrate both the soundness of the datasets and multi-task learning in a machine learning context, and provide a reference point for other researchers developing new models for expected performance of simple and reproducible models. \n\nAlthough more thorough experiments are left for future work both internally and to the community, we aim to add results for the Graph Transformers. We further added some scaling law results using the MPNN++ architecture, the backbone of the GPS++ model that won the OGB-LSC competition, and we observed an impressive scaling trend up to 1B parameters.\n\n### W4. Setting not clear\n>Some empirical settings are not clear or strict, making the comparison or benchmark not solid.\n\n**Answer**\n\nWe provide details on our experimental settings for TOYMIX, LARGEMIX and ULTRALARGE in detail in Section 4.1, 4.2 and 4.3 respectively. Appendix E also provides details on the graphium library for multi-level, multi-task and multi-label learning, the modeling and more. We would be glad to further clarify any specific concerns for the reviewer."
                    },
                    "title": {
                        "value": "We hope to address the weaknesses"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700624680261,
                "cdate": 1700624680261,
                "tmdate": 1700627428532,
                "mdate": 1700627428532,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "URwMkmAaEi",
                "forum": "Zc2aIcucwc",
                "replyto": "LjHoqbxCuk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8594/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8594/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the questions"
                    },
                    "comment": {
                        "value": "### Q1. Lack of biological task\n> ... It would be more comprehensive if it included more biological tasks, such as ADMET properties.\n\n**Answer**\n\nWe want to point out that our contributed datasets contain a total over 3000 tasks thus are highly diverse in nature. When examining the balance between biological tasks and quantum tasks, one must first consider the data availability. Note that ADMET properties are generally only found in very small amounts as it requires lab experiments. The well-known TDC benchmark[1] contains a number of ADMET properties however each property only has 500-6000 molecules and are notorious for their curation issues, see [\u201cGetting Real with Molecular Property Prediction](https://tinyurl.com/mr2mvavt) and [\u201cWe Need Better Benchmarks for ML in DD\u201d](https://tinyurl.com/cdhht757).\n\nTherefore, we omitted the ADMET at the moment due to the issues with dataset curation and sizes. We also reiterate that we are proposing datasets for pre-training at a large scale, not a task-specific benchmark.\n\n[1] Huang, Kexin, et al. \"Therapeutics Data Commons: Machine Learning Datasets and Tasks for Drug Discovery and Development.\" 2021.\n\n### Q2. did not create any new data\n\n> Seems that this paper did not create any new data, instead, they only collected some existing data...\n\n**Answer**\n\nWe refer the reviewer to the detailed response we provided for W2. \n\n### Q3. explanation\n>... multitasks aids in improving the performance of ZINC12k and Tox21, but it doesn't yield the same benefit for Quantum tasks (QM9)...\n\n**Answer**\n\nWe thank the reviewer for raising this point. First, note that performance benefits on the ZINC12k and Tox21 are **more interesting** than QM9. This is because, in practice, biological tasks have significantly less training data than quantum tasks, and the goal of building a foundational model with a 2D GNN is to improve the performance of low-data biological tasks through the joint pre-training with quantum tasks which we observe in this case. \n\nSecond, the models use the same amount of parameters to train on both multitask and the sole QM9 task thus the parameters are shared across other tasks for the multitask model. Third, QM9 originally has a much higher volume of data, so it benefits less from the other tasks.\n\n### Q4. explanation\n>... performance for the PCBA_1328 dataset in the largemix dataset at Table 2 not surpass that of the single task setting? ...\n\n**Answer**\n\nWe thank the reviewer for this observation and will clarify it in the paper. We believe the main cause is underfitting, as a 10M parameter model is used to train on >3000 tasks jointly. Thus, we argue that longer training (capped at 100 epochs) and more parameters (capped at 10M) will benefit the multi-task model more.\n\nThis hypothesis is supported by the reported results below, on single task, the test set is between 11% and 30% **worse** than train, but on multi-task, the test set is between 5% and 9% **better**. Again, looking at the scaling results, we can see that the performance on the PCBA_1328 goes up very significantly despite the multi-tasking.\n\n|  | Train BCE Single task | Train BCE Multi-Task | Test BCE Single task | Test BCE Multi-Task |\n|--|--|--|--|--|\n| GCN  | .0284 \u00b1 0.0010  | .0382 \u00b1 0.0005 | .0316 \u00b1 0.0000 | .0349 \u00b1 0.0002 |\n| GIN  | .0249 \u00b1 0.0017  | .0359 \u00b1 0.0011 | .0324 \u00b1 0.0000 | .0342 \u00b1 0.0001 |\n| GINE | .0258 \u00b1 0.0017 | .0361 \u00b1 0.0008 | .0320 \u00b1 0.0001 | .0341 \u00b1 0.0001 |\n\n### Q5. More Baseline\n>The baselines ... only include three different types of GCNs...\n\n**Answer**\nWe would like to refer the reviewer to the general comment, where we added baselines for MPNN++, the backbone model behind the OGB-LSC challenge winner, and scaling laws. \nAnd additionally clarify for the reviewer that the aim is to provide baselines for the datasets, not to optimize performance on this new dataset collection.  .\n\n\n### Q6. Performance of foundation model\n>If this dataset is aimed at the foundation model, it could potentially achieve the best performance on various tasks...\n\n**Answer**\n\nWe refer the reviewer to the general comment, where we provided scaling laws showcasing significant improvements up to 1B parameters.\n\n\n### Q7. more splits\n>More sophisticated split functions beyond random, such as scaffold, can be explored...\n\n**Answer**\n\nWe would like to reiterate that we are not proposing a benchmark paper, but rather datasets to pre-train a model, and pre-training is known to work better with random split as it allows the model to better see the desired chemical space. However, the Graphium library does include an easy access to the TDC API where OOD generalization can be tested using the various splits proposed. A tutorial on how to finetune on TDC is available in the file graphium/notebooks/finetuning-on-tdc-admet-benchmark.ipynb."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700626071141,
                "cdate": 1700626071141,
                "tmdate": 1700627652399,
                "mdate": 1700627652399,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0Oj8wVIqAB",
                "forum": "Zc2aIcucwc",
                "replyto": "jb0Tbic3pN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8594/Reviewer_Zdj5"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8594/Reviewer_Zdj5"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response. \nTo be clear, my question about unclear empirical setting is that, we are not sure whether for each task, all the baselines employ the same setting, e.g. data split strategy or scaffold spit strategy, which are usually crucial factors to produce different results."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8594/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700661688679,
                "cdate": 1700661688679,
                "tmdate": 1700661688679,
                "mdate": 1700661688679,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]