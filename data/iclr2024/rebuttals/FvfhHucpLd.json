[
    {
        "title": "DIVERSITY OF THOUGHT IMPROVES REASONING ABILITIES OF LARGE LANGUAGE MODELS"
    },
    {
        "review": {
            "id": "0EDzDCDU0W",
            "forum": "FvfhHucpLd",
            "replyto": "FvfhHucpLd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6540/Reviewer_YP6t"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6540/Reviewer_YP6t"
            ],
            "content": {
                "summary": {
                    "value": "- The authors propose a prompting method to increase the diversity of thoughts. The authors propose a two step solution to generate diverse prompts. First, ask an LLM to generate personas and approaches to solve a task. Next, (in the DIV-SE case), provide few-shot examples using the different approaches in the prompt, and have the LLM generate answers, over which we take a majority vote.\n- The authors show a number of cost/accuracy trade off plots for AQUA-RAT, Blocksworld, GSM8K and Commonsense Reasoning. The authors also show results of using various ensemble sizes for DIV-SE.\n- The authors examine error propagation in the case of IDIV-SE, and other aggregation strategies beyond a simple majority vote."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Paper is well written and the method is clear."
                },
                "weaknesses": {
                    "value": "- The novelty of the work is very limited. There exists work in which diverse prompts are used to generate diverse reasoning paths: [This paper ](https://arxiv.org/pdf/2206.02336.pdf) should be cited due to its similarity.\n- It is not completely clear why DIV-SE works well on Blockworlds and AQUA-RAT, but less so on GSM8K and Commonsense QA.\n- IDIV is likely to have significant context length constraints.\n- It\u2019s not clear whether adding a persona increases the diversity of output. I suspect the persona does not add much to the method. This requires an ablation.\n- The labels on each of the Figures could be clearer. The color codes are missing.\n\n\nIn conclusion, while the proposed method by the authors is clear, it appears the novelty of this work is severely limited (see above). Furthermore, IDIV seems to have a significant context length constraint, and the experiments do not show very convincing improvement across the board. Therefore I cannot recomment acceptance of this paper to ICLR."
                },
                "questions": {
                    "value": "- Why are the results for Blockworld 3 in Figure 1 different from the one in Figure 3? Why is the inference cost much lower for DIV-SE-3 and DIV-SE-5 in Figure 3?\n- How many trials are the experiments over?\n- Can you explain at a high-level why your method is so much stronger on Blocksworld 3 and Blocksworld 4 / 5 compared to the other tasks? Can you provide some outputs of DIV-SE vs. baseline to illustrate?\n- Could you clarify what the various colors mean in Figure 1 and Figure 3 (purple, green, blue, orange etc.)?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6540/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6540/Reviewer_YP6t",
                        "ICLR.cc/2024/Conference/Submission6540/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6540/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698885835226,
            "cdate": 1698885835226,
            "tmdate": 1700599737476,
            "mdate": 1700599737476,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dbm2qLEAaq",
                "forum": "FvfhHucpLd",
                "replyto": "0EDzDCDU0W",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6540/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6540/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your feedback!"
                    },
                    "comment": {
                        "value": "[part 1]\nWe thank the reviewer for their comments.  We now respond to any concerns the reviewer may have. Should the reviewer have any clarifications, we are happy to further engage. If the responses are satisfactory, we kindly request the reviewer to increase their score towards acceptance.\n\n**The novelty of the work is very limited. There exists work in which diverse prompts are used to generate diverse reasoning paths: This paper should be cited due to its similarity.**\n\nResponse: We thank the reviewer for sharing this paper, but would like to strongly stress that the methodology of this paper is very different from that of ours. In the paper by Li et al., the reasoning problem\u2019s prompt is formed by providing multiple, yet different examples depending on the test sample (refer to figure 10 in their paper), and using a step-wise verifier to correct errors made. **This requires them to have a base of examples from which they can sample few-shot examples for each prompt, a critical limitation as noted in Appendix B.1 of their paper. We do not.**\n\nThe \u201cdiversity\u201d in their prompts are reasoning paths based on self-consistency for examples from the base of examples (i.e., a hold out set); these reasoning paths are not truly diverse as they all use the same approach (as highlighted in response to reviewer PAGk) and only serve as \u201cmore examples\u201d for the model or at best as linguistic diversity triggers (but not reasoning diversity). In contrast, our work (i) involves truly diverse (refer to response to reviewer PAGk) and \u201crelated\u201d approaches to solve the reasoning problem (refer to Figure 2 in our work), whilst (ii) limiting the number of examples in the prompt (we use 5, Li et al. need close to 20) and (iii) do not have a step-wise verifier (which further increases the cost).\n\n**It is not completely clear [how/why] DIV-SE works well on Blockworlds and AQUA-RAT, but less so on GSM8K and Commonsense QA.**\n\nResponse:  We would like to stress that the minor improvements are in scenarios where the models are already very performant in the tasks; regardless - the performance using our method is consistently high (with an average improvement of 8 percentage points) and often state-of-the-art (as in the Blocksworld case, with a 29.69 percentage point improvement). All this, with a fraction of the cost of contemporary approaches. We request the reviewer to look at the table below (in the summary link) to learn more about performance gains, and Figure 1 + 3 in the paper to learn more about the cost vs. performance trade-offs. \n\nThe reasons for little improvements for some models and datasets is because of task saturation (particularly in the case of GSM8K and GPT-4). This can be for a variety of reasons, such as these tasks not needing substantial reasoning capabilities as the models become bigger, or dataset contamination. However, for tasks such as Blocksworld, reasoning is more important and this is where our method shines compared to prior approaches.\n\nSummary of the results can be found here:: https://ibb.co/68PF2Dr\n\n**IDIV is likely to have significant context length constraints.**\n\nResponse: The prompts proposed in the work by Li et al. are significantly longer (with an average of 6050 tokens per prompt, based on their training data provided in https://github.com/microsoft/CodeT/tree/main/DIVERSE) compared to IDIV-SE (which has an average of 523 tokens per prompt) for the GSM8K task \u2013 almost a 12x gap. Additionally, the context length of models is increasing (as shown in most recent model releases), and we believe this should not be an issue. Additionally, we have taken measures to mitigate this potential issue. Specifically, we limit our prompts to a maximum of 3-shots, as opposed to (a) 5-7 shots typically used in standard few shot prompts (Wang et al., 2023), or (b) 20 shots as used by the work of Li et al. (https://arxiv.org/pdf/2206.02336.pdf). Please note the inference cost reported in Figure 1 and 3 accounts for both input and output token costs. \n\n**It\u2019s not clear whether adding a persona increases the diversity of output. I suspect the persona does not add much to the method. This requires an ablation.** \n\nResponse: As part of our preliminary analysis, we observed that the persona was very important in generating enhanced performance. The work of Salewski et al. that we cite highlights the importance of personas in in-context learning situations."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6540/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700272353165,
                "cdate": 1700272353165,
                "tmdate": 1700272367231,
                "mdate": 1700272367231,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "r4aahXV4s3",
                "forum": "FvfhHucpLd",
                "replyto": "o9w2nZLhQ9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6540/Reviewer_YP6t"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6540/Reviewer_YP6t"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for answering my questions. Thank you also for addressing the concerns highlighted.\n\nI am happy with the answers with respect to performance that you provided. I have increased the score accordingly.\n\nWith respect to Li et. al. I agree there are differences between your method and theirs, but I still believe the amount of novelty in your method is limited. Perhaps more important than novelty, I agree with reviewer \"Vhwc\" that the way in which this paper is written currently overstates its contribution as it does not sufficiently address past related works and highlights the similarities and differences. I believe a material change to Section 1 (Introduction) and Section 4 (Related Works) might be necessary."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6540/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700599769192,
                "cdate": 1700599769192,
                "tmdate": 1700599769192,
                "mdate": 1700599769192,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "bkVbz9fT79",
            "forum": "FvfhHucpLd",
            "replyto": "FvfhHucpLd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6540/Reviewer_Vhwc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6540/Reviewer_Vhwc"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a novel prompting framework, DIV-SE that ensembles diverse prompts instead of ensembling multiple decoding outputs in self-consistency. The diverse prompts are generated by two steps: 1) instruct an LLM to generate names of approaches or names of personas. 2) generate the rationale for each exemplar and each approach by analogizing to existing CoT examples. It also proposes a cost-effective variant, IDIV-SE, to reduce the cost of multiple inference calls. Compared to self-consistency, DIV-SE and IDIV-SE set up a new Pareto frontier in performance-cost trade-off."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper proposes a novel variant of self-ensembling for LLMs, which doesn\u2019t require much prompt engineering and is applicable to many tasks.\nThe authors experimented with the proposed method on 3 tasks and 4 datasets. The proposed method outperforms self-consistency in performance-cost trade-off on the all datasets except for CommonsenseQA."
                },
                "weaknesses": {
                    "value": "The methodology part of this paper is not well written. Figure 2 is readable, but Section 2 lacks a clear high-level structure. What are the goals for extracting approaches & personas, augmented demonstrations in the proposed method? Can you describe more details about how you generated the few-shot exemplars for each task? Is it automatically generated by LLM or manually written? If they are automatically generated, what if there are errors in the generated exemplars? Do you need to verify the generated exemplars on a validation set? If you need a validation set for developing this method, it would be not fair to compare it with self-consistency in terms of cost, since self-consistency works out-of-the-box without a validation set.\nMerging multiple inference calls into one was first invented and discussed in Batch Prompting[1]. Please cite it and tone down your contribution on this technique.\nThe paper seems to be written in a rush. Page 5 is badly formatted.\n\n\n[1] Cheng, et al. Batch Prompting: Efficient Inference with Large Language Model APIs. EMNLP 2023."
                },
                "questions": {
                    "value": "Maybe you can put Figure 2 on page 3 instead of page 4?\nSection 2.2. \u201cIt independently formulates new approaches\u201d -> Is it a hallucination or a feature? It looks like a hallucination to me. If this is important for achieving good performance, can you provide an ablation study based on whether to allow new approaches or not?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6540/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698957711526,
            "cdate": 1698957711526,
            "tmdate": 1699636736939,
            "mdate": 1699636736939,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3S4IciaAEj",
                "forum": "FvfhHucpLd",
                "replyto": "bkVbz9fT79",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6540/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6540/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your feedback"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their comments, and for finding our approach novel, and one that doesn\u2019t require extensive prompt engineering while being applicable to many tasks.  We now respond to any concerns the reviewer may have. Should the reviewer have any clarifications, we are happy to further engage. If the responses are satisfactory, we kindly request the reviewer to increase their score towards acceptance.\n\n**The methodology part of this paper is not well written. Figure 2 is readable, but Section 2 lacks a clear high-level structure. What are the goals for extracting approaches & personas, augmented demonstrations in the proposed method?**\n\nResponse: We apologise for the lack of clarity in our presentation and will strive to improve this aspect, based on your suggestions and questions. What we wished to convey was the following structure:\n\n1. Prompts in our proposal comprise of a combination of approaches (that provide technical insight) and personas (to bootstrap the model and align it)\n2. We use the prompting template shown in Figure 6 to request the LLM to generate the names of various approaches. We then construct a word cloud from these approaches using a hold-out set and select the top five. For personas, we directly ask the model to provide a list of individuals suitable for task resolution.\n3. To generate the few-shot examples, once the approaches are selected (based on frequency of occurrence), we first start with a chain-of-thought demonstration used in Wei et al. (2022), and query GPT-4 to style transfer this using the selected approach, to create an \u201caugmented demonstration\u201d. To ensure the quality of these demonstrations, we conduct a manual evaluation. Given that the task primarily involves a style transfer of the demonstrations, we found no errors. Thus, we have a prompt with (a) a persona, (b) a set of diverse approaches, and (c) corresponding augmented samples. \n\nWe agree with the observation made by the reviewer that in practice, our proposal requires a hold out set for evaluating the choice of approaches and personas. However, this set turns out to be very small, with 100 samples (though we believe 50 might often suffice). Additionally, most prompting strategies that are deployed require such a hold out set, and this is not a limitation to our work alone (https://docs.anthropic.com/claude/docs/optimizing-your-prompt). \n\nWe also thank the reviewer for other formatting changes suggested to improve the clarity of the paper; we will actively work on making these changes.\n\n\n\n**Merging multiple inference calls into one was first invented and discussed in Batch Prompting ([1] Cheng, et al. Batch Prompting: Efficient Inference with Large Language Model APIs. EMNLP 2023.). Please cite it and tone down your contribution on this technique.**\n\nResponse: We thank the reviewer for the pointer to the paper, and will cite it. We would, however, like to highlight the difference between our approach and Batch Prompting. In our approach, we batch multiple \u201creasoning paths\u201d within the same prompt. Batch Prompting does not (a) specifically address reasoning problems, and (b) primarily involves grouping the response to **\u201cmultiple queries together\u201d whereas our approach involves soliciting the response to \u201cone query\u201d using multiple reasoning paths** within the prompt.\n\n\n**Section 2.2. \u201cIt independently formulates new approaches\u201d -> Is it a hallucination or a feature? It looks like a hallucination to me. If this is important for achieving good performance, can you provide an ablation study based on whether to allow new approaches or not?**\n\nResponse: Since there is no well-defined manner to restrict the model to only following the approaches we propose, we believe it would be hard to perform the ablation. However, from our evaluation of the approaches created (or hallucinated as suggested by the reviewer), the methodology proposed and calculations performed are often accurate. This begs the question as to understanding why these approaches must be restricted. Could the reviewer shed some additional clarity on their thoughts?"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6540/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700271807569,
                "cdate": 1700271807569,
                "tmdate": 1700271807569,
                "mdate": 1700271807569,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "L3hE4W5Rv6",
            "forum": "FvfhHucpLd",
            "replyto": "FvfhHucpLd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6540/Reviewer_PAGk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6540/Reviewer_PAGk"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes DIV-SE and IDIV-SE as prompting strategies to increase diversity of LLM generated responses to reasoning tasks. Instead of relying on the decoding algorithm (sampling) to generate diverse solutions, this approach creates prompts using different approaches from a pool of approaches suitable for a task. When prompted with these different approaches the LLM is shown to generate diverse solutions. Aggregating the results from these diverse prompts has been shown to be more effective than the self-consistency baseline. \n\nThe method can be summarised as follows:\n1. Create Persona, Approach combinations for a given task: Given a dataset - pick a random question q; ask LLM to come up with Personas & Approaches using LLM output (aggregating m x n suggestions from LLMs based in instruction|question|template ) & then picking pick top 5 using word cloud. Similarly let the LLM generate suggestions for apt personas for a given task.\n2. Pick an optimal P,A: For all P,A combinations the composite prompt is tried on a held-out set. And those with the highest performance are selected.\n3. Create Augmented demonstrations: Once the approaches for a task are selected as per above, we ask the LLM to modify existing demonstrations with the given set of approaches. \n4. Inference: Run with multiple prompts, each with a different augmented demonstration. Then output of these is aggregated. This can be done in a single call to the LLM (IDIV-SE) instead of independent inference steps (DIV-SE)."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Clever inference cost optimisation on top of self-consistency which requires making multiple calls to the model for a given task. With the IDIV-SE approach a single call is sufficient to extract different approaches and their corresponding solutions are obtained from the LLM which are then aggregated.\n- A novel take on prompting methods, diversity in prompt hasn't been explored to the best of my knowledge.\n- Interesting ablation study on error propagation.\n- Paper is very well written, most technical aspects are clearly described."
                },
                "weaknesses": {
                    "value": "- The method requires a held out set where different personas and approaches can be tested to pick useful ones. This makes the proposed DIV-SE method somewhat limited in practical applications. CoT prompting on the other hand provide universally applicable prompts, and self-consistency provides a generally applicable framework without needing a held-out set to fine-tune on.\n\n- Results seem mixed: Blocksworld clearly benefits from the diversity in prompting. It is clear on this benchmark that with IDIV-SE more can be achieved in less cost. But on other benchmarks this is not necessarily true e.g. GSM8K (Fig 3 & Fig 4).\n\n- No qualitaitve/quantitative assessment of the synthetically generated demonstrations (using LLMs). For augmented demonstrations - how is the quality of this dataset ensured? I suspect some human annotation to improve the quality of these demonstrations can improve eventual model performance.\n\n- Limited evaluation: Some commonly used reasoning benchmarks are not present, making it hard to compare with prior work like Wang et al's Self Consistency baseline. Arithmetic reasoning: AddSub MultiArith ASDiv SVAMP. Commonsense and symbolic reasoning:  CSQA StrategyQA ARC-e ARC-c Letter Coinflip\n\n- Fig 4 & 5 - For a fair comparison with DIVSE-1 to 5, shouldn't Self Consistency baseline also be given multiple reasoning paths instead of just report SC-1?\n\n- The study could also be extended to other models with smaller sizes e.g. Llama 2 7B variants.\n- Difference in effectiveness of DIV-SE could be reported for pre-trained vs chat finetuned/RLHF-ed models."
                },
                "questions": {
                    "value": "- What does it mean to have a zero shot setting of DIV-SE? Isn't it always atleast one shot as shown in Fig 2? I couldn't find details of how this is done in zero-shot setting. Is the prompt appended with list of approaches but no examples?\n\n- What is the quality of these augmentations? Are they really diverse? Are each of them valid? If yes, are they different from other prompts?\n\n- Sec 2.2 . In practice, for all (persona, approach) combinations, we evaluate the prompt formed using the composition on a held-out set and choose those with the highest performance. This seems like a limitation - for open ended reasoning tasks that could appear in conversational applications, how can this be done outside the benchmarks studied?\n\n- Fig 6 & 8 are referenced in the text but missing in the paper? Did you mean Fig 2?\n\n- Can you explain how different this approach is from self-consistency: I'm not sure if the approach can be described as one bringing diversity in prompting. The diversity is being attempted in the set of approaches taken by the LLM to solve a problem. This is still very similar in spirit to self-consistency - where instead of naively sampling n times, the model is prompted to generate different approaches. The approaches themselves are model generated."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6540/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6540/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6540/Reviewer_PAGk"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6540/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698984249094,
            "cdate": 1698984249094,
            "tmdate": 1699636736800,
            "mdate": 1699636736800,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VQqcJQ5Lk6",
                "forum": "FvfhHucpLd",
                "replyto": "L3hE4W5Rv6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6540/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6540/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your feedback!"
                    },
                    "comment": {
                        "value": "[part 1] We thank the reviewer for finding our work clever, novel, and emphasizing the importance of diversity in prompting. We now respond to any concerns the reviewer may have. Should the reviewer have any clarifications, we are happy to further engage. If the responses are satisfactory, we kindly request the reviewer to increase their score towards acceptance.\n\n**The method requires a held out set where different personas and approaches can be tested to pick useful ones. This makes the proposed DIV-SE method somewhat limited in practical applications.** \n\nResponse: We agree with the observation made by the reviewer that in practice, our proposal requires a hold out set for evaluating the choice of approaches and personas. However, this set turns out to be very small, often with 100 samples (though we believe fewer, e.g., 50 might also suffice). Prompt engineering is typically a one-time effort, and the resulting prompt could potentially serve thousands or even millions of user queries\n\nIn addition, all prompt engineering practices in general (and not only our proposed approach) **do** require a hold out set, but the main issue with most practices in the status quo is that they require a significant amount of trial and error (https://docs.anthropic.com/claude/docs/optimizing-your-prompt).\n\nAdditionally, the approaches discovered by our DIVERSE-PROMPTING strategy are general and re-usable across reasoning problems of the same domain, adding to the practicality of our approach. Thus, the cost of evaluating the approaches on a hold out set is further amortised. As an example, for the GSM8K task, some of the LLM-generated approaches include: using visualisations, working backwards, using direct calculation, and method of elimination; these can be reused for other arithmetic reasoning problems.\n\n**Results seem mixed: Blocksworld clearly benefits from the diversity in prompting. It is clear on this benchmark that with IDIV-SE more can be achieved in less cost. But on other benchmarks this is not necessarily true e.g. GSM8K (Fig 3 & Fig 4).**\n\nResponse: We would like to stress that the minor improvements are in scenarios where the models are already very performant in the tasks; regardless - the performance using our method is consistently high (with an average improvement of 8 percentage points) and often state-of-the-art (as in the Blocksworld case, with a 29.69 percentage point improvement). All this, with a fraction of the cost of contemporary approaches. We request the reviewer to look at the table (in the summary link below) to learn more about performance gains, and Figure 1 + 3 in the paper to learn more about the cost vs. performance trade-offs. \n\nThe reasons for little improvements for some models and datasets is because of task saturation (particularly in the case of GSM8K and GPT-4). This can be for a variety of reasons, such as these tasks not needing substantial reasoning capabilities as the models become bigger, or dataset contamination. However, for tasks such as Blocksworld, reasoning is more important and this is where our method shines compared to prior approaches.\n\nSummary of the results can be found here: https://ibb.co/68PF2Dr\n\n**No qualitaitve/quantitative assessment of the synthetically generated demonstrations (using LLMs).  I suspect some human annotation to improve the quality of these demonstrations can improve eventual model performance.**\n\nResponse: In generating the demonstrations for a specific approach, we do not solely rely on the LLM to create the demonstrations from scratch. Instead, we utilize the same chain-of-thought demonstrations from Wei et al. (2022) as a base, and instruct GPT-4 to perform a \u201cstyle transfer\u201d of the solution using the specific approach. \n\nTo ensure the quality of these demonstrations, we conducted a manual evaluation as well. Given that the task primarily involves a style transfer of the demonstrations, we found no errors in the style transferred demonstrations i.e., correctness was preserved.\n\nWe also agree with the reviewer that more curation of the \u201caugmented examples\u201d can boost performance. However, we would like to point out that despite the lack of such curation, our approaches demonstrate SOTA performance on tasks that require complex reasoning (e.g., Blocksworld)."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6540/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700272119322,
                "cdate": 1700272119322,
                "tmdate": 1700272119322,
                "mdate": 1700272119322,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HvNlyvY7FJ",
                "forum": "FvfhHucpLd",
                "replyto": "GxANJLEl9r",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6540/Reviewer_PAGk"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6540/Reviewer_PAGk"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Authors, Thank you for your response to many of the concerns and clarifications. I'm however unable to recommend this work for acceptance. The mixed results on the benchmarks studied and the absence of some relevant benchmarks still remain my top concerns here."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6540/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700636813909,
                "cdate": 1700636813909,
                "tmdate": 1700636813909,
                "mdate": 1700636813909,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UrinsQdVZU",
                "forum": "FvfhHucpLd",
                "replyto": "KCa2lMhhPi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6540/Reviewer_PAGk"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6540/Reviewer_PAGk"
                ],
                "content": {
                    "comment": {
                        "value": "As I understand the goal of this paper is to design a general prompting strategy that improves the reasoning abilities of LLMs. To be able to find this claim convincing, I'd expect evidence of the method being useful on a few more reasoning tasks beyond Blockworlds and AQUA-RAT. I understand the authors argue that on benchmarks like GSM8K and Commonsense QA, GPT-3.5 like models are performant enough. One alternative could then be proving that DIV-SE and IDIV-SE help attain significant performance gain when applied with models less capable or much smaller than GPT-3.5 on common reasoning benchmarks, or considering a broader set of models besides GPT-3.5 and 4 (similar to the Table 2 from Wang et al 2023 that you pointed out). The 'additional insight' I'm expecting is substantial proof that the method you have proposed is general and effective enough beyond the 2 datasets and the 2 models where DIV-SE & IDIV-SE do provide convincing value."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6540/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700713629830,
                "cdate": 1700713629830,
                "tmdate": 1700713629830,
                "mdate": 1700713629830,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]