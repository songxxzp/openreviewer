[
    {
        "title": "A Simple Data Augmentation for Feature Distribution Skewed Federated Learning"
    },
    {
        "review": {
            "id": "9Z38euiwcZ",
            "forum": "258EqEA05w",
            "replyto": "258EqEA05w",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4875/Reviewer_9DEf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4875/Reviewer_9DEf"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new data augmentation method to improve the performance of FL under feature shift. This method can be combined with other existing augmentation methods. The experiments demonstrate that the proposed method achieves better performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Addressing the skewed feature distribution problem from a data perspective is interesting and important.\n- The proposed method is simple yet seems to be effective in addressing the feature shift problem, while keeping rather high privacy and security of the local data.\n- The paper is generally well-written and easy to follow.\n- The proposed method can be easily combined with existing methods and elevate their performances."
                },
                "weaknesses": {
                    "value": "- Several existing methods are not compared in the paper: e.g., FedBN [1] and FedWon [2], which also focuses on addressing the feature shift problem. It seems that FedBN achieves better performance than most of the baselines + FedRDN at least in certain domains.\n- Only AlexNet is used for evaluating classification tasks.\n- The scope of the paper in terms of FL scenario is not clearly explained. Does the method work under cross-silo FL, cross-device FL, or both?\n\n[1] Fedbn: Federated learning on non-iid features via local batch normalization\n\n[2] Is Normalization Indispensable for Multi-domain Federated Learning?"
                },
                "questions": {
                    "value": "- How would the proposed method perform using other models, such as ResNet?\n- It seems that the reason why the FedRDN can improve performance is not well illustrated in the manuscript.\n- Figure 3 in the supplementary is not very intuitive to demonstrate the superiority of FedRDN. Can the author offer more explanation?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4875/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4875/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4875/Reviewer_9DEf"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4875/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698507310435,
            "cdate": 1698507310435,
            "tmdate": 1699636471642,
            "mdate": 1699636471642,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hhHuc9mmV6",
                "forum": "258EqEA05w",
                "replyto": "9Z38euiwcZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4875/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4875/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer 9DEf"
                    },
                    "comment": {
                        "value": "Thanks for your constructive comments!\n\n> Q1. Several existing methods are not compared in the paper: e.g., FedBN [1] and FedWon [2], which also focuses on addressing the feature shift problem. It seems that FedBN achieves better performance than most of the baselines + FedRDN at least in certain domains.\n\n\nDue to the absence of code release for FedWon,  we compare FedBN with our method on Office-Caltech-10 and DomainNet with the same experimental settings.  In addition, we have included MOON [3] and FPL [4] in the baseline. The results are reported below. we can see that FPL and FedBN can outperform several baselines + FedRDN. However, FedRDN enables some outdated methods to achieve closed or better performance than these SOTA methods.\n\n\n| Dataset | FedBN | MOON | FPL |\n| :-----|:----: |:----: |:----: |\n| Office-Caltech-10 | 70.65 |  63.20 | 71.27 |\n| DomainNet | 43.56 | 42.75  | 44.06 |\n\n\n> Q2. How would the proposed method perform using other models, such as ResNet?\n\n\nThank you for your valuable suggestion. In response, we have carried out supplementary experiments using ResNet-18 on Office-Caltech-10. The outcomes of the supplementary experiments are provided in the following sections. \nDue to the small size of the dataset, the performance of ResNet18 is not as good as that of AlexNet. However, the results underscore the consistent enhancements attained through our proposed augmentation approach, underscoring its efficacy, adaptability, and resilience.\n\n| Dataset | Network | FedAvg | FedAvg + norm | FedAvg + FedMix | FedAvg + FedRDN |\n| :-----|:----: |:----: |:----: |:----: |:----: |\n| Office-Caltech-10 | AlexNet | 62.51 | 61.46 | 63.59 | 69.80 |\n| Office-Caltech-10 | ResNet-18 | 43.74 | 43.60 | 53.81 | 56.70 |\n\n> Q3. It seems that the reason why the FedRDN can improve performance is not well illustrated in the manuscript.\n\nThe effectiveness of our method is owing to learning shared distribution information for all clients, thereby indirectly mitigating the bias of model optimization. Experimental results compared with traditional normalization in Tables 1 and 2,  and cross-site evaluation in Table 3 demonstrated that the effectiveness of our method is not from the pixel-wise re-scaling but from its capacity for biased distribution.\n \n> Q4. Figure 3 in the supplementary is not very intuitive to demonstrate the superiority of FedRDN. Can the author offer more explanation?\n\nIn Fig. 3, we employed t-SNE to visualize the feature distribution of the global model for the images belonging to the same category across four different clients. Due to the underlying distributions among these clients, their feature distributions exhibit a shift, referred to as the feature shift phenomenon. Intuitively, as shown in Fig.3 (a),  the features of client 2 (DSLR) are clustered in the bottom-left corner, showing a noticeable shift from the features of other clients. After applying our method, the features of all four clients are uniformly distributed, indicating that the features from these clients are now in a shared feature space. The above result shows that FedRDN can effectively mitigate the feature shift. We will add more explanation in the final version.\n\n> Q5. The scope of the paper in terms of FL scenario is not clearly explained. Does the method work under cross-silo FL, cross-device FL, or both?\n\nFeature distribution skewed FL is a type of heterogeneous FL scenario that focuses on addressing diverse local distributions. Therefore, it can work under both cross-silo and cross-device scenarios, as long as there is feature distribution skew among different clients' data. However, in cross-device scenarios, such as between mobile phones and cloud servers, there may be imbalances in the computational resources of the devices. This issue is beyond the scope of this study.\n\n**References**\n\n[1] FedBN: Federated Learning on Non-IID Features via Local Batch Normalization. ICLR, 2021.\n\n[2] Is Normalization Indispensable for Multi-domain Federated Learning? arxiv, 2023.\n\n[3] Model-Contrastive Federated Learning. CVPR, 2021.\n\n[4] Rethinking Federated Learning With Domain Shift: A Prototype View. CVPR, 2023."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4875/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700407714382,
                "cdate": 1700407714382,
                "tmdate": 1700408462074,
                "mdate": 1700408462074,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "olrbSiVnrB",
                "forum": "258EqEA05w",
                "replyto": "hhHuc9mmV6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4875/Reviewer_9DEf"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4875/Reviewer_9DEf"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the responses! However, the reviewer still has some concerns.\n\nQ1: Do the results on the table represent the original method or the method + FedRDN? If it is the method + FedRDN, what is the performance of the original method? It seems that FedWon[2] also has experiment results on these datasets. Can they be compared directly? Some discussion should be given in the related work session.\n\nQ2: The results on ResNet-18 seem to be abnormal. It should not have such a large performance gap with AlexNet. Some hyperparameter tuning may be needed. \n\nQ5: Could the authors help demonstrate that the method could work on cross-device FL, under the assumption the computation resources of the device are similar? For example, the total number of clients is 100, and only a small subset of clients are selected."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4875/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700729773958,
                "cdate": 1700729773958,
                "tmdate": 1700729773958,
                "mdate": 1700729773958,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "IVVuNgtCMY",
            "forum": "258EqEA05w",
            "replyto": "258EqEA05w",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4875/Reviewer_rKgT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4875/Reviewer_rKgT"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, a data augmentation approach is proposed to tackle the issue of feature distribution skew in FL. This technique involves the computation and sharing of the mean and standard deviation of data across local client devices. Throughout the training process, data samples are normalized using randomly selected mean and standard deviation values from these stored statistics. This mechanism injects global information, resulting in improved accuracy."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "**Clarity & Quality**: This paper presents its method in a straightforward manner, substantiated by a series of experiments. The experimental outcomes are presented through tables and figures, facilitating a clear assessment of the efficacy of their approach.\n\n**Originality & Significance**: This paper presents an innovative approach involving the direct application of data statistics to input data. This method proves to be effective in addressing feature distribution skew within FL, resulting in improved accuracy"
                },
                "weaknesses": {
                    "value": "1. The paper lacks theoretical analysis and comprehensive explanation. The proposed method needs more elaboration and theoretical support. (Q1, Q2)\n\n2. This study exhibits certain resemblances to FedFA. The approach involving the calculation of mean and standard deviation bears similarity to FedFA, with the key distinction being that this work concentrates on normalizing the input data. In this context, the paper could lack novelty or benefit from more comprehensive comparisons with FedFA.\n\n4. This approach has the potential to cause privacy risks. For instance, if the training data consists of patient information vectors from a specific hospital, sharing the mean and std could compromise the confidentiality of this sensitive patient data.\n\n3. Some details of the experiments are missing. (Q3)"
                },
                "questions": {
                    "value": "1. In section 3.2, the author claims that sharing aggregated statistics is like injecting global information. Is there any guarantee or analysis to support that normalizing data using randomly selected mean and standard deviation values is considered equivalent to injecting global information?\n\n2. This method chooses different schemes for training and testing since it says \"output results may differ due to the varied statistics chosen\". Is this difference significant with varied choices of statistics? Could it work if applying no normalization during the test time?\n\n3. What are the details of the involved datasets? For example, how many clients do they have, how many samples on each client, etc.?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4875/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4875/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4875/Reviewer_rKgT"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4875/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698518521008,
            "cdate": 1698518521008,
            "tmdate": 1699636471546,
            "mdate": 1699636471546,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NP8crEGZWu",
                "forum": "258EqEA05w",
                "replyto": "IVVuNgtCMY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4875/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4875/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer rKgT"
                    },
                    "comment": {
                        "value": "Thanks a lot for your valuable comments!\n\n> Q1. In section 3.2, the author claims that sharing aggregated statistics is like injecting global information. Is there any guarantee or analysis to support that normalizing data using randomly selected mean and standard deviation values is considered equivalent to injecting global information?\n\nDuring the training process of FedRDN, we will randomly select a statistic to conduct augmentation for each image. Consequently, after multiple rounds, the number of selections surpasses the quantity of statistics by a substantial margin. This implies that each client leverages the local distribution information from all clients to augment each image, which potentially injects all local information from every client into the client-side training. The results of the cross-site evaluation (Table 3) indicate that our approach significantly improves the generalization of local models. Besides, Fig.3 also demonstrates that our approach has alleviated the feature shift among clients, learning more generalized feature representations.\n\n> Q2. This method chooses different schemes for training and testing since it says \"output results may differ due to the varied statistics chosen\". Is this difference significant with varied choices of statistics? Could it work if applying no normalization during the test time? \n\nSorry for confusion. 1) During the testing phase, if we continue to randomly select a statistic, multiple inferences on the same image may yield different results, leading to uncertainty in the test result. Besides, there is no communication between the client and the server. Therefore, it is more practical for the client to choose its own statistic. 2) If normalization is omitted during testing, there will be inconsistency in the data distribution between the training and testing phases, leading to a significant degradation in performance.\n\n\n> Q3. What are the details of the involved datasets? For example, how many clients do they have, how many samples on each client, etc.?\n\nThanks for your comment. As stated in 'Datasets' section (Sec 4.1), we employ the subsets of each dataset as clients, and we present the detailed results of each client in Table 1 and 2.  The data sizes of the three datasets are shown as below. We will include it in the final version.\n\n| **Office-Caltech-10** | Amazon | Caltech | DSLR | Webcam |\n| :-----|:----: |:----: |:----: |:----: |\n| train | 459 | 538 | 75 | 141 |\n| test | 192 | 225 | 32 | 59 |\n\n| **DomainNet**  | Clipart | Infograph | Painting | Quickdraw | Real | Sketch |\n| :-----|:----: |:----: |:----: |:----: |:----: |:----: |\n| train | 672 | 840 | 791 | 1280 | 1556  | 708 |\n| test | 526  | 657 | 619 | 1000 | 1217 | 554 |\n\n| **ProstateMRI**  | Clipart | Infograph | Painting | Quickdraw | Real | Sketch |\n| :-----|:----: |:----: |:----: |:----: |:----: |:----: |\n| train | 156 | 94 | 280 | 230 | 246  | 105 |\n| test | 52  | 31 | 93 | 76 | 82 | 35 |\n\n> Q4. Difference between our method and FedFA.\n\nThanks for your comment.  We clarify it in several aspects as follows: 1) Although the process of calculating statistics shares similarities with FedFA's computation process, they lie in their respective focus on input data and features, respectively. Therefore, our approach can be further combined with FedFA to improve its performance. 2) FedFA requires modifying the network structure, which may be constrained in real-world applications. In contrast, our approach requires no modifications to the network, which can be seamlessly integrated into the data augmentation pipeline. Therefore, our method exhibits better generalization and versatility.\n\n> Q5. This approach has the potential to cause privacy risks. For instance, if the training data consists of patient information vectors from a specific hospital, sharing the mean and std could compromise the confidentiality of this sensitive patient data.\n\nIn Sec.5, we stated that our method is only applicable to visual tasks. For image data, the statistics ($\\mathbb{R}^3$ for RGB images) are privacy-irrelevant information, as they only capture the distribution information. Additionally, they represent the statistics of local datasets and do not contain individual-level information. Therefore, our method is privacy-secure."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4875/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700407029639,
                "cdate": 1700407029639,
                "tmdate": 1700407185367,
                "mdate": 1700407185367,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qMhgLkTKEA",
            "forum": "258EqEA05w",
            "replyto": "258EqEA05w",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4875/Reviewer_aJPJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4875/Reviewer_aJPJ"
            ],
            "content": {
                "summary": {
                    "value": "This work aims at tackling feature distribution skewed in FL. To this end, the authors propose a simple yet effective method where the statistics of data are shared across clients to augment local data. Solid experiments are conducted to verify the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed method is simple yet effective, with relatively high privacy security.\n\n2. Many scenarios are considered for evaluating the proposed method, providing solid experimental evaluation. The experimental results, like performance gain, are promising."
                },
                "weaknesses": {
                    "value": "1. The authors may overlook some related works. The authors claim \u201cfew studies pay attention to the data itself\u201d, but many works pay attention to the data itself in FL, such as [1] [2] and [3].\n\n2. It is hard to figure out why \u201cinjects the statistics of the dataset from the entire federation into the client\u2019s data\u201d can cause \u201ceffectively improve the generalization of features, and thereby mitigate the feature shift problem.\u201d This is the key contribution of this work, but the authors claim it without support. This significantly weakens the contribution of this work.\n\n[1] Federated learning with non-iid data. Zhao et al. 2018\n[2] Virtual Homogeneity Learning: Defending against Data Heterogeneity in Federated Learning. Tang et al. 2022\n[3] Federated learning via synthetic data. Goetz and Tewari. 2020"
                },
                "questions": {
                    "value": "I have several suggestions that may make the work more attractive:\n\n1. I suggest the authors do careful proofreading so that the paper can be more rigorous. For instance, the authors claim that \u201cits (FL model) performance inevitably degrades, while suffering from data heterogeneity\u201d. However, if clients hold iid data, its performance is comparable to the scenario of centralized training.\n2. According to the authors\u2019 explanation, it is hard to figure the difference in data heterogeneity and feature shit or feature distribution skewed. I suggest the authors do careful proofreading so that the paper is more readable.\n3. All experiments are conducted under the P(X) shifting scenarios. I suggest the authors report more results on the scenario of P(Y) shifts, which may make the work more attractive (do not have much stress, as it is just a suggestion).\n4. Detailed descriptions for Figure 3 will make the motivation and conclusion more clear."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4875/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698655754751,
            "cdate": 1698655754751,
            "tmdate": 1699636471460,
            "mdate": 1699636471460,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4yHJCCOhjO",
                "forum": "258EqEA05w",
                "replyto": "qMhgLkTKEA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4875/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4875/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer aJPJ"
                    },
                    "comment": {
                        "value": "Thanks a lot for your constructive comments!\n\n> Q1. The authors may overlook some related works. The authors claim \"few studies pay attention to the data itself\", but many works pay attention to the data itself in FL, such as [1] [2] and [3]. \n\nLiterature [1], [2], and [3] focus on label distribution skew, which are different from the issue in this paper. \n\n> Q2. It is hard to figure out why \"injects the statistics of the dataset from the entire federation into the client\u2019s data\"  can cause \"effectively improve the generalization of features, and thereby mitigate the feature shift problem.\"  This is the key contribution of this work, but the authors claim it without support. This significantly weakens the contribution of this work.\n\nDuring the training process of FedRDN, we will randomly select a statistic to conduct augmentation for each image. Consequently, after multiple rounds, the number of selections surpasses the quantity of statistics by a substantial margin. This implies that each client leverages the local distribution information from all clients to augment each image, which potentially injects all local information from every client into the client-side training. The results of the cross-site evaluation (Table 3) indicate that our approach significantly improves the generalization of local models. Besides, Fig.3 also demonstrates that our approach has alleviated the feature shift among clients, learning more generalized feature representations.\n\n> Q3. I suggest the authors do careful proofreading so that the paper can be more rigorous. For instance, the authors claim that \"its (FL model) performance inevitably degrades, while suffering from data heterogeneity.\" However, if clients hold iid data, its performance is comparable to the scenario of centralized training.\n\nSorry for confusion. We will carefully proofread our paper. \n\n> Q4. According to the authors' explanation, it is hard to figure the difference in data heterogeneity and feature shit or feature distribution skewed. I suggest the authors do careful proofreading so that the paper is more readable.\n\n\nSorry for confusion. We will maintain consistency in words and carefully revise it in the final version.\n\n\n> Q5. All experiments are conducted under the P(X) shifting scenarios. I suggest the authors report more results on the scenario of P(Y) shifts, which may make the work more attractive (do not have much stress, as it is just a suggestion).\n\nP(Y) shifting is label distribution skew, which is different from the issue in this paper. This work focuses on the feature distribution skew, i.e., P(X) shifting. The details of this problem can be seen in Sec 3.1. \n\n> Q6. Detailed descriptions for Figure 3 will make the motivation and conclusion more clear. \n\nIn Fig. 3, we employed t-SNE to visualize the feature distribution of images belonging to the same category across four different clients. Due to the different distributions among these clients, their feature distributions exhibit a shift, referred to as the feature shift phenomenon. Intuitively, as shown in Fig.3 (a),  the features of client 2 (DSLR) are clustered in the bottom-left corner, showing a noticeable shift from the features of other clients. After applying our method, the features of all four clients are uniformly distributed, indicating that the features from these clients are now in a shared feature space. The above result shows that FedRDN can effectively mitigate the feature shift. We will add more explanation in the final version.\n\n**References**\n\n[1] Federated learning with non-iid data. Zhao et al. 2018 \n\n[2] Virtual Homogeneity Learning: Defending against Data Heterogeneity in Federated Learning. Tang et al. 2022 \n\n[3] Federated learning via synthetic data. Goetz and Tewari. 2020"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4875/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700405669817,
                "cdate": 1700405669817,
                "tmdate": 1700408591664,
                "mdate": 1700408591664,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Fn0JcyqvcR",
                "forum": "258EqEA05w",
                "replyto": "4yHJCCOhjO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4875/Reviewer_aJPJ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4875/Reviewer_aJPJ"
                ],
                "content": {
                    "title": {
                        "value": "Re: response"
                    },
                    "comment": {
                        "value": "Thanks for the detailed response. After reading the response and other reviewers' comments, I think the paper is borderline. I am going to keep my original score."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4875/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700730460024,
                "cdate": 1700730460024,
                "tmdate": 1700730460024,
                "mdate": 1700730460024,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wsTatyvScQ",
            "forum": "258EqEA05w",
            "replyto": "258EqEA05w",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4875/Reviewer_BGPc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4875/Reviewer_BGPc"
            ],
            "content": {
                "summary": {
                    "value": "This paper discusses the problem of feature distribution skew in federated learning (FL) and proposes a data augmentation technique called FedRDN to mitigate this issue. The main challenge in FL is data heterogeneity, which leads to feature shift due to different underlying distributions of local datasets. While previous studies have focused on addressing this issue through model optimization or aggregation, few have paid attention to the data itself. FedRDN addresses this by randomly injecting the statistics of the dataset from the entire federation into the client's data, improving the generalization of features and mitigating feature shift. The method is simple, effective, and can be seamlessly integrated into the data augmentation flow. Experimental results demonstrate its scalability and generalizability. The document also provides a summary of related work in FL with statistical heterogeneity and data augmentation techniques."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This approach is different from previous methods and focuses on mitigating the feature shift at the input-data level.\n\n2. The paper is generally well-written and clear in presenting the problem, proposed approach, and experimental results.\n\n3. Experiments are conducted on multiple datasets."
                },
                "weaknesses": {
                    "value": "1. The literature review appears to be incomplete or lacks recent research contributions.\n\n2. Improved paragraph transitions and organization are required.\n\n3. The presentation needs improvement."
                },
                "questions": {
                    "value": "1. I am not that familiar with the skewed FL scenario, could you explain more about it?\n2. In Section 1, the effectiveness of data augmentation for FL at the input level has been mentioned times, how to improve it in this paper?\n3. In term of data augmentation, what are the differences between previous methods and the proposed method?\n4. In Eq.(6), the obtained image are equipped with global information, but how to measure the contribution of multiple distributions?\n5. The paper will be more attractive if state-of-the-art methods are included in experiments for comparison.\n6. For the purpose of reproducibility, it would be better to provide the code and datasets."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4875/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698974881303,
            "cdate": 1698974881303,
            "tmdate": 1699636471382,
            "mdate": 1699636471382,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "cZEpepTzbY",
                "forum": "258EqEA05w",
                "replyto": "wsTatyvScQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4875/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4875/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer BGPc"
                    },
                    "comment": {
                        "value": "Thanks a lot for your constructive comments!\n\n> w1. Literature review is incomplete. \n\nWe carefully reviewed recent literatures, which are related to the feature distribution skewed FL. The following content will be included to the final version.\n\n*'More recently, FedPCL [5] employed a pre-trained model to reduce the number of learnable parameters and applied prototype-wise contrastive learning to regularize feature representation learning across different clients. This offers an effective solution for training large models in the feature distribution skewed federated learning (FL) scenario. Motivated by prototype learning, FPL [6] utilized clustering to acquire unbiased class prototypes and then alleviated feature shift through prototype and local embedding alignment. In contrast to the aforementioned methods, ADCOL [7] introduced a novel adversarial collaborative learning approach to mitigate feature shift, replacing the model-averaging scheme with adversarial learning.'*\n\n> w2 & w3. Problem of writing.\n\nWe will revise the language of manuscript and invite native speakers for proofreading.\n\n> Q1. I am not that familiar with the skewed FL scenario, could you explain more about it?\n\nFeature distribution skew [1] is a fundamental challenge in federated learning. As federated learning typically involves multiple discrete clients, data collected by different clients unavoidably leads to distinct underlying distributions [3]. For client $k$, the underlying data distribution $P_k(x,y)$ can be rewritten as $P_k(y|x)P_k(x)$, and $P_k(x)$ varies across clients while  $P_k(y|x)$ is consistent for all clients. For instance, different hospitals possess MRI images scanned by different devices, and different phones store images of different styles (such as cartoon images and natural images). In summary, feature distribution skewed federated learning (FL) typically focuses on multi-domain data. Due to variations in the distributions of different data domains, it results in biased feature distributions among different local models [2, 7].\n\n\n> Q2&Q3. Explanation of data augmentation.\n\nSorry for confusion. There may be some misunderstandings. In previous FL research, there is no input-level data augmentation method. To the best of our knowledge, **this paper is the first work to explore the input-level data augmentation for feature distribution skewed FL**. Traditional input-level data augmentation methods in centralized learning often struggle to effectively address the feature shift issue stemming from distributional differences among local datasets. In this work, we focus on extending the traditional normalization operation to handle the feature distribution skewed FL scenario. To achieve this, we transfer distribution characteristics of all clients, i.e., mean and std, and utilize them to augment the images of each client. Cross-site evaluation (Table 3) and feature distribution visualization (Fig.3)) have demonstrated our method can effectively mitigate feature shift, thereby significantly improve the peformance (Tables 1 and 2).\n\n> Q4. In Eq.(6), the obtained image are equipped with global information, but how to measure the contribution of multiple distributions?\n\nSorry for confusion. In Eq.(6), we did not aggregate the statistics from all clients to get gloabl satistic but randomly selected one from them for augmentation. Therefore, there is no need to measure the contribution of each client here.\n\n> Q5. The paper will be more attractive if state-of-the-art methods are included in experiments for comparison.\n\nThanks for your comment. Based on your suggestion, we compared more baselines (FedBN [2], MOON [4] and FPL [6]) on Office-Caltech-10 and DomainNet with the same experimental settings. The results are repoted as below. we can see that FPL and FedBN can outperforms several baselines + FedRDN. However, FedRDN enables some outdated methods to achieve closed or better performance than these SOTA methods.\n\n| Dataset | FedBN | MOON | FPL |\n| :-----|:----: |:----: |:----: |\n| Office-Caltech-10 | 70.65 |  63.20 | 71.27 |\n| DomainNet | 43.56 | 42.75  | 44.06 |\n\n\n> Q6. For the purpose of reproducibility, it would be better to provide the code and datasets.\n\nThanks for your suggestion. The dataset is publicly available and the code will be released.\n\n**References**\n\n[1] Federated Learning on Non-IID Data Silos: An Experimental Study. ICDE, 2022.\n\n[2] FedBN: Federated Learning on Non-IID Features via Local Batch Normalization. ICLR, 2021.\n\n[3] FedFA:\u00a0Federated Feature Augmentation. ICLR, 2023.\n\n[4] Model-Contrastive Federated Learning. CVPR, 2021.\n\n[5] Federated Learning from Pre-Trained Models: A Contrastive Learning Approach. NeurIPS, 2022.\n\n[6] Rethinking Federated Learning With Domain Shift: A Prototype View. CVPR, 2023.\n\n[7] Adversarial Collaborative Learning on Non-IID Features. ICML, 2023."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4875/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700404857567,
                "cdate": 1700404857567,
                "tmdate": 1700407822389,
                "mdate": 1700407822389,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]