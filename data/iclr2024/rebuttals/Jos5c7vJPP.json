[
    {
        "title": "Exchangeable Dataset Amortization for Bayesian Posterior Inference"
    },
    {
        "review": {
            "id": "4EZw2bwPcY",
            "forum": "Jos5c7vJPP",
            "replyto": "Jos5c7vJPP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8217/Reviewer_xVE8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8217/Reviewer_xVE8"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies amortization schemes for variational Bayesian approximate inference methods. The approach is akin to the inference procedure used in standard variational autoencoders (maximize the reverse KL/ELBO), but amortization is performed over datasets instead of over individual datapoints. To solve this, the paper employs standard exchangeable aggregation architectures like deep sets or transformers.\n\nIn the experimental evaluation the authors consider a range of probabilistic models and explore two architectural choices: (i) deep sets vs. transformer-based aggregation (ii) Gaussian vs. normalizing flow variational posterior approximations. They compare against non-amortized inference schemes (max. likelihood, MCMC, random) as well as against an amortized approach based on the forward KL. The authors also evaluate how the methods perform under distribution shift."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is mostly well written and the authors provide an extensive experimental evaluation with enough details to ensure reproducibility. I think that the architectural comparisons (Gaussian vs. normalizing flow/deep set vs. transformer) are interesting. Unfortunately, the experiments in their current form due not yet convince me of the paper's significance (see weaknesses)."
                },
                "weaknesses": {
                    "value": "My main concerns are (i) that the approach lacks novelty and (ii) that the experimental evaluation should be improved in various aspects.\n\nDetails:\n\n(i) Amortized inference has been studied extensively in the past, e.g., in the context of the variational autoencoder. Amortization on the dataset level is also not new: it has been studied for years in the meta-learning community. In fact, the method is conceptually very similar to neural process (NP) [1] like approaches. The difference is that inference is performed over the decoder parameters directly and that, consequently, there are no free parameters that are optimized for predictive performance. While this is an architectural difference, it does not require any adaptations wrt to the posterior inference method (which is the only methodological proposal of the paper): both methods just optimize the ELBO wrt the variational parameters. The authors acknowledge these similarities, but argue that their method is new in the sense that NP-like methods are \"predominantly designed for predictive modeling and thus cannot be used to provide useful information and uncertainty about model parameters\". Unfortunately, the authors also largely focus on posterior predictive performance. The only results studying the quality of the approximate posterior are in Tab. 4 and Fig. 4 (c,d) which lack any comparisons against non-amortized baselines. I encourage the authors to explore further in which sense their method yields \"useful information and uncertainty about model parameters\", at least by adding more baselines to Tab. 4 (in particular baselines that allow to judge the amortization gap introduced by their method, cf. below).\n\n(ii) Following my remarks above, I consider the paper's contribution to be exclusively empirical. While the provided architectural comparisons are interesting, I do not yet consider the contribution significant enough  to be of interest for the community. Thus, I encourage the authors to improve/extend their experimental evaluation:\n- Please provide details about how the L2 and accuracy metrics were computed. (Please provide the exact formulae).\n- Could you elaborate on why you do not evaluate the predictive log marginal likelihood instead of the L2 loss (as is typically done for assessing the predictive performance of Bayesian models). This metric should better measure the quality of predictive epistemic uncertainty estimates and, thus, implicitly of the posterior approximation.\n- How much variance is introduced in the results due to the algorithm's/network's initialization? Please provide confidence intervals for your experimental results. In its current form it is impossible to judge their significance.\n- I would propose to also add a non-amortized version of the proposed method as a baseline. This would allow to judge the amortization gap, i.e., the approximation error introduced by amortization alone.      \n- The authors state that normalizing flows do not increase approximation accuracy due to the mode-seeking behavior of the reverse KL objective. I would be interested in a discussion and/or comparison to recent natural-gradient based methods such as [2,3] that perform VI with expressive Gaussian mixture approximations by inducing terms in the objective that prevent mode collapse.\n- The authors argue that deep sets are inferior to transformer-based architectures because of the naive sum/mean-based aggregation of deep sets. [4] propose a Bayesian aggregation method that tackles exactly this problem. It would be interesting to see how Bayesian aggregation compares to transformer-based aggregation.\n\n[1] https://arxiv.org/abs/1807.01622\n[2] https://arxiv.org/abs/2002.10060\n[3] https://openreview.net/pdf?id=tLBjsX4tjs\n[4] https://openreview.net/forum?id=ufZN2-aehFa"
                },
                "questions": {
                    "value": "See my comments below \"Weaknesses\"."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "---"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8217/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697735157727,
            "cdate": 1697735157727,
            "tmdate": 1699637020316,
            "mdate": 1699637020316,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "X2C1zXunYm",
                "forum": "Jos5c7vJPP",
                "replyto": "4EZw2bwPcY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8217/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8217/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8217/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8217/Reviewers",
                    "ICLR.cc/2024/Conference/Submission8217/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission8217/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8217/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their valuable comments. Our response aims to address the raised concerns, and we are available for further discussions to resolve any outstanding comments or ambiguities. \n\n**Contribution and Metrics** \n\nWe refer the reviewer to the common shared response which provides a discussion about the novelty of our work as well as the different contributions made. It also refers to the exact formulae used to define the metrics that we consider.\n\n**Novelty** \n\nWe would like to respectfully disagree with the reviewer on their point about novelty. While we agree that the methodologies used (eg. Variational Inference (VI), amortization on the dataset, transformers) do exist in current literature, it is important to note that its application for amortized Bayesian posterior estimation hadn\u2019t been explored yet and this is precisely the void that we aimed to fill. It is true that in hindsight it might look like a simple application of existing concepts but this gap does indeed exist in literature and we feel that there is merit and contribution in addressing it since the class of parametric models with tractable likelihoods do span a significant volume of models used by practitioners. Thus, leveraging and combining existing methods to allow for faster and more efficient posterior estimation in such a class of models is important.\n\nAdditionally, as the reviewer points out, Neural Processes (NPs) are only applicable in predictive tasks and thus our proposed approach does tackle a different problem. In particular, our objective is not the same as NPs as we optimize the ELBO with respect to the variational parameters only (there are no other parameters in the likelihood model) whereas NPs optimize the ELBO with respect to both variational parameters as well as the parameters in the likelihood model. Though seemingly similar, it is important to note that the former is a direct application of the VI framework while the latter of Variational Expectation Maximization.\n\nFinally, we would also like to point out that neither NPs nor Simulation-based Inference (SBI) approaches generally handle variable dimensional inputs in modeling the predictive tasks. Further, the two directions have mostly seen progress separately, without works comparing them under the common setting of probabilistic models with tractable likelihoods. Additionally, we also consider model mis-specification and OoD generalization based real world settings which have been relatively less explored in both SBIs and NPs. \n\nPredictive log marginal likelihood: We are not quite clear what the reviewer means by this quantity, but we do add another metric definition in Appendix D (CNLL). An example of this metric in our proposed experiments is available in Tables 5 and 6. The reason we did not include this metric was because it was fairly well correlated with downstream $L_2$ or accuracy metrics, but for completeness we are happy to include it in the Appendix. We request the reviewer to let us know if they had a different metric in mind.\n\n**Related Work**\n\nWe thank the reviewer for pointing out some of the relevant works on VI approaches leveraging a Gaussian Mixture distribution as the approximating distribution as well as different context averaging methods like Bayesian Context Averaging. We believe that empirical comparisons against these approaches is a contribution on its own and thus leave it as future work. However, we do include a discussion on them in the main text as well as the Appendix in the revised draft.\n\n**Variance due to Initialization**\n\nWe agree with the reviewer that it would be nice to have an estimate of variance due to initialization in the posterior estimation. We would like to point out, however, that all our metrics are evaluated over 100 datasets, each with 25 samples from the approximate variational distribution which already provides an estimate of the reliability of the model. We omit the standard deviation in this setup so as to improve readability in the tables, but we will open-source our code for the community to freely use the approach. The experiments are computationally extensive to run since we test on a wide variety of probabilistic models but we would be happy to attempt to provide some estimates. Is there a particular metric / setup that the reviewer is interested in seeing the effect of initialization on?\n\n**Non Amortized Baseline** \n\nWe thank the reviewer for this point and note that we do consider two non amortized baselines, optimization and MCMC. These baselines in particular show that the amortized VI setup is not as strong as optimization in predictive modeling but does compare significantly favorably to MCMC. We also decided to opt out of KDE estimates of MCMC in Figure 4 just to make the figures clearer as we already have the true posterior on it.\n\nWe hope that our response clarifies the reviewer's concerns and we would be happy to answer any additional questions and concerns."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8217/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700109963476,
                "cdate": 1700109963476,
                "tmdate": 1700109963476,
                "mdate": 1700109963476,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jLvrbbQaMB",
                "forum": "Jos5c7vJPP",
                "replyto": "X2C1zXunYm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8217/Reviewer_xVE8"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8217/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8217/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8217/Reviewers",
                    "ICLR.cc/2024/Conference/Submission8217/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission8217/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8217/Reviewer_xVE8"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the feedback"
                    },
                    "comment": {
                        "value": "I thank the authors for their answer and clarifications. Unfortunately, I'm still not convinced that the manuscript is ready for publication at a conference like ICLR. I also feel like my view is in line with the other reviewers, so I'll keep my score. Please find some details for my decision below.\n\n- While I agree that the paper considers \"pure variational inference\" in contrast to NP's variational expectation maximization, I do not think that this fact alone counts as a relevant theoretical/methodological contribution. In fact, the theoretical discussion (Sec. 3) as well as architectural approaches (Sec. 4) are well known, i.p., in the meta-learning community. I also agree that NPs perform inference over a conceptually different set of variational parameters (i.e., not over the likelihood aka decoder parameters, but over the inputs to the decoder), but from an abstract point of view this does not require any changes to the methodology used. Moreover, \"purely variational\" approaches have also been studied in the meta-learning community for a long time, e.g., in probabilistic/Bayesian extensions of MAML such as [1]. Finally, I agree with the other reviewers that the author's masking-based approach to handling variable dimensionality is neither new nor theoretically especially appealing. Therefore, I'm still convinced that the paper's contribution is exclusively empirical. \n- As mentioned in my initial review, I in principle *do* consider empirical papers valuable for the community (as noted, some of the architectural comparison provided in the paper are indeed interesting). Unfortunately, I do not think that the provided experimental evaluation of the author's manuscript overall provides enough benefit for the community to be ready for publication. I.p., I still do not see how the author's claimed contribution \n\n\"Instead, our primary objective is to infer the posterior distribution over them. This nuanced differentiation in methodology contributes to the unique positioning of our approach within the broader landscape of Bayesian posterior estimation methodologies. [...] our contribution lies in their application to the specific challenge of Bayesian posterior estimation in probabilistic models with tractable likelihood functions.\"\n\nis reflected in the experimental evaluation. Concretely, I do not see the central question answered why performing \"pure\" variational inference in the likelihood's parameters space is beneficial in comparison to established approaches from the NP or MAML [1] families. To reiterate my concerns:\n- Except for simple toy examples, the authors also only compare predictive performance, but do not include comparisons against the mentioned baselines from the meta-learning literature.\n- I'm not convinced that the used predictive metrics (L2/accuracy) are suitable as proxies for Bayesian posterior estimation quality. More precisely: I think that *predictive* metrics can in principle be used as proxies for *posterior* estimation. However, I'm not convinced that predictive *L2/accuracy* is suitable (as noted by the authors, the added conditional NLL metric should be largely equivalent to predictive L2). How do these metrics measure the quality of epistemic uncertainty estimates? What I meant in my initial review is using the log marginal predictive likelihood, as for example used in [2], Eq. 16. I'd be interested in the author's view on the distinction between the metrics and why they chose L2 over log marginal predictive likelihood.\n- While the authors include a discussion with MAML/NP like approaches, \"the comparison is often limited to a few sentences that are, in my opinion, vague and insufficient\" (as noted also by reviewer iJJB).\n\n[1] https://arxiv.org/pdf/1806.02817.pdf\n[2] https://openreview.net/pdf?id=sb-IkS8DQw2"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8217/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700672626767,
                "cdate": 1700672626767,
                "tmdate": 1700672626767,
                "mdate": 1700672626767,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "SBIpMu4rzA",
            "forum": "Jos5c7vJPP",
            "replyto": "Jos5c7vJPP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8217/Reviewer_iJJB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8217/Reviewer_iJJB"
            ],
            "content": {
                "summary": {
                    "value": "This manuscript proposes a method for amortized Bayesian posterior inference. In particular, this method leverages set-based neural network architectures to design an amortized posterior that can deal with observation of varying cardinality. The model is trained using the reverse-KL divergence which is shown empirically to work better for the considered benchmarks. The authors also show that this leads to better performance when the model used differs from the data-generating process."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The method is sound.\n* Building amortized Bayesian inference algorithms that can deal with sets of observations of different cardinality and be robust to model specification is significant."
                },
                "weaknesses": {
                    "value": "Overall, I find that the paper lacks of clarity making it hard to follow. Here is a list of things that, in my opinion, harms clarity:\n\n* The contributions are not clear. Here are the three claimed contributions:\n   1. *\"Proposing a novel method for performing Bayesian inference in probabilistic models solely through inference on a trained amortization network, and demonstrating its effectiveness in a variety of settings and with several well-known probabilistic models.\"* \nThroughout the paper, it is not clear to me what is claimed as novel in the proposed method. Is performing Bayesian inference based on a trained amortization network claimed to be novel? Is using the reverse KL divergence novel? Is the fact of using a backbone that accepts sets as input to handle datasets of different cardinality novel?\n\n\t2. *\"Providing insights into various design choices like the architectural backbone used and the choice of parametric distribution through detailed ablation experiments.\"* Ok\n\n\t3. *\"Highlighting the superior performance of our proposed approach when compared to existing baselines, especially in the presence of model misspecification and real-world data.\"* Does the contribution lie in the design of a new method to handle model misspecification or the empirical study of existing methods in this context?\n\n* There are figures all over the place while they all belong to section 4. It is very confusing to see experimental figures in the middle of the introduction. In addition, when reading the experiment section, the reader has to jump back to the introduction to see the figure.\n\n* Equation (8) seems to be very similar to equation (9) from prior work. Would it be easier to start from there, explain what $\\chi$ is and say that you use the reverse KL instead? I feel that previous explanations dilute the message and make things hard to follow while equation (9) is straightforward to understand.\n\n* Section 4.3 seems to be full of methodological elements while being in the middle of the experiments section. I think grouping all the methodological elements together would help clarify the contributions.\n\n* In section 4.3 it is said that \"In contrast, we can leverage our proposed reverse KL approach to train an amortized inference model to predict the posterior over the assumed probabilistic model\u2019s parameters by directly using the available unpaired data during training.\" It is not clear to me how this is done while this seems to be a contribution of the paper. It would be worth to expand on this more. \n\t\nI think the following paper should be discussed in the related works. It addresses the problem of amortized Bayesian inference for datasets of different cardinality. It exploits the fact that the scores of each individual observation can be composed to produce the score of the joint observations. This joint score can then be used to efficiently produce samples from the posterior distribution.\nGeffner, T., Papamakarios, G., & Mnih, A. (2023). Compositional Score Modeling for Simulation-Based Inference.\n\nIn the experiments, the quality of the approximate posteriors is quantified using either the expected $L_2$ loss or the expected accuracy loss. This is unclear to me what those losses are. I think it is important to include their mathematical definition in the manuscript. From what I understood, the expected $L_2$ loss can be defined as \n$L_2 = E_{p(\\theta|D)}[(\\theta - \\tilde{\\theta})^2] $\nwhere $\\tilde{\\theta}$ would be the parameters used to generate $D$. I think this metric is unsuited when the posterior is multimodal. An approximation that puts the mass in the middle of the two modes (where there should be no mass) will have a lower $L_2$ than an approximation that puts half the mass in each mode. \n\nI cannot assess the novelty due to the lack of clarity regarding the contributions."
                },
                "questions": {
                    "value": "* Could you clarify what in the manuscript is a contribution and what belongs to the background?\n\n* Could you clarify what are the quantities used for evaluation and justify the use of those?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8217/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8217/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8217/Reviewer_iJJB"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8217/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698748860973,
            "cdate": 1698748860973,
            "tmdate": 1699637020200,
            "mdate": 1699637020200,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "B1unGV1D96",
                "forum": "Jos5c7vJPP",
                "replyto": "SBIpMu4rzA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8217/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Submission8217/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8217/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8217/Reviewers",
                    "ICLR.cc/2024/Conference/Submission8217/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission8217/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8217/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response"
                    },
                    "comment": {
                        "value": "We sincerely appreciate the reviewer's valuable comments. In our response, we aim to address and clarify the majority of the concerns raised and would be happy to engage in additional discussions should there be any remaining unresolved comments. \n\n**Contribution and Metrics**\n\nWe refer the reviewer to the common shared response which provides a discussion about the novelty of our work as well as the different contributions made. It also refers to the exact formulae used to define the metrics that we consider.\n\n**Starting from Equation 8-9** \n\nWe argue that the reason Equation 9 seems familiar from prior work is because it is the general starting point of defining the optimization problem for Simulation-based Inference (SBI) approaches. However, we rely on the reverse KL / Variational Inference (VI) framework where the derivation leads to the well studied ELBO objective. Thus, we discuss the connections to ELBO and amortization more clearly in the start to provide a complete story as well as the exact loss formulation, which is defined in Equation 7. Mathematically, equations 7 and 8 describe an equivalent optimization problem.\n\n**Section 4.3** \n\nWe provide each section of the experiments with its own set of methodological details and defer the readers to the Appendix for additional tangential details (eg. the choice of mis-specification explored). This is because we want each experimental section to be self-contained about the experiments discussed there. We will take the reviewer\u2019s concerns into account and update Section 4.3 in the next revision to clarify some of the concerns regarding the setup.\n\nTo clarify, we would like to point the reviewer to the differences in Equations 8 and 9. Equation 9 is only tractable for training if $\\chi$ defines sampling according to the probabilistic model $p(\\mathcal{D} | \\mathbf{\\theta})$, since then we observe the pairs $\\{(\\mathcal{D}, \\mathbf{\\theta})\\}$. However, in general, we often only observe a stream of data $\\{\\mathcal{D}\\}$ from some data generating function $\\chi\u2019$ coming from an unknown probabilistic model, without its corresponding parameters $\\mathbf{\\theta}$. In this setting of model mis-specification, we find that when we train both the proposed method and SBI baseline on $\\chi$ and evaluate on $\\chi\u2019$, the proposed method generalizes better.\n\nAdditionally, even though we don\u2019t know the underlying probabilistic model, we can still model the observations relatively well. Practitioners often define a probabilistic model to explain this stream of data; which could be different from the ground-truth underlying probabilistic model and hence wrong. However, one could still model the data well by finding a good set of parameters of this ill-specified probabilistic model. A caveat of SBI approaches, which are generally framed as a Forward KL optimization problem, is that they cannot be trained using data obtained from $\\chi\u2019$ and thus would not be able to leverage diverse data coming from different and unknown probabilistic models. In contrast, our proposed method can leverage such data during training, and we show in Table 3 that leveraging such data improves performance even further.\n\nMore succinctly, this difference arises from swapping $\\chi$ with $\\chi\u2019$ in Equations 8 and 9 such that $\\chi\u2019$ does not follow $p(\\mathcal{D} | \\mathbf{\\theta})$ while $\\chi$ does. This swap makes Equation 9 infeasible to optimize, while Equation 8 still remains feasible. We hope that this clarifies the reviewer\u2019s doubts regarding how this setting is formulated.\n\nAs an example, we can consider the probabilistic model as a nonlinear Bayesian Neural Network model. It can only be trained under the SBI framework if $\\chi$ represents nonlinear data sampled according to this model. However, we might receive a stream of data of interest that might follow a linear relationship. This data cannot be part of the training framework in the SBI setup, but can be in our proposed method.\n\n**Related Work** \n\nWe have added a discussion about the work on score modeling for SBI in the Appendix. We were not aware of this work but as we point out, it is still different from the proposed approach since we are not leveraging the SBI framework for amortized posterior estimation and instead propose a complementary research stream and show benefits of performing amortized VI. However, we provide a small discussion on the similarities in the Appendix A of the revised draft.\n\n**Figure Positioning**\n\nWe apologize for the figure positioning and will try to improve it where possible.\n\nWe hope that our response clarifies the reviewer's concerns and we would be happy to answer any additional questions and concerns."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8217/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700109840893,
                "cdate": 1700109840893,
                "tmdate": 1700109840893,
                "mdate": 1700109840893,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "o7pwqUFtd9",
                "forum": "Jos5c7vJPP",
                "replyto": "B1unGV1D96",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8217/Reviewer_iJJB"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Submission8217/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8217/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8217/Reviewers",
                    "ICLR.cc/2024/Conference/Submission8217/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission8217/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8217/Reviewer_iJJB"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for this detailed response! I will here share my updated view on the different points raised both here and in the common response.\n\nFirst, I should say that many things have been clarified with this response. It shows the value of this work but also strenghten the need for substantial rewritting. It is now clear to me that, in its current form, the paper lacks too much of clarity to be accepted but that it can become valuable work if rewritten. It particular, I think the paper would greatly benefit from a clearer explanation of how this work is positionned in the litterature and what differs from existing work in SBI/NP/GP. The last paragraph of section 4.3 should also be extended to explain how such data can be leveraged as this seems to be a contribution of this work. \n\nI also have to point out this sentence with which I disagree.\n\n> Moreover, it is crucial to emphasize that to the best of our knowledge, none of the existing methods within SBI or NPs demonstrate the capability to effectively handle inputs of variable dimensions while our method can, which in itself is a novel contribution.\n\nI have to disagree because this is precisely what is done in Geffner, T., Papamakarios, G., & Mnih, A. (2023). Compositional Score Modeling for Simulation-Based Inference. It constructs a score model that can handle inputs of variable dimensions and be used to sample from the posterior."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8217/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700497367875,
                "cdate": 1700497367875,
                "tmdate": 1700497367875,
                "mdate": 1700497367875,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2uoibg6Y9z",
                "forum": "Jos5c7vJPP",
                "replyto": "WfsoVyLkZs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8217/Reviewer_iJJB"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Submission8217/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8217/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8217/Reviewers",
                    "ICLR.cc/2024/Conference/Submission8217/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission8217/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8217/Reviewer_iJJB"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your response.\n\nOther approaches are indeed mentioned but the comparison is often limited to a few sentences that are, in my opinion, vague and insufficient. Also, this is only a small example of a more general lack of clarity. Regarding the variable dimensionality, my thinking is that handling variable dimensional spaces is something more related to the neural network architecture used than the inference algorithm. Geffner et. al work could easily be extended to handle variable dimensional spaces by modeling the score with an appropriate neural network. For those reasons, I will leave my score unchanged."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8217/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700661645489,
                "cdate": 1700661645489,
                "tmdate": 1700661645489,
                "mdate": 1700661645489,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "yBdwl2NfUJ",
            "forum": "Jos5c7vJPP",
            "replyto": "Jos5c7vJPP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8217/Reviewer_oaRk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8217/Reviewer_oaRk"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a framework for amortized inference of probabilistic model parameters, $\\theta$, using neural networks that maintain permutation equivariance among data points. The neural network takes in a dataset of some number of datapoints and provide amortized inference of the model parameters, it is also capable of taking in datasets of various dimensions. \n\nThe method doesn\u2019t require ground truth parameters during training. Instead, the objective is to minimize the reverse KL divergence under the Variational Inference (VI) framework, with the requirement that the model provides a closed-form likelihood of the data given the model parameters. The method is applied to probabilistic models such as (non-)linear regression/classification and Gaussian mixtures. On unseen problems, the amortized inference parameters serve as good initial guess that can speed up optimization based on that."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- *Versatility of Application*: The method is demonstrated to be effective for both fixed and variable-dimension parameter spaces. In the latter case, the method cleverly leverages masking to manage unused dimensions.\n- *Model Robustness*: By adopting a reverse KL approach rather than forward KL, the presented model offers greater resilience to model-misspecification. This implies that it can effectively handle cases where training datasets and test datasets might be characterized by different underlying probabilistic models."
                },
                "weaknesses": {
                    "value": "- *Literature Gap*: The paper seems to omit relevant literature on amortized GP hyperparameters [1][2][3]. And GP belongs to the framework considered here because it has closed form likelihoods given model parameters. Specifically,[1] produces amortized inference for point estimate of the posterior for GP hyperparameters given a dataset. The neural network architecture proposed in [1] also makes use of transformer for permutation equivariance. [1][2][3] also generalize to unseen datasets, with the same meta-learning flavor. This paper broadens the perspective by considering general probabilistic models and considering a distribution rather than a point estimate. But the basic idea and architecture choices share the same spirit, which decreases the novelty in the methodological contribution.\n- *Variable Dimension Handling*: The method of managing variable-dimensions through masking might be limited. It wastes GPU memory and is not equivariant w.r.t. dimensions. There could be potential benefits in exploring the neural network employed by [1] if each dimension has its own parameters, such as in linear regression and GMM.\n- *Clarity on GMM*: It is unclear how the proposed approach would manage variable  number of mixtures in the case of Gaussian Mixture Models (GMM).\n- *Ablation Limitations*: While the mention of an ablation study is commendable, it would be beneficial to see a more comprehensive study, for instance, sweeping across dimensions ranging from 1-100D, to see how the approach extrapolates on dimensions different than the training data.\n\n[1] Liu, Sulin, Xingyuan Sun, Peter J. Ramadge, and Ryan P. Adams. \"Task-agnostic amortized inference of gaussian process hyperparameters.\" Advances in Neural Information Processing Systems 33 (2020): 21440-21452.\n\n[2] Simpson, Fergus, Ian Davies, Vidhi Lalchand, Alessandro Vullo, Nicolas Durrande, and Carl Edward Rasmussen. \"Kernel identification through transformers.\" Advances in Neural Information Processing Systems 34 (2021): 10483-10495.\n\n[3] Bitzer, Matthias, Mona Meister, and Christoph Zimmer. \"Amortized Inference for Gaussian Process Hyperparameters of Structured Kernels.\" UAI (2023)."
                },
                "questions": {
                    "value": "- *Choice of MCMC*: What was the motivation behind choosing Langevin instead of HMC? Further, is the paper referring to stochastic gradient Langevin dynamics? Maybe HMC type algorithms such as NUTS [4] should also be considered, since they have shown to be performing well empirically and given the number of datapoints is not too large that needs stochastic gradient . \n- *Handling Variable Dimensions*: While masking is one approach to manage variable dimensions, could the authors clarify if they looked into other methods, like the ones used by [1]?\n- *GMM's Variable Dimension Handling*: How does the model handle variable output dimensions in number of mixtures for GMMs, and what is the strategy for determining the number of mixtures?\n- *Figure Positioning*: The positions of the figures within the paper were not specified. Could the authors provide more clarity on this aspect?\n- *Comprehensive Ablation Study*: Would the authors consider conducting an ablation that sweeps on dimensionality from 1-100D?\n\n[4] Hoffman, Matthew D., and Andrew Gelman. \"The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.\" J. Mach. Learn. Res. 15, no. 1 (2014): 1593-1623."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8217/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698784398631,
            "cdate": 1698784398631,
            "tmdate": 1699637020090,
            "mdate": 1699637020090,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XWW16y9XzF",
                "forum": "Jos5c7vJPP",
                "replyto": "yBdwl2NfUJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8217/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8217/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8217/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8217/Reviewers",
                    "ICLR.cc/2024/Conference/Submission8217/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission8217/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8217/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their valuable comments and hope that our response addresses and clarifies the raised concerns. We are open to further discussions to resolve any remaining comments or ambiguities.\n\n**Contribution and Metrics**\n\nWe refer the reviewer to the common shared response which provides a discussion about the novelty of our work and the different contributions made as well as references to the exact formulae used to define the metrics that we consider.\n\n**Literature Gap** \n\nWe thank the reviewer for bringing these related lines of work to our attention. While they share similarities in the sense that they amortize the inference process for the kernel function of Gaussian Processes (GPs), it is crucial to delineate the distinctions in our approach. Unlike these methodologies, our framework does not involve the estimation of kernel functions for GPs. Instead, we present a more comprehensive framework for Bayesian posterior estimation based on amortized inference, emphasizing the modeling of the entire posterior distribution rather than relying on point estimates. However, since our approach does share some of the underlying similarities (connections to meta learning, use of transformer architecture, etc.), we include a discussion on the mentioned approaches in Appendix A of the revised manuscript. \n\n**Variable Dimension Handling**\n\nWe agree with the reviewer about predicting feature-specific parameters in modeling the posterior distribution. We had actually tried such an approach for linear regression where we leveraged attention across features as well as across observations. However, not only was it too compute intensive because of such interleaved attention operations but it also did not perform comparably to our current approach. \n\nWhile we do agree with the reviewer\u2019s point that using a parameter for each feature dimension allows for leveraging the existing permutation equivariance in the feature space for a class of probabilistic models, we argue that such a setting can be fairly limited. That is, it is conceptually straightforward to learn such a system for linear regression or Gaussian Mixture models but learning such a general system that exploits all the equivariances present in more complex models (eg. Bayesian Neural Nets) is far less obvious. In particular, leveraging the methodology explored in [1] would not work for models with deep learning based probabilistic models, for which it is not clear if the parameters corresponding to some intermediate layers should be tied to certain feature dimensions, and if so, which? In particular, explicitly modeling all the equivariances present in a deep neural network is likely intractable and hence while we agree that it is a very interesting direction, we feel that it is an orthogonal line of research which would deserve a separate exploration. \n\n**GMM\u2019s Variable Dimension Handling**\n\nWe would like to clarify that although our methodology accommodates the modeling of Gaussian Mixture Model (GMM) tasks with varying feature dimensions, it does not currently support variable numbers of mixtures within the same model. We acknowledge any lack of clarity on this matter and will make necessary revisions in the draft to mitigate potential confusion.\n\n**Ablation Limitations** \n\nWe would also like to clarify that for variable dimensional experiments, we choose the dimensions 1-100 uniformly so even if we were to do a sweep over these dimensions to see how the performance varies, it remains \u201cin-distribution\u201d testing. That being said, we take the reviewer\u2019s point under consideration and showcase the trends over different dimensional setups in Figures 5-7 over different KL-based optimization strategies, architecture choices and variational assumptions and hope that it solves the reviewer\u2019s concerns. For OoD testing, we refer the reviewer to the model mis-specification and tabular experiments.\n\n**Choice of MCMC** \n\nWe apologize for not providing more clarity on this. We actually use Langevin Dynamics (full batch).  We also experimented with NUTS sampler but found it to be quite slow in nonlinear Bayesian Neural Network parameter estimation, especially since for each metric we would need to run the MCMC algorithm 100 times as we consider an average over 100 different datasets for each experiment. \n\n**Figure Positioning**\n\nWe apologize for the figure positioning and will try to improve it where possible.\n\n[1] Liu, Sulin, Xingyuan Sun, Peter J. Ramadge, and Ryan P. Adams. \"Task-agnostic amortized inference of gaussian process hyperparameters.\" Advances in Neural Information Processing Systems 33 (2020): 21440-21452.\n\nWe hope that our response clarifies the reviewer's concerns and we would be happy to answer any additional questions and concerns."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8217/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700109657161,
                "cdate": 1700109657161,
                "tmdate": 1700109657161,
                "mdate": 1700109657161,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Y1rbk2jpwL",
                "forum": "Jos5c7vJPP",
                "replyto": "XWW16y9XzF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8217/Reviewer_oaRk"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8217/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8217/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8217/Reviewers",
                    "ICLR.cc/2024/Conference/Submission8217/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission8217/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8217/Reviewer_oaRk"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for providing clarifications on GMM number of mixtures, problems with varying dimensions. I acknowledge that the paper proposes a more general framework for probabilistic models with tractable likelihoods. However, I share similar concerns with other reviewers about how this paper should be positioned in the context of literature of amortized inference. There has been much efforts of developing amortized inference framework for different models, in regression it is Neural processes and amortized GP hyperparameters (a special case of this paper's framework). It would be necessary to show how this general framework solves problems beyond previous methods. Current experiments focus on predictive performance and linear/non-linear models and GMMs, which are less interesting if the purpose of the paper's mainly focus is on empirical contributions."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8217/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700685034647,
                "cdate": 1700685034647,
                "tmdate": 1700685034647,
                "mdate": 1700685034647,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]