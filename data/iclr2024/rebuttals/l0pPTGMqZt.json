[
    {
        "title": "Domain Generalization for Domain-Linked Classes"
    },
    {
        "review": {
            "id": "4qXz5Fn92s",
            "forum": "l0pPTGMqZt",
            "replyto": "l0pPTGMqZt",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2856/Reviewer_UVpZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2856/Reviewer_UVpZ"
            ],
            "content": {
                "summary": {
                    "value": "This paper delves into the realm of Domain Generalization (DG), emphasizing the challenges posed by domain-linked classes, which are specific to certain domains and thus present significant hurdles in generalization. The authors introduce an algorithm, Fair and cONtrastive feature-space regularization algorithm for Domain-linked DG (FOND), designed to enhance the generalizability of domain-linked classes by leveraging representations from domain-shared classes. Through extensive experiments, FOND purportedly demonstrates state-of-the-art performance in DG tasks for domain-linked classes, provided a sufficient number of domain-shared classes are available. The paper also offers theoretical insights into the factors influencing the performance of domain-linked classes."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Novelty: The paper addresses a less-explored area in DG \u2014 the challenge posed by domain-linked classes, which significantly hinders the performance of generalization models.\n\nQuality: The introduction of the FOND algorithm, which aims to improve the generalizability of domain-linked classes by utilizing domain-shared class representations, is a noteworthy methodological contribution."
                },
                "weaknesses": {
                    "value": "1. Significance: The practical applicability of the research is questionable, given that the empirical validation is conducted on synthetic datasets, which may not effectively simulate real-world complexities.\n\n2. Quality: The theoretical analysis lacks depth, presenting generalized bounds without significant divergence from existing domain generalization theories, thereby offering limited novel insights.\n\n3. Novelty: The paper's innovation is constrained, primarily adapting existing fairness methods to a new context. The complexity introduced in the loss function isn't justified adequately.\n\n4. Clarity: The paper could benefit from a more coherent presentation of ideas, especially concerning the algorithm's design and the theoretical underpinnings."
                },
                "questions": {
                    "value": "1. Could you elaborate on the choice of synthetic datasets for validation? How do these datasets simulate the challenges of real-world applications?\n\n2. The theoretical analysis seems to align closely with established domain generalization theories. Could you elucidate the novel contributions of your theoretical insights?\n\n3. The FOND algorithm introduces considerable complexity, especially in the loss function. Can you justify this complexity in relation to the performance gains observed?\n\n4. How does the FOND algorithm ensure the transfer of useful representations between domain-shared and domain-linked classes? Is there a mechanism to prevent the transfer of domain-specific biases?\n\n5. Given the focus on domain-linked classes, could the proposed method be adapted to scenarios with fewer or no domain-shared classes?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2856/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2856/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2856/Reviewer_UVpZ"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2856/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697801846993,
            "cdate": 1697801846993,
            "tmdate": 1700568880589,
            "mdate": 1700568880589,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9f8BCIh3Co",
                "forum": "l0pPTGMqZt",
                "replyto": "4qXz5Fn92s",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2856/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2856/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank you for your review. Below we will address the comments.\n\n**1. Misconception about the evaluation datasets:**\n\n> W1 - Significance: The practical applicability of the research is questionable, given that the empirical validation is conducted on synthetic datasets...\n> Q1 - Could you elaborate...\n\nThe reviewer is mistaken. The dataset used \u2013 PACS, VLCS and OfficeHome are not synthetic and incorporate real-world images as shown in Fig. 2. Moreover, all contemporary domain generalization works use these dataset for evaluation, and therefore our work cannot be evaluated against an unrealistic benchmark.\n\n**2. Significance of the theoretical result:**\n> W2 - Quality: The theoretical analysis lacks depth...\n> Q2 - The theoretical analysis seems to align closely with established domain generalization theories....\n\nWe would like to respectfully disagree. Our main theoretical result is the first result in DG literature which illuminates domain-linked DG challenges; this is extremely important in light of recent calls to develop real world DG techniques. Moreover, existing results also assume that all classes are represented in all domains; this does not reflect real-world challenges.\n\nFurthermore, while existing results are mainly focused on theoretical analysis only, our work leverages the analysis to motivate the proposed approach, whose impacts are further corroborated by in the empirical evaluation where we see that higher number of shared classes helps learning for domain-linked learning. Therefore, while our analysis, like other DG results, uses well-known results in the literature [1,2,3], it is extremely non-trivial and establishes the conditions under which domain-shared classes are better-off than domain linked ones. \n\n**3. Comments about algorithm complexity:**\n\n> Q3 - The FOND algorithm introduces considerable complexity, especially in the loss function. Can you justify this complexity in relation to the performance gains observed?\n> Q4 - How does the FOND algorithm ensure the transfer of useful representations between domain-shared and domain-linked classes? Is there a mechanism to prevent the transfer of domain-specific biases?\n\n1. From our theoretical and experimental results we observe that domain-linked classes are inherently disadvantaged. Therefore, our aim is to transfer useful representations from domain-shared ones. \n2. To prevent the transfer of domain-specific biases FOND imposes that inter-domain positive and intra-domain negative comparisons should be amplified via the $\\beta$ and $\\alpha$ functions respectively. Even in the absence of fairness we observed that the inclusion of both these parameters (FOND\\F) yields a **+1.5%** performance improvement.\n3. To ensure the transfer of useful representations, the FOND objective enforces that learned representations must benefit both domain-shared and domain-linked classes via the fairness objective. This, to effect, encourages the model to ignore domain-specific representations for domain-linked classes and identify generalizable domain-invariant representations from domain-shared classes. Consequently, we observe a **+10%** performance improvement averaged across all datasets and shared-class settings.\n4. As a result FONDS learning objectives are aligned with our theoretical insights, and are required to accomplish domain-linked generalization. \n\n**4. The case of fewer or no domain-shared classes**\n> Q5 Given the focus on...\n\nThis question motivated our decision to create \"low\" and \"high\" shared settings. Our methodology shows how domain-shared classes can be used to boost domain-linked performance and our future work involves settings where domain-shared classes cannot be observed (or added) at all.\n\n**5. Comments about clarity and novelty (regarding fairness):**\n\nThe paper contributes on multiple fronts, one of which is its novel use of fairness for domain-linked classes (see Sec. 1 and 3 for other contributions and details). Further motivations for the proposed approach are developed in Sec. 4, followed by the methodology in Sec. 5. \n\nConventional fairness methods reduce distance/divergence metrics between the model\u2019s output on classes across protected attributes [1]; note this requires a class to be expressed by different protected attributes. However, fairness in our context cannot be applied to domains since some classes cannot be observed in multiple domains; this makes the domain-linked setting highly non-trivial.\n\nThis is the first work to propose a way to impose fairness in the context of DG aiming to draw useful discriminative representations for domain-linked classes. \n\n**References:**\n\n[1] Eastwood, Cian, et al. \"Probable domain generalization via quantile risk minimization.\" NeurIPS (2022)\n\n[2] Zhang, Guojun, et al. \"Quantifying and improving transferability in domain generalization.\" NeurIPS (2021)\n\n[3] Robey, Alexander, George J. Pappas, and Hamed Hassani. \"Model-based domain generalization.\" NeurIPS (2021)"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2856/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700100105388,
                "cdate": 1700100105388,
                "tmdate": 1700100105388,
                "mdate": 1700100105388,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mEFy44kNh7",
                "forum": "l0pPTGMqZt",
                "replyto": "9f8BCIh3Co",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2856/Reviewer_UVpZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2856/Reviewer_UVpZ"
                ],
                "content": {
                    "comment": {
                        "value": "As for W1, my primary concern is that this paper only rebuilds the standard DG datasets rather than proposes or finds a real-world application that has a suitable dataset for the new setting. If there is no fitting dataset existing in the real world, how can you say that the new setting is practical and significant?\n\nAs for W2, I cannot get the point what are the theoretical contributions of this paper. In my opinion, modifying the existing theory to the new setting is not novel.\n\nBased on the response, unfortunately, I have to lower the score."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2856/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700568826460,
                "cdate": 1700568826460,
                "tmdate": 1700568826460,
                "mdate": 1700568826460,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KZdYrBwmfD",
            "forum": "l0pPTGMqZt",
            "replyto": "l0pPTGMqZt",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2856/Reviewer_8VB1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2856/Reviewer_8VB1"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a novel task of domain generalization and devises an algorithm aimed at acquiring generalizable representations for domain-linked classes by transferring valuable insights from domain-shared classes."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This paper introduces a new setting of domain generalization where classes can be domain-shared or domain-linked.\n- The proposed method applies fairness for the domain-linked classes."
                },
                "weaknesses": {
                    "value": "(1) In section 5.2, the description of fairness is somewhat unclear. Is $M$ referring to the model, specifically the neural network? If so, it seems that the fairness loss is intended to reduce the classification loss gap between domain-linked and domain-shared classes, suggesting that minimizing the fairness loss aims to make the classification loss for both types of classes have similar values during training. However, it would be helpful to clarify how exactly this loss relates to fairness.\n\n(2) Does $\\beta$ in equation (4) have different values for each domain? If $\\beta$ is a unique value for all domains, then equation (4) can be rewritten as $...log\\frac{\\alpha}{\\beta} \\frac{exp(...)}{\\sum exp(...)}$. In this case, should we use $\\frac{\\alpha}{\\beta}$ as one hyperparameter instead of two separate hyperparameters ($\\alpha$ and $\\beta$)? If so, $\\frac{\\alpha}{\\beta}$ would be similar to $\\lambda_{xdom}$.\n\n(3) In section A.3 of the appendix, the hyper-parameter selection and model selection process is not quite clear. It references evaluation settings for domains without distinguishing the source and target domains. Does the selection process use the target domain to evaluate the performance?"
                },
                "questions": {
                    "value": "Please refer to the Weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2856/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2856/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2856/Reviewer_8VB1"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2856/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698664127341,
            "cdate": 1698664127341,
            "tmdate": 1699636229104,
            "mdate": 1699636229104,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bRElk0WjuX",
                "forum": "l0pPTGMqZt",
                "replyto": "KZdYrBwmfD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2856/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2856/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their clarifying questions. We provide details below. All results are reproducible, and further details are in supplementary and the code.\n\n**1. A note about the questions/weaknesses:**\n\nIt seems that the Reviewer is enthusiastic about the work, and we are happy to ensure that the reviewer is satisfied with the clarity to improve the presentation. But since none of their questions relate to the quality of contribution, technical novelty, correctness, or experimentation quality, we will strive to address them in the discussion period and we sincerely hope that the Reviewer can reconsider their scores.\n\n**2. Fairness objective clarification:**\n\n> W1 - In section 5.2, the description of fairness is somewhat unclear. Is M referring to the model, specifically the neural network? If so, it seems that the fairness loss is intended to reduce the classification loss gap between domain-linked and domain-shared classes, suggesting that minimizing the fairness loss aims to make the classification loss for both types of classes have similar values during training. However, it would be helpful to clarify how exactly this loss relates to fairness.\n\nIndeed M refers to the model and conventional fairness objectives aim to make the model's performance independent of protected attributes [1-5] (e.g. gender, race, geography). This is formulated as learning objectives that minimize distance/divergence metrics between the model\u2019s output on a certain class with different protected attributes [1]; note this requires a class to be expressed in different protected attributes. However, the reviewer is correct that fairness in our context cannot be applied to domains since some classes cannot be observed in multiple domains. Therefore, we define a fairness objective that seeks to promote representations that benefit both domain-shared and domain-linked classes. We observe that this regularization yields a +10% domain-linked accuracy performance improvement when tested on novel domains.\n\n**3. Clarifying $\\beta$:**\n> W2 - Does [beta] in equation (4)...\n\n$\\beta$ does not have different values for each domain. $\\beta$ is a function, $\\beta(z_i,z_j)$, that outputs a value (a hyper-parameter $>1$ ) when a pair of samples $z_i,z_j$ are from different classes (negative) but the same domain (intra-domain). Therefore the $\\beta$ function (outputs either 1 or b) cannot be factored out of the summation $\\sum\\limits \\beta \\exp(...)$ as you would a constant. \n\n**4. Clarifying hyper-parameter selection:**\n> W3 - In section A.3 of the appendix, the hyper-parameter selection and model selection process is not quite clear. It references evaluation settings for domains without distinguishing the source and target domains. Does the selection process use the target domain to evaluate the performance?\n\n- Model Selection Data: 20% of each source (training) domain held-out during training\n- Model Evaluation Data: 100% of the target (testing) domain\n\nThe target domain data must not be used for model/hyper-parameter selection since this data is to remain \"unseen\" and emulate real-world conditions [6].\n\n**References:**\n\n[1] Wang, Zeyu, et al. \"Towards fairness in visual recognition: Effective strategies for bias mitigation.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.\n\n[2] Pham, Thai-Hoang, Xueru Zhang, and Ping Zhang. \"Fairness and accuracy under domain generalization.\" International Conference on Learning Representations (ICLR). 2023.\n\n[3] Makhlouf, Karima, Sami Zhioua, and Catuscia Palamidessi. \"Machine learning fairness notions: Bridging the gap with real-world applications.\" Information Processing & Management 58.5 (2021): 102642.\n\n[4] Dwork, Cynthia, et al. \"Fairness through awareness.\" Proceedings of the 3rd Innovations in Theoretical Computer Science Conference on-ITCS'12. ACM Press, 2012.\n\n[5] Madras, David, et al. \"Learning adversarially fair and transferable representations.\" International Conference on Machine Learning. PMLR, 2018.\n\n[6] Gulrajani, Ishaan, and David Lopez-Paz. \"In Search of Lost Domain Generalization.\" International Conference on Learning Representations. 2020."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2856/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700098175666,
                "cdate": 1700098175666,
                "tmdate": 1700098175666,
                "mdate": 1700098175666,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Iiao1awl8H",
                "forum": "l0pPTGMqZt",
                "replyto": "bRElk0WjuX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2856/Reviewer_8VB1"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2856/Reviewer_8VB1"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response. Despite the author's clarification of certain details, the primary concern persists regarding the explanation of fairness and the corresponding loss. Besides, applying fairness or causality to domain generalization is not quite novel [1,2].\n\n[1] Mahajan, Divyat, Shruti Tople, and Amit Sharma. Domain generalization using causal matching. ICML, 2021.\n\n[2] Lv, Fangrui, et al. Causality inspired representation learning for domain generalization. CVPR. 2022."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2856/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700652453572,
                "cdate": 1700652453572,
                "tmdate": 1700652453572,
                "mdate": 1700652453572,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZEg1s56cf3",
            "forum": "l0pPTGMqZt",
            "replyto": "l0pPTGMqZt",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2856/Reviewer_x5U3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2856/Reviewer_x5U3"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses a key challenge in Domain Generalization (DG): the difficulty in generalizing to unseen target domains when classes are unique to specific domains (domain-linked). The authors introduce the concept of domain-linked classes in DG and propose the FOND algorithm, which enhances generalization by leveraging knowledge from domain-shared classes. Through comprehensive experiments, they demonstrate that FOND achieves state-of-the-art results in DG tasks, particularly for domain-linked classes. The paper also offers theoretical and practical insights into managing domain-linked class generalizability in real-world scenarios."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Indeed, modeling that explicitly considers the relationship between domains and classes is not extensively developed in existing methodologies. In this regard, addressing this specific aspect presents a novel approach to problem-solving in the field. This innovative focus could provide significant advancements in understanding and tackling domain-specific challenges.\n\nIt's reasonable to assume that domain-linked classes might have limited data compared to domain-shared classes. If the information from the more abundant domain-shared class data can be effectively utilized for the learning of domain-linked classes, it could indeed be beneficial. This approach seems quite plausible and potentially impactful in addressing data scarcity challenges in specific domains."
                },
                "weaknesses": {
                    "value": "The simplicity of the proposed methodology, which essentially relies on contrastive learning based on domain-shared classes and aligns the losses between domain-linked and domain-shared classes, does seem straightforward. While leveraging information from domain-shared classes to inform domain-linked classes could be beneficial, it's understandable to question whether such loss matching alone suffices to supply rich information.\n\nFurthermore, the connection between merely aligning loss magnitudes and achieving fairness metrics seems tenuous. A deeper, more nuanced approach might be necessary to ensure that the model not only aligns superficial loss values but also genuinely captures and transfers the underlying complexities and variances of the classes across different domains. \n\nThe term \"domain-linked class,\" used to describe classes that correspond one-to-one with a specific domain, does not seem particularly intuitive. Just recommend utilizing an other word. \n\nThe assumption of awareness on domain-shared classes and domain-linked classes are also not realistic.\n\nThe likelihood of encountering domain-linked classes in real-world problems may not be immediately apparent or intuitive. Can you provide a clear, real-world example where such classes prominently emerge?\n\nThe result of Theorem 1 appears overly direct. Its derivation through the PAC-Bayes bound seems far too straightforward, making it questionable to regard this as a true theorem."
                },
                "questions": {
                    "value": "Q1. Is it common in this field to define a dataset comprising both inputs and labels as a domain, as done in this paper?\n\nQ2. (Same as weaknesses) The likelihood of encountering domain-linked classes in real-world problems may not be immediately apparent or intuitive. Can you provide a clear, real-world example where such classes prominently emerge?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2856/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2856/Reviewer_x5U3",
                        "ICLR.cc/2024/Conference/Submission2856/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2856/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698822061330,
            "cdate": 1698822061330,
            "tmdate": 1700626585383,
            "mdate": 1700626585383,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GCYQvppGxS",
                "forum": "l0pPTGMqZt",
                "replyto": "ZEg1s56cf3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2856/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2856/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank you for your review. We address the main comments below.\n\n**1. A note about the misconception in the main concern:**\n\nIt seems that the scores are based on the misconception that the availability of labels and domain membership of classes is unrealistic; domain generalization works assume that this information is available [1]. Moreover, we do not assume anything about the target, which may contain any subset of classes observed in the source domain. Therefore, we sincerely urge the Reviewer to reconsider their scores.\n\n**2. Comments about the algorithm structure:**\n> W1 - The simplicity of the proposed methodology ...\n\nWe would like to respectfully disagree. Drawing from contrastive and fairness learning literature to address domain-linked class DG is highly non-trivial. Fairness objectives minimise divergences between a model\u2019s output on a class regardless of protected attribute [4]; this requires a class to be expressed in different protected attributes. However, we cannot compare model performance for a class across domains since some are domain-linked. To overcome these challenges we use loss values across domain-shared and domain-linked classes (eq 5) as a surrogate for fairness. Although counter-intuitive, successful DG approaches do not seek to capture the variances across different domains but to be **invariant** to them; see [1] and the references therein. Therefore, our method draws discriminative representations from domain-shared classes to benefit domain-linked ones.\n\n> W2 - ...more nuanced approach...genuinely captures...underlying complexities...\n\nWe also respectfully disagree that FOND does not genuinely capture and transfer the underlying complexities. On the contrary, our results and ablations consistently demonstrate how FOND significantly outperforms, even when tested on novel domains, in our rigorous experimental set-up. Moreover, the T-SNE plots demonstrate how our methodology is able to transfer discriminative characteristics for domain-linked classes. We also introduce this task to the community to spark further research, an additional goal of our work.\n\n**3. Misconception about domain/class label accessibility in Domain Generalization:**\n> Q1 - Is it common in this field to define a dataset comprising both inputs and labels as a domain, as done in this paper?\n\n> W4 - The assumption of awareness on domain-shared classes and domain-linked classes are also not realistic.\n\nYes, datasets such as PACS, VLCS, and OfficeHome are widely used as different domains in domain generalization literature [1,2,3]. Since DG assumes that source domain identities and labels are given, the assumption is in complete alignment with the literature.\n\n**4. Domain-Linked classes in the real-world:**\n> Q2 - The likelihood of encountering domain-linked classes in real-world...\n\nDomain-linked classes occur in real-world applications such as defect detection for quality control applications in manufacturing and food inspection.  In these applications, defect types (classes) vary by products (domain), with certain defects being observed only in certain products. This makes defect detection in new future products extremely challenging where, due to unobserved defects in new contexts, the accuracies of defect detection vary by their type. Specifically, since defects are linked to products, their detection in new products suffers since the model learns spurious correlations between the defect and the product. With its focus on overall accuracy, the current domain generalization methods are inadequate. This is where domain-linked domain generalization can greatly alleviate the performance gap by addressing generalization under these data scarcity issues.\n\n**5. Comments regarding nomenclature:**\n> The result of Theorem 1 appears overly direct...\n\nWe use the term \u201cTheorem\u201d as opposed to \u201cProposition\u201d since the result encapsulates an important result of the paper. This is the first result in domain generalization literature which establishes the conditions under which domain-shared classes are better off than domain linked ones. We are open to renaming based on reviewer\u2019s comments, but we would like to respectfully disagree that this is a weakness of the work since naming can be fixed. \n\n> The term \"domain-linked class,\" ... does not seem particularly intuitive...\n\nThank you for the feedback. We also considered 'domain-specific', but this term is also used in the literature in other contexts. Since this task has never been considered, we chose \u201cdomain-linked\u201d,  but we are open to other recommendations.\n\n**References:**\n\n[1] Zhou et al. Domain generalization: A survey. TPAMI 2022.\n\n[2] Gulrajani, Ishaan, and David Lopez-Paz. \"In Search of Lost Domain Generalization.\" ICLR. 2020.\n\n[3] Zhang, Xingxuan, et al. \"Nico++: Towards better benchmarking for domain generalization.\" CVPR. 2023.\n\n[4] Wang, Zeyu, et al. \"Towards fairness in visual recognition: Effective strategies for bias mitigation.\" CVPR. 2020."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2856/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700097858088,
                "cdate": 1700097858088,
                "tmdate": 1700097858088,
                "mdate": 1700097858088,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qk3aIW4y1K",
                "forum": "l0pPTGMqZt",
                "replyto": "GCYQvppGxS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2856/Reviewer_x5U3"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2856/Reviewer_x5U3"
                ],
                "content": {
                    "title": {
                        "value": "Response on the author's rebuttal"
                    },
                    "comment": {
                        "value": "Most concerns are resolved by the author's response.\nI would like to increase my score from 3 to 5. \nThe novelty issues remain unchanged."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2856/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700626573169,
                "cdate": 1700626573169,
                "tmdate": 1700626573169,
                "mdate": 1700626573169,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]