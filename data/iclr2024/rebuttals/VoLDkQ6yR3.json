[
    {
        "title": "Understanding Reconstruction Attacks with the Neural Tangent Kernel and Dataset Distillation"
    },
    {
        "review": {
            "id": "NS33PRG53M",
            "forum": "VoLDkQ6yR3",
            "replyto": "VoLDkQ6yR3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6267/Reviewer_kua5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6267/Reviewer_kua5"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the reconstruction attack, and shows that the reconstruction attack can recover all samples in the training data set. Studies are carried out on the properties of easily-reconstructed images."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper provides interesting experimental results. The main paper is clear and easy to understand."
                },
                "weaknesses": {
                    "value": "My major concern is about the theoretical results in this paper. The paper claims their theoretical results as one of their major contributions, but from the presentation in the paper, this contribution is not as sound as the empirical side.\n\nFor the two theorems, Theorem 1 and 2, their presentation needs improvement.\n*    For Theorem 1, one can intuitively understand its meaning, but it is hard to interpret the English sentence into a formal mathematical statement. The proof is also vague, with many descriptions but few math formulas and equations. It is hard to rigorously understand the mathematical meaning of this theorem, and it is also hard to check the correctness of the proof. The authors need to rewrite Theorem 1 (maybe leave an informal description in the main paper and postpone the full theory statement in the appendix) and provide a more rigorous proof.\n*    For Theorem 2, the derivation in the appendix is readable, but the theorem statement in the main paper needs to be more clear. However, when considering infinite width of the neural network, some derivations are missing: for example, in Page 19, the first \"->\" needs more details. Although k_{\\theta_0} -> k_{NTK}, the error terms are needed in the later derivation to show that a negligible |k_{\\theta_0}-k_{NTK}| really leads to a negligible error term in the first \"->\" in Page 19."
                },
                "questions": {
                    "value": "I think the empirical studies in this paper are sound but the theoretical parts are below the acceptance standard, so I give a score 5. Please consider improve the theorems, and update them either in the submission or reply in the rebuttal."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6267/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6267/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6267/Reviewer_kua5"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6267/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698613612122,
            "cdate": 1698613612122,
            "tmdate": 1699924305670,
            "mdate": 1699924305670,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "f5vO2g6UAt",
                "forum": "VoLDkQ6yR3",
                "replyto": "NS33PRG53M",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6267/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6267/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Comment Part 1"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their thoughtful critiques regarding the theory aspect of this paper, as well as recognizing the sound empirical findings. We would like to clarify the questions raised by the reviewer in this rebuttal, and these changes will make their way into the paper in future revisions.\n\n**Theorem 1**\n\nWe will reword the theorem as follows:\n\n**Theorem 1**\n If $L_\\textrm{reconstruction} \\to 0$ (from Eq. 7), as $w\\to \\infty $, then $X_R \\to X_T $ in probability for training data, $X_T$ on the unit hypersphere.\n\nThe proof follows closely with the outline provided in the text as is, but to clarify some bits which are possibly unclear, we rewrite the proof steps here:\n\\begin{align}\n   L_{recon} =  &\\quad \\Big\\|\\Delta \\theta - \\sum_{\\mathclap{\\alpha_j x_j \\in \\alpha^R, X_R}} \\alpha_j \\nabla_{\\theta_f} f_{\\theta_f} (x_j)\\Big\\|^2_2 =\\Big\\|\\sum_{\\mathclap{\\alpha_i, x_i \\in \\alpha^T, X_{T}}}{\\alpha_i \\nabla_{\\theta_0}f(x_i)} - \\sum_{\\mathclap{\\alpha_j x_j \\in \\alpha^R, X_R}} \\alpha_j \\nabla_{\\theta_f} f_{\\theta_f} (x_j)\\Big\\|^2_2 \\\\\n    &= \\Big\\|\\sum_{\\mathclap{\\alpha_i, x_i \\in \\alpha^T, X_{T}}}{\\alpha_i k_{\\theta_0}(x_i, \\cdot)} - \\sum_{\\mathclap{\\alpha_j x_j \\in \\alpha^R, X_R}} \\alpha_j k_{\\theta_f}(x_j, \\cdot)\\Big\\|^2_2 \n&\\to \\Big\\|\\sum_{\\mathclap{\\alpha_i, x_i \\in \\alpha^T, X_{T}}}{\\alpha_i k_{NTK}(x_i, \\cdot)} - \\sum_{\\mathclap{\\alpha_j x_j \\in \\alpha^R, X_R}} \\alpha_j k_{NTK}(x_j, \\cdot)\\Big\\|^2_2 \\mathbf{i.p.}\n\\end{align}\nDefine \n\\begin{align}\nP_T = \\sum_{\\alpha_i, x_i \\in \\alpha^T, X_{T}}{\\alpha_i\\delta(x_i)},\nP_R = \\sum_{\\alpha_j, x_j \\in \\alpha^R, X_{R}}{\\alpha_j\\delta(x_j)}\n\\end{align}\n\nWhich are both signed measures over $\\Omega = S^{d}$.\n\nThen we can rewrite \n\\begin{align}\n\\sum_{\\mathclap{\\alpha_i, x_i \\in \\alpha^T, X_{T}}}{\\alpha_i k_{NTK}(x_i, \\cdot)}\n\\end{align} as \n\\begin{align}\n\\int_{\\Omega} k_{NTK}(x, \\cdot) dP_T(x)\n\\end{align}, and likewise for $P_R$. Then, we have\n\n\\begin{align}\nL_{recon} \\to \\Big\\|\\int_{\\Omega} k_{NTK}(x, \\cdot) dP_T(x) - \\int_{\\Omega} k_{NTK}(x, \\cdot) dP_R(x)\\Big\\|^2_2 = MMD_{k_{NTK}}(P_R, P_T)\n\\end{align}\n\nThis is the maximum mean discrepancy described in [1]. From [2], we have that $k_{NTK}$ being universal over $S^{d}$ [3] implies that i $MMD_{k_{NTK}}(P_R, P_T) = 0$ implies that $P_R = P_T$, i.e. $X_R = X_T$. $L_{recon} \\to 0$, as assumed, so $MMD_{k_{NTK}}(P_R, P_T) \\to 0$, in probability. As $k_{NTK}$, and the MMD are continuous in their inputs, this implies that $X_R \\to X_T$ in probability as well.\n\nWe hope that this clarifies the proof. We acknowledge that the description in the text is rather space constrained and in future revisions we will have the more informal statement in the main text, and defer the proof to the appendix, as suggested by the reviewer.\n\n[1]Arthur Gretton, Karsten M. Borgwardt, Malte J. Rasch, Bernhard Sch \u0308olkopf, and Alexander Smola.\nA kernel two-sample test.\n\n[2] Jacot, A., Gabriel, F., & Hongler, C. (2018). Neural Tangent Kernel: Convergence and Generalization in Neural Networks.\n\n[3] Bharath K. Sriperumbudur, Kenji Fukumizu, and Gert R.G. Lanckriet. Universality, characteristic\nkernels and rkhs embedding of measures.\n\n[4] Timothy Nguyen, Zhourong Chen, and Jaehoon Lee. Dataset meta-learning from kernel ridge-\nregression."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6267/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699913734586,
                "cdate": 1699913734586,
                "tmdate": 1699913734586,
                "mdate": 1699913734586,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pW5U1Lzu1Y",
                "forum": "VoLDkQ6yR3",
                "replyto": "qpO3mhbNXD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6267/Reviewer_kua5"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6267/Reviewer_kua5"
                ],
                "content": {
                    "title": {
                        "value": "Followup in the proof of Theorem 1"
                    },
                    "comment": {
                        "value": "I appreciate the authors clarify the theory part. For Theorem 1, could you elaborate more on why both $f_{\\theta_0}$ and $f_{\\theta_f}$ converges to the same kernel? Do you use existing results in literature?"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6267/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699921748021,
                "cdate": 1699921748021,
                "tmdate": 1699921748021,
                "mdate": 1699921748021,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "D7GSxT8rEo",
                "forum": "VoLDkQ6yR3",
                "replyto": "IDqY6XBq1g",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6267/Reviewer_kua5"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6267/Reviewer_kua5"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks, I have raised my score from 5 to 6. Please help update all the changes in the paper, and also add the references when using the convergence of NTK."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6267/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699924465898,
                "cdate": 1699924465898,
                "tmdate": 1699924465898,
                "mdate": 1699924465898,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ldzQUENlip",
            "forum": "VoLDkQ6yR3",
            "replyto": "VoLDkQ6yR3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6267/Reviewer_GBp6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6267/Reviewer_GBp6"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors investigated the reconstruction attack in the view of neural tangent kernel (NTK). From a well formulated description, the authors showed interesting results with both theoretical and practical meaning."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The memory of deep neural networks is of great interests and importance. It is believed that the memory and also the memorization is closely related to the training dynamics, which is however not clearly investigated. Thus, I personally like the way of modelling the data reconstruction by NTK, which indeed capture the main properties on memorization dynamics. Though there are still many simplification, the good performance demonstrate the rationality of the modelling. So I think the main strengths include:\n\n- A novel and interesting way of modelling memorization from training dynamics.\n\n- Theoretical discussion well coincides with numerical experiments.\n\n- Clear discussion on the weakness, which actually could inspire future works."
                },
                "weaknesses": {
                    "value": "The main weakness are for some unclear settings. Please see the questions below."
                },
                "questions": {
                    "value": "In the current version, the reconstruction performance is related to the number of training samples as well as the property of the samples. How about the effect of data dimension. Especially, the author cast the reconstruction loss as a sparse coding, also Haim et al. (2021) regarded the training process as encoding. Then, can the authors obtain some conclusion about data dimension?\n\nThe reconstruction problem is a complicated optimization problem and the result could be totally different when different initial solutions are used. I notice that in algorithm 2 \"randomly initialized reconstruction images\" are used. Then how about the divergence of the reconstruction result? Is that necessary to use special initialization, e.g., an image in one of the two classes, an image from another class, a natural image of which the class is not in the training set, or a random generated matrix?\n\nAfter reading the rebuttal and good discussion, I would like to increase the score from 6 to 8. But please talk more about the link to e.g., GradViT: Gradient Inversion of Vision Transformers; Deep Leakage from Gradients, which can use local gradient information (even the model is not well trained) to reconstruct the training samples."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6267/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6267/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6267/Reviewer_GBp6"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6267/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698641426798,
            "cdate": 1698641426798,
            "tmdate": 1700580089567,
            "mdate": 1700580089567,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VITRMWiG8E",
                "forum": "VoLDkQ6yR3",
                "replyto": "ldzQUENlip",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6267/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6267/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank the reviewer for acknowledging the contributions of this paper in linking the training dynamics of neural networks with the memorization phenomenon, and in recommending its acceptance. We would like to address the questions raised by the reviewer here:\n\n**Data Dimension** Indeed the efficacy of our reconstruction attack depends on the dimension of the data. Previous work has shown that the quality of the NTK approximation suffers with high data dimension [1,2], and as our method relies on the NTK approximation to prove theorem 1, we expect our attack to be less effective with larger data dimension. Indeed, in appendix J.2. (page 26) and figure 18 and 19 (page 25), we perform the same attack on a higher resolution dataset Tiny-Imagenet (resolution 64x64x3). We see that reconstruction quality suffers, but we are still able to reconstruct images with high quality. Combining the approach provided in this paper with prior work on understanding quality of NTK approximation [1,2] could lead to a more robust definition of how networks \u201cencode\u201d their data points, which is the subject of future work.\n\n\n**Image Initialization** In all our experiments we initialize reconstruction images with random noise, ensuring that we have no a priori knowledge about the dataset. We will clarify this in future revision. We observe that our method is not sensitive to the initialization scheme in practice, although we acknowledge that the reconstruction loss is provably non-convex, but in practice this does not seem to be a major concern.\n\n[1] Bombari, S., Amani, M. H., & Mondelli, M. (2023). Memorization and Optimization in Deep Neural Networks with Minimum Over-parameterization. \n\n[2] Adlam, B., & Pennington, J. (2020). The Neural Tangent Kernel in High Dimensions: Triple Descent and a Multi-Scale Theory of Generalization."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6267/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699913357317,
                "cdate": 1699913357317,
                "tmdate": 1699913357317,
                "mdate": 1699913357317,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ZYRvkk3vYu",
                "forum": "VoLDkQ6yR3",
                "replyto": "ldzQUENlip",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6267/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6267/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We were wondering if the reviewer has had a chance to consider our rebuttal, and if there were still any remaining concerns which we can address before the discussion period ends."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6267/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700333028783,
                "cdate": 1700333028783,
                "tmdate": 1700333028783,
                "mdate": 1700333028783,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "a1qCrt7Mlu",
                "forum": "VoLDkQ6yR3",
                "replyto": "ZYRvkk3vYu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6267/Reviewer_GBp6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6267/Reviewer_GBp6"
                ],
                "content": {
                    "title": {
                        "value": "thanks and one more question"
                    },
                    "comment": {
                        "value": "Thanks for the authors' discussion on the dimensionality and initialization. Both I think there are lots of interesting things to think. For example, the learning behaviour of DNN is closely linked to different initializations.\n\nOne more question is about the link to approaches that can reconstruct images from gradients: e.g., GradViT: Gradient Inversion of Vision Transformers; Deep Leakage from Gradients. Is that the case that they use local gradient but you use the \"global one\", i.e., the gradient of the linearly approximated system."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6267/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700363527227,
                "cdate": 1700363527227,
                "tmdate": 1700363527227,
                "mdate": 1700363527227,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "w6gtPMnpSl",
                "forum": "VoLDkQ6yR3",
                "replyto": "5mKFr6HvAh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6267/Reviewer_GBp6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6267/Reviewer_GBp6"
                ],
                "content": {
                    "title": {
                        "value": "thanks"
                    },
                    "comment": {
                        "value": "Thanks for your further explanation. Gradient inversion attacks can reconstruct training samples even when the NN has not converged (the quality is lower than using those attack on well-trained NN). At least, it empirically shows the reconstruction may come from local properties rather than the whole training process. I just write this idea here since may be there is a bit difference to the discussions in this paper. BUT I do not to say this paper is not good. On contrast, I suggest acceptance of this paper. So I would like to increase the score to 8."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6267/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700579926316,
                "cdate": 1700579926316,
                "tmdate": 1700579926316,
                "mdate": 1700579926316,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "RrocTUkBO1",
            "forum": "VoLDkQ6yR3",
            "replyto": "VoLDkQ6yR3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6267/Reviewer_FNQS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6267/Reviewer_FNQS"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a new, more stable method for performing reconstruction attacks against neural networks based on the neural tangent kernel. This method requires access to both the initial weight state and the trained weight state, but does not require any information about the data distribution. A number of ablation studies confirm conventional wisdom that larger networks essentially memorize their training sets, that outlier datapoints are most vulnerable to reconstruction attacks, and that there is a strong mathematical connection between reconstruction attacks and dataset distillation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper develops a very nice algorithm for dataset distillation based on inducing point methods. Figure 8 in particular shows the value of the proposed approach. The underlying theoretical connections to dataset inversion provide confidence in the method.\n\nThe paper provides thorough experimental evidence for the theoretical claims. The datasets used (restricted MNIST and CIFAR) are small, but this is to be expected with a computationally-intensive object like the NTK. The reconstruction attacks on ImageNet are impressive.\n\nThe discussion about the choice of kernel in Appendix I is interesting. The authors should at least incorporate the insight about combining initial and final weight states into the main text. Likewise, why are the results on more complex architectures reserved for Appendix J? These are interesting results that should be incorporated into the paper, if even briefly."
                },
                "weaknesses": {
                    "value": "The authors claim that \u201coutliers\u201d are more vulnerable to reconstruction attacks, but this notion of \u201coutlier\u201d is not well defined up front. I believe that your technical definition for outliers is points that have high $\\alpha$ values (i.e. points that are \u201chard to fit\u201d), but this does not necessarily mean that these are points that are distant e.g. under the Euclidean metric in the input space.\n\nThe text on most of the figures is so small it makes them hard to read, even on a screen.\n\nReconstruction plots are not explained until the first paragraph of Page 6, but the plots appear as early as page 4. This creates a readability problem, since the construction of these plots is not self-evident.\n\nIt would be nice to have a central definition of all model variants (e.g. RKIP, RKIP-finite). These definitions are currently spread across the paper.\n\nSmall issues:\n* This phrase in the abstract doesn\u2019t make sense: \u201cof its effective regime **which** datapoints are susceptible to reconstruction.\u201d\n* The statement that non-privacy preserving networks are \u201cuseless\u201d is probably a bit hyperbolic in the introduction, this is very application-dependent.\n* In Table 1, specify whether the values are \u201caccuracy\u201d."
                },
                "questions": {
                    "value": "1. Can you make claims about the effect of self-supervised learning on the effectiveness of your reconstruction attacks? Does your method naturally extend to structured outputs, not just scalar outputs?\n2. Do you have any speculation how informative your results will be for networks trained with different losses than MSE? Is this a simplifying assumption to enable your proofs or a factor that could significantly change the structure of the empirical NTKs your method uses?\n3. Is there an underlying assumption in (1) that there is a prior (i.e. weight decay) on the parameters of the network?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6267/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6267/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6267/Reviewer_FNQS"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6267/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699453079376,
            "cdate": 1699453079376,
            "tmdate": 1699636685631,
            "mdate": 1699636685631,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Crjg3NEP6o",
                "forum": "VoLDkQ6yR3",
                "replyto": "RrocTUkBO1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6267/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6267/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank the reviewer for acknowledging our contributions and recommending our acceptance. We would like to take this space to address some of their concerns.\n\n**Various presentation points**\nWe apologize for the poor readability of some of the figures. Indeed we were very constrained in terms of space, and consequently had to reduce figure sizes, as well as move certain results to the appendix, which is why the results on convolutional architectures were moved there. We will address these concerns, along with the other minor concerns pointed out by the reviewer in future revisions.\n\n**Definition of outliers**\nWe define an outlier to be a datapoint which is harmful/uninformative to the training procedure, has a strange/unusual visual appearance or is far away from other training data in terms of training dynamics. Moreover, there is no agreed-upon definition in the literature. We show that easily reconstructed images fit these three properties as follows:\n1. Harmful to the training procedure/uninformative - see fig. 6, in which we show that removing these data points do not adversely affect training\n2. Strange visual appearance - see figures 25-40 in the appendix, where we see that the more easily reconstructed images tend to have more \u201cunusual\u201d features (i.e. solid-colored backgrounds for CIFAR-10, faint lines for MNIST)\n3. Difficulty to fit - see the discuss of alpha values\nWe do not believe that L2 distance in the euclidean space is a good definition for an \u201coutlier\u201d data point when working with neural networks, as it does not take into account data structure, or the training procedure. We believe that the qualities that we looked at in terms of defining an outlier are suitable properties and reflect a more nuanced view which takes into account training dynamics and dataset properties. We are happy to discuss this further.\n\n**Self Supervised Learning and output structure**\nWe note that our attack works with vector outputs, as seen by the results on multiclass classification. Extended our work to self-supervised learning may be more difficult as self-supervised learning typically occurs outside of the NTK regime, i.e. there is a large amount of representation learning, which is not modeled by the NTK. However, we believe that our work fills a vital first-step in understanding reconstruction attacks in a more simplified regime.\n\n**Non-MSE losses**\nOur method should work on non-MSE losses such as cross-entropy. We include a discussion in appendix G.2. The main requirement of our attack to work is that the change in network parameters lies in the span of the datapoint gradients, and that these gradients do not change significantly over the course of training. This is fulfilled by wide neural networks under any loss (see [1], appendix B for more details). We chose to focus on MSE loss in this work as it allows a closed for solution for the $\\alpha$ values, simplifying analysis, but the analysis still applies. In the proof for Theorem 1, we do not explicitly require MSE loss, so this proof still holds for non-MSE losses in the kernel regime.\n\n**Weight Decay**\nWe do not assume weight decay, but including weight decay would not affect the theoretical results in our paper. Like in the answer to the previous question, weight decay does not affect whether the weight changes remain in the span of the dataset gradients, and thus our analysis still holds. Note that we can have a similar effect to weight decay with early stopping, and we carefully ablate the effects of early stopping in appendix G.1.\n\nWe hope that these points address the reviewers main concerns and we would be happy to discuss further with them.\n\n[1] Lee, J., Xiao, L., Schoenholz, S. S., Bahri, Y., Novak, R., Sohl-Dickstein, J., & Pennington, J. (2020). Wide neural networks of any depth evolve as linear models under gradient descent"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6267/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699913295107,
                "cdate": 1699913295107,
                "tmdate": 1699913324896,
                "mdate": 1699913324896,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Gv1XG4cTXS",
                "forum": "VoLDkQ6yR3",
                "replyto": "Crjg3NEP6o",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6267/Reviewer_FNQS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6267/Reviewer_FNQS"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your reply"
                    },
                    "comment": {
                        "value": "I appreciate the authors' detailed response. This is an interesting paper. I would like to keep my score of 6."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6267/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700452737732,
                "cdate": 1700452737732,
                "tmdate": 1700452737732,
                "mdate": 1700452737732,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]