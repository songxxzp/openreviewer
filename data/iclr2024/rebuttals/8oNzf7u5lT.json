[
    {
        "title": "Pylic: Leveraging Source Code for Planning in Structured Environments"
    },
    {
        "review": {
            "id": "DgPdqlwrHv",
            "forum": "8oNzf7u5lT",
            "replyto": "8oNzf7u5lT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6159/Reviewer_uEX5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6159/Reviewer_uEX5"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents an approach that uses the code of the simulator (or I would the analytical model) and a set of interesting events to solve problems with complex dynamics system. The approach first searches over a sequence of interesting events that reach a goal and then reduces achieving each interesting event (as I understand) as an optimization problem."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- The paper is easy to read. It nicely uses a running example to ground the concepts discussed in the paper. \n\n- The paper makes its assumptions clear which makes the paper really understandable."
                },
                "weaknesses": {
                    "value": "While the paper presents attempts to solve an interesting approach, it has a few significant limitations: \n\n- In my opinion, the paper seriously lacks novelty. It invents (or introduces) new terms for concepts that have long existed. E.g., the main contribution claimed by the paper is using **code of the simulator** for solving the problem faster. However, this is nothing but having access to an analytical model of the system. Why to complicate the paper? The second term would be the **meaningful events**. The events that are required or necessary to be achieved in order to reach the goal state. These is analogous to landmarks [1] or critical regions [2]. Landmarks and critical regions have been extensively used in planning and robotics literature. \n\n- The approach requires the analytical of the model of the system as well as a set of landmarks or critical regions to be provided upfront. This does not only require a domain expert at the train time but at the test time as well. Which is infeasible to have. Especially, when a lot of research has been focused on learning these landmarks or critical regions automatically as well as approaches than learn policy without explicitly having access to an analytical model of the environment and treating the simulator as a blackbox. \n\n- It is not clear from the paper that how a sequence of low-level action is generated to reach each meaningful event. My educated guess is the problem is reduced to an optimization problem but it has to be clear from the paper. \n\n- Lastly, the empirical evaluation is extremely weak. Especially, the choice of the baselines. Given that this approach is a model-based optimization approach. This should be compared with a hierarchical planning approach [2,3,4] or a hierarchical optimization approach [5] or a model-based RL approach. \n\n### References \n\n\n[1] Hoffmann, J\u00f6rg, Julie Porteous, and Laura Sebastia. \"Ordered landmarks in planning.\" Journal of Artificial Intelligence Research 22 (2004): 215-278.\n\n[2] Shah, Naman, and Siddharth Srivastava. \"Using Deep Learning to Bootstrap Abstractions for Hierarchical Robot Planning.\" Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems. 2022.\n\n[3] Garrett, Caelan Reed, Tom\u00e1s Lozano-P\u00e9rez, and Leslie Pack Kaelbling. \"Pddlstream: Integrating symbolic planners and blackbox samplers via optimistic adaptive planning.\" Proceedings of the International Conference on Automated Planning and Scheduling. Vol. 30. 2020.\n\n[4] Shah, Naman, et al. \"Anytime integrated task and motion policies for stochastic environments.\" 2020 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2020.\n\n[5] Toussaint, Marc. \"Logic-Geometric Programming: An Optimization-Based Approach to Combined Task and Motion Planning.\" IJCAI. 2015."
                },
                "questions": {
                    "value": "Please refer to the previous section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6159/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6159/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6159/Reviewer_uEX5"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6159/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698790047752,
            "cdate": 1698790047752,
            "tmdate": 1699636668397,
            "mdate": 1699636668397,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9XCho2vGpK",
                "forum": "8oNzf7u5lT",
                "replyto": "DgPdqlwrHv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6159/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6159/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We greatly appreciate your insightful comments and questions, which have helped us improve our manuscript and also inform ongoing efforts. We follow up on your comments below.\n\n### On simulator code\n\nWe agree that source code is ultimately an analytical model. However, we argue that source code has key features that make it unlike other forms of analytical models. Specifically, our focus on leveraging control flow makes it possible to easily reuse parts of the model when communicating domain knowledge. Our claim is that this allows complex search spaces to be described efficiently by an expert user, allowing the system to find solutions to a problem domain, as shown in the experiments.\n\nThis is why the focus on source code is not inconsequential and is not equivalent to a general analytical model with no assumptions about its internal structure.\n\n### On meaningful events\n\nWe appreciate the connection to landmarks and critical regions, and we agree that the concept of meaningful events is related to concepts used in other planning frameworks. Note that our \"meaningful events\", however, have additional assumptions specific to our framework, which would make the use of, e.g., the terms \"landmarks\" or \"critical regions\" incorrect (even if, broadly speaking, they are related). This is why we decided to use a different term. We have revised our manuscript to explicitly reference the related concepts.\n\n### On requiring a domain expert at test time\n(Also included in response to Reviewer ppCk)\n\nWe want to clarify that the domain knowledge provided to the system is general to a problem domain and not bound to a particular problem instance. We believe this important point was not efficiently communicated in our manuscript. Specifically, the user provides general principles to search over sequences of meaningful events for an entire problem domain (section 3.2). We have revised our manuscript to clarify this.\n\nThus, we do not \"require\" the domain expert for any particular task; the expert is only required to describe the search over sequences of meaningful events for a problem domain.\n\n### On generating the sequence of low-level actions\n\nYour assumption is correct; the problem is reduced to an optimization problem. This is described in Section 3.1 (now 3.2). We have revised the manuscript to make the description of the framework easier to follow.\n\n### On the choice of baselines\n(Also included in response to Reviewer wE34)\n\nWe agree that comparing our approach with pure RL and MPC approaches is not completely straightforward because we allow users to provide structured domain knowledge. We also agree that the techniques you list would be good candidates for further benchmarking.\n\nSpecifically, we are working on a comparison of our technique with planning techniques that leverage temporal specifications. This is more of an apples-to-apples comparison because some of these techniques also allow (and rely) on a human to provide the domain knowledge to make a domain of tasks feasible, and this knowledge is encoded at a comparable level of abstraction."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6159/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700455871815,
                "cdate": 1700455871815,
                "tmdate": 1700455871815,
                "mdate": 1700455871815,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "J9I7TmDEgJ",
                "forum": "8oNzf7u5lT",
                "replyto": "9XCho2vGpK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6159/Reviewer_uEX5"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6159/Reviewer_uEX5"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "I appreciate authors' response to the issues raised. The response has resolved some of the issues, however, I still do not agree with authors' on some of the points. \n\n- Authors still claim that \"meaningful events\" and \"landmarks\" or \"critical regions\" are different but they do not provide any information on how.\n\n- The authors claims that the approach does not require an expert at the test time but I do not agree. Meaningful events are different for different problems in the same domain. The alternative is to exhaustively list all possible meaningful events a priori which I don't feel is possible neither mentioned in the paper. \n\n- The authors claim that their reason for using simulator code and not the analytical model ( IMO both are the same) is to encourage reuse. However, this is not at all clear from the paper. Here the expert just not have to be expert in the domain but also at the simulator. There details that are important and in a way significant to your approach needs to be extremely clear from the paper."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6159/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700655293381,
                "cdate": 1700655293381,
                "tmdate": 1700655293381,
                "mdate": 1700655293381,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "VICjRqpDb5",
            "forum": "8oNzf7u5lT",
            "replyto": "8oNzf7u5lT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6159/Reviewer_ppCk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6159/Reviewer_ppCk"
            ],
            "content": {
                "summary": {
                    "value": "The paper describes an approach that utilizes code inspection techniques to locate discontinuities in a task together with user-provided critical junction points to formulate a tree-based search problem. The approach assumes that solutions between junction points can be found by local numerical search methods while the global sequencing is guided by the user-provided \"meaningful events\"."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The general idea of the work is interesting in that it attempts to leverage program verification approaches and logic to solve complex global optimization problems."
                },
                "weaknesses": {
                    "value": "While the general idea is interesting, there are many issues with the paper in its current form.\n\nThe paper argues that other methods rely on specialized representations, which makes them hard or inconvenient to use. However, the proposed method requires the user to specify so-called \"meaningful events\". Judging from the examples and the description, this would appear to be an even more onerous requirement as they have to be defined by the end-user instead of the designer of a general method for particular problem scenarios. This aspect is insufficiently discussed in the paper, making it unclear that this approach is practical in contrast to other methods such as reinforcement learning, model-based control, or Monte Carlo tree search.\n\nThe core aspect of the work revolves around tracing the code logic to find control flow statements. In that context, the paper repeatedly mentions simulators as the code to be traced. However, in the experiments, only one example traces through something akin to a simulator and in all other instances, some generic logic code is traced. Therefore, the mention of simulators is quite confusing as in no instance is a proper simulator, such as pybullet, mujoco, Isaac Sim, drake, etc., traced. It also remains unclear that the discontinuities in the simulation that this process should find are necessarily \"telegraphed\" by control flow statements rather than pure linear algebra, which the proposed approach would not appear to register. Tracing general program execution can still be interesting, as the experiments show. However, the description of the applications and properties described in the main body of the text is misleading. Without seeing the experiments, I would have expected the proposed method to be able to trace through complex physics engines as employed by Isaac sim or pybullet.\n\nThe proposed method uses quite a few components and joins them together. While an overview is provided in Figure 1, this figure is never used in the text to help the reader understand how things connect. As such, it is hard to follow where the different pieces go and how they interact. For example, there is a connection between user-defined events, code tracing, and trace predicates. This can be gleaned from the text to some extent, but making the connections more easily understood and more evident would improve the readability of the paper significantly.\n\nThe paper states that the local search is sufficient to find parameters to reach the next meaningful event. However, it is not mentioned how this can be guaranteed or why this should hold in the first place. Are there theoretical guarantees that can alert the user when this is impossible, or does the user have to add \"meaningful event\" specifications until things can be solved?\n\nThe experimental section, while containing several experiments, is lacking in detail. There are detailed descriptions of the experimental setups, yet the discussion of the results is unsatisfactory as they provide no real insight. Furthermore, the choice of baselines and problem setups is perplexing. The biggest issue is that some of the experiments would be ideally suited for Monte Carlo tree search methods, especially given the tree search nature of the proposed system, yet approaches based on this technique are absent. Another aspect is that the problem setups for different methods are not identical,  making it unclear whether the results are comparable. A good example of this is 4.2, where the proposed method operates on a state representation of button states while the RL and MPC baseline operate on an entirely different state space.\n\nWhile the idea, in general, is interesting, I cannot recommend this paper for publication in its current state."
                },
                "questions": {
                    "value": "- Some of the description and experimental tasks used give a task and motion planning vibe, would such tasks and methods be sensible comparisons for this work?\n- Is the need to have traced control flow labels, predicates, and user-specified \"meaningful events\" not more challenging and domain-specific than representations required by other approaches?\n- How can the assumption of local searches finding connections between the sequence of \"meaningful events\" be guaranteed?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6159/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698850433944,
            "cdate": 1698850433944,
            "tmdate": 1699636668259,
            "mdate": 1699636668259,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "eBJV1iZFbO",
                "forum": "8oNzf7u5lT",
                "replyto": "VICjRqpDb5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6159/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6159/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We greatly appreciate your insightful comments and questions, which have helped us improve our manuscript and also inform ongoing efforts. We follow up on your comments below.\n\n### Question 1: baselines\n(Also included in response to Reviewer wE34)\n\nAs you correctly point out, our proposed approach currently relies on a human to provide the space of meaningful events for a given problem domain (and relate them to the source code). Thus, comparing our approach with pure RL and MPC approaches is not completely straightforward because we allow users to provide structured domain knowledge.\n\nWe are working on a comparison with planning techniques that leverage temporal specifications. This is more of an apples-to-apples comparison because some of these techniques also allow (and rely) on a human to provide the domain knowledge to make a domain of tasks feasible, and this knowledge is encoded at a comparable level of abstraction.\n\n### Question 2: user effort\n(Also included in response to Reviewer wE34)\n\nWe argue that the amount of effort required by our approach is similar to, or smaller than, techniques that leverage domain knowledge during planning. This is because, in our framework, the user can encode complex conditions (e.g., a collision) simply by referencing the corresponding constructs in the meaningful event predicates without reimplementing them from scratch (provided that such constructs are present in the simulator, which is one of our assumptions).\n\n### Question 3: How can the assumption of local searches finding connections between the sequence of \"meaningful events\" be guaranteed?\n\nWe assume that the user has provided events for which this assumption is true. We have revised our manuscript to further highlight this assumption.\n\nIn the special case where meaningful events induce convex problems, the connections between events can be guaranteed to be reachable with gradient descent. However, in general, the user is subject to the limitations of the optimization method used to define meaningful events.\n\n### On specifying meaningful events\n\nWe want to clarify that the domain knowledge provided to the system is general to a problem domain and not bound to a particular problem instance. We believe this important point was not efficiently communicated in our manuscript. Specifically, the user provides general principles to search over sequences of meaningful events for an entire problem domain (section 3.2). We have revised our manuscript to clarify this.\n\n### On tracing simulators\n\nIt is precisely the logic that reflects the structure of a problem domain that can be related to domain knowledge. As we show, this key logic can be low-level dynamics (e.g., collision handling), but more often it will be logic that leverages a low-level physics engine (e.g., the button dynamics in \"Password locomotion\"). This is why, in the experiments, we explain how we leverage code at the appropriate level of abstraction for a given problem domain.\n\n### On the connections between components of the system\n\nThe different components come together in Algorithm 2 (now Algorithm 1). We have revised the manuscript Methods section to make the description easier to follow and the connections between components more explicit."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6159/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700455730108,
                "cdate": 1700455730108,
                "tmdate": 1700455730108,
                "mdate": 1700455730108,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rrjaKp7q37",
            "forum": "8oNzf7u5lT",
            "replyto": "8oNzf7u5lT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6159/Reviewer_wE34"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6159/Reviewer_wE34"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a novel method of using trace information from the source code of a simulator to more efficiently solve planning problems. The method is evaluated on three simulation examples where it compares favorably to RL (SAC) and sampling-based MPC."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The idea of using the source code of a simulator to speed up planning is interesting and appears novel.\n- The paper is fairly well-written, but there are a lot of things going on\n- The benchmark results are encouraging"
                },
                "weaknesses": {
                    "value": "The fundamental limitation of this approach is that it needs a human to extract what they call \"meaningful events\" that serves as the - foundation of the planning tree. This makes comparisons against model-free methods like RL and sampling-based MPC rather apples-to-oranges. If this step was more automatic, or shown to be very simple, I think the paper would be much stronger.\n- This is exacerbated by not using any standard benchmarks that I can see.  \n- The performance difference compared to model-free approaches also does not appear that large in two of three experiments. Ultimately if this is useful or not probably depends on the users proficiency in the syntax of the proposed framework and the level of understanding of the simulator code. Not sure if a user study might help.\n\nMinor:\n- The success rate curves could also use a confidence interval (or quartiles)."
                },
                "questions": {
                    "value": "- Why did you not include any standard benchmark environments from e.g. RL as you are comparing against RL?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6159/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698878526975,
            "cdate": 1698878526975,
            "tmdate": 1699636668128,
            "mdate": 1699636668128,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SOJfefUuCv",
                "forum": "8oNzf7u5lT",
                "replyto": "rrjaKp7q37",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6159/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6159/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We greatly appreciate your insightful comments and questions, which have helped us improve our manuscript and also inform ongoing efforts. We follow up on your comments below.\n\n### On \"comparison with RL and MPC is not apples-to-apples\"\n\nAs you correctly point out, our proposed approach currently relies on a human to provide the space of meaningful events for a given problem domain (and relate them to the source code). Thus, comparing our approach with pure RL and MPC approaches is not completely straightforward because we allow users to provide structured domain knowledge.\n\nWe are working on a comparison with planning techniques that leverage temporal specifications. This is more of an apples-to-apples comparison because some of these techniques also allow (and rely) on a human to provide the domain knowledge to make a domain of tasks feasible, and this knowledge is encoded at a comparable level of abstraction.\n\nFinally, we argue that the amount of effort required by our approach is similar to, or smaller than, that required by these techniques. This is because the user can encode complex conditions (e.g., a collision) simply by referencing the corresponding constructs in the meaningful event predicates without reimplementing them from scratch (provided that such constructs are present in the simulator, which is one of our assumptions).\n\n### On \"standard RL benchmarks\"\n\nThe reason we did not include the standard RL benchmarks is that our tool requires the code that has to be traced to be Python code. However, in the OpenAI Gym continuous tasks (e.g., half-cheetah, hopper, etc.), the code that encodes the structure of the task is the Mujoco simulator, which is a binary of C source code.\n\nBecause of this, we designed the --arguably harder-- \"Password Locomotion\" task, which leverages the rigid body dynamics as part of a more complex simulation. The simulator makes use of Mujoco but encodes the logic that handles the dynamics of pressing buttons and unlocking the goal in Python.\n\n### On success rates curves confidence intervals\n\nThese curves are an exact measurement: they are the cumulative number of tasks that are solved over the course of the experiment (which itself consists of multiple tasks). In other words, these curves correspond exactly to the count of successful tasks as the experiment progresses (i.e., they are not an aggregate value), and thus have no confidence interval associated."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6159/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700455496912,
                "cdate": 1700455496912,
                "tmdate": 1700455496912,
                "mdate": 1700455496912,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "S8zvv3uux6",
                "forum": "8oNzf7u5lT",
                "replyto": "SOJfefUuCv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6159/Reviewer_wE34"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6159/Reviewer_wE34"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "I thank the authors for the candid responses. My score remains unchanged as I think the paper needs to do more to show practical utility. The other reviewers also had some good suggestions. One idea could be a user study where you show that this is less work, however not comparing on any standard benchmark because you require python is also a pretty big problem. Maybe you can find at least some benchmarks from other papers that are only in Python. E.g. the simple ones like Lander, pendulum swing-up etc. I'm sure there are more."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6159/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700505871085,
                "cdate": 1700505871085,
                "tmdate": 1700505871085,
                "mdate": 1700505871085,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]