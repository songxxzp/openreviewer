[
    {
        "title": "Unveiling and Manipulating Prompt Influence in Large Language Models"
    },
    {
        "review": {
            "id": "B6zlOS3B3c",
            "forum": "ap1ByuwQrX",
            "replyto": "ap1ByuwQrX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3427/Reviewer_rNoS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3427/Reviewer_rNoS"
            ],
            "content": {
                "summary": {
                    "value": "Existing saliency methods have problems that are inconsistent with LLM generation goals or rely heavily on linear assumptions. To address this, this paper proposes token distribution dynamics (TDD) to unveil and manipulate the role of prompts in generating LLM outputs. TDD leverages the interpreting capabilities of the language model head to assess input saliency. It projects input tokens into the embedding space and then estimates their significance based on distribution dynamics over the vocabulary. Experiments reveal that the TDD surpasses baselines in elucidating the causal relationships between prompts and LLM outputs and achieves good results on two prompt manipulation tasks for control text generation tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The motivation of this paper is clear, and the method is simple and effective. The proposed token distribution dynamics (TDD) can unveil and manipulate the role of prompts in generating LLM outputs and it simply depends on the dynamic of token distribution.\n2. The method proposed in this paper works well and has achieved improved results on 11 datasets.\n3. In addition to achieving great improvement in elucidating the causal relationship between prompts and LLM output, the method in this paper also demonstrates its potential application value in controllable text generation tasks."
                },
                "weaknesses": {
                    "value": "1. The TDD method is based on multiple assumptions listed at the bottom of page 4. Some assumptions are strong without any theoretical and experimental proof, especially the first and second assumptions.\n2. For controllable text generation, this paper uses simple meaningless space tokens as alternative tokens in toxic language mitigation. In sentiment direction, this paper uses simple key tokens \u201cpositive\u201d or \u201cnegative\u201d as alternative tokens. Although this can prove that the method in this paper has potential application value in controllable text generation tasks, this method is too simple for practical applications. And whether such a way will impact the reasonableness of the evaluation of the results.\n3. In controllable text generation tasks, only automatic evaluation is used, manual evaluation is lacking, and the indicators used in automatic evaluation are relatively simple. It is difficult to fully reflect the quality of the generated text, especially when there is no ground truth for the task of this paper.\n4. LLMs can already complete controllable text generation tasks well, such as by giving LLMs toxic prefixes and designed prompts, making LLMs generate non-toxic text. This paper lacks a comparison with them, which may reduce the application value of this work.\n5. The attribution of the prompt for the next token prediction is a simple problem that has been explored in many text classification tasks. The SOTA method such as integrated gradients (IG) should be also considered as a baseline. Furthermore, I think the attribution of the prompt for the sequence of generated text is a more practical task than the current one."
                },
                "questions": {
                    "value": "The major concerns are listed in the Weaknesses. \n\nSome other questions are listed below.\n\n1. If it is in controllable text generation under multi-attribute control, what is the scalability and performance of this method?\n2. In the task of controllable text generation, the data used in this paper does not have ground truth, and the existing evaluation results cannot fully reflect the quality of the generated text. How does the method in this paper perform under manual evaluation?\n3. The highlighted number in Table 3 column 5 is wrong."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3427/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3427/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3427/Reviewer_rNoS"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3427/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698481514797,
            "cdate": 1698481514797,
            "tmdate": 1700646444153,
            "mdate": 1700646444153,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GxUYoRCauT",
                "forum": "ap1ByuwQrX",
                "replyto": "B6zlOS3B3c",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3427/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3427/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer rNoS (1/4)"
                    },
                    "comment": {
                        "value": "Dear Reviewer rNoS,\n\nThank you for your detailed and constructive feedback on our paper. We have carefully considered your insights and have addressed the identified weaknesses (**W**) as well as responded to the questions (**Q**) you raised. Our comprehensive responses (**A**) are provided below for your review.\n\n[**W1**] The TDD method is based on multiple assumptions listed at the bottom of page 4. Some assumptions are strong without any theoretical and experimental proof, especially the first and second assumptions.\n\n[**Q1**] We are sorry for the insufficient clarity in articulating the theoretical and empirical foundations for the assumptions presented on page 4. In response, we reassess the assumptions underlying TDD from both theoretical and empirical perspectives.\n\n**Theoretical Justification**\n\nGeva et al. (2021; 2022) have theoretically demonstrated that in GPT2, token representations at each layer can be projected as evolving distributions over the vocabulary. Considering the consistent decoder-only transformer architecture in contemporary autoregressive language models (LLMs) such as GPTJ and LLaMA2, this theoretical analysis is extendable to these models as well since their mathematical derivations are exactly the same. This supports our first assumption/ finding: the concept of \u201ctoken representations at each layer as evolving distributions\u201d is applicable across various LLMs.\nHowever, their empirical study only focuses on GPT2. To validate the generalization empirically, we conducted experiments across various LLMs and datasets.\n\n**Empirical Justification**\n\nDetailed descriptions of the experiments and their settings are provided in Appendix A. \n\n1) Finding 1: The theory of \u201ctoken representations at each layer as evolving distributions over the vocabulary\u201d can be generalized across various LLMs.\nGiven an input text, we first visualize the token distributions at each layer projected by the LM head for various LLMs including GPT2, GPTJ, BLOOM, Pythia and LLaMA2 in Figure 2 in Appendix A. Using LLaMA2 in Figure 2e as an example, for the initial input \u201c Some\u201d, intermediate layers produce outputs such as \u201cSomeone\u201d and \u201cSomewhere\u201d. With the input \u201cSome boys discover\u201d, outputs like \u201cSome boys discover themselves\u201d emerge. In the upper layers, the prediction logit incrementally rises, converging to the final prediction. These visualizations underscore that token representations from any layer can be depicted as meaningful token distributions over the vocabulary. Furthermore, this notation can be applied to all input tokens, instead of the only last token for prediction.\n\nTo quantitatively assess the dynamics of token distributions across layers, we treat the token distribution at the final layer as the \u201cground-truth\u201d. We then compute the KL-divergence between intermediate layer token distributions and this ground-truth to study their convergence patterns. We employ datasets from BLiMP to estimate the KL-divergence for each token. Figure 2f depicts the mean divergence across layers for all input tokens in all datasets. It can be observed that the learning process reflects the evolving token distributions over the vocabulary, which converge in a roughly monotonic manner to the distribution of the final layer.\n\nBoth qualitative and quantitative analyses corroborate our first finding regarding the generalizability of token representation theory across various LLMs.\n\n2) Finding 2: Projected token distributions from the LM head hold the potential to elucidate causal relationships between prompts and LLM outputs.\nOur first finding confirms that the LM head projects complex token representations at each layer as distributions over the vocabulary. Advancing this concept, we observe that these distributions are both interpretable and integral to the model's generative process. Each dimension of the token distribution represents a specific token in the vocabulary, with the value of each logit indicating the likelihood of the subsequent token based on current and preceding tokens. This capability of the LLM to track prediction or distribution changes with the progressive introduction of tokens enables us to infer which tokens influence the prediction of a target token, offering explanatory insights. Thus, our second finding is that projected token distributions from the LM head hold the potential to elucidate causal relationships between prompts and LLM outputs.\n\nThe experiments detailed in Section 4 further validate our assumptions and findings. These experimental results show that utilizing the token distributions projected by the LM head yields the most faithful explanations. This substantiates our assertion that the LM head possesses the potential to clarify causal relationships between prompts and LLM outputs.\n\nDetailed analysis and experiments are provided in Section 3.2 and Appendix A in our revised paper."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3427/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700144085300,
                "cdate": 1700144085300,
                "tmdate": 1700146854278,
                "mdate": 1700146854278,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dkhnwho9cN",
                "forum": "ap1ByuwQrX",
                "replyto": "F6LvqOGfQh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3427/Reviewer_rNoS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3427/Reviewer_rNoS"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the detailed response, while some concerns are still there, I will not modify my score.\n\n- A5 as I have mentioned the SOTA is integrated gradients (IG) but the author does not consider this baseline.\n- there is no definition of 'zero-shot controlled text generation' in the paper and response, what is the meaning of zero-shot? Does that mean other baselines are not zero-shot?"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3427/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700573221424,
                "cdate": 1700573221424,
                "tmdate": 1700573221424,
                "mdate": 1700573221424,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dT0fzA3lpz",
                "forum": "ap1ByuwQrX",
                "replyto": "B6zlOS3B3c",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3427/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3427/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer rNoS"
                    },
                    "comment": {
                        "value": "Dear Reviewer rNoS,\n\nThank you for your follow-up. We have further addressed your concerns as outlined below:\n\n**1**. A5 as I have mentioned the SOTA is integrated gradients (IG) but the author does not consider this baseline.\n\nWe apologize for this omission in our first revision. We have recently completed the experiments involving IG and have now included these results in our revised paper. Here are the details:\n\nIn addition to our proposed method, we have compared it with the advanced explanation method Integrated Gradients (IG) (Sundararajan et al., 2017). The experimental results, presented in Table 2 of our revised paper, show that IG slightly underperforms compared to the SOTA contrastive method Con-GI. However, our TDD significantly outperforms all baselines by a considerable margin of 5%-7%. We argue that the suboptimal performance of IG is primarily due to its focus solely on target tokens while disregarding alternative tokens.\n\nThese revisions and detailed results can be found in Sections 4.4-4.5 and Table 2 of our revised paper.\n\n**2** there is no definition of 'zero-shot controlled text generation' in the paper and response, what is the meaning of zero-shot? Does that mean other baselines are not zero-shot?\n\nWe apologize for not previously defining \u201czero-shot controlled text generation.\u201d This term refers to a scenario where no training samples are available or provided, and all methods must be executed without such samples.\n\nOur TDD approach is designed to function without any training samples. To ensure a fair comparison, we selected six baselines that are also applicable in a zero-shot setting. This setting, common yet challenging in real-life applications, tests the ability to control attributes like sentiment and toxicity in large language models (LLMs) without prior training. Our experiments demonstrate that TDD effectively manages these attributes under zero-shot conditions.\n\nWe hope our response resolves your concerns. Please do not hesitate to contact us if you have further questions."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3427/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700645114847,
                "cdate": 1700645114847,
                "tmdate": 1700645618453,
                "mdate": 1700645618453,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "h6Ify1ub97",
                "forum": "ap1ByuwQrX",
                "replyto": "dT0fzA3lpz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3427/Reviewer_rNoS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3427/Reviewer_rNoS"
                ],
                "content": {
                    "comment": {
                        "value": "It sounds reasonable and addresses most of my concerns. I plan to raise my score.\n\nFurther small suggestions, 1) the colors and alignment of Figure 1 should be improved; 2) there are many text style transfer works that should also be mentioned in this paper.\n\nFor example, papers saying \"unsupervised text style transfer\" are somehow similar to the application,\n[1] Unsupervised text style transfer using language models as discriminators\n[2] Transductive learning for unsupervised text style transfer\n[3] Reformulating unsupervised style transfer as paraphrase generation"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3427/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700646415035,
                "cdate": 1700646415035,
                "tmdate": 1700646415035,
                "mdate": 1700646415035,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "lEKkIANTpv",
            "forum": "ap1ByuwQrX",
            "replyto": "ap1ByuwQrX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3427/Reviewer_jvM3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3427/Reviewer_jvM3"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers the roles of individual tokens in prompts in guiding the responses of LLMs. To analyze the dynamics of token distributions, this paper proposes three methods (TDD-forward, TDD-backward, TDD-bidirectional), each offering insights into token relevance. \n\nTDD-forward computes $r_i - r_{i-1}$, where each $r_i$ is the difference between the probability of token i (computed from a contextualized LM) and the probability of the alternative token. TDD-backward computes the probabilities at the last token, and uses $r_{i-1} - r_i$. TDD-bidirectional is the sum of the TDD-forward and TDD-backward.\n\nOn 11 out of the 67 datasets on BLiMP, this paper shows that TDD-based methods in general have better AOPC and Sufficiency results than multiple baseline methods. Additionally, in some case studies (toxic language suppression and controllable text generation), the TDD method works better than some baseline methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The method is simple and efficient.\n- The analysis towards understanding causal mechanisms of token probability distributions is a timely and important research topic."
                },
                "weaknesses": {
                    "value": "- The TDD methods heavily depend on the alternative word $w_a$. The datasets chosen in this paper (those BLiMP datasets) provide sentence pairs with exactly one-word differences. Other datasets may not have such well-defined alternative words. This greatly limits the potential applicability of the proposed TDD methods.\n    - A related point: it is unclear to me how the w_a in the Section 5 experiments are identified.\n- The analyses presented in this paper are not really causal analyses, despite claims that the LM head \u201celucidate causal relationships between prompts and LLM outputs\u201d (page 4). No controlled variable is specified, and no treatment effect is measured. This paper could be much stronger if some sort of causal scores are computed, for example, how large is the treatment effect of changing w to w_a causes the toxicity of the generated texts. Currently, the numbers shown in Tables 3 and 4 look similar to the treatment effects, but without more descriptions about how the variables are controlled, we can\u2019t really say the numbers are treatment effects.  \n- A minor point about writing styles: Excessive adverbs (e.g., those in the sentence \u201celegantly simple yet remarkably effective\u201d) can make the paper read less rigorous, rendering the text resemble more of a social media post than a scientific paper."
                },
                "questions": {
                    "value": "In section 5, which variant of TDD is used? Are TDD-forward used there?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3427/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3427/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3427/Reviewer_jvM3"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3427/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698608903582,
            "cdate": 1698608903582,
            "tmdate": 1700629625370,
            "mdate": 1700629625370,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SFD3WOgZ3Q",
                "forum": "ap1ByuwQrX",
                "replyto": "lEKkIANTpv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3427/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3427/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer jvM3 (1/2)"
                    },
                    "comment": {
                        "value": "Dear Reviewer jvM3,\n\nWe appreciate your comprehensive review and valuable feedback on our manuscript. In response, we have systematically addressed the identified weaknesses (**W**) and answered your queries (**Q**). Our detailed responses (**A**) are outlined below.\n\n[**Q1**] In section 5, which variant of TDD is used? Are TDD-forward used there?\n\n[**A1**] We apologize for the lack of clarity regarding our choice of TDD variants for the controlled text generation. In our application experiments in section 5, we specifically chose the TDD-bidirectional variant for both toxicity suppression and sentiment steering. This decision was based on its superior performance observed in our main experiments, which are thoroughly discussed in Section 4. We have added such clarification in our revised manuscript.\n\n[**W1**] The TDD methods heavily depend on the alternative word w_a. The datasets chosen in this paper (those BLiMP datasets) provide sentence pairs with exactly one-word differences. Other datasets may not have such well-defined alternative words. This greatly limits the potential applicability of the proposed TDD methods.  A related point: it is unclear to me how the w_a in the Section 5 experiments are identified.\n\n[**A2**] Thank you for highlighting your concerns. We apologize for any lack of clarity regarding the scope of TDD in our paper. Actually, **TDD's effectiveness is not strictly dependent on alternative tokens. TDD is versatile and can be applied in various scenarios, including those with 1) a single target token and a single alternative token, 2) only target tokens, 3) multiple target tokens and multiple alternative tokens, and 4) controlled attributes in generated sequences.** We substantiate each of these applications with experimental evidence as follows:\n\n**Scope of TDD**\n\n1) Single Target and Single Alternative Token: Section 4 details our main experiments, which validate TDD's effectiveness in scenarios involving a single target token and a single alternative token.\n\n2) Target Token Only: TDD is applicable even in the absence of alternative tokens. By assigning a zero probability to alternative tokens in Equations 2 and 4 in the paper, we can negate the necessity of alternative tokens. In the added experiments, we estimate each token\u2019s importance by using only target tokens, and the alternative tokens are not provided. The results, summarized in Table 5, show TDD's significant outperformance of strong baselines\u2014by about 3%\u2014in scenarios without alternative tokens. \n\n3) Multiple Target and Alternative Tokens: TDD accommodates scenarios involving multiple target and alternative tokens by aggregating their probabilities in Equations 2 and 4. The effectiveness of TDD in these settings was assessed through experiments using AG\u2019s News and SST2 datasets, with details provided in the Appendix B.2.3 of our revised paper. These results in Table 6 demonstrate TDD\u2019s effectiveness for multiple target and alternative tokens.\n\n4) Generated Sequence Attribute Control: The experiments described in Section 5, focusing on toxic language suppression and sentiment steering, further confirm TDD's applicability in controlling attributes of generated sequences.\n\nMore details are available in Section 3.6 and Appendix B.2 in our revised manuscript.\n\n**Defined Target and Alternative Tokens in Section 5**\n\nFor zero-shot toxic language suppression, we utilized a predefined list of toxic words from WORDFILTER as target tokens, treating all other tokens as alternatives. In this context, considering all other tokens as alternatives is equivalent to having no alternatives.\nFor zero-shot positive sentiment steering, we identified negative words from SenticNet as target tokens, using positive words as alternative tokens. This approach allows TDD to identify key words that could lead to negative outcomes and suppress them. To generate negative responses, we simply reverse the roles of the target and alternative tokens, while keeping other settings constant."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3427/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700143716908,
                "cdate": 1700143716908,
                "tmdate": 1700146287206,
                "mdate": 1700146287206,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "e3fkwgvB8a",
                "forum": "ap1ByuwQrX",
                "replyto": "YuihkPJCPg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3427/Reviewer_jvM3"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3427/Reviewer_jvM3"
                ],
                "content": {
                    "title": {
                        "value": "Reviewer reply"
                    },
                    "comment": {
                        "value": "Thank you for the response and the updates to the pdf. These address most of my concerns, especially about the causal analysis. Clarifying the scope of TDD is helpful as well. I'm happy to raise my score."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3427/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700629771242,
                "cdate": 1700629771242,
                "tmdate": 1700629771242,
                "mdate": 1700629771242,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KdfxyTBbvU",
            "forum": "ap1ByuwQrX",
            "replyto": "ap1ByuwQrX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3427/Reviewer_1T7y"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3427/Reviewer_1T7y"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a novel method for constrastive XAI for autoregressive LMs. Instead of using gradients or attention maps, the introduced TDD approach is based on token distributions. TDD aims to explain token influence in the input prompt. To this end, three variants are presented: forward, backward, and bidirectional, as the authors describe, each offering unique insights into token relevance.\nThe introduced approach is evaluated based on the explanations' faithfulness and the capability to steer the model\u2019s outcome.\nSteering is done by replacing the most influential tokens and replacing them, e.g., with white space tokens."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The proposed method is a simple and efficient method\n- In general, the paper is well-written, with a clear introduction method and description of experiments\n- Evaluation of multiple autoregressive models\n- The authors seem to provide all the necessary details for reproducible experiments\n- Additional showcasing on interesting and important use cases"
                },
                "weaknesses": {
                    "value": "- The difference between the TDD variants is not well discussed. While the applications are very interesting, the authors could have used the space to elaborate on the differences between the introduced variants. \n- Captions Table 1 and Table 3 are too sparse.\n- While not being a contrastive XAI method, important related work on explainability for autoregressive LMs missing: \nATMAN: Understanding Transformer Predictions Through Memory Efficient Attention Manipulation. Bj\u00f6rn Deiseroth, Mayukh Deb, Samuel Weinbach, Manuel Brack, Patrick Schramowski, Kristian Kersting. In Proceedings of NeurIPS 2023"
                },
                "questions": {
                    "value": "- Can you elaborate on the difference between TDD and AtMan [Deiseroth et al., 2023] (see weaknesses) beyond contrastive explanations? It seems to be more similar to TDD than Rollout while at the same time relying on attention layers.\n- In the steering demonstration, multiple alternative tokens are used at the same time. As far as I understood, in Sec. 4, only one alternative token is selected. How robust is TDD when multiple alternative tokens are used?\n- Beyond the benchmark experiments, how would one select an alternative token to explain the LMs decision? \n- Which TDD variant is applied in the steering experiments? You mentioned that each TDD variant offers unique insights into token relevance. Can you further elaborate on this regard? Unfortunately, I could not find a discussion in the paper. Are there scenarios where one variant is beneficial? \u0010"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3427/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698761974998,
            "cdate": 1698761974998,
            "tmdate": 1699636294417,
            "mdate": 1699636294417,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "OVqq7wuOok",
                "forum": "ap1ByuwQrX",
                "replyto": "KdfxyTBbvU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3427/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3427/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1T7y  (1/2)"
                    },
                    "comment": {
                        "value": "Dear Reviewer 1T7y,\n\nThank you for your thorough review and insightful feedback on our paper. We have addressed each identified weakness (**W**) and responded to the questions (**Q**) raised. Our detailed responses (**A**) are summarized below.\n\n[**Q1**] Can you elaborate on the difference between TDD and AtMan [Deiseroth et al., 2023] (see weaknesses) beyond contrastive explanations?\n\n[**A1**] Thank you for your insightful feedback. We apologize for the oversight regarding the omitted reference and have addressed this in our revised manuscript. To clarify, the primary distinctions between our TDD method and the AtMan approach are as follows:\n\n1. Saliency Estimation Medium: AtMan evaluates input saliency by iteratively manipulating the attentions of each input token and observing changes in cross-entropy. In contrast, TDD utilizes the token distribution as the medium for calculating token saliency.\n\n2. Inference Process: AtMan introduces noise at the beginning of forward propagation, whereas TDD performs inference directly at the end of propagation, after the forward propagation process is complete.\n\n3. Parameter Dependence: TDD has the advantage of not requiring any hyperparameters. On the other hand, AtMan necessitates setting hyperparameters, such as the suppression factor and the lower bound of cosine similarity, which can vary across different datasets.\n\nThe revision can be found in Section 2.1 in our revised paper.\n\n\n[**Q2**] How robust is TDD when multiple alternative tokens are used?\n\n[**A2**] Thanks for your professional comment. To affirm the robustness of our TDD method, we expanded our experimental scope to include additional datasets featuring multiple target and alternative tokens. These experiments demonstrate TDD's superior performance over strong baseline methods across diverse datasets. Further details are provided below.\n\nExperiment Setup: In the absence of ready-made datasets for evaluating multiple alternative tokens, we leverage a prompt-learning framework to simulate such an environment. We select two datasets: AG\u2019s News for topic classification and SST2 for sentiment analysis. The inputs are structured as cloze questions, with AG\u2019s News framed as \"<input> This topic is about___\" and SST2 as \"<input> It was __\". We incorporate multiple target and alternative tokens by utilizing label words from the KPT method. For each sample, the label words corresponding to the ground-truth label serve as target tokens, while those from other classes are alternative tokens. \n\nTable 6 in Appendix B.2.3 presents the performance comparison of TDD-bidirectional against other baselines. In the SST2 dataset, TDD surpasses SOTA methods by around 7% in AOPC and demonstrates a 6% enhancement in Suff over current baselines. In the AG's News dataset, TDD achieves a 3%-5% margin over existing methods in both AOPC and Suff. These findings verify TDD's efficacy in scenarios involving multiple target and alternative tokens.\n\nMore details can be found in Section 3.6 and Appendix B.2.3 in our revised manuscript.\n\n[**Q3**] Beyond the benchmark experiments, how would one select an alternative token to explain the LMs decision?\n\n[**A3**] Thank you for highlighting this aspect. In response to your query, we approach the selection of alternative tokens in three distinct ways:\n\n1. Omitting Alternative Tokens: Alternative tokens can be excluded from explanations. By assigning a probability of zero to alternative tokens in Equations 2 and 4, we negate their necessity. Our experiments in Appendix B.2.2, which involved the omission of alternative tokens, confirm the effectiveness of our TDD method.\n\n2. Choosing Based on Linguistic Features: The selection of alternative tokens can align with specific linguistic features under study. For instance, to understand why the model generates \"waitresses\" in response to the prompt \"Amanda was respected by some\", we can vary the alternative tokens. For syntactic and morphological analysis, an alternative like \"waitress\" may be used, while \"pictures\" may be chosen for semantic analysis. This also underscores our preference for contrastive explanation over conventional explanations in TDD, which we find offers quantifiably superior insights into grammatical phenomena and enhances model simulatability for users.\n\n3. Observing LLM Output Probabilities: A practical method involves examining the LLM's top-k or top-p output tokens. This approach is straightforward and effective for explaining the model\u2019s choices among similar or commonly confused tokens."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3427/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700143344225,
                "cdate": 1700143344225,
                "tmdate": 1700143344225,
                "mdate": 1700143344225,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yqCC0MmLon",
                "forum": "ap1ByuwQrX",
                "replyto": "KdfxyTBbvU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3427/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3427/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1T7y  (2/2)"
                    },
                    "comment": {
                        "value": "[**Q4**] Which TDD variant is applied in the steering experiments? You mentioned that each TDD variant offers unique insights into token relevance. Can you further elaborate on this regard? Unfortunately, I could not find a discussion in the paper. Are there scenarios where one variant is beneficial?\n\n[**A4**] We appreciate your feedback and have incorporated detailed discussions about the TDD variants and its use in our steering experiments.\n\n1. In our steering experiments, we specifically chose the TDD-bidirectional variant, as detailed in the revised manuscript. This decision was based on its superior performance observed in our main experiments, which are thoroughly discussed in Section 4.\n\n**2. Detailed Variant Discussion.** \n\na. Calculation Direction: The TDD-forward evaluates token importance sequentially from the first to the last input token. Conversely, TDD-backward assesses saliency in reverse, from the last input token to the first. TDD-bidirectional, drawing inspiration from bidirectional neural networks, combines saliency estimates from both TDD-forward and TDD-backward.\n\nb. Information Perspective: TDD-backward is less influenced by linguistic conventions, offering a more targeted approach. The TDD-forward overlooks the inherent linguistic influence of individual tokens. Consider the sentence completion by the LLM: \u201c This design is quite novel and fantastic. I really ___\u201d, our aim is to explain why the LLM generates \u201clike\u201d instead of \u201chate\u201d. Linguistic conventions render it improbable to predict tokens such as \u201clike\u201d or \u201chate\u201d following \u201cis\u201d or \u201cnovel\u201d, indicating potential inaccuracies in token contribution assessments. TDD-backward can mitigate this issue. Specifically, in TDD-backward, the words \u201cI really ___\u201d are fed to the LLM in the first two iterations. Subsequently, other tokens, such as \u201cfantastic\u201d, are progressively introduced This initial phase sharpens the model's focus, enhancing its accuracy in predicting words such as \u201clike\u201d or \u201chate\u201d as the LLM consistently generates predictions following the phrase \"\u2026 I really __\" in each iteration.\n\n**3. Application Scenarios** TDD-forward is preferable in time-sensitive or computationally constrained scenarios, as it requires only one forward propagation due to the auto-regressive structure of LLMs. TDD-backward and TDD-bidirectional are better suited for contexts where time is not a constraint, and there is a higher demand for explanation fidelity. They demand iterations equal to the input length for saliency estimation. The revised paper\u2019s Table 2 showcases the higher faithfulness of explanations by TDD-backward and TDD-bidirectional, while Table 9 confirms the computational efficiency of TDD-forward. \n\nMore details are provided in Appendix B.1 and G in our revised paper.\n\n[**W1**] The difference between the TDD variants is not well discussed. While the applications are very interesting, the authors could have used the space to elaborate on the differences between the introduced variants.\n\n[**A5**] Please refer to our response [A4] to question 4 [Q4].\n\n[**W2**] Captions Table 1 and Table 3 are too sparse.\n\n[**A6**] Thanks for pointing this out. We have revised the captions for Tables 1, 3 and 4 accordingly in our modified manuscript.\n\n[**W3**] While not being a contrastive XAI method, important related work on explainability for autoregressive LMs missing: ATMAN: Understanding Transformer Predictions Through Memory Efficient Attention Manipulation. Bj\u00f6rn Deiseroth, Mayukh Deb, Samuel Weinbach, Manuel Brack, Patrick Schramowski, Kristian Kersting. In Proceedings of NeurIPS 2023\n\n[**A7**] Please refer to our response [A1] to question 1 [Q1]."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3427/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700143509167,
                "cdate": 1700143509167,
                "tmdate": 1700146069140,
                "mdate": 1700146069140,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IhiCwVYH0L",
                "forum": "ap1ByuwQrX",
                "replyto": "yqCC0MmLon",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3427/Reviewer_1T7y"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3427/Reviewer_1T7y"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarifications and for addressing the remaining concerns. I'm happy to keep my score and vote to accept the paper."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3427/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700677555278,
                "cdate": 1700677555278,
                "tmdate": 1700677555278,
                "mdate": 1700677555278,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "x0vs3sffW2",
            "forum": "ap1ByuwQrX",
            "replyto": "ap1ByuwQrX",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3427/Reviewer_4Y86"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3427/Reviewer_4Y86"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a new method via using Token Distribution Dynamics (called TDD) to both interpret and control LLMs' generations. \n\nThe authors compared the proposed method with a few baselines (attention rollout, contrastive gradient) and show TDD obtains a more precise explanation with lower sufficiency. The authors also put TDD into real use for toxic language suppression and sentiment steering, and show TDD can effectively control LLMs' outputs."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The idea of analyzing the token distributions throughout the progression of prediction is quite interesting. The idea is simple but seems to be quite useful in unveiling the importance of input tokens when providing contrastive explanations.\n\n- The authors did experiments over a fairly comprehensive set of language models including GPT-2/J, BLOOM, and LLaMA.\n\n- The applications on toxic language suppression and sentiment steering further demonstrate the usefulness of the proposed TDD method."
                },
                "weaknesses": {
                    "value": "- One simple way to control LLMs' generations is via prompting for style transfer, e.g., ask the model to transform the outputs into \"less toxic\" content, or \"positive/negative\" sentiment. How would this baseline compare to the proposed TDD?\n\n- The models used in experiments are relatively smaller models (maximum size 7B), how would the proposed approach work on larger models (e.g., llama-2 13B, 70B)? What is the computation cost (efficiency, memory) for running TDD over larger models?\n\n- The proposed TDD provides contrastive explanations on the token level, it would be interesting to see if this method can be extended to higher-level concepts, e.g., why sometimes a model chooses to generate an unfaithful output."
                },
                "questions": {
                    "value": "- Could the authors add a simple baseline by prompting the LLMs for style transfer on the outputs?\n\n- What is the computation cost (efficiency, memory) for running TDD over larger models?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3427/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698767244837,
            "cdate": 1698767244837,
            "tmdate": 1699636294342,
            "mdate": 1699636294342,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AaEsomC0zA",
                "forum": "ap1ByuwQrX",
                "replyto": "x0vs3sffW2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3427/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3427/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 4Y86"
                    },
                    "comment": {
                        "value": "Dear Reviewer 4Y86,\n\nThank you for taking the time to review our paper and providing insightful feedback. Our responses (**A**) to the mentioned weaknesses (**W**) and posed questions (**Q**) are summarized as follows.\n\n[**Q1 & W1**]: One simple way to control LLMs' generations is via prompting for style transfer. How would this baseline compare to the proposed TDD? Could the authors add a simple baseline by prompting the LLMs for style transfer on the outputs?\n\n[**A1**]: We appreciate the valuable suggestion offered. In response, we have incorporated two robust baselines from the field of text style transfer aimed at regulating the toxicity and sentiment in LLM outputs.\n\nWe compare TDD with two baselines from this field. Style Prompting (SP) (Reif et al., 2022) integrates specific style instructions like toxicity into prompts, while Augmented Style Prompting (ASP) (Reif et al., 2022) enhances this approach by introducing varied rewriting examples for a broader application. Detailed information regarding these two prompting strategies can be found in Appendix H and M.\n\nIn our revised manuscript, Tables 3 and 4 detail the experimental results. SP records a toxicity of 0.47, ASP attains 0.41, whereas TDD achieves a notably lower score of 0.20, significantly outperforming SP and ASP. In terms of negative sentiment steering, TDD surpasses both SP and ASP by a substantial margin of about 0.30. For positive sentiment steering, TDD exceeds SP and ASP by more than 0.20, underscoring its considerable advantage over style transfer methods.\n\n\n\n[**Q2&W2**]: \nHow would the proposed approach work on larger models (e.g., llama-2 13B, 70B)? What is the computation cost (efficiency, memory) for running TDD over larger models?\n\n[**A2**]: Thank you for your insightful feedback. In response, we have expanded our research to include experiments on explanation faithfulness using larger models such as LLaMA2-13B and OPT-30B to ensure its scalability. Additionally, we have included a comparison of the computational costs for both our methods and the baseline approaches. The key findings are summarized below.\n\n**Scalability**. We conduct experiments with LLaMA2-13B and OPT-30B (Zhang et al., 2022) to assess the effectiveness of TDD in explaining larger models. The summarized results in Table 8 in the revised manuscript reveal that TDD-forward outperforms the baselines by margins of 3.15% in AOPC and 4.4% in Suff using LLaMA2-13B. Both TDD-backward and TDD-bidirectional demonstrate superior performance, exceeding the baselines by more than 4% in AOPC and over 5% in Suff. For OPT-30B, TDD surpasses competitive baselines by a significant margin of 4% to 6%. These results prove TDD's scalability and effectiveness in larger models.\n\n**Computation Cost**. For the computational cost analysis, we evaluate the average memory usage and processing time required by our method for processing a single input sample. Consistency is maintained across all experiments, which are conducted on an NVIDIA RTX A5000 GPU. For models larger than 6 billion parameters, their 4-bit versions are utilized. Detailed memory and time metrics are presented in Table 9 in the paper. Regarding memory consumption, Rollout and the three TDD variants (TDD-forward, TDD-backward, and TDD-bidirectional) are the most efficient. In terms of processing time, TDD-forward and Rollout emerge as the fastest, whereas TDD-backward and TDD-bidirectional exhibit slightly longer processing time.\n\nMore details are provided in Section 4.6 and Appendix F, G in our revised manuscript.\n\n[**W3**]: The proposed TDD provides contrastive explanations on the token level, it would be interesting to see if this method can be extended to higher-level concepts, e.g., why sometimes a model chooses to generate an unfaithful output.\n\n[**A3**]: Thank you for your constructive suggestions. We agree that applying our method to higher-level concepts is an interesting direction for future work. \nGenerally speaking, LLM generations can be explained from basic to advanced levels. At the token level, it's crucial to understand and explain the reasons behind the generation of specific tokens. The sequence-attribute level involves interpreting why LLMs produce sequences with attributes like toxicity or positivity. The third, more complex level, examines the production of biased or unfaithful outputs. We've demonstrated our method's effectiveness at the first and second levels through experiments in Section 4 and controlled text generation in Section 5. Applying our approach to the third level remains a goal for future research, aiming to deepen our understanding of LLMs and further their development.\n\n\nReferences\n\nReif, E., Ippolito, D., Yuan, A., Coenen, A., Callison-Burch, C., & Wei, J. (2022). A Recipe for Arbitrary Text Style Transfer with Large Language Models. \n\nZhang S, Roller S, Goyal N, et al. Opt: Open pre-trained transformer language models[J]."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3427/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700143101351,
                "cdate": 1700143101351,
                "tmdate": 1700143101351,
                "mdate": 1700143101351,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XjhLGLImwQ",
                "forum": "ap1ByuwQrX",
                "replyto": "AaEsomC0zA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3427/Reviewer_4Y86"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3427/Reviewer_4Y86"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "Thanks the authors for adding the details. Overall I think this is an interesting paper and lean towards acceptance.\n\nFor SP and ASP though, I'm surprised that they're not effective in either task (very little difference compared to the baseline GPT-2 model). Have you studied why this is the case? Is it because of how the prompt is written (e.g., instead of \"less toxic\", we can say \"not toxic at all\", can this lead to more toxicity suppression?), or because the model doesn't follow the instruction very well (e.g., using an instruction-tuned model would work better)?"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3427/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700628443441,
                "cdate": 1700628443441,
                "tmdate": 1700628443441,
                "mdate": 1700628443441,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XxYYXaBR7k",
                "forum": "ap1ByuwQrX",
                "replyto": "x0vs3sffW2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3427/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3427/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 4Y86"
                    },
                    "comment": {
                        "value": "Dear Reviewer 4Y86,\n\nThank you very much for your follow-up and positive assessment. We are pleased to note that our responses have addressed most of your concerns.\n\nRegarding the main reason why SP and ASP are less effective, we argue it is due to GPT2's limited capacity to comprehend and adhere to instructions. Our tests involved various prompt styles. For example, to generate positive outputs, we experimented with prompts containing keywords such as \"be more positive/good/very positive/totally positive\" and \"be less negative/bad,\" including synonyms of these terms. Unfortunately, these prompts proved largely ineffective. The most successful prompts have been carefully selected and are detailed in our revised paper. Consequently, we infer that GPT2 struggles with following SP and ASP instructions, even though some demonstrations are included in ASP.\n\nWe would also like to highlight that in the original SP and ASP paper, their effectiveness was demonstrated using much larger models like LaMDA-137B and GPT3-175B, as opposed to the significantly smaller GPT2-774M and LlaMA-7B models. This leads us to believe that SP and ASP techniques may be more suited to and effective with larger or instruction-tuned models.\n\nThank you again for your response. Please let us know if you have further questions."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3427/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700644877957,
                "cdate": 1700644877957,
                "tmdate": 1700645765565,
                "mdate": 1700645765565,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]