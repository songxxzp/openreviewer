[
    {
        "title": "Supermodular Rank: Set Function Decomposition and Optimization"
    },
    {
        "review": {
            "id": "CSeNew3RCk",
            "forum": "REKRLIXtQG",
            "replyto": "REKRLIXtQG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6412/Reviewer_HVke"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6412/Reviewer_HVke"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the set function optimization problem, where there is a ground element set and the goal is to pick an element subset such that some certain objective is maximized. The authors mainly consider two concrete models: matroid-constrained maximization and set function ratio minimization. In the first model, we are given a monotone, non-negative function $f$ with generalized curvature $\\alpha$ and submodularity ratio $\\gamma$, and a matroid system $M$. The goal is to pick an element subset $S\\in M$ such that $f(S)$ is maximized. The authors prove that there exists a framework such that by applying it to any approximation algorithm with $O(q(m))$ queries ($q(\\cdot)$ is a polynomial function), a better approximation ratio can be obtained in time $O(2^{r-1}n^{r-1} q(n))$, where $r$ is the elementary submodular rank. In the second model, we are given two set functions $f, g$ and the goal is to pick a subset $S$ such that $f(S)/g(S)$ is minimized. The authors prove that when $f,g$ are normalized positive monotone functions and $f$ has a bounded elementary submodular rank, they obtain an approximation ratio polynomially that was previously only available when function $f$ was submodular. Finally, the authors conduct experiments to investigate the empirical performance of the algorithms."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper considers two classical and important models in set function optimization. The main contribution of the paper is introducing the concept of elementary submodular rank and building on it to extend the previous results to a more general function class. \n\n- Both theoretical analyses and experimental evaluations for the proposed algorithms are provided in the paper."
                },
                "weaknesses": {
                    "value": "- A main weakness is that the paper is not well-written. The structure is quite confusing. The formal definitions of the considered models are not provided until section 4. Several new definitions are introduced before Section 4. However, the absence of any intuitive explanations renders the paper less accessible to readers."
                },
                "questions": {
                    "value": "(1) Could you give some intuition about the elementary-submodular-rank-based trick used in the paper?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6412/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6412/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6412/Reviewer_HVke"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6412/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698593860157,
            "cdate": 1698593860157,
            "tmdate": 1699636714436,
            "mdate": 1699636714436,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fgYbgdCpv1",
                "forum": "REKRLIXtQG",
                "replyto": "CSeNew3RCk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6412/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6412/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> A main weakness is that the paper is not well-written. The structure is quite confusing. The formal definitions of the considered models are not provided until section 4. Several new definitions are introduced before Section 4. However, the absence of any intuitive explanations renders the paper less accessible to readers.\n\nWe thank the reviewers for their comments. We have updated the manuscript to add more explanatory examples to improve the paper\u2019s readability. The changes are highlighted in blue. \n\n> (1) Could you give some intuition about the elementary-submodular-rank-based trick used in the paper?\n\nThe intuition might be more apparent if we think of continuous functions. The idea behind the elementary rank can be thought of (not strictly true, but ok for intuition reasons) as determining the number of coordinate directions in which the function is non-convex. Once we have determined these directions, we decompose our function into convex orthogonal functions. Then, we independently optimize these functions."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6412/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700532037363,
                "cdate": 1700532037363,
                "tmdate": 1700532037363,
                "mdate": 1700532037363,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "H4VJmJdRs5",
                "forum": "REKRLIXtQG",
                "replyto": "fgYbgdCpv1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6412/Reviewer_HVke"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6412/Reviewer_HVke"
                ],
                "content": {
                    "comment": {
                        "value": "The reviewer thanks the author for their response and the newly added examples in the revision. I believe this is an interesting work. However, the paper seems to still need a cleaner overall structure to make the main contributions more readable."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6412/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700668443548,
                "cdate": 1700668443548,
                "tmdate": 1700668443548,
                "mdate": 1700668443548,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "OaKPtzSTBk",
                "forum": "REKRLIXtQG",
                "replyto": "glAjFwP2YL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6412/Reviewer_HVke"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6412/Reviewer_HVke"
                ],
                "content": {
                    "comment": {
                        "value": "The reviewer thanks the author for their further response. For me, it's more natural to introduce the target optimization problems (Section 4) as soon as possible, so that the reader can get the main goal quickly. And then state why defining the supermodular rank is helpful and necessary. This seems a better way to organize the paper, but this is just my personal opinion, the authors should avoid overfitting."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6412/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700696027614,
                "cdate": 1700696027614,
                "tmdate": 1700696027614,
                "mdate": 1700696027614,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZJ5kR0cnBx",
            "forum": "REKRLIXtQG",
            "replyto": "REKRLIXtQG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6412/Reviewer_jvwD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6412/Reviewer_jvwD"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers the supermodular and submodular optimization problem. In these problems, we are given a supermodular/submodular or a related function defined over a ground set. The goal is to select a certain subset of the ground elements such that (1) the selected subset satisfies some properties; (2) the value of the selected subset is optimized. If a function is not submodular/supermodular, one can describe it into several parameters, and the approximation ratio shall also be related to these parameters.\n\nThe main contribution of this work is a new approach to grading the space of set function. They propose a new concept called supermodular/submodular rank, which is defined over a partial order set. Based on such a concept, they show that a function can be decomposed into a summation of several \\p-supermodular/submodular functions. Then, one can improve the approximation by such a splitting."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The high-level idea of this paper is clear. The main technical idea is to decompose a function into a sum of functions that are \\pi-supermodular/submodular. And then split the problem into several submodular pieces. This improves the approximation when the submodular/supermodular rank is bounded.\n\n2. This paper is technically involved. To my knowledge, there is no such definition and decomposition in the literature. Probably the most related one is that a submodular function can be decomposed into n! additive functions, but the definition used in this paper is quite different from this."
                },
                "weaknesses": {
                    "value": "1. The presentation of this work is poor. It seems that the authors ran out of space and moved a lot of background knowledge to the appendix. Without this knowledge, it's hard to get the definition of \\pi-supermodular. After moving, it seems that the authors didn't do careful proofreading. For example, R(alpha, gamma) in Theorem 25 is not defined. This significantly impairs readability. I appreciate that the authors also try to explain their ideas with some examples, and I also understand that the space issue is not the authors' fault, but it is a fact that the paper does need a better presentation.\n\n2. To my understanding of Table 2, the proposed algorithm improves the previous ratio only in the case where the elementary submodular rank is a constant. If this is true, it\u2019s not clear how important this improvement is. Because the paper didn't include a discussion about whether there exists some famous functions with a constant submodular rank. Besides this, the paper only includes an upper bound on the rank of a function but excludes the way to compute the rank of a function. Maybe I missed something, and such a computation is trivial, but this should be stated explicitly."
                },
                "questions": {
                    "value": "See my second comment in Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6412/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698653167716,
            "cdate": 1698653167716,
            "tmdate": 1699636714298,
            "mdate": 1699636714298,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "njCEWzw6W5",
                "forum": "REKRLIXtQG",
                "replyto": "ZJ5kR0cnBx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6412/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6412/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> The presentation of this work is poor. It seems that the authors ran out of space and moved a lot of background knowledge to the appendix. Without this knowledge, it's hard to get the definition of \\pi-supermodular. After moving, it seems that the authors didn't do careful proofreading. For example, R(alpha, gamma) in Theorem 25 is not defined. This significantly impairs readability. I appreciate that the authors also try to explain their ideas with some examples, and I also understand that the space issue is not the authors' fault, but it is a fact that the paper does need a better presentation.\n\nWe thank the reviewers for their comments. We have updated the manuscript to add more explanatory examples to improve the paper\u2019s readability. The changes are highlighted in blue. \n\n> To my understanding of Table 2, the proposed algorithm improves the previous ratio only in the case where the elementary submodular rank is a constant. If this is true, it\u2019s not clear how important this improvement is. Because the paper didn't include a discussion about whether there exists some famous functions with a constant submodular rank. Besides this, the paper only includes an upper bound on the rank of a function but excludes the way to compute the rank of a function. Maybe I missed something, and such a computation is trivial, but this should be stated explicitly.\n\nComputing the rank of a function (unless we know something about the function) is not easy. We do not have a simple method for doing so. However, we can provide examples of functions that have low submodular rank. \n\n**RBM**\n\nThe first example comes from Restricted Boltzmann Machines (RBMs). These are graphical models for modeling probability distributions on $\\{0,1\\}^n$. They have a hyperparameter $m$, the number of hidden nodes. Prior work (See references [Allman et al., 2015]) has shown that when $m=1$, this model can represent distributions $f(x)$ if and only if $\\log f$ is $\\pi$-supermodular and satisfies certain polynomial equality constraints. \nThen, when we move to more significant values of $m$, it can be shown that the model can model distribution $f(x)$ only if $\\log f$ is rank-$m$ supermodular. Thus log RBM distributions are functions with bounded supermodular rank. In this case, the optimization problem would correspond to finding modes of the distribution. \n\n**One hidden layer neural networks**\n\nBuilding on this, we have the following.\n\n**Proposition:** Let $f$ be a real-valued function on $\\{0,1\\}^n$  that is the composition of an affine function and a convex function. That is, $f(x) = \\phi(wx + c)$ where $w$ is a vector of length $1 \u00d7 n$ and $c$ is a scalar and $\\phi : \\mathbb{R} \\to \\mathbb{R}$  is convex. Then $f$ is sign(w)-supermodular.\n\n*Proof*:We show that the elementary imset inequalities are satisfied. \nSuch an inequality involves four vectors on a two-dimensional face of the cube $\\{0, 1\\}^n$. We have two indices $x_i,x_j$ that vary and a fixed value of $x_{[n]\\setminus\\{i,j\\}}$, the vector $x$ restricted to the set $[n]\\setminus\\{i,j\\}$. \nLet $y$ be the entry of the face where $x_i = x_j = 0$. \nLetting $c' = c + Ay$, we seek to compare $\\phi(c' + w_i) + \\phi(c' + w_j)$ with $\\phi(c') + \\phi(c' + w_i + w_j)$. \nBy the definition of ${\\rm sign}(w)$-supermodularity, \nif both entries $w_i$ and $w_j$ have the same sign, we require \n$$\\phi(c' + w_i) + \\phi(c' + w_j) \\leq \\phi(c') + \\phi(c' + w_i + w_j) $$\nwhile if $w_i w_j \\leq 0$, we require \n$$\\phi(c' + w_i) + \\phi(c' + w_j) \\geq \\phi(c') + \\phi(c' + w_i + w_j) .$$\nThe inequalities hold by the fact that $\\phi$ is convex.\nFor example, if $w_i,w_j\\geq0$, then $c\\leq c+w_i, c+w_j\\leq c+w_i+w_j$, and we apply the definition of convexity as applied to a comparison of four points.\n\n**Thus, in particular, a one-hidden layer ReLU neural network, when restricted to $\\\\{0,1\\\\}^n$ with $k$ hidden nodes with positive outer weights, is rank-$k$ supermodular.**"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6412/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700532024937,
                "cdate": 1700532024937,
                "tmdate": 1700532024937,
                "mdate": 1700532024937,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JSclguJmOd",
                "forum": "REKRLIXtQG",
                "replyto": "njCEWzw6W5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6412/Reviewer_jvwD"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6412/Reviewer_jvwD"
                ],
                "content": {
                    "comment": {
                        "value": "I'd like to thank the authors' response. I am satisfied with my second question. It is particularly interesting to see that there is a rank-k-supermodular function in neural networks. I believe this is an interesting work, and it's a good paper, but not in its current version due to the presentation."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6412/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700709960189,
                "cdate": 1700709960189,
                "tmdate": 1700709960189,
                "mdate": 1700709960189,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "F6yobVnidg",
            "forum": "REKRLIXtQG",
            "replyto": "REKRLIXtQG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6412/Reviewer_Pie2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6412/Reviewer_Pie2"
            ],
            "content": {
                "summary": {
                    "value": "This work measures how far a function $F$ from being submodular or supermodular. The main idea is the decomposition of $F$ into the sum of the smallest number $r$ of submodular function with a different total order on individual variables. The number $r$ is the submodular rank of $F$. The less interesting part of this work is the elementary submodular rank where the order can be reversed in one variable at most for each function. The paper proposes a simple R-SPLIT algorithm using the proposed notion, which splits up a function $f$ of rank $r+1$ into $2^r$ pieces and runs a simple algorithm e.g. greedy on each piece returning the best solution."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "It is clear that this work is novel in terms of the definitions of supermodular/submodular rank and elementary rank. This work also provides both theoretical results and empirical evaluation."
                },
                "weaknesses": {
                    "value": "The theoretical contribution of this work seems to be very weak. In particular, the elementary rank $r$ basically says that the function becomes submodular for all assignments to a subset of the variables, which leads to an exhaustive search for this subset. Hence, demonstrated by the complexity of the algorithmic part, the contribution of this work does not meet the bar of top-tier conferences such as ICLR. I have two additional comments:\n\n1. The current paper is very tough to read.\n2. The empirical evaluation is not convincing.\n\nMy suggestion to the authors is to consider submitting this paper to other venues such as ICALP, SODA, and ESA. The main reason behind this suggestion is that I think the paper can be presented much better without the practical part (which is not convincing in my opinion), which can be replaced by highlighting some non-trivial theoretical results such as Theorem 10."
                },
                "questions": {
                    "value": "1) Seems like when the submodular rank $r$ is high, the algorithms are impractical.\n2) Empirical evaluation is not convincing."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6412/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698691284744,
            "cdate": 1698691284744,
            "tmdate": 1699636714176,
            "mdate": 1699636714176,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "sbijaBFNbu",
                "forum": "REKRLIXtQG",
                "replyto": "F6yobVnidg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6412/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6412/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> The theoretical contribution of this work seems to be very weak. In particular, the elementary rank r basically says that the function becomes submodular for all assignments to a subset of the variables, which leads to an exhaustive search for this subset. \n\nAs the reviewer pointed out, the notion of supermodular rank is novel and interesting. Please see the general response for an explanation of our contributions.\n\nThe elementary supermodular rank is a particular case where we restricted the types of permutations that were allowed. Here, apriori, there is no reason that this notion would simplify to such an elementary property, but the fact that it does is quite interesting.\n \nBuilding on this, since the idea of supermodular rank is novel, this gradation of the space of set functions is new. It provides a valuable way to think about the complexity of set function optimization. \n\nRegarding the complexity of our algorithms, recall that there is no free lunch in optimization. Our paper provides a lower bound that says that set function optimization for a rank $r$ function necessarily requires $2^r$ function evaluations. Our algorithms can maintain a low complexity for optimizing functions with low elementary supermodular rank. By necessity, the complexity of optimizing general objective functions, or functions that have a high elementary supermodular rank, is high. To illustrate this more concretely, we can provide examples that serve as a lower bound as follows. \n\nLet $\\hat{f}$ be your favorite submodular function on a set of size $n-r$, and define $f$  to be an elementary rank-$r$ submodular function with pieces given by $\\hat{f}+c_k$. All of the pieces of $f$ are just shifts of $\\hat{f}$. To get an $O(1)$ approximation algorithm for general $c_k$'s, at the very minimum, we need to evaluate the function $f$ once at each of the $2^r$ shifts. Thus, we will always need at least $\\Omega(2^r)$  time. As mentioned in Remark 27, if the decomposition is known, which is the case for the lower bound, the only exponential term in the time complexity for R-split is $2^r$. Thus, the algorithm achieves the complexity lower bound. \n\nWe would also like to highlight that our algorithm is different from other methods. In particular, typically, algorithms for submodular optimization, such as the plain greedy, are analyzed for things like weak submodularity, but no changes are made to the algorithm to deal with the lack of submodularity. We exploit the non-submodularity structure by providing gradation on the space of functions. \n\nIn light of the above strengths, the fact our algorithm is additionally *simple* is an additional strength. \n\n> Hence, demonstrated by the complexity of the algorithmic part, the contribution of this work does not meet the bar of top-tier conferences such as ICLR. \n\nThe primary contribution of the paper is not algorithmic but theoretical. The main contributions are\n1. The definition of rank\n2. The proof of the maximal rank\n3. The gradation of the space set functions \n4. The results show that theoretical guarantees obtained for submodular functions can be lifted to higher ranks but with a necessary penalty. That is, this penalty cannot be avoided in some cases. \n\n> The current paper is very tough to read.\n\nWe thank the reviewers for their comments. We have updated the manuscript to add more explanatory examples to improve the paper\u2019s readability. The changes are highlighted in blue. \n\n> The empirical evaluation is not convincing.\n\nWe kindly disagree. The experimental results show a consistent and significant improvement in the performance compared to Greedy. For example, \n\n1. Figure 1a shows that the theoretical bound improves by 400\\% in one instance. \n2. Figure 1b shows orders of magnitude decrease in the error\n3. Figure 2a shows a consistent improvement as well. \n4. Figure 2b shows that in most cases, going from greedy to 1-split greedy, the percentage of times we find the optimal set more than doubles. \n5. Figure 2c shows that it scales to large problems, and we consistently have over 5\\% improvement. \n\n> Seems like when the submodular rank $r$  is high, the algorithms are impractical.\n\nYes, but we provide an impossibility result in approximating the solution to a related problem with less work."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6412/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700531971773,
                "cdate": 1700531971773,
                "tmdate": 1700531971773,
                "mdate": 1700531971773,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gij4T8AeAO",
                "forum": "REKRLIXtQG",
                "replyto": "sbijaBFNbu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6412/Reviewer_Pie2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6412/Reviewer_Pie2"
                ],
                "content": {
                    "comment": {
                        "value": "I would like to thank the authors for their response. My initial understanding of the paper would appear to be correct."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6412/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700602407788,
                "cdate": 1700602407788,
                "tmdate": 1700602407788,
                "mdate": 1700602407788,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Cc0EWGLQ0m",
            "forum": "REKRLIXtQG",
            "replyto": "REKRLIXtQG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6412/Reviewer_1L31"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6412/Reviewer_1L31"
            ],
            "content": {
                "summary": {
                    "value": "The authors introduce the concept of supermodular rank for functions defined on partially ordered sets. Supermodular rank characterizes how a function can be decomposed into a sum of functions that exhibit a \"supermodular\" property. This concept allows for a more refined understanding of the structure of set functions. The authors propose optimization algorithms, namely R-SPLIT and R-SPLIT RATIO, for optimizing monotone set functions and the ratio of set functions. These algorithms provide a trade-off between computational cost and accuracy, offering theoretical guarantees for their performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Introduction of Supermodular Rank: The concept of supermodular rank is considered interesting and valuable for understanding the structure of set functions.\n\n2. Optimization Algorithms: The proposed optimization algorithms, R-SPLIT and R-SPLIT RATIO, are seen as valuable contributions. They provide a trade-off between computational cost and accuracy while offering theoretical guarantees for their performance."
                },
                "weaknesses": {
                    "value": "1. Complex and Notation-Heavy: The paper is noted as being quite complex and filled with notation, making it challenging to follow. Simplifying the presentation or providing additional explanations could enhance the accessibility of the material.\n\n2. Lack of Clarity on Performance Improvement: The paper's comparison to existing solutions, particularly in Table 2, is mentioned as lacking clarity. It is not immediately clear how the proposed algorithm outperforms existing solutions. The authors should elaborate on the additional benefit brought by the proposed algorithm's computational overhead."
                },
                "questions": {
                    "value": "See Weakness 2 above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6412/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6412/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6412/Reviewer_1L31"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6412/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699586570703,
            "cdate": 1699586570703,
            "tmdate": 1699636714068,
            "mdate": 1699636714068,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "F5cccM27HN",
                "forum": "REKRLIXtQG",
                "replyto": "Cc0EWGLQ0m",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6412/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6412/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1L31"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their feedback. \n\n\u200b> Complex and Notation-Heavy The paper is noted as being quite complex and filled with notation, making it challenging to follow. Simplifying the presentation or providing additional explanations could enhance the accessibility of the material.\n\nWe thank the reviewers for their comments. We have updated the manuscript to add more explanatory examples to improve the paper\u2019s readability. The changes are highlighted in blue. \n\n> Lack of Clarity on Performance Improvement: The paper's comparison to existing solutions, particularly in Table 2, is mentioned as lacking clarity. It is not immediately clear how the proposed algorithm outperforms existing solutions. The authors should elaborate on the additional benefit brought by the proposed algorithm's computational overhead.\n\nThe table should be read not as saying that we improve the performance of the method (which we do show happens empirically), but in a different manner. Specifically, prior work showed that for a family of functions $\\mathcal{F}$, we can **prove** that we have a good approximation rate. With our framework, we can show that this approximation rate can be lifted to a larger family of functions $\\mathcal{G}$ such that $\\mathcal{F} \\subset \\mathcal{G}$. Table 1 shows that the size of $\\mathcal{G}$ can be significantly bigger than $\\mathcal{F}$."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6412/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700531741073,
                "cdate": 1700531741073,
                "tmdate": 1700531843858,
                "mdate": 1700531843858,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]