[
    {
        "title": "If there is no underfitting, there is no Cold Posterior Effect"
    },
    {
        "review": {
            "id": "kaH6g7yT9W",
            "forum": "zamGHHs2u8",
            "replyto": "zamGHHs2u8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6387/Reviewer_B5C9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6387/Reviewer_B5C9"
            ],
            "content": {
                "summary": {
                    "value": "This work investigates the so-called cold posterior effect, a phenomenon in Bayesian deep learning where it is observed that tempering the Bayesian posterior can counter-intuitively lead to improved test performance. The authors show how the CPE arises as a consequence of models under-fitting the data and demonstrate how this can be remedied precisely by lowering the temperature. They connect their findings with previously established theories surrounding the CPE and show that most such explanations can be unified within their framework."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The problem of the cold posterior effect has lead to a plethora of works aiming at understanding it and most of these explanations tackle very different aspects of this problem in very different ways. I think this work is a timely contribution as it tries to unify all these previous approaches in a single more \u201cglobal\u201d lens. The authors also show great knowledge of the related works, covering most of the contributions to this problem.\n2. I really find the result in Theorem 4 quite interesting and also somewhat surprising. I think this is actually the core result of this work although it is not really highlighted like that."
                },
                "weaknesses": {
                    "value": "1. I find the claims in this work somewhat misleading. The main contribution is the fact that if the posterior is not underfitting, then there is no cold posterior effect. But this statement is almost trivial as (almost) all that is to prove is already assumed in the statement. Underfitting, as defined by the authors, means \u201ca model having training and testing losses much higher than they could be i.e. there exists another model in the model class having simultaneously lower training and testing losses.\u201d Taking the opposite, no underfitting basically means that there is no model with better train and test loss, hence if the Bayesian posterior is not underfitting then of course there is no cold posterior effect. Am I missing something here? \u2028The authors then show that posteriors with smaller temperature having smaller training loss, which is not surprising since the effect of the prior is essentially down-weighted and the model concentrates more on the likelihood, which exactly guarantees a better fit. This, not very surprising fact does all the heavy-lifting here: If one now assumes CPE, then yes, there is a model with smaller temperature and better test loss, which also has smaller training loss but again, not much has been shown here. I also find all the mathematical notation more confusing than helpful here, it makes this relatively simple fact seem more complicated than it really is. I think my issues are somewhat addressed by Theorem 4 which seems to more strongly show the claims made **before** presenting it. I would really appreciate if the authors could clear up my confusion as to what is assumed when words like \u201cunderfitting\u201d are used, and what is proved rigorously. \n2. Theorem 4 is a very interesting result and I would have loved to see some empirical verification of it, i.e. if the posterior is optimal at $\\lambda = 1$, does the train loss really not change anymore if you add a new sample to the posterior (of course one would need to average over adding the sample)? Can you basically predict optimality of $\\lambda=1$ from this property alone? \n3. I think one important theoretical work in the literature regarding the origins of CPE in conjunction with data augmentation has not been treated in this work. While you cite [1] for re-scaling the prior, you don\u2019t discuss their results regarding data augmentation and how the correlations of errors, arising from assigning the same label to augmented samples, influences the resulting posterior. It is not obvious to me at first glance how those results can be casted within the under-fitting hypothesis of this work, especially the correlated nature of the data. Could you elaborate on the connection to your work?\n\n\n[1] Bachmann et al., How Tempering Fixes Data Augmentation in Bayesian Neural Networks"
                },
                "questions": {
                    "value": "In Proposition 3, how does the underlying data distribution $\\nu$ enter the picture here? The CPE is clearly a function of the data distribution $\\nu$ as it talks about generalisation loss, but the inequality seems to be independent of $\\nu$ except for involving training samples that are drawn from it. Could you elaborate how you are able to make this connection?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6387/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698750120123,
            "cdate": 1698750120123,
            "tmdate": 1699636707688,
            "mdate": 1699636707688,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ssPcmaI5Fy",
                "forum": "zamGHHs2u8",
                "replyto": "kaH6g7yT9W",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6387/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6387/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your feedback. Let us try to clarify the confusion. \n\n> Taking the opposite, no underfitting basically means that there is no model with better train and test loss, hence if the Bayesian posterior is not underfitting then of course there is no cold posterior effect. Am I missing something here?\n\n\n\nThis kind of reasoning can be tricky, we will try to explain here why \u201cno underfitting implies no CPE\u201d cannot be directly proved by simply inverting the definition (without using Theorem 2).\n\nIt\u2019s correct that no underfitting means there is no model with **both** better training **and** better testing loss **simultaneously**. Hence, the following must hold if there is no underfitting:\n1. If another model has better train loss, it must have worse test loss.\n2. If another model has better test loss, it must have worse train loss.\n\nThe situation, where increasing $\\lambda>1$ gives a better testing loss (there is CPE), itself contradicts neither situation 1) nor 2). It is because it could be the case where the tempered posterior has worse train loss (situation 2). Therefore, no underfitting and CPE could co-exist. \n\nHowever, situation 2) cannot happen as Theorem 2 shows that the train loss is also enhanced by increasing $\\lambda>1$. If you do not use Theorem 2 and try to show the implication from the definition, you do not reach any contradiction. \n\n> In Proposition 3, how does the underlying data distribution enter the picture here?\n\nProposition 3 is a consequence of Proposition 6 in Appendix A.3 and the definition of CPE. To shed some light here, Proposition 6 says essentially that the gradient of the Bayes loss has an equivalent form as the difference between the Gibbs loss of the updated posterior (Eq. (6)) and the tempered posterior; where the \u201cdata-generating distribution\u201d appears in the updated posterior. Next, the definition of CPE says the gradient of the Bayes loss is negative $< 0$, i.e, the Gibbs loss of the updated posterior is lower than the Gibbs loss of the tempered posterior. Hence, the Gibbs loss of the posterior cannot reach the minimum, which is the message of Proposition 3. Therefore, we don\u2019t see the data-generating distribution in the conclusion of Proposition 3 since the related quantity is thrown away in some sense in the middle of derivation.\n\n>Theorem 4 is a very interesting result and I would have loved to see some empirical verification of it, i.e. if the posterior is optimal at lambda=1, does the train loss really not change anymore if you add a new sample to the posterior (of course one would need to average over adding the sample)? Can you basically predict optimality of lambda=1 from this property alone?\n\nWe are really glad that you can appreciate the relevance of this result. Yes, if $\\lambda=1$ is optimal, then the training loss does not change for the updated posterior (in expectation). Please note Thm 4 establishes a  \u201cif and only if\u201d condition. \n\nWe will try to highlight this result more in the new version. And we also plan to include a table like the next one illustrating this result for the linear regression model of Figure 1 under the four setups depicted there. \n\n|               | Fig.1(a): no CPE | Fig.1(b): WPE | Fig.1(c): CPE-likelihood | Fig.1(d): CPE-prior |\n|--------------------------------------------|------------------|---------------|--------------------------|---------------------|\n| $\\hat{G}(p,D)$                             | 1.521            | 0.467         | 1.922                    | 1.996               |\n| Mean of 10 estimates of $\\hat{G}(\\bar{p},D)$                       | 1.519            | 0.536         | 1.888                    | 1.905               |\n| Standard Deviation of 10 estimates of $\\hat{G}(\\hat{p},D)$ | 0.009            | 0.013         | 0.009                    | 0.009               |\n\nAs can be seen, when there is no CPE the train loss does not change, as predicted by Thm 4. And, as Proposition 6 in the Appendix also predicts, when there is a \u201cwarm posterior effect\u201d, the train loss of the expected updated posterior becomes bigger.  And when there is CPE, the train loss of the expected updated posterior becomes smaller. We plan to add this discussion to the main paper. Thanks for bringing this up!"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6387/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700162290854,
                "cdate": 1700162290854,
                "tmdate": 1700162290854,
                "mdate": 1700162290854,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ybWrG760A2",
                "forum": "zamGHHs2u8",
                "replyto": "aRJOeLNIsy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6387/Reviewer_B5C9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6387/Reviewer_B5C9"
                ],
                "content": {
                    "title": {
                        "value": "Reply"
                    },
                    "comment": {
                        "value": "I thank the authors for their response!\n\n**No underfitting --> No CPE:** I'm still not convinced by this point and especially the \"amount\" of that statement that the authors actually need to prove.\n\nLet's assume that we have no underfitting of the posterior, i.e. the posterior $f$ is optimal and any other (tempered) posterior $f^T$ that reaches better training loss must have worse test loss (this all comes from the definition of overfitting). Now it is not very surprising that reducing the temperature leads to better training loss as we upscale the importance of the likelihood, reducing the regularisation effect of the prior.  If one accepts that Bayesian models tend to fit their training data slightly worse than the same models purely optimised in an MLE-sense (which is pretty much known to any ML practitioner), then the claim basically becomes a consequence of the definition. That's why I feel like the definition of \"underfitting\" basically does all the heavy-lifting. Theorem 2 makes the \"T small --> training loss small\" mathematically explicit but also makes things look more complicated than they really are. All that is needed for the core-characterisation is that Bayesian models fit worse on training data, so to me the insights from this must be limited.\n\n**Experiments for Thm 4:** Thanks for performing these experiments, that's a nice result. \n\n**Comparison to [1]**: Thank you for this comparison, I think this makes sense. I guess the fact that samples are correlated can be absorbed into the underfitting notion, which does not care about how samples correlate? In a sense that is nice as it makes things easier, but again I have the feeling that such a point of view might miss important details. Or how would the fact that observations (or more precisely, errors) are correlated enter into your framework?\n\nOverall, I remain reluctant to increase my score as the entire paper builds upon the notion of underfitting, which again to me is almost a rephrasing of the cold posterior effect as it only relies on the fact that Bayesian models fit their training data worse. I might still be missing something on the other hand and I ask the authors to point out if something in my assessment is wrong."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6387/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700476222223,
                "cdate": 1700476222223,
                "tmdate": 1700476222223,
                "mdate": 1700476222223,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "U2NGg8IzY5",
            "forum": "zamGHHs2u8",
            "replyto": "zamGHHs2u8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6387/Reviewer_MuTU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6387/Reviewer_MuTU"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents in a theoretical and empirical setup that the presence of CPE implies the existence of under-fitting along with previous evidence of CPE such as misspecification of the prior and the likelihood. That is in a way that the misspecification of the prior or the likelihood have underfitting as an outcome and therefore the CPE."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "-Interesting take on the CPE problem that might give light to new avenues on why CPE exists and how to tackle it.\n-Potential of good value if the argument is made more clear or presented in a better way."
                },
                "weaknesses": {
                    "value": "-The argument is a bit unclear from my perspective. The authors argue that the problem is under-fitting which comes from misspecification. So is the problem the under-fitting or the misspecification which causes the under-fitting.\n-The paper seems to be stepping on previous results and works, claiming that the misspecification of the prior or the likelihood lead to underfitting, and therefore underfitting is the problem that causes CPE. Well if CPE is present when under-fitting is present then the problem falls on either the prior or the likelihood.\n-Some of the results are not convincing. A simple linear regression model on synthetic data is not enough in Figure 1. Figure 2 and 3 are also a bit unclear."
                },
                "questions": {
                    "value": "My main question is what is the argument that the authors are making? Reading the paper it looks like you are arguing that misspecification is causing the CPE by causing underfitting. It is well known that any misspecification in Bayesian setups leads to lower performance. \n\nI think I have understood the math and the experiments of the paper but the main argument does not seem very novel. Can the authors better explain?\n\nOne tip that I can give on the presentation is to add the results of the big models in the main text and the toy experiments in the Supplement. Or have a gradual increase of difficulty in the presentation of the experiments. For instance you start with linear regression on synthetic data, then you have a ResNet experiment on CIFAR10 and then on Imagenet."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6387/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6387/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6387/Reviewer_MuTU"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6387/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698795041789,
            "cdate": 1698795041789,
            "tmdate": 1699636707554,
            "mdate": 1699636707554,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jd2OiV5YMT",
                "forum": "zamGHHs2u8",
                "replyto": "U2NGg8IzY5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6387/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6387/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your feedback. Let us try to clarify the confusion. \n\n> The argument is a bit unclear from my perspective. The authors argue that the problem is under-fitting which comes from misspecification. So is the problem the under-fitting or the misspecification which causes the under-fitting\n\n> The paper seems to be stepping on previous results and works, claiming that the misspecification of the prior or the likelihood lead to underfitting, and therefore underfitting is the problem that causes CPE. Well if CPE is present when under-fitting is present then the problem falls on either the prior or the likelihood.\n\n> My main question is what is the argument that the authors are making? Reading the paper it looks like you are arguing that misspecification is causing the CPE by causing underfitting. It is well known that any misspecification in Bayesian setups leads to lower performance.\n\n> I think I have understood the math and the experiments of the paper but the main argument does not seem very novel. Can the authors better explain?\n\nTo start, we would like to clarify that the main takeaway message of our work is the following: **The presence of CPE implies that our Bayesian setup is misspecified and underfitting at the same time.**\n\nThis is a simple, clean but actually **novel** way to interpret CPE.\n1. Connections to previous work: The connection with underfitting has not been made before when trying to understand CPE. Most of the current literature focuses on the misspecification problem itself, but **not on misspecification in the context of underfitting**. We find it quite important that the ML community is fully aware of this point.\n2. \u201cit is well known that any misspecification in Bayesian setups leads to lower performance.\u201d: We totally agree. But this \u201clower performance\u201d can be due to **underfitting or overfitting**, i.e., you can have a misspecified model that is severely overfitting your training data, as we show in Figure 1 (b). Understanding which of the two is present when we observe CPE is quite relevant. Reviewer wHkC states that this question \u201c hold[s] profound implications.\u201d \n\nHaving said that, we agree that we could do better in characterizing the relationship between misspecification and underfitting and will do so in the final version.\n\n>Some of the results are not convincing. A simple linear regression model on synthetic data is not enough in Figure 1. Figure 2 and 3 are also a bit unclear.\n\n>One tip that I can give on the presentation is to add the results of the big models in the main text and the toy experiments in the Supplement. Or have a gradual increase of difficulty in the presentation of the experiments. For instance you start with linear regression on synthetic data, then you have a ResNet experiment on CIFAR10 and then on Imagenet.\n\nThanks for this tip! We will consider your advice in the next version."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6387/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700160549144,
                "cdate": 1700160549144,
                "tmdate": 1700160549144,
                "mdate": 1700160549144,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "w7xbM7odhg",
                "forum": "zamGHHs2u8",
                "replyto": "jd2OiV5YMT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6387/Reviewer_MuTU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6387/Reviewer_MuTU"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for the response. After reading Reviewer B5C9's review and discussion, I understand that we have a similar way of seeing the situation. I am still a bit reluctant about increasing my score, since the argument made here is not novel. I will keep my score of 5. I would suggest the authors to rethink of the way of presenting the argument as something different than underfitting."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6387/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700611985713,
                "cdate": 1700611985713,
                "tmdate": 1700611985713,
                "mdate": 1700611985713,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "6aJfdtVhfw",
            "forum": "zamGHHs2u8",
            "replyto": "zamGHHs2u8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6387/Reviewer_wHkC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6387/Reviewer_wHkC"
            ],
            "content": {
                "summary": {
                    "value": "- The paper claim that if there is cold posterior effect, it means the posterior distribution is underfitted.\n\n- They provide theoretical and experimental evidence which support their claim."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- They address a highly significant issue, and their arguments hold profound implications. If properly substantiated, their work is poised to be regarded as a pivotal study.\n\n- Their notation is clean, and well-written."
                },
                "weaknesses": {
                    "value": "$\\bf{(Major)}$\n\nAccording to the definition of CPE, as lambda increases, the test loss should decrease. Additionally, as $\\lambda$ increases, the train loss always decreases irrespective of CPE. Up to this point, arguments in Theorem 2, Proposition 3 are accurate but rather self-evident.  \n\nHowever, they have not demonstrated that the distribution, whose existence was proven, becomes a posterior distribution (which should be definable from a new likelihood or a new prior). Hence, according to the definition \u201cunderfitting\u201d defined by authors, Insight 1 may not be correct. \n\nAfter demonstrating that, I believe at least one of the following two pieces of evidence should be provided. \n1) The original likelihood (or prior) is misspecified, compare to new likelihood (or prior). \n2) An inverse proposition also holds.(i.e., If there is underfitting, there exists CPE). \n\nIn the current manuscript, I believe that their main claim has not been theoretically clarified.\n\n$\\bf{(Minor)}$\n\nIt seems that Figure 2 and Figure 3 do not connect well with the main claims of the paper. The common implication in the results appears to merely suggest that \"CPE exists in image data analysis.\""
                },
                "questions": {
                    "value": "In page 3, authors state that\n\n\u201cIn the context of Bayesian inference, we argue that the Bayesian posterior is underfitting if there exists another posterior distribution with lower empirical Gibbs and Bayes losses at the same time.\u201d\n\nIs this a commonly accepted concept or a newly proposed one? If it's the former, it seems appropriate to provide references."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6387/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698803222400,
            "cdate": 1698803222400,
            "tmdate": 1699636707434,
            "mdate": 1699636707434,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6JBLtqaxRa",
                "forum": "zamGHHs2u8",
                "replyto": "6aJfdtVhfw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6387/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6387/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your feedback. Let us try to clarify in the following. \n\n> According to the definition of CPE, as $\\lambda$ increases, the test loss should decrease. Additionally, as  $\\lambda$  increases, the train loss always decreases irrespective of CPE. Up to this point, arguments in Theorem 2, Proposition 3 are accurate but rather self-evident.\n\nAs we have answered in the overall rebuttal at the top of the page, we do agree that the connection is, in some sense, straightforward.  However, it's noteworthy that this link has not been recognized in the literature. The primary contribution of our study is to make the community aware of this connection. Because it is essential for comprehending and addressing the challenges associated with CPE.\n\nHaving said that, our formalization also provides new insights into CPE. Theorem 4 provides an interesting characterization not done before. Reviewer B5C9 is very positive about it. In our opinion, the connection with Data Augmentation does also provide new insights. \n\n\n\n> However, they have not demonstrated that the distribution, whose existence was proven, becomes a posterior distribution (which should be definable from a new likelihood or a new prior). Hence, according to the definition \u201cunderfitting\u201d defined by authors, Insight 1 may not be correct.\n\n\nLet us first clarify that, in our work, we refer to a \u201cposterior distribution\u201d to **any distribution over the parameter space which depends on the training data**. We refer to the \u201cBayesian posterior distribution\u201d to a \u201cposterior distribution\u201d which is the result of the strict application of the Bayes\u2019 rule. I.e.,  $p^\\lambda(\\theta|D)$ is a posterior distribution, while $p^{\\lambda=1}(\\theta|D)$ is the Bayesian posterior distribution. We will make this distinction crystal clear in our paper. \n\nTherefore, Insight 1 is correct as we said \u201cthere exists **another posterior**, rather than **another Bayesian posterior**, that has lower training and testing loss at the same time.\u201d\n\nAs you say,  it would be great to know if this tempered posterior can be attained by some other Bayesian posterior coming from another likelihood/prior. We think this indeed is an interesting question. Although we think it is out of the scope to include this in our paper, where the focus is to highlight the connection between CPE and underfitting that has been overlooked so far, there are references showing positive answers, which we provide in the next section.\n\n>  I believe at least one of the following two pieces of evidence should be provided. \nThe original likelihood (or prior) is misspecified, compared to new likelihood (or prior).\nAn inverse proposition also holds.(i.e., If there is underfitting, there exists CPE).\n\nThe first point is highly related to the previous question; it is clear that if CPE is present, prior and/or likelihood are misspecified, otherwise the Bayesian posterior would be optimal and CPE would not be present. As far as we know, at least in certain cases, the tempered posterior can be derived as the Bayesian posterior with a proper likelihood and prior (Wenzel et al., 2020 Wilson, Izmailov, 2020, Nabarro et al., 2022). Please refer to those for more details.\n\n\nRegarding the inverse proposition; whether it holds is also a good question. However, it is not true in general; consider the extreme case where the prior distribution is a delta distribution centered at a model that does not explain either train or test data, let\u2019s say $\\theta_0$. In this setting, the Bayesian posterior is\n$$\np(\\theta|D) \\propto P(D|\\theta)p(\\theta),\n$$\nwhich is also a delta distribution centered at $\\theta_0$. The same happens with any tempered posterior. Even if the model $\\theta_0$ is underfitting (there exist models with better training and testing loss), CPE does not appear in this context.\n\n> In the current manuscript, I believe that their main claim has not been theoretically clarified.\n\nWith the above clarifications, our claim \u201cIf CPE is present, there exist alternative **posteriors** with better train and test loss\u201d theoretically holds. As said before, what we don\u2019t show is that \u201cIf CPE is present, there exist alternative **Bayesian posteriors** with better train and test loss\u201d theoretically holds. We are fully aware this would be a stronger result. But we do consider this paper as a first step in this direction. This work can help to bring attention to this relevant open questions."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6387/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700153426446,
                "cdate": 1700153426446,
                "tmdate": 1700153426446,
                "mdate": 1700153426446,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "d6mBmS3hpe",
                "forum": "zamGHHs2u8",
                "replyto": "K10nUFr2JT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6387/Reviewer_wHkC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6387/Reviewer_wHkC"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for authors\u2019 responses and discussions.\nThe rebuttal has helped me understand exactly what the paper's claims are and what implications it intends to give.\nTheir claim (Insight 1) is valid, and I understand that it is logically flawless.\nHowever, after hearing their definition of 'posterior distribution,' my impression that it resembles an obvious proposition akin to wordplay has intensified.\nAdditionally, even if this state has not existed before, I am especially doubtful about what implication this state can provide for AI.\nFor these reasons, I have decided not to lower or raise the score."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6387/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700707286788,
                "cdate": 1700707286788,
                "tmdate": 1700707286788,
                "mdate": 1700707286788,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Yqn2Sc9Ssb",
            "forum": "zamGHHs2u8",
            "replyto": "zamGHHs2u8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6387/Reviewer_dcZF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6387/Reviewer_dcZF"
            ],
            "content": {
                "summary": {
                    "value": "The authors investigate the cause of the cold posterior effect (CPE) and argue that it is due to model underfitting. They do this both analytically and empirically; they show theoretically that the CPE implies underfitting and further construct experiments to analyse the influence of likelihood and prior misspecification as well as data augmentation. They conclude that each of these settings induces a CPE only if they cause the posterior to underfit. They further show that the CPE exists even for models that allow for exact Bayesian inference and that a \"warm\" posterior effect can occur too when the likelihood is misspecified. Together, these results explain why certain priors and likelihoods can lead to a CPE, as well as why larger models suffer less from the CPE."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1. The paper presents an elegant unification of previous explanations and observations of the CPE as being due to underfitting. It explains both the role of prior or likelihood misspecification as well as addresses the observed CPE when using data augmentations, which is really remarkable.\n2. The experiments are cleverly designed and convey some great insights into the CPE.\n3. The paper is well-written, and the authors do a great job of explaining ideas and results that are quite abstract.\n4. The paper is original and of high technical quality. It seems bound to become extremely significant for understanding the CPE and will therefore be of great interest to the ICLR community."
                },
                "weaknesses": {
                    "value": "This might be the first time I have struggled to find weaknesses in a paper. While the usual do-more-experiments comment can always be used, I cannot think of particular experiments that would dramatically contribute to the paper. It seems to be all-round solid work."
                },
                "questions": {
                    "value": "**Questions**  \n1. Your results indicate that larger model capacities should be less susceptible to the CPE since they are less likely to underfit. However, Wenzel et al. (2020), figure 11, actually show the opposite, namely that increasing the depth of an MLP has no effect on the CPE, and that increasing the width makes the effect more pronounced. Do you have any thoughts on this?\n2. I am trying to understand what the next steps for research on this topic might be. Did you observe any situations where underfitting could not explain the CPE?\n3. Do you have any suggestions for future work?\n\n\n**Suggestions**  \n- Minor thing: the plots seem to have been rasterised with such high resolution that my pdf viewer struggles. I would suggest using vector graphics instead."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6387/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699409531384,
            "cdate": 1699409531384,
            "tmdate": 1699636707276,
            "mdate": 1699636707276,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5BFhOd3vTY",
                "forum": "zamGHHs2u8",
                "replyto": "Yqn2Sc9Ssb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6387/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6387/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your positive review. We answer to your questions below:\n\n>Your results indicate that larger model capacities should be less susceptible to the CPE since they are less likely to underfit. However, Wenzel et al. (2020), figure 11, actually show the opposite, namely that increasing the depth of an MLP has no effect on the CPE, and that increasing the width makes the effect more pronounced. Do you have any thoughts on this?\n\nThanks a lot for pointing us to this figure. We did not realize this experiment was present there. One of the possible explanations is that they are using full-tempering while we are using likelihood tempering.\n1. For full-tempering, Theorem 2 does not necessarily hold anymore. Intuitively, since \\lambda works on both likelihood (data) and prior (regularization) together, the effect of increasing \\lambda is mixed, thus not necessarily improving the fit on training data.\n2. Thus, the CPE brought by full-tempering, as \\lambda increases, does not necessarily come with a better training loss, i.e., training loss may not be improvable. Hence, full-tempered CPE can no longer be interpreted as just underfitting only.\n3. As such, for full-tempering, increasing the model capacity may not achieve a lower degree of CPE as in our case.\nHowever, we believe it\u2019s still valuable and will reproduce this experiment with likelihood-tempering to clear the argument. \n\n> I am trying to understand what the next steps for research on this topic might be. Did you observe any situations where underfitting could not explain the CPE?\n\nIf there is CPE, then your Bayesian posterior is underfitting. But, it might be the case that the posterior is underfitting and you do not have CPE. We haven\u2019t said anything about the reverse implication. But, we do think this implication does not really hold in general. In the response to Reviewer wHkC we provide a counterexample. \n\nFor us, a relevant question is: is there any problem in working with tempered posteriors? What is preventing us from tuning this hyperparameter when using a Bayesian approach? This lambda hyper-parameter could be tuned using, for example, an independent validation dataset. Providing theoretical arguments in favor of this approach would be valuable. This work would support this, because if we do not do it, we know we are not squeezing out all the power of (generalized) Bayesian methods."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6387/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700149588920,
                "cdate": 1700149588920,
                "tmdate": 1700149588920,
                "mdate": 1700149588920,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]