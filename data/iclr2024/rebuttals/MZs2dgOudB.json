[
    {
        "title": "Exploring Active Learning in Meta-Learning: Enhancing Context Set Labeling"
    },
    {
        "review": {
            "id": "4qaFoJ6F0w",
            "forum": "MZs2dgOudB",
            "replyto": "MZs2dgOudB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9044/Reviewer_r9Lv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9044/Reviewer_r9Lv"
            ],
            "content": {
                "summary": {
                    "value": "The paper focuses on active meta-learning. Firstly, it summarizes different ways of combining active learning with meta learning. Additionally, it suggested a new active learning methods based on Gaussian Mixture Selection for the testing stage of meta learning. The paper presents numerous experiments conducted on real-world datasets, comparing the results with baseline algorithms."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper gives a comprehensive summarization of the active selecting context in Meta learning, presentation and notation in this section is clear. \n\nThe paper provides numerous experiment results on both classification and regression problems."
                },
                "weaknesses": {
                    "value": "The contribution of this paper is incremental. As the paper points out, Gaussian Mixture selection for active learning is not new. Although the paper combines it with meta learning, but the nothing is tailored for meta learning. To me, it simply applies existing algorithms in the testing stage of meta learning. \n\nSome presentation in this paper is not good. For example, in the introduction, the paper does not explicitly highlight that the proposed method is designed for low budget, especially one-shot learning under an unstratified setting. In section 3.2, the paper proposes to use penultimate layer of the initialization neural net as the features for active context selection, but this important detail is only mentioned midway through that section. \n\nThe choice of Gaussian Mixture Selection is not adequately explained, and the paper fails to discuss its advantages compared to other clustering algorithms."
                },
                "questions": {
                    "value": "In Figure 2, the caption mentions that the figure depicts mean and standard error, but in the figure itself, it actually represents accuracy.\n\nIn proposition 1, it should it be \"X|Y =  x~N(mu_y, sigma^2 I)\" ? And why this proposition is beneficial for active learning is not fully discussed. \n\nIn Figure 3, why is Gaussian Mixture Selection effective in covering more classes in the one-shot unstratified task? This appears to be a challenging task for unsupervised learning without the aid of labels. How does Gaussian Mixture Selection outperform other competing algorithms in this context?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9044/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9044/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9044/Reviewer_r9Lv"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9044/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698598623907,
            "cdate": 1698598623907,
            "tmdate": 1700600185372,
            "mdate": 1700600185372,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "koYtY8AVXA",
                "forum": "MZs2dgOudB",
                "replyto": "4qaFoJ6F0w",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer r9Lv (1/3)"
                    },
                    "comment": {
                        "value": "Thank you for your comments. Please see the common response above, in addition to discussion here.\n\n\n> The contribution of this paper is incremental. As the paper points out, Gaussian Mixture selection for active learning is not new. Although the paper combines it with meta learning, but the nothing is tailored for meta learning. To me, it simply applies existing algorithms in the testing stage of meta learning.\n\nWe would first like to argue that the proposed GMM method is indeed particularly suited to meta-learning as we mentioned in the first response of the common response above. The reviewer will find more detailed answers there but here, we summarize it as follows:\n\n\n1. We proposed the GMM method for very low budget regime where meta-learning belongs. The budgets of low budget active learning methods (around 60, 600, or 6000) are still much larger than that of typical meta learning where it is usually $\\leq 25$. \n2. The GMM method ensures that the context set is \u201cgood reference\u201d for the target set, even in the worse case, as it selects the samples closest to the cluster means as the context set. It is opposite with uncertainty-based methods where they select samples in less dense regions. Even the low budget active learning methods select points in locally dense regions, not global coverage.\n\nWe hope the reviewer recognizes that our work is specifically tailored for meta-learning. However, if there are still disagreements on this aspect, we would be more than willing to engage in further discussion to provide additional clarification or address any concerns..\n\n\n\n\n> Some presentation in this paper is not good. For example, in the introduction, the paper does not explicitly highlight that the proposed method is designed for low budget, especially one-shot learning under an unstratified setting. \n\nIn the third paragraph of introduction, we specified that our focus is on active meta-learning and raised the question, \"How can a meta-learner exploit an active learning setup to learn the best model possible, using only a very small number of labels in its context sets?\u201d. In addition to this explicit reference to \u201ca very small number of labels,\u201d the vast majority of the extensive literature on meta-learning is for low-budget settings (one- or five-shot cases).\n\nWe are willing to make this clearer if the reviewer still thinks it is not clearly highlighted enough, or to address any other points of presentation which are \u201cnot good.\u201d\n\n\n\n> In section 3.2, the paper proposes to use penultimate layer of the initialization neural net as the features for active context selection, but this important detail is only mentioned midway through that section.\n\nFirst, we did briefly mention this point in the introduction: \u201cIn particular, we propose a natural algorithm based on fitting a Gaussian mixture model to the unlabeled data, using meta-learned feature representations.\u201d\n\nAlso, we frame active meta-learning in Section 2 and propose our method in Section 3. In Section 3.1, we review how previous works in active learning works, particularly focusing on low budget active learning since they are competing algorithms to ours. Then, in Section 3.2, we explained how features are selected in our method. Although feature selection is an important aspect of the algorithm, we think it makes sense to introduce how related methods work first. If you have a suggestion for a logical earlier place to discuss this place, however, we\u2019re happy to take any suggestions."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700471178938,
                "cdate": 1700471178938,
                "tmdate": 1700471178938,
                "mdate": 1700471178938,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mKJmsaV7p6",
                "forum": "MZs2dgOudB",
                "replyto": "4qaFoJ6F0w",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer r9Lv (2/3)"
                    },
                    "comment": {
                        "value": "> The choice of Gaussian Mixture Selection is not adequately explained, and the paper fails to discuss its advantages compared to other clustering algorithms.\n\nOne advantage of a very simple method is that it can be fully explained very briefly, which we do at the beginning of Section 3.3: \u201cfit a mixture of $k$ Gaussians to the unlabeled data features, where $k$ is the label budget, using EM with a $k$-means initialization. We use a shared diagonal covariance matrix. Once a mixture is fit, we select the highest-density point from each component: \n$\\arg \\min_{x \\in \\mathcal U } (x - \\mu_j)^T \\Sigma^{-1} (x - \\mu_j)$  for each $j \\in [k]$.\u201d\n\nFor the sake of full completeness, we added more details about fitting Gaussian mixtures with EM to Appendix M.\n\nIn terms of choosing Gaussian mixtures over other clustering algorithms, we indeed provided multiple empirical comparisons. Typiclust, based on $k$-means, is compared with in Tables 1-5 and 7-11. Table 6, in Appendix E, further directly compares Gaussian mixture modeling to $k$-means with exactly the same algorithm in two settings (MinImageNet with MAML and FC100 with ProtoNet). We further added a comparison to $k$-means++ initialization below, and updated Table 6 below. GMM generally either matches or significantly outperforms $k$-means methods, other than a single case where $k$-means++ performed slightly better (1-shot unstratified on MiniImageNet).\n\nLastly, we also provided comparison with hybrid active learning methods, many of which have clustering components, in the common response as well as Appendix L. \n\nHowever, if the reviewer has particular clustering-based active learning methods that the reviewer thinks we need to compare ours with, please let us know. We are eager to conduct more experiments to enhance our work.\n\n| $Pick^{eval}_\\theta$ | 1-Shot fully strat. | 1-Shot train strat. | 1-Shot unstrat.  | 5-Shot fully strat. | 5-Shot train strat. | 5-Shot unstrat.  |\n| -------------------- | ------------------- | ------------------- | ---------------- | ------------------- | ------------------- | ---------------- |\n| $k$-means            | 56.75 $\\pm$ 0.20    | 33.29 $\\pm$ 0.26    | 37.26 $\\pm$ 0.18 | 65.76 $\\pm$ 0.18    | 41.61 $\\pm$ 0.24    | 59.17 $\\pm$ 0.20 |\n| $k$-means++          | 56.12 $\\pm$ 0.26    | 32.87 $\\pm$ 0.32    | 38.53 $\\pm$ 0.21 | 65.49 $\\pm$ 0.21    | 43.61 $\\pm$ 0.32    | 58.63 $\\pm$ 0.26 |\n| GMM (ours)           | 58.82 $\\pm$ 0.24    | 33.34 $\\pm$ 0.24    | 37.68 $\\pm$ 0.19 | 67.18 $\\pm$ 0.18    | 54.35 $\\pm$ 0.20    | 59.05 $\\pm$ 0.20 |\n\n**Table. Comparison of the variants of $k$-means with GMM on MiniImageNet using MAML**\n\n\n\n| $Pick^{eval}_\\theta$ | 1-Shot fully strat. | 1-Shot train strat. | 1-Shot unstrat.  | 5-Shot fully strat. | 5-Shot train strat. | 5-Shot unstrat.  |\n| -------------------- | ------------------- | ------------------- | ---------------- | ------------------- | ------------------- | ---------------- |\n| $k$-means            | 50.20 $\\pm$ 0.17    | 29.69 $\\pm$ 0.20    | 35.03 $\\pm$ 0.23 | 54.07 $\\pm$ 0.17    | 41.42 $\\pm$ 0.23    | 41.34 $\\pm$ 0.23 |\n| $k$-means++          | 49.91 $\\pm$ 0.17    | 27.27 $\\pm$ 0.22    | 34.93 $\\pm$ 0.27 | 54.72 $\\pm$ 0.30    | 41.61 $\\pm$ 0.39    | 42.64 $\\pm$ 0.39 |\n| GMM (ours)           | 50.22 $\\pm$ 0.18    | 34.23 $\\pm$ 0.23    | 35.03 $\\pm$ 0.23 | 54.76 $\\pm$ 0.17    | 46.30 $\\pm$ 0.21    | 47.03 $\\pm$ 0.20 |\n\n**Table. Comparison of the variants of $k$-means with GMM on FC100 using ProtoNet.**\n\n\n\n> In Figure 2, the caption mentions that the figure depicts mean and standard error, but in the figure itself, it actually represents accuracy.\n\nThe values refer to the mean and standard error of the accuracy; we believe this was clear from context in the first place (the only other interpretation we can see being that they would refer to the mean features, which would not make sense), but we have made this more explicit in the revised paper."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700471273763,
                "cdate": 1700471273763,
                "tmdate": 1700471273763,
                "mdate": 1700471273763,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GwK0usclTo",
                "forum": "MZs2dgOudB",
                "replyto": "4qaFoJ6F0w",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer r9Lv (3/3)"
                    },
                    "comment": {
                        "value": "> In proposition 1, it should it be \u201c$X|Y = x~N(\\mu_y, \\sigma^2 I)$\" ? And why this proposition is beneficial for active learning is not fully discussed.\n\nWe meant what we wrote: the random variable $X$, conditioned on the random variable $Y$ (the label) taking a specific value $y$ (e.g. 2), follows a Gaussian distribution with mean $\\mu_y$ and covariance $\\sigma^2 I$. We added parentheses to hopefully make the equation more unambiguous.\n\nIn Section 3.3, right before the Proposition 1, we specified that \u201cif class-conditional data distributions are isotropic Gaussians with the same covariance matrices, labeling the cluster centers can be far preferable to labeling a random point from each cluster.\u201d \nThis statement is backed up by Proposition 1: when we use a max-margin separator (as in MetaOptNet or, asymptotically, ANIL), training on cluster centers yields the Bayes-optimal classifier. This would not be the case with randomly selected data points. This is further illustrated by Figure 4 in Appendix A.\n\nFor more general settings, we argue that GMM is still a good method based on being an efficient set cover (e.g. Figure 5 in Appendix A).\n\nIf any aspects remain unclear, we welcome your further inquiries. Your feedback is invaluable, and we appreciate your thorough review.\n\n\n\n> In Figure 3, why is Gaussian Mixture Selection effective in covering more classes in the one-shot unstratified task? This appears to be a challenging task for unsupervised learning without the aid of labels. How does Gaussian Mixture Selection outperform other competing algorithms in this context?\n\nThank you for bringing up an important question. We posit that the inferiority of the other competing methods compared to GMM may be attributed to its implicit exploration of locally dense regions or inappropriate measure of representativeness. Here we analyzed potential reasons of their failure in very low budget regime.\n\n\n- Typiclust: after conducting $k$-means, it selects samples for each cluster $j$, based on $ \\arg \\max_{x \\in \\mathcal clust_j} ( \\frac{1}{K} \\sum_{x_i \\in KNN(x)} || x - x_i ||_2 ) ^{-1} $ where KNN denotes $k$-nearest neighbors of which size is fixed to 20. This measure seeks for locally dense region by selecting samples that are close to its nearest neighbors.\n- ProbCover: it greedily finds the maximally covering samples given a fixed radius. This greedy algorithm provide $(1 - \\frac{1}{e})$-approximation for the optimal solution but the gap with the optimal solution can be quite large. Also, the selection of the radius is hard as we discussed in Appendix F. When the radius is small, it tries to find samples that are in locally dense regions.\n- DPP: it finds samples of which a kernel matrix (with a pre-defined kernel function) has the maximum determinant, which implicitly finds diverse samples. The determinant of a matrix, however, may not align with selecting maximum covering (or representative) samples. In particular, maximizing the determinant of the kernel matrix may lead to selecting samples far away from other samples.\n\nCompared to these methods, GMM tries to find globally representative samples in non-greedy fashion (using expectation maximization). Also, its measure of covering other samples is in Mahalanobis distance, which intuitively makes more sense than the determinant of a kernel matrix as a measure. The proposed GMM method is also theoretically motivated by the Proposition 1, which says a classifier trained with the selected samples from GMM (cluster means) is a Bayes-optimal classifier under certain conditions."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700471416510,
                "cdate": 1700471416510,
                "tmdate": 1700471416510,
                "mdate": 1700471416510,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ObfSysVO5J",
                "forum": "MZs2dgOudB",
                "replyto": "GwK0usclTo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9044/Reviewer_r9Lv"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9044/Reviewer_r9Lv"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate your thoughtful response to my feedback. Your arguments solve some of my concerns about the paper, especially they answer my last question, I'll raise my score to 6."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700600171014,
                "cdate": 1700600171014,
                "tmdate": 1700600171014,
                "mdate": 1700600171014,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KJTSPW7sVd",
            "forum": "MZs2dgOudB",
            "replyto": "MZs2dgOudB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9044/Reviewer_EFev"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9044/Reviewer_EFev"
            ],
            "content": {
                "summary": {
                    "value": "the abstract discusses the concept of active meta-learning, which involves actively selecting which data points to label in the context set during the meta-learning process. A proposed algorithm based on fitting Gaussian mixtures is introduced. The key findings suggest that this algorithm outperforms state-of-the-art active learning methods when used with various meta-learning algorithms across multiple benchmark datasets. In essence, the study highlights the potential advantages of integrating active learning principles into meta-learning to improve performance"
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "Overall, the motivation of this paper is very interetsting to use active learning to save the label cost in meta learning. This paper summarize the difference of current related work and clarify their difference. I appreciated the conducted experiments."
                },
                "weaknesses": {
                    "value": "The technique novelty is too limited. The introduced algrithm is very simple based on normal distribution. So, the overal paper looks more like a technique report or a survey."
                },
                "questions": {
                    "value": "If the algorithm is theoretically motivated, why is there no theories or lemmas in the mainbody?\n\n____\nAfter rebuttal: I appreciate the author's response and added experiments. I would suggest adding more theoretical analysis to the main body for a simple method and moving a part of related work to the Appendix. Some short-paper tracks may be more suitable for this paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9044/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9044/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9044/Reviewer_EFev"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9044/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698623875538,
            "cdate": 1698623875538,
            "tmdate": 1700670606034,
            "mdate": 1700670606034,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Kn7afTScaJ",
                "forum": "MZs2dgOudB",
                "replyto": "KJTSPW7sVd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer EFev"
                    },
                    "comment": {
                        "value": "Thank you for your comments. Please see the common response above, in addition to discussion here.\n\n\n> The technique novelty is too limited. The introduced algrithm is very simple based on normal distribution. So, the overal paper looks more like a technique report or a survey.\n\n\nWe agree that the proposed method is very simple, but we believe that algorithmic simplicity is not a limitation but rather a strength. As we have demonstrated throughout many experiments, our simple algorithm outperforms much more complicated existing active learning methods. \n\nMore importantly, we would like to emphasize that our work is not merely an application of an existing method to a new task. The introduction of the GMM method stems from an observation that has not been considered in previous active learning research. As illustrated in Figure 2, the GMM method consistently matches or outperforms existing low-budget active learning methods in the very low budget regime where meta-learning is situated.\nMoreover, in the context of meta-learning, providing effective \u201creference points\u201d is crucial. We propose the GMM method as it is well-suited for this purpose by ensuring that the context set remains proximate to the target set, even in worst-case scenarios.\n\nWe have further listed contributions of our paper in the second response of the common response above. Here, we summarize our contributions as follows, \n\n1. We provide a general framework for active meta-learning in meta-test time and identify a major challenge in the traditional setup for meta-learning in classification in Section 2.\n2. We propose a simple active learning method tailored for meta-learning with an observation that is not considered in the previous works, along with theoretical motivation in Section 3.\n3. We demonstrate the effectiveness and robustness of our method on multiple datasets with various meta-learning algorithms for both classification and regression tasks in Section 4.\n\n \nWe sincerely hope the reviewer considers these contributions and re-evaluate our work. If the reviewer still has any remaining concerns or questions, we are eager to address them further.\n \n\n> If the algorithm is theoretically motivated, why is there no theories or lemmas in the mainbody?\n\nThe theoretical motivation for our algorithm is prominently presented in the main body of the paper, specifically in Section 3.3 through Proposition 1. The proofs for Proposition 1 are rigorously established by Lemma 1 and Lemma 2, both of which can be found in Appendix A.1. While we recognize the importance of detailed theoretical foundations, due to space constraints, we had to place Lemma 1 and 2 in the appendix."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700471123722,
                "cdate": 1700471123722,
                "tmdate": 1700471123722,
                "mdate": 1700471123722,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3DwhZAe3Nm",
                "forum": "MZs2dgOudB",
                "replyto": "KJTSPW7sVd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Post-Rebuttal Comment"
                    },
                    "comment": {
                        "value": "We value your insightful feedback. After reviewing the post-rebuttal comment, we remain uncertain about the basis for the 'reject' rating.\n\nAs highlighted in our common response and individual response to the reviewer, we explained that simplicity is a strength, not a weakness. However, if the reviewer still looks at it differently, we are open to further discussion.\n\nAdditionally, we've included a theoretic motivation in Proposition 1, supported by a clear proof and additional insights in Appendix A.1. If the reviewer seeks more theoretical analysis, we kindly ask for specific aspect our work may lack in this regard.\n\nWe kindly request a reconsideration of the overall rating. If the suggestion to move related work to the appendix is the remaining concern, we believe a 'reject' may be too severe. Your re-evaluation would be greatly appreciated."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700688330069,
                "cdate": 1700688330069,
                "tmdate": 1700688330069,
                "mdate": 1700688330069,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "fIw5UTyZPV",
            "forum": "MZs2dgOudB",
            "replyto": "MZs2dgOudB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9044/Reviewer_PTqo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9044/Reviewer_PTqo"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the effectiveness of active learning in the meta-learning setting.  The authors first discuss the different ways active-learning can be applied to meta-learning including actively selecting data to label at training and test time as well as actively selecting tasks to train on.  Experiments with using active learning to select labeled data at meta-training time showed no benefit over uniform sampling so the authors focus on active labeling at meta-test time.  Here, they\npropose a simple Gausian Mixture Model to identify highest-density points to label.  Experiments show GMM to outperform other labeling approaches at meta-test time on multiple computer vision meta-learning benchmarks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Active learning at meta-test time is a novel problem to study; prior work I am aware of have primarily focused on active learning during meta-training phase.\n- Experimental results for GMM for active-learning at test time are quite strong compared to other approaches.\n- Good coverage of meta-learning approaches including metric (ProtoNet), optimization (MAML), and model (Baseline++) type approaches.\n- The paper is clear and easy to understand."
                },
                "weaknesses": {
                    "value": "- Missing reference to [Al-Shedivant et al. 2021](https://arxiv.org/pdf/2102.00127.pdf).  This paper studies active learning for meta-learning at training time and proposes a hybrid informative and diverse clustering labeling approach using k-means++.  I encourage the authors to include this active learning approach as an additional baseline in their experiments.\n- Limited technical novelty since theory and approach are straightforward.  However, I am not placing too much weight on this since experimental results are strong.\n- The paper can benefit from a discussion of practical implications of being able to be more label-efficient at meta-test time grounded in a real-world example.\n- Theoretical justification is very basic and presumed to hold in meta-learning case with ad-hoc justification."
                },
                "questions": {
                    "value": "- For Tables 1, 2, 3, how many runs are used to compute error bars?\n- Is there a hypothesis for why GMM helps at test time but not at meta-train time?  This is an important discrepancy that is worth understanding deeper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9044/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698817702026,
            "cdate": 1698817702026,
            "tmdate": 1699637138738,
            "mdate": 1699637138738,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ElHP5p6nbU",
                "forum": "MZs2dgOudB",
                "replyto": "fIw5UTyZPV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer PTqo (1/2)"
                    },
                    "comment": {
                        "value": "Thank you for your comments. Please see the common response above, in addition to discussion here.\n\n\n> Missing reference to Al-Shedivant et al. 2021. [\u2026] I encourage the authors to include this active learning approach as an additional baseline in their experiments.\n\nThanks for alerting us to this paper. Although they indeed focus on active learning in meta-training time, it is quite related to our work. We compared experimentally to their approach (along with other hybrid methods); results are discussed in the common response, but in short we substantially outperform their approach and other hybrid methods, probably because uncertainty methods perform so poorly in this very-low-budget regime.\n\nMost uncertainty measures should be high near decision boundaries and/or outlier points; this is undesirable for low-budget settings, since they are hard to generalize from in \u201cinitial\u201d stages of learning. Methods like our GMM-based proposal ensure that the context set points are \u201cnear\u201d most of the target set, helping in the early phases of learning which are all that meta-learning considers. Hybrid methods considering both uncertainty and diversity are likely to help in middle-budget regimes, but not in extremely-low budget settings like meta-learning. We\u2019ve added discussion of this point to Appendix L of the revised paper. \n\nNote that for this experiment, we applied their method only in meta-test time, for fair comparison to other approaches. Applying this category of approach in meta-training, including theirs as well as ours, requires a substantial computational overhead, since we must run clustering for each task considered in meta-training; we saw in Appendix J that doing so does not seem helpful in general.\n\nWe provide further analysis on Al-Shedivat et al. in the reviewer\u2019s last question. \n  \n\n> Limited technical novelty since theory and approach are straightforward. However, I am not placing too much weight on this since experimental results are strong.\n\nWe appreciate the reviewer for valuing our strong experimental results. We agree that our proposed method is simple and straightforward, however, we want to emphasize that simple methods are not a limitation but rather a strength. Many existing active learning approaches, despite their improvement, require tuning several hyperparameters and complicated implementation details. For instance, as we discussed in Appendix F, the recent low-budget active learning technique ProbCover is highly sensitive to its difficult-to-tune radius value. On the other hand, GMM is extremely straightforward and easy to apply, with high-quality implementations widely available.\n\nWe would like to also emphasize that despite its simplicity and strength, GMMs have not been broadly used in the active learning community of late (including outside the very-low-budget regime): many papers use $k$-means variants, but our experiments show that GMMs often outperform $k$-means in these settings (please refer to the response to the fourth question of Reviewer r9Lv for details). Separately from the choice of clustering method, it also seems that most work \u201cdefaults\u201d to hybrid methods (as did e.g. Al-Shedivat et al.) without further considering the tradeoffs. We believe that hybrid methods are indeed likely the best choice in medium- or high-budget settings, but as we demonstrate here, in the very-low-budget setting it seems that very simple selection criteria substantially beat other approaches. We believe these observations can bring new insights to the active learning community.\n\n\n> The paper can benefit from a discussion of practical implications of being able to be more label-efficient at meta-test time grounded in a real-world example.\n\nThis is indeed a very good presentation suggestion. There are several natural examples where label efficiency at meta-test time is of paramount important, such as:\n\n- Few-shot learning for medical imaging: when a meta-learner is deployed for new imaging instruments or modalities, such as switching between differently-configured CT scanners or from CT scans to ultrasound images, the resulting images can change dramatically. These changes in features are hard to predict, and because reliable annotations of medical images are extremely expensive, the meta-learner should adapt to the new modality very quickly. By strategically choosing context samples in the new modality, the meta-learner can adapt with only a few samples, and effectively utilize new types of medical imaging data.\n- Industrial automation: consider a factory which frequently switches between manufacturing different types of goods. A quality control system should learn to adapt to the new setting without extensive human labeling for what to look for.\n\nWe will add one of these examples throughout the main body, so that readers can better understand implications of the setting and our method."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700470945985,
                "cdate": 1700470945985,
                "tmdate": 1700470945985,
                "mdate": 1700470945985,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XGpU02ixIU",
                "forum": "MZs2dgOudB",
                "replyto": "fIw5UTyZPV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer PTqo (2/2)"
                    },
                    "comment": {
                        "value": "> Theoretical justification is very basic and presumed to hold in meta-learning case with ad-hoc justification.\n\nIt is true that our theorem is of limited scope. We believe it is useful as an illustrative example for \u201cwhy\u201d the method can be a good idea, rather than presuming that the exact mechanism elucidated in the theorem applies for practical meta-learning regimes: indeed, Figure 5 shows a simple setting where the theorem fails. (Almost no theorems in machine learning theory precisely apply to practical deep learning settings.) We do believe, however, that the reasoning described in Proposition 1/Figure 4 and in the discussion around Figure 5 provide good motivation for the method.\n\n\n\n> For Tables 1, 2, 3, how many runs are used to compute error bars?\n\nAs specified in the last sentence of the second paragraph of Section 4.1, we evaluated a single meta-learned algorithm on 600 meta-test tasks, and reported $95%$ confidence intervals across those tasks. This follows the widely-used convention in the meta-learning literature, including MAML, ANIL, SimpleShot, and more.\n\n\n\n> Is there a hypothesis for why GMM helps at test time but not at meta-train time? This is an important discrepancy that is worth understanding deeper.\n\nWe do agree that a deeper understanding of this problem is important. We have a hypothesis as to why this might be the case.\n\nThe GMM-based method provides context sets which give better-performing predictors. Doing this at meta-training time, however, makes a given task easier. With optimal context set selection, even mediocre features might yield a good meta-learned model on that task; the problem becomes \u201ctoo easy,\u201d and the meta-learned features will not give such clear classifications on harder problems. With worse selection of context sets, however, the meta-learner must learn better features, such that even mediocre labelings still achieve reasonable task performance.\n\nWe conjecture the improvement of Al-Shedivat et al. in meta-training time might be partially explained by this hypothesis. Recall that Al-Shedivat et al. create clusters of unlabeled samples using k-means++, then select the points from each cluster with the highest entropy. As discussed previously, this will tend to select points near cluster boundaries; the meta-learner should then find features that separate clusters very well, so that these points remain informative enough for the final classifier. \n\nOne might be curious about the combination of Al-Shedivat et al. and our GMM method, since their method is for meta-training time and ours is for meta-test time. We thus trained a ProtoNet on MiniImageNet using Al-Shedivat et al., denoted as [1], rather than the Random selection as in the experiments in the paper. We then employed Random, [1], and GMM methods at meta-testing time.\nAs shown in the table below, models meta-trained with [1] perform somewhat better with [1]-based meta-testing than random meta-testing. When the model is meta-trained with random selection, the two meta-testing methods are about the same. For both meta-training methods, however, meta-testing with the GMM method substantially outperforms the other two approaches.\n\nUsually ProtoNet is trained for 5,000 iterations; these results use only 1,000 or 2,000 iterations, since meta-training with [1] requires substantial computational overhead (mainly, running k-means++ for every task considered during training).\n\n\n| Train $\\rightarrow$ Test | [1] $\\rightarrow$ Random | [1] $\\rightarrow$ [1]    | [1] $\\rightarrow$ GMM    | Random $\\rightarrow$ Random | Random $\\rightarrow$ [1]  | Random $\\rightarrow$ GMM |\n| ------------ | ------------ | ------------ | ------------ | --------------- | ------------- | ------------ |\n| 1000 iter    | 33.40 $\\pm$ 0.22 | 34.76 $\\pm$ 0.24 | 40.65 $\\pm$ 0.28 | 34.94 $\\pm$ 0.24   | 33.64 $\\pm$ 0.25 | 38.94 $\\pm$ 0.26 |\n| 2000 iter    | 36.17 $\\pm$ 0.25 | 36.87 $\\pm$ 0.25 | 40.76 $\\pm$ 0.28 | 35.43 $\\pm$ 0.26   | 36.30 $\\pm$ 0.2)  | 42.49 $\\pm$ 0.28 |\n\n**Table. MiniImageNet using ProtoNet trained with [1] or Random selection**\n\n\n[1] M. Al-Shedivat, L. Li, E. Xing and A. Talwalkar, \u201cOn data efficiency of meta-learning\u201d,  AISTATS 2021."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700471005047,
                "cdate": 1700471005047,
                "tmdate": 1700521501189,
                "mdate": 1700521501189,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0ycmNUos5d",
                "forum": "MZs2dgOudB",
                "replyto": "fIw5UTyZPV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A Reminder to Reviewer PTqo"
                    },
                    "comment": {
                        "value": "Dear Reviewer PTqo,\n\nWe kindly remind Reviewer PTqo that the discussion period will end in approximately 12 hours. We highly appreciate the reviewer for valuing our work and providing constructive feedback. \n\nIn response to  the reviewer\u2019s valuable comments, both in the common response and directly to the reviewer, we have clarified questions, provided real world examples as suggested, and conducted more experiments, specifically on both hybrid active learning methods and the suggested AL-Shedivat et al. \n\nYour feedback on our rebuttal and revised paper would be greatly appreciated. We are willing to address any remaining doubts or questions. Thank you for your time and consideration."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700688994383,
                "cdate": 1700688994383,
                "tmdate": 1700688994383,
                "mdate": 1700688994383,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Qz3YjpazX4",
                "forum": "MZs2dgOudB",
                "replyto": "0ycmNUos5d",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9044/Reviewer_PTqo"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9044/Reviewer_PTqo"
                ],
                "content": {
                    "title": {
                        "value": "Post author response"
                    },
                    "comment": {
                        "value": "Thank you for responding to my questions and the weaknesses I raised. I will maintain my score of 6 since I believe my assessment when writing the review still holds; namely this is a strong empirical paper with limited technical novelty."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700720330124,
                "cdate": 1700720330124,
                "tmdate": 1700720330124,
                "mdate": 1700720330124,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "xRzp3Ldba2",
            "forum": "MZs2dgOudB",
            "replyto": "MZs2dgOudB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9044/Reviewer_xa6o"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9044/Reviewer_xa6o"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces an approach that integrates active learning into meta-learning with the goal of enhancing data efficiency when selecting context points during the meta-testing phase. The paper starts with an analysis of where in the meta-learning process active learning can be applied, along with a concise review of meta-learning and active learning methods. Empirical evidence is presented to demonstrate that actively selecting context points during meta-training does not significantly impact meta-learning but does prove beneficial during meta-testing. In this context, the authors propose a Gaussian Mixture Model-based acquisition function, which stands as the primary technical contribution of this paper. In essence, this method employs meta-trained features to model a mixture of k Gaussian distributions, with k equating to the label budget, often referred to as batch size in active learning. The empirical results, based on experiments conducted across four few-shot image datasets, indicate that the proposed GMM-based acquisition strategy outperforms other acquisition strategies when integrated into meta-testing."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Originality: While the concept of integrating active learning into meta-learning is interesting, it's worth noting that this idea, at a high level, has been explored before. However, the authors' empirical findings regarding the placement of active learning align with existing research, indicating that actively selecting context points during meta-training does not significantly improve few-shot performance. The use of an acquisition function based on a mixture of Gaussians has demonstrated effective performance across various few-shot classification tasks.\n\nClarity: The paper effectively communicates its main ideas. The explanation of how active learning can be incorporated into meta-learning is well-presented and offers valuable guidance for practical applications.\n\nSignificance: The proposed method, utilizing a GMM-based acquisition strategy, has exhibited promising results when compared to several acquisition strategies employed in active learning. This achievement is particularly noteworthy across multiple few-shot image classification and vision regression datasets."
                },
                "weaknesses": {
                    "value": "The primary technical contribution of this paper lies in the GMM-based acquisition function, which is suggested to outperform other acquisition functions in scenarios with extremely limited annotation budgets, as required by meta-learning. However, the results presented in Figure 2 do not convincingly demonstrate a substantial performance improvement of the proposed GMM-Based method over Typiclust.\n\nFurthermore, selecting the samples close to the cluster centre can better capture the diversity. However, it's important to note that several hybrid active learning approaches already consider both uncertainty and diversity. For example, BEMPS [1] integrates these aspects. To better highlight the advantages of the proposed methods, a more comprehensive examination within the context of active learning is advisable.\n\nReferences\n*  W.Tan, L.Du, and W.Buntine, \u201cDiversity enhanced active learning with strictly proper scoring rules,\u201d in Advances in Neural Information Processing Systems, 2021,pp.10906\u2013 10918."
                },
                "questions": {
                    "value": "The reviewer has a question about the setup of active learning in meta-testing. \nWas the acquisition just run to acquire N*K samples?  Or was the acquisition run multiple times until the total annotation budget N*K was exhausted? If the later case, was the meta-trained model retrained after each acquisition iteration? And what was the batch size (No. Samples acquired) used in each iteration?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9044/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699232934677,
            "cdate": 1699232934677,
            "tmdate": 1699637138601,
            "mdate": 1699637138601,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dY8riWBHJ7",
                "forum": "MZs2dgOudB",
                "replyto": "xRzp3Ldba2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer xa6o (1/2)"
                    },
                    "comment": {
                        "value": "Thank you for your comments. Please see the common response above, in addition to discussion here.\n\n\n> The primary technical contribution of this paper lies in the GMM-based acquisition function, which is suggested to outperform other acquisition functions in scenarios with extremely limited annotation budgets, as required by meta-learning. However, the results presented in Figure 2 do not convincingly demonstrate a substantial performance improvement of the proposed GMM-Based method over Typiclust.\n\nWe would like to emphasize that our goal in Figure 2 was not to claim that the GMM-based method significantly outperforms other methods such as Typiclust; indeed, we described the results as saying that it \u201cmatches or outperforms other low-budget methods.\u201d Figure 2 is a motivational experiment for active meta-learning, justifying that the GMM method is a reasonable active learning scheme in the very-low-budget but non-meta setting. In our main experiments for active meta-learning, in Section 4, we believe we do convincingly demonstrate a substantial performance improvement over Typiclust: for instance, the first results in Tables 1 and 2 show improvements over Typiclust varying between two and eight percentage points of accuracy.\n\n\n\n> Furthermore, selecting the samples close to the cluster centre can better capture the diversity. However, it's important to note that several hybrid active learning approaches already consider both uncertainty and diversity. For example, BEMPS [1] integrates these aspects. To better highlight the advantages of the proposed methods, a more comprehensive examination within the context of active learning is advisable.\n\nThank you for this important suggestion. We added an experiment comparing our approach with hybrid active learning methods, with results listed in the common response. These results show that the proposed GMM-based method significantly outperforms hybrid methods, which we think was somewhat expected since uncertainty-based methods perform so poorly (often much worse than random selection) in these settings.\n\nMost uncertainty measures should be high near decision boundaries and/or outlier points; this is undesirable for low-budget settings, since they are hard to generalize from in \u201cinitial\u201d stages of learning. Methods like our GMM-based proposal ensure that the context set points are \u201cnear\u201d most of the target set, helping in the early phases of learning which are all that meta-learning considers. Hybrid methods considering both uncertainty and diversity are likely to help in middle-budget regimes, but not in extremely-low budget settings like meta-learning. We\u2019ve added discussion of this point to Appendix L of the revised paper. \n\nFor BEMPS in particular, as we mentioned in the common response, it is hard to apply to typical meta-learning settings, since it requires a posterior over models. Bayesian active learning papers mostly compare only to other Bayesian active learning methods. We have added a citation to Section 3.1, however."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700470547390,
                "cdate": 1700470547390,
                "tmdate": 1700470547390,
                "mdate": 1700470547390,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BAx2jC2crM",
                "forum": "MZs2dgOudB",
                "replyto": "xRzp3Ldba2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer xa6o (2/2)"
                    },
                    "comment": {
                        "value": "> Was the acquisition just run to acquire NK samples? Or was the acquisition run multiple times until the total annotation budget NK was exhausted? If the later case, was the meta-trained model retrained after each acquisition iteration? And what was the batch size (No. Samples acquired) used in each iteration?\n\nThanks for raising the question. As briefly mentioned in Section 3.1, we mostly considered the former scenario where we sample $N\\times K$ samples at once. Although iterative sampling is more common in active learning, we focused on this scenario for the following two reasons:\n\n\n1. Even when we iteratively label additional samples, for most meta-learning algorithms (other than MAML), this does not change the features we will use for our meta-learning methods. Even for other optimization-based methods such as ANIL, since the feature extractor is not updated during adaptation on a context set, the features stay the same for iterative process of active learning. As we demonstrated with ProtoNet in Figure 9 (c)-(d) in Appendix K (details about experiments in [1] below), when we iteratively add more labeled samples, the performance does not change much as the features do not change. In this case, selecting $N \\times K$ samples at once is not very different from the iterative process, but it is computationally cheaper.\n2. If we iteratively add labeled samples, we will quickly move beyond the few-shot regime of meta-learning, which is often not very practical in real world settings. Suppose we have a meta learner trained in $5$-way $1$-Shot. It is reasonable to add $5$ samples per iteration, since that is the minimum number to cover all the classes. But only after $5$ iterations, it will reach few-shot regime where we typically have $25$ labeled context samples. This is even less practical for $5$-Shot case.\n\nWe added the above explanation and experiments in Appendix K. If this is still not clear, we are eager to elaborate it further.\n\n[1] We used MAML and ProtoNet trained on MiniImageNet in $5$-way $1$-Shot with randomly sampled context and target data. In meta-test time, we label $K$ (the number of shots) samples using various active learning methods at each iteration until the total number of context samples reaches $50$. Again, for each iteration, we evaluated on $600$ test tasks."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700470618389,
                "cdate": 1700470618389,
                "tmdate": 1700470618389,
                "mdate": 1700470618389,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3A5Kc0zX2w",
                "forum": "MZs2dgOudB",
                "replyto": "xRzp3Ldba2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A Reminder to Reviewer xa6o"
                    },
                    "comment": {
                        "value": "Dear Reviewer xa6o,\n\nWe kindly remind Reviewer xa6o that the discussion period will end in approximately 12 hours. In response to your valuable feedback, we have addressed two points of misunderstanding and incorporated additional experiments, particularly in comparison to hybrid active learning methods as the reviewer suggested (see the common response above). We would greatly appreciate your feedback on any remaining unclear points in our responses and revisions. We are willing to address any doubts or questions until the last minutes. Thank you for your time and consideration."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687843300,
                "cdate": 1700687843300,
                "tmdate": 1700687843300,
                "mdate": 1700687843300,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yWLeiOgfeN",
                "forum": "MZs2dgOudB",
                "replyto": "3A5Kc0zX2w",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9044/Reviewer_xa6o"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9044/Reviewer_xa6o"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate that the authors took to respond to my questions and concerns.\n\nIn regard to GMM, if its performance is only comparable with those competitors considered in Figure 2, the contribution of the proposed GMM to low-budget active learning is questionable."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700729072331,
                "cdate": 1700729072331,
                "tmdate": 1700729072331,
                "mdate": 1700729072331,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3qM462iR1J",
                "forum": "MZs2dgOudB",
                "replyto": "xRzp3Ldba2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9044/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Reviewer xa6o"
                    },
                    "comment": {
                        "value": "Thank you for your feedback. However, we want to **re-emphasize** that we do not claim that our contribution is for improving low-budget active learning as we have already addressed in the rebuttal.\n\nThe setting for Figure 2 is \"regular\" supervised image classification tasks for low budget whereas our target task is meta-learning (either classification or regression). **We want to emphasize that they are two very different tasks.** As we have answered in the response, we provided Figure 2 as a motivational experiment for active meta-learning, justifying that the GMM method is a reasonable active learning scheme in the very-low-budget but non-meta-learning setting.\n\nAs the reviewer stated the performance of GMM is comparable (sometimes better) with other competitors for image classification, thus there is no our contribution. On the other hand, for meta-learning, as our extensive experiments show, the proposed GMM significantly outperforms other active learning methods.\n\n**Once again, we earnestly request the reviewer's understanding of the distinctions between them.**\n\nIf this was the only remaining concern, we would greatly appreciate the reviewer's re-evaluation of our work based on clarification.\nThank you for your time and consideration."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9044/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700731370756,
                "cdate": 1700731370756,
                "tmdate": 1700732258220,
                "mdate": 1700732258220,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]