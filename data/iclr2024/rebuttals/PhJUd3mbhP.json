[
    {
        "title": "AutoAgents: A Framework for Automatic Agent Generation"
    },
    {
        "review": {
            "id": "XUrmOMqHzo",
            "forum": "PhJUd3mbhP",
            "replyto": "PhJUd3mbhP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission93/Reviewer_ypGp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission93/Reviewer_ypGp"
            ],
            "content": {
                "summary": {
                    "value": "AutoAgents is a framework for orchestrating multiple specialized\nagents dynamically to form AI teams tailored to different tasks. It\ndivides the process into a Drafting Stage and an Execution Stage,\nallowing agents to collaborate effectively."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This study provides a valuable clarification of its position,\nespecially in the context of LLM-based Agent frameworks. In comparison\nto AgentVerse and SSP, this research stands out by highlighting the\nsignificance of Self-Refinement agents and Collaborative Refinement\nAction as key differentiators."
                },
                "weaknesses": {
                    "value": "The paper is perceived as having low readability and insufficient\nreproducibility. The reviewer kindly requests a more granular\ndescription of the methodology that enables readers to implement the\nprocedures step by step. For instance, while Table 1 is highly\nbeneficial for positioning this research within the LLM-based Agent\nframework, in comparison to AgentVerse and SSP, it distinctly\nhighlights the significance of Self-Refinement agents and\nCollaborative Refinement Action. Nevertheless, the two points\nmentioned above are not clearly articulated in Section 3.2, \"EXECUTION\nSTAGE.\" They are mentioned in the text and Figure 2, but their\npresentation as steps is absent, making it challenging for readers to\ncomprehend and evaluate reproducibility.\n\nThe evaluation in the experiments lacks qualitative insights. In the\nexperiments, it remains unclear how the introduction of\nSelf-Refinement agents and Collaborative Refinement Action has led to\ndifferential outcomes compared to SSP, and what specific effects these\ntwo points have had. While accuracy has undeniably improved, it is\nessential to qualitatively demonstrate how these two aspects have\ncontributed to the observed results.\n\nThere are concerns regarding the reproducibility of the\nexperiments. It is unclear whether the CASE STUDY has been practically\nrealized or if it serves as an imagined example for\napplication.\n\n\nThe paper lacks an ablation study to assess the impact of modifying or\nomitting certain components within the system, particularly in the\nDraft and Execution phases where multiple agents are involved, such as\nAgent Observer, Plan Observer, Researcher, Planner, Writer, Character\nDeveloper, and others. This study could help elucidate the\nsignificance of each component and its contribution to the overall\nsystem.  Furthermore, the absence of an ablation study regarding\nShort-term memory, Long-term memory, and Dynamic memory raises\nconcerns. Investigating the effects of altering or removing these\nmemory components could provide valuable insights into their\nrespective roles and importance within the framework.  Overall,\nconducting such ablation studies would enhance the paper's depth and\nprovide a more comprehensive understanding of the system's inner\nworkings and the role of its individual components."
                },
                "questions": {
                    "value": "Could you provide a more detailed, step-by-step description of the\nSelf-Refinement agents and Collaborative Refinement Action in Section\n3.2, \"EXECUTION STAGE,\" to enhance readability and reproducibility?\n\nCan you offer qualitative insights to elucidate how the introduction\nof Self-Refinement agents and Collaborative Refinement Action has\ninfluenced the experiment results, particularly in comparison to SSP,\nto help readers better understand the effects of these elements?\n\nPlease note that further clarification on the practical realization of\nthe CASE STUDY would be valuable to address concerns about\nreproducibility.\n\nIs there an opportunity for conducting ablation studies to investigate\nthe importance of individual components in both the Draft and\nExecution phases, as well as the Short-term memory, Long-term memory,\nand Dynamic memory components in Knowledge Sharing Mechanism? Such\nstudies could help clarify the significance and roles of these\ncomponents in the framework.\n\nThese three elements - the number of agents, self-refinement, and\nCollaborative Refinement Action - are key characteristics of this\nstudy from Table 1. Can you please explain why the OPEN-ENDED QUESTION\nANSWER and The Trivia Creative Writing tasks are well-suited for\nassessing the impact of these factors?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission93/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission93/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission93/Reviewer_ypGp"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission93/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698542926792,
            "cdate": 1698542926792,
            "tmdate": 1699635934330,
            "mdate": 1699635934330,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "66jjjJmk1R",
                "forum": "PhJUd3mbhP",
                "replyto": "XUrmOMqHzo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors"
                    },
                    "comment": {
                        "value": "Thank you for your motivating review and concrete suggestions. Detailed responses to your questions are listed as follows.\n\n> 1. The paper is perceived as having low readability and insufficient reproducibility. The reviewer kindly requests a more granular description of the methodology that enables readers to implement the procedures step by step. For instance, while Table 1 is highly beneficial for positioning this research within the LLM-based Agent framework, in comparison to AgentVerse and SSP, it distinctly highlights the significance of Self-Refinement agents and Collaborative Refinement Action. Nevertheless, the two points mentioned above are not clearly articulated in Section 3.2, \"EXECUTION STAGE.\" They are mentioned in the text and Figure 2, but their presentation as steps is absent, making it challenging for readers to comprehend and evaluate reproducibility.\n> 2. Could you provide a more detailed, step-by-step description of the Self-Refinement agents and Collaborative Refinement Action in Section 3.2, \"EXECUTION STAGE,\" to enhance readability and reproducibility?\n\nIn order to streamline the implementation process of self-refinement and collaborative refinement, we have introduced the concept of a 'custom agent'. The intricate design of its prompt has been meticulously detailed in Appendix D.5. For enhanced clarity and understanding, we have itemized the core design principles of this custom agent below:\n\n1. Understanding Previous Results: Begin by analyzing the results of previous agents to grasp the context and progress of the task.\n\n2. Task Analysis and Breakdown: Understand, analyze, and deconstruct the given task. Use available tools to assist in task completion.\n\n3. Current Step Identification and Execution:\n- 3.1 Examine completed steps and their outcomes to identify the current step that needs to be completed.\n- 3.2 In the absence of completed steps, analyze the task, design a plan for the necessary steps, and accomplish the first one.\n- 3.3 If steps have been completed, understand them to determine the next step to be completed.\n\n4. Tool Selection and Action Execution:\n- 4.1 Choose the appropriate tool from the given list ({tool}) to complete the current step.\n- 4.2 Follow specific format guidelines when using tools like 'Write File'.\n- 4.3 Once all steps are completed, use the 'Final Output' action to summarize each step's outputs, ensuring the final output is detailed, comprehensive, and solves the task.\n\n5. Maintaining Format Consistency: Ensure that the final output adheres to the given format example, prioritizing helpfulness, relevance, accuracy, and detail.\n\nBuilding upon the custom agent's framework, a critical aspect of the refinement process is the configuration of 'completed steps' in step 3.1. The specific procedural steps for self-refinement and collaborative refinement are outlined as follows:\n\n__Self-refinement Action__: During its first execution, each custom agent omits the outlined step 3.1 and proceeds to complete the remaining steps. If the task's criteria are not met or the step limit has not been reached, the outcomes from this execution are incorporated as 'completed steps' in the prompt for the next iteration of the task. In subsequent executions, the custom agent will execute all steps, continuing this process until the task is deemed successfully completed.\n\n__Collaborative Refinement Action__: This mirrors the self-refinement action, yet involves active collaboration between multiple agents. For instance, when agents A and B collaborate on a task, A initially bypasses step 3.1 in its first execution. Upon completion, B incorporates A's results as 'completed steps' and then executes all steps. In later cycles, A and B alternate their roles in the task, perpetuating this collaborative cycle until a joint conclusion is reached.\n\n-----"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission93/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700366857676,
                "cdate": 1700366857676,
                "tmdate": 1700366857676,
                "mdate": 1700366857676,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8h2gD89MnA",
                "forum": "PhJUd3mbhP",
                "replyto": "XUrmOMqHzo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors"
                    },
                    "comment": {
                        "value": "As the rebuttal phase draws to a close, we want to thank the reviewers for their valuable feedback. We believe we have successfully addressed your concerns in our responses and welcome any further questions you might have.\n\nGiven the improvements and clarifications made based on your feedback, we kindly ask the reviewers to reconsider their evaluations to account for these updates. We greatly appreciate your consideration."
                    }
                },
                "number": 27,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission93/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700620123177,
                "cdate": 1700620123177,
                "tmdate": 1700728396753,
                "mdate": 1700728396753,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KUTJW9Ftwy",
            "forum": "PhJUd3mbhP",
            "replyto": "PhJUd3mbhP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission93/Reviewer_Tafn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission93/Reviewer_Tafn"
            ],
            "content": {
                "summary": {
                    "value": "This paper propose AutoAgents, a framework to generate multiple agents and let them cooperate to solve different problems. The framework consists of the draft stage and the execution stage. The draft stage uses 3 predefined agents to cooperatively produce an agent list and an execution plan for a specific problem. The execution stage uses the proposed expert agents to execute the plan and solve the problem. Experiments on two benchmark show the effectiveness of the proposed framework."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Clear presentation of high-level idea: the overall framework and process is clearly presented through well-drawn figures like Fig. 1 and 2.\n- Strong reproducibility: the author provides source code and the temperature of LLM is set to 0, which makes it easy to reproduce the result in the paper."
                },
                "weaknesses": {
                    "value": "- Limited novelty: according to Table 1, the main difference between the proposed framework and other existing methods like Social Simulacra, Epidemic Modeling, SSP, and AgentVerse is that this work uses self-refinement and collaborative refinement. This difference is more of a prompting technique and has already been used in many existing works like [1, 2, 3]\n- Unclear presentation of detailed techniques: though the high-level idea is well-presented, the details of many technique are unclear. For example, how to determine when and which agents should engage in collaborative refinement? This is the main differnce from other methods but there is very little detailed description. More questions are in the Question part.\n- Insufficient evaluation: \n    1. Lack of baselines: Table 1 lists 12 existing frameworks, but none is used as baseline in task 1, and only 1 is used in task 2. Comparisons with existing methods are needed to show the effectiveness of the proposed methods.\n\n    2. Lack of ablation study: there is no quantitive ablations on different components of the framework like self-refinement, collaborative refinement, etc.\n\n    3. Unfair comparisons and potential problem in metric: in task 1, it is unfair to compare AutoAgents using GPT-4 with ChatGPT and Vicunna-13B. In task 2, the metric only considers the QA quality, how about the quality of the story around the given topic?\n\nReference:\n\n[1] Noah Shinn, Beck Labash, and Ashwin Gopinath. Reflexion: an autonomous agent with dynamic memory and self-reflection. arXiv preprint arXiv:2303.11366, 2023.\n\n[2] Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Nan Duan, and Weizhu Chen. Critic: Large language models can self-correct with tool-interactive critiquing, 2023.\n\n[3] Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, et al. Inner monologue: Embodied reasoning through planning with language models. arXiv preprint arXiv:2207.05608, 2022."
                },
                "questions": {
                    "value": "Detailed techniques:\n\n1. Section 3.1 Plan Generation: why plan genreation is parallel to agent generation? If the agent list has not been generated, how is it possible to \"entail a clear identification of agent\" for each step?\n\n2. Section 3.2 Action Observer: how does the Action Observer interact and communicate with other agents to act as the tasks manager and how is this process determined? When will the Action Observer adapt the execution plan.\n\n3. Section 3.2 Collaborative Refinement: how to determine when and which agents should engage in collaborative refinement?\n\n4. Section 3.2 Knowledge Sharing Mechanism: how to determine what knowledge is shared and who to share with?\n\nExperiments:\n\n5. Compare with more baselines in Table 1 for both task 1 and task 2, especially multi-agent frameworks like Social Simulacra, Epidemic Modeling, SSP, and AgentVerse.\n\n6. Unfair comparisons in Section 4.1: fair comparisons would be AutoAgents using ChatGPT v.s. ChatGPT and AutoAgents using Vicuna-13B v.s. Vicuna-13B.\n\n7. Metric problem in Section 4.2: the trivia creative writing task has two subtask: (a) craft a coherent story around a given topic (2) answer N questions. The current metric only evaluate the result of subtask (b), there need another metric for subtask (a).\n\n8. Ablation study: uantitive ablation results on different components of the framework. For example, remove self-refinement, collaborative refinement, different Observers, etc."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission93/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission93/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission93/Reviewer_Tafn"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission93/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698746150240,
            "cdate": 1698746150240,
            "tmdate": 1700577997012,
            "mdate": 1700577997012,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vHWsLtMxVZ",
                "forum": "PhJUd3mbhP",
                "replyto": "KUTJW9Ftwy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors"
                    },
                    "comment": {
                        "value": "Thank you for your comments and suggestions. We think there might be a misunderstanding of our contributions. We will clarify these concerns with detailed responses in the following.\n\n## Method\n> Limited novelty: according to Table 1, the main difference between the proposed framework and other existing methods like Social Simulacra, Epidemic Modeling, SSP, and AgentVerse is that this work uses self-refinement and collaborative refinement. This difference is more of a prompting technique and has already been used in many existing works like [1, 2, 3]\n\nHere, we further elucidate the main contributions of AutoAgents, a novel framework that addresses two salient issues: multi-agent generation and multi-agent cooperation. With respect to multi-agent generation, our method surpasses four existing methods in terms of the completeness and adaptability of agent creation, by employing Agent Generalization by Multi-Agent Discussion and Prompt Generalization. Regarding multi-agent cooperation, our framework exhibits the efficacy of Self-refinement Action and Cooperative Refinement Action. As illustrated in the table below, the distinctive features of AutoAgents encompass Agent Generalization by Multi-Agent Discussion, Prompt Generalization, Self-refinement Action, and Cooperative Refinement Action. AutoAgents is the first holistic framework that integrates multi-agent generation and collaboration. Detailed accounts of Agent Generalization by Multi-Agent Discussion and Prompt Generalization are given in below.\n\n| Method | Task | Agent Generalization by Multi-Agent Discussion | Prompt Generalization | Self-refinement Action | Collaborative Refinement Action |\n| --- | --- | --- | --- | --- | --- |\n| Social Simulacra | Social Simulation | &cross; | &cross; | &cross; | &cross; |\n| Epidemic Modeling | Social Simulation | &cross; | &cross; | &cross; | &cross; |\n| SSP | General Autonomous Agents | &cross; | &cross; | &cross; | &cross; |\n| AgentVerse | General Autonomous Agents | &cross; | &cross; | &cross; | &cross; |\n| AutoAgents | General Autonomous Agents | &check; | &check; | &check; | &check; |\n\n- __Agent Generalization by Multi-Agent Discussion__: Existing agent generation frameworks rely more on a single agent to generate the list of agents, but this often limits their adaptability to different tasks. For AutoAgents\uff0c the drafting stage is very important for the auto-generation of agents, as the list of agents to be generated is determined through cooperative discussions between the Planner agent and the two Observers. Additionally, in Appendix A, we further supplement with ablation experiments concerning the Agent Observer and Plan Observer, with the following table providing a detailed comparison. It is evident that in the absence of cooperative discussions among Observers, there is a significant decline in the overall performance of AutoAgents. This also validates the importance of generating reasonable agents for task adaptability.\n\n| Method | N (# triva questions) = 5|\n| --- | --- |\n| AutoAgents w/o observers | 87.0  |\n| AutoAgents | 90.0 |\n\n__Note__: Please refer to the Appendix A of the revision for the detailed setup of the experiment.\n\n- __Prompt Generalization__: The prompt employed by AutoAgents exhibits a more universal nature, signifying its capacity to acclimate to diverse tasks without necessitating bespoke customization. Both AgentVerse[1] and SSP[2] have implemented task-specific enhancements for varied task evaluations. In contrast, our methodology leverages a singular, unified prompt format to accommodate an array of tasks. The commendable efficacy in open-ended question answer and trivia creative writing tasks further corroborates the wide-ranging applicability and versatility of prompt design within the AutoAgents framework.\n\n__Note__: In the revision, we have improved Table 1 and provided additional comparisons in Appendix A.\n\n[1] https://github.com/OpenBMB/AgentVerse/tree/minecraft/agentverse/tasks\n\n[2] https://github.com/MikeWangWZHL/Solo-Performance-Prompting/tree/main/prompts\n\n-----"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission93/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700366534474,
                "cdate": 1700366534474,
                "tmdate": 1700367171248,
                "mdate": 1700367171248,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2JpzhnDhWz",
                "forum": "PhJUd3mbhP",
                "replyto": "BhGrIg42wW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission93/Reviewer_Tafn"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission93/Reviewer_Tafn"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for answering my questions. The response has helped me better evaluate the contribution of the work. I'll increase my score to 5, but I still have some reservations about the work.\n\n1. Unfair comparison. As said in my review, it is unfair to compare AutoAgents using GPT-4 with ChatGPT or Vicuna-13B. The performance improvement could come from the strong ability of GPT-4 instead of using AutoAgents. The fair comparison is AutoAgents using ChatGPT v.s. ChatGPT, and AutoAgents using Vicuna-13B v.s. Vicuna-13B. Moreover, since the human evaluators are asked to rate the score instead of comparing two outputs, I think it is better and more straightforward to report the average score instead of win rate.\n2. Unclear detailed techniques. Although the authors have provided further explanations and prompts, these descriptions are still abstract and hard for the readers to understand or reproduce the details in these techniques based on the manuscript. Concrete examples to show the process of collaborative refinement or the functionality of the action observer could also improve the clarity, but there is no such example."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission93/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700577971409,
                "cdate": 1700577971409,
                "tmdate": 1700577971409,
                "mdate": 1700577971409,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "afG9sd317u",
                "forum": "PhJUd3mbhP",
                "replyto": "KUTJW9Ftwy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors"
                    },
                    "comment": {
                        "value": "As the rebuttal phase draws to a close, we want to thank the reviewers for their valuable feedback. We believe we have successfully addressed your concerns in our responses and welcome any further questions you might have.\n\nGiven the improvements and clarifications made based on your feedback, we kindly ask the reviewers to reconsider their evaluations to account for these updates. We greatly appreciate your consideration."
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission93/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700620086670,
                "cdate": 1700620086670,
                "tmdate": 1700728386094,
                "mdate": 1700728386094,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "CZlayiAqtq",
            "forum": "PhJUd3mbhP",
            "replyto": "PhJUd3mbhP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission93/Reviewer_uXv7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission93/Reviewer_uXv7"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a framework for automatically synthesizing collaborative specialized agents. AutoAgents mimics the collaborative process of human teams by decomposing tasks into drafting and execution phases and delegating different subtasks to different agents. AutoAgents couples the relationship between tasks and roles by dynamically generating multiple required agents based on task content and planning solutions for the current task based on the generated expert agents. Finally, the experimental and empirical evaluation on various benchmarks validates the advantages of AutoAgents."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.\tThis paper presents a framework that adaptively generates and coordinates multiple specialized agents to build an AI team according to different tasks.\n2.\tThe paper is technically sound and the research question is clear. \n3.\tThe contribution of the paper is relevant for LLM-based multi-agent collaboration. The results of this paper is interesting and significant in automatic agent generation. The proposed AutoAgents framework generates more coherent and accurate solutions than the existing multi-agent methods."
                },
                "weaknesses": {
                    "value": "1.\tHow the proposed AutoAgents framework expands the scope of collaborative applications and reduces the consumption of resources should be elaborated. \n2.\tThe authors do not explain how to determine the number of agents in the section of the framework for automatic agent generation.\n3.\tThe section about automatic agent generation is too tedious to introduce too much related works\n4.\tIn addition to ChatGPT, Vicuna-13B and GPT4 in Table 2, it has not enough recent models to further show the superiority of the proposed framework-AutoAgents in open-ended question answer task in the experimental part.\n5.\tIn the experimental part, the performance on N=10 is better than N=5 in trivia creative writing task, but there is no explanations."
                },
                "questions": {
                    "value": "1.\tDuring the execution stage, why the authors adopt the vertical communication paradigm, which assigns different responsibilities to agents according to their roles. \n2.\tThe authors present results for the Open-ended Question Answer task and the Trivia Creative Writing task to evaluate the framework effectiveness. What if the Question Answer task is not open-ended? Does the proposed framework AutoAgents still work?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission93/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698822027003,
            "cdate": 1698822027003,
            "tmdate": 1699635934136,
            "mdate": 1699635934136,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CvWemlMKDI",
                "forum": "PhJUd3mbhP",
                "replyto": "CZlayiAqtq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors"
                    },
                    "comment": {
                        "value": "Thank you for your motivating review and concrete suggestions. Detailed responses to your questions are listed as follows.\n\n> __Q1:__ How the proposed AutoAgents framework expands the scope of collaborative applications and reduces the consumption of resources should be elaborated.\n\nExisting agent technologies are overly dependent on pre-defined prompts. This reliance poses a substantial user barrier and limits their practicality for broader applications. AutoAgents addresses this by automating the creation of new agent roles, which streamlines both the definition of roles and the execution of tasks, thereby enhancing the system's versatility.\n\nAutoAgents significantly extends its adaptability to diverse applications through the automatic generation of multiple intelligent agents, each tailored for specific tasks. This improvement in agent generation quality is achieved through the collaborative efforts of three predefined agents - the Planner, Agent Observer, and Plan Observer. These agents work together to discuss, refine, and finalize the list of agents and their corresponding execution plans. In Appendix A, we delve deeper into this aspect with ablation experiments focusing on the Agent Observer and Plan Observer. Our comparative analysis, as shown in the following table, reveals a marked decrease in AutoAgents' overall performance in the absence of cooperative dialogues among Observers. This outcome not only underscores the efficacy of collaborative refinement but also highlights the critical role of these discussions in enhancing task adaptability and resource optimization in the AutoAgents framework.\n\n| Method | N (# triva questions) = 5|\n| --- | --- |\n| AutoAgents w/o observers | 87.0  |\n| AutoAgents | 90.0 |\n\n__Note__: Please refer to the Appendix A of the revision for the detailed setup of the experiment.\n\n-----\n\n> __Q2:__ The authors do not explain how to determine the number of agents in the section of the framework for automatic agent generation.\n\nAutoAgents fundamentally predefines only a Planner and three types of Observers. Throughout the automatic agent generation phase, neither the number nor the types of agents to be generated are pre-specified. Instead, the decision regarding both the number and types of agents is dynamically and autonomously determined through collaborative discussions among the Planner, Agent Observer, and Plan Observer. This process ensures that the agents generated are optimally aligned with the specific requirements and nuances of each task.\n\n-----\n\n> __Q3:__ The section about automatic agent generation is too tedious to introduce too much related works\n\nIn Appendix A, we have included an expanded comparison of methodologies for agent generation. Traditional frameworks in agent generation typically hinge on the capability of a single agent to determine the list of agents. This approach, however, often results in limited adaptability across various tasks. In contrast, the AutoAgents framework places significant emphasis on the drafting stage for the auto-generation of agents. Here, the compilation of the agent list is a result of collaborative discussions between the Planner agent and the two Observers, enhancing adaptability and flexibility.\n\nMoreover, the prompts utilized in AutoAgents are designed with a universal approach, reflecting their ability to adapt to a wide range of tasks without the need for task-specific customization. While platforms like AgentVerse[1] and SSP[2] have opted for task-specific modifications, AutoAgents adopts a more holistic, unified prompt strategy. This uniform approach is adept at catering to diverse tasks, which is evident in our system's notable performance in open-ended question answering and trivia creative writing tasks. Such results highlight the extensive applicability and adaptability of our prompt design, making AutoAgents a versatile tool in the realm of agent-based systems.\n\n| Method | Task | Agent Generalization by Multi-Agent Discussion | Prompt Generalization |\n| --- | --- | --- | --- |\n| Social Simulacra | Social Simulation | &cross; | &cross; |\n| Epidemic Modeling | Social Simulation\t| &cross; | &cross; |\n| SSP | General Autonomous Agents | &cross; | &cross; |\n| AgentVerse | General Autonomous Agents | &cross; | &cross; |\n| AutoAgents | General Autonomous Agents | &check; | &check; |\n\n[1] https://github.com/OpenBMB/AgentVerse/tree/minecraft/agentverse/tasks\n\n[2] https://github.com/MikeWangWZHL/Solo-Performance-Prompting/tree/main/prompts\n\n-----"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission93/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700366415330,
                "cdate": 1700366415330,
                "tmdate": 1700366415330,
                "mdate": 1700366415330,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HennTk0Roz",
                "forum": "PhJUd3mbhP",
                "replyto": "CZlayiAqtq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your review!"
                    },
                    "comment": {
                        "value": "__We appreciate your time in reading our feedback and look forward to further discussion and your suggestions.__"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission93/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700531544413,
                "cdate": 1700531544413,
                "tmdate": 1700531592881,
                "mdate": 1700531592881,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "samZve15Cl",
                "forum": "PhJUd3mbhP",
                "replyto": "CZlayiAqtq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors"
                    },
                    "comment": {
                        "value": "As the rebuttal phase draws to a close, we want to thank the reviewers for their valuable feedback. We believe we have successfully addressed your concerns in our responses and welcome any further questions you might have.\n\nGiven the improvements and clarifications made based on your feedback, we kindly ask the reviewers to reconsider their evaluations to account for these updates. We greatly appreciate your consideration."
                    }
                },
                "number": 25,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission93/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700620050519,
                "cdate": 1700620050519,
                "tmdate": 1700728371804,
                "mdate": 1700728371804,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ob0b8RztbY",
                "forum": "PhJUd3mbhP",
                "replyto": "CvWemlMKDI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission93/Reviewer_uXv7"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission93/Reviewer_uXv7"
                ],
                "content": {
                    "comment": {
                        "value": "Thank the authors for their feedback. After reading other reviewers' comments and the authors' rebuttal, I decide to maintain the score as is."
                    }
                },
                "number": 29,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission93/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700732030115,
                "cdate": 1700732030115,
                "tmdate": 1700732030115,
                "mdate": 1700732030115,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "XZLGgAbXIr",
            "forum": "PhJUd3mbhP",
            "replyto": "PhJUd3mbhP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission93/Reviewer_paZk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission93/Reviewer_paZk"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes AutoAgents, a framework to generate and coordinate multiple specialised agents with distinct roles to construct an AI team to accomplish specialised tasks. The process comprises two stages: Drafting and Execution. The drafting stage involves Planner, Agent Observer, and Plan Observer agents discussing to generate the agent team and an execution plan, which is executed by the generated agents in the execution stage. The authors evaluated the performance of AutoAgents against a few existing solutions in the Open-ended Question-answering and Trivia Creative Writing task, and results show that AutoAgents performs better against the tested baselines. They performed a qualitative evaluation in a task requiring AutoAgents to generate the Tetris game."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The idea of dynamically generating agents who play different roles to solve team tasks is interesting and useful. I found the idea to be novel. It is easy for the reader to get a good overview of the idea of AutoAgents. However, there was a need to look at supplementary materials to understand aspects of what the different predefined roles were supposed to do. The visuals helped me understand the idea better. The background was sufficient, in my opinion, and well-written. This discussion and Table 1 made the contributions clear."
                },
                "weaknesses": {
                    "value": "Section 3:\nFor the agent generation, the motivation for the format of the Prompt P is unclear. Additionally, when we look at the supplementary material, the specific elements of the prompt are not explained -- are these taken from existing works?\n\nOthers:\nI also found details that needed to be included in a few other sections, such as the self-refinement process. Furthermore, I had questions about specific choices of parameters during the evaluations. I have included my questions in the next part to capture the specific places where I needed more information.\n\nMinor typos:\nPage 2: effectiveness of AutoAgents. [we] also conduct\nPage 7: at = lt \u222a pt \u222a ot, [where lt,] where lt denotes"
                },
                "questions": {
                    "value": "1) What motivated the design of the prompt elements for the predefined agents? Did you consider alternatives, or did existing works inspire these?\n2) How were the roles, skills, and actions decided for the specific tasks? Were they injected in the prompt, or did the Planner agent generate them?\n3) For the self-refinement process, what was the source of the thoughts, i.e., who decided what thoughts to include and why?\n4) Regarding knowledge sharing, did you experiment with each agent using different types, or were these predefined onset?\n5) How did you decide to use the number of discussions in the two stages to 3 and 5, respectively (page 7)?\n6) In multiple places, the agents' discussions may be stopped after some predefined threshold if the agents do not reach a consensus (e.g. during collaborative refinement, page 7). How often did this happen, and if the team did process, what is the quality of the outcome?\n7) In the Open-ended Q&A, the authors mention recruiting volunteers, but no more details are provided about how, whether ethics approval was sought, etc. Could the authors please provide more details on this."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Other reasons (please specify below)"
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "In the Open-ended Q&A, the authors mention recruiting volunteers, but no more details are provided about how, whether ethics approval was sought, etc."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission93/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission93/Reviewer_paZk",
                        "ICLR.cc/2024/Conference/Submission93/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission93/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698909690899,
            "cdate": 1698909690899,
            "tmdate": 1700736503888,
            "mdate": 1700736503888,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "QMQWixFNT1",
                "forum": "PhJUd3mbhP",
                "replyto": "XZLGgAbXIr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors"
                    },
                    "comment": {
                        "value": "We thank you for your constructive comments! We have fixed the grammatical errors in the revision. We also have addressed the other comments below and incorporated the feedback in the revision.\n\n-----\n\n> __Q1:__ What motivated the design of the prompt elements for the predefined agents? Did you consider alternatives, or did existing works inspire these?\n\n\nExisting agent technologies are overly dependent on pre-defined prompts, presenting a significant barrier to users and rendering them impractical for widespread use. By developing a system that automatically creates new agent roles, we can automate both the definition of roles and the execution of tasks, significantly increasing the technology's versatility. AutoAgents, potentially a pioneering framework, is distinctively geared towards generating universal prompts applicable to a wide range of agents. Our design not only ensures the accomplishment of each agent's predefined tasks but also, through careful consideration during the design phase, enhances the adaptability of these prompts to a variety of tasks, thus broadening their general applicability. In the updated appendix, we have incorporated a section at the outset of each prompt detailing the design principles and underlying logic.\n\n-----\n\n> __Q2:__ How were the roles, skills, and actions decided for the specific tasks? Were they injected in the prompt, or did the Planner agent generate them?\n\nThe Planner agent serves as the architect in our framework, initially crafting a comprehensive array of roles specifically designed for a variety of tasks. This includes not only the creation of prompts, descriptions, and toolsets for each role but also the formulation of an intricate execution plan. This plan distinctly specifies whether self-refinement or collaborative refinement actions are required. Following this initial phase, both the list of roles and the execution plan are subject to further refinement, achieved through collaborative dialogues with Observer agents. It is imperative to note that the choice of specific tools and techniques employed by each agent to navigate the steps in the execution plan is made independently by the agents themselves. A crucial aspect of our methodology is that we do not create unique prompts for each task. Rather, the primary prompts are methodically generated by the Planner agent, ensuring a consistent and streamlined approach across various tasks.\n\n-----\n\n> __Q3:__ For the self-refinement process, what was the source of the thoughts, i.e., who decided what thoughts to include and why?\n\nAs described in the appendix about the 'custom agent', each agent, upon receiving their assigned task, must first understand and analyze the task. They need to plan the steps required for future action and determine the immediate steps to be taken. The agent then outputs the results of completing the current step. In the next round of feedback, the history of executed steps and their outcomes (short-term memory) are fed back into the prompt under 'completed steps and responses'. This helps the agent to determine the steps needed in the future. The prompt's design rationale is additionally detailed in the appendix of the revision.\n\n-----"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission93/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700366278814,
                "cdate": 1700366278814,
                "tmdate": 1700366278814,
                "mdate": 1700366278814,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3ILQao7MHg",
                "forum": "PhJUd3mbhP",
                "replyto": "XZLGgAbXIr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors"
                    },
                    "comment": {
                        "value": "> __Q4:__ Regarding knowledge sharing, did you experiment with each agent using different types, or were these predefined onset?\n\nTo further elucidate, we delineate the specific agent types that are compatible with the three modes of knowledge sharing, as depicted in Figure 7 of the revision:\n\n- __Short-term Memory__: This is predominantly utilized by agents that emerge from self-refinement and collaborative-refinement processes. These agents leverage short-term memory to retain historical records throughout the refinement phase. Notably, every agent generated within our framework actively employs short-term memory.\n\n- __Long-term Memory__: This component archives the execution results of each agent, primarily chronicling the cumulative progress of the execution plan. Access to long-term memory is exclusive to a pre-designated Action Observer. The Action Observer utilizes this memory to evaluate whether additional execution steps are necessary or if there's a need to generate dynamic memory content.\n\n- __Dynamic Memory__: This memory type is essential for distilling and summarizing pivotal information from long-term memory for diverse agents. Generated by the Action Observer, dynamic memory serves to amalgamate critical aspects of the overall execution plan, thereby facilitating the agents responsible for implementing subsequent tasks. Consequently, the dynamic memory content available to each generated agent may differ, contingent upon their specific roles and tasks.\n\nDue to the fundamental nature of Short-term Memory and Long-term Memory as indispensable components within the system, our investigation was exclusively focused on understanding and analyzing the role of dynamic memory. In the Appendix A of the revision, we have included an ablation study of dynamic memory. The following table shows the results without the dynamic memory. It is observed that the performance of AutoAgents decreases by 1% without the summarization from dynamic memory, which also proves the importance of dynamic memory.\n\n| Method | N (# triva questions) = 5|\n| --- | --- |\n| AutoAgents w/o dynamic memory | 89.0  |\n| AutoAgents | 90.0 |\n\n__Note__: Please refer to the Appendix A of the revision for the detailed setup of the experiment.\n\n-----\n\n> __Q5:__ How did you decide to use the number of discussions in the two stages to 3 and 5, respectively (page 7)?\n\nOn one hand, it's been observed through experience that a detailed plan and a complete list of agents can generally be obtained after about three rounds of collaborative planning discussions. In cases where a single agent is operating, there's a high probability that the current task can be completed within five rounds. While a greater number of execution rounds typically leads to better outcomes, on the other hand, since we rely on GPT-4, more iterations mean increased costs. This setup is designed to manage and control the costs associated with task execution.\n\n-----\n\n> __Q6:__ In multiple places, the agents' discussions may be stopped after some predefined threshold if the agents do not reach a consensus (e.g. during collaborative refinement, page 7). How often did this happen, and if the team did process, what is the quality of the outcome?\n\nThe frequency of such occurrences is inherently tied to the complexity of the problem or task at hand. It is acknowledged that a premature termination of the refinement process could potentially compromise the quality of the final output. To address this, once the specified limit is reached, our system prompts with an instruction: 'You should synthesize the responses of previous steps and provide the final feedback.' This directive is designed to guide the agent towards concluding the refinement process, ensuring that a coherent and comprehensive outcome is still achieved despite the early halt in discussions.\n\n-----"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission93/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700366337294,
                "cdate": 1700366337294,
                "tmdate": 1700584843758,
                "mdate": 1700584843758,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VBJR1sv9be",
                "forum": "PhJUd3mbhP",
                "replyto": "XZLGgAbXIr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission93/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors"
                    },
                    "comment": {
                        "value": "As the rebuttal phase draws to a close, we want to thank the reviewers for their valuable feedback. We believe we have successfully addressed your concerns in our responses and welcome any further questions you might have.\n\nGiven the improvements and clarifications made based on your feedback, we kindly ask the reviewers to reconsider their evaluations to account for these updates. We greatly appreciate your consideration."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission93/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700620010134,
                "cdate": 1700620010134,
                "tmdate": 1700728336979,
                "mdate": 1700728336979,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5zwODvQqKS",
                "forum": "PhJUd3mbhP",
                "replyto": "VBJR1sv9be",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission93/Reviewer_paZk"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission93/Reviewer_paZk"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your clarifications and updates. I have updated my score."
                    }
                },
                "number": 31,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission93/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700736612126,
                "cdate": 1700736612126,
                "tmdate": 1700736612126,
                "mdate": 1700736612126,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]