[
    {
        "title": "Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with Agent Team Optimization"
    },
    {
        "review": {
            "id": "3IIIndWOAr",
            "forum": "i43XCU54Br",
            "replyto": "i43XCU54Br",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7199/Reviewer_yyiU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7199/Reviewer_yyiU"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposed a feedforward dynamic LLM agent network which can collaborate to improve the performance on reasoning and coding tasks. Previous work often include a static set of agents, which does not generalise to various tasks and requires strong human priors. In contrast, DyLAN (Dynamic LLM-Agent Network) has the following advantages with their design: 1. agents with different roles can exchange messages via the feedforward network 2. early-stopping when the agents reach consensus 3. automatic team optimisation by propagation (rating their predecessors in the network), aggregation (aggregate ratings from successors to quantify an agent's contribution) and selection (selecting top performing agents according to their scores derived from the propagation and aggregation steps). Finally, the model is evaluated on reasoning and coding tasks and demonstrates improved performance with reasonable computation cost."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper is written clearly and is easy to follow. The comparison with baseline methods are clearly illustrated in table 1.\n- The design of the feedforward communication and dynamic optimisation structure seems straightforward to implement and easily generalisable to various different types of tasks which require multi-agent collaboration and does not require strong human prior.\n- The case study (Figure 5) is helpful to understanding practical use cases of the model, and draw a connection of the proposed multi-agent feedforward interaction network to real-world software development scenarios where human developers are assigned different roles to collaborate in improving code quality."
                },
                "weaknesses": {
                    "value": "One limitation, which seems to be also shared with the compared baselines, is the performance gain compared with computation cost increase, especially when compared with the single execution. For example, in table 2-4, the Overall performance improved 4% but required 7 API calls (MATH dataset), 4 API calls (MMLU dataset) and 15 API calls (HumanEval dataset) compared to 1 API call with the single execution baseline."
                },
                "questions": {
                    "value": "For the coding case study, I think it is clear to me why such a multi-agent collaboration is helpful in improving the code performance. However, in the general reasoning task provided (Figure 6), it is unclear to me why it would require the language model to act 4 different roles? I see that on some topic which is debatable, perspectives from agents with diverse roles would help, but it is unclear if that is necessary on some topics which has a single correct solution?\n- If an agent is assigned the role of a doctor for solving the example mathematics problem, is the underlying language model deliberately trying to act as if it doesn't know how to solve the problem despite the fact that the same language model underlies the role of the mathematician?\n- For example, if we started with a majority of non-experts and a minority of experts, could the system potentially produce a wrong solution due to the non-experts reaching a consensus on a wrong solution and being the majority of the multi-agent system?\n\nOn Page 1, in the last paragraph, what does sensitivity mean?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7199/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7199/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7199/Reviewer_yyiU"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7199/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698264226576,
            "cdate": 1698264226576,
            "tmdate": 1699636855191,
            "mdate": 1699636855191,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KDHQoZn6tD",
                "forum": "i43XCU54Br",
                "replyto": "3IIIndWOAr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7199/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7199/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the constructive comments. Below, we provide detailed responses to each of your points.\n\n1. **Performance Gain vs. Computation Cost:**\n\nWe acknowledge your observation regarding the performance gain relative to the computation cost increase in experimental results. We want to clarify that **current multi-agent methods inherently involve a trade-off between performance gains and computational costs** and were discussed limitedly in previous works. Instead, we take it as an important factor.\n\nIt is important to note that our methods are orthogonal to different prompting methods, as shown in Table 2. **While prompt engineering methods can improve performance without increasing #API calls, our framework demonstrates improvement across different prompting methods by leveraging the collaborative strengths of multiple agents.** \n\nCompared with single execution, the seemingly marginal improvement from **all current methods** actually results from the limited collaborative capacity of the backbone model. We still view the LLM-agent collaboration as a promising direction for better utilization of LLMs. And we thought of two possible approaches to address it in the future work: (1) build LLMs that inherently incorporate collaboration mechanisms; (2) investigate specific scenarios that single LLMs struggle to complete, e.g., agents have exclusive resources or are distributedly deployed.\n\n2. **Necessity of Multi-Agent Collaboration:**\n\nPlease refer to General Response 2 for overall responses to your concern about the collaborations of agents with different roles. Here're some detailed explanations:\n\nYour question about the role of a doctor in solving a mathematics problem is insightful. There are chances that agents with certain roles refuse to answer specific queries. Generically, agents' behaviors are unpredictable without their actual responses, indicating that ideal agent team optimization could not be achieved based on human priors (also see General Response 5). **Since different roles provide diversity as well as potential poor performance, we propose a posterior agent team optimization method in DyLAN to mitigate this gap.** \n\nSpecific to your concern, as we described in General Response 2, Doctor, Programmer, Economist, and Mathematician agents may exclusively have correct answers to different mathematical queries, and it's difficult to distinguish whose answer is the correct one. Moreover, they may all have false answers but come up with a correct one after a discussion on the reasoning process / factual knowledge / probable hallucination. In conclusion, given that we couldn't predict whether an agent will respond faithfully according to its backbone model, give better solutions due to the stimuli of tools and role prompts, or even refuse to answer, **collaboration is necessary and is usually (if not always) better for accuracy on some topics even if they have a single correct solution**.\n\nWe will clarify this point by stating the discussion explicitly and demonstrating clearer cases in the case study.\n\n3. **Risk of Non-Expert Consensus Leading to Incorrect Solutions:**\n\nWe want to clarify that in most subjects of MMLU, there are only 1-2 expert agents among seven candidates in our experiments, and no expert agents for a few subjects, aka. **we have already conducted experiments with a majority of non-expert agents**. Please refer to General Response 3 for further discussion about the imbalance of experts and non-experts.\n\nRegarding the potential risk of non-experts reaching a consensus on an incorrect solution, **our Agent Team Optimization algorithm plays a key role in mitigating this**, as described in General Response 3. In extreme cases, where all agents are designed to perform poorly in specific tasks, possible techniques could be designed in addition to agent team optimization, such as automatically creating agents before optimization with validation, which is not our primary focus. \n\n4. **Clarification of \"Sensitivity\":**\n\nIn the last paragraph of Page 1, the term \"sensitivity\" refers to the system's low adaptability to the domain and complexity of different tasks. In a static setup, the lack of flexibility can lead to suboptimal performance when faced with tasks that deviate from the expected domain or complexity. Our dynamic multi-round approach in DyLAN and Agent Team Optimization method is designed to adapt more effectively to a broader range of tasks. We will clarify the term in the updated version."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7199/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700589536528,
                "cdate": 1700589536528,
                "tmdate": 1700590353760,
                "mdate": 1700590353760,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "t439dQbGgC",
                "forum": "i43XCU54Br",
                "replyto": "KDHQoZn6tD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7199/Reviewer_yyiU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7199/Reviewer_yyiU"
                ],
                "content": {
                    "title": {
                        "value": "thank the authors for their rebuttal"
                    },
                    "comment": {
                        "value": "thank the authors for their rebuttal and I have no further questions."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7199/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700658610265,
                "cdate": 1700658610265,
                "tmdate": 1700658610265,
                "mdate": 1700658610265,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rWyFEf48Kd",
            "forum": "i43XCU54Br",
            "replyto": "i43XCU54Br",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7199/Reviewer_9MJA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7199/Reviewer_9MJA"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces the Dynamic LLM-Agent Network (DyLAN), a framework for improving LLM agents collaboration. DyLAN structures the interaction between agents in a feed-forward manner, with an early-exit mechanism and inference time agent selection. It also provides a 3-step agent optimization algorithm (with a metric called Agent Important Score). The framework is evaluated on a number of tasks and has shown performance improvement over a single agent."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- As far as I know, formulating the LLM agent interaction as a feed-forward network seems novel. \n- The proposed method agent selection method and early exit method seem to improve performance and reduce the number of communication rounds."
                },
                "weaknesses": {
                    "value": "- It would be beneficial if some of the details of the method were discussed more clearly. For example, how are the agents different from each other? Did you manually create a list of agents before running the experiments? \n- It seems the agent team optimization part is an additional step to the inference, how many rounds of communication and \"training\" are required to get a specific task ready for inference with high accuracy? Do you need like 10% or more of the dataset for this optimization before you can use it for inference?"
                },
                "questions": {
                    "value": "- When top k agents are selected for the inference agent selection, how is the k selected?\n- Are the prompts the same between the agents when queried? Some of the existing methods assign fixed roles, which will guide the LLM to specialize in certain tasks/subtasks, how is the proposed method able to do that?\n- In the evaluation section, for Table 4, it seems the gain from your method to the baseline is smaller when using GPT-4 (than GPT3.5). Will this method still be effective when the single LLM model performance improves?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7199/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698723046740,
            "cdate": 1698723046740,
            "tmdate": 1699636855064,
            "mdate": 1699636855064,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tk25J6Jr8V",
                "forum": "i43XCU54Br",
                "replyto": "rWyFEf48Kd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7199/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7199/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the constructive feedback and comments. Below, we address each of your points in detail.\n\n1. **Clarification on Agent Differentiation and Construction:**\n\nPlease refer to General Response 4 for detailed clarification. \n\nIn DyLAN, the prompts are not the same between prompt-based agents according to Section 3.1 & 4.1 and Appendix E. This approach allows the agents to specialize in specific tasks or subtasks, contributing their unique strengths to the collaborative effort and utilizing different tools in various tasks. While diverse prompts may not significantly affect performance in some tasks like MATH, this specialization is crucial for achieving high accuracy in other scenarios like general reasoning and code generation. \n\nSpecific to your concern, agents with specific expertise could be automatically settled in each time step by the Agent Team Optimization process. Orthogonally, agents can be manually set in different time steps; e.g., we designate four code writers and four judges in different time steps for code generation tasks, as exhibited in Figure 5. Thus, agents could collaborate at both task and subtask levels.\n\nOur revised paper will provide a more precise explanation of the process and construction of agent teams.\n\n2. **Agent Team Optimization Process:**\n\nThe agent team optimization in DyLAN is indeed an additional step. Please note that the process is unsupervised, meaning it does not rely on labeled data. As described in Appendix C.1, the additional consumption of API calls is 8.30 on average for general reasoning tasks and 23.04 on average for code generation. We did not add these costs to the collaboration process of optimized teams of agents because the unsupervised optimization could be performed offline, and the scores are reusable. Moreover, according to the first paragraph of Section 4.3, only a small amount of data is enough for optimization towards higher accuracy.\n\nAlso, the unsupervised optimization process required no extra data as an additional step to inference. Please note that it is not an overfitting since no label is used during the process. We will emphasize these details in our revised paper to provide a comprehensive understanding of the agent team optimization process.\n\n3. **Selection of Top k Agents and Efficiency:**\n\nk is a super-parameter that is tuned to balance efficiency and performance. We assign k=2 because it is the minimal number for agents\u2019 interactions, and empirically found it brings a great trade-off between effectiveness and efficiency. We will include the information on how k is selected in our revised paper.\n\n4. **Performance Improvement Relative to Backbone Models:**\n\nRegarding the observation in Table 5 about the smaller gains over the baseline when using GPT-4 compared to GPT-3.5, we believe this is due to the simplicity of HumanEval benchmark instead of the ineffectiveness of the method, since the score is 90+ and the improvement seems to be marginal. It is easy to understand that very weak LMs cannot collaborate and solve tasks, but DyLAN with GPT-3.5 actually gains excellent improvement. Thus, **the improvement of backbone models actually makes collaboration and agent team optimization more effective**. That is because capacities of reasoning, instruction following, etc., determine the effectiveness of LLM-agent collaborations.\n\nAs **for empirical results**, due to budget limits, we have only tested DyLAN on the humanities category of MMLU with GPT-4-0314, and we found an improvement from 83.9 (single execution) to 87.9 (+4.0), greater than +2.3 (from 59.8 to 62.1) with GPT-3.5 in Table 3. Nonetheless, we acknowledge that, ideally, if single agents are capable of solving tasks in whatever complexity at 100% accuracy, DyLAN will be meaningless. Nevertheless, in fact, even GPT-4 can only reach <50% accuracy or even lower in some challenging tasks, including MATH (we have tested), WebArena [1], SWE-bench [2], etc., denoting strong potential for LLM-agent collaboration and agent team optimization methods in DyLAN.\n\nWe are also experimenting with how our framework can be adapted to leverage the collaborative potential of LLMs in a more challenging task - WebShop. If time permits, we will also update the results.\n\n[1] WebArena: A Realistic Web Environment for Building Autonomous Agents. https://arxiv.org/abs/2307.13854  \n[2] SWE-bench: Can Language Models Resolve Real-World GitHub Issues? https://arxiv.org/abs/2310.06770"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7199/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700590708433,
                "cdate": 1700590708433,
                "tmdate": 1700596795685,
                "mdate": 1700596795685,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "uv7x4DigSl",
            "forum": "i43XCU54Br",
            "replyto": "i43XCU54Br",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7199/Reviewer_qY2A"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7199/Reviewer_qY2A"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents Dynamic LLM-Agent Network (DyLAN) for LLM-agent collaboration on complicated tasks like reasoning and code generation. It improves the efficiency and the performance of LLM-agent collaboration via inference-time agent selection at a middle-time step and byzantine consensus to terminate inference at a proper layer. They further design an automatic agent team optimization algorithm to optimize the composition of agents for DyLAN based on an unsupervised metric Agent Importance Score,"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. DyLAN properly combines multiple standard techniques to improve the performance and efficiency of LLM-agent collaboration on complicated tasks.\n2. In the ablation studies section, the paper empirically shows how different strategies can individually and together contribute to improvement."
                },
                "weaknesses": {
                    "value": "1. Novelty is somewhat limited since the framework is primarily a combination of standard technologies.\n2. The baseline (i.e., random selection) for agent team optimization is very weak."
                },
                "questions": {
                    "value": "In addition to empirical results, do you have any insights to explain why Shapley Value is not a good metric?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7199/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7199/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7199/Reviewer_qY2A"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7199/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698758120180,
            "cdate": 1698758120180,
            "tmdate": 1699636854951,
            "mdate": 1699636854951,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9kB63mVVSr",
                "forum": "i43XCU54Br",
                "replyto": "uv7x4DigSl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7199/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7199/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the constructive comments. Below, we address each of your concerns in detail.\n\n1. **Novelty of the Framework:**\n\nPlease refer to General Response 1 for the overall explanation of our contributions. We understand your perspective on the perceived limited novelty of our framework, given its use of standard technologies. However, we argue that the novelty of our work lies in **the unique concept of agent team optimization, and the innovative and effective method based on the unsupervised metric Agent Importance Score**. We will emphasize and clarify the point in the updated version of our paper.\n\n2. **Baseline for Agent Team Optimization:**\n\nPlease refer to General Response 5 for the additional baseline (Human Prior Selection) for Agent Team Optimization. We demonstrated that the current agent team optimization method is posterior and based on actual interactions and peer ratings between agents. **It exhibits significant improvement compared to prior selections.** As a detailed explanation, prior selections seem to overweigh the statement from role prompts and fail to predict each agent's actual behaviors and the functions of tools from short descriptions. We will add the results and the discussion in the updated paper.\n\n3. **Shapley Value as a Metric for Individual Contributions:**\n\nShapley Value is **well-used for measuring marginal (individual) contributions in multi-agent settings**. We chose not to use Shapley Value as a metric for agent team optimization because it is **inherently a supervised metric**, requiring labeled data to accurately assess the contribution of each agent, let alone its **high computational costs**. It's impractical in real scenarios and limited in generalizability. In contrast, our Agent Importance Score is an unsupervised metric designed to evaluate agent contributions without needing labeled data. This approach is more aligned with the practical constraints and diverse applications of LLM-agent collaborations, where labeled data may not always be available or feasible to obtain. Appendix D.5 elaborates on **Shapley Value as the self-evident metric for validating Agent Importance Score**. We will emphasize this point in the updated version of the paper."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7199/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700590099931,
                "cdate": 1700590099931,
                "tmdate": 1700590329788,
                "mdate": 1700590329788,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "lrSp4oqMd8",
            "forum": "i43XCU54Br",
            "replyto": "i43XCU54Br",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7199/Reviewer_KzWB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7199/Reviewer_KzWB"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed an approach called DyLAN to optimize the performance of an ensemble of LLMs when answering a query of interest. DyLAN enables better collective performance by having a collaboration framework where ensemble members interact for multiple iterations and rate each others' responses to the query. DyLAN then proposed (i) an **agent selection mechanism** that filters out a few ensemble members with the worst responses and (ii) an **early stopping mechanism** that stops interaction between ensemble members once 2/3 of the ensemble members agree on a common response.\n\nThe authors demonstrate that DyLAN achieves better accuracy than baselines in three tasks requiring the ensemble to reason or generate code. DyLAN was compared against representative works that also attempt to improve the performance of a collection of interacting LLMs. Ablation studies were also conducted to demonstrate the importance of various factors related to DyLAN's training process and its own agent selection and early-stopping mechanism."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "**Minor Strength - Originality - Method Novelty** \n\nTo the best of my limited knowledge about training an ensemble of LLMs, DyLAN seems to be a novel approach. At least compared to the methods provided in the related section of the work, DyLAN appears to have significant differences (i.e. with respect to the early stopping and agent selection mechanisms) with previous work, which seem plausible in further improving the performance of an ensemble of LLMs. Nonetheless, the topic of training a collection of interacting LLMs itself seems to have been explored by previous works already.\n\n**Minor Strength - Quality - Method Soundness**\n\nExcept for some minor weaknesses (written in the section below), DyLAN's early stopping and agent selection mechanism seems generally sound from a multiagent systems perspective. Given the existence of a sufficient number of LLMs that can expertly handle an input query, I find it plausible that DyLAN should be able to identify a smaller number of LLMs whose response we can refer to once they achieve consensus.\n\n**Major Strength - Quality - Experiment**\n\nWhile I cannot comment much on the baseline selection following my limited knowledge of the topic, I find that the designed experiments were well designed to demonstrate DyLAN's advantages in terms of its overall accuracy and incurred cost during an interaction. At the same time, I highly appreciate the ablation study conducted by the authors to investigate the importance of the early-stopping and agent selection mechanisms. I especially like how it demonstrates the importance of the agent selection mechanism.\n\n**Major Strength - Clarity - Experiment Analysis**\n\nAs a reader with less expertise in this topic, I also highly appreciate how the authors carefully outlined the different insights gained from each experiment. This helps in pinpointing the importance of the DyLAN's various components and in gaining an understanding of the capabilities achieved by DyLAN. Similarly, insights gained from comparison against different baselines were properly written down, also making it easier for a reader with less expertise in this topic."
                },
                "weaknesses": {
                    "value": "**Minor weakness - Clarity - Lack of Problem Formulation**\n\nIt was slightly tricky to grasp the type of queries being solved by the ensemble of LLMs and how they interact with each other. While it is unfortunate that it was relegated to the appendix, Figure 5 is an excellent figure that could have helped readers understand the problem being solved if it had been presented earlier. In place of Figure 5 which seems to take a lot of space, perhaps the authors could consider describing a formal model of the interaction between agents and decision-making problems just to give more context.\n\n**Minor Weakness - Soundness - Expert LLMs being outnumbered by non-expert members of the ensemble**\n\nI suppose one of the weaknesses of DyLAN is when the number of expert LLMs for dealing with a particular query is significantly lower than the number of non-experts. If somehow the number of non-expert LLMs selected during agent selection is still larger than the experts after agent selection, DyLAN can still yield poor accuracies. Perhaps it could be useful to have multiple rounds of agent selection until some average score/metric (ideally reflecting their capacity in solving the task) of the remaining LLMs is above a certain threshold.\n\n**Minor Weakness - Soundness - Absence of reliable rankers**\n\nAnother possible pitfall occurs when DyLAN does not have a reliable ranker for agent selection, which results in the selection of possibly highly suboptimal members of the ensemble for the final decision."
                },
                "questions": {
                    "value": "1. Is DyLAN equipped with a mechanism to deal with a severe imbalance between expert and non-expert agents?\n2. Can you explain the rankers considered for DyLAN and why a specific ranker is chosen?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "I have ethical concerns of the method."
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7199/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698785579929,
            "cdate": 1698785579929,
            "tmdate": 1699636854823,
            "mdate": 1699636854823,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "uFMSoQwYv1",
                "forum": "i43XCU54Br",
                "replyto": "lrSp4oqMd8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7199/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7199/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the constructive feedback and comments. Below, we respond to each of your concerns in detail.\n\n1. **Clarity and Problem Formulation:**\n\nWe appreciate your suggestion regarding our formulations. We agree that Figure 5 is a crucial element in conveying the concept and operations of DyLAN. Currently, we demonstrate the formal model for agent interactions as a feed-forward network $S=(A, E)$, in Section 3.1, and we described how task query $q$ is solved by the system's output $o$ in the last paragraph. Based on your suggestion, we will consider including a formal model, including the decision-making process earlier in the text, to provide readers with a clearer and more immediate understanding of the problem being solved. \n\n2. **Handling Imbalance Between Expert and Non-Expert Agents:**\n\nYour concern about the potential imbalance between expert and non-expert LLMs in DyLAN is insightful. Please refer to General Response 3 for detailed explanations. Based on empirical results, we explained that **Agent Team Optimization could deal with the imbalance between expert and non-expert agents**. Implementing multiple rounds of agent selection is likely to be effective in addressing extreme cases, as you suggested. We believe this approach will enhance the robustness of DyLAN against the risk of poor accuracies due to an imbalance in expertise.\n\n**To step further, we want to share some thoughts on building metrics that reflect an agent's capacity for certain tasks**. A new work demonstrates several aspects for evaluating agents under multi-agent settings [1]. We think it is possible to extend its metric to certain timesteps inside DyLAN for a clear understanding of agents' capacities. We will add the discussion to our updated paper.\n\n3. **Selection and Effectiveness of Rankers:**\n\nRegarding the rankers used in DyLAN, we conducted an ablation study to evaluate the performance of various ranking methods in Appendix D.3. The choice of a specific ranker was based on its ability to improve the overall performance with reasonable computational costs. As described in the second paragraph in Section 2, there are mainly two types of rankers - listwise and pairwise. The former ranks candidates in one pass, and the latter ranks candidates by scoring them based on the comparison result of each pair of candidates. We tested three kinds of pairwise candidates, including LLM-Blender (using GPT-3.5 to judge each pair), Elo Score (using GPT-3.5 as a judge within theoretic probability distribution models), and Sliding Window (using GPT-3.5 with only $nk$ times comparison for top k), along with listwise ranker (based on GPT-3.5). \n\nWe eventually found **their performance roughly the same** for DyLAN, and the listwise method saved computational costs. It might be because of the strong discrimination ability of GPT-3.5. We use the listwise ranker for all other experiments, and it indeed demonstrates effectiveness and efficiency on downstream tasks. Also, we acknowledge that multiple rankers could be potentially beneficial for DyLAN but may introduce extra costs. We will state these discussions explicitly in the updated paper.\n\nIn conclusion, we believe that our paper's additional explanations, experiments, and reorganization, as suggested in response to your feedback, will significantly strengthen our work. We are committed to advancing the field of LLM-agent collaborations and appreciate your valuable input in helping us refine our approach.\n\n[1] MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration. https://arxiv.org/abs/2311.08562"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7199/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700591329687,
                "cdate": 1700591329687,
                "tmdate": 1700591329687,
                "mdate": 1700591329687,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KdCeKo152l",
                "forum": "i43XCU54Br",
                "replyto": "uFMSoQwYv1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7199/Reviewer_KzWB"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7199/Reviewer_KzWB"
                ],
                "content": {
                    "title": {
                        "value": "Response to Author Comments"
                    },
                    "comment": {
                        "value": "Thank you for your response. It does help address some of my concerns. As such, I will keep my original scores."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7199/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700657851182,
                "cdate": 1700657851182,
                "tmdate": 1700657851182,
                "mdate": 1700657851182,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "4G1SwBp4Wg",
            "forum": "i43XCU54Br",
            "replyto": "i43XCU54Br",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7199/Reviewer_mH5o"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7199/Reviewer_mH5o"
            ],
            "content": {
                "summary": {
                    "value": "This paper suggests the creation of a tactical group of agents that communicate within a flexible interaction structure tailored to the specific task at hand. The approach involves developing a system called the Dynamic LLM-Agent Network (DyLAN), which facilitates collaboration among LLM agents on complex activities, including reasoning and generating code. DyLAN allows for multi-round interactions among agents within an adaptable framework, incorporating on-the-fly agent selection and a premature termination feature to enhance both performance and efficiency. Additionally, this paper introduces a method for the automatic optimization of the agent team, utilizing an unsupervised metric named the Agent Importance Score. This score helps in determining the most effective agents by evaluating the individual contributions of each agent."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Pros:\n1. This paper proposes a framework DyLAN, which presents a novel structure for LLM-agent cooperation, assembling agents in a tiered, feed-forward network that features adaptive architecture, incorporating mechanisms for selecting agents during inference and halting the process prematurely when necessary. \n2. To optimize agent collaboration within DyLAN, this paper crafted a self-governing optimization algorithm that leverages an Agent Importance Score determined without supervision, aiming for a balance of performance and efficiency.\n3. This paper claimed that DyLAN has been shown to deliver strong results in accuracy, efficiency, and consistency across a spectrum of tasks, including general reasoning, numerical problem-solving, and the generation of code."
                },
                "weaknesses": {
                    "value": "Cons:\n1. This paper cannot demonstrate that agent collaboration must perform better than single agent. For example, in Figure 6, the agent collaboration is totally unnecessary. The roles such as Programmer, Economist and Doctor are useless for the math reasoning problem.\n2. The results are not convincing. For example, does agent collaboration really perform better than single agent on math reasoning? The example in Figure 6 does not show the benefit of agent collaboration on math reasoning.\n3. The collaboration process is unclear. For example, in Figure 5, how does the algorithm developer and programmer collaborate together? It seems programmer can already finish the task very well.\n4. It is suggested that the authors explain more clearly the function of Agent Importance Scores using examples. Otherwise, it is unclear why it is necessary. This paper says that \u201cWe ignore the peer rating scores in responses of agents for computing Agent Importance Scores.\u201d In Figure 5. The author may not ignore the peer rating process.\n5. The contribution is limited. The agent collaboration framework only use \u201crole-playing\u201d for different agents, which is proposed in the previous paper [1], and also discussed in many previous papers such as [2]. It is suggested that the authors could consider adding tool use. For example, it does not make sense to use LLMs as unit tester (in Figure 5).\n6. Some important references are missing. It is worth noting that this paper does not cite the paper [1] which proposed \u201crole-playing\u201d.\n\n[1] CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language Model Society NeurIPS 2023 https://arxiv.org/abs/2303.17760\n\n[2] Unleashing cognitive synergy in large language models: A task-solving agent through multi-persona self-collaboration https://arxiv.org/abs/2307.05300"
                },
                "questions": {
                    "value": "See weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7199/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7199/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7199/Reviewer_mH5o"
                    ]
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7199/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698839851968,
            "cdate": 1698839851968,
            "tmdate": 1699636854722,
            "mdate": 1699636854722,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4pFBM0MOXr",
                "forum": "i43XCU54Br",
                "replyto": "4G1SwBp4Wg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7199/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7199/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the constructive feedback and comments. Below, we address each of your concerns in detail.\n\n1. **Clarification on the contributions and motivation**\n\nPlease refer to General Response 1 for the summary of the contributions. We want to clarify that \"role-playing\" agents are not our focus and are **only used partially in both the formulation and experiments**.\n\n2. **Addressing Factual Errors:**\n\nWe acknowledge the confusion caused by certain aspects of our presentation. Here are clarifications:\n\n2.1. Empirically, we have compared the performance of **single and multiple agents** (in Table 2, 3, and 5), and our findings align with previous research underscoring the benefits of multi-agent collaboration.\n\n2.2. In response to your suggestion regarding **tool usage**, we refer to our General Response 4, where we elaborate on tool usage in DyLAN, as described in Section 3 & 4.1. \n\n2.3. In Figure 5, **Unit Tester** is indeed an LLM agent equipped with Code Interpreter as a tool, according to the last sentence of Section 4.1 and the last paragraph of Appendix C.1. We didn't deploy extra tools except code interpreters because of the alignment towards baseline methods.\n\n2.4. We ignore the scoring process in Figure 5 mainly due to simplicity since there are 8 agents in Figure 5. We chose to demonstrate **the scoring process in Figure 6** with only 4 agents.\n\nWe will clarify these points and rectify any wording issues in our revised paper.\n\n3. **Necessity and Performance of Agent Collaboration vs. Single Agent:**\n\nPlease refer to General Response 2 for the discussion of the effectiveness of LLM-agent collaborations. Detailed explanations about comparing the collaboration with single LLM agents are as follows.\n\nOur work is grounded in the philosophy that while a single, perfect agent capable of efficiently handling all tasks is an ideal goal, it is not yet achievable. In this context, our Dynamic LLM-Agent Network (DyLAN) framework aims to leverage the strengths of multiple agents in a collaborative setting to achieve better results and cost-efficiency, as well as better generalizability compared to a single agent.\n\nFrom our observations in current experiment settings: (1) Expert is hard to manually select when there are many candidates; (2) The selection from human priors (by LLMs) mismatches the optimal team of agents and cause severe performance drop (refer to General Response 5).\n\nIn response to your comments, **Mathematician and Programmer agents alone are not enough for all mathematical and programming problems, respectively**. For instance, Programmer and Economist agent can outperform Mathematician agent in elementary mathematics, and a single programmer in Figure 5 (based on GPT-35-turbo-0301) could only achieve 73.2 on HumanEval compared to 82.9 from DyLAN. Collaboration. We'll add a different case to demonstrate the effectiveness of collaborations, e.g., DyLAN solves a query where all single agents fail.\n\n4. **Clarification of the Collaboration Process:**\n\nTo be specific, in Figure 5, Programmer and Algorithm Developer agents write incorrect programs at t=1, and at t=3, they receive the judgment from judges at t=2, thereby perceiving other cases along with according judgments from Unit Tester, Syntax Checker, and other judges. Programmer at t=3 refined its solution, which turned out to be correct, while Algorithm Developer still failed. The process demonstrates that code writers refine their solutions based on the feedback from judges and ensemble cases from other code writers. After Inference-Time Agent Selection, the other two agents reach a consensus and vote for the final, correct answer.\n\nIn short, **the interplay of agents' distinct expertise leads to a more robust and accurate solution than what a single agent could achieve**. We will add these descriptions to the caption of Figure 5. Additionally, to demonstrate the necessity and effectiveness of Agent Importance Score in Figure 5, we will include more detailed examples in the revised version.\n\n5. **Missing References:**\n\nWe apologize for the oversight in not citing the relevant paper. Though \"role-playing\" is not our core focus, we acknowledge its importance in the field of LLM agents. The reference will be duly added in the next version of our paper."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7199/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700586467403,
                "cdate": 1700586467403,
                "tmdate": 1700596767260,
                "mdate": 1700596767260,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "YAPg4fgCjm",
            "forum": "i43XCU54Br",
            "replyto": "i43XCU54Br",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7199/Reviewer_CxXZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7199/Reviewer_CxXZ"
            ],
            "content": {
                "summary": {
                    "value": "The main contributions of this paper are:\n\n- Proposing a new framework called Dynamic LLM-Agent Network (DyLAN) for organizing collaboration between multiple LLM agents. DyLAN allows agents to interact over multiple rounds in a dynamic architecture.\n- Introducing two key components in DyLAN - inference-time agent selection to filter out low-performing agents, and an early stopping mechanism based on Byzantine consensus theory to improve efficiency.\n- Developing an unsupervised metric called Agent Importance Score to quantify each agent's contribution, which can then be used to automatically optimize the composition of the agent team for a given task.\n- Demonstrating DyLAN's effectiveness on multiple tasks including reasoning, arithmetic and code generation, showing accuracy improvements and reasonable computational cost compared to baselines. Agent team optimization is shown to further boost performance on specific tasks/domains."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The technical claims around the DyLAN framework and agent team optimization seem reasonably sound, though not groundbreaking. The core ideas build incrementally on related work.\n- The experimental methodology is generally solid, with evaluations on multiple representative tasks using reasonable baselines. However, comparisons to some very latest multi-agent LLM methods are lacking.\n- The central claims around DyLAN's performance are supported reasonably well by the experiments. The gains over baselines help validate the techniques.\n- Analysis and insight could be deeper around why agent team optimization works and whether the proposed scoring method effectively captures agent contributions.\nOverall the paper quality seems good. The techniques seem to work fairly well in practice. But the novelty and advancement over recent related work appears modest."
                },
                "weaknesses": {
                    "value": "The core ideas around dynamically organizing LLM agent collaborations and automatically optimizing the agent team seem novel and could be of interest to the ICLR community. However, the paper is generally incremental work building on a lot of recent research around multi-agent LLMs. The techniques used, like inference-time pruning and unsupervised contribution scoring, are not completely new concepts either. \nIn more details:\n- The experimental validation is reasonable but mainly incremental - evaluating on established datasets with existing baseline methods. More complex, real-world tasks could be illustrative.\n- The paper claims efficient collaboration but the overhead of techniques like peer rating and consensus checks could be significant. More analysis on computational costs is needed.\n- There is limited ablation study or analysis into the agent scoring method. It is unclear if it is actually capturing meaningful contribution effectively.\n- Why was CodeT chosen as the baseline? This does not appear to be a reasonable baseline. CodeT is not a multi-agent framework for code generation. It works on the principle of generating more test cases in order to improve the ranking of the solutions. Stronger baselines should be chosen for a fairer comparison.\n- The presentation seems repetitive in parts with previous sections being paraphrased. More clarity and conciseness in writing would strengthen the paper."
                },
                "questions": {
                    "value": "- How does DyLAN's performance compare to other very recent works on multi-agent LLMs? The baselines used seem a bit outdated.\n- Can you provide more analysis/insight into why agent team optimization works well? Is the Agent Importance Score capturing something meaningful?\n- Have you experimented with DyLAN on more complex, open-ended tasks beyond the datasets used? How does it perform?\n- Could DyLAN be extended to do online agent team optimization during inference as well?\n- For early stopping via Byzantine consensus, how did you determine the optimal threshold for answer similarity? Was this tuned per task?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7199/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7199/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7199/Reviewer_CxXZ"
                    ]
                }
            },
            "number": 6,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7199/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699369265669,
            "cdate": 1699369265669,
            "tmdate": 1699636854626,
            "mdate": 1699636854626,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "zpIrhS4zAz",
                "forum": "i43XCU54Br",
                "replyto": "YAPg4fgCjm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7199/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7199/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Individual Response 1"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the constructive feedback and comments. Below, we respond to each point in detail.\n\n1. **Summary of Key Contributions and Novelty:**\n\nPlease refer to General Response 1 for the summary of contributions. Our core contribution of improving LLM-agent collaborations by optimizing agent teams is **distinct from previous methods or concepts**, especially as we proposed an unsupervised metric Agent Importance Score to implement the posterior optimization. \n\n2. **Experimental Validation and Real-World Applicability:**\n\nOur experiments were designed to provide a clear and objective evaluation of DyLAN's performance. We chose established general datasets and **the strongest baselines (before the submission time)** for their recognized validity in the research community. All baselines are chosen for fair reasons. Specifically, CodeT is the strongest method based on GPT-35-turbo before submission. Even though Reflexion managed to reach SOTA using GPT-4, it still performs worse than CodeT on GPT-35-turbo, as shown in Table 5.\n\nWe acknowledge that CodeT is not a multi-agent method, but **it serves as a strong baseline even with multi-agent methods coming out near the submission date**. Because we were not able to re-implement all of them, we post a few reported results from recent (concurrent) multi-agent works on HumanEval with different backbone models:\n\n|Method|GPT-35-turbo|GPT-4|\n|:----|:---:|:---:|\n|AgentVerse [1]|75.6|89.0|\n|CAMEL [2]|69.4| - |\n|MetaGPT [3]| - |85.9|\n|The best baselines in our paper|74.8 (CodeT)|91.4 (Reflexion)|\n|**DyLAN** (*Ours*)|**82.9**|**92.1**|\n\nRegarding MMLU and MATH datasets, most multi-agent works [4] have not reported their results on the datasets or used the same backbone model, and it\u2019s out of budget for us to reimplement those methods on GPT-35-turbo. Nonetheless, we demonstrate our fair reasons for baseline selections and the effectiveness of DyLAN.\n\nWe acknowledge your point about the potential benefits of evaluating DyLAN on more complex, real-world tasks. As part of the rebuttal response, we are extending our evaluation to more diverse and challenging scenarios, such as WebShop [5], to demonstrate the applicability of our framework further. Due to the time limit, we plan to update the results later.\n\n3. **Clarification on Computational Overhead and Efficiency:**\n\nRegarding the computational overhead of techniques like peer rating and consensus checks, we have **already included these factors** in the number of API calls reported in our experiments:\n\n- In Appendix C.2, we mentioned that the rating is implemented by the suffix of prompts. Thus, the rating process does not affect #API calls. Indeed, this kind of prompting would increase token consumption. However, we find it insignificant since CoT prompts, reasoning processes, mathematical formulas, and codes take up most of the token consumption.\n\n- In the last two paragraphs of Appendix C.1, we mentioned that consensus checks are processed by template matching with pure scripts. Thus, the overhead is small and does not change #API calls as well. \n\nWe appreciate your concern about our potential mistakes. We will explicitly describe the overhead above in the next version of the paper.\n\n4. **Clarity and Conciseness of Presentation:**\n\nWe appreciate your feedback on our paper's presentation. We will undertake a thorough review to eliminate repetitive content and improve clarity and conciseness.\n\n[1] AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors. https://arxiv.org/abs/2308.10848  \n[2] CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language Model Society. In proceedings of the 37th Conference on Neural Information Processing Systems. https://arxiv.org/abs/2303.17760  \n[3] MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework. https://arxiv.org/abs/2308.00352v5  \n[4] AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation. https://arxiv.org/abs/2308.08155  \n[5] WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents. https://arxiv.org/abs/2207.01206"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7199/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700587747681,
                "cdate": 1700587747681,
                "tmdate": 1700596739379,
                "mdate": 1700596739379,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2gNakaCR4u",
                "forum": "i43XCU54Br",
                "replyto": "YAPg4fgCjm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7199/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7199/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Individual Response 2"
                    },
                    "comment": {
                        "value": "5. **Analysis and Insights on Agent Team Optimization:**\n\nThe effectiveness of our agent team optimization approach is a key contribution of our work. The Agent Importance Score is designed to capture the contributions of individual agents within a collaboration based on actual responses. \n\nFirst, we want to clarify the **motivation** of the scoring method. The scoring method is inspired by neural Importance Score in traditional machine learning studies, as explained in Section 2. While the algorithm couldn\u2019t be directly transferred, we propose a three-step algorithm (as described in Section 3.3) by leveraging peer ratings to achieve effectiveness and efficiency. There are also several human-team optimization findings supporting our methodology, as shown in Section 2.\n\nWe also **provided empirical results to demonstrate Agent Importance Score as the indicator of individual contributions**. (1) The direct proof is the performance improvement after optimization in downstream tasks. In the last paragraph in Section 4.2 and the second paragraph in Section 4.3, we clearly describe the benefits of Agent Team Optimization and the impact of team sizes. (2) We also compared the scoring distribution with Shapley Value (Appendix D.5). We found that Agent Importance Score has a closer distribution to Shapley Value, which shows that the scoring process grasps the individual contributions of each agent to a fair extent.\n\nSome insights could be derived from the existing results. As shown in Table 6, Agent Team Optimization is capable of **differentiating contributory agents** from the others. Some contributory agents match human prior, e.g., Mathematician for college mathematics, and some seem to be unrelated or not directly related, e.g., Psychologist for public relations. It reveals that Agent Team Optimization could not only retrieve domain experts but might **also retrieve agents with other domain knowledge that might help** (refer to Appendix D.1 & D.4). Moreover, peer ratings are more reliable than self-confidence due to previous studies [6], which provides extra solid support for our method.\n\nPlease refer to General Response 5 for the additional experiment of another baseline for Agent Team Optimization. We will add the discussion in the next version of our paper.\n\n6. **Extension to Online Agent Team Optimization:**\n\nFirst, we want to clarify that **Agent Team Optimization does not depend on the label or the ground truth of datasets**. The optimization is based on the unsupervised metric Agent Importance Score. Thus, the optimization method **can already be performed posteriorly during inference** at this stage. \n\nRegarding online agent team optimization methods, DyLAN currently employs Inference-Time Agent Selection as a naive approach of online optimization, as described in Appendix B (Limitation). **The challenge is to capture the actual multi-round behaviors of agents in the middle of collaboration**. Inference-Time Agent Selection only considers single-round responses and does not consider the ratings from the agents themselves. There is potential for further development in this area, allowing for more concrete and adaptive online agent team optimization.\n\n7. **Optimal Threshold of Answer Similarity for Early Stopping:**\n\nIn Appendix C.1, we described using exact match for classification queries and BLEU scores for open-ended generation tasks, including code generation tasks. We set the threshold of BLEU score to 0.9 empirically for all open-ended generation tasks without specific tuning since it\u2019s not our primary focus. In Appendix B (Limitation), we acknowledge that the threshold and choices of methods could be further optimized, and based on our observation, it does affect the performance, though marginally.\n\n[6] Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs. https://arxiv.org/abs/2306.13063"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7199/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700588079175,
                "cdate": 1700588079175,
                "tmdate": 1700596752358,
                "mdate": 1700596752358,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]