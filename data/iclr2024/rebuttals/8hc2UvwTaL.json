[
    {
        "title": "FLAIM: AIM-based Synthetic Data Generation in the Federated Setting"
    },
    {
        "review": {
            "id": "Sk8Ik6AbJE",
            "forum": "8hc2UvwTaL",
            "replyto": "8hc2UvwTaL",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5296/Reviewer_DXga"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5296/Reviewer_DXga"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies differentially private data synthesis in the horizontal federated learning setting. The authors identify the key challenge of this problem is the data heterogeneity. In this paper, the authors propose two variants of the central AIM algorithm, DistAIM and FLAIM. Compared with DistAIM, the FLAIM is expected to rely on a more light-weight secure aggregation algorithm. The authors show the proposed algorithm can outperform the naive implementation of AIM in a federated learning setting."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The authors identify the challenges in differentially private data synthesis with heterogeneous local data in the federated learning setting.\n2. The authors propose two different algorithms for solving the challenge of differentially private data synthesis with heterogeneous data.\n3. The proposed FLAIM solution on how to handle the heterogeneity in marginal selection is novel."
                },
                "weaknesses": {
                    "value": "* Some key elements of the algorithm are not clearly motivated or explained, leaving the effectiveness of the algorithm unjustified.\n* Although it is acceptable that the DP data synthesis paper cannot provide a theoretical guarantee, some counter-intuitive phenomena in the experiments are not clearly explained.\n* The writing needs to be improved. \n  - Speaking at the paper structure level, while the core idea of the paper should be relatively straightforward, the paper's organization may introduce extra difficulties for readers to catch those ideas. Especially while the DistAIM and the proposed FLAIM are in the same section, it is not clear whether DistAIM is used as a motivation for FLAIM or serves as other purposes. \n  - As for the notation level, the paper user both $u(q; D)$ and $u(D; q)$ for the EM utility score. In the algorithm, $\\sigma_i$ (in line 14) may not be clearly defined (not sure whether it is used with $\\sigma_t$ interchangeably)."
                },
                "questions": {
                    "value": "1. Why does the local client still need to \"estimate the new local model via PGM\"? This step looks strange because the local models are not aggregated globally, but it may affect the query selection and measurement in the following local rounds, making it unclear what local measurement error will be aggregated to the server.\n2. What is the $\\tilde{N}$ and $\\sigma_i$ in line 14 of Algorithm 1?\n3. Is there any theoretical performance guarantee for the algorithm?\n4. Why is secure aggregation not applicable to the DistAIM?\n5. What assumption of trust between participants and compute servers is relaxed when switching from DistAIM to FLAIM? How much overhead is reduced because of cryptographic protocol changes? \n6. Why does AugFlaim (non-private) have worse performance than AugFlaim (private)? Does it mean too accurate heterogeneity information hurts the algorithm's performance? \n7. Why there is no AugFlaim (non-private) results in Figure 2f?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5296/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5296/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5296/Reviewer_DXga"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5296/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698116030311,
            "cdate": 1698116030311,
            "tmdate": 1699636529798,
            "mdate": 1699636529798,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "X8c4mcu34P",
                "forum": "8hc2UvwTaL",
                "replyto": "Sk8Ik6AbJE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5296/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5296/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer DXga (1/2)"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for their detailed comments and would like to address their questions and concerns.\n\n> The writing needs to be improved. \n\nWe have addressed the two points made about the paper structure and writing highlighted in your review (see below). Additionally, we have provided clearer conclusions in our experimental section and in the description of the FLAIM algorithm which has been highlighted in the new version of the paper.\n\n> Speaking at the paper structure level, while the core idea of the paper should be relatively straightforward, the paper's organization may introduce extra difficulties for readers to catch those ideas. Especially while the DistAIM and the proposed FLAIM are in the same section, it is not clear whether DistAIM is used as a motivation for FLAIM or serves as other purposes. \n\nThe purpose of DistAIM is twofold. First, it acts as motivation for FLAIM since it is one way to perform synthetic data generation in the federated setting via AIM. However, the key motivation that follows is that DistAIM is not defined within the standard FL framework, and because of this can suffer from high overhead with its cryptographic protocols.\n\nSecondly, DistAIM acts as a baseline derived from the extant literature. It is a modification of the Pereira et al. work which has been adapted to use AIM and to work in the FL setting with client subsampling. Following your comment, we have modified the paper to include clearer motivation of FLAIM (via DistAIM) and to separate the sections.\n\n>As for the notation level, the paper user both U(q;D) and U(D;q)  for the EM utility score [...]\n\nWe have fixed this inconsistency in the new version to use only $u(q;D$).\n\n>Why does the local client still need to \"estimate the new local model via PGM\"? This step looks strange because the local models are not aggregated globally, but it may affect the query selection and measurement in the following local rounds, making it unclear what local measurement error will be aggregated to the server.\n\nIf the local client is performing a single local step, they do not need to estimate the new local model via PGM. They simply choose a marginal to submit based on the global model estimates that are received at the start of the round. Line 9 of Algorithm 1 can be omitted when local steps s=1. We have updated the algorithm to make this clearer.\n\nA point of interest with FLAIM is whether performing multiple local steps gives any significant utility increase. There is a natural analog with the standard training of federated neural networks, where clients train a local model for a number of local epochs (or local steps). However, unlike standard DP-FL training of NNs, the privacy cost of FLAIM training is not decoupled from the number of local rounds performed. In other words, you must scale the privacy cost in the number of local rounds (in addition to the number of global steps). In the case of s > 1 local steps, the local model does need to be updated since they are making multiple marginal selections\n\n> What is the N and sigma in line 14 of Algorithm 1?\n\n$\\sigma$ is the associated standard deviation of the Gaussian noise that was added to the measurement. When the number of global rounds (T) is fixed, this is a constant for all measurements. If instead budget annealing is used, then sigma changes on a per-round basis (it is halved when the annealing condition passes, see Appendix A.1). In the presentation of Line 14 we have updated $\\sigma_i$ to be $\\sigma_t$ to make this clearer.\n\nN is the total number of samples that contributed to the measurement of a marginal across clients who provided it. To improve the clarity, we have updated the notation in the algorithm and defined it clearly at the end of Section 4.3 with a more detailed description.\n\n> Is there any theoretical performance guarantee for the algorithm?\n\nThere are no theoretical utility guarantees for the algorithm in the federated setting. We note that there are also no theoretical utility guarantees of the AIM method in the central setting. It may be possible to provide some guarantee showing the utility of FLAIM is close to that of central AIM and is something we regard as future work.\n\n> Why is secure aggregation not applicable to the DistAIM?\n\nSecure aggregation is applicable only to the aggregation of marginals in the AIM algorithm. This means secure-aggregation could be used to share the workload answers but further cryptographic techniques must be used by DistAIM to compute the exponential mechanism which is required for choosing a marginal to add to the model at a given round. One reason for introducing FLAIM is that secure-aggregation can be used in a straightforward manner without further cryptographic protocols."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5296/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700238355401,
                "cdate": 1700238355401,
                "tmdate": 1700238355401,
                "mdate": 1700238355401,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "VKudl4iyzz",
            "forum": "8hc2UvwTaL",
            "replyto": "8hc2UvwTaL",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5296/Reviewer_B23T"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5296/Reviewer_B23T"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a Federated Learning-based synthetic data generation method called FLAIM, a variation of the AIM algorithm, where data is distributed across multiple clients. The objective is to maintain individual privacy while collaboratively facilitating data sharing. FLAIM modifies AIM to handle heterogeneity and reduces overhead compared to traditional Secure Multi-party Computation (SMC) techniques. The proposed approach is evaluated on benchmark datasets and compared to other state-of-the-art methods, demonstrating improved utility while reducing overhead. This paper offers valuable insights into the challenges and solutions related to SDGs in a federated setting. The FLAIM algorithm proposed in the paper shows the potential to create effective synthetic data while maintaining privacy. The empirical study emphasizes the significance of considering heterogeneity in Federated Learning and the trade-offs between privacy and utility performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1) This paper suggests a new method for generating synthetic data in a Federated Learning setting while addressing the challenges of heterogeneity in federated settings.\n\n2) After conducting a comprehensive assessment of the FLAIM technique on standard datasets, the authors compared its performance with other cutting-edge techniques. The results showed that the FLAIM method offers better efficiency with reduced overhead."
                },
                "weaknesses": {
                    "value": "1) It remains a challenge to determine whether the FLAIM method would retain its efficiency when applied to real-world datasets that display more intricate structures and distributions, as its performance has been evaluated solely on benchmark datasets.\n\n2) Although the paper compares the FLAIM method to other advanced methods, it does not give a complete comparison to all the related methods in the literature."
                },
                "questions": {
                    "value": "I saw that you achieved significant performance improvement in the FL setting. What are the problems you will solve to re-implement the AIM algorithm in the FL setting?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5296/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5296/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5296/Reviewer_B23T"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5296/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698513209140,
            "cdate": 1698513209140,
            "tmdate": 1699636529711,
            "mdate": 1699636529711,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dSe5uxvRMu",
                "forum": "8hc2UvwTaL",
                "replyto": "VKudl4iyzz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5296/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5296/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer B23T"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for their comments.\n\n> It remains a challenge to determine whether the FLAIM method would retain its efficiency when applied to real-world datasets that display more intricate structures and distributions, as its performance has been evaluated solely on benchmark datasets.\n\nWe have selected a number of benchmark tabular datasets to be consistent with experiments performed in prior work in the central setting of DP. For example, the original AIM paper uses the Adult dataset in their experiments. Furthermore, we simulate the federation of these datasets using standard methods in the literature such as the label-skew approach introduced in [1]. \n\nWe believe these benchmarks are representative of \u2018real-world\u2019 data, which justifies their widespread adoption in the ML community.  Nevertheless, it is relevant to perform more evaluations on diverse data sets for FLAIM (as well as AIM). It is still challenging to run such tests in the federated setting because there are not \u201creal-world\u201d federated datasets freely available for tabular data. Benchmarks such as LEAF [2], aim to simulate realistic non-IID partitions but are for image/text data which is not well-suited for our task.\n\n[1] Li, Qinbin, et al. \"Federated learning on non-iid data silos: An experimental study.\" 2022 IEEE 38th International Conference on Data Engineering (ICDE). IEEE, 2022.\n\n[2] Caldas, Sebastian, et al. \"Leaf: A benchmark for federated settings.\" arXiv preprint arXiv:1812.01097 (2018).\n\n> ... it does not give a complete comparison to all the related methods in the literature.\n\nWe performed a thorough literature review, and reported the most relevant examples in the paper. For the federated case, we are not aware of any other methods except for the work of Pereira et al. in distributing MWEM which we have compared to by using DistAIM which is an improved version. The closest alternative is to compare with deep learning synthesizers such as GANs. These can be federated privately by training within standard DP-FL frameworks i.e., using DP-FedSGD. However, many recent studies such as [3,4,5] have highlighted the performance gap between graphical models and deep learning synthesizers when trained with DP in the central setting. They show graphical model approaches consistently perform better on tabular datasets. In particular, iterative methods that use PGM rank high on average. Additionally, the performance gap is likely worsened in FL where approaches like DP-GAN will not scale as well.\n\nWe already ran initial experiments to compare with alternative central baselines such as Bayesian methods (e.g. PrivBayes) and DP-GANs. We found that such methods perform worse than AIM on our benchmarks and even sometimes DistAIM/FLAIM. Hence, if we were to federate these methods they would follow the same performance gap (and likely be even worse).\n\n[3] Tao, Yuchao, et al. \"Benchmarking differentially private synthetic data generation algorithms.\" arXiv preprint arXiv:2112.09238 (2021).\n\n[4] Liu, Yucong, Chi-Hua Wang, and Guang Cheng. \"On the Utility Recovery Incapability of Neural Net-based Differential Private Tabular Training Data Synthesizer under Privacy Deregulation.\" arXiv e-prints (2022): arXiv-2211.\n\n[5] Ganev, Georgi, Kai Xu, and Emiliano De Cristofaro. \"Understanding how Differentially Private Generative Models Spend their Privacy Budget.\" arXiv preprint arXiv:2305.10994(2023).\n\n> I saw that you achieved significant performance improvement in the FL setting. What are the problems you will solve to re-implement the AIM algorithm in the FL setting\n\nTo recap, in Section 3 (of the revised paper), we introduce DistAIM, an extension of the recent work by Pereira et al. which replaces the poor in utility MWEM method with the SOTA method AIM. We change the setting by assuming only a proportion of clients are available to participate at a particular round which is common in practical FL scenarios. While this approach can have good utility it also requires significant overhead due to cryptographic protocols. We instead explore a more \u201ctraditional\u201d approach in FL which is based on clients performing a number of local steps before sending back model updates. This leads us to develop NaiveFLAIM which is a natural analog to standard FL training. However, we highlight in Section 4.1 the key problem we have to solve when working with FLAIM. If we let clients make decisions locally (and across multiple local steps) they are typically biased by heterogeneity in their local datasets. In order to correct this, we introduce (in Section 4.2 and 4.3)  a non-private and private measure of heterogeneity that can be used to correct these issues and maintain utility. Furthermore, when working under the FLAIM framework we can avoid the use of heavyweight cryptography which is needed in DistAIM which results in smaller overheads when datasets have features with large cardinality."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5296/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700237890151,
                "cdate": 1700237890151,
                "tmdate": 1700237890151,
                "mdate": 1700237890151,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "dVRXuSzYo2",
            "forum": "8hc2UvwTaL",
            "replyto": "8hc2UvwTaL",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5296/Reviewer_gW6i"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5296/Reviewer_gW6i"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers the problem of federated differentially private (DP) synthetic data generation (SDG). They start from the state of the art method AIM for DP SDG in the central model and consider multiple ways of distributing it. Firstly they consider a version of it implemented in secure multi-party computation (SMC), though they allow only a fraction of the data holders to be present at each step, introducing some extra error compared to using AIM. They then try to remove most of the heavy SMC by switching to a method based on federated learning, which introduces some more error from heterogeneity in the dataset. They then largely mitigate this new error using a private estimate of the heterogeneity to improve client choices.\n\nThey also provide an experimental section that shows that they do indeed get accuracy improvements from the parts of the algorithm designed to improve accuracy on various datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is clear and well written.\nThe results all seem reasonable and correct.\nThe privacy guarantees are rigorous."
                },
                "weaknesses": {
                    "value": "The biggest question mark here is whether DP-SDG isgoing to be the practical answer in any situation, though this seems worth exploring anyway."
                },
                "questions": {
                    "value": "Is the utility of the generated data actually good enough to make this a practical solution for any application?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5296/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698672086938,
            "cdate": 1698672086938,
            "tmdate": 1699636529612,
            "mdate": 1699636529612,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bRWHl3xWvL",
                "forum": "8hc2UvwTaL",
                "replyto": "dVRXuSzYo2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5296/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5296/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer gW6i"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for their feedback.\n\n>The biggest question mark here is whether DP-SDG is going to be the practical answer in any situation, though this seems worth exploring anyway.\n\n>Is the utility of the generated data actually good enough to make this a practical solution for any application?\n\nThese are important points and are the core motivation for our work. Firstly, we note that FLAIM is not meant to be a practical solution to all applications. SDG methods using graphical models often perform poorly on high-dimensional datasets (in the central setting) and our FLAIM method will inherit these problems as well. Furthermore, FLAIM is limited to tabular generation and so is unsuitable for image/text.\n\nWe claim that FLAIM does exhibit sufficient utility to allow it to be used for downstream tasks. Our primary notion of utility is the test AUC of classifiers trained on the synthetic data, as an exemplar task.  Figure 2f in our paper shows our best FLAIM methods can consistently achieve a test AUC of ~0.8 for $\\varepsilon=1$ on the Adult dataset. This is not far from the central AIM result of ~0.85 and would be a practically useful classifier. In our experiments, we often present the average L1 workload error to be consistent with prior work in this area. Here, there is an appreciable gap between the federated and central workload errors. However, this is not always predictive of the test AUC as we have shown."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5296/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700237328257,
                "cdate": 1700237328257,
                "tmdate": 1700237328257,
                "mdate": 1700237328257,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]