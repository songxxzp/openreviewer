[
    {
        "title": "Unsupervised Order Learning"
    },
    {
        "review": {
            "id": "bOFPwh7C36",
            "forum": "1CK45cqkEh",
            "replyto": "1CK45cqkEh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4789/Reviewer_rbKP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4789/Reviewer_rbKP"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed an unsupervised order clustering algorithm for dealing with order data To be specific, authors first proposed a ordered k-means algorithm which defines a measurement of the deviation of sample x from the cluster centroid chain in learned embedding space. Then authors claim that the ordered clustering can be defined as the distance between sample x and its centroid and two neighbored centroids. Based on these, authors proposed an ordered k-means algorithm for clustering ordered data."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper is well-written and the core idea and motivation are easy to follow."
                },
                "weaknesses": {
                    "value": "First, In page 3, authors claimed that \u201cwe propose the first unsupervised algorithm for order learning\u201d. Actually, this paper belongs to a kind of ordered data clustering task, which has been studied in many previous works, such as \n[1] An ordinal data clustering algorithm with automated distance learning, AAAI, 2020;\n[2] Deep repulsive clustering of ordered data based on order-identity decomposition, ICML, 2020.\nThus, this sentence is not precise.\n\nSecond, the deviation of sample x from the chain is borrowed from Lim et al. 2020, thus the true contribution of this paper is the ordered k-means algorithm in Algorithm 1 which is easy to deduce if we have Eq. (1). In a word, I think the true contribution is not enough for ICLR.\n\nThiredly, in experiments, the compared algorithms mostly are traditional clustering algorithms which can not verify the effectiveness of proposed methods. \n\nIn all, I prefer to give the \u201cmarginally below the acceptance threshold\u201d decision."
                },
                "questions": {
                    "value": "N/A"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4789/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698568944783,
            "cdate": 1698568944783,
            "tmdate": 1699636461409,
            "mdate": 1699636461409,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Vmhf3xYPNq",
                "forum": "1CK45cqkEh",
                "replyto": "bOFPwh7C36",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4789/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4789/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors"
                    },
                    "comment": {
                        "value": "Thank you for your constructive comments. We have revised the paper to address your comments faithfully. We have highlighted the revised parts in blue. Please find our responses below.\n\n---\n\n> **Relation with DLC (Zhang et al., AAAI 2020)**\n\nDLC is an *ordinary* clustering algorithm, but it attempts to cluster data with ordinal attribute values. Whereas ordinary clustering algorithms, including DLC, do not consider the order between resultant clusters, the proposed *ordered* clustering attempts to find clusters together with their meaningful order.\n\nFor example, DLC aims to group car instances with (already provided) ordinal attributes, such as buying cost, safety score, maintenance cost, and the number of doors.  A buying cost is labeled as one of four ordinal categories: \u2018low,\u2019 \u2018median,\u2019 \u2018high,\u2019 and \u2018very high.\u2019 The difference between \u2018low\u2019 and \u2018median\u2019 may not be the same as that between \u2018high\u2019 and \u2018very high.\u2019 DLC attempts to properly define the distance between these attribute values for better clustering. It is worth pointing out that DLC requires data instances with ordinal attribute values, which is a very different scenario from the assumption of the proposed UOL. \n\nWe have discussed the relation of the proposed UOL with DLC in the revision. Please see the last paragraph on page 2.  \n\n> **Relation with DRC-ORID (Lee and Kim, ICLR 2021)**\n\nDRC-ORID is an unsupervised clustering algorithm to group instances according to the properties unrelated to order (e.g. ethnicity and gender). To this end, Lee and Kim assumed that all ordering relationships between instances --- which are what the proposed UOL aims to discover --- are known. For example, DRC-ORID aims to group facial images into three categories of \u2018African American,\u2019 \u2018Caucasian,\u2019 and \u2018Asian,\u2019 which are unrelated to ages. In contrast, UOL aims to group instances according to their ages. Therefore, the objective of DRC-ORID is orthogonal to ours. This has been clarified. Please see 3rd paragraph on page 3. \n\n> **Deviation from the chain**\n\nPlease note that the deviation of an instance $x$ from consecutive centroids in Eq. (1) is first proposed in this paper. It is not borrowed from OL (Lim et al., ICLR 2020). The unsupervised clustering for the $k$-chain hypothesis in OL assigns an instance $x$ to clusters (chains) based on affinity scores. However, the deviation in Eq. (1) and the affinity scores in OL are not related at all. \n\nMoreover, as in DRC-ORID, the objective of clustering in OL is to group instances into clusters according to order-unrelated properties (e.g. gender in a facial age dataset). In contrast, UOL aims to cluster instances according to order-related properties (e.g. age in a facial age dataset). We have clarified this difference. Please see 3rd paragraph on page 3. \n\n> **Comparison with traditional algorithms**\n\nAs mentioned in the above responses, there is no conventional algorithm for ordered clustering. Therefore, we compare our results with the clustering algorithms for nominal data. However, to make the comparison as fair as possible, we permute the clusters of those algorithms via the Hungarian method so that the order of the clusters matches the ground truth as well as possible. \n\n---\n\nIf you have any additional concerns, please let us know. We will address them faithfully. We do appreciate your constructive comments again."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4789/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699703325979,
                "cdate": 1699703325979,
                "tmdate": 1699894425478,
                "mdate": 1699894425478,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "igyOlkdhZ1",
            "forum": "1CK45cqkEh",
            "replyto": "1CK45cqkEh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4789/Reviewer_T1Ca"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4789/Reviewer_T1Ca"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new algorithm, called unsupervised order learning (UOL), for clustering ordered data. It aims to discover hidden ranks (or ordered classes) of objects with no supervision."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The author proposes the first deep clustering algorithm for ordered data.\n\n2. The authors have introduced the ordered k-means algorithm, which extends the conventional k-means approach.\n\n3. This enhanced method effectively groups object instances and arranges the resulting clusters in a meaningful order. The authors have also provided a proof of the local optimality of the solution."
                },
                "weaknesses": {
                    "value": "See questions"
                },
                "questions": {
                    "value": "1. As a clustering method, it is inappropriate and unfair to compare only two types of metrics regarding the order of the data, SRCC and MAE. Some basic clustering metrics, such as ACC and NMI, lack comparison. Also this explains why other comparison algorithms achieve poorer performance.\n\n2. We question the value of unsupervised order clustering. The important value of clustering as a classical unsupervised method is that it does not require a tedious data preprocessing process such as labeling data in advance. In contrast, the order clustering proposed by the authors has high requirements for the dataset itself (sequentially), and such requirements are usually obtained by tedious manual sorting, which contradicts the advantages of clustering itself. Can the authors provide a real dataset or scenario where sequential order exists and clustering is required? Note that this is different from the manually ordered dataset used by the authors in the experimental section.\n\n3. Why did you select only two data sets for your different ablation experiments? Did the authors artificially select the datasets to present the ablation experiments? Meanwhile, the parameter \\gamma lacks ablation experiments with relevant parameter descriptions. More experimental results are expected"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4789/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4789/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4789/Reviewer_T1Ca"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4789/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698724554327,
            "cdate": 1698724554327,
            "tmdate": 1700791778627,
            "mdate": 1700791778627,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ixDJV1vpxL",
                "forum": "1CK45cqkEh",
                "replyto": "igyOlkdhZ1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4789/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4789/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors"
                    },
                    "comment": {
                        "value": "We do appreciate your constructive comments. We have addressed them faithfully in the revised paper, and we have marked the revised parts in blue. Please find our responses below.\n\n---\n\n> **Accuracy & NMI**\n\nWe compared the accuracy and NMI scores on the MORPH II and RetinaMNIST datasets. Please see Table 11 and its description on page 19. \n\nAs compared to ordinary classification datasets, it is more difficult to group instances according to their classes in these ranking (ordinal classification) datasets. This is because adjacent classes are not clearly distinguished. For example, 16-year-olds and 20-year-olds may have similar appearances. Therefore, the overall scores are relatively low. However, note that the proposed UOL performs the best in all tests.\n\n> **The value of ordered clustering**\n\nPlease note that the proposed UOL does not require any additional data preprocessing, labeling, or manual sorting of data. In other words, it uses training instances only, as conventional deep clustering algorithms do. Also, UOL uses pseudo labels for its training, but these labels are estimated via the ordered $k$-means automatically. Using pseudo labels for network training is a common practice in deep clustering.\n\nThe primary goal of UOL is to group instances according to their classes, as in ordinary clustering. However, as shown in the experiments on datasets with underlying orders, UOL provides better clustering results than conventional algorithms. Hence, as described in the 4th paragraph in Section 1 on page 1, UOL can reduce the annotation burden, for example, for medical data by generating initial prediction results. Similarly, it can be used for other types of data for ranking tasks, such as facial age estimation and historical image classification. Furthermore, it is shown in Appendix C.4 on page 15 that UOL also yields promising results on a language dataset and an audio dataset, as well as image datasets. \n\n> **Parameter $\\gamma$**\n\nWe compared the performances according to $\\gamma$ in Table 10. As you suggested, we have discussed how to select $\\gamma$ in more detail. Please see Table 10 and its description on page 17. \n\n> **Ablation study**\n\nThank you for your suggestion. Below are additional ablation results on the RetinaMNIST dataset. Similar to MORPH II and DR, RetinaMNIST provides similar ablation results: both ablated methods I and II degrade the performances in comparison with UOL (III). We have added these results in the revised paper. Please see Table 5 on page 9.\n\n| Method | $\\ell_{\\text{SL}}$ | $\\ell_{\\text{D}}$ | SRCC   | MAE   |\n|--------|--------------------|-------------------|--------|-------|\n| I      | v                  |                   | 0.533  | 0.994 |\n| II     |                    | v                 | 0.527 | 0.994 |\n| III    | v                  | v                 | 0.567  | 0.953 |\n\n---\n\nIf you have any additional concerns, please let us know. We will address them faithfully. Thank you again for your constructive comments."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4789/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699698949130,
                "cdate": 1699698949130,
                "tmdate": 1699894399896,
                "mdate": 1699894399896,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CyRdZwcJ1N",
                "forum": "1CK45cqkEh",
                "replyto": "ixDJV1vpxL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4789/Reviewer_T1Ca"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4789/Reviewer_T1Ca"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your response"
                    },
                    "comment": {
                        "value": "Thanks for your response! I'd like to keep my positive score and increase the confidence to 5."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4789/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700731463252,
                "cdate": 1700731463252,
                "tmdate": 1700731463252,
                "mdate": 1700731463252,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qMsWvKQC0m",
            "forum": "1CK45cqkEh",
            "replyto": "1CK45cqkEh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4789/Reviewer_kD3Z"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4789/Reviewer_kD3Z"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents an unsupervised algorithm for clustering ordered data. Specifically, it proposes a so-called ordered k-means algorithm, in which the rules to update the centroids and to find the assignments are modified by adding some reference terms with respect to the previous cluster and the next cluster. Experiments on benchmark datasets are conducted, showing some improvements over the listed baseline algorithms."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ It sounds interesting to modify the ordinary $k$-means algorithm to handle ordered data clustering. \n+ Experimental results on benchmark datasets show promising improvements."
                },
                "weaknesses": {
                    "value": "- The difference from the ordinary $k$-means algorithm is the way to update the mean and the way to assign clustering index, both of the two stages are computed by taking a tradeoff between the current clusters and the socalled previous cluster and the next cluster. However, it is not always meaningful to define the previous cluster and the next cluster, if the dimension of the embedding space  (which is also the dimension of the centriods of the clusters) is larger than 2. \n\n- In Eq. (4), the formula to update the centroids contains a parameter $\\alpha$.  From the results in Table 9, the performance is sensitive the parameter $\\alpha$. Without the proper value for parameter $\\alpha$, the promising performance cannot be obtained."
                },
                "questions": {
                    "value": "- It seems not always meaningful to define the previous cluster and the next cluster, provided that the dimension of the embedding space (which is also the dimension of the centriods of the clusters) is larger than 2. \n\n- In Eq. (4), the formula to update the centroids contains a parameter $\\alpha$. As can be read from Table 9, the performance of the clustering is very sensitive the value of the parameter $\\alpha$. The promising performance cannot be obtained without using the proper value of $\\alpha$. Is there any principled rule to set it? Moreover, does the proper value of $\\alpha$ vary from dataset to dataset?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4789/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698924633957,
            "cdate": 1698924633957,
            "tmdate": 1699636461209,
            "mdate": 1699636461209,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "B12MdtDe7B",
                "forum": "1CK45cqkEh",
                "replyto": "qMsWvKQC0m",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4789/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4789/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors"
                    },
                    "comment": {
                        "value": "We do appreciate your constructive comments. We have addressed them faithfully in the revised paper. We have highlighted the revised parts in blue. Please find our responses below.\n\n---\n\n> **Previous and next clusters**\n\nWe agree that it is hard to define an order between points in a high-dimensional space in general. However, we employ the straight line loss in Eq. (9), which encourages instances to be located near a 1D manifold in the embedding space. Therefore, we can arrange the clusters according to their order along the 1D manifold in the high-dimensional space. This has been clarified in the revision. Please see the last paragraph on page 5.\n\n> **Sensitivity to $\\alpha$**\n\nPlease note that we fix $\\alpha=0.2$ for all datasets. Even though the performances are affected by $\\alpha$, they are not sensitive when $\\alpha$ is around 0.2. Moreover, by comparing Table 9 with Tables 1 and 3, we can see that UOL yields better or comparable results than the conventional algorithms at $\\alpha = 0.1$ and $\\alpha = 0.3$ as well, despite 50% differences from the default $\\alpha=0.2$. We have revised the paper to clarify this point. Please see Appendix C.6 on page 17. \n\nAlso, we will compare the performances on various datasets by varying $\\alpha$ more finely in 0.01 units, instead of 0.1 units. \n\n---\n\nIf you have any additional concerns, please let us know. We will address them faithfully. Thank you again for your constructive comments."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4789/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699701038652,
                "cdate": 1699701038652,
                "tmdate": 1699894370279,
                "mdate": 1699894370279,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bYxtGwxaQF",
                "forum": "1CK45cqkEh",
                "replyto": "B12MdtDe7B",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4789/Reviewer_kD3Z"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4789/Reviewer_kD3Z"
                ],
                "content": {
                    "comment": {
                        "value": "The reviewer has read the clarification in the rebuttal but did not find the reason to change the pre-rating."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4789/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700656367575,
                "cdate": 1700656367575,
                "tmdate": 1700656367575,
                "mdate": 1700656367575,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "XCxTZdAKAp",
            "forum": "1CK45cqkEh",
            "replyto": "1CK45cqkEh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4789/Reviewer_cgay"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4789/Reviewer_cgay"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces an unsupervised method to perform clustering when there exists a total order between clusters. This total order can for instance define the age of people in images, and people who are about the same age tend to be in the same cluster or neighbor clusters. The proposed method is similar to soft clustering in the sense that it assigns samples to different clusters (here, at most 3 clusters) and updates the centroids accordingly. However, it also considers some total order on the centroids."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is well-written and the exposition of the method is clear. The difference with standard clustering algorithms that do not consider orders between clusters, and also with other ranking methods that use supervision is well defined. Assuming that there exists an order between the cluster in the dataset, the motivation for using the proposed method is clear.\nAs motivated in the paper, the method can be used as a pretraining stage for downstream tasks including ordinal regression, or it can facilitate an initial understanding of data characteristics. However, only the latter part is evaluated in the paper."
                },
                "weaknesses": {
                    "value": "One main limitation of the method is that it assumes that there exists a total order between the categories/clusters, which is not always the case. The idea of the paper is similar to relative attributes [A] although it considers the unsupervised case. Even with relative attributes, it may be difficult to define a total order between categories so an equivalence between pairs of categories is sometimes defined. Partially ordered sets are in general easier to define than total orders. \n\nMoreover, there might exist different ways to define orders between categories. For instance, in ref [A], the orders between face categories might define age, chubbiness, roundness, color, big lips etc... Fortunately, in Fig 1 (c) of the submission, the face images are ordered by age, but another criterion might have been extracted by the method since it is unsupervised, and the reported scores would not have been as good. \n\n[A] Devi Parikh & Kristen Grauman, Relative Attributes, ICCV 2011"
                },
                "questions": {
                    "value": "How important is initialization? Assuming that there exist different possible orders between categories, would one initialization reflect one order (for instance age) and another reflect something else (for instance color)? And in this case, how would the method be useful for real-world applications since there is no way to control the extracted clustering order? In particular, if we consider network pre-training, one initialization would improve performance only if the extracted order aligns with the target order."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4789/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698996840853,
            "cdate": 1698996840853,
            "tmdate": 1699636461139,
            "mdate": 1699636461139,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HfccutZgpH",
                "forum": "1CK45cqkEh",
                "replyto": "XCxTZdAKAp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4789/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4789/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors"
                    },
                    "comment": {
                        "value": "Thank you for your positive review and insightful suggestions. We have revised the paper to address your comments faithfully. We have highlighted the revised parts in blue. Please find our responses below.\n\n---\n\n> **Assumption of total order**\n\nWe agree with you. Please note that UOL is the first attempt to cluster ordered data. Hence, we focus on developing a simple but reasonable algorithm for this task, instead of considering all possible cases. It is a future research issue to extend the proposed algorithm for scenarios where there is no total order. We have clarified this point in the revised paper. Please see 1st paragraph in Section 3 on page 3 and the last paragraph on page 20.\n\n> **Different orders**\n\nWe also agree that different orders based on different criteria can be discovered. However, this is a natural property in unsupervised clustering. As long as the discovered order of clusters is meaningful and consistent, we believe that it is a good clustering result, which can facilitate an understanding of data characteristics. This has been clarified in the revision. Please see the second last paragraph on page 8.   \n\nSince UOL is an unsupervised learning algorithm, it is likely (and also desirable)  to learn the most dominant and obvious order in a dataset. Thus, in our experiments on facial age datasets, the clusters are divided mainly according to ages, which are the most prominent characteristics of those datasets. Similarly, in our experiments on the FER+ dataset in Figure 5 on page 7, UOL sorts the images according to the level of \u2018making a face,\u2019 because it is the dominant and consistent ordering criterion for describing the three different emotions.\n\n> **Initialization**\n\nTable 13 on page 19 lists the SRCC results of five random initializations. In the experiments, UOL yields roughly the same order regardless of the cluster initialization. This is because UOL tends to learn the most obvious order in a dataset, as mentioned above. \n\n---\n\nIf you have additional comments, please let us know. Thank you again for your positive comments."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4789/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699697850602,
                "cdate": 1699697850602,
                "tmdate": 1699894314589,
                "mdate": 1699894314589,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uBe4UI4yCF",
                "forum": "1CK45cqkEh",
                "replyto": "HfccutZgpH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4789/Reviewer_cgay"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4789/Reviewer_cgay"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "Thank you for the addition of different initializations. Why did you include only the average performance and not the standard deviation in Table 13?"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4789/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700582823670,
                "cdate": 1700582823670,
                "tmdate": 1700582823670,
                "mdate": 1700582823670,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]