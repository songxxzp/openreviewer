[
    {
        "title": "Compressed Online Sinkhorn"
    },
    {
        "review": {
            "id": "wVh30iGJmT",
            "forum": "vA5Rs9mu97",
            "replyto": "vA5Rs9mu97",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2060/Reviewer_XcQQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2060/Reviewer_XcQQ"
            ],
            "content": {
                "summary": {
                    "value": "Sinkhorn is a popular algorithm for calculating entropic-regularised OT distances. However, before applying the Sinkhorn algorithm to the discrete probability measures, one should first draw a large stream of data from the probability distributions. This situation has been improved by online Sinkhorn method, which continuously samples data from two probability distributions in batches and iteratively computes the results. This paper revisits the recently introduced online Sinkhorn algorithm of $Mensch\\ \\& \\ Peyre \\ (2020)$ and rises two improvements. \n\n1. This work presents a new convergence rate for the the online Sinkhorn algorithm, which is faster than the previous rate under certain parameter choices.\n\n2. Under two new assumptions, the authors propose the compressed online Sinkhorn algorithm which combines measure compression techniques with the online Sinkhorn algorithm. Under certain parameter values, the new algorithm theoretically has a faster speed and smaller error than the previous online Sinkhorn algorithm.\n\nThe authors also provide experimental results to show the numerical gains of these two improvements."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The authors provide clear theoretical analysis for the issues present in  Mensch and Peyre  (2020)  and their new method.\n2. The presentation of the results are clear."
                },
                "weaknesses": {
                    "value": "1. The authors do not discuss the performance of the algorithm in high-dimensional situations. Real-world data often has a high dimensionality (such as datasets of images and amino acid sequences), but the authors do not discuss cases where $d > 5$. In \\textbf{section A.5.2}, for data of dimension $d$, the compression error is $O(\\frac{|\\log m|^{d}}{m})$, which may too large in high-dimensional situations (i.e., assumption 4 with a large coefficient for $O(m_t^{-\\zeta})$). In fact, in the experimental part,  Figure 2(c), when d=5, the online Sinkhorn algorithm already has lower error than the new compressed online Sinkhorn algorithm.\n\n2. The Algorithm 2 proposed by the author improves the speed compared to the original online Sinkhorn algorithm by using measure compression technique to compress $u_t$ and $v_t$ from $n$ atoms to $m$. However, there is a trade-off between accuracy and speed. According to assumption 4, the smaller the value of $m$, the faster the algorithm but the larger the error. The article seems to lack a detailed discussion on this matter, such as how to choose an appropriate batch size $m_t$ when solving actual OT problems.\n\n3. The experimental sections lack the application of the algorithm on real-world data and more complex distributions."
                },
                "questions": {
                    "value": "The new convergence rate of the proposed online Sinkhorn algorithm in this paper is better than the original rate when $a > -b$. Additionally, Algorithm 2 proposed in this paper is theoretically more efficient than Algorithm 1 when $\\zeta > \\frac{3(a-b)}{4a+1}$. However, the paper lacks an explanation on how to choose specific values for parameters $a$, $b$, and $\\zeta$, which makes the experiments in this paper somewhat less persuasive. Please explain why specific parameter values are chosen in the experiments."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2060/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2060/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2060/Reviewer_XcQQ"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2060/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698734133767,
            "cdate": 1698734133767,
            "tmdate": 1699636137974,
            "mdate": 1699636137974,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xqOk2No9TG",
                "forum": "vA5Rs9mu97",
                "replyto": "wVh30iGJmT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2060/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2060/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate your thorough review of our paper, and your feedback has been very valuable to us. We've  addressed each of your points:\n\n> The authors do not discuss the performance of the algorithm in high-dimensional situations.\n\nAs mentioned above, we have clarified the issues with dimension when applying  QMC-based Fourier method and explained the dimension dependence of the error bound. Asymptotically, the compressed online Sinkhorn can be more efficient. It is more difficult  however to get into the asymptotic regime with the dimension $d$ is high.\n\n> However, there is a trade-off between accuracy and speed. According to assumption 4, the smaller the value of $m$, the faster the algorithm but the larger the error. The article seems to lack a detailed discussion on this matter, such as how to choose an appropriate batch size $m_t$ when solving actual OT problems.\n\nWe made some changes to Assumption 4, please check the new version. The choice of $m_t$ depends on the compression algorithm, such that Assumption 4 holds. The purpose of this assumption is that the compression error does not exceed the online Sinkhorn error in Algorithm 1, and we focus on the overall efficiency of the compressed algorithm. This allows for an increased error if there is sufficient reduction in computational effort to allow more iterations. This is now shown more effectively in the numerical experiments, where we ensure the error in the objective for the different algorithms match in the Figure 2.\n\n\n> The experimental sections lack the application of the algorithm on real-world data and more complex distributions.\n\nThanks for this valid point. This work is a first attempt at a compression method and the improvements are mainly in the asymptotic regime and lower dimensional setting. As future work, we plan on refining this by investigating adaptive choices of the parameters to enhance the fast transient behaviour in the error bound, making the algorithm more competitive for real-world data."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2060/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700644249839,
                "cdate": 1700644249839,
                "tmdate": 1700644249839,
                "mdate": 1700644249839,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DJpKnm1Qcz",
                "forum": "vA5Rs9mu97",
                "replyto": "xqOk2No9TG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2060/Reviewer_XcQQ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2060/Reviewer_XcQQ"
                ],
                "content": {
                    "title": {
                        "value": "Thanks"
                    },
                    "comment": {
                        "value": "Thanks for your response, and I will consider it in the next discussion stage."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2060/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700700875718,
                "cdate": 1700700875718,
                "tmdate": 1700700875718,
                "mdate": 1700700875718,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KDPKPFnQcw",
            "forum": "vA5Rs9mu97",
            "replyto": "vA5Rs9mu97",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2060/Reviewer_q5md"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2060/Reviewer_q5md"
            ],
            "content": {
                "summary": {
                    "value": "This paper adds a compression step on top of the online sinkhorn algorithm of Mencsh and Peyr\u00e9 in regimes in which some measure compression can be perform. They show two such compression schemes: gaussian quadrature and to Fourier moments compression. They analyze the method theoretically and provide numerical evidence of its lower runtime while the observed error empirically is comparable to the one of the uncompressed method."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The authors provide two settings for which their compression can be implemented: Gaussian quadrature and Fourier moments compression.\n\nThey fix a minor error in a proof of a previous paper on online Sinkhorn.\n\nNumerical evidence is presented.\n\nThe paper is well written."
                },
                "weaknesses": {
                    "value": "The experiments are done in settings of very low dimensionality. For the one of greater dimension (d=5), the uncompressed method starts to look quite better."
                },
                "questions": {
                    "value": "I wonder if what I mentioned above regarding the uncompressed method working better and better with increasing dimension is a general trend."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2060/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698832259772,
            "cdate": 1698832259772,
            "tmdate": 1699636137905,
            "mdate": 1699636137905,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "N9ISIGglBC",
                "forum": "vA5Rs9mu97",
                "replyto": "KDPKPFnQcw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2060/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2060/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your thorough review of our paper. Your feedback has been invaluable to us. We've  addressed your points:\n\n> The experiments are done in settings of very low dimensionality. For the one of greater dimension (d=5), the uncompressed method starts to look quite better. I wonder if what I mentioned above regarding the uncompressed method working better and better with increasing dimension is a general trend.\n\nWe have clarified the issues with dimension when applying  QMC method. Asymptotically, the compressed online Sinkhorn can be more efficient. It is difficult however to get into the asymptotic regime due to the small contraction rate ($\\kappa\\approx 1$) and available compression methods."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2060/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700644044156,
                "cdate": 1700644044156,
                "tmdate": 1700644044156,
                "mdate": 1700644044156,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "fmGEbMUiyb",
            "forum": "vA5Rs9mu97",
            "replyto": "vA5Rs9mu97",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2060/Reviewer_5NvN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2060/Reviewer_5NvN"
            ],
            "content": {
                "summary": {
                    "value": "The Sinkhorn algorithm for entropy-regularized optimal transport is well-known, but very computationally complex. The present paper considers two online variants of this method. The first one comes from a Mensch and Peyr\u00e9: the bound here is sometimes worse, sometimes better, but the present paper claims (convincingly) through theory and simulations that the previous bound was wrong. The second variant is a compressed version of online Sinkhorn where the random samples are compressed eg. via quadrature techniques."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The idea of compressing measures seems very interesting from an algorithmic point of view. The analysis is quite simple. (See below, however.) The previous bound for the first algorithm does seem to have been incorrect."
                },
                "weaknesses": {
                    "value": "The bounds depend on a constant $\\kappa$ that can be quite small. The proofs are fairly straightforward. \n\nProof writing leaves a bit to be desired and I had trouble following some arguments. \n\n1) The constant $\\kappa$ and the fact that it is at most $1$ are explained for the first time\n2) I believe the Lipschitz constant in Lemma 4 (with the notation employed) should be $L$, or maybe the formula for $T_\\beta$ is missing a $1/\\epsilon$ factor in the exponent. \n3) The last equality in the first math display in page 13 should probably be an upper bound."
                },
                "questions": {
                    "value": "See the above points where I had trouble."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2060/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698897108112,
            "cdate": 1698897108112,
            "tmdate": 1699636137834,
            "mdate": 1699636137834,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "95tFtltBnk",
                "forum": "vA5Rs9mu97",
                "replyto": "fmGEbMUiyb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2060/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2060/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your valuable feedback on our paper. Your insights have been very helpful in refining our work. We have made the following adjustments:\n\n> The constant $\\kappa$ and the fact that it is at most $1$ are explained for the first time\n\nA definition $\\kappa = 1-\\exp(-L\\text{diam}\\mathcal{X})$ has been added to the sketch proof of Theorem 1.\n\n> I believe the Lipschitz constant in Lemma 4 (with the notation employed) should be $L$, or maybe the formula for $T_{\\beta}$ is missing a $1/\\epsilon$ factor in the exponent.\n\nThis is true, we have missed out an $\\epsilon$ in $T_{\\mu}$. Please see the updated definition of $T_{\\mu}$ before Lemma 4, thanks for pointing it out.\n\n\n> The last equality in the first math display in page 13 should probably be an upper bound.\n\nSorry about the confusion, it is defined in Lemma 7 that $M(x)=\\int_y\\exp((f^*(x)+g(y)-C(x,y))/\\epsilon)\\mathrm{d}\\beta(y)$ and this equality is a simplification of the notation."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2060/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700643952141,
                "cdate": 1700643952141,
                "tmdate": 1700643952141,
                "mdate": 1700643952141,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "JcaWskHMt0",
            "forum": "vA5Rs9mu97",
            "replyto": "vA5Rs9mu97",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2060/Reviewer_3eZq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2060/Reviewer_3eZq"
            ],
            "content": {
                "summary": {
                    "value": "This paper deals with computing entropic regularized optimal transport distances between continuous distribution. Traditionally, one draws samples from the continuous distribution and then computes these distances between discrete distribution by constructing an $n^2$ sized cost matrix. However, the focus has shifted on finding the distances between continuous distributions directly. The challenge in doing so is that how one can compactly represent the continuous dual functions in a discrete manner. Mensch and Peyre introduced the online Sinkhorn where they primarily showed how to execute the Sinkhorn algorithm by representing the continuous duals compactly and showed how the dual functions converge to the optimal ones. \n\nThere are two main contributions of this paper. First, the authors provide an updated convergence rate for the online Sinkhorn algorithm (after correcting an existing inaccuracy in the work of Mensch and Peyre). They also conduct experiments to suggest that their bound may be tight for certain distributions.\n\nSecond, the sample size grows polynomially as the algorithm progresses. To make it more space efficient, they provide a compression mechanism to represent the distributions leading to certain gains in experiments."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The problem of estimating dual potentials for OT on continous distribution is a difficult one. For this reason, despite being incremental in nature, I think the result may be important."
                },
                "weaknesses": {
                    "value": "On the negative side, I had a hard time appreciating the five different assumptions made in the paper. I couldn\u2019t quite tell whether they were necessary or they were made as a matter of convenience. Also, the paper is written in a way that makes it only accessible to people who are familiar with previous work (and not for folks who may have a good understanding of the optimal transport problem but lack familiarity with online Sinkhorn). I\u2019m still not able to fully appreciate the result and understand within the landscape of existing algorithms (including time, space and sample complexities etc) for approximating continuous optimal transport. A discussion on this would be good. \n\nOverall, I think this seems like a good contribution, but the writing does not let me full appreciate the result."
                },
                "questions": {
                    "value": "NA"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2060/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698941748142,
            "cdate": 1698941748142,
            "tmdate": 1699636137766,
            "mdate": 1699636137766,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "o9M6UzwJjf",
                "forum": "vA5Rs9mu97",
                "replyto": "JcaWskHMt0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2060/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2060/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your valuable review of our paper. We've addressed each of your points:\n\n> On the negative side, I had a hard time appreciating the five different assumptions made in the paper. I couldn\u2019t quite tell whether they were necessary or they were made as a matter of convenience.\n\nAssumption 1 on the cost regularity is needed for the OT problem to have a solution.\nThe stepsize choices in Assumptions 2 are fairly standard for SGD.\nAssumption 3 provides criteria for the batch size in relation to the accuracy of the Monte Carlo method. We have added further commentary on the assumptions in the text.\n\nThe original Assumptions 4 and 5 are made together to ensure that the additional error is limited to $O(t^{b-a})$ and are consistent with the Online Sinkhorn error; please see Section 3.3 for the change we made to these assumptions.\n\n> Also, the paper is written in a way that makes it only accessible to people who are familiar with previous work (and not for folks who may have a good understanding of the optimal transport problem but lack familiarity with online Sinkhorn). I\u2019m still not able to fully appreciate the result and understand within the landscape of existing algorithms (including time, space and sample complexities etc) for approximating continuous optimal transport. A discussion on this would be good.\n\nWe have added content in Section 3.1 and discussed the motivation for online Sinkhorn with compression."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2060/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700643538087,
                "cdate": 1700643538087,
                "tmdate": 1700643538087,
                "mdate": 1700643538087,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]