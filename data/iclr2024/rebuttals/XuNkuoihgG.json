[
    {
        "title": "Orthogonal Sequential Fusion in Multimodal Learning"
    },
    {
        "review": {
            "id": "lNM0Sg85Wl",
            "forum": "XuNkuoihgG",
            "replyto": "XuNkuoihgG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7815/Reviewer_8gNn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7815/Reviewer_8gNn"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a multimodal fusion paradigm called Orthogonal Sequential Fusion (OSF) to intergate in a sequential and selective manner.   The authors claim that OSF can integrate more complementary information from the multimodal inputs leading to more balanced representations. Experimental results on commonly used benchmark support their claims."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Multimodal fusion is an interesting research topic. It is important to ensure integrating complementary information from multiple sources.\n- This paper is well written, the proposed OSF algorithm is well motivated and clearly explained.\n- Model-agnostic fusion techniques can be easily deployed in various multimodal learning methods, and thus I think the proposed methods can be seamlessly deployed in many multimodal applications."
                },
                "weaknesses": {
                    "value": "- It seems that the proposed OSF determine the order of fusing the modalities by ranking the unimodal performances. This ranking-based approach may result in additionally computational cost in my view. On the other hand, sometimes it is impossible to use the same model for unimodal training and further evaluate the unimodal performance. Thus using unimodal performance as a proxy of distinct contributions to the task at hand may not be well motivated.\n- The proposed method is intuitively motivated. Although the authors present the underlying motivations in detail. More theoretical analysis is appreciated.\n- The empirical results are not convinced enough for me. For example, in Table. 2, the proposed method OSF are only compared to some simple fusion methods. It will be more convincing for me if more strong baseline such as self-attention or recent [1] can be involved in the future.\n\n[1] Ma, Huan, et al. \"Trustworthy multimodal regression with mixture of normal-inverse gamma distributions.\" NIPS 2021"
                },
                "questions": {
                    "value": "Please address the issues raised in the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7815/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698066017016,
            "cdate": 1698066017016,
            "tmdate": 1699636956621,
            "mdate": 1699636956621,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "iFDeBxIP3L",
            "forum": "XuNkuoihgG",
            "replyto": "XuNkuoihgG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7815/Reviewer_SAr6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7815/Reviewer_SAr6"
            ],
            "content": {
                "summary": {
                    "value": "This paper deals with mutimodal fusion in the context of neural networks. The proposed method is based on a sequential fusion of modalities. Modalities are processed iteratively in a predefined order. At each fusion layer, a specific loss metric is proposed that looks for having orthogonality between the two input embeddings. \n\nExperimental results are reported on 2 datasets CMU-MOSI and TCGA-KIRP and compared to baseline simple fusion techniques."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "No real novelty in the proposed work"
                },
                "weaknesses": {
                    "value": "This paper lack of reference to more advanced fusion technique. For example, what about [1, 2] works that present some alternate direction of analysis to deal with relative importance of modalities.\n\nSome elements of the paper would need better clarification to have a better understanding. For example: how do embeddings of modalities are aligned to the same dimension D? What is the 'embedding' operation mentionned in Algorithm 1 performed after the CONCAT operation ?\n\nIn section 4.3 it is mentioned that input models are pre-trained models. So if they are not modified what is the effective impact of orthogonality criterion? For first level, if input modalities does not change then the orthogonal loss term will not change. For the other layers, we could expect 'embedding operation' (e.g. considering that it is a linear layer) of previous layer to guarantee having orthogonality with the second input layer while keeping same level of information. \n\nWhen comparing to [2], what is the rationale behind using orthognality criterion rather than a more complex criterion such used in [2]?\n\nLooking at Table 1, sequential approach turns out to be less performant than Late fusion. Could you elaborate on that? If the embedding operation consist of a linear layer, then we could consider that sequential fusion is quite similar to late fusion (using a linear fusion operator). Why is it so different in table 2?\nFurthermore when considering confidence intervals in tables 2 and 3, there is no significant difference between results. \n\nAblation study provided is rather a discussion on previous results than additional analysis with additional experiments. \n\n[1] Li, F., Neverova, N., Wolf, C., & Taylor, G. (2016). Modout: Learning to Fuse Modalities via Stochastic Regularization. Journal of Computational Vision and Imaging Systems, 2(1).\n\n[2] Andrew, G., Arora, R., Bilmes, J., Livescu, K.: Deep canonical correlation analysis.In: International Conference on Machine Learning. (2013) 1247\u20131255"
                },
                "questions": {
                    "value": "1. What is the 'embedding' operation in Algorithm 1? (performed just after CONCAT to get a D-dimensional fused embedding)\n2. What about orthogonality criterion rather than cross correlation criterion such as in [2]?\n3. Since CMU-MOSI has only 3 modalities, what is the real impact of modality ranking?\n4. Why does the sequential fusion approach performs worse than late fusion?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7815/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698682233828,
            "cdate": 1698682233828,
            "tmdate": 1699636956517,
            "mdate": 1699636956517,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "qJVXX6jNQQ",
            "forum": "XuNkuoihgG",
            "replyto": "XuNkuoihgG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7815/Reviewer_HooP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7815/Reviewer_HooP"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new fusion paradigm called orthogonal sequential fusion. It sequentially merges inputs and permits selective weighting of modalities. It offers a flexible way to weight and prioritize individual modalities based on their relevance, allowing for dynamic weighting or prioritization of individual modalities. Moreover, it explores the potential of orthogonal representations in fusion and is used to improve fusion performance."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. It proposes a new sequential fusion paradigm, which is significant different from existing traditional fusion paradigms.\n2. It designs a method to determine the optimal order for sequential fusion. \n3. The article is easy to understand and the results show superiority to the traditional early fusion, late fusion, max/mean/sum fusion and sequential fusion."
                },
                "weaknesses": {
                    "value": "1. The related work lacks a discussion on multimodal information fusion works in recent years. It lacks the analysis of the state-of-art methods.\n2. This paper proposes a way for modalities ordering. It starts from the least performing modality and moves towards the most performing one. However, the soundness of this approach does not have good theoretical support. The reason that it can provide valuable insights into the relationships and interactions between different modalities is unclear.\n3. Orthogonal orthogonality is used in the fusion of two modalities and is not closely related to the proposed sequential fusion paradigm.\n4. It lacks the experiment to validate the superiority of the modalities ordering way to other ordering results."
                },
                "questions": {
                    "value": "1. When fusing N modalities, the proposed method needs N-1 fusion layers. Compared to Early fusion, Mean/Max/Sum fusion, Late fusion, will such a N-1 fusion layer increase computational complexity and runtime?\n2. The loss function promotes the orthogonal representations of features. But how the information of the two modalities is fused after determining the orthogonal representations?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7815/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7815/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7815/Reviewer_HooP"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7815/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698726585547,
            "cdate": 1698726585547,
            "tmdate": 1699636956384,
            "mdate": 1699636956384,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "eF51xFYFX8",
            "forum": "XuNkuoihgG",
            "replyto": "XuNkuoihgG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7815/Reviewer_ZKms"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7815/Reviewer_ZKms"
            ],
            "content": {
                "summary": {
                    "value": "The authors introduced OSF, a novel fusion paradigm for multimodal machine learning. This fusion approach allows features from different modalities to be fused step-by-step. The orthogonality facilitation model extracts as much complementary information as possible from the different modalities. The method performs well compared to existing fusion methods and can be incorporated into a state-of-the-art model."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The fusion paradigm proposed by the authors in this paper is straightforward in its thinking. Compared to the traditional Multimodal Learning and Traditional Fusion Techniques, the OSF proposed in this paper performs an initial ordering of modalities through the relative strengths of different modalities in the task and fuses them step by step. \n2. The author added an orthogonal term to the loss function, which allows the model to extract complementary features from different modes to the maximum extent possible.\n3. The OSF method proposed in this paper outperforms a variety of previous traditional Multimodal Learning and Traditional Fusion Techniques in terms of experimental metrics. and is able to be added to existing multimodal fusion models."
                },
                "weaknesses": {
                    "value": "1. The explanation of method theory in Chapter 3 is slightly weak. This chapter is the core work of the article, and the author should provide a more detailed explanation of this part of the work.\n2. In Section 3.2, the authors described the OSF method \u201cfuse the modalities starting from the least performing modality and moving towards the most performing one.\u201d I would like to know why the authors chose to do the ordering in this way, and how the fusion results would change if the order was reversed? \n3. In the same section, the author mentions that \" In some cases, certain modalities may be highly correlated or redundant, and the ranking may not accurately reflect their true contributions to the task. In such cases, alternative methods for determining fusion order, such as using expert knowledge, may be more suitable.\" How should the user judge whether OSF can be used for this task, and is there a clear evaluation metric to assist the user in this judgment?"
                },
                "questions": {
                    "value": "Please refer to weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7815/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7815/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7815/Reviewer_ZKms"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7815/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698859770985,
            "cdate": 1698859770985,
            "tmdate": 1699636956288,
            "mdate": 1699636956288,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]