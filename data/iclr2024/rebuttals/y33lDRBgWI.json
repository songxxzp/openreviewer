[
    {
        "title": "AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of Diffusion Probabilistic Models"
    },
    {
        "review": {
            "id": "2GVGf7QNJU",
            "forum": "y33lDRBgWI",
            "replyto": "y33lDRBgWI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2354/Reviewer_CqXY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2354/Reviewer_CqXY"
            ],
            "content": {
                "summary": {
                    "value": "This paper...\n- proposes AdjointDPM for differentiating through the diffusion sampling process,\n- reparametrizes PF ODE and augmented ODE to reduce numerical errors,\n- applies AdjointDPM to a wide variety of tasks, such as vocabulary expansion, security auditing, stylization, etc."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is well-written and easy to follow.\n- This paper is a nice application of adjoint sensitivity methods to diffusion models. To the best of my knowledge, such application of adjoint sensitivity methods has not been explored before.\n- The proposed method can potentially be applied to a wide variety of downstream tasks for diffusion models."
                },
                "weaknesses": {
                    "value": "I must clarify that I am not very familiar with application of diffusion models to tasks such as vocabulary expansion, security auditing, etc. Hence, I am not sure whether the authors have chosen an appropriate and comprehensive set of baselines, or have followed proper evaluation protocol. So, my current score for this paper is \"marginally above the acceptance threshold\", and I will adjust my score based on other reviews and authors' reply to my concerns.\n\n- NFE and wall-clock time for AdjointDPM and the baselines is missing, so it is difficult to gauge the efficiency of AdjointDPM.\n- A background section explaining and comparing other related backpropagation methods, such as DOODLE, FlowGrad, DEQ_DDIM in detail would help readers understand the position of AdjointDPM w.r.t. previous work. Specifically, this paper lacks a discussion of theoretical and practical advantages/disadvantages of AdjointDPM w.r.t previous work on backpropagation through diffusion sampling. For instance, the authors state DEQ-DDIM require the diffusion sampling process to have equilibrium points -- is this a significant drawback? Are there certain tasks where this equilibrium assumption do not hold, so AdjointDPM is applicable while DEQ-DDIM is not?"
                },
                "questions": {
                    "value": "See Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2354/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2354/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2354/Reviewer_CqXY"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2354/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698400484193,
            "cdate": 1698400484193,
            "tmdate": 1699636167693,
            "mdate": 1699636167693,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8pY99ND1KA",
                "forum": "y33lDRBgWI",
                "replyto": "2GVGf7QNJU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2354/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2354/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer CqXY - part I"
                    },
                    "comment": {
                        "value": "Thank you for carefully reviewing this work and asking us very insightful questions! We have tried our best to answer your questions below.\n\n > NFE and wall-clock time for AdjointDPM and the baselines are missing, so it is difficult to gauge the efficiency of AdjointDPM.\n \n**Reply:** For the analysis of NFE, please refer to the global response. The actual training time highly depends on the hardware configuration.\n\nWhen we finetune parameters of neural networks, for example, the stylization task, it takes around 18 hours to optimize in a A100 GPU. But once trained, this network can be used to generate any images with a certain style. The training time is acceptible in this case.\n\nFor guided sampling tasks (such as vocabulary expansion, security auditing, and text embedding inversion), as the key time consumption is in traversing sampling steps and doing gradient backpropagation, here we present the wall-clock time required for a single optimization step. In these tasks, we run the code in a V100 GPU. For optimization of initial noises and text embedding inversion in Stable diffusion, it takes around 30 seconds per optimization step. For optimization of initial noises in ImageNet 256x256 generation, it takes around 5.3 seconds per optimization step.\n\n> A background section explaining and comparing other related backpropagation methods, such as DOODLE, FlowGrad, DEQ_DDIM in detail would help readers understand the position of AdjointDPM w.r.t. previous work. Specifically, this paper lacks a discussion of theoretical and practical advantages/disadvantages of AdjointDPM w.r.t previous work on backpropagation through diffusion sampling. For instance, the authors state DEQ-DDIM require the diffusion sampling process to have equilibrium points -- is this a significant drawback? Are there certain tasks where this equilibrium assumption do not hold, so AdjointDPM is applicable while DEQ-DDIM is not?\n > \n**Reply:** We have presented part of comparsion with existing models, mainly including DOODL and FlowGrad in Appendix B. Here we have a brief comparison: \n\n1. **Comparison with [1] End-to-End Diffusion Latent Optimization Improves Classifier Guidance**\n    DOODL in [1] optimizes the initial diffusion noise vectors w.r.t a model-based loss on images generated from the full-chain diffusion process. In their work, they obtain the gradients of loss w.r.t noise vectors by using invertible neural networks (INNs). There are two main differences between [1] and our work:\n  - While DOODL optimizes the initial diffusion noise vectors, our work optimizes related variables, including network parameters, initial noises and textual embeddings w.r.t a model-based loss on images generated from the full-chain diffusion process. Thus, we consider the broader cases of DOODL. \n  - In the calculation of gradients w.r.t initial noises, [1] uses the invertibility of EDICT, i.e., $x_0$ and $x_T$ are invertible. This method does not apply to the calculation of gradients w.r.t. the network parameters and textual embeddings as they share across the full-chain diffusion process. Finally, with regard to the memory consumption when calculating gradients with respect to the initial noise, our experimental results are as follows: We utilized the stable diffusion v1.4 checkpoint to run both the AdjointDPM and DOODL models on a V100 GPU (32GB memory). For the AdjointDPM method, backpropagating the gradients with respect to the initial noise required 19.63GB of memory. In comparison, the DOODL method consumed 23.5GB for the same operation.  Thus, our method is more efficient in terms of memory consumption. In terms of time consumption, DOODL relies on the invertibility of EDICT, resulting in identical computation steps for both the backward gradient calculation and the forward sampling process. However, our AdjointDPM methods have the flexibility to design adaptive steps, allowing for faster backward gradient calculation."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2354/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700533393001,
                "cdate": 1700533393001,
                "tmdate": 1700533393001,
                "mdate": 1700533393001,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FPwL62VSu8",
                "forum": "y33lDRBgWI",
                "replyto": "CBIVsew8jx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2354/Reviewer_CqXY"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2354/Reviewer_CqXY"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the detailed feedback! After weighing the pros (practicality of AdjointDPM compared to [1,2,3], as discussed in the authors' feedback) and cons (lack of theoretical or methodological novelty, as this method is a straightforward application of the adjoint sensitivity method), I'm satisfied with my current score, which is already positive."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2354/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700551565336,
                "cdate": 1700551565336,
                "tmdate": 1700551565336,
                "mdate": 1700551565336,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ep4mPDIu6T",
            "forum": "y33lDRBgWI",
            "replyto": "y33lDRBgWI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2354/Reviewer_5NNi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2354/Reviewer_5NNi"
            ],
            "content": {
                "summary": {
                    "value": "This work leverages the adjoint methods for optimizing the parameters and/or samples of diffusion ODEs under a given differentiable scalar-valued function. To efficiently solve the adjoint ODE, this work also leverages the expoenential integrators and introduce a change-of-variable formula to obtain a simpler ODE. Experiments show that the proposed method can be used for classifier-based sampling, adversarial sampling and stylization with a single reference."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed method is easy to understand and the writing is clean and easy to follow.\n- The proposed adjoint method is novel to the diffusion model community and the combination with exponential integrator is useful.\n- The studied topic is important to the field."
                },
                "weaknesses": {
                    "value": "- Major:\n\n  - The proposed method seems to be quite **inefficient** because it needs to optimize the model / sample at each specific task, while other guided sampling methods (e.g., classifier guidance or classifier-free guidance) do not. Note that the optimization procedure needs to solve the whole ODE at each training step, the training cost (i.e., total training time) seems to be quite expensive.\n\n  - The proposed method cannot guarantee the property of diffusion models, i.e., the noise-pred network corresponds to the score functions, because it directly train the neural ODE. Thus, it may be hard to leverage the other properties of diffusion models, such as classifier / classifier-free guidance, and it may be hard to further use diffusion SDEs for better sample quality. Instead, other guided sampling methods introduce another guidance model at each time step, which is based on the score functions and thus can maintain the diffusion property.\n\n- Minor:\n\n  - Equation(9) is exactly the EDM sampler so it is not a new method. It should be compared and discussed in detail.\n\n[1] Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine. Elucidating the design space of diffusion-based generative models. In Advances in Neural Information Processing Systems, 2022."
                },
                "questions": {
                    "value": "1. What is the training time for each experiment?\n\n2. After training, can the model be used for classifier / classifier-free guidance and diffusion SDEs?\n\n==========\n\nThanks for the detailed reply! After reading the authors' rebuttal, I raised my score to 6."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2354/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2354/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2354/Reviewer_5NNi"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2354/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698824569226,
            "cdate": 1698824569226,
            "tmdate": 1700665535177,
            "mdate": 1700665535177,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pj4N1T8iws",
                "forum": "y33lDRBgWI",
                "replyto": "ep4mPDIu6T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2354/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2354/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer 5NNi - part I"
                    },
                    "comment": {
                        "value": "Thank you for carefully reviewing this work. We have tried our best to answer your questions below.\n\n> Weakness Major 1. The proposed method seems to be quite inefficient ... the training cost (i.e., total training time) seems to be quite expensive.\n\n**Reply:**  AdjointDPM can be used for both finetuning network weights and guided sampling.\n\nRegarding fine-tuning network weights, we only need to train the model **once** for a specific task. After training, we can use any type of sampling method to generate new results. The efficiency of finetuing is not an issue. \n\nOn the other hand, in guided sampling (i.e., fine-tuning noisy samples during the sampling process and text embedding inversion), AdjointDPM is much more flexible than CG or CFG. We need **pairs** of data of image and guidance to train a classifier or CFG. In contrast, we do not need paired data in AdjointDPM since it supports any type of computable metrics defined on the generated results. Besides, it is not possible for CG or CFG to perform some tasks like security auditing or single image guided generation.\n\n> Weakness Major 2. The proposed method cannot guarantee the property of diffusion models..., which is based on the score functions and thus can maintain the diffusion property.\n\n> Question 2. After training, can the model be used for classifier / classifier-free guidance and diffusion SDEs?\n\n**Reply:** Thanks for raising this issue. \n\n**For finetuning of initial noises**, as long as we control the scale of perturbation on initial noises, the trained noises have little influence on the sampling process of diffusion models. Then for finetuning of text embedding, it also has little influence on score estimation as we just want to learn a proper text embedding for specific visual effects. Thus, CG/CFG and SDEs still apply in these two cases.\n\nIn related experiments, besides the guidance from the loss function defined on final outputs, we still can use CG/CFG and SDEs in sampling. For example, in security auditing, we use CG to generate images with prescribed classes and find an initial noise which can mislead pretrained ImageNet classifier while visually similar to the original one. Besides, after finding this initial noise and text embedding, we could still use SDEs (such as DDPM sampler) to generate better-quality images. The results are added to Appendix.\n\nHowever, **when using AdjointDPM to finetune or train the parameters of diffusion networks**, the question of whether this operation will change the property of the underlying diffusion models is still largely open. However, we surmise that finetuning a diffusion model on a small amount of data for a few steps will still preserve the applicability of CG/CFG techniques. In practice, after finetuning the parameters of the Unet only for 10 epochs in stylization, we still use the CFG to guide the sampling with given text prompts under a guidance scale of 7.5. We also test the generation in SDE solvers and it works. The results are added to Appendix.\n\nBesides, we observe, in some other works that distill diffusion models based on Neural ODEs (e.g., consistency model, rectified flow), the resultant/distilled model lacks sampling diversity. This is a commonly-encountered problem concerning finetuning of diffusion models based on deterministic ODEs. In the future, we will explore techniques for effectively finetuing diffusion models and preserving their original properties.\n\n> Weakness Minor 1. Equation(9) is exactly the EDM sampler so it is not a new method. It should be compared and discussed in detail.\n\n**Reply:** The exponential integration technique has been used in many diffusion ODE-type solvers, including EDM [1], DPM-solver [2], DEIS [3]. Here our point is not to compare the difference on the exponential integration technique in different ODE solvers. We emphasize that AdjointDPM can retain comparable image generation quality with existing models (see FID results in Table 1), and at the same time, it can support obtaining the gradients by solving a backward ODE. Exploiting semi-linear accelerates both the forward and backward ODEs as there also exists a semi-linear structure in the backward ODE.\n\n[1] Karras, T., et al. (2022). Elucidating the design space of diffusion-based generative models.\n\n[2] Lu, C., et al. (2022). Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps.\n\n[3] Zhang, Q., et al. (2022). Fast Sampling of Diffusion Models with Exponential Integrator."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2354/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700533198458,
                "cdate": 1700533198458,
                "tmdate": 1700533546043,
                "mdate": 1700533546043,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wvZ1PxrFhF",
                "forum": "y33lDRBgWI",
                "replyto": "ep4mPDIu6T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2354/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2354/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer 5NNi - part II"
                    },
                    "comment": {
                        "value": "> Question 1. What is the training time for each experiment?\n\n**Reply:** For the analysis of NFE, please refer to the global response. The actual training time highly depends on hardware configuration. When we finetune parameters of neural networks, for example, the stylization task, it takes around 18 hours to optimize in a A100 GPU. But once trained, this network can be used to generate any images with a certain style. The training time is acceptible in this case.\n\nFor guided sampling tasks (such as vocabulary expansion, security auditing, and text embedding inversion), the key time consumption is in traversing sampling steps and doing gradient backpropagation, here we present the wall-clock time required for a single optimization step. In these tasks, we run the code in a V100 GPU. For optimization of initial noises and text embedding inversion in Stable Diffusion, it takes around 30 seconds per optimization step. For optimization of initial noises in ImageNet 256x256 generation, it takes around 5.3 seconds per optimization step."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2354/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700533221537,
                "cdate": 1700533221537,
                "tmdate": 1700533556175,
                "mdate": 1700533556175,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7oJGt3jyG5",
                "forum": "y33lDRBgWI",
                "replyto": "wvZ1PxrFhF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2354/Reviewer_5NNi"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2354/Reviewer_5NNi"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the detailed discussion!"
                    },
                    "comment": {
                        "value": "I appreciate the authors' responses and I think it addressed my concerns, so I raised the score to 6."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2354/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700665654991,
                "cdate": 1700665654991,
                "tmdate": 1700665654991,
                "mdate": 1700665654991,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "1DScnbxrW8",
            "forum": "y33lDRBgWI",
            "replyto": "y33lDRBgWI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2354/Reviewer_6hcA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2354/Reviewer_6hcA"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes an interesting idea, named AdjointDPM, merging Diffusion Models and techniques from Neural ODE literature. The core offering of the paper is a way of backpropagating gradients of any loss computed using the output of a (trained) Diffusion model. Specifically the authors used the well-known Adjoint Backpropagation method from Neural ODE, which is a backprop algorithm with $\\mathcal{O}(1)$ memory w.r.t the *discretization* of the ODE solver.\n\nThe authors applied their AdjointDPM method on three tasks that either require gradients w.r.t initial state $X_T$ of the reverse process, all intermediate states $\\\\{ X_t \\\\}\\_{t=1}^T$ of the reverse process or the parameters $\\theta$ of denoising model $\\epsilon_{\\theta}(\\cdot)$. They showed good performance in terms of quantitative metrics and also showed qualitative results."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The proposal of the paper is overall good, theoretically sound and shown to have worked well.\n\n- Theoretically, it makes sense to use the Adjoint method on the reverse ODE.\n- The authors exploited the semi-linear nature of the ODE even in the Adjoint backprop, following DPM-Solver/DEIS."
                },
                "weaknesses": {
                    "value": "- While the proposal is quite novel, one might still argue that it is not really necessary to use Adjoint Backprop. One can very well accomplish the same task by backprop-ing through the solver machinery (maybe by deceasing sampling steps and using better sampler), which of course, won\u2019t be very efficient. So, at the end, it all boils down to compute/memory efficiency. While I understand the memory advantage, sadly, the paper barely talks anything about computational requirements of the method. BTW, Neural ODEs (and Adjoint Backprop) are known to be not very scalable.\n- Experiments are okay-ish, but not really extensive. Qualitative samples are lacking in some experiments (e.g. vocabulary expansion). Also Vocabulary Expansion is shown for only two classes.\n- No comparison or mention of methods that DO backprop through the ODE solver."
                },
                "questions": {
                    "value": "I have the following questions for the authors.\n\n- I am confused about section 3.4. That is not AdjointDPM \u2014 that is just unconditional generation with an already known sampler (DEIS, which used Adam-Bashforth) that exploits the semi-linear nature. What part of this is your contribution ? Am I missing something here ?\n- In the \u201csecurity auditing\u201d application, what exactly is the guidance $L$ ? What is the meaning of \u201cdistance between a harmful prompt and a prediction score\u201d ? Also, what exactly is the NSFW filter $f(\\cdot)$ ? Can you provide more details please ?\n\nMinor questions or suggestions:\n\n- The unnumbered eq b/w Eq. 5 & 6 \u2014 what is the meaning of that line (\u201dSimilarly, for $\\theta$, we can regard ..\u201d) ?\n- \u201cadjoint state $\\mathbf{a}(t) = ..$, which represents how the loss depends on the state ..\u201d \u2192 \u201cadjoint state $\\mathbf{a}(t)$ = .., which represents how the loss **changes w.r.t the** state ..\u201d.\n- The AdjointDPM eq. 8 shows gradient w.r.t $t$ \u2014 is it acutally used anywhere ?\n- Why is it called \u201cvocabulary expansion\u201d ? I still don\u2019t get it.\n- \u201cSecurity Auditing\u201d is just fancy name for Adversarial Samples ?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2354/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2354/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2354/Reviewer_6hcA"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2354/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699049891602,
            "cdate": 1699049891602,
            "tmdate": 1699636167532,
            "mdate": 1699636167532,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HcSsUCjOIw",
                "forum": "y33lDRBgWI",
                "replyto": "1DScnbxrW8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2354/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2354/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer 6hcA"
                    },
                    "comment": {
                        "value": "Thank you for carefully reviewing this work and asking us very insightful questions! We have tried our best to answer your questions below.\n> Weakness 1. While the proposal is quite novel, one might still argue that it is not really necessary to use Adjoint Backprop....While I understand the memory advantage, sadly, the paper barely talks anything about the computational requirements of the method. BTW, Neural ODEs (and Adjoint Backprop) are known to be not very scalable.\n> Weakness 3. No comparison or mention of methods that DO backprop through the ODE solver.\n> \n**Reply:**  \n- When we try to finetune the state-of-the-art text-to-image diffusion model (e.g., Stable Diffusion), it is nearly infeasible to do direct backpropagation. Stable Diffusion usually requires more than 25 steps to produce a high-quality image, however even V100-GPU cannot back-propagate gradients throughout 5 times of iterations (31913MiB / 32768MiB), let alone 25 iterations. \n- For the memory consumption, NFE analysis, and scalability, please refer to Global Response.\n\n> Weakness 2. Experiments are okay-ish, but not really extensive. Qualitative samples are lacking in some experiments (e.g. vocabulary expansion). Also Vocabulary Expansion is shown for only two classes.\n\n  **Reply:** Thanks for raising this point. We extend our results comparison to 90 classes in Standford dogs Dataset. We compute the change of FID relative to the original Stable Diffusion generations for comparison. The results are shown in the following table. As there is limited time to run DOODL's result for us, we use the value reported in [1]. We also did not extend the comparison to more classes on the Birds dataset. Complete quantitative results will be added to the final version of the manuscript in Table 2. More qualitative results are added in Appendix.\n  \n  | Dataset   | DOODL | AdjointDPM|\n| -------- |  ------- |  ------- |\n| Dogs  | -5.3% | -7.1% | \n\n[1] Bram Wallace, et al. End-to-end diffusion latent optimization improves classifier guidance. \n\n> Q1. I am confused about section 3.4. That is not AdjointDPM \u2014 that is just unconditional generation with an already known sampler (DEIS, which used Adam-Bashforth) that exploits the semi-linear nature. What part of this is your contribution? Am I missing something here? \n\n**Reply:**  Sorry for the confusion. The exponential integration technique has been used in many diffusion ODE-type solvers, including EDM [1], DPM-solver [2], DEIS [3]. Here our point is not to compare the difference on the exponential integration technique in different ODE solvers. We emphasize that AdjointDPM can retain comparable image generation quality with existing models (see FID results in Table 1), and at the same time, it can support obtaining the gradients by solving a backward ODE. Exploiting semi-linear accelerates both the forward and backward ODEs as there also exists a semi-linear structure in the backward ODE.\n\n[1] Karras, T., et al. (2022). Elucidating the design space of diffusion-based generative models. \n\n[2] Lu, C., et al. (2022). Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps. \n\n[3] Zhang, Q., et al. (2022). Fast Sampling of Diffusion Models with Exponential Integrator. \n\n> Q2. In the \u201csecurity auditing\u201d application, what exactly is the guidance? What is the meaning of \u201cdistance between a harmful prompt and a prediction score\u201d? Also, what exactly is the NSFW filter $f()$? Can you provide more details please?\n\n**Reply:** Security auditing aims to search for adversarial initial noises $\\mathbf{x}_T$ that will evolve into harmful images and bypass the filter. In the paper, we present two examples: the first one sets the filter to be a pretrained ImageNet classifier (in the experiment, we use the pretrained Resnet50) and the second one is the Not Safe For Work (NSFW) Filter [2] in Stable Diffusion. \n\nFor the ImageNet classifier, the guidance is set to be the cross entropy loss between the classification results of the generated images and any class that is not equal to the classification results (we choose this class randomly). For the NSFW filter, we set the guidance to be a weighted combination of cosine similarities between CLIP image features of the generated unsafe image and CLIP text features of some harmful concepts [2]. Usually in an NSFW filter, when the similarity of the generated image to harmful features is greater than a threshold, the generated images will be filtered. Thus, we minimize the similarity to help the generated unsafe images skip the filter.\n\n[2] Schramowski, et al. (2023). Safe latent diffusion: Mitigating inappropriate degeneration in diffusion models."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2354/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700532789166,
                "cdate": 1700532789166,
                "tmdate": 1700532789166,
                "mdate": 1700532789166,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HyB6lLiKsL",
                "forum": "y33lDRBgWI",
                "replyto": "oWagrQe6IS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2354/Reviewer_6hcA"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2354/Reviewer_6hcA"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the rebuttal"
                    },
                    "comment": {
                        "value": "Thanks to the authors for the rebuttal. They clarified a most of my doubts. They provided more experiments, and most importantly some computational analysis.\n\nWhile I still think the computations are relatively costly, I would like to re-terate my stand that the paper is conceptually/theoretically good. Weighting pros and cons, I think I would like to stick to my score, which I think is a right balance."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2354/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700683098659,
                "cdate": 1700683098659,
                "tmdate": 1700683098659,
                "mdate": 1700683098659,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]