[
    {
        "title": "NL2ProGPT: Taming Large Language Model for Conversational Protein Design"
    },
    {
        "review": {
            "id": "zYdinG17CQ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1229/Reviewer_kJGB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1229/Reviewer_kJGB"
            ],
            "forum": "sFJr7okOBi",
            "replyto": "sFJr7okOBi",
            "content": {
                "summary": {
                    "value": "This paper trains a P(protein sequence | metadata) model, where metadata encompasses both natural language descriptions of target attributes of the protein and some control tags for structural features based on clustering structures of natural proteins. There are some interesting modeling ideas, such as fine-tuning GPT-2 and using an RL objective to reward sequences with low Rosetta energy. Samples from the model are evaluated using various sanity checks using protein structure prediction models, etc."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper draws on a number of modeling techniques that are popular in the modern toolbox: RLAIF, fine-tuning foundation models, using protein structure prediction tools to provide eval metrics that are cheaper than wet-lab experiments."
                },
                "weaknesses": {
                    "value": "The paper's title/abstract/intro/conclusion have lots of language about the promise of a  'conversational' natural language interface for designing proteins. However, the paper does not explore such text descriptions. It just uses a simple text rendering for converting protein database entries obeying a certain schema into text. For example, \"Provides a protein that contains {domain description}, belongs to {family}, {ESM class} and {ONTO class}.<p>{protein sequence}\" (Fig 1). There are significant resources available for true natural language descriptions of proteins. For example, Uniprot entires have one-line name fields and also longer description fields. Further, there are lookup tables available that map GO terms, EC numbers, Pfam families, etc to free text descriptions.\n\nSimilarly, the paper seems to over-state the novelty of structured-guided design with language models. The paper says \"\u2026none of them enables the sequence generation given target structures due to the lack of structural constraints.\" This ignores the significant body of work using RFDiffusion+ProteinMPNN. Further, the paper's claim that it is doing structure-guided design is quite weak: they take embeddings from an ESMFold model (which presumably encode some structure information), map them down to 2 (!!) dimensions, and then cluster these. Conditioning on a cluster id is the only way that structural information is provided. The confirmation that the generated sequences have desired structures in Table 2 is quite simplistic and anecdotal.\n\nI found the RLAIF setup quite confusing. How does it make sense to use Rosetta energy as an absolute reward function? Doesn't this need to be relative to proteins having a similar fold, similar length, etc?\n\nThe paper fine-tunes GPT-2 (which was not pretrained on protein sequences) on only 1M examples of proteins. It's unclear why this generative model was used. Why not train something from scratch, or why not train on more proteins? No ablations about the impact of using GPT-2 pretraining are provided."
                },
                "questions": {
                    "value": "I found it very surprising that no recent papers from the Baker lab were cited (RFDiffusion, ProteinMPNN, etc) were cited. These are really important contributions to the field and highly related to your paper. Can you please comment on these?\n\nI am extremely confused about why you did k-means on the 2-dimensional UMap representations. Can you provide more background about why this approach is more 'intuitive and reliable'? \n\nI don't understand how the rosetta energy function was used as a reward, since the energy needs to somehow be normalized by the energy of ground truth proteins with the desired attributes. You say, \"Generally, protein structures with lower scores are more likely to be closer to the native structure.\" What is 'native structure' and how is it used?\n\nThe rewards in eqs (9) and (10) have an optimum when the model just generates cluster centers, which will severely hurt diversity. When presenting your various eval metrics, I'm curious what would have happened if you had considered a simple baseline approach that just memorized a few exemplars.\n\nI don't understand the overall evaluation setup. What does 'We randomly generate 1000 protein sequences from these models'. What metadata did you condition on? Was it 1000 different sets of metadata? How do you make this comparison fair when using models like ESM that don't have the ability to condition on metadata?\n\nThe \"Protein credibility prediction\" paragraph should mention that progen also confirms  wet-lab experiments.\n\nThe citation format is incorrect. It appears that there are many places where you should have been using natbib \\citet{}."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1229/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697465920357,
            "cdate": 1697465920357,
            "tmdate": 1699636049615,
            "mdate": 1699636049615,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "eO7eNAwGYh",
                "forum": "sFJr7okOBi",
                "replyto": "zYdinG17CQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1229/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1229/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer kJGB"
                    },
                    "comment": {
                        "value": ">Q1: I found it very surprising that no recent papers from the Baker lab were cited (RFDiffusion, ProteinMPNN, etc) were cited. These are really important contributions to the field and highly related to your paper. Can you please comment on these?\n\nA1: Our work focuses on text-to-protein generation, integrating structural information from protein representation models. (Refer to our \u201ccontributions\u201d). RFDiffusion and ProteinMPNN are protein sequence design **given protein backbones**, which are not so-called highly related to our work.\n\n>Q2: I am extremely confused about why you did k-means on the 2-dimensional UMap representations. Can you provide more background about why this approach is more 'intuitive and reliable'?\n\nA2: Directly clustering protein representation in **high-dimensional space is unstable and hard to optimize**. The UMap could reduce the dimensionality while maintaining the spatial relationship between proteins. In addition, our experiments also confirmed that this clustering result has certain biological significance, as shown in Table 2 and Table 3.\n\n\n>Q3: I don't understand how the rosetta energy function was used as a reward, since the energy needs to somehow be normalized by the energy of ground truth proteins with the desired attributes. You say, \"Generally, protein structures with lower scores are more likely to be closer to the native structure.\" What is 'native structure' and how is it used?\n\nA3: It is common knowledge that **lower molecular energy corresponds to higher stability**. For example, ProGen and ProtGPT2 both use Rosetta scores for evaluation (see the Related Works Section). For more details, please see (https://www.rosettacommons.org/demos/latest/tutorials/scoring/scoring). The native structure means the structure of natural proteins.\n\n>Q4: The rewards in eqs (9) and (10) have an optimum when the model just generates cluster centers, which will severely hurt diversity. When presenting your various eval metrics, I'm curious what would have happened if you had considered a simple baseline approach that just memorized a few exemplars.\n\nA4: In fact, it is not generating the cluster center point that can obtain the optimal reward. Hitting the cluster representation means hitting the dimensionally reduced region (where **the reward is the same within the region**), not a single point. Therefore, such rewards do not hurt the generation's diversity.\n\n>Q5: I don't understand the overall evaluation setup. What does 'We randomly generate 1000 protein sequences from these models'. What metadata did you condition on? Was it 1000 different sets of metadata? How do you make this comparison fair when using models like ESM that don't have the ability to condition on metadata?\n\nA5: We selected 10 text descriptions and obtained 1000 protein sequences. For ESM-2MR, we selected 10 text descriptions corresponding to protein sequences from the dataset, randomly masked 50%, and reconstructed the sequences.\n\n>Q6: The \"Protein credibility prediction\" paragraph should mention that progen also confirms wet-lab experiments.\n\nA6: Thanks for your advice."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1229/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700630432000,
                "cdate": 1700630432000,
                "tmdate": 1700630828714,
                "mdate": 1700630828714,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "lPOO1Fabt8",
            "forum": "sFJr7okOBi",
            "replyto": "sFJr7okOBi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1229/Reviewer_PWDH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1229/Reviewer_PWDH"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new LLMs-based framework \u201cNL2ProGPT\u201d for macromolecular protein sequence generation that bridges the domain gap between natural and protein languages. The authors train a reward model to align the protein laguage model with the Rosetta energy function, following an RLAIF fashion, and empirically verify the effectiveness of NL2ProGPT."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The authors have provided detailed explanations of their proposed methods and presented promising results."
                },
                "weaknesses": {
                    "value": "The authors claim that:\n\n\u201cmost existing methods mainly utilize protein sequential or structural information to model the intrinsic properties of protein, lacking the kind of controllable generation in a conversational way like LLMs.\u201d \n\nIt is unclear what advantages can be brought by \u201cgeneration in a conversational way.\u201d"
                },
                "questions": {
                    "value": "Misc: \n\nThe citations should be enclosed by parentheses, such as using the\u201c\\citep{}\u201d command instead of \u201c\\cite{}\u201d.\n\nTypo in Table 1: \u201cOntoProtien\u201d, \u201cNL2ProGTP\u201d"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1229/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698721668655,
            "cdate": 1698721668655,
            "tmdate": 1699636049543,
            "mdate": 1699636049543,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CJsRcM7IFK",
                "forum": "sFJr7okOBi",
                "replyto": "lPOO1Fabt8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1229/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1229/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer PWDH"
                    },
                    "comment": {
                        "value": "Conversational protein generation models, by offering a more intuitive, flexible, and interactive interface, provide a powerful tool for researchers in the field of biology, potentially driving deeper breakthroughs in related research. As discussed in the introduction's LLM section, they can serve as a tool for researchers in the field of biology, facilitating discoveries and advancing related research. As stated in our paper, \"Consequently, LLMs offer unprecedented potential to advance protein discovery, particularly in the context of text-to-protein translation.\""
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1229/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700630021451,
                "cdate": 1700630021451,
                "tmdate": 1700630021451,
                "mdate": 1700630021451,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "pOgyYuXMYf",
            "forum": "sFJr7okOBi",
            "replyto": "sFJr7okOBi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1229/Reviewer_se98"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1229/Reviewer_se98"
            ],
            "content": {
                "summary": {
                    "value": "This work studies the problem of protein design with large language models (LLMs), where the input to their model is a natural description of protein features that contain both functional and structural information via preprocessing with existing MSA tools and pre-trained protein language model (e.g., ESM2). The framework \u2014 NL2ProGPT also consists of two steps of self-supervised fine-tuning on GPT2 and reinforcement learning from AI feedback (with protein-based and cluster-based rewards) to improve the model's prediction.\nThey evaluate the quality of proteins generated by the proposed framework and show relatively good performance on closeness to the real-data distribution and high consistency. The authors also provide interesting findings on exploring disordered regions and case studies to understand cluster representations further."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The problem of protein design is important. With the rapid growth of LLMs, utilizing LLMs for protein design is a timely and interesting problem.\n2. The design of the NL2ProGPT framework seems to be novel in terms of integrating existing techniques used for LLMs with natural languages and techniques specified for protein learning.\n3. As measuring the generation of protein is still open research, the paper makes a good effort in quality evaluation and shows a good performance of the proposed method.\n4. I appreciate the effort of the authors in providing the case study"
                },
                "weaknesses": {
                    "value": "- Correctness/Soundness of the framework:\n    - Evaluation: the method seems to use the same model in the framework for evaluation. For instance, they use ESM2 to embed the structure with reward constraints to an ESM-based cluster and use ESMFold (built on ESM2) for structure prediction evaluation. Also, they use the consistency (with Rosetta) reward in Step 3 to constrain the model and evaluation. This may raise the question of model performance benefits from the inductive bias of these pretrained models and tools.\n    - The paper claims to embed the structural information into the description, but it\u2019s doubtful how much the structure is preserved. First, though the ESM2 paper claims their embeddings have structural information, it is still implicit. Second, though the case study shows some insight into the cluster representation, it\u2019s unclear how much information UMAP (into 2-D) and k-mean can preserve, as we know the loss of information after the dimension reduction and the difficulty of clustering.\n- Results:\n    - In Figure 2, it doesn\u2019t seem the proposed method achieves the best performance in any measure. For instance, a similar approach \u2014 ESM2-MR model is closer to the GT and performs better in the first one.\n    - As NL2ProGPT is not the first approach combining natural language and protein (e.g., proteinDT), this raises the question of motivation in which scenario the proposed method is necessary.\n- Novelty/Originality: while I appreciate the novelty in integration methods for protein design, each framework component seems to be incremental in the design for protein learning.\n- Writing or Presentation: Overall, the paper is easy to follow, but the presentation is not at the quality of the top conference and should be improved.\n    - Typos: there are a few typos, such as missing space right before the citation on page 1 (ProGEn-2Nij), (ref2015Park), page 6 (-2(base)), \u2026. These typos somewhat indicate that the paper was not properly proofread.\n    - I can not find the appendix or detailed description of the model, settings, and template. It should be more useful for understanding to provide the sample template.\n    - (Optional) The writing should be improved to be more concise. Some sentences and claims are  vague and less precise, e.g., \u201cThis training process helps us understand the distribution of combined sequences.\u201d  or \u201cOverall, our generated protein sequences may have a higher success rate when performing wet experiments.\u201d Furthermore, the notations, e.g. aw can also be improved for consistency.\n    - I didn\u2019t find the description/definition of the TM score in the paper.\n    - Minor: For Figure 1, step 1, the figure of ChatGPT seems to be a cropped version of the ChatGPT official icon without modification."
                },
                "questions": {
                    "value": "Together with previous questions, I have some clarification questions:\n\n1. For structure embedding, have you considered other methods, such as explicitly embedding structure from AlphaFold generation, which some recent papers use?\n2. For step 1, how do you improve the diversity with ChatGPT? Do you also input the protein sequence to ChatGPT?\n3. For step 2, what are the input and output? From the figure, it seems like a pretraining step with self-supervision (next-token prediction). Still, the description in the paper says it\u2019s p(a|w), meaning predicting amino acids from the description. Can you elaborate on this step?\n4. For step 2, what is the initial state of GPT2? Which checkpoint is that? \n5. For step 4, how do you control the diversity of generated sequences given an input protein?\n6. How well do they cluster in 2-d of UMAP?\n7. Terminology: why do you call it conversational protein design? It may be confusing to the dialog or conversation-based LLM."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1229/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1229/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1229/Reviewer_se98"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1229/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698824970542,
            "cdate": 1698824970542,
            "tmdate": 1700640342440,
            "mdate": 1700640342440,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "niE377oYFG",
                "forum": "sFJr7okOBi",
                "replyto": "pOgyYuXMYf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1229/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1229/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer se98"
                    },
                    "comment": {
                        "value": ">Q1: The method seems to use the same model in the framework for evaluation. For instance, they use ESM2 to embed the structure with reward constraints to an ESM-based cluster and use ESMFold (built on ESM2) for structure prediction evaluation. Also, they use the consistency (with Rosetta) reward in Step 3 to constrain the model and evaluation. This may raise the question of model performance benefits from the inductive bias of these pretrained models and tools.\n\nA1: We sincerely do not agree that our evaluation is unfair because ESMFold is only used for structure prediction, and the real score is obtained by the Rosetta scoring function. In addition, we do not think that using RL is unfair for comparison. First, we use multiple evaluation metrics to verify our model\u2019s superior performance than other methods as shown in Figure 2. Second, we also report the performance of our method without RL in Table 1, still showing a better performance than the baseline model.\n\n>Q2: The paper claims to embed the structural information into the description, but it\u2019s doubtful how much the structure is preserved. First, though the ESM2 paper claims their embeddings have structural information, it is still implicit. Second, though the case study shows some insight into the cluster representation, it\u2019s unclear how much information UMAP (into 2-D) and k-mean can preserve, as we know the loss of information after the dimension reduction and the difficulty of clustering.\n\nA2: From Table 2, we can see that our method can preserve quite high structural information in the generated proteins. It also should be emphasized that we provide a new **flexible** way to incorporate structural information for the protein language model that has not been explored before. \n\n>Q3: In Figure 2, it doesn\u2019t seem the proposed method achieves the best performance in any measure. For instance, a similar approach \u2014 the GT model performs better in the first one. \n\nA3: It is important to clarify that in Figure 2, **'GT' represents the ground truth protein**.\n\n>Q4: As NL2ProGPT is not the first approach combining natural language and protein (e.g., GTprotein), this raises the question of motivation in which scenario the proposed method is necessary.\n\nA4: Could you give a reference of GTprotein or do you mean the ground truth model ?\n\n> Q6\uff1a Questions:\n1. Our approach exhibits strong scalability, allowing for the incorporation of additional protein representation models in the future.\n\n2. We exclusively leverage ChatGPT to enrich the textual description of proteins. Only text is inputted; protein sequences are not included.\n\n3. Our methodology involves concatenating protein textual descriptions with protein sequences for unified input during self-supervised training. Our focus is solely on obtaining protein sequences through text. During inference, protein sequences are fully derived from the model through textual descriptions.\n\n4. We utilize the official GPT-2 checkpoints provided by Hugging Face: https://huggingface.co/gpt2.\n\n5. GPT employs sampling during generation, providing control over diversity by adjusting the sampling strategy.\n\n6. The combination of Figure 4, Table 2, and Table 3 indirectly validates the effectiveness of our clustering approach.\n\n7. Since our model is developed as a protein generation model within a conversational system, we refer to it as conversational protein design."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1229/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700631026138,
                "cdate": 1700631026138,
                "tmdate": 1700631026138,
                "mdate": 1700631026138,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tb7NADiU0r",
                "forum": "sFJr7okOBi",
                "replyto": "pOgyYuXMYf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1229/Reviewer_se98"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1229/Reviewer_se98"
                ],
                "content": {
                    "title": {
                        "value": "Re: clarification for Q3 & Q4"
                    },
                    "comment": {
                        "value": "Hi, \n\nThanks for your response. \n\n* Regarding Q3, I meant the 'ESM-2MR' model  -- is closer performance to the GT (I'm sorry for the typo). \n* Regarding Q4, the references for using text with protein design are the ProteinDT model (A Text-guided Protein Design Framework, Liu et. al. 2023. https://arxiv.org/pdf/2302.04611.pdf), or ProGen family (Large language models generate functional protein sequences across diverse families, Madani et. al., 2023, https://www.nature.com/articles/s41587-022-01618-2)."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1229/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700639294085,
                "cdate": 1700639294085,
                "tmdate": 1700640482749,
                "mdate": 1700640482749,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "uEZmdg5qN6",
            "forum": "sFJr7okOBi",
            "replyto": "sFJr7okOBi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1229/Reviewer_Gu8r"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1229/Reviewer_Gu8r"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes to train a joint model on both the protein and text modalities (optionally with RL with some rewards around generality and consistency). The model is then used to generate proteins, sometimes with textual constraints that are key to the authors' approach.\n\nThe models are evaluated with respect to several related works on both the generality and consistency dimensions."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "I think the idea of building joint protein text representations for controllable protein generation is important and has a lot of promise."
                },
                "weaknesses": {
                    "value": "-Overall I have some questions about the paper below that I feel are critical to my understanding both to understand the method and make sure the evaluation is fair. \n\n(1) I don't quite understand how ChatGPT is used to generate the text descriptions. It says something like:\n\n\"We then feedthese constructed templates into ChatGPT OpenAI (2023) to obtain diverse protein text descriptions\nby using several prompts. These descriptions constitute the training dataset for text-protein pairs,\nserving as a foundation for further research and analysis.\"\n\nIn Section 4.1 it also says:\n\"Our training dataset comprise 1,001,890 text-protein sequence pairs in total.\"\n\nAre these training examples from the above process with ChatGPT? If so, how did you do any verification on the quality of this dataset?\n\n(2) Given that some of them models use text as inputs like the authors' approach and some do not e.g. Progen I am a bit confused as to how all the models are compared e.g. is each model fed a different input and what are these inputs?\n\n(3) When evaluating for generality and consistency are the metrics used the same as that were used for RL? (in which case it would be unfair since the model would be overfitting on the reward). Some clarification would be great."
                },
                "questions": {
                    "value": "See questions above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1229/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699030297500,
            "cdate": 1699030297500,
            "tmdate": 1699636049406,
            "mdate": 1699636049406,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ThKtUX9Koo",
                "forum": "sFJr7okOBi",
                "replyto": "uEZmdg5qN6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1229/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1229/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer Gu8r"
                    },
                    "comment": {
                        "value": "> Q1\uff1a\u00a0I don't quite understand how ChatGPT is used to generate the text descriptions. Are these training examples from the above process with ChatGPT? If so, how did you do any verification on the quality of this dataset?\n\nA1\uff1a We enriched textual descriptions using ChatGPT, specifically by leveraging the generated text from templates through ChatGPT to diversify the textual descriptions. For instance, the original statement \"Provides a protein that contains GNAT domain and belongs to ESM_51 and ONTO_38.\" was transformed into \"This protein presents attributes encompassing the GNAT domain and falls under the classifications of ESM_51 and ONTO_38.\" This process focuses solely on **enhancing the diversity of textual descriptions**, ensuring that the quality of the dataset remains unaffected.\n\n>Q2: Given that some of them models use text as inputs like the authors' approach and some do not e.g. Progen I am a bit confused as to how all the models are compared e.g. is each model fed a different input and what are these inputs?\n\nA2: In fact, we mainly compare the **quality** of generated protein sequences through three metrics, i.e., conformational energy distributions, foldability-measured sequence pLDDT distributions and self-consistency distributions. Therefore, for those methods without text inputs, the protein sequences are generated without text constraints. \n\n>Q3: \u00a0When evaluating for generality and consistency are the metrics used the same as that were used for RL? (in which case it would be unfair since the model would be overfitting on the reward). Some clarification would be great.\n\nA3: We sincerely do not think that using RL is unfair for comparison. First, we do not find any overfitting evidence in our experiment results. Second, we use multiple evaluation metrics to verify our model\u2019s superior performance than other methods as shown in Figure 2. Third, we also report the performance of our method without RL in Table 1, still showing the better performance than the baseline model."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1229/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700629862241,
                "cdate": 1700629862241,
                "tmdate": 1700629862241,
                "mdate": 1700629862241,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]