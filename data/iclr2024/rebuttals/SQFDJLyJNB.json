[
    {
        "title": "PromptCCD: Learning Gaussian Mixture Prompt Pool for Continual Category Discovery"
    },
    {
        "review": {
            "id": "u6Nx3acbeo",
            "forum": "SQFDJLyJNB",
            "replyto": "SQFDJLyJNB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1406/Reviewer_si3G"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1406/Reviewer_si3G"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses the challenge of continual category discovery (CCD). CCD consists of two stages: the first stage involves training on a labeled dataset with known categories, while the second stage encompasses a continual setting where unlabeled data arrives sequentially. In each continual session, the objective is to identify new categories and classify all data instances, encompassing both known and novel classes. The authors approach CCD by substituting the prompt pool from L2P (Wang et al.) with a Gaussian Mixture Model (GMM). At every incremental step, both the last block of the backbone and the GMM module are updated. For prompting, the top-k Gaussian components (analogous to L2P) for each data instance are selected based on probability. The means of these components are then prepended to the input for inference. To mitigate the issue of forgetting, a subset of Gaussian samples is randomly chosen and forwarded to the next stage, allowing for dynamic expansion of the GMM modules. Additionally, the GMM module is coupled with a class number estimation method to gauge the count of emerging categories"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Expanding the prompt pool dynamically is beneficial and intuitively sound in a continual setting.\n- Based on the experimental results, modifying the prompt pool using GMM appears promising. However, some confusion still needs to be addressed.\n- Extensive experiments and comparison with SOTA methods."
                },
                "weaknesses": {
                    "value": "- In the proposed method, the top-k \"means\" are treated as prompts. However, how should one interpret this? I am unclear about how adding the mean of the GMM can enhance the guidance provided to the backbone. It's worth noting that the GMM is detached from the backbone. Consequently, learning in the GMM module is somewhat disconnected from the optimization process. This is akin to integrating additional information, such as features, into the system.\n\n- Much emphasis has been placed on the assertion that previous prompt methods are unsuitable for CCD because they require full supervision. The proposed method aims to address this by fitting the GMM. However, this claim might be overly assertive. The relaxation in data labels primarily stems from the two loss functions (both supervised and unsupervised) presented in Eqs. 2 and 3. Such techniques are commonly used in GCD, as noted by Vaze et al. (2022).\n\n- The authors claim that 'these prompts facilitate adaptation to emerging data, thus preventing catastrophic forgetting.' However, in subsequent sections, the issue of forgetting is addressed by drawing samples from previous stages and reusing them in the second stage. This approach is reminiscent of a replay mechanism.\n\n- Concerning the estimation of the novel class number, Table 3 provides interesting insights. Apart from the fine-grained CUB200, the estimation remains relatively consistent, irrespective of the class number across different stages. Even though the estimation does not align perfectly with the ground truth, the final performance might actually surpass scenarios where the class number is known, as illustrated by the comparison between Tiny200 in Tables 2 and 3. Has the study provided any rationale or explanation for this observation?\n\n- Why is the final block of the backbone updated? Prompt learning aims to use prompts to 'instruct' the foundational model to access rich information without modifying it, as seen in methods like L2P and VPT[1]. It's worth noting that updating the backbone is geared towards acquiring new 'knowledge'. Is the overall performance improvement primarily attributed to the model being tailored to a specific dataset, or is it due to the 'instruction' provided by prompt learning?\n\n* The description in the GMP module is somewhat confusing: \n  - If I've interpreted it correctly, both the letter 'C' in Section 2.2 and the letter 'K' in Section 3.2 represent the number of classes. If that's the case, consistency in notation would be appreciated. Are the top-k prompts selected from among these C/K Gaussian components? \n  - The method for obtaining GMM samples (as represented by the dots in Fig. 4) for optimizing the GMM is unclear. \n  - How many samples advance to subsequent stages? \n  - The algorithm appears to have inherent randomness, both from the selection of Gaussian samples and the random selection of reusable samples for later stages.\n\n [1] Jia et al. \u201cVisual Prompt Tuning\u201d. ECCV 2022."
                },
                "questions": {
                    "value": "Which query function is used? I assume the cls token of the backbone output is used as in L2P?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1406/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1406/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1406/Reviewer_si3G"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1406/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698715024414,
            "cdate": 1698715024414,
            "tmdate": 1699636068614,
            "mdate": 1699636068614,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "QJwfD4Fxov",
                "forum": "SQFDJLyJNB",
                "replyto": "u6Nx3acbeo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1406/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1406/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## Response to reviewer si3G, *part 1*\n\nWe would like to thank reviewer si3G for their careful review, insightful feedback, and acknowledgement of our novel and intuitively sound contributions, and extensive experiments. Here we would like to clarify some concerns addressed by reviewer si3G:\n\n- ### Q1: *How GMM\u2019s mean components guide CCD model.*\nThe motivation of our proposed model is to design a prompt module that can guide or instruct a self-supervised vision foundation model for better CCD. Moreover, not only can it guide the model, but we also believe there is a need to design a prompt module that suits the open-world nature of CCD with unlabelled data that contains unseen categories over time. Thus, intuitively we choose the Gaussian mixture model (GMM) as the candidate for our prompt design. By using the GMM mean component, it acts as a class prototype (to accommodate the absence of label information) which guides/enforces the model about the criteria / to look at (information/features that the model should care about) when making the decision to discover a category. We further show in **Appendix I**, that our GMM coupled with self-supervised vision foundation models actually produce prompts that are discriminative within different classes. Moreover, we conduct an experiment in Table 14, where instead of taking the \u201ctop-k\u201d mean components/prompts, we vary the prompts \u201crandom-k\u201d to observe the effect of difference prompt relevancy towards overall CCD performance. We can see that varying the prompt hurts the model\u2019s performance, especially for the \"NEW\" ACC i.e., novel categories.\n\n- ### Q2: *Limitation of L2P and DualPrompt for CCD task.*\nThanks for the comments. Please refer to **General response - Clarification on L2P & DualPrompt vs Our GMP**.\n\n- ### Q3: *Clarification on how GMM samples are used to prevent catastrophic forgetting.*\nIndeed, our method can be viewed as a replay method, unlike existing methods, it does not need to store any samples, but the parameter-efficient GMM can be used to generate an infinite number of replay samples on the fly. Also,  we use our replay differently than the usual replay-based method in the continual learning literature. Here the replay data is generated randomly by our GMM in each stage for each component and will be used to fit the next GMM which eventually builds/transfers previous GMM components which eventually leads to the formation of component means a.k.a prompts into the current stage GMM. Thus, by prompting these \u201cprevious components\u201d from the previous replay samples, our model can tackle catastrophic forgetting.\n\n- ### Q4: *Rationale explanation regarding Table 3, main paper results.*\nThank you very much for this comment. We followed this suggestion to investigate the cause of this phenomenon. While investigating the phenomenon between the TinyImageNet results obtained from both **Table 2 and Table 3**, we discovered a technical flaw in Table 3\u2019s experiments Specifically, an incorrect training configuration was mistakenly loaded for training when using the GCD\u2019s category number estimator. We have loaded the correct training configuration to retrain all models and updated the results in Table 3 accordingly. Based on the comparison of our model with other models in the unknown K settings in Table 3, we can see that our model outperforms all other models on all datasets under all metrics, except for the \u201cOLD\u201d accuracy of the Imagenet100 dataset. By comparing our proposed method in both Tables 2 and 3, we can observe that our proposed model has a slight decrease in accuracy for the \u201cOLD\u201d class when applying the estimated class number, while the \u201cNEW\u201d accuracy decreases more. This could be due to the prior introduced by the SS-Kmeans, which favours the \u201cOLD\u201d categories more. In addition, we conducted another experiment in **Appendix D, Table 7**, where we seamlessly adopted the GMM-based dynamic category number estimator into our CCD framework. We would like to emphasize that Table 7 aligns better with our proposed method and is therefore more preferred. As a result, we will swap Table 3 and Table 7 in our final manuscript."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1406/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700734606417,
                "cdate": 1700734606417,
                "tmdate": 1700735484409,
                "mdate": 1700735484409,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TQ9c4VKv4I",
                "forum": "SQFDJLyJNB",
                "replyto": "u6Nx3acbeo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1406/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1406/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## Response to reviewer si3G, *part 2*\n\n- ### Q5: *Clarification on why the final block of the backbone is updated.*\nOur model $H_{\\theta}: \\{\\phi, f_{\\theta}\\}$ i.e., the self-supervised vision foundation model (in this case DINO) consists of $\\phi$, an MLP projection head, and $f_{\\theta}=\\{f_e, f_b\\}$ a transformer-based feature backbone that includes an input embedding layer $f_e$ and self-attention blocks $f_b$. During training, we only optimize $\\phi$ and the final block of $f_b$. After training, we only require $f_{\\theta}$ to extract the token classification i.e., $z\\texttt{[CLS]}$ feature is used for clustering. If we fully freeze the backbone $f_b$, then unlike the L2P supervised continual learning implementation which has a final learnable fully connected layer for classification, our model will eventually not learn anything and act as a frozen DINO. Therefore, we further optimize the final block of the backbone to prevent this issue. For reference, we provide comparison results between frozen DINO, frozen DINO with learned L2P prompt pool and our proposed model in **Appendix H**. We can see that Our fine-tuned model outperforms the frozen models in all ACC metrics and for all datasets. Moreover, our fine-tuned model also appears to generalize better to data distributions (C100 & CUB200 datasets) that the DINO foundation model has not encountered before, which further justifies the design choice of our method for CCD.\n\n- ### Q6: *Clarifications of our GMP module.*\n1. We thank the reviewer for their careful review,  the number of components in GMM is similar to the number of categories i.e, $C$ and the top-K prompts are selected among these $C$ Gaussian components.\n2. To optimize GMM, we make use of classification token $z\\texttt{[CLS]}$ extracted in the \u201cgradient detach\u201d mode of our own backbone $f_{\\theta}$ as GMM samples.\n3. Based on the ablation study the optimal number of samples is 100 samples per component.\n4. For clarity we further provide a pseudo code of PromptCCD w/GMP model training in **Appendix A**.\n\n- ### Q7: *Clarification on query functions used on our proposed model.*\nAs explained in **R-si3G-Q6 Clarifications of our GMP module sub-section (2)** we make use of our own backbone model $f_{\\theta}$ as the query function to extract the classification token $z\\texttt{[CLS]}$."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1406/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700734790156,
                "cdate": 1700734790156,
                "tmdate": 1700735246110,
                "mdate": 1700735246110,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "50OUKJfiQN",
            "forum": "SQFDJLyJNB",
            "replyto": "SQFDJLyJNB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1406/Reviewer_YA1L"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1406/Reviewer_YA1L"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a prompt-based method for continual category discovery, which continually learns the keys of prompt by a GMM in an unsupervised manner. It also introduces a category estimation strategy based on GM when the number of new categories is unknown. The proposed method is evaluated on the benchmarks of continual GCD with comparisons to other baseline methods."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper proposes a GMM-based replaying strategy for the prompt-based method to address the continual GCD problem, which is a new and reasonable design for the task.\n\n- The experimental evaluation are conducted on both the settings of known and unknown class number with good results."
                },
                "weaknesses": {
                    "value": "- The novelty of the paper is mainly on the proposed Gaussian Mixture Prompt Pool, which is rather limited. The authors argue that \"the fixed-size prompt module restricts the model's ability to select prompts to a maximum of $M$\",   but the proposed Gaussian Mixture Prompt Pool seems also a fixed-size prompt. In addition, what is the advantage of GMM compared to K-means, if we also store mean and covariance for replaying?\n\n- The adaptation of L2P and Dual Prompt is not clear, which is vitally important since the main novelty is the design of keys. Specifically, how to learn the key of those two methods?\n\n- In the prompt-based continual learning diagram, they only learn the prompt pool and fix the whole backbone. But this paper argues that \"During training, only the final block of the vision transformer is finetuned .....\".  What are the results if the backbone is fixed? Is the input query also learned by finetuning the vision transformer?\n\n- The conclusion in ablation studies is incoherent. When the prompt selection is set to 5, and GMM sampling is set to 100, the \"Spherical\" outperforms \"Diagonal\". But the optimal number of prompts seems to be 10. The conclusion of ablation studies should be adjusted.\n\n- Typo: there are many typo errors and some notation is unclear. For example, \"Fourth, We hypothesize that categories may share commonalities regarding colour, shape, and other factors. \",  and $B$ and $B^L$ in Eqn(4). Please carefully check the manuscript."
                },
                "questions": {
                    "value": "See the comments in the above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1406/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698805870734,
            "cdate": 1698805870734,
            "tmdate": 1699636068526,
            "mdate": 1699636068526,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MODpleGyZD",
                "forum": "SQFDJLyJNB",
                "replyto": "50OUKJfiQN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1406/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1406/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## Response to reviewer YA1L\n\nWe would like to thank reviewer YA1L for their careful review, insightful feedback,  acknowledgement of our model\u2019s novelty and model promising results compared to other baseline models. Here we would like to clarify some concerns addressed by reviewer YA1L:\n\n- ### Q1: *Clarification of our GMP module.*\n\nOur Gaussian mixture prompt pool (GMP) differs from L2P and DualPrompt prompt pool in three ways. First, GMP parameters are not fixed as they depend on the number of C components (as shown in **Appendix H**), which is crucial in CCD tasks where the number of classes in the unlabelled data can grow or reduce over time. Second, we argue that GMM is advantageous over K-means when working with high/complex dimensional data. By using GMM, we allow a sample to have multiple memberships towards different cluster components, i.e., non-convex clusters. K-means assumes that the probability a sample belongs to a cluster is one, which in real-world data might not be true. Third, we show in **Appendix I** that GMM outperforms K-means for all clustering metrics, which means better prompt quality. Therefore, it is natural to choose GMM as a pool of prompts. For further discussion, please refer to **General response - Clarification on L2P & DualPrompt vs Our GMP**. \n\n- ### Q2: *Adaptation of L2P and DualPrompt for CCD.*\n\nTo adapt L2P and DualPrompt as our baseline models for CCD as shown in **Section 2.1, main paper**, we make the following key modifications: (1) we change the pretrained model from a strong supervised pretrained model to DINO self-supervised pretrained model, (2) Originally in supervised continual settings, L2P and DualPrompt adopt supervised objective loss i.e., cross-entropy loss to optimize their models. For CCD, we modify the loss function into a contrastive learning objective, **Section 2.3, the main paper** combined with surrogate loss, **Eq.(1)** to optimize the prompt pool to pull selected keys close to corresponding query features. Please note that for our proposed method i.e., PromptCCD w/GMP, we do not use any surrogate loss as GMM is optimized separately. For details on how we optimize GMM, see **Appendix A**.\n\n- ### Q3: *Model optimization when the DINO backbone is fully frozen.*\n\nIn the L2P model, the prompts are learnable parameters which are optimized jointly with the model. Unlike L2P, our prompts are not learnable as it is fitted from the features $z\\texttt{[CLS]}$ which is learned by fine-tuning the final block of the backbone. Thus, if we fixed the backbone, then the only learnable parameter left in our model is the projection head which is not used during inference i.e. the model becomes fully frozen. Here we provide the comparison results between the frozen DINO w/GMP,  frozen DINO w/L2P and our proposed model in **Appendix H, Table 13**. We can see that our fine-tuned model substantially outperforms the frozen models. Moreover, the frozen models failed to generalize to distribution that DINO had not encountered before (i.e., CIFAR100 and CUB200, as DINO was pre-trained on ImageNet 1K). This led to a significant loss in accuracy compared to the fine-tuned models with average difference losses of 26.43% and 18.29% respectively. This observation further emphasizes the importance of our design choice.\n\n- ### Q4: *Clarification on model\u2019s ablation studies.*\n\nOur model\u2019s GMP ablation studies consider three factors: covariance type for GMM, number of prompts, and number of GMM sampling for replay. **Table 4** shows that the optimal GMM covariance types for CIFAR100 and CUB200 datasets are \u201cSpherical\u201d and \u201cFull,\u201d respectively, with five prompts and 100 GMM samples. Although there is some ambiguity on the covariance type, we set the default configurations to be \u201cDiagonal\u201d for the GMM covariance type, five prompts, and 100 GMM samples, which appears to be a good trade-off. We further perform an additional ablation study in **Appendix K** where we keep all covariance of GMMs to be spherical. The results show that 5 prompts and 100 samples lead to the best \u201cALL\u201d accuracy"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1406/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700734200714,
                "cdate": 1700734200714,
                "tmdate": 1700736289927,
                "mdate": 1700736289927,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "C4QDVD6WSE",
            "forum": "SQFDJLyJNB",
            "replyto": "SQFDJLyJNB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1406/Reviewer_1nUF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1406/Reviewer_1nUF"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a novel approach to the problem of continual category discovery (CCD), where the goal is to label objects in an unlabeled data stream that arrives over time, containing both known and new categories. The authors introduce PromptCCD, which incorporates a Gaussian Mixture Prompt Module (GMP) to dynamically update and guide data representation, mitigating forgetting. PromptCCD also features a Gaussian Mixture-based module for estimating categories within the unlabeled data, eliminating the need for prior knowledge of the number of categories. Additionally, the paper adapts the evaluation metrics from generalized category discovery for CCD and conducts comprehensive benchmarks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1-It features an innovative Gaussian mixture prompt module that alleviates the need for label information and effectively addresses the issue of catastrophic forgetting.\n\n2-The methodology liberates the model from depending on a predetermined number of categories, enhancing its adaptability to real-world scenarios.\n\n3-The method is validated through extensive experimentation, where it consistently surpasses other state-of-the-art methods in performance.\n\n4-The literature review is thorough, encompassing a wide array of existing works in the field, thus providing a solid foundation for the proposed approach."
                },
                "weaknesses": {
                    "value": "1-The figures included are complex and lack clear, informative descriptions, necessitating repeated reference to the text for full comprehension, which disrupts the flow of understanding.\n\n2-The method is described with an excessive level of detail that, while potentially beneficial, also burdens the reader with information overload. A more concise presentation, perhaps through structured pseudocode similar to that provided for the evaluation, could clarify the methodology more effectively. Additionally, the depiction of the method across Figures 2-4 is spread over multiple figures with captions that do not sufficiently convey the information, thereby diluting the explanatory power of the visuals."
                },
                "questions": {
                    "value": "1-Given that a Gaussian Mixture Model (GMM) is employed, does the assumption of similarity between learning stages in conventional continual learning scenarios, which may vary greatly, potentially limit the model's capabilities?\n\n2-Considering that a portion of the data is initially labeled, is it possible to leverage this labeled subset to learn a preliminary GMM that could subsequently be integrated into the broader GMM for the entire dataset?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1406/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698833816906,
            "cdate": 1698833816906,
            "tmdate": 1699636068447,
            "mdate": 1699636068447,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6pLCuGXfc1",
                "forum": "SQFDJLyJNB",
                "replyto": "C4QDVD6WSE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1406/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1406/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "##  Response to reviewer 1nUF\nWe would like to thank reviewer 1nUF for their careful review, insightful feedback, and acknowledgement for recognising the innovation and novelty of our approach, comprehensive benchmark and extensive experiments, and comprehensive literature review. Here we would like to clarify some concerns addressed by reviewer 1nUF:\n\n- ### Q1: *Suggestion on paper presentations.*\n\nWe thank reviewer 1nUF for their suggestions. We have revised the manuscript with updated  **Figures 2 & 3** with added captions and provide the pseudo-code to explain the overall process in **Appendix A**.\n\n- ### Q2: *Clarifications on how GMP is employed.*\n\nWe used Gaussian mixture models (GMMs) even during the initial learning with labelled data. The GMM learned the features from the labelled data and transferred this knowledge in the form of GMM random samples and fit them to the next GMM.\n\n- ### Q3: *Discussion on the limitation of GMP.*\n\nAs shown in **Appendix I, Table 13**, by learning GMM as a pool of prompt, and finetuned the final layer of the backbone, we observe the performance on C100 and CUB200 datasets to be interesting, we see that our proposed model guided by GMM\u2019s mean components generalized better (compared to frozen DINO backbone) to datasets that the DINO foundation model has not encountered before which further justifies the design choice of our method. This argument is further justified in **Appendix H**, where we show that GMM\u2019s prompts represent class prototypes. Thus, our method does not limit the model\u2019s capability when the task identity for each stage is different."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1406/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700733984925,
                "cdate": 1700733984925,
                "tmdate": 1700734360122,
                "mdate": 1700734360122,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LAVusyrnsC",
            "forum": "SQFDJLyJNB",
            "replyto": "SQFDJLyJNB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1406/Reviewer_k1JJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1406/Reviewer_k1JJ"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a Gaussian Mixture Prompt Module (GMP) for Continual Class Discovery (CCD), a prompt learning technique that employs a Gaussian mixture model (GMM) as a dynamic prompt pool. The GMP overcomes the drawbacks of previous prompt learning methods by obviating the need for label information, adapting the parameterization based on data distribution, alleviating catastrophic forgetting, and exploiting shared commonalities among categories. The paper defines the optimization objectives for different learning stages, comprising supervised and unsupervised contrastive learning losses, as well as a surrogate loss to optimize the learnable prompt pool. The paper demonstrates that the proposed methods surpass existing approaches in terms of accuracy."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper demonstrates the superiority of the proposed method over existing models by conducting a rigorous comparative analysis and achieving a substantial margin of improvement.\n- The paper provides a comprehensive and lucid presentation of the technical details, including equations, tables, and descriptions of the methodology. The paper elucidates the underlying concepts and methods in an accessible manner, enabling readers to grasp the essence and rationale of the approach.\n- The paper exhibits a high level of clarity and coherence in its organization and writing, facilitating the comprehension of the proposed approach and its merits."
                },
                "weaknesses": {
                    "value": "- The method presented in this paper bears some resemblance to the one proposed in [1], but differs in that it tackles the CCD problem through incremental learning without any annotated information. \n- This method employs DINO as the pre-training model. Although a similar pre-training approach was also adopted in [1], the problems addressed are different. The Continuous Learning task has annotation information, so the utilization of DINO\u2019s self-supervised model is justified. However, in the CCD problem, there is no annotation information, and most incremental tasks are self-supervised. For models that are unsupervised, and the training data may have overlaps, using DINO is not equitable. \n- The performance enhancement of this method stems more from DINO, and the paper lacks a comparison with methods without DINO pre-training models. The table in the paper does not specify the model's parameters used by different methods.\n\n[1] Wang, Zifeng, et al. \"Learning to prompt for continual learning.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022."
                },
                "questions": {
                    "value": "- In Appendix C of the paper, the authors propose a method for dynamically adapting to the number of unknown categories, denoted as PromptCCD+. The method employed by PromptCCD in the main text to cope with unknown categories is to fix the number of categories to a predefined value. \n- It would be beneficial to provide a direct comparison between the number of dynamically adapted unknown categories and the number of actual categories. This would offer a clearer insight into the effectiveness of the proposed method. \n- Most of the experiments in the paper are conducted in three stages. Is it feasible to extend the method to more incremental stages?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1406/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1406/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1406/Reviewer_k1JJ"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1406/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698928347377,
            "cdate": 1698928347377,
            "tmdate": 1699636068355,
            "mdate": 1699636068355,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tNcyzr0SxK",
                "forum": "SQFDJLyJNB",
                "replyto": "LAVusyrnsC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1406/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1406/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## Response to reviewer k1JJ\nWe would like to thank reviewer k1JJ for their careful review, insightful feedback, and acknowledgement of our rigorous analysis of the CCD task, high-level clarity and comprehensive presentation of our paper, and the effectiveness of our proposed method. Here we would like to clarify some concerns addressed by reviewer k1JJ:\n\n - ### Q1: *Clarifications on the difference between the L2P method and our proposed method*\n\nIn terms of the difference between the L2P method and our proposed method, please refer to **General response - Clarification on L2P & DualPrompt vs Our GMP**. \n\n- ### Q2: *The motivation for using the self-supervised vision foundation model for the CCD task*\n\nWe would like to clarify that for L2P, they did not use a self-supervised pretrained model. Instead, they adopt a fully supervised pretrained model on very large-scale labelled data i.e., ImageNet-21K. In contrast, we use the fully self-supervised pretrained model DINO, which has been widely adopted in the static GCD task, by leveraging its strong feature generalization capability. DINO is a self-supervised (SSL) pretrained model (no labels are used during training). We want to point out that the SSL model has been widely adopted and justified in both NCD [**A**] and all GCD literature so far. It is a valid and reasonable choice to use such models because no supervision, such as class labels, was used to train the feature backbone. \n\n- ### Q3: *Information on the learnable parameters from all compared models.*\n\nWe provide the table comparison of each model\u2019s learnable parameters in **Appendix H**. Here we show that our model\u2019s GMM parameters are flexible as we only need to define the number of components to scale it. Overall, compared to our baseline models (L2P and DualPrompt), Our proposed model\u2019s learnable parameters are only 0.33% higher with category number C set to 100, which is still parameter efficient. \n\n- ### Q4: *Fixing the number of categories for main experiments.*\n\nYes, in the main table experiments i.e., **Table 2**, we fix the number of categories to a predefined value for all models and datasets for fair comparison.\n\n- ### Q5: *Comparison between the predicted number of categories vs the actual number of categories.*\n\nWe provide the tables for comparison between the predicted number of categories and the ground truth categories in **Table 3** (GCD [**B**] category number estimator) and **Appendix D** (Ours, by seamlessly adopting the GMM based dynamic category number estimator from GPC [**C**]). Overall, in this realistic scenario, our model still consistently outperforms other methods by a large margin across different datasets.\n\n- ### Q6: *The feasibility of extending the number of discovery stages.*\n\nFor a fair comparison, we follow the previous work [**D**] data distribution i.e., 3 discovery stages. Also, we would like to clarify that our approach does not have any constraint on the number of discovery stages. In **Appendix E** we further compare our model with the recent ICCV-accepted papers called MetaGCD with 4 incremental category discovery stages and PAiGCD with 2 incremental category discovery stages."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1406/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700733812216,
                "cdate": 1700733812216,
                "tmdate": 1700735451196,
                "mdate": 1700735451196,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]