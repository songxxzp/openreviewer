[
    {
        "title": "MetaGPT: Meta Programming for Multi-Agent Collaborative Framework"
    },
    {
        "review": {
            "id": "a2Wdn7SSsA",
            "forum": "VtmBAGCN7o",
            "replyto": "VtmBAGCN7o",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5488/Reviewer_uj5i"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5488/Reviewer_uj5i"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces MetaGPT, an innovative meta-programming framework for multi-agent collaborations based on LLM, which encodes Standardized Operating Procedures (SOPs) into prompt sequences for more streamlined workflows. It selects a group of agents as a simulated software company, to generate a variety of code-based softwares. Through extensive experiments, MetaGPT achieves state-of-art performance on multiple code benchmarks HumanEva, MBPP and a software development benchmark SoftwareDev."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The idea of encodes SOPs of software development into LLM-based multi-agent systems is very interesting and also pracitical to use.\n2. The framework is very sound and solid, with Specialization of Roles, PRD workflow across Agents, Structured Communication for complex tasks, and a compute-efficient Message Pool mechanism with both global memory and Subscription Mechanism. It also introduces an executive feedback mechanism to enhance code generation quality during runtime. \n3. MetaGPT achieves state-of-art performance on multiple benchmarks such as HumanEva, MBPP and a software development benchmark SoftwareDev. It opens new possibility for the software development paradigm."
                },
                "weaknesses": {
                    "value": "1. Most of the experiment are on GPT4, which is expensive to access, how is the performance on the benchmarks or real development demands when used with open-source LLMs? Can you share some insight on which abilities of the LLMs matters most for the success of using this multi-agent framework and how to choose proper LLMs for use?"
                },
                "questions": {
                    "value": "1. Does the framework have strong generalizability when switched to GPT 3.5 or other open-source models? how far can the framework or practical use go with open-source models?\n2. In table 3, In this multi-agent collaboration with different roles, do you have some qualitive analysis or case study to show where each role contributes to the final performance, except for an executability score? Can you provide more detailed analysis?\n3. Whether the framework can also solve problems other than code, such as math and QA in Autogen? Is there other challenges for these kinds of problems for the framework?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5488/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698723559148,
            "cdate": 1698723559148,
            "tmdate": 1699636560713,
            "mdate": 1699636560713,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "DWesHFtBWb",
                "forum": "VtmBAGCN7o",
                "replyto": "a2Wdn7SSsA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5488/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5488/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your review! Authors' feedback."
                    },
                    "comment": {
                        "value": "We appreciate your valuable time and positive comments (i.e., **the idea of encoding SOPs of software development into LLM-based multi-agent systems is very interesting and also practical to use**, **the framework is very sound and solid**, **it opens new possibilities for the software development paradigm.**). In the following, we will carefully respond to your questions.\n\n---\n\n**Q1.  Can you share some insight on which abilities of the LLMs matter most for the success of using this multi-agent framework and how to choose proper LLMs for use?**\n\nIn our experience, coding tasks need GPT-4, while GPT-3.5 suffices for other tasks without obvious performance impact. We recommend using models fine-tuned for specific skills in future developments. For example, a model specialized in code generation can be an engineer's LLM, optimizing cost and role performance.\n\n---\n \n**Q2. Most of the experiments are on GPT4, which is expensive to access, how is the performance on the benchmarks or real development demands when used with open-source LLMs?  Does the framework have strong generalizability when switched to GPT 3.5 or other open-source models? how far can the framework or practical use go with open-source models?**\n\nFollowing your suggestions, we evaluated the HumanEval & MBPP datasets and a few SoftwareDev tasks to assess using GPT-3.5 and Deepseek Coder 33B as backends. The results indicate that although MetaGPT can complete tasks with these LLMs, using GPT-4 as the backend yields superior performance.\n\n\n|Model|HumanEvel|MBPP|\n|:--------------------|:----------------|:----------------|\n|GPT-3.5|$48.1$|$52.2$|\n|MetaGPT (w/ GPT-3.5)| $62.8 (+14.7)$|$74.7 (+21.5)$|\n|GPT-4| $67.0$|-|\n|MetaGPT (w/ GPT-4)|$85.9 (+18.4)$|$87.7$|\n\n\n| Model| Open source|Running time(s)|Total Code Lines|Executability |Human Revision Cost(times)|\n|---|---|:---:|:---:|:---:|:---:|\n|MetaGPT (w/ GPT-3.5)|\u2717|$75.18$|$161.6$|$2.8$|$2.4$|\n|MetaGPT (w/ GPT-4)|\u2717|$552.94$|$178.2$|$3.8$|$1.2$|\n|MetaGPT (w/ Deepseek Coder 33B)|\u2713|$1186.20$|$120.2$|$1.4$|$2.6$|\n\n---\n\n\n**Q3: In Table 3, In this multi-agent collaboration with different roles, do you have some qualitative analysis or case study to show where each role contributes to the final performance, except for an executability score? Can you provide more detailed analysis?**\n\nThank you for your comment. To illustrate, we'll use the task **'write a python3 GUI app which allows drawing images on it'** as an example (the intermediate processes involving full team members are detailed in Appendix B). Here, we provide a qualitative analysis of each role's contribution to the final performance.\n\nHere is the summary of the impact of removing certain agent roles:\n\n- **Without Architect:**\n  - An absence of detailed system design leads to structural and functional issues in coding, which affects the robustness of final product.\n  - Task decomposition lacks sufficient granularity.\n- **Without ProjectManager:**\n  - Missing module dependencies result in incomplete functionality and additional bugs.\n- **Without ProductManager:**\n  - Lack of function design and plan results in incomplete design and missing functionality, directly impacting the total number of files and generated code.\n\n\n---\n\n**Q4. Whether the framework can also solve problems other than code, such as math and QA in Autogen? Is there other challenges for these kinds of problems for the framework?**\n\nMetaGPT can address a variety of domain issues with minor implementation changes. While our current implementation (of submission) may not be ideal for specific tasks like Math and QA, we can quickly create specialized agents for these areas. Benefiting from MetaGPT's cost-effectiveness and adaptability in task modeling, we've successfully used it to replicate applications, including games like Minecraft [1] and Werewolf [2], and in roles like research assistants.\n\n[1] Wang G, Xie Y, Jiang Y, et al. \"Voyager: An open-ended embodied agent with large language models\". arXiv:2305.16291, 2023.\n\n[2] Xu Y, Wang S, Li P, et al. \"Exploring large language models for communication games: An empirical study on werewolf\". arXiv:2309.04658, 2023.\n\n---\n\n**We appreciate your time in reading our feedback and look forward to further discussion and your suggestions.**"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5488/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700429943732,
                "cdate": 1700429943732,
                "tmdate": 1700429943732,
                "mdate": 1700429943732,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qUr42RO1IH",
            "forum": "VtmBAGCN7o",
            "replyto": "VtmBAGCN7o",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5488/Reviewer_itRX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5488/Reviewer_itRX"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces MetaGPT, a meta-programming framework designed to enhance the efficiency and accuracy of large language model (LLM)-based multi-agent systems. By incorporating Standardized Operating Procedures (SOPs) into prompt sequences and adopting an assembly line approach, MetaGPT enables agents to specialize in diverse roles and collaboratively solve complex tasks with reduced errors. \n\nI believe this paper is interesting and makes a contribution by introducing an instrumental tool for automated code generation. I have several questions that I believe need to be addressed before publication. Aside from the questions below, my biggest concern is the relevance of the paper to Learning Representations. This paper mostly seems to be a nice fit for a journal focused on systems and applications.\n\n- It appears that this system needs existing expertise and strategy, correct? How primal/high-level the initial instructions can be? For instance, is a novice user going to have a hard time using this because they don\u2019t have enough knowledge about breaking an initial task into sub-steps?\n\n- Does the level of initial input from human affect the performance? For instance, if the human gives a very high-level input vs a more detailed, structured input instruction?\n\n- The human user side of the system is never discussed, although I believe it\u2019s very critical to understand the requirements, skills, knowledge, etc. the system imposes on or requires from a human user. The initial task or input instructions from the user are also never discussed.\n\n- The paper uses the term collaborative multi-agent systems, but later mentions that they define multi-agent frameworks as LLM-based multi-agent systems. I think the term collaborative multi-agent systems is very broad and comprehensive and it could be misleading to readers. The \u2018LLM-based\u2019 attribute of the multi-agent systems must be reflected in Title. Also, this leads to some misleading sentences such as \u201cMost of current multi-agent frameworks utilize natural language as a communication interface.\u201d Without using the term LLM-based multi-agent frameworks, this sentence is incorrect.\n\n- Is the shared communication/message pool interpretable to humans? Is it accessible by humans during or after the process?\n\n- Would the system ever need human interaction, or further input from human to address its potential questions?\n\n- There are multiple agents introduced in the system each with different roles, however, it is never discussed how are these specialized agents built or trained, algorithmically. Are they using specifically trained models?\n\n- Can there be multiple agents with the same role? i.e., multiple engineers that would work on different parts of implementations in parallel? How\u2019s the parallelization process performed? For example, if multiple engineers will be working different parts of the problem designated by the architect, how will they choose which part to work on? Is there priority assigned, or is there a decision-making problem being solved? Sometimes the order by which a problem is solved could significantly affect its efficiency.\n\n- What are some of the limitations of the system at its current stage? Limitations, both in the system and on the human user side must be discussed.\n\nAt current states I vote weak reject (mostly due to relevance), although the system seems to be sound and working. I need to see more discussions and revisions as suggested above, as well as suggested by my fellow reviewers to make this an ICLR-ready paper. I\u2019d be happy to increase my score when authors satisfactorily addressed the questions and comments."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "See above."
                },
                "weaknesses": {
                    "value": "See above."
                },
                "questions": {
                    "value": "See above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5488/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5488/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5488/Reviewer_itRX"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5488/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698742009299,
            "cdate": 1698742009299,
            "tmdate": 1700503750191,
            "mdate": 1700503750191,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tPBzbnJDRe",
                "forum": "VtmBAGCN7o",
                "replyto": "qUr42RO1IH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5488/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5488/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your review! Authors' feedback [1/2]."
                    },
                    "comment": {
                        "value": "We appreciate your time and positive feedback (for examples, **\"I believe this paper is interesting and makes a contribution by introducing an instrumental tool for automated code generation. I have several questions that I believe need to be addressed before publication.\")**. We will carefully answer your questions one by one.\n\n---\n\n**Q1. Aside from the questions below, my biggest concern is the relevance of the paper to Learning Representations.**\n\nOur work aligns with the objectives of the tolerant ICLR community and focuses on the topic [1] \u2013 applications in robotics, autonomy, and planning. Similar papers have been accepted in related communities [2,3,4].  \n\n[1] https://iclr.cc/Conferences/2024/CallForPapers\n\n[2] Zeng A, Attarian M, Ichter B, et al. \"Socratic models: Composing zero-shot multimodal reasoning with language\". In ICLR, 2023.\n\n[3] Li G, Hammoud H A A K, Itani H, et al. \"Camel: Communicative agents for\" mind\" exploration of large scale language model society\". In NeurIPS, 2023.\n\n[4] Yao S, Zhao J, Yu D, et al. \"React: Synergizing reasoning and acting in language models\". In ICLR, 2022.\n\n---\n\n**Q2**. **(1) It appears that this system needs existing expertise and strategy, correct? (2) How primal/high-level the initial instructions can be? For instance, is a novice user going to have a hard time using this because they don\u2019t have enough knowledge about breaking an initial task into sub-steps?**\n\n(1) For developers, it's correct that multi-agent frameworks typically require humans to pre-define the agents (which need existing expertise and strategy). However, for users, we have already completed these definitions, enabling users to generate software directly without significant barriers.\n\n(2) There is no need to break down an initial task; users can use very basic instructions, such as 'design a Flappy Bird game' or 'write a Python3 GUI app where you can draw an image', etc. The subsequent processes are automated by MetaGPT, making it user-friendly. Additional examples can be found in rows 0-2, 4, 9-10 of Table 5 (Appendix), with their corresponding performances outlined in Table 6 (Appendix).\n\n---\n\n**Q3. Does the level of initial input from human affect the performance? For instance, if the human gives a very high-level input vs a more detailed, structured input instruction?**\n\nThanks for these valuable comments. We conduct additional experiments to verify your questions. Here, we first give two examples of prompts:  \n* **High-level prompt**: `Create a brick breaker game.`\n* **Detailed prompt**: `Creating a brick breaker game. In a brick breaker game, the player typically controls a paddle at the bottom of the screen to bounce a ball towards a wall of bricks. The goal is to break all the bricks by hitting them with the ball.`\n\nWe select 5 tasks from SoftwareDev, and construct detailed prompts for them. Here are the experimental results:\n\n|$\\textbf{Model}$|$\\textbf{Num. of word}$|$\\textbf{Running time(s)}$|$\\textbf{Token usage}$|$\\textbf{Total Code Lines}$|$\\textbf{Executability}$|$\\textbf{Productivity}$|$\\textbf{Human Revision Cost}$|\n|---|---|---|---|---|---|---|---|\n|$\\textbf{High-level prompt}$|$13.2$|$552.9$|$28384.2$|$178.2$|$3.8$|$163.8$|$1.2$|\n|$\\textbf{Detailed prompt}$  |$42.2$|$567.8$|$29657.0$|$257.0$|$4.0$|$118.0$|$1.6$|\n\nWe observe that: **detailed prompts lead to better software projects with lower productivity ratios because of clearer requirements and functions, while simple inputs can still generate good enough software using MetaGPT with an executability rating of 3.8, which is comparable to the detailed prompt scenario.** (Note that, Productivity = Token usage / Total Code Lines. The lower this ratio, the better.)\n\n---\n\n**Q4. The human user side of the system is never discussed, although I believe it\u2019s very critical to understand the requirements, skills, knowledge, etc. the system imposes on or requires from a human user. The initial task or input instructions from the user are also never discussed.**\n\nThanks, this is a very valuable comment. We will add our responses in **Q3** and **Q4** to fill this gap in the manuscript.\n\n---\n\n**Q5. The \u2018LLM-based\u2019 attribute of the multi-agent systems must be reflected in the Title. Also, this leads to some misleading sentences such as \u201cMost of current multi-agent frameworks utilize natural language as a communication interface.**\n\nThank you for pointing out this issue. As pointed out in related work: ``We refer to multi-agent frameworks as LLM-based multi-agents and distinguish them from previous settings (Schmidhuber, 1999; Busoniu et al., 2008)''. **We agree with you that we need to change the illustration of the misleading sentence to \"Most of the current LLM-based multi-agent frameworks...\"** For the title, we will use \"MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework\" to make it clear that MetaGPT is one (and one kind) of the multi-agent collaborative frameworks."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5488/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700430122252,
                "cdate": 1700430122252,
                "tmdate": 1700430122252,
                "mdate": 1700430122252,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YSuZ7JigyJ",
                "forum": "VtmBAGCN7o",
                "replyto": "qUr42RO1IH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5488/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5488/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your review! Authors' feedback [2/2]."
                    },
                    "comment": {
                        "value": "**Q6. Is the shared communication/message pool interpretable to humans? Is it accessible by humans during or after the process?**\n\nDuring the running, **humans can actively watch the inputs and outputs of each role in the terminal.** MetaGPT also automatically saves the intermediate files, such as PDFs, PNGs, Python code, etc., during the execution. Humans can easily access them after the process.\n\n---\n\n**Q7. Would the system ever need human interaction, or further input from human to address its potential questions?**\n\nThis is a good question. In our design, **in order to strengthen full automation (honestly speaking, it is more appealing)**, we proactively ignored human interactions. However, **we also provide an interface, and humans can easily interact with MetaGPT if they want**, such as helping to debug the code or revise the PRD. In terms of techniques, it is not hard to achieve.\n\n---\n\n**Q8. There are multiple agents introduced in the system each with different roles, however, it is never discussed how are these specialized agents built or trained, algorithmically. Are they using specifically trained models?**\n\nRegarding the construction of agents, we define each role's profile, name, goal, and constraints, while also initializing their specific context and skills, which is stated in the first paragraph Sec. 3.1 and illustrated in Figure 2 (right). We employ GPT-4 as the only trained model and the default LLM backend for all agents. It is noteworthy that, in terms of experiment cost, other open-source LLMs can be used flexibly in MetaGPT, such as using CodeX [5] for Engineers.\n\n[5] Chen M, Tworek J, Jun H, et al. \"Evaluating large language models trained on code\". arXiv:2107.03374, 2021.\n\n---\n\n**Q9. Can there be multiple agents with the same role? i.e., multiple engineers that would work on different parts of implementations in parallel? How\u2019s the parallelization process performed? For example, if multiple engineers will be working different parts of the problem designated by the architect, how will they choose which part to work on? Is there priority assigned, or is there a decision-making problem being solved? Sometimes the order by which a problem is solved could significantly affect its efficiency.**\n\nThank you for bringing up a professional question. In our earlier version, we incorporated a simplified approach to handle multiple engineers working on the same project. Although different agents could write different code files simultaneously, it didn't necessarily guarantee an improvement in the overall output quality of the project. We agree that processing dependencies between files and modules poses a more complex decision-making problem.\n\n---\n\n**Q10. What are some of the limitations of the system at its current stage? Limitations, both in the system and on the human user side must be discussed.**\n\n1) **System side**: At present, our system cannot fully cater to specific scenarios, such as UI and front-end, as we have yet to incorporate such agents and multimodal tools. Furthermore, despite generating the most amount of code among comparable frameworks, it remains challenging to fulfill real-world applications' diverse and complex requirements.\n\n2) **Human user side**: A key challenge for users is to interrupt the running process of each agent, or set the starting running point (checkpoint) for each agent.  \n\n---\n\n**We appreciate your time in reading our feedback and look forward to further discussion and your suggestions.**"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5488/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700430283223,
                "cdate": 1700430283223,
                "tmdate": 1700430283223,
                "mdate": 1700430283223,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JFCCoEZCJ6",
                "forum": "VtmBAGCN7o",
                "replyto": "YSuZ7JigyJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5488/Reviewer_itRX"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5488/Reviewer_itRX"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "Thank you to authors for clarifying. I also appreciate the additional experiments and results which add to the value of their work. I also read the comments by my fellow reviewers and overall, I'm positively satisfied and vote for acceptance. I raised my score accordingly. Congratulations to the authors for their great work and, good luck!"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5488/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700503710579,
                "cdate": 1700503710579,
                "tmdate": 1700503710579,
                "mdate": 1700503710579,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "haoCfWsayk",
            "forum": "VtmBAGCN7o",
            "replyto": "VtmBAGCN7o",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5488/Reviewer_WkUQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5488/Reviewer_WkUQ"
            ],
            "content": {
                "summary": {
                    "value": "MetaGPT is a framework designed for programming in multi-agent collaborative environments, specifically utilizing the Large Language Model (LLM). Its main contribution is the integration of human workflows into LLM-based multi-agent collaboration, which is effective for complex software engineering tasks. The framework assigns different roles to the GPT model, similar to a pipeline in software development, including roles such as product manager, architect, and engineer. Its main advantage lies in generating coherent solutions and decomposing complex tasks through the collaboration of multiple AI agents."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Problem-solving: MetaGPT can solve complex tasks by using different AI agents to handle different parts of the problem.\n\n2. Clear solutions: MetaGPT provides sensible solutions that favor tasks that require different elements to work together seamlessly.\n\n3. Flexibility: MetaGPT can be used for different tasks, and provide multiple outputs ranging from project plans to technical documentation."
                },
                "weaknesses": {
                    "value": "1. Methodological innovation: A key issue with MetaGPT is the lack of innovation in its methodology. While it effectively utilizes Large Language Models (LLMs) in multi-agent systems, this approach may not be significantly different from existing approaches. Or MetaGPT is different from other methods in a trivial way, I don't really see their differences as being significant and requiring exploration with greater depth.\n\n2. Fairness of experimental comparisons: The comparison methods used to assess the effectiveness of MetaGPT do not appear to be fully equivalent to what MetaGPT offers. Such differences may lead to biased or misleading conclusions about their superiority or efficiency.\n\n\n3. Experimental validation of statements: Current experiments may not adequately validate the authors' claims about the efficiency and robustness of MetaGPT."
                },
                "questions": {
                    "value": "1. My primary concern is that MetaGPT lacks methodological and theoretical innovation. To gain a more innovative edge, MetaGPT could deeply explore what deep-seated challenges in integrating newer AI techniques or unique collaboration strategies make it more clearly distinguishable from other LLM-based frameworks. (Honestly, I think MetaGPT is more suited for system demonstration conferences or tracks)\n\n2. In the Introduction, \"MetaGPT stands out as a special solution that allows efficient meta-programming through a well-organized and specialized group of agents\". How does the author define these professional concepts? For example, \"efficient\" and \"well-organized\".1) I haven't seen any evidence or convincing analysis of why it can be \"efficient\", nor have I seen experimental validation.2) How do you define \"specialized group\"? This seems trivial and can be varied.\n\n3. In the Introduction, \"MetaGPT achieves a 100% task completion rate, further demonstrating the robustness and efficiency of our design\", and \"Our innovative integration of human-like SOPs throughout MetaGPT\u2019s design significantly enhances its robustness\". 1) What is the definition of \"robustness\" here? I didn't see any discussion of \"robustness\" except in the Introduction section. 2) What are the deeper methodological challenges of integrating human-like SOPs?\n\n4. In the Related Work, \"In this paper, we identify the main challenges in multi-agent cooperation: maintaining consistency, avoiding unproductive cycles, and controlling beneficial interactions\". There seems to be inconsistency in the description of the research challenges between the \"Related Work\", the \"Introduction\" and the rest of the paper. Furthermore, is it trivial to maintain consistency in MetaGPT?\" What are the professional definitions of \"unproductive cycle\" and \"beneficial\"? Are there experimental results to validate these advantages?\n\n5. In the Experiments, \"We compare recent domain-specific LLMs in the code generation field ...\" Is it fair to compare with these LLMs?\n\n6. In the Experiments, \"We modified certain role-based prompts in order to instruct the MetaGPT framework to generate individual functions instead of entire classes\" 1) Is it fair to compare with these frameworks? LangChain and AutoGPT, for example, which are not specific to the tasks involved in this commit. 2) How can we ensure that \" prompt modification\" does not lead to unfair comparisons?\n\n7. Figure 4. What are the results of multiple attempts and are they stable? Were there any problems, like robustness?\n\n8. In Section 4.2, what is \"the cost of human revision\" and how can it be rigorously measured?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Other reasons (please specify below)"
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "This submission does not discuss any potential ethical issues, which I think is uncritical, especially for generative AI technologies. There are potential privacy, security, and bias issues that accompany the collection, processing, and use of data, exchange between agents, communication, and so on, in open-ended tasks with multi-person collaboration. For example, I perceive at least the following concerns and considerations.\n\n1. Unemployment and skill obsolescence: Automation of complex tasks in software engineering and other fields may lead to job losses. Professionals in these fields may need to adapt and acquire new skills to remain relevant. How to manage and communicate these changes is an ethical issue.\n\n2. Transparency and accountability: As AI takes on more complex collaborative tasks, it becomes critical to maintain transparency in decision-making. It should be clear how MetaGPT arrives at solutions and who is accountable for those decisions, especially in critical applications.\n\n3. Privacy and data security: The use of large-scale language models and AI in processing potentially sensitive information raises concerns about data privacy and security. Ensuring that user data is protected and used ethically is a key consideration."
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5488/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5488/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5488/Reviewer_WkUQ"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5488/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699739370167,
            "cdate": 1699739370167,
            "tmdate": 1699739370167,
            "mdate": 1699739370167,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "de8yQDQOPS",
                "forum": "VtmBAGCN7o",
                "replyto": "haoCfWsayk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5488/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5488/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your review! Authors' feedback [1/3]."
                    },
                    "comment": {
                        "value": "We appreciate your valuable time, insights, and highlight our strengths (i.e., **problem-solving**, **clear solutions**, and **flexibility**). We'll address your concerns in our following response.\n\n---\n\n**Q1 (original W1). Methodological innovation: How does MetaGPT differ from other methods?**\n\n> 1) **Agents in SOPs**: MetaGPT pioneers the introduction of SOPs (Standard Operating Procedures), a departure from works like CAMEL [2], which don't discuss task-specific labor division. Unlike generative agents [1] that simulate open-world human behavior freely, MetaGPT focuses more on applying valuable human practice and better organizing multiple agents.  \n> 2) **Structured communication v.s. Chat-based communication**: Sec 3.2 highlights how MetaGPT, unlike other chat-based communication models such as ChatDev [3], Self-collaboration [4], and CAMEL [2], introduces structured communication. MetaGPT limits the range of message content, focusing agents on relevant information and avoiding meaningless conversational chat. Consequently, this approach reduces token usage and enhances task success rates.\n\n[1] Park, Joon Sung, et al. \"Generative agents: Interactive simulacra of human behavior.\" In UIST, 2023.\n\n[2] Li, Guohao, et al. \"CAMEL: Communicative Agents for\" Mind\" Exploration of Large Language Model Society.\" In NeurIPS, 2023.\n\n[3] Qian, Chen, et al. \"Communicative agents for software development.\" arXiv:2307.07924, 2023.\n\n[4] Dong Y, Jiang X, Jin Z, et al. \"Self-collaboration Code Generation via ChatGPT.\" arXiv:2304.07590, 2023.\n\n---\n\n**Q2 (Original Q1). Deep-seated challenges.**\n\nMetaGPT also alleviates or solves these challenges with its unique designs:  \n1) **Use Context Efficiently**: Two sub-challenges are present. First, unfolding short natural language descriptions accurately to eliminate ambiguity. Second, maintaining information validity in lengthy contexts, enables LLMs to concentrate on relevant data without distraction.\n2) **Reduce Hallucinations**:  Using LLMs to generate entire software programs faces code hallucination problems\u2014-including incomplete implementation of functions, missing dependencies, and potential undiscovered bugs, which may be more serious than hallucinations in natural language generation. Deep-seated challenges in task decomposition and translating from natural language to code language persist. LLMs often struggle with software generation due to vague task definitions. Focusing on granular tasks like requirement analysis and package selection offers guided thinking, which LLMs lack in broad task solving.\n\n---\n\n**Q3 (Original W2, Q5, Q6). The comparison methods used to assess the effectiveness of MetaGPT do not appear to be fully equivalent to what MetaGPT offers. **(1)** \"We compare recent domain-specific LLMs in the code generation field ...\"; **(2)** \"We modified certain role-based prompts in order to instruct the MetaGPT framework to generate individual functions instead of entire classes. Is it fair to compare with these frameworks? LangChain and AutoGPT? How can we ensure that prompt modification does not lead to unfair comparisons?\"**\n\nThanks for pointing these out, but these are misunderstandings.\n**(1) Both the baselines and MetaGPT are conducted under the same settings.** We acknowledge that comparing MetaGPT with single LLMs may seem partially unfair. However, our goal is to help readers quickly grasp the advancements in this field, where both LLMs (PaLM Code vs. GPT-4) and methodologies (Codex vs. Codex+CodeT) are essential. The most important point here is \"When MetaGPT collaborates with GPT-4, it substantially improves the Pass@1 in the HumanEval benchmark, exceeding the performance of GPT-4 alone\" as stated in the manuscript.\n**(2) In the SoftwareDev dataset, we maintain fully equivalent settings for a fair comparison with AutoGPT, LangChain, and ChatDev.** In HumanEval and MBPP, we've slightly modified the prompts to align with response format requirements. These modifications aim to address format-specific issues (i.e., Python problems). To enhance clarity in our manuscript, we propose adding 'In HumanEval and MBPP' at the beginning of Sec 4.1.\n\n---\n\n**Q4 (Original Q3). Statements: \"MetaGPT achieves a 100% task completion rate, further demonstrating the robustness and efficiency of our design\", and \"Our innovative integration of human-like SOPs throughout MetaGPT's design significantly enhances its robustness\". What is the definition of \"robustness\" here?**\n\n**Robustness** refers to the ability to generate software codes that can complete various tasks with consistent quality and adhere to specific designs. \uff08Figure 5 & Table 6\uff09Existing experiments support these claims. For example: 1) In Figure 5, we display many demos generated by MetaGPT, demonstrating its robustness to generate different software. 2) In Table 4 & Table 6 (Appendix), we have shown that MetaGPT can generate high-quality software aligned with expectations.\n\n---"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5488/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700430695174,
                "cdate": 1700430695174,
                "tmdate": 1700430695174,
                "mdate": 1700430695174,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cpQTIuAITg",
                "forum": "VtmBAGCN7o",
                "replyto": "haoCfWsayk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5488/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5488/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your review! Authors' feedback [2/3]."
                    },
                    "comment": {
                        "value": "**Q5 (Original Q2). Statements: \"MetaGPT stands out as a special solution that allows efficient meta-programming through a well-organized and specialized group of agents\". How does the author define these professional concepts? For example, \"efficient\" and \"well-organized\". **(1)** I haven't seen any evidence or convincing analysis of why it can be \"efficient\", nor have I seen experimental validation. **(2)** How do you define \"specialized group\"?**\n\n**(1) Existing experiments validate our claims.** In Table 1, we show \"efficiency\" with lower Running Times (762 vs. 541 seconds) than ChatDev, using identical instructions for software generation. We also report higher Productivity (token usage/total code lines), with our figures at 248.9 vs. 124.3, using half as many tokens per code line.\n\n|Model|Running Times (/seconds)|Productivity (token usage/total code lines)|\n|---|---|---|\n|ChatDev|$762$|$248.9$|\n|MetaGPT|$541$|$124.3$|\n\n**(2)** In our context, a **'specialized group'** refers to a group of agents where each agent is assigned specific roles with unique tools and skills. This ensures efficient task execution and collaboration. **For instance, the ProductManager can summarize instructions and write product requirement documents (as in Figure 1), whereas the Engineer focuses on code execution and debugging with coding tools.** In MetaGPT, different roles can also output specialized files in PDF, PNG, and Python formats, and users can directly view them.\n\n---\n\n**Q6 (Original Q4). Is it trivial to maintain consistency in MetaGPT? What are the professional definitions of \"unproductive cycle\" and \"beneficial\"? Are there experimental results to validate these advantages?**\n\n* 1) **Consistency:** Maintaining consistency is not trivial and presents a challenge in many applications, as highlighted in work [1,2,3]. MetaGPT addresses this by breaking down tasks into granular sub-tasks, enabling each agent to gain a deeper understanding of their specific responsibilities. This approach is crucial, particularly in function design and coding requirements for downstream agents (e.g., Engineer), to prevent misunderstandings or error propagation during collaboration using LLMs.  \n* 2) **Unproductive cycles:** In work [2], it's noted that two cooperating agents often face challenges like the 'Assistant Repeats Instruction' problem or the 'Infinite Loop of Messages'. These issues emerge from repetitive, context-less conversations leading to unproductive exchanges, such as repeatedly saying \"Goodbye\". Reference [4] discusses an issue where agents become stuck in a loop while addressing complex or ambiguous tasks, chaining thoughts in a behavior-like pattern. We can improve the quality of code generation by reducing unproductive cycles through SOPs, as described in Table 1.  \n* 3) **Beneficial interactions:** Previous work [5] highlights the requirements engineering in software development, particularly abstraction and decomposition, significantly improving code generation. Constraints also improve LLMs' understanding of fuzzy, abstract, and multitasking semantics [6]. Thus, we introduced a structural communication protocol to assist agents in task decomposition and semantic understanding, aiming to minimize ambiguities and errors, fostering beneficial interactions.\n\nWhen reproduced to other frameworks, we found that these issues occur frequently. The SOPs and communication mechanisms in MetaGPT can alleviate these issues, thus achieving better performances (see Table 1, Table 2, Table 4).\n\n[1] Elazar Y, Kassner N, Ravfogel S, et al. \"Measuring and improving consistency in pretrained language models\". TACL, 2021.\n\n[2] Li, Guohao, et al. \"CAMEL: Communicative Agents for\" Mind\" Exploration of Large Language Model Society.\" In NeurIPS, 2023.\n\n[3] Wang X, Wei J, Schuurmans D, et al. \"Self-consistency improves chain of thought reasoning in language models\". arXiv:2203.11171, 2022.\n\n[4] Talebirad Y, Nadiri A. \"Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents\". arXiv:2306.03314, 2023.\n\n[5] Jiang X, Dong Y, Wang L, et al. \"Self-planning code generation with large language model\". arXiv:2303.06689, 2023.\n\n[6] Shin R, Lin C H, Thomson S, et al. \"Constrained language models yield few-shot semantic parsers\". arXiv:2104.08768, 2021.\n\n\n---\n\n**Q7 (Original Q8). In Section 4.2, what is \"the cost of human revision\" and how can it be rigorously measured?**\n\n**Human revision** refers to times of manual code corrections, which tackle problems like package import errors, incorrect class names, or incomplete reference paths. Typically, each correction involves up to 3 lines of code. To minimize subjectivity, we enlisted three individuals (paid at a rate equivalent to a minimum of 15 USD per hour) to document their debugging process.\n\n---"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5488/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700430732595,
                "cdate": 1700430732595,
                "tmdate": 1700655187032,
                "mdate": 1700655187032,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KtkuUb98rm",
                "forum": "VtmBAGCN7o",
                "replyto": "haoCfWsayk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5488/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5488/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your review! Authors' feedback [3/3]."
                    },
                    "comment": {
                        "value": "**Q8 (Original Q7): Figure 4. What are the results of multiple attempts and are they stable? Were there any problems, like robustness?**\n\n1) **According to this comment, we conduct GPT-4 and GPT-3.5 experiments on HumanEval and MBPP.** For GPT-4, upon reviewing the results, we observe that MetaGPT has a lower standard deviation of 0.498% for HumanEval, while MBPP experiences a higher standard deviation of 0.862%. Most variation in MBPP results from inaccurate test case generation due to a lack of input examples, resulting in passing tests but failing actual results. MetaGPT can produce robust results for these benchmarks.\n\n2) **Compared to GPT-4, GPT-3.5-turbo has a higher standard deviation (more unstable)** in both HumanEval and MBPP.\n\n|||GPT-4||||GPT-3.5|||\n|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n||HumanEval|| MBPP-sanitized ||HumanEval|| MBPP-sanitized||\n||Attempts|Pass@$1$(%)|Attempts|Pass@$1$(%)|Attempts|Pass@$1$(%)|Attempts|$Pass@$1$(%)|\n||$1$|$86.0$|$1$|$87.6$|$1$|$61.6$|$1$|$75.9$|\n||$2$|$84.8$|$2$|$86.7$|$2$|$64.0$|$2$|$74.5$|\n||$3$|$85.4$|$3$|$85.5$|$3$|$62.8$|$3$|$73.8$|\n||$\\textbf{avg}$(%)|$85.4$|$\\textbf{avg}$(%)|$86.6$|$\\textbf{avg}$(%)|$62.8$|$\\textbf{avg}$(%)|$74.7$|\n||$\\textbf{std}$(%)|$0.490$|$\\textbf{std}$(%)|$0.860$|$\\textbf{std}$(%)|$0.980$|$\\textbf{std}$(%)|$0.873$|\n\n\n---\n\n**Q9 (Original Details Of Ethics Concerns). Discuss any potential ethical issues.**\n\n\nThanks for pointing this out. We will include an additional potential ethical section in the Appendix: \n1) **Unemployment and Skill Obsolescence**: MetaGPT enables more people to program in natural languages, thereby making it easier for engineers to get started. Over the years, programming languages have evolved from punched cards to assembly, C, Java, Python, and now natural language. As a result, humans have become more proficient at programming, increasing the demand for programming-related positions. Furthermore, programming with natural language may offer a significantly easier learning curve, making programming more accessible to a broader audience.\n2) **Transparency and Accountability**: MetaGPT is an open-source framework that facilitates interactive communication between multiple agents through natural language. Humans can initiate, observe, and stop running with the highest level of control. It provides real-time interpretation and operation of the natural language, displayed on the screen and logs, ensuring transparency. MetaGPT enhances \"natural language programming\" capabilities, and human engineers are the users and responsible for the outcomes.\n3) **Privacy and Data Security**: MetaGPT operates locally, ensuring user data privacy and security. It does not collect user data. For interactions with third-party LLMs, such as those by OpenAI, users are encouraged to refer to the respective privacy policies (e.g., OpenAI Privacy Policy). However, we provide the option of open-source LLMs as backends.\n\n---\n\n**We appreciate your time in reading our feedback and look forward to further discussion and your suggestions.**"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5488/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700430784799,
                "cdate": 1700430784799,
                "tmdate": 1700430784799,
                "mdate": 1700430784799,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]