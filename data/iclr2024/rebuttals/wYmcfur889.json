[
    {
        "title": "Data Prediction Denoising Models: The Pupil Outdoes the Master"
    },
    {
        "review": {
            "id": "eQuHhPY5QQ",
            "forum": "wYmcfur889",
            "replyto": "wYmcfur889",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5134/Reviewer_gGZJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5134/Reviewer_gGZJ"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses the performance drop in DMs with limited sampling steps, attributing it to the weak denoisers used in their training. To mitigate this issue, the authors introduce the Data Prediction Denoising Model (DPDM), a multi-step generative model that outperforms DMs with few sampling steps. DPDM enhances data recovery capabilities by minimizing distribution divergence, which results in stronger denoisers capable of better recovering data distributions from noisy data. A corresponding sampling algorithm, DPDM sampler, is introduced to generate samples from DPDMs."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1) The paper addresses a useful and practical issue with Diffusion Models (DMs). The research is novel and the exposition is clear and well-structured. \n2) The paper begins with a clear and well-supported empirical observation regarding the performance drop in DMs when the number of sampling steps is limited. The paper introduces the Data Prediction Denoising Model (DPDM) as a novel approach to address the limitations of DMs. DPDM is designed to enhance data recovery abilities, and its effectiveness is rigorously demonstrated through experiments.\n3) The paper provides some mathematical foundation for DPDM by emphasizing the importance of minimizing distribution divergence. This adds depth and theoretical support to the proposed model.\n4) The paper goes beyond presenting DPDM and conducts extensive comparisons with existing multi-step generative models."
                },
                "weaknesses": {
                    "value": "1) While the paper claims to solve a practical problem by needing less compute resources for sampling compared to DMs. However, training DPDMs require an auxiliary diffusion model, a retrained DM and a multi-step denoiser model which may bring additional memory costs and training time requirements.\n2) The paper predominantly focuses on low-resolution image generation tasks, such as 64x64 pixel images. While it demonstrates the effectiveness of DPDM in this context, it does not explore or provide results for higher-resolution image generation or other types of data generation tasks.\n3) Minor comment: When NFE is first introduced in Page 2, the full form is not mentioned. Please include this in the revised version to improve readability."
                },
                "questions": {
                    "value": "While the paper is generally well-written, I have the following questions.\n\n1) Can the authors demonstrate the results for generating higher resolution images such as 256x256 or higher and how DPDMs compare with DMs?\n2) Can the authors comment on the training and inference times and compute requirements for DPDMs and comparable DMs?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5134/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698688007544,
            "cdate": 1698688007544,
            "tmdate": 1699636506476,
            "mdate": 1699636506476,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JlAlMrHqmY",
                "forum": "wYmcfur889",
                "replyto": "eQuHhPY5QQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5134/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5134/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for liking our work!"
                    },
                    "comment": {
                        "value": "Thank you for liking our work, we will incorporate your wonderful suggestions in the revision. We will address your concerns one by one in the following paragraphs.\n\n**Q1**. training DPDMs requires an auxiliary diffusion model, a retrained DM, and a multi-step denoiser model which may bring additional memory costs and training time requirements.\n\n**A1**. We appreciate your keen intuition. We acknowledge that the additional diffusion model ($\\boldsymbol{s}_ \\phi$ in Algorithm 1) brings additional memory cost. However, this additional memory cost is limited because the memory bottleneck of training lies in the computational graph of the backpropagation, instead of only saving one more model. In DPDM's training, the auxiliary model $\\boldsymbol{s}_ \\phi$ and the model $\\boldsymbol{d}_ \\theta$ are updated alternatively, which means that the other model's parameters are fixed and do not participate in back-propagation when one model is being updated. So the memory cost for back-propagating through the computational graph is almost the same as one model. To quantitatively measure how much additional computational costs are brought in, we compare DPDM's training with another multi-step model, the consistency model (consistency distillation, CD) in terms of memory and computational costs in Table 6 in the Appendix of the submission.\n\n**Table 6** shows that DPDM brings in minor additional memory costs than CD (10.40 over 9.55). This is because the DPDM only needs additional GPU memory to save the auxiliary model. But $\\boldsymbol{s}_\\phi$ and $\\boldsymbol{d}_ \\theta$ are updated alternatively, so their computational graph does not interact. As a result, the memory bottleneck caused by computational graphs and back-propagation does not bring more costs to DPDM.\n \nAs for the wall-clock time for 1K iterations, we see that DPDM costs 0.0728 seconds, while the CD costs 0.0489 seconds. This is because each iteration of DPDM consists of two alternate steps as we show in Algorithm 1. Overall, the DPDM costs almost the same GPU and CPU memory as the baseline CD, but about 1.5 times wall-clock time than the CD for each iteration. \n\n**Q2**. it does not explore or provide results for higher-resolution image generation or other types of data generation tasks. Can the authors demonstrate the results for generating higher resolution images such as 256x256 or higher and how DPDMs compare with DMs?\n\n**A2**. We appreciate your suggestions on larger-scale experiments such as high-res image modeling or text2img generation. However, these experiments demand substantial computational resources beyond our current reach. For example, training a Stable Diffusion t2i model consumes a cloud cluster with 256 Nvidia A100 GPUs for about 150,000 hours, costing a total of about 600,000 USD, which is far beyond our financial affordance. However, in this work, we have demonstrated strong performances of DPDM on standard benchmarks, and we are glad to try to explore the possibility of scaling DPDM to larger-scale tasks such as high-res data generation and t2i generative models within our financial permissions.\n\n**Q3**. Can the authors comment on the training and inference times and compute requirements for DPDMs and comparable DMs?\n\n**A3**. The training of DPDM starts with an initialization of a pre-trained DM. We take the CIFAR10 dataset as a demonstration. Empirically, a DM on the CIFAR10 dataset is supposed to converge on 4 Nvidia-V100 GPUs within 2 wall-clock days. Starting from a pre-trained DM, we empirically find that a DPDM converges within 12 hours. Therefore, if we already have a DM, the total training time of DPDM is about 1/8 of a DM. If we do not have a pre-trained DM, therefore, we are supposed to first pre-train a DM and then train a DPDM. The total time for training DPDM from scratch costs about 9/8 of diffusion models. \n\nAs for the inference. We implement the DPDM with the same architecture as the diffusion model (i.e. a weight-sharing network $\\boldsymbol{d}_\\theta(x_t,t)$ to parametrize multiple denoisers), therefore, the inference cost per step of DPDM is the same as the diffusion model, so NFE is a fair metric for evaluating the inference efficiency when comparing DPDM and the DM. **Table 4** in the submission has a relatively clear comparison of the inference efficiency of DPDM and DM. In Table 4, the FID value of DPDM converges below 3.0 (which is regarded as a line of good performance) with 6 NFEs, on the contrary, the baseline diffusion model's FID is still larger than 3.0 with even 18 NFEs. Since both models have the same cost for each NFE, we conclude that the DPDM is about 3 times more efficient than diffusion models for few-step generations.\n\nWe really thank you for your useful suggestions on notations and clarifications which we will incorporate in the revision. We hope our answers can resolve your concerns."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5134/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699939252435,
                "cdate": 1699939252435,
                "tmdate": 1699939252435,
                "mdate": 1699939252435,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "V3AYFAqsLU",
            "forum": "wYmcfur889",
            "replyto": "wYmcfur889",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5134/Reviewer_twcE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5134/Reviewer_twcE"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces an algorithm to train a denoiser given a pre-trained diffusion model, use the denoiser to sample an image, and shows that this method is better than general diffusion on small sampling steps."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- A new algorithm to accelerate the diffusion sampling.\n- Excellent results on small sampling step."
                },
                "weaknesses": {
                    "value": "With my carefully proofreading, I still suffer from understanding the key idea of this paper. From what I understand, this paper aims to train a separate denoiser such that (1) the denoiser can predict a clean image from noisy image, and (2) when Gaussian noise is added to the predicted clean image, the distribution of the new noisy image is consistent to that of the noisy images used to train the diffusion model. However, training this separate denoiser is the same with the training loss of the original diffusion model. From this aspect, it seems like this idea is more like a fine-tuning (or just training it longer) method. I cannot follow why such a fine-tuning idea is effective when having small sampling step. Could the author clarify this point?\n\nThe sampling method considers the clean image as the mean of the next step distribution, which contradicts the theoretical analysis of DDPM. Could the author also justify this point? \n\nMoreover, this paper claims it provides a solid mathematical foundation for the proposed method, which is unclear what that means."
                },
                "questions": {
                    "value": "Need justification and more explanation of the proposed method. (see the weakness)"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5134/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5134/Reviewer_twcE",
                        "ICLR.cc/2024/Conference/Submission5134/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5134/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698714486704,
            "cdate": 1698714486704,
            "tmdate": 1700699947220,
            "mdate": 1700699947220,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "nMP1Lt3gQK",
                "forum": "wYmcfur889",
                "replyto": "V3AYFAqsLU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5134/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5134/Authors"
                ],
                "content": {
                    "title": {
                        "value": "DPDM is totally different from diffusion models."
                    },
                    "comment": {
                        "value": "Thank you for your reviews. We will address your concerns one by one in the following paragraphs. Before that, we first give a summary of the main contributions of our work.\n\nIn this work, we propose a novel stand-alone generative model termed the Data-prediction denoising model (DPDM), which achieves significantly better generative performance than baseline diffusion models under the few-step sampling settings. We characterize the training process of DPDM through a novel smoothed KL divergence minimization formulation which results in significantly stronger data-recovery ability than the baseline diffusion model. \n\nNext, we address your concerns one by one.\n\n**Q1**. However, training this separate denoiser is the same as the training loss of the original diffusion model. From this aspect, it seems like this idea is more like a fine-tuning (or just training it longer) method. I cannot follow why such a fine-tuning idea is effective when having a small sampling step. Could the author clarify this point?\n\n**A1**. First, we would like to emphasize that our baseline EDM diffusion model is obtained from official checkpoints which are trained till convergence. Second, we would like to emphasize that the training objective of DPDM is totally different from the diffusion model's training. Therefore, the training of DPDM has no relation to fine-tuning with diffusion model loss function. \n\nMore precisely, the training objective of the diffusion model is Equation 3.1, which encounters an L2 minimization to train weak denoisers. On the contrary, the DPDM is based on minimizing a novel smoothed KL divergence between the denoiser distribution and the ground truth data distribution. To minimize the smoothed KL for multi-level denoisers, we derive an explicit gradient formula of the denoisers' parameter $\\theta$ with respect to a combination of the smoothed KL divergences, i.e. Equation 3.4. Overall, we propose a practical algorithm 1, which implements such a divergence minimization formulation to obtain stronger denoisers. \n\n**Q2**. The sampling method considers the clean image as the mean of the next step distribution, which contradicts the theoretical analysis of DDPM. Could the author also justify this point?\n\n**A2**. We do not clearly understand what you mean by contradicting the theoretical analysis of DDPM. As far as we guess, we assume you have mistaken our sampling algorithm 2 as the same as DDPM's sampling algorithm. We would like to emphasize that the DPDM is a stand-alone generative model that is totally different from diffusion models (so is the DDPM). And its model training and sampling are also different from the diffusion model (DDPM). More precisely, each sampling step of DDPM gradually predicts the mean of the next-step denoised distribution. On the contrary, each step of DPDM's sampling step directly predicts clean data and then adds a Gaussian noise to obtain samples from the less-noisy distribution. Provided that the DPDM is a different generative model, we do not see the necessity of its sampling algorithm to match the DPDM's sampling algorithm.\n\n**Q3**. This paper claims it provides a solid mathematical foundation for the proposed method, which is unclear means?\n\n**A3**. In section 3.2, we elaborately establish the mathematical formulation of enhancing the data-recovery ability of denoisers as a smoothed KL divergence minimization problem. This part highlights the math foundation of DPDM (through probability divergence minimization) and helps to derive a practical training algorithm of DPDM (Algorithm 1).\n\nWe hope our answers have resolved your concerns, and if you still have any concerns, please let us know, and we will be glad to further address them."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5134/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699931235215,
                "cdate": 1699931235215,
                "tmdate": 1699931235215,
                "mdate": 1699931235215,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mGXClRhksG",
                "forum": "wYmcfur889",
                "replyto": "V3AYFAqsLU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5134/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5134/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your reviews! we are glad to provide more clarifications."
                    },
                    "comment": {
                        "value": "Dear reviewer:\n\nThank you for your reviews! The author-reviewer rebuttal period is coming to a close soon. We sincerely hope that our responses have adequately addressed the concerns you have raised. \n\nIn this work, we introduce a **new class of multi-step generative models**, named Data-prediction Denoising Models, which show significantly **stronger performance than diffusion models** under the few-step setting. We also explore the weak data distribution recovery ability of the diffusion model's denoisers and practical solutions for enhancing them. We believe that our findings and solutions may benefit future researchers in either improving diffusion models or proposing new generative models.\n\nWe hope our rebuttal has resolved your questions. If you still have any unresolved concerns or additional questions, please do let us know! We would be very glad to provide more clarification and address any remaining issues.\n\nBest wishes,\n\nAuthors of the submission #5134."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5134/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700464402391,
                "cdate": 1700464402391,
                "tmdate": 1700464402391,
                "mdate": 1700464402391,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "acTTYkWcvB",
                "forum": "wYmcfur889",
                "replyto": "mGXClRhksG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5134/Reviewer_twcE"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5134/Reviewer_twcE"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the rebuttal."
                    },
                    "comment": {
                        "value": "I think the authors's responses have addressed my concerns. I will increase my score accordingly. Two remaining points: (1) please do a better job to **highlight** that DPDM is different from DDPM in the introduction, given DPDM looks quite similar to DDPM (I always worry that I type this method wrong); and (2) like other reviewers, I also have concerns about the application of this method to large-scale problems."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5134/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700699878968,
                "cdate": 1700699878968,
                "tmdate": 1700699878968,
                "mdate": 1700699878968,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZfVHlxJLQd",
            "forum": "wYmcfur889",
            "replyto": "wYmcfur889",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5134/Reviewer_X9iJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5134/Reviewer_X9iJ"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes Data Prediction Denoising Models (DPDM)s, a new class of generative models that incorporates a sequence of strong denoisers for data generation. It is argued that conventional diffusion models embody weak denoisers, which in turn requires a high number of steps at inference time for generation, reducing the overall efficiency. To alleviate this challenge, DPDM training uses a teacher DM for initialization, and minimizes probability divergences between denoiser-recovered data distributions and the ground truth data distribution. In addition, a sampler suitable for DPDMs is presented. It is shown that DPDM can attain strong performance on CIFAR-10, and ImageNet64x64 with only a few number of sampling steps."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The proposed method is novel, and the technical contribution is strong. DPDMs provide a new framework for generative modeling which is different from diffusion models, although it draws many inspirations from diffusion models.\n- The experimental results are convincing where DPDMs outperform many recent baselines, illustrating their capability on data generation using a small number of NFEs."
                },
                "weaknesses": {
                    "value": "- The scope of the experiments section is limited where the results are presented on low-resolution datasets such as CIFAR-10, and ImageNet 64x64. The experiments would benefit from demonstrations with high-resolution datasets to illustrate the generalizability of the method. \n- Although the focus of the paper is on inference efficiency, inference metrics are not provided. The comparison is made in terms of NFEs which is an important aspect. However, metrics such as inference memory, seconds per iteration at inference, and overall inference time until convergence should be provided for a valid comparison."
                },
                "questions": {
                    "value": "Questions:\n- How does inference memory and time compare with state-of-the-art baselines?\n- What does $\\tilde{x}$ stand for in Equation 1? I don't think it has been defined anywhere.\n\nSuggestions:\n- Typographical issues: There are issues such as duplicate references, (Song et al., 2020b and Song et al., 2020c), duplicate paragraphs (Training Efficiency and GPU-memory Cost in main and appendix) and other issues which should be fixed."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5134/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5134/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5134/Reviewer_X9iJ"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5134/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699338819451,
            "cdate": 1699338819451,
            "tmdate": 1699636506286,
            "mdate": 1699636506286,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "BPNcft6URy",
                "forum": "wYmcfur889",
                "replyto": "ZfVHlxJLQd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5134/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5134/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your useful suggestions!"
                    },
                    "comment": {
                        "value": "Thank you for your helpful suggestions, we will incorporate them in the revision. We will address your concerns one by one in the following paragraphs.\n\nIn this paper, we propose a stand-alone generative model, the DPDM, which draws inspiration from diffusion models from a denoiser perspective. The DPDM shows strong performance under few-step generative settings.\n\n**Q1**. The experiments would benefit from demonstrations with high-resolution datasets to illustrate the generalizability of the method.\n\n**A1**. We appreciate your suggestions on larger-scale experiments such as high-res image modeling or text2img generation. However, these experiments demand substantial computational resources beyond our current reach. For example, training a Stable Diffusion t2i model consumes a cloud cluster with 256 Nvidia A100 GPUs for about 150,000 hours, costing a total of about 600,000 USD, which is far beyond our financial affordance. However, in this work, we have demonstrated strong performances of DPDM on standard benchmarks, and we are glad to try to explore the possibility of scaling DPDM to larger-scale tasks such as high-res data generation and t2i generative models within our financial permissions.\n\n**Q2**. Metrics such as inference memory, seconds per iteration at inference, and overall inference time until convergence should be provided for a valid comparison. How do inference memory and time compare with state-of-the-art baselines?\n\n**A2**. We appreciate your suggestions. First, we would like to say that when implementing DPDM, we use a weight-sharing multi-level denoiser network $\\mathbf{d}_\\theta(x_t,t)$ to parametrize multiple denoisers in a single network. This network follows the same architecture as the baseline EDM diffusion model. Therefore, the inference costs of DPDM per step are exactly the same as the EDM diffusion model. From this view, the NFE is a fair metric for comparing the sampling efficiency of the DPDM and EDM diffusion models. As for the inference cost for convergence, **Table 4** in the submission has a relatively clear demonstration. In Table 4, the FID value of DPDM converges below 3.0 (which is regarded as a line of good performance) with 6 NFEs, on the contrary, the baseline diffusion model's FID is still larger than 3.0 with even 18 NFEs. Since both models have the same cost for each NFE, we conclude that the DPDM is about 3 times more efficient than diffusion models for few-step generations. \n\nHowever, as we pointed out in Section 6, the performance of DPDM with sufficient NFEs (FID of 2.68 with 8 NFEs) is still worse than the diffusion model (FID of 1.97 with 35 NFEs). This is currently a limitation of DPDM and we are very glad to further explore the performance ceiling of DPDM through advanced training configurations, tricks, and other aspects.\n\n**Q3**. What does $\\tilde{x}$ stand for in Equation 1? I don't think it has been defined anywhere.\n\n**A3**. We appreciate your careful reading and We feel sorry for the confusion. There is a typo in Equation 1 in Algorithm 1. Here the $\\tilde{x}_t$ is a mistake for $\\hat{x}_t$ in the expectation operation. Thank you for pointing out the typo.\n\nWe will incorporate your suggestions on other minor issues in the revision. We hope our answers have resolved your concerns. If you still have concerns, please let us know."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5134/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699936511970,
                "cdate": 1699936511970,
                "tmdate": 1699936511970,
                "mdate": 1699936511970,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "IO2HqVoy78",
            "forum": "wYmcfur889",
            "replyto": "wYmcfur889",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5134/Reviewer_u1HV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5134/Reviewer_u1HV"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies student-teacher fine-tunning method that improves and accelerates sampling steps for Diffusion Models (DM). The primary hypothesis motivating this research asserts that the conventional score matching objective used in training leads to suboptimal denoisers for DM, thereby limiting the generation of high-quality samples when constrained to a minimal number of sampling steps (NFE < 10). Results are shown on two datasets comparing to several most recent  baselines."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1, The beginning of the article (Section 1 and Section 2) is well written and presents the motivation behind the introduction of the proposed student-teacher fine-tunning method in a very didactic way.\n\n2,  There are some theoretical justifications for the training gradient of the proposed smoothed KL.\n\n3,  Numerical experiments on small datasets (e.g., 64X64) verify that the proposed DPDM outperforms previous sampling methods in terms of quality (FID) with fewer function evaluations"
                },
                "weaknesses": {
                    "value": "1, While Diff-Instruct was not explicitly designed to accelerate diffusion model sampling, the proposed DPDM still shares many similarities in format, such as the smoothed KL divergence, student-teacher fine-tuning, and the gradient update of the 'objective.' More importantly, Diff-Instruct tested its sampling quality with small NFEs as well. These aspects make the actual novelty of DPDM not clear to the reviewer.\n\n2, While there are some theoretical demonstrations concerning the gradient of KL divergence for a single denoiser, equivalent analyses for multiple denoisers in Eq.3.4 appear to be missing, making the work somehow incomplete.\n\n3,  Compared to other training-free sampling acceleration methods, the computation costs of DPDM are still relatively heavy, making the practical impacts unclear.\n\n4, This work is only demonstrated for image synthesis on small datasets, while other conditional sampling tasks (e.g., text-to-image or image-to-image translation) are missing."
                },
                "questions": {
                    "value": "1, What is the runtime comparison between the proposed and other methods ?\n\n2, Can this strategy be directly adapted to other conditional sampling methods, such as image-to-image translation? On the other hand, given that the sampling trajectory is implemented by different denoising operators, how robust is the DPDM to variations at intermediate stages, especially at low noise levels ?\n\n3, In Table 4, it seems that DPDM performs worse than Diff-Instruct for NFE < 4. What accounts for such differences?\n\n4, When training multiple denoisers, how does convergence occur in those student networks?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5134/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699500779144,
            "cdate": 1699500779144,
            "tmdate": 1699636506137,
            "mdate": 1699636506137,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xwHhXaaxmx",
                "forum": "wYmcfur889",
                "replyto": "IO2HqVoy78",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5134/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5134/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your useful feedback (1)"
                    },
                    "comment": {
                        "value": "Thank you for your useful feedback, we will incorporate them in the revision.  We will address your concerns one by one in the following paragraphs. Before that, we first give a summary of the main contributions of our work.\n\nIn this work, we propose a novel stand-alone generative model termed the Data-prediction denoising model (DPDM), which achieves significantly better generative performance than diffusion models under the few-step sampling settings. \n\n**Q1**. DPDM shares similarities with Diff-Instruct [1], which also performs well with few sampling steps. Could you give some more discussions?\n\n**A1**. We highly appreciate your keen intuition. In this work, when defining the DPDM, we draw inspiration from two amazing works: the diffusion models (i.e., the EDM work [2]) and the Diff-Instruct [1] (which achieves strong performance for single-step generation). The DPDM combines the advantages of both worlds, resulting in strong few-step generative performances. However, such a combination of both works is non-trivial, because:\n\n(1). Though the Diff-Instruct achieves state-of-the-art single-step diffusion distillation performance during its publishing, it does not support multi-step sampling, because the Diff-Instruct can only train a one-step student model to directly transport a Gaussian latent vector to obtain generated samples. The most amazing part of Diff-Instruct is its mathematical foundations (i.e. the formulation of divergence minimization when deriving the algorithm). However, the possibility (with improved performances) of incorporating such a math formulation for stronger few-step generative modeling has not been yet explored. To our knowledge, we are the first work that explored and successfully achieved a strong few-step generative performance with an FID of 3.66 on ImageNet$32\\times 32$ data with 8 sampling steps, which is stronger than Diff-Instruct (which only supports one-step sampling) and baseline diffusion models. \n\n(2). Though diffusion models can generate promising data samples when the sampling steps are sufficient, they perform poorly under a few-step setting (even with the best solvers). In this work, we analyze and locate the reason for such a performance drop under a few-step setting as the weak distribution recovery ability of diffusion models' denoiser (Section 5.1 in the submission). Such an observation of weak denoisers not only motivates us to propose DPDM with improved denoisers but also sheds light on other future work which potentially aims to address the weakness of diffusion models.\n\n(3). We incorporate all enhanced denoisers through a single $\\mathbf{d}_\\theta(x_t,t)$ network with weight sharing. This overcomes the heavy computational and memory cost when storing multiple denoisers.\n\n**Q2**. Put more discussions on Eq.3.4.\n\n**A2**. We feel sorry for the confusion. Equation 3.4 is a generalization of Equation 3.3 which only considers a single noise level. For a single noise level, we only consider a single denoiser. When generalizing to multiple denoisers, we use a weight-sharing multi-level denoiser network $\\mathbf{d}_ \\theta(x_t,t)$ to parametrize multiple denoisers in a single network $\\mathbf{d}_\\theta$. \n\nTherefore, the gradient formula to update $\\theta$ of $\\mathbf{d}_\\theta(x_t,t)$ is a weighted combination of the single-step gradient Equation 3.3 through a weighting function $w(t)$ over diffusion time t (or over different noise levels). We really thank you for your careful reading and we acknowledge that there is a small typo in Equation 3.4.: \n\nthe denoiser should write $x_t = \\mathbf{d}_ \\theta(x_0 + \\sigma(t)\\epsilon, t) + \\tilde{\\epsilon}$  instead of $x_t = \\mathbf{d}_ \\theta(x_0 + \\epsilon) + \\tilde{\\epsilon}$, and the Equation 3.4 should be modified to\n\n$$ \\operatorname{Grad}(\\theta)= \\int_ 0^ T w(t)\\mathbb{E}_ { \\boldsymbol{x}_ t=\\boldsymbol{d}_ \\theta(\\boldsymbol{x}_ 0 + \\sigma(t)\\epsilon, t)+\\tilde{\\epsilon} \\atop \\boldsymbol{x}_ 0 \\sim p_ 0, \\epsilon,\\tilde{\\epsilon} \\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{I})} \\big[\\boldsymbol{s}_ {q_t}( \\boldsymbol{x}_ t, t) - \\boldsymbol{s}_ { p_ t}( \\boldsymbol{x}_ t, t) \\big] \\frac{\\partial \\boldsymbol{x}_ t}{ \\partial \\theta} \\mathrm{d}t. $$\n\nWe hope fixing this typo will make our presentation more clear and resolve your concerns."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5134/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699933692439,
                "cdate": 1699933692439,
                "tmdate": 1699933692439,
                "mdate": 1699933692439,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "c93nsToyBC",
                "forum": "wYmcfur889",
                "replyto": "IO2HqVoy78",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5134/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5134/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your reviews! we are glad to provide more clarifications."
                    },
                    "comment": {
                        "value": "Dear reviewer:\n\nThank you for your reviews! The author-reviewer rebuttal period is coming to a close soon. We sincerely hope that our responses have adequately addressed the concerns you have raised. \n\nIn this work, we introduce a **new class of multi-step generative models**, named Data-prediction Denoising Models, which show significantly **stronger performance than diffusion models** under the few-step setting. We also explore the weak data distribution recovery ability of the diffusion model's denoisers and practical solutions for enhancing them. We believe that our findings and solutions may benefit future researchers in either improving diffusion models or proposing new generative models.\n\nWe hope our rebuttal has resolved your questions. If you still have any unresolved concerns or additional questions, please do let us know! We would be very glad to provide more clarification and address any remaining issues.\n\nBest wishes,\n\nAuthors of the submission #5134."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5134/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700464449613,
                "cdate": 1700464449613,
                "tmdate": 1700464449613,
                "mdate": 1700464449613,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fezy7S5mkG",
                "forum": "wYmcfur889",
                "replyto": "c93nsToyBC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5134/Reviewer_u1HV"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5134/Reviewer_u1HV"
                ],
                "content": {
                    "title": {
                        "value": "Thank You for Addressing My Comments"
                    },
                    "comment": {
                        "value": "The reviewer would like to thank the authors for taking the time to address their comments. After reviewing the authors' responses, I find this work to be interesting and novel enough for publication. However, there is still a lack of strong evidence supporting the direct application of this distillation technique to large-scale image/video generation. As a result, the reviewer must maintain their original rating."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5134/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700693159494,
                "cdate": 1700693159494,
                "tmdate": 1700693159494,
                "mdate": 1700693159494,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]