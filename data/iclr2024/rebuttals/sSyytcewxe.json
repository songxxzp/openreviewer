[
    {
        "title": "Divide and not forget: Ensemble of  selectively trained experts  in Continual Learning"
    },
    {
        "review": {
            "id": "y5Ffd3PjEC",
            "forum": "sSyytcewxe",
            "replyto": "sSyytcewxe",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission49/Reviewer_rq4G"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission49/Reviewer_rq4G"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents Selection of Experts for Ensemble Diversification (SEED), an algorithm that tackles exemplar-free class-incremental learning (CIL). Existing exemplar-free CIL algorithms incrementally trains new local experts on new tasks, and SEED provides a task selection technique to diversify trained experts, mitigate forgetting, and maintain plasticity. Specifically, an expert is a Bayes classifier that targets a distinct set of classes, with each class corresponding to a Gaussian distribution. To diversify expert selection, the next task is selected via the highest KL-divergence from encountered distributions. Inference is done by averaging the logits output from each expert and selecting the class with highest probability."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper clearly identifies a problem of task diversification in CIL.\n2. The language is easy to follow."
                },
                "weaknesses": {
                    "value": "1. Lack of novelty: selecting the next task based on largest KL divergence in continual learning is not a novel strategy. So is the expandable MoE architecture and the inference method.\n2. Overhead growth: one biggest disadvantage of architecture expansion is that the memory overhead grows linearly with respect to the number of tasks. That is, it needs K experts for K tasks with nothing reusable. SEED omits the selection procedure to decide the number of experts needed even if the number of tasks is large. This is not scalable in continual learning, where the number of tasks can be unbounded."
                },
                "questions": {
                    "value": "Please address the two weakness points above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission49/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission49/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission49/Reviewer_rq4G"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission49/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698597746331,
            "cdate": 1698597746331,
            "tmdate": 1700602843283,
            "mdate": 1700602843283,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AR4kXlWWhR",
                "forum": "sSyytcewxe",
                "replyto": "y5Ffd3PjEC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission49/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission49/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate the feedback provided by the Reviewer. We will now address the specific weaknesses indicated:\n\n\n**Novelty concern related to the next task selection**\n\n> *Selecting the next task based on largest KL divergence in continual learning is not a novel strategy. So is the expandable MoE architecture and the inference method.*\n\nWe thank the reviewer for that comment, yet we believe that there may be some misunderstanding of our method. Please note that we do not select tasks. We use KL-divergency to assign a single, existing expert to be trained on a given task. However, during the inference time, we use an ensemble of all available $K$ experts whose predictions are aggregated, and this approach is different from conventional MoE architectures. As far as the novelty of our approach is concerned, we believe that our work is the first to show how allocating experts to be trained on tasks can alleviate catastrophic forgetting in continual learning. We would appreciate if the Reviewer could link references to the mentioned relevant existing continual learning strategies so we can refer to them in our work.\n\n**Concern of the overhead growth**\n\nAs stated in Method section 3 ```Our approach, presented in Fig.2, consists of $K$ deep network experts```. Therefore, K is the number of experts, which is equal to 3 or 5 in our experimental section regardless of the number of tasks |T|. We do not grow the network architecture above that number, e.g., in Fig. 4 and Tab. 1 we present experiments with |T|=50, where K=5 experts are used.  \n\n---\n\nWe hope our explanation alleviates any concerns the Reviewer may have. However, if there are any remaining uncertainties, kindly specify references and additional questions, and we can further discuss them. Otherwise, we'd appreciate if the reviewer reconsidered the final score of our submission."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission49/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700081787325,
                "cdate": 1700081787325,
                "tmdate": 1700081787325,
                "mdate": 1700081787325,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Wu9tBcvx6r",
                "forum": "sSyytcewxe",
                "replyto": "y5Ffd3PjEC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission49/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission49/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer rq4G,  \n\nThe discussion period ends in 24 hours.  \n\nWe appreciate the Reviewer's contributions to the reviewing process. We have put much effort into our work and would appreciate the Reviewer's constructive feedback.   \n\nWe are also dedicated to the review process and ensuring that our work adheres to the highest standards. We kindly ask the Reviewer to respond to our previous comment and identify specific areas in our submission where further improvement would allow the Reviewer to confidently recommend our paper for acceptance (more than above-borderline acceptance). We highly value and appreciate your efforts."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission49/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700572445680,
                "cdate": 1700572445680,
                "tmdate": 1700572538837,
                "mdate": 1700572538837,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XMYhT5LuFs",
                "forum": "sSyytcewxe",
                "replyto": "Wu9tBcvx6r",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission49/Reviewer_rq4G"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission49/Reviewer_rq4G"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response. By the novelty concern, I mean that there exist selection algorithms in continual learning by measuring task similarities, e.g. [1, 2], and one of the used method of measuring similarities is by KL-divergence [3]. Moreover, using experts to model distributions at each task in continual learning is also an established work [4].\n\nIf the authors are able to elaborate the main differences from a combination of experts and task similarity measurement, and convince me that the difference is non-trivial, I would be happy to raise my rating to 6 or above.\n\n[1] Basterrech, Sebasti\u00e1n, and Micha\u0142 Wo\u017aniak. \"Tracking changes using Kullback-Leibler divergence for the continual learning.\" 2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC). IEEE, 2022.\n\n[2] Simon, Christian, Piotr Koniusz, and Mehrtash Harandi. \"On learning the geodesic path for incremental learning.\" Proceedings of the IEEE/CVF conference on Computer Vision and Pattern Recognition. 2021.\n\n[3] Pentina, Anastasia, and Christoph H. Lampert. \"Lifelong learning with non-iid tasks.\" Advances in Neural Information Processing Systems 28 (2015).\n\n[4] Lee, Soochan, et al. \"A neural dirichlet process mixture model for task-free continual learning.\" arXiv preprint arXiv:2001.00689 (2020)."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission49/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700573198933,
                "cdate": 1700573198933,
                "tmdate": 1700573198933,
                "mdate": 1700573198933,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WZPcIhTqIW",
                "forum": "sSyytcewxe",
                "replyto": "Bs7hLKTkZk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission49/Reviewer_rq4G"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission49/Reviewer_rq4G"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your explanation. I have updated my rating accordingly."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission49/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700602865118,
                "cdate": 1700602865118,
                "tmdate": 1700602865118,
                "mdate": 1700602865118,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "2jBSD3iOAY",
            "forum": "sSyytcewxe",
            "replyto": "sSyytcewxe",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission49/Reviewer_hfuR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission49/Reviewer_hfuR"
            ],
            "content": {
                "summary": {
                    "value": "This work studies the class incremental learning (CIL) problem from the mixture-of-experts (MOE) angle where only a subset of the model (expert) is activated for each task. To this end, the authors propose SEED that selects one expert per task during continual training and aggregates the experts during evaluation. Thus, SEED promotes diversity representations while requiring no task identifiers during inference. Experiments on various CIL benchmarks show promising results of SEED."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This work studies the MoE for CIL, which has been gaining interests as a promising approach to CIL.\n- The proposed method is simple yet demonstrated encouraging results.\n- The authors conduct various ablation studies to explore different aspects of SEED."
                },
                "weaknesses": {
                    "value": "## Major concern - experiment\n- In table 1 and 2, although it is clear that SEED performs better than the baselines, different methods have different memory footprint (model parameters and other components) or training complexities. Thus, it is difficult to judge if the gains come from the proposed method or from the additional complexities.\n\n## Major concern - conceptual drawback of SEED\n- SEED implies that the number of experts should be smaller than the number of tasks and there is only one expert activated per task. Thus, it is inevitably that some experts will be reused in the future, leading to catastrophic forgetting especially when the tasks are conflicting. The use of LwF regularization might not be helpful if the expert stay inactive for a long period. \nTogether with with the ambiguity in the experimental settings and results, the contribution of this work seems marginal.\n\n## Minor concern \n- Additional baselines: A recent related method [A] that seems to outperforms SEED should be discussed.\n- There are two different references for CoSCL in the Introduction.\n\n[A] Ardywibowo, Randy, et al. \"VariGrow: Variational Architecture Growing for Task-Agnostic Continual Learning based on Bayesian Novelty.\" International Conference on Machine Learning. PMLR, 2022."
                },
                "questions": {
                    "value": "- Performance comparison under a fair setting.\n- How could SEED avoid forgetting when the number of tasks is significantly larger than the number of experts."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission49/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission49/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission49/Reviewer_hfuR"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission49/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698683752799,
            "cdate": 1698683752799,
            "tmdate": 1699635928593,
            "mdate": 1699635928593,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XaAbd5G7gS",
                "forum": "sSyytcewxe",
                "replyto": "2jBSD3iOAY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission49/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission49/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the Reviewer for the constructive feedback, insightful comments and providing a reference. Below we respond to the weaknesses mentioned:\n\n**Do the gains come from the proposed method or from the additional complexities?**\n\nWe agree that the question whether the gains come from the proposed method or the additional complexities is important. Therefore, we run the experiments with results presented in Tab. 3 and Tab. 4 of our submission. More specifically, in Tab. 4, we show that our method of ensembling experts in CIL outperforms existing SoTA ensembling methods; all require the same amount of parameters. In Tab. 3, our method achieves better results than competitors while using fewer parameters. We have also performed another experiment presented in Tab. 5 (and below) where we evaluate methods with regard to the number of theirs parameters during inference. We have added it to the revised version. The above observations lead us to the conclusion that the gain of our method does not result only from the additional complexities.  \n\nWe affirm that various CL methods present different memory/computational footprints. Especially for ensemble methods, it is inherent that few experts have to be stored in memory. Evaluating the complexity of some methods from Tab. 1 & 2 is not trivial, e.g., SSRE uses a complex few-phase training with expansion and pruning phases. However, pruning can also be applied to every other method from these tables. We try to be clear about SEED, and therefore we present and discuss: (1) the parameter efficiency in Tab. 3 compared to other MoE and ensemble architectures, (2) memory footprint in Appendix A.3, (3) we have also added a tradeoff between number of models' parameters vs accuracy in Appendix A.4 (revision version) to better address this concern.\n\n**Performance comparison under a limited number of parameters.**\n\nTo address this concern, we have added Tab. 5 to the appendix (and below). SEED achieves better accuracy than the best competitor (FeTriL) from Tables 1&2 while using less parameters. Here we consider number of parameters required by the method to perform the inference. For SEED these paramters come from feature extractors of experts (here they share first 17 layers) and Gaussian distributions.\n\n| Method | Network    | Network weights |Total parameters| \\|T\\|=10 | \\|T\\|=20 | \\|T\\|=50 |\n| -------- | -------- |-------- |-------- | -------- | -------- | -------- |\n| EWC     |ResNet32   |  473K   |  473K  | 24.5     | 21.2 | 15.9\n| LWF     |ResNet32   |  473K   |  473K  | 45.9     | 27.4 | 20.1\n| FeTrIL  |ResNet32   |  467K   |  473K  | 46.3     | 38.7 | 27.0\n| SEED    |ResNet20   |  339K   | 460K   | 54.7     | 48.6 | 33.1\n\n**Avoiding catastrophic forgetting in SEED**\n\nOne of the main goals of our method is to limit catastrophic forgetting. For that reason, we proposed our expert selection strategy to alleviate forgetting. We demonstrate the improvements in Tab. 4 and Fig. 6. Please note that we train only one expert in each task and that knowledge distillation regularization is applied only to it. If an expert is inactive (not trained on tasks), the parameters of its feature extractor do not change. Thus, it's not prone to catastrophic forgetting.\n\n**How could SEED avoid forgetting when the number of tasks is significantly larger than the number of experts?**\n\nIn that case SEED avoids forgetting in two ways. First, in each task SEED trains only one expert, other experts (K-1) remain unchanged so that they avoid forgetting. Please note, that layers shared by experts are frozen after the first task. Second, we utilize feature distillation for trained expert to alleviate its forgetting - we made it more clear in Section 3 in the revised version. \n\n\n**Comparing VariGrow to SEED**\n\nThe method cited by the Reviewer performs experiments with exemplars and auxilary datasets (4.1 Implementation details: ```We also use these exemplars along with OoD datasets```), while we propose an exemplar-free method for more challenging scenarios and we do not use exemplars or auxilary data in our experiments. \n\n**Two different references for CoSCL in the Introduction.**\n\nWe have fixed this in the revised version. Thank you.\n\n---\n\nWe trust that our explanation has addressed the Reviewer's concerns. Should there be any additional queries, we are more than willing to provide further details. If no further clarification is needed, we kindly ask the Reviewer to reconsider the final score."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission49/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700081499747,
                "cdate": 1700081499747,
                "tmdate": 1700081499747,
                "mdate": 1700081499747,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "L772vzn9If",
                "forum": "sSyytcewxe",
                "replyto": "2jBSD3iOAY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission49/Reviewer_hfuR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission49/Reviewer_hfuR"
                ],
                "content": {
                    "title": {
                        "value": "Conceptual Drawback of SEED"
                    },
                    "comment": {
                        "value": "I appreciate the authors efforts in addressing my comments. \n\nHowever, my concerns regarding the drawback of SEED remains. SEED alleviates forgetting by freezing the feature extractor and activating only 1 expert per task. However, this strategy strongly assumes that the first task can provide a good feature representation for all future tasks and there are no tasks that require a completely different representation, which are quite restrictive. For example, consider the complex transfer settings in the CTrL benchmark [A] where the data stream can have unrelated tasks ($\\mathcal{S}^{\\text{plastic}}$), or the first task only have limited training data ($\\mathcal{S}^+$), then SEED may not perform well on such scenarios.\n\nIt may not be feasible to conduct comprehensive experiments on the CTrL benchmark during this rebuttal period, but the authors should clearly state the assumption of SEED, indicating which settings it might work well on, and acknowledging the conceptual drawbacks. \n\n[A] Veniat, Tom, Ludovic Denoyer, and Marc'Aurelio Ranzato. \"Efficient continual learning with modular networks and task-driven priors.\" ICLR 2021."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission49/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700208871589,
                "cdate": 1700208871589,
                "tmdate": 1700209307804,
                "mdate": 1700209307804,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dxa7FVwo8z",
                "forum": "sSyytcewxe",
                "replyto": "2jBSD3iOAY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission49/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission49/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Although the rebuttal period is almost over, we are still eager to answer the Reviewer's questions and continue the discussion. Insights provided by the Reviewer were helpful and allowed to increase the quality of our work. If we have addressed uncertainties regarding our work, we would appreciate adjusting the final score."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission49/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700646590257,
                "cdate": 1700646590257,
                "tmdate": 1700646590257,
                "mdate": 1700646590257,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "9verQTtCpg",
                "forum": "sSyytcewxe",
                "replyto": "dxa7FVwo8z",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission49/Reviewer_hfuR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission49/Reviewer_hfuR"
                ],
                "content": {
                    "title": {
                        "value": "Acknowledgement"
                    },
                    "comment": {
                        "value": "Dear authors,\n\nI have gone through the discussion thus far. Although I have no further questions, I would like to discuss with AC and other Reviewers before finalizing my rating.\n\nThank you"
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission49/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700647408332,
                "cdate": 1700647408332,
                "tmdate": 1700647408332,
                "mdate": 1700647408332,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ayUa90RD0O",
            "forum": "sSyytcewxe",
            "replyto": "sSyytcewxe",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission49/Reviewer_3XPS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission49/Reviewer_3XPS"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a new class-incremental learning algorithm which relies on a set of expert models with a shared backbone. In each training step, only one expert is trained on the new task. This expert is chosen based on how well it separates the new classes. At inference time, all experts make predictions but their contribution to the final prediction is conditioned on the input.\nExperiments are conducted on three different datasets in two variants and for task-agnostic and task-aware cases.\nThe authors provide several ablation studies on core components of the method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The authors make an interesting observation by showing that some methods work significantly better if more data is available initially.\nThey propose a method that improves over the baselines, in particular in the case where few data is available initially. The method and description is good and reminds me of S-Prompts which has a similar setup but works with pretrained transformer models.\nAs far as I can tell, all important aspects are covered by ablation studies, leaving only room for few questions."
                },
                "weaknesses": {
                    "value": "A not fully covered discussion is the number of parameters vs accuracy tradeoff. The proposed methods requires significantly more parameters than some of the baselines which might be a limitation if the models are extremely large. Furthermore, training from scratch is a rather uncommon scenario. It is unclear how this method would work if a pretrained model is used."
                },
                "questions": {
                    "value": "Figure 7 (right): what is the difference between SEED with 1 expert and finetuning? What is your explanation that your method is doing very well in this particular setup?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission49/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698772211825,
            "cdate": 1698772211825,
            "tmdate": 1699635928488,
            "mdate": 1699635928488,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "g1MEavymzw",
                "forum": "sSyytcewxe",
                "replyto": "y5Ffd3PjEC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission49/Reviewer_3XPS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission49/Reviewer_3XPS"
                ],
                "content": {
                    "comment": {
                        "value": "Can you be a bit more elaborate on Weakness 1 to give the authors an opportunity to answer and the other reviewers to verify for themselves? In particular, I'd like to see references to the existing work. Thanks!"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission49/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699891361430,
                "cdate": 1699891361430,
                "tmdate": 1699891361430,
                "mdate": 1699891361430,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UJHBe4umaw",
                "forum": "sSyytcewxe",
                "replyto": "ayUa90RD0O",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission49/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission49/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We express our gratitude to the reviewer for the constructive feedback and insightful remarks. We shall commence by addressing the specific weaknesses pointed out:\n\n**The tradeoff between number of parameters and accuracy**\n\nWe have run additional experiments and presented them in Appendix A.4, where we use ResNet32 and ResNet18 architectures and provide accuracy depending on the number of experts and shared layers. The tradeoff between an overall number of model parameters and accuracy can be observed. We can use that analysis to limit the parameters and still reach a satisfactory accuracy. However, we agree that number of parameters can be a limiting factor our method if the models are extremely large, as few experts have to be stored in memory.\n\n**The impact of a pretrained model on SEED**\n\nWe have performed experiments to examine the impact of using a pretrained model vs training from scratch. The results for DomainNet datasets are presented below (we also added them in A.5):\n\n| DomainNet \\|T\\| | Avg. acc. scratch | Avg. acc. pre | Avg. forgetting scratch | Avg. forgetting pre |\n| :--------: | :--------: | :--------: | :--------: | :--------: |\n| 12     | 45.0     | 53.1     | 12.1 | 12.8\n| 24     | 49.0     | 54.2     | 11.2 | 12.1\n| 36     | 39.2     | 53.6     | 13.7 | 15.6\n\nWe use DomainNet here as we consider it the most interesting scenario to use ImageNet pretrained network. SEED can benefit from starting each expert from the pretrained network and reach better accuracies with a slightly higher forgetting. However, here, we use the same setting as from the scratch (hyperparameters), which can be suboptimal for this scenario.\n\n**Differences between finetuning and one expert setting**\n\nThere are two significant differences between using SEED with one expert and finetuning. First, we perform Bayes classification during the inference. Second, we use a feature distillation to increase the stability of the expert. The method is doing well in this scenario as in our ensemble, few experts are not finetuned and increase stability of the method, while the one being finetuned allows for good plasticity.\n\n---\n\nIf we have adequately addressed the Reviewer's concerns, we kindly ask for your support. If you have any further concerns or additional points to raise, we are eager to address them. Your insights are valuable in enhancing the quality and impact of our research."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission49/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700081252083,
                "cdate": 1700081252083,
                "tmdate": 1700081252083,
                "mdate": 1700081252083,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6VAJtGcWwa",
                "forum": "sSyytcewxe",
                "replyto": "UJHBe4umaw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission49/Reviewer_3XPS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission49/Reviewer_3XPS"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for addressing my comments. I have no further questions."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission49/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700220319997,
                "cdate": 1700220319997,
                "tmdate": 1700220319997,
                "mdate": 1700220319997,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "pU5n1hZXLi",
            "forum": "sSyytcewxe",
            "replyto": "sSyytcewxe",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission49/Reviewer_Hjf8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission49/Reviewer_Hjf8"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes an (exemplar-free) ensemble method for Class Incremental Continual Learning (CIL). A fixed number of experts are trained on a stream of tasks. At each task, only one expert is finetuned. The result is a diverse expert ensemble which is reported to perform very well on several benchmarks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "I believe this paper advances the field of continual learning.\n\nSpecifically,\n\n- Tackles a popular continual learning scenario.\n- Good empirical results. Show significant improvements on several datasets.\n- Well written and clear.\n- Sound experiments with several ablation studies."
                },
                "weaknesses": {
                    "value": "No major weaknesses. Perhaps just the fact that several models (experts) have to be trained and stored (but this is inherent in ensemble methods).\n\n\n### Minor remarks (I don't expect any response on these remarks in the rebuttal) \n- In Figure 3, it's hard to see that task 3 overlap least with the second expert. Perhaps make this a bit clearer.\n- In Page 4, perhaps the inference and training algorithms would be easier to read in an \"Algorithm\" structure rather than simple paragraphs.\n- In Page 5, just before Section 4.1., the task incremental scenario is mentioned but is not really defined properly in my opinion."
                },
                "questions": {
                    "value": "1. In Page 8, it's written that *\"SEED uses a regularization method known from LwF\"*. Are you actually using LwF for each expert? I don't recall reading it in other places in the paper. Please clarify.\n1. How are the hyperparameters of EWC and LwF set in the experiments ? For instance, Figure 7 shows $\\lambda\\in [100,10000]$ without any justification.\n1. In Page 1, the authors mention *\"The trend is evident... results steadily improve over time\"*. What time?\n1. In Table 1, how many repetitions are performed per experiment?\n1. In Table 1, why aren't there results for ImageNet-Subset for two algorithms?\n1. In Figure 5, the presented metric is \"relative accuracy\". Relative to what?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission49/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698909914197,
            "cdate": 1698909914197,
            "tmdate": 1699635928413,
            "mdate": 1699635928413,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "DJvgLKPlf9",
                "forum": "sSyytcewxe",
                "replyto": "pU5n1hZXLi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission49/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission49/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the Reviewer for the positive feedback and insightful comments. We begin by responding to the weakness pointed out in the review:\n\n**The need to train and store a number of experts**\n\nAs the Reviewer stated, this is inherent in ensemble methods. However, we discuss the number of parameters in Tab.3 and Appendix A.3. We have additionally run experiments to examine the trade-off between the number of parameters and accuracy of SEED in Appendix 4. We show that the total number of parameters can be lowered, and SEED can still achieve satisfactory results.\n\n**Improvements in the paper**\n>_In Figure 3, it's hard to see that task 3 overlap least with the second expert. Perhaps make this a bit clearer._\n\nWe appreciate that suggestion. We updated the figure in the new revision.\n\n\n>_In Page 4, perhaps the inference and training algorithms would be easier to read in an \"Algorithm\" structure rather than simple paragraphs._\n    \n>_In Page 5, just before Section 4.1., the task incremental scenario is mentioned but is not really defined properly in my opinion.\n\nWe have addressed both comments in the revised version. Thank you.\n\n**Questions**\n\n>_In Page 8, it's written that \"SEED uses a regularization method known from LwF\". Are you actually using LwF for each expert? I don't recall reading it in other places in the paper. Please clarify._\n\nSEED uses feature distillation for each expert, similar to LwF (logit distillation) but performed in the latent space. It's mentioned in Sec. 3, Training (page 4/5). We clarified this part of our method description in the new revision.\n\n>_How are the hyperparameters of EWC and LwF set in the experiments ? For instance, Figure 7 shows without any justification._\n\nWe set default parameters of the methods as reported in the original articles. For avoidance of doubt, we also stated it in Appendix A.1: ```For baseline methods, we set default hyperparameters```. For Fig. 7 hyperparameters were manually chosen to exhibit the tradeoff between intransigence and forgetting, and we list all these parameters in Appendix A.1 as well.\n\n>_In Page 1, the authors mention \"The trend is evident... results steadily improve over time\". What time?_\n\nIn this case, we meant the dates of publication of the corresponding articles. The methods presented in Fig. 1 are positioned according to the order of their publication dates. We have labeled the publication year axis x in Fig. 1 to better visualize that in the revised version.\n\n>_In Table 1, how many repetitions are performed per experiment?_\n\nWe perform three repetitions per experiment, as stated in Appendix A.1: ```All experiments are the average over three runs```.\n\n>_In Table 1, why aren't there results for ImageNet-Subset for two algorithms?_\n\nFor these two methods, we performed experiments using their implementations in PyCIL benchmark and default hyperparameters. However, on ImageNet-Subset IL2A performance was really low, while PASS experiments did not converge, probably getting stuck, and we could not finish them.\n\n>_In Figure 5, the presented metric is \"relative accuracy\". Relative to what?_\n\nWe present the metric relative to the mean achieved by all experts. We have clarified that in the caption of Fig. 5 in the updated version: ```It is calculated by subtracting the accuracy of each expert from the averaged accuracy of all experts.```\n\n---\n\nIf the Reviewer's concerns have been sufficiently addressed in our responses, we humbly seek their support for the paper."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission49/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700082721109,
                "cdate": 1700082721109,
                "tmdate": 1700082721109,
                "mdate": 1700082721109,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mVe5qE0Wua",
                "forum": "sSyytcewxe",
                "replyto": "DJvgLKPlf9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission49/Reviewer_Hjf8"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission49/Reviewer_Hjf8"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for addressing my comments. \n\nRegarding my minor remarks - in the revised Figure 3, I still cannot see immediately that the purple task overlaps least with the second expert. Regarding the algorithm in Page 4, I suggested using an [algorithm environment](https://www.overleaf.com/learn/latex/Algorithms), not just writing \"Algorithm\" in the paragraph's title.\n\nAnyway, I have no further questions and I keep my score (8)."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission49/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700564104336,
                "cdate": 1700564104336,
                "tmdate": 1700564104336,
                "mdate": 1700564104336,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]