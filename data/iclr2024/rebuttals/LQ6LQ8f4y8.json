[
    {
        "title": "CCIL: Continuity-Based Data Augmentation for Corrective Imitation Learning"
    },
    {
        "review": {
            "id": "3vEvL6zKzI",
            "forum": "LQ6LQ8f4y8",
            "replyto": "LQ6LQ8f4y8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3972/Reviewer_iEcJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3972/Reviewer_iEcJ"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes to enhance the robustness of imitation learning methods by generating corrective data to account for compounding error and disturbances. Their work is based upon utilizing the local continuity in the environment dynamics. The paper augments the original expert's dataset with generated corrective labels within the neighborhood of the demonstrations but beyond the actual set of states and actions in the dataset. The authors' argue that this augmentation helps the agent to recover from perturbations and deal\nwith compounding error."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Their problem is well-defined, and methods are explained clearly.\n- Related work covers basic prior work.\n- The data augmentation part where the authors utilize the local continuity of dynamics model helped them achieve better performance than the basic Behavioral Cloning Algorithm."
                },
                "weaknesses": {
                    "value": "- While the writing was clear and easy to understand, the paper lacked substantial content. I didn't find any need to pause and think while reading and I skimmed through the paper rather quickly .\n- Performance comparisons of their work are only done with basic Behavior Cloning and NoiseBC algorithms that are basic Imitation Learning (IL) Algorithms. Comparison with state-of the-art IL methods are missing.\n-  I would recommend the authors to include experiments to compare the sample efficiency with other state of the art algorithms in terms of trajectories needed as that is also an important metric in IL paradigm.\n- There are many Offline IL algorithms proposed recently in literature that have the same settings where they don't make any new interaction with the environment or the expert. Comparisons with them would be interesting to see.\n- I would recommend the authors to also report results on Humanoid environment from Mujoco."
                },
                "questions": {
                    "value": "Please check the Weaknesses part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3972/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3972/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3972/Reviewer_iEcJ"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3972/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698553984183,
            "cdate": 1698553984183,
            "tmdate": 1699636358501,
            "mdate": 1699636358501,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TpMEUuivtq",
                "forum": "LQ6LQ8f4y8",
                "replyto": "3vEvL6zKzI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for recognizing the novelty and soundness of our proposal. We address each of your concerns as follows:\n\n> \u201cWhile the writing was clear and easy to understand, the paper lacked substantial content\u201d\n\nOur proposal stems from a key observation - that the dynamics of robotic systems abides by physics laws and contains local continuities. While certainly simple, the literature in imitation learning has not investigated this form of structure for data augmentation and for alleviating the compounding errors. As seen from our empirical results, this data augmentation method is principled and makes a substantial difference in performance.\n\n\n> \u201cComparison with state-of-the-art IL methods are missing.\u201d\n\nPer your request, we compared our method against two additional baselines: an imitation learning method [MILO](https://arxiv.org/abs/2106.03207) and model-based offline reinforcement learning method [MoREL](https://arxiv.org/abs/2005.05951). MILO is a state-of-the-art IL method which also learns a dynamic model from data and uses the learned model to learn from demonstrations. However, MILO usually demands access to a large dataset of transitions (in order to train a good dynamic model). In our experiments, we train MILO with only the given expert data. Similarly, model-based Offline RL requests additional access to a reward function as an assumption. \n\nOur results indicate that our method, CCIL, consistently outperforms these baselines in various tasks:\n- In the car domain, CCIL outperformed all other baselines.\n- In the drone domain (given the limited time, we used a subset of data for training), CCIL outperformed all other baselines.\n- In MuJoCo tasks, CCIL was the leading method on 3 out of 4 tasks.\n- In MetaWorld tasks, CCIL was competitive, tying with other baselines in 3 out of 4 tasks and slightly underperforming only in one task against MILO.\n\n**Mujoco**\n| | | | | | \n|--------------------------------------|:------------------------:|:------------------------:|:------------------------:|:------------------------:|\n|          | **Hopper** | **Walker**| **Ant** | **Halfcheetah** \n| CCIL | **3102.25 $\\pm$309.25** | **4605.26 $\\pm$ 129.02** |2073.60 $\\pm$ 217.97 | **4182.15 $\\pm$ 501.44** \n| VanillaBC | 2902.78 $\\pm$689.64 | 3810.63 $\\pm$ 828.23 |1646.24 $\\pm$ 202.71 | 3872.82 $\\pm$ 460.09 \n| NoiseBC | 1563.56 $\\pm$1012.02 | 2893.21 $\\pm$ 1076.89 |**3160.51 $\\pm$ 48.68** | 2044.24 $\\pm$ 291.59 \n| MOREL | 152.19 $\\pm$34.12 | 70.27 $\\pm$ 3.59 |1000.77 $\\pm$ 15.21 | -2.24 $\\pm$ 0.02 \n| MILO | 566.98$\\pm$100.32 | 526.72$\\pm$127.99 |1006.53$\\pm$160.43 |151.08$\\pm$117.06 \n\n**Metaworld**\n| | | | | | \n|--------------------------------------|:------------------------:|:------------------------:|:------------------------:|:------------------------:|\n|         | **CoffeePull** |**ButtonPress** | **CoffeePush**|**DrawerClose**\n| CCIL | **4168.46 $\\pm$192.98** | **3775.22 $\\pm$ 91.24** |**2484.19 $\\pm$ 976.03** | 4145.45 $\\pm$ 76.23 \n| VanillaBC | 3552.59 $\\pm$233.41 | **3693.02 $\\pm$ 104.99** |1288.19 $\\pm$ 746.37 | 2809.56 $\\pm$ 439.70 \n| NoiseBC | 3072.86 $\\pm$785.91 | **3663.44 $\\pm$ 63.10** | **2551.11 $\\pm$ 857.79** | 4226.71 $\\pm$ 18.90 \n| MOREL |18.78 $\\pm$0.09 | 14.85 $\\pm$17.08 | 18.66 $\\pm$ 0.02 |1222.2 3$\\pm$ 1241.47\n| MILO | 232.49$\\pm$110.44 | 986.46$\\pm$105.79 | 230.62$\\pm$19.37 | **4621.11$\\pm$39.68**|\n\n**Car**\n| | | | \n|--------------------------------------|:------------------------:|:------------------------:|\n|    | **Succ.Rate** |**Avg. Score** \n| CCIL | **56.4%** | **0.75 $\\pm$ 0.25**\n| VanillaBC | 31.9% | 0.58 $\\pm$ 0.25 \n| NoiseBC | 39.2% | 0.63 $\\pm$ 0.27 \n| MOREL | 0% | 0.001 $\\pm$0.001 \n| MILO | 0% | 0.21$\\pm$0.003\n\n**Drone** (due to time constraint, we used ~50 trajectories for the drone tasks here)\n| | | | |\n|--------------------------------------|:------------------------:|:------------------------:|:------------------------:|\n|    | **Hover** |**Circle** |**FlyThrough** \n|CCIL  |-0.96E8 | -8.03E7 | -0.78E8 \n|VanillaBC | -1.08E8 | -9.56E7 | -1.06E8  \n|NoiseBC | -1.13E8 | -9.88E7 | -1.07E8 \n|MOREL | -1.25E8 | -1.24E8 | -1.25E8 \n|MILO | -1.26E8 | -1.25E8 | -1.25E8 \n\n\n\n> \u201cmany Offline IL algorithms proposed recently in literature\u201d\n\nOur proposal is meant to only leverage the given expert demonstration data, without access to reward or large amounts of offline data. Addressing your request, we just added [MILO](https://arxiv.org/abs/2106.03207) and [MoREL](https://arxiv.org/abs/2005.05951) for comparison. We would be happy to take a look if you could point us to other Offline IL algorithms with minimal assumptions.\n\n\n> \u201creport results on the Humanoid environment\u201d\n\nAll our MuJoCo experiments used the expert data from the D4RL dataset which, unfortunately, did not provide demonstrations for the Humanoid. To keep the evaluations consistent and use an open-source dataset for MuJoCo, we did not include results on the Humanoid environment."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700036867389,
                "cdate": 1700036867389,
                "tmdate": 1700175648363,
                "mdate": 1700175648363,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Z8lEbzKU7n",
                "forum": "LQ6LQ8f4y8",
                "replyto": "3vEvL6zKzI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for sharing valuable feedback to help improve our work. We have provided additional experiments and clarifications as requested. Please let us know whether our response has addressed your comments. We would be happy to engage in further discussions if needed."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700647744554,
                "cdate": 1700647744554,
                "tmdate": 1700647744554,
                "mdate": 1700647744554,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "x5oWlK7xtf",
            "forum": "LQ6LQ8f4y8",
            "replyto": "LQ6LQ8f4y8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3972/Reviewer_vWGV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3972/Reviewer_vWGV"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes the data augmentation method for behavioral cloning (BC) utilizing the local Lipschitz constraint. To train the forward dynamics from expert data, the proposed method (CCIL) minimizes mean-squared error with the regularization that is computed from the local Lipschitz constraint. Then, two techniques are proposed to generate transition triplets that can be used as expert data.  Once the dataset is augmented, naive BC is applied to find a policy. CCIL is evaluated on various tasks and outperforms BC and NoiseBC."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Although the proposed idea is simple, the experimental results show that CCIL is very powerful even if the environmental dynamics is not globally continuous. \n2. The authors evaluated CCIL on various tasks, and it suggests that the proposed method is appealing to practitioners. \n3. The manuscript is written well and easy to follow and understand."
                },
                "weaknesses": {
                    "value": "1. My major concern is that the proposed method has to solve relatively complicated optimization problems. For example, Equation (3) contains two complicated terms: Lipschitz constraint and L0 norm. How to deal with the max operator in the Lipschitz constraint term is unclear. \n2. The proposed method assumes a deterministic transition function. I am curious when the proposed method is applied to stochastic systems."
                },
                "questions": {
                    "value": "1. The proposed method is formulated in a discrete-time state transition model, whereas the corresponding true system operates in continuous-time. Therefore, the proposed method implicitly applies a time discretization. In this case, the time interval is critical, and I think the Lipschitz constant depends on the time interval. How did the authors determine an appropriate Lipschitz constant? Or, are there any assumptions on the time discretization in the proposed method? \n2. I do not fully understand the major differences between the techniques of the proposed method and Data as Demonstrator (DaD) proposed by Venkatraman et al. (2015)? I think the core idea is similar; therefore, it is worth discussing the advantages of the proposed method.  \n3. Two augmentation techniques are proposed, but I am unsure whether either would be equally useful. Is it possible to conduct an additional ablation study where one of the techniques is removed? \n4. In the paragraph above Definition 4, the authors introduce $\\mathrm{Support}(d^\\pi)$, but it is not defined. Is $d^\\pi$ a stationary distribution induced by $\\pi$? \n5. The first paragraph on page 5: $\\hat{f}(s_t, a_t) \\to s_{t+1}^* - s_t^*$ should be $\\hat{f}(s_t^*, a_t^*) \\to s_{t+1}^* - s_t^*$. \n6. Is $\\bar{\\lambda}$ in Equation (3) is an average of $\\{ \\lambda_j \\}_j$? \n7. Please define $f'$ in Equation (3) explicitly.\n8. Regarding the technique 1 (Backtrack label), what does \"xlabel\" mean?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3972/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698647464334,
            "cdate": 1698647464334,
            "tmdate": 1699636358395,
            "mdate": 1699636358395,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CZU12zivpE",
                "forum": "LQ6LQ8f4y8",
                "replyto": "x5oWlK7xtf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for acknowledging the strengths of our work, particularly the empirical results and the clarity of the manuscript. We address your questions as follows:\n\n> **W1: Complexity of Optimization Problems in the Proposed Method**\n\nOur approach requires learning a dynamic model while enforcing local Lipschitz continuity. We use a sampling-based estimation for the local Lipschitz continuity in Eq. 3. We implement the max term to penalize violations of Lipschitz continuity using the ReLU function. This method has empirically demonstrated an advantage over baselines without extensive hyper-parameter tuning. For tasks with largely local continuity, simpler techniques like Spectral Normalization can be used (details in Appendix C.1). Our method is flexible, allowing the use of any learned dynamics model that exhibits local continuity.\n\n> **Q1: How did the authors determine an appropriate Lipschitz constant?**\n\n\nIndeed the Lipschitz constant of the dynamics will depend on the time interval. Without assuming any prior knowledge about the system dynamics, we use empirical experiments to choose the desired local Lipschitz continuity for each task domain, as documented in Appendix D.3. Essentially, we tried constraining the Lipschitz continuity per each neural network layer to use different continuities (L=  2 / 3 / 5) and inspect the resulting training errors. Since the theoretical bound of our generated labels depends on both L and the training errors $\\epsilon$ of the learned dynamics model (e.g., <= 0.001 \u00b7 L + (1 + L)\u03f5 ), we choose the hyperparameter to yield the best theoretical bound. \n\n> **Q2: Comparison to Data as Demonstrator (DaD)**\n\nSimilar to DaD, our method aims to generate \u201ccorrective\u201d labels. However, our method is fundamentally different to DaD in (1) the assumptions and (2) the problem we are trying to solve. \n\n(1) We cited DaD in Section 2 paragraph 1 and explained that this method leveraged a form of **invariance** for data augmentation. Our method relies on the presence of local continuity instead. Our assumption is less strong and is applicable beyond position controlled domains. \n\n(2) DaD is a data augmentation method for training a dynamic model but not for policy. NoiseBC extends DaD to train a policy. It also leverages a form of known invariance (e.g., position control), injects noise disturbance and reuses the action label. Hence we include NoiseBC as a baseline, essentially reusing the ideas from DaD. We showed that our method could outperform NoiseBC in most domains we considered. \n\n> **Q3: Ablation Study on Augmentation Techniques**\n\nIn our empirical evaluations we found that different tasks might benefit more from different techniques. For simplicity, in all our experiments, we used one of the techniques proposed. For example, on MuJoCo and MetaWorld tasks, NoisyAction technique outperforms Backward technique on half of the tasks. The benefits of using which technique to generate labels depends on the ground truth system dynamics and the learned dynamics function. We attach an additional ablation comparing the effectiveness of two techniques on Metaworld.\n\n**Metaworld**\n| | | | | | \n|--------------------------------------|:------------------------:|:------------------------:|:------------------------:|:------------------------:|\n|         | **CoffeePull** |**ButtonPress** | **CoffeePush**|**DrawerClose**\n| NoisyAction | **4168.46 $\\pm$192.98** | 3758.89 $\\pm$ 67.39  |**2484.19 $\\pm$ 976.03** |  3988.67 $\\pm$ 168.27\n| Backward | 3954.12$\\pm$322.67 | **3775.22 $\\pm$ 91.24** |1584.45$\\pm$935.01 |**4145.45 $\\pm$ 76.23**\n| VanillaBC | 3552.59 $\\pm$233.41 | **3693.02 $\\pm$ 104.99** |1288.19 $\\pm$ 746.37 | 2809.56 $\\pm$ 439.70"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700208443530,
                "cdate": 1700208443530,
                "tmdate": 1700208753554,
                "mdate": 1700208753554,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sHW78lxv8K",
                "forum": "LQ6LQ8f4y8",
                "replyto": "x5oWlK7xtf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for sharing valuable feedback to help improve our work. We have provided additional experiments and clarifications as requested. Please let us know whether our response has addressed your comments. We would be happy to engage in further discussions if needed."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700647770623,
                "cdate": 1700647770623,
                "tmdate": 1700647770623,
                "mdate": 1700647770623,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "52ZHSOG8Tv",
            "forum": "LQ6LQ8f4y8",
            "replyto": "LQ6LQ8f4y8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3972/Reviewer_mpW3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3972/Reviewer_mpW3"
            ],
            "content": {
                "summary": {
                    "value": "This study is dedicated to enhancing the robustness of imitation learning through the generation of corrective data, compensating for compounding errors and disturbances. Numerous experiments have been executed on an array of tasks, ranging from drone navigation and locomotion to robot manipulation, to validate the effectiveness of the proposed approach."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This work offers a detailed theoretical analysis, providing evidence that the quality of the generated label is bounded under specific assumptions related to the dynamics.\n\n2. Various tasks ranging from drone navigation to locomotion and robot manipulation have been extensively experimented and analyzed in the study."
                },
                "weaknesses": {
                    "value": "1. The proposed method is only compared to vanilla BC and noisy BC. The proposed method declares it constructs a dynamics model for policy learning and has used implementation with a model-based RL framework; therefore, it would be more robust to also include a comparison with other model-based RL methods. As model-based RL also constructs a dynamic model first before planning the most effective actions.\n\n2. There is a lack of clarity in important implementation details. The process of generating corrective labels is discussed in Section 4 but the paper does not make it clear how these labels are employed in later stages. The additional corrective labels could be used to train the imitation learning agent, presumably a neural network? However, if this is the case, further details on the network's implementation could be discussed."
                },
                "questions": {
                    "value": "The reason why noise BC underperforms compared to vanilla BC is not clear. If we reduce the noise added to the BC, noiseBC's performance should align more closely with that of vanilla BC. Nonetheless, in multiple tasks, noiseBC exhibits significantly poorer results. This could potentially be attributed to the fact that the added noise has not been not carefully chosen and thus, an excessive amount of noise has been injected into the system?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3972/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3972/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3972/Reviewer_mpW3"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3972/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698671398607,
            "cdate": 1698671398607,
            "tmdate": 1699636358281,
            "mdate": 1699636358281,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VbVttJsD2Q",
                "forum": "LQ6LQ8f4y8",
                "replyto": "52ZHSOG8Tv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for recognizing our theoretical contributions and comprehensive evaluations. To address your feedback, we have expanded our comparisons and clarified implementation details.\n\n**Clarification on Implementation Details**\n\nWe augment the original training dataset with the newly generated labels. We then train imitation learning agents using these augmented data by feeding the data into a policy function. Our policy function predicts actions from input states. It is modeled by a neural network with 2 layers of 128 neurons each, using ReLU activation. Our implementation uses the BC algorithm from the open-source library [d3rlpy](https://takuseno.github.io/d3rlpy/). \n\n**Explanation of Noise BC's Underperformance**\n\nThere are two main reasons why Noise BC underperforms compared to vanilla BC. First, certain domains may not be well-suited for NoiseBC. For instance, in drone navigation tasks using RPM control and in MuJoCo locomotion tasks that use torque control, reusing the action label after state perturbation may not be effective. Second, as you correctly pointed out, the level of noise introduced is crucial. Inappropriate noise levels can significantly impact performance.\n\nIn our experiments, we experimented with the size of the noise (variance = 0.001, 0.0005, 0.0001). Our experiments currently applied a small noise level for NoiseBC across all tasks (noise variance = 0.0001). However, recognizing your concern, we experimented with a smaller noise level (variance = 0.00005) in two MuJoCo tasks (Hopper and Walker) where NoiseBC lagged behind vanilla BC. We observed that Noise BC's performance is indeed sensitive to the size of the noise. Reducing the noise slightly improved NoiseBC's performance, but it still did not reach the level of Vanilla BC. This suggests that the application of NoiseBC requires careful calibration of the noise level.\n\nThese observations highlight the limitations of NoiseBC, further emphasizing the need for our proposed method.\n\n| | | | \n|--------------------------------------|:------------------------:|:------------------------:|\n|          | **Hopper** | **Walker**\n| NoiseBC (original, var=0.0001) | 1563.56 $\\pm$1012.02 | 2893.21 $\\pm$ 1076.89  \n| NoiseBC (new, var=0.00005) | 2300.27 $\\pm$823.85 | 2906.48 $\\pm$ 326.78 \n| VanillaBC | 2902.78 $\\pm$689.64 | 3810.63 $\\pm$ 828.23 \n\n**Additional Baseline Comparisons**\n\nPer your request, we compared our method against two additional baselines: an imitation learning method [MILO](https://arxiv.org/abs/2106.03207) and model-based offline reinforcement learning method [MoREL](https://arxiv.org/abs/2005.05951). \n\nMILO is a state-of-the-art IL method which also learns a dynamic model from data and uses the learned model to learn from demonstrations. However, MILO usually demands access to a large dataset of transitions (in order to train a good dynamic model). In our experiments, we train MILO with only the given expert data. Similarly, model-based Offline RL requests additional access to a reward function as an assumption. \n\nOur results indicate that our method, CCIL, consistently outperforms these baselines in various tasks:\n- In the car domain, CCIL outperformed all other baselines.\n- In the drone domain (given the limited time, we used a subset of data for training), CCIL outperformed all other baselines.\n- In MuJoCo tasks, CCIL was the leading method on 3 out of 4 tasks.\n- In MetaWorld tasks, CCIL was competitive, tying with other baselines in 3 out of 4 tasks and slightly underperforming only in one task against MILO."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700041510150,
                "cdate": 1700041510150,
                "tmdate": 1700175559443,
                "mdate": 1700175559443,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oIiLaCLZCV",
                "forum": "LQ6LQ8f4y8",
                "replyto": "52ZHSOG8Tv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Additional Baseline"
                    },
                    "comment": {
                        "value": "**Mujoco**\n| | | | | | \n|--------------------------------------|:------------------------:|:------------------------:|:------------------------:|:------------------------:|\n|          | **Hopper** | **Walker**| **Ant** | **Halfcheetah** \n| CCIL | **3102.25 $\\pm$309.25** | **4605.26 $\\pm$ 129.02** |2073.60 $\\pm$ 217.97 | **4182.15 $\\pm$ 501.44** \n| VanillaBC | 2902.78 $\\pm$689.64 | 3810.63 $\\pm$ 828.23 |1646.24 $\\pm$ 202.71 | 3872.82 $\\pm$ 460.09 \n| NoiseBC | 1563.56 $\\pm$1012.02 | 2893.21 $\\pm$ 1076.89 |**3160.51 $\\pm$ 48.68** | 2044.24 $\\pm$ 291.59 \n| MOREL | 152.19 $\\pm$34.12 | 70.27 $\\pm$ 3.59 |1000.77 $\\pm$ 15.21 | -2.24 $\\pm$ 0.02 \n| MILO | 566.98$\\pm$100.32 | 526.72$\\pm$127.99 |1006.53$\\pm$160.43 |151.08$\\pm$117.06 \n\n**Metaworld**\n| | | | | | \n|--------------------------------------|:------------------------:|:------------------------:|:------------------------:|:------------------------:|\n|         | **CoffeePull** |**ButtonPress** | **CoffeePush**|**DrawerClose**\n| CCIL | **4168.46 $\\pm$192.98** | **3775.22 $\\pm$ 91.24** |**2484.19 $\\pm$ 976.03** | 4145.45 $\\pm$ 76.23 \n| VanillaBC | 3552.59 $\\pm$233.41 | **3693.02 $\\pm$ 104.99** |1288.19 $\\pm$ 746.37 | 2809.56 $\\pm$ 439.70 \n| NoiseBC | 3072.86 $\\pm$785.91 | **3663.44 $\\pm$ 63.10** | **2551.11 $\\pm$ 857.79** | 4226.71 $\\pm$ 18.90 \n| MOREL |18.78 $\\pm$0.09 | 14.85 $\\pm$17.08 | 18.66 $\\pm$ 0.02 |1222.2 3$\\pm$ 1241.47\n| MILO | 232.49$\\pm$110.44 | 986.46$\\pm$105.79 | 230.62$\\pm$19.37 | **4621.11$\\pm$39.68**|\n\n**Car**\n| | | | \n|--------------------------------------|:------------------------:|:------------------------:|\n|    | **Succ.Rate** |**Avg. Score** \n| CCIL | **56.4%** | **0.75 $\\pm$ 0.25**\n| VanillaBC | 31.9% | 0.58 $\\pm$ 0.25 \n| NoiseBC | 39.2% | 0.63 $\\pm$ 0.27 \n| MOREL | 0% | 0.001 $\\pm$0.001 \n| MILO | 0% | 0.21$\\pm$0.003\n\n**Drone**(due to time constraint, we used ~50 trajectories for the drone tasks here)\n| | | | |\n|--------------------------------------|:------------------------:|:------------------------:|:------------------------:|\n|    | **Hover** |**Circle** |**FlyThrough** \n|CCIL  |-0.96E8 | -8.03E7 | -0.78E8 \n|VanillaBC | -1.08E8 | -9.56E7 | -1.06E8  \n|NoiseBC | -1.13E8 | -9.88E7 | -1.07E8 \n|MOREL | -1.25E8 | -1.24E8 | -1.25E8 \n|MILO | -1.26E8 | -1.25E8 | -1.25E8"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700041555529,
                "cdate": 1700041555529,
                "tmdate": 1700175636396,
                "mdate": 1700175636396,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "z6TjA2nPbt",
                "forum": "LQ6LQ8f4y8",
                "replyto": "52ZHSOG8Tv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for sharing valuable feedback to help improve our work. We have provided additional experiments and clarifications as requested. Please let us know whether our response has addressed your comments. We would be happy to engage in further discussions if needed."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700647780577,
                "cdate": 1700647780577,
                "tmdate": 1700647780577,
                "mdate": 1700647780577,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "n4nllYlCOT",
            "forum": "LQ6LQ8f4y8",
            "replyto": "LQ6LQ8f4y8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3972/Reviewer_cJ4u"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3972/Reviewer_cJ4u"
            ],
            "content": {
                "summary": {
                    "value": "This work presents a method for augmenting imitation learning data by learning locally lipschitz-continuous dynamics models and then generating additional labels by perturbing the action to find noisy states as well as tracing states that would lead to the current state with the current action according to the learned dynamics model. Experiments on a diverse set of simulated tasks demonstrate the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Offline data augmentation is an important area of research that could lead to more robust  policies. This paper proposes an intuitive solution by generating additional data around existing data points by querying a locally smooth dynamics model.\nThe proposed solution categorizes two types of data augmentation: one by perturbing action labels and finding states that would land in the next state given this noise label, and the other by tracing states that would land in the current state given the current action.\nThis work presents thorough evaluation of the proposed method by experimenting with diverse task settings ranging from controlling a drone to manipulation tasks that have discontinuous dynamics."
                },
                "weaknesses": {
                    "value": "The theoretical and algorithmic contribution is novel and exciting but the empirical results are not as impressive.\n\nIt would be great if the authors could test augmenting the training data with ground truth dynamics models (isn\u2019t it deterministic -> computable given low-dimensional state representations?) to showcase the full potential of data-augmentation-based methods and situate the performance of the proposed method: i.e. help the audience understand if the performance gain/no-gain attribute to additional data or quality of the dynamics model.\n\nThis work could also benefit from additional experiments with varying number of demonstrations in a particular domain to show how much data is needed to learn a good dynamics model and at the same time could still benefit from additional augmentation data. \n\nThis work only conducted experiments in simulation, where dynamics models are deterministic and different from real applications. The authors should comment more on what challenges there would be to apply the proposed method in the real world and if one can benefit more or less from this paradigm of data augmentation.\n\n\n----- Edit ------\nThe authors presented additional results during rebuttal that address some of my concerns about the evaluation. However, I do think a real-world experiment is practical and valuable for the true impact of this paper, given the proposed method is fully offline.\n\nI am happy to raise my evaluation to weakly accept."
                },
                "questions": {
                    "value": "See weakness for major concerns."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3972/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3972/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3972/Reviewer_cJ4u"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3972/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698705302781,
            "cdate": 1698705302781,
            "tmdate": 1700435839846,
            "mdate": 1700435839846,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0bNBhCOgf5",
                "forum": "LQ6LQ8f4y8",
                "replyto": "n4nllYlCOT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for recognizing the novelty in our proposal and our thorough evaluations. Addressing your concerns, we have run more experiments to enhance the empirical evidence supporting our method, CCIL.\n\n**Ablation Experiment using Varying Number of Demonstrations**\n\nIn response to your suggestion, we conducted an ablation study to vary the number of demonstrations on the Discontinuous Pendulum and the Drone environments. \n\nOur observations from both domains indicate that CCIL improves the performance of BC regardless of whether small or large amounts of data are used. This highlights a key advantage of our approach: CCIL does not require the learning of an extensive dynamics model using a large number of samples. As long as the learned model is well-fitted to the given demonstrations and the dynamic function exhibits local continuity around the data, CCIL can effectively generate corrective labels, thereby enhancing the robustness of imitation learning.\n\n\n*Discontinuous Pendulum*\n| | | | | |\n|--------------------------------------|:------------------------:|:------------------------:|:------------------------:|:------------------------:|\n|    | **500 demos** |**300 demos** |**100 demos** |**10 demos** |\n|CCIL  | -2556|-3194|-3275|-3807\n|VanillaBC  | -3204|-4075|-4213|-15236\n\n\n*Drone*\n| | | | |\n|--------------------------------------|:------------------------:|:------------------------:|:------------------------:|\n|    | **Hover** |**Circle** |**FlyThrough** \n|CCIL(~50 trajectories)  |-0.96E8 | -8.03E7 | -0.78E8 \n|VanillaBC(~50 trajectories) | -1.08E8 | -9.56E7 | -1.06E8\n|CCIL(5000 traj) | -16458.96 | -2549.87 | -37060.3  \n|VanillaBC(5000 traj) | -1.5E6 | -5.8E4 | -1.73E5\n\n\n\n**Ablation Experiment using the Ground Truth Dynamics**\n\nWe conducted an ablation study to generate corrective labels using the ground truth dynamic model. This ablation requires that we have access to the ground truth dynamics, so we run it on the discontinuous Pendulum task. We run our experiment across 3 random seeds and found that on this simple domain, CCIL performs nearly as well as the ablation baseline that uses the ground truth dynamics:\n| | | \n|--------------------------------------|:------------------------:|\n|    | **Rewards** |\n|CCIL  | -2556\n|Ablation | -2453 \n\n\n\n\n**Real-World Application Considerations**\n\nAs we plan to apply our method to real robots, there are two key considerations. \n\nFirst, imitation learning policies in real-world scenarios are more susceptible to compounding errors due to sensor and actuator noise. Robustness would be a more critical issue to real world imitation learning. As highlighted by [1], the improvement brought by data augmentation techniques could be more prominent in real-world imitation learning policies than those observed in simulations.\n\nSecond, real-world dynamics are often more complex than those in simulators due to contacts, friction cones, sensor and actuation noises. A significant challenge lies in how to effectively regularize the training of dynamics models for our approach. The successful application of CCIL in real-world settings will depend on our ability to accurately fit a dynamic model using real-world data. \n\n[1]: Ke, Liyiming, et al. \"Grasping with chopsticks: Combating covariate shift in model-free imitation learning for fine manipulation.\" 2021 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2021."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700095235156,
                "cdate": 1700095235156,
                "tmdate": 1700175688216,
                "mdate": 1700175688216,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "62hWf9cxv0",
                "forum": "LQ6LQ8f4y8",
                "replyto": "n4nllYlCOT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Comparison with Additional Baselines:**\n\nTo further highlight the effectiveness of CCIL, we conducted comparative experiments with two state-of-the-art methods:the [MILO](https://arxiv.org/abs/2106.03207) imitation learning method and the  [MoREL](https://arxiv.org/abs/2005.05951) model-based offline reinforcement learning method. Both these methods, like ours, construct a dynamic model from data for policy learning.  While MILO requires a large dataset of transitions, we trained it solely with the expert data available to us. MoREL, on the other hand, assumes additional access to a reward function. Our results indicate that our method, CCIL, consistently outperforms these baselines in various tasks. \n\nOur results indicate that our method, CCIL, consistently outperforms these baselines in various tasks:\n- In the car domain, CCIL outperformed all other baselines.\n- In the drone domain (given the limited time, we used a subset of data for training), CCIL outperformed all other baselines.\n- In MuJoCo tasks, CCIL was the leading method on 3 out of 4 tasks.\n- In MetaWorld tasks, CCIL was competitive, tying with other baselines in 3 out of 4 tasks and slightly underperforming only in one task against MILO.\n\n**Mujoco**\n| | | | | | \n|--------------------------------------|:------------------------:|:------------------------:|:------------------------:|:------------------------:|\n|          | **Hopper** | **Walker**| **Ant** | **Halfcheetah** \n| CCIL | **3102.25 $\\pm$309.25** | **4605.26 $\\pm$ 129.02** |2073.60 $\\pm$ 217.97 | **4182.15 $\\pm$ 501.44** \n| VanillaBC | 2902.78 $\\pm$689.64 | 3810.63 $\\pm$ 828.23 |1646.24 $\\pm$ 202.71 | 3872.82 $\\pm$ 460.09 \n| NoiseBC | 1563.56 $\\pm$1012.02 | 2893.21 $\\pm$ 1076.89 |**3160.51 $\\pm$ 48.68** | 2044.24 $\\pm$ 291.59 \n| MOREL | 152.19 $\\pm$34.12 | 70.27 $\\pm$ 3.59 |1000.77 $\\pm$ 15.21 | -2.24 $\\pm$ 0.02 \n| MILO | 566.98$\\pm$100.32 | 526.72$\\pm$127.99 |1006.53$\\pm$160.43 |151.08$\\pm$117.06 \n\n**Metaworld**\n| | | | | | \n|--------------------------------------|:------------------------:|:------------------------:|:------------------------:|:------------------------:|\n|         | **CoffeePull** |**ButtonPress** | **CoffeePush**|**DrawerClose**\n| CCIL | **4168.46 $\\pm$192.98** | **3775.22 $\\pm$ 91.24** |**2484.19 $\\pm$ 976.03** | 4145.45 $\\pm$ 76.23 \n| VanillaBC | 3552.59 $\\pm$233.41 | **3693.02 $\\pm$ 104.99** |1288.19 $\\pm$ 746.37 | 2809.56 $\\pm$ 439.70 \n| NoiseBC | 3072.86 $\\pm$785.91 | **3663.44 $\\pm$ 63.10** | **2551.11 $\\pm$ 857.79** | 4226.71 $\\pm$ 18.90 \n| MOREL |18.78 $\\pm$0.09 | 14.85 $\\pm$17.08 | 18.66 $\\pm$ 0.02 |1222.2 3$\\pm$ 1241.47\n| MILO | 232.49$\\pm$110.44 | 986.46$\\pm$105.79 | 230.62$\\pm$19.37 | **4621.11$\\pm$39.68**|\n\n**Car**\n| | | | \n|--------------------------------------|:------------------------:|:------------------------:|\n|    | **Succ.Rate** |**Avg. Score** \n| CCIL | **56.4%** | **0.75 $\\pm$ 0.25**\n| VanillaBC | 31.9% | 0.58 $\\pm$ 0.25 \n| NoiseBC | 39.2% | 0.63 $\\pm$ 0.27 \n| MOREL | 0% | 0.001 $\\pm$0.001 \n| MILO | 0% | 0.21$\\pm$0.003\n\n**Drone** (due to time constraint, we used ~50 trajectories for the drone tasks here)\n| | | | |\n|--------------------------------------|:------------------------:|:------------------------:|:------------------------:|\n|    | **Hover** |**Circle** |**FlyThrough** \n|CCIL  |-0.96E8 | -8.03E7 | -0.78E8 \n|VanillaBC | -1.08E8 | -9.56E7 | -1.06E8  \n|NoiseBC | -1.13E8 | -9.88E7 | -1.07E8 \n|MOREL | -1.25E8 | -1.24E8 | -1.25E8 \n|MILO | -1.26E8 | -1.25E8 | -1.25E8 \n\nWe hope these additional experiments address your concerns. Let us know if you have any further question."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700095291665,
                "cdate": 1700095291665,
                "tmdate": 1700175664074,
                "mdate": 1700175664074,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qPUjCw68a1",
                "forum": "LQ6LQ8f4y8",
                "replyto": "n4nllYlCOT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3972/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Preliminary Real Robot Result**\n\nWe thank the reviewer for your feedback. To address your concern, we added a preliminary real world experiment, applying our proposal to a manipulator robot. On a peg insertion task that requires precision, CCIL achieved 40% success rate whereas BC had zero success rate, trained using 100 demonstrations. You can view an example rollout of CCIL at [imgur](https://imgur.com/a/TQANAJx)"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700647495432,
                "cdate": 1700647495432,
                "tmdate": 1700647495432,
                "mdate": 1700647495432,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]