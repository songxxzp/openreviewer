[
    {
        "title": "CosPGD: an efficient white-box adversarial attack for pixel-wise prediction tasks"
    },
    {
        "review": {
            "id": "hP3IUznZP2",
            "forum": "ATaE46G1eJ",
            "replyto": "ATaE46G1eJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission909/Reviewer_3VUb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission909/Reviewer_3VUb"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a white-box adversarial attack CosPGD for dense predictions tasks such as semantic segmentation, optical flow and image restoration. CosPGD adopts the cossine similarity to weight the basic PGD attack, which has better interpretability compared to the weight adjustment based on the number of iterations used in SegPGD. Experimental results show CosPGD is strong attack performance in multi tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The authors discuss the differences and advantages of PGD and SegPGD.\n2. Compared to SegPGD, CosPGD has a broader generality, which can be applied not only to pixel classification tasks but also to pixel regression tasks."
                },
                "weaknesses": {
                    "value": "1. The core of the proposed method is very similar to SegPGD, as both aim to focus on the pixels where the attack has not been successful yet (e.g. pixels with large cosine similarity weight). Therefore, the novelty is limited.\n2. Ablation experiments lacking other metrics like cosine distance.\n3. Lack of performance comparison experiments with state-of-the-art methods [1] for semantic segmentation tasks.\n\n[1] Rony J, Pesquet J C, Ben Ayed I. Proximal Splitting Adversarial Attack for Semantic Segmentation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 20524-20533."
                },
                "questions": {
                    "value": "See Weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission909/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission909/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission909/Reviewer_3VUb"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission909/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698397453531,
            "cdate": 1698397453531,
            "tmdate": 1699636017754,
            "mdate": 1699636017754,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "QPxJrUyKz4",
                "forum": "ATaE46G1eJ",
                "replyto": "hP3IUznZP2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' rebuttal"
                    },
                    "comment": {
                        "value": "Dear Reviewer 3VUb,\n\nThank you very much for your insightful review. We hope to answer your questions in a satisfactory manner.\n\n1. The proposed CosPGD is motivated by SegPGD and indeed the equations look similar. Yet, there are significant conceptual differences that provide a strong benefit of CosPGD over SegPGD, which we also discuss on page 3 in our submission. Please refer to our general reply for details on the conceptual differences between the two and the resulting benefit of CosPGD. Please note that no other existing attack scales the loss pixel-wise using **similarity between the posterior and target distributions**. All attacks focus on final model predictions. This makes CosPGD significantly novel. Does this answer the important concern?\n\n\n2. To the best of our knowledge, cosine distance is not the most commonly evaluated metric for any of the tasks considered: semantic segmentation, optical flow estimation, and image restoration(we evaluate structural similarity for this task).\nFor all our considered models and tasks, we report all the metrics that are used by the authors to evaluate their proposed models and attacks. \n\n\n3. Our experiments focus on the wide applicability of CosPGD rather than on outperforming a particular, dedicated approach on a particular task. We will try to provide results comparing our method to [1] for the final version, which is however not trivial since [1] proposes a minimal attack and CosPGD is an epsilon-bounded attack. In any case, we now cite in the revised version and will discuss this paper. \n**Please note** that according to the ICLR guidelines, https://iclr.cc/Conferences/2024/ReviewerGuide, publications from recent conferences (\u201cpublished [...] within the last four months\u201d: \u201con or after May 28, 2023\u201d) are assumed to be contemporaneous work and a comparison is not required - this is the case for [1].\n\nWe hope we were able to answer all your questions to your satisfaction. Please let us know if you have further questions or concerns.\n\nBest Regards\n\nAuthors of Paper #909"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission909/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700024812006,
                "cdate": 1700024812006,
                "tmdate": 1700024812006,
                "mdate": 1700024812006,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tEATlgtqvR",
                "forum": "ATaE46G1eJ",
                "replyto": "hP3IUznZP2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Gentle Reminder"
                    },
                    "comment": {
                        "value": "Dear Reviewer 3VUb,\n\nWe were curious if you happened to find the time to read our official comments and incorporated changes in the revised version. If so, we would be glad to answer any further questions or doubts you might have.\n\nBest Regards,\n\nAuthors of Paper #909"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission909/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700511474110,
                "cdate": 1700511474110,
                "tmdate": 1700511474110,
                "mdate": 1700511474110,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qKONQf6yKs",
                "forum": "ATaE46G1eJ",
                "replyto": "tEATlgtqvR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission909/Reviewer_3VUb"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission909/Reviewer_3VUb"
                ],
                "content": {
                    "comment": {
                        "value": "For Q1, we believe that the most basic cross-entropy is also a measure between distributions. Therefore, we have the same idea as Reviewer YMdT and think it is a simple improvement of SegPGD. In addition, the current version does not explain why this is better, visually or quantitatively.\n\nFor Q2, our question is why does it have to be cos distance? Is KL or JS distance also possible?\n\nLooking forward to your further explanation."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission909/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700636746401,
                "cdate": 1700636746401,
                "tmdate": 1700636746401,
                "mdate": 1700636746401,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "opdXMvcKKW",
                "forum": "ATaE46G1eJ",
                "replyto": "hP3IUznZP2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for rephrasing your question! We think we better understand the question Q1 now, from a mathematical perspective.\n\nBoth SegPGD and CosPGD propose to modify the update step of the original PGD applied to each pixel, as given in our equation (1).\n\n$sign\\nabla_{\\boldsymbol{X}}L$\n\n Here, we write L to denote the original model loss with respect to the current model $f$ 's prediction based on an adversarial sample \n$\\boldsymbol X$    \n\nand the one-hot encoded ground truth \n$Y$.\n\nFor segmentation, i.e. in SegPGD $L$ is a cross-entropy loss as specified in their equation (2) . In our paper, we also use a cross entropy loss when considering segmentation, but $L$ can in principle be any loss of the respective original model, as in PGD. For optical flow, we use an optical flow loss, to be consistent with PGD.\n\nIn SegPGD, the above update is modified to\n\n$sign\\nabla_{\\boldsymbol{X}}(\\frac{1-\\lambda}{N}\\sum_{i\\in P^T} L_i  + \\frac{\\lambda}{N}\\sum_{k\\in P^F} L_k)$ \n\nwhere  $P^T$\nis the set of correctly classified pixels and  $P^F$ \nis the set of wrongly classified pixels, $N$ is the total number of pixels and $\\lambda$ is a scaling factor between the two parts of the loss that is set heuristically. See their equation (4) for details. \n\nFor positive $\\lambda$, this equation could be rewritten as\n\n$sign\\nabla_{\\boldsymbol{X}}(\\frac{1}{N}\\sum_{i\\in P^T\\cup P^F} (1- |\\lambda - |(argmax(f(\\boldsymbol{X}))-Y|/2|) L_i) $\n\nfor adversarial examples \n$\\boldsymbol{X}$\n\ni.e. $|\\lambda - |(argmax(f(\\boldsymbol{X}))-Y|/2|$ equals $1-\\lambda$ for incorrect predictions, it equals $\\lambda$ for correct predictions.\n\nYou can consider this representation of SegPGD to be the starting point of our argument: no matter what loss to use for L, we argue that the weighting of the pixel-wise loss with this weight after the argmax is an issue: it limits SegPGD to applications where the correctness of the prediction can be evaluated in a binary way, and it disregards the actual prediction scores. This is why CosPGD proposes in our equation (5) proposes to use a continuous measure of correctness instead:\n\n$sign\\nabla_{\\boldsymbol{X}}(\\frac{1}{N}\\sum_{i\\in P^T\\cup P^F} cos(softmax(f(\\boldsymbol{X})), Y) L_i) $ \n\nPlease note that this facilitates CosPGD to operate on the segmentation scores instead of the final argmax predictions. Positive side aspects are that we do not need to set any heuristic parameter $\\lambda$ and that we can directly apply this same procedure for a wide variety of tasks beyond segmentation. The experiments we show demonstrate the significant benefit of considering the actual prediction scores w.r.t. the cosine similarity of their softmax to the ground truth.  \nWe empirically show the benefit of CosPGD over SegPGD in a wide variety of experiments.\n\nDoes this address your concern with respect to the difference of CosPGD to SegPGD?"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission909/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700647519718,
                "cdate": 1700647519718,
                "tmdate": 1700648904898,
                "mdate": 1700648904898,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8aaZvI51Qq",
                "forum": "ATaE46G1eJ",
                "replyto": "hP3IUznZP2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Q2"
                    },
                    "comment": {
                        "value": "Regarding question Q2, we would like to reconsider the example of semantic segmentation, i.e. the formulation that you see above, where both SegPGD and CosPGD scale the cross-entropy loss per pixel. \nThen, in CosPGD, we have the softmax of the prediction scores which means that the input to the cosine similarity is a set of two vectors, both of which have values between zero and one and are normalized to one. The one-hot encoded label vector $Y$ has values that are either zero or one. \nThis means that the ground truth $Y$ is a vector of binary values and just indicates the correct label. Therefore, we did not consider distribution losses (KL or JS) in general. This might be an interesting future research direction.\n\nIn principle, for the proposed scaling of the pixel-wise loss to be reasonable, the scaling value for the loss at each location also needs to be between zero and one. \nWe acknowledge that one could consider further variants for the scaling. Cross-entropy between the prediction and the GT will however map to an inappropriate value range, similar to  L2 or L1 distances between these two vectors, which would need to be normalized. The cosine similarity has the desired properties and seems appropriate to assess the angle between the softmax prediction and the ground truth. Therefore, the cosine similarity is an intuitive choice. We will add a respective discussion to the revision."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission909/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700650775767,
                "cdate": 1700650775767,
                "tmdate": 1700656846931,
                "mdate": 1700656846931,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "e8DUaVTZrk",
            "forum": "ATaE46G1eJ",
            "replyto": "ATaE46G1eJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission909/Reviewer_E2Ss"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission909/Reviewer_E2Ss"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposed a white-box adversarial attack method CosPGD that considers the cosine similarity between predictions and targets for each pixel.  The authors claimed that CosPGD can be used for various pixel-wise prediction tasks, outperforming existing attacks on semantic segmentation and providing insights into model performance. It is similar to SegPGD and the experiments are insufficient to validate the advantage of the proposed method."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1) The authors introduce the principle and method of CosPGD clearly in **Sec.3**.\n\n2) The universal design for loss function of CosPGD make it be applicable to a wide range of pixel-wise prediction tasks."
                },
                "weaknesses": {
                    "value": "1) Take the non-targeted attack as an example, the proposed loss function in Eq.(5) $L_{\\mathrm{cos}}=\\frac{1}{H \\times W} \\sum_{H \\times W} \\cos (\\overrightarrow{\\text { pred }}, \\overrightarrow{\\text { target }}) \\cdot L\\left(f_{\\text {net }}\\left(\\boldsymbol{X}^{\\text {adv } v}\\right), \\boldsymbol{Y}\\right),$\n   is very similar with the loss function of SegPGD[1]  $L_{SegPGD} = \\frac{1}{{H}\\times{W}} \\sum_{j\\in P^T} L_j + \\frac{1}{{H}\\times{W}} \\sum_{k\\in P^F} L_k$.  Thus, the novelty is limited.\n\n2) Although it claims that CosPGD can be used for various pixel-wise prediction tasks, but it does not bring about significant improvement compared to SegPGD[1] in image restoration task as shown in **Fig.7**, especially with 20 times iterations.\n\n3\uff09 In **Sec.4.2** the paper identify their method perform in optical flow task, but it only did experiments compared with PGD[2] in **Fig.5**. I wonder how is the SegPGD[1] perform in optical flow task?\n\n4\uff09 In **Sec4.3** the authors said \"We observe that at low number of attack iterations (3 attack iterations) it performs significantly worse than PGD, thus demonstrating its limitation on this task.\" However, the SegPGD[1] is need to adjust their balance factor during the attack iteration, and as far as I know, white box attacks usually don't compare attack performance at low iterations. So I do not think it is fair to compare with SegPGD[1] in 3 attack iterations.\n\nRef. [1] Gu J, Zhao H, Tresp V, et al. Segpgd: An effective and efficient adversarial attack for evaluating and boosting segmentation robustness[C]//European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2022: 308-325.\n\nRef. [2] A. Madry, A. Makelov, L. Schmidt, et al. Towards deep learning models resistant to adversarial attacks[J]. arXiv preprint arXiv:1706.06083, 2017.\n\n-----------------------------------\nAfter Rebuttal\n------------------------------------\nThanks a lot for the authors' rebuttal. The main concern still lies in its novelty.\n (1) While the rebuttal claims that \"there are no other attack method scaling the loss pixel-wise using similarity between the posterior and target distributions\", which seems a bit trivial and cannot be regarded as a main contribution to this field. \n(2) Although SegPGD can not be directly applied to image restoration, it can be adapted to other supervised learning tasks by doing some simple modifications.\n(3) Considering that authors have provided lots of experiments and analysis, I have upgraded the score."
                },
                "questions": {
                    "value": "Please see the weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission909/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission909/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission909/Reviewer_E2Ss"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission909/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698404046587,
            "cdate": 1698404046587,
            "tmdate": 1700531730586,
            "mdate": 1700531730586,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "j9d1xpMShC",
                "forum": "ATaE46G1eJ",
                "replyto": "e8DUaVTZrk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' rebuttal"
                    },
                    "comment": {
                        "value": "Dear Reviewer E2Ss,\n\n\nThank you very much for your insightful review. We hope to answer your questions in a satisfactory manner.\n\n1. The proposed CosPGD is motivated by SegPGD and indeed the equations might look similar at first glance. Yet, there are significant conceptual differences that provide a strong benefit of CosPGD over SegPGD, which we also discuss on page 3 in our submission. Please refer to our general reply for details on the conceptual differences between the two and the resulting benefit of CosPGD. Please note, that no other existing attack scales the loss pixel-wise using **similarity between the posterior and target distributions**. All attacks focus on final model predictions. This makes CosPGD significantly novel. Does this answer this important concern?\n\n\n2. For image restoration, SegPGD can not be directly applied but by defining a threshold to determine from when on a prediction is considered to be correct. For the comparison on image restoration, we assume that the prediction should be as correct as possible, i.e. assume the lowest numerically possible threshold. After this adaptation, SegPGD\u2019s performance comes close to the performance of CosPGD but only after 20 attack iterations. While CosPGD is significantly better for lower numbers of iterations. SegPGD nearly closing the gap in performance, despite taking 20 attack iterations, speaks to the credit of needing pixel-wise scaled adversarial attacks.\n\n\nFor the task of image restoration, 20 attack iterations take a significantly long amount of time to evaluate.\nThus we propose CosPGD, **an efficient attack** which as discussed in Section 4.3 can be very useful in predicting a new model\u2019s robustness efficiently.\nAdditionally, we would like to request the reviewer to reconsider the following snippet for Semantic segmentation from **Table 4 Section B.3 in the supplementary material**. Here we observe, that despite the numerical difference in performance at 20 iterations being low, the maximum difference being 3.19%, its significance is very high. CosPGD is bringing down the performance of multiple powerful segmentation models to almost 0% in just 20 attack iterations.\n\n|Model|Attack|mIoU at 20 attack iterations|mAcc at 20 attack iterations|\n|:----|:----|:----|:----|\n|UNet|SegPGD|2.98|14.24|\n| |CosPGD|0.06|0.38|\n|PSPNet|SegPGD|1.82|7.39|\n| |CosPGD|0.04|0.11|\n|DeepLabV3|SegPGD|3.31|12.4|\n| |CosPGD|0.12|0.48|\n\nPlease note as well that the remaining prediction quality after SegPGD and CosPGD are both very low for 20 attack iterations, and CosPGD is still consistently better.\n\n3. SegPGD can not be used on Optical Flow for the reasons detailed in Answer 1 unless the method is modified by defining a threshold. Similar to the results we provide for SegPGD for restoration, we can also report for optical flow as detailed below:\n\nTable 6 in Section C.1 in the appendix of the revised version (Table 4 in original submission). A Lower(\u2193) epe wrt to Target and a Higher( \u2191) epe wrt to Initial signifies a stronger attack.\n\n|Attack Iterations|KITTI2015| | | | | |MPI Sintel| | | | | | | | | | | |\n|----:|----:|----:|----:|----:|----:|----:|----:|----:|----:|----:|----:|----:|----:|----:|----:|----:|----:|----:|\n| | | | | | | |Clean| | | | | |Final| | | | | |\n| |PGD| |CosPGD| |SegPGD| |PGD| |CosPGD| |SegPGD| |PGD| |CosPGD| |SegPGD| |\n| |Target\u2193|Initial \u2191|Target\u2193|Initial \u2191|Target\u2193|Initial \u2191|Target\u2193|Initial \u2191|Target\u2193|Initial \u2191|Target\u2193|Initial \u2191|Target\u2193|Initial \u2191|Target\u2193|Initial \u2191|Target\u2193|Initial \u2191|\n|10|10.5|22.1|9|23.4|11.08|21.36|3.4|11.2|2.9|11.4|3.51|11.16|3.1|11.3|2.6|11.5|3.13|11.32|\n|20|8.1|24.6|6.5|25.8|7.76|24.55|2.8|11.7|2|12.1|2.97|11.61|2.5|11.8|1.6|12.1|2.62|11.7|\n|40|7.3|25|4.8|27.4|7.53|24.89|2.8|11.7|1.6|12.4|2.66|11.8|2.6|12.3|1.3|12.3|2.4|11.83|\n\nHowever, please note again that SegPGD was not conceived for optical flow attacks and the low performance is to be expected since SegPGD is not designed for regression tasks.\n\n4. CosPGD is stronger when few iterations are considered and therefore provides reliable results at a lower compute budget. The purpose of adversarial attacks is to reveal model weaknesses with as few iterations as possible. Therefore, we understand that an attack that outperforms others when run for only a few attack iterations is particularly valuable. In particular, when considering adversarial training, high attack iterations are extremely expensive and 3 attack iterations would be a typical value. \n\nWe hope we were able to answer all your questions to your satisfaction. Please let us know if you have further questions or concerns.\n\nBest Regards\n\nAuthors of Paper #909"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission909/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700024577904,
                "cdate": 1700024577904,
                "tmdate": 1700024638213,
                "mdate": 1700024638213,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nxuaVAQlcm",
                "forum": "ATaE46G1eJ",
                "replyto": "e8DUaVTZrk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Gentle Reminder"
                    },
                    "comment": {
                        "value": "Dear Reviewer E2Ss,\n\nWe were curious if you happened to find the time to read our official comments and incorporated changes in the revised version. If so, we would be glad to answer any further questions or doubts you might have.\n\nBest Regards,\n\nAuthors of Paper #909"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission909/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700511438892,
                "cdate": 1700511438892,
                "tmdate": 1700511438892,
                "mdate": 1700511438892,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3sExIMF6pn",
                "forum": "ATaE46G1eJ",
                "replyto": "e8DUaVTZrk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' reply to 'After Rebuttal'"
                    },
                    "comment": {
                        "value": "Dear Reviewer E2Ss,\n\nThank you for acknowledging the strength of our work in terms of experiments and analysis. \nWe would appreciate it if you would consider the following,\n\nBoth SegPGD and CosPGD propose to modify the update step of the original PGD applied to each pixel, as given in our equation (1).\n\n$sign\\nabla_{\\boldsymbol{X}}L$\n\n Here, we write L to denote the original model loss with respect to the current model $f$'s prediction based on an adversarial sample \n$\\boldsymbol X$    \n\nand the one-hot encoded ground truth $Y$.\n\nFor segmentation, i.e. in SegPGD $L$ is a cross-entropy loss as specified in their equation (2) . In our paper, we also use a cross entropy loss when considering segmentation, but $L$ can in principle be any loss of the respective original model, as in PGD. For optical flow, we use an optical flow loss, to be consistent with PGD.\n\nIn SegPGD, the above update is modified to\n\n$sign\\nabla_{\\boldsymbol{X}}(\\frac{1-\\lambda}{N}\\sum_{i\\in P^T} L_i  + \\frac{\\lambda}{N}\\sum_{k\\in P^F} L_k)$ \n\nwhere  $P^T$\nis the set of correctly classified pixels and  $P^F$ \nis the set of wrongly classified pixels, $N$ is the total number of pixels, and $\\lambda$ is a scaling factor between the two parts of the loss that is set heuristically. See their equation (4) for details. \n\nFor positive $\\lambda$, this equation could be rewritten as\n\n$sign\\nabla_{\\boldsymbol{X}}(\\frac{1}{N}\\sum_{i\\in P^T\\cup P^F} (1- |\\lambda - |(argmax(f(\\boldsymbol{X}))-Y|/2|) L_i) $\n\nfor adversarial examples \n$\\boldsymbol{X}$\n\ni.e. $|\\lambda - |(argmax(f(\\boldsymbol{X}))-Y|/2|$ equals $1-\\lambda$ for incorrect predictions, it equals $\\lambda$ for correct predictions.\n\nYou can consider this representation of SegPGD to be the starting point of our argument: no matter what loss to use for L, we argue that the weighting of the pixel-wise loss with this weight after the argmax is an issue: it limits SegPGD to applications where the correctness of the prediction can be evaluated in a binary way, and it disregards the actual prediction scores. This is why CosPGD proposes in our equation (5) proposes to use a continuous measure of correctness instead:\n\n$sign\\nabla_{\\boldsymbol{X}}(\\frac{1}{N}\\sum_{i\\in P^T\\cup P^F} cos(softmax(f(\\boldsymbol{X})), Y) L_i) $ \n\nPlease note that this facilitates CosPGD to operate on the segmentation scores instead of the final argmax predictions. Positive side aspects are that we do not need to set any heuristic parameter $\\lambda$ and that we can directly apply this same procedure for a wide variety of tasks beyond segmentation. The experiments we show demonstrate the significant benefit of considering the actual prediction scores w.r.t. the cosine similarity of their softmax to the ground truth.  \nWe empirically show the benefit of CosPGD over SegPGD in a wide variety of experiments.\n\nThus, we do not modify the loss, neither does SegPGD, the loss is the respective loss of the downstream task.\n**We are replacing the scaling in SegPGD with a closed-form continuous setting i.e. cosine similarity**.\n\nWe agree that SegPGD, with some modifications, can be extended to other downstream tasks. And we proposed CosPGD, which goes beyond SegPGD and is significantly stronger than SegPGD on the task for which SegPGD was proposed. \nAnd, as shown in our experiments, **CosPGD extends to other tasks much better than the adaptations of SegPGD to those tasks**.\n\nAdditionally, adversarial attacks are time and resource consuming. Thus, the availability of an efficient adversarial attack that requires merely 3 attack iterations to efficiently gauge a model\u2019s relative robustness is indeed a significant contribution to the field. As discussed in the paper for each downstream task considered, CosPGD is able to expose model vulnerabilities that were previously unknown even with SegPGD. \n\nMoreover, CosPGD requires merely 3 attack iterations during adversarial training to train a significantly more robust model.\n\n\nDoes this address your concern with respect to the difference of CosPGD to SegPGD and the novel contribution of this work?\n\nBest Regards\n\nAuthors of Paper #909"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission909/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700657960143,
                "cdate": 1700657960143,
                "tmdate": 1700658040831,
                "mdate": 1700658040831,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "xq7zXPUG4a",
            "forum": "ATaE46G1eJ",
            "replyto": "ATaE46G1eJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission909/Reviewer_kcAq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission909/Reviewer_kcAq"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes CosPGD, a unified white-box adversarial attack aiming to any pixel-wise prediction task based on the cosine similarity between the distributions over the predictions and ground truth. The effectiveness of the method is demonstrated through a series of experiments across multiple tasks including semantic segmentation, optical flow and image denoising."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "First and foremost, in comparison to the recently introduced SegPGD, CosPGD demonstrates a considerably more pronounced adversarial attack impact in semantic segmentation tasks. Notably, what sets CosPGD apart is its applicability beyond segmentation-specific tasks when compared to SegPGD. CosPGD serves as a versatile attack method applicable to any pixel-wise prediction task, boasting efficient deployment capabilities and superior efficacy in contrast to the general PGD method."
                },
                "weaknesses": {
                    "value": "Section 4.3's content warrants appropriate adjustment. This section primarily showcases the superior degradation effect of CosPGD on NAFNet in comparison to PGD and SegPGD (particularly at low attack iterations). However, this evidence alone may not adequately support the assertion that \"CosPGD can efficiently enhance a new model's robustness.\" To convincingly substantiate this claim, the authors should present more compelling evidence within the main body of the paper, rather than relegating it to the appendix. It is particularly essential to include results from the denoising task (as presented in Appendix D2)."
                },
                "questions": {
                    "value": "1. Although CosPGD exhibits substantial improvements over SegPGD in terms of attack efficacy and generality, it is worth noting that SegPGD also contributes significantly to enhancing model robustness through adversarial training. The absence of corresponding experiments makes it challenging to completely establish the effectiveness of this aspect.\n\n2. An inquiry arises regarding the rationale behind the author's choice of an optical flow experiment to evaluate the versatility of CosPGD. The choice of optical flow as a benchmark should be substantiated by explaining how the characteristics of this task effectively highlight the advantages of CosPGD. Furthermore, additional experiments should be incorporated to showcase CosPGD's performance in various image restoration tasks, such as single image deraining, to bolster its claims further.\n\n3. It seems like the authors need to reorganize the contribution of the paper, since the core of the paper is actually a general improvement on adversarial training for pixelwise classification tasks."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission909/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission909/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission909/Reviewer_kcAq"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission909/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698585587039,
            "cdate": 1698585587039,
            "tmdate": 1699636017563,
            "mdate": 1699636017563,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6QqXVFOvOF",
                "forum": "ATaE46G1eJ",
                "replyto": "xq7zXPUG4a",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Authors' rebuttal to weakness and questions"
                    },
                    "comment": {
                        "value": "Dear Reviewer kcAq,\n\nThank you very much for your insightful review. We hope to answer your questions in a satisfactory manner.\n\n**Answer to weakness:**\n\nPlease refer again to our section 4.3. We never make the claim that  \"CosPGD can efficiently enhance a new model's robustness\". \nInstead, we propose CosPGD as an effective adversarial attack that can evaluate a model\u2019s relative robustness correctly even with low attack iterations (iterations<=3).\nThus our claim is: \u201cCosPGD can be very useful in **predicting** a new model\u2019s robustness efficiently.\u201d Would you agree that this claim is sufficiently substantiated by our experiments (including the new results we provide in the rebuttal), or is there anything else you would like to see in particular? \n\n**Answers to Questions:**\n\n1. Adversarial attacks have a purpose beyond adversarial hardening: the evaluation of existing methods in terms of stability/robustness.  We therefore focused on evaluating CosPGD across diverse conditions. In the following, we also report a comparison in terms of adversarial training. Here the models were trained with the \u201cTraining Attack\u201d with 3 attack iterations, $\\alpha$=0.01 and $\\epsilon\\approx\\frac{8}{255}$ with a 50%-50% minibatch split, meaning only 50% of the samples in a batch were adversarially perturbed. Then, the adversarially trained models were evaluated using \u201cTesting Attack\u201d with multiple attack iterations are shown in the following table (here we report only the mIoU(%) for better readability):\n\n|Model|Training Attack|Testing Attack|3 attack iterations|5 attack iterations|10 attack iterations|20 attack iterations|40 attack iterations|100 attack iterations|\n|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n|UNet|None|PGD|23.18|14.58|8.21|5.57|4.14|3.6|\n| |PGD|PGD|29.26|21.28|13.74|9.29|7.47|6.38|\n| |SegPGD|PGD|31.77|22.77|14.86|11.03|8.98|7.45|\n| |**CosPGD**|PGD|**47.35**|**43.75**|**38.1**|**34.33**|**32.28**|**30.55**|\n| |None|SegPGD|12.38|7.75|4.46|2.98|2.2|1.55|\n| |PGD|SegPGD|29.38|21.31|13.77|9.39|7.45|6.38|\n| |SegPGD|SegPGD|31.69|22.47|14.82|10.9|9.09|7.33|\n| |**CosPGD**|SegPGD|**47.16**|**43.85**|**37.64**|**33.99**|**31.91**|**30.48**|\n| |None|CosPGD|9.67|3.71|0.61|0.06|0.03|0.01|\n| |PGD|CosPGD|29.23|21.09|13.49|9.28|7.36|6.29|\n| |SegPGD|CosPGD|31.53|22.46|14.81|10.86|9.2|7.28|\n| |**CosPGD**|CosPGD|**47.07**|**43.95**|**37.64**|**34.01**|**32.0**|**30.55**|\n\n\nWe include this table in the revised version of the paper as Table 5 in Section B.4\n\nAdditionally, we include Figure 11 in Section B.4 in the revised version of the paper, in this figure we show the segmentation masks predicted by UNet after being adversarially trained. We observe that even after 100 attack iterations, the model adversarially trained using CosPGD is making reasonable predictions. \nHowever, the model trained with SegPGD is merely predicting a blob.\n\n\n2. Could you please rephrase this question? We are not sure if we understand it correctly. Our rationale is that previous methods for attacks on pixel-wise prediction tasks always only focused on a single task, i.e. there has been SegPGD for semantic segmentation and PCFA for Optical Flow. CosPGD is more general than both and can therefore be applied to both. In Section 4.2 Optical Flow: we explain in detail how CosPGD is exposing model vulnerabilities that were unknown before. \nTo further showcase the generality of the approach, we also evaluate it on image restoration for recent SotA methods. Does this address your question?\nRegarding deraining, we attempted to evaluate CosPGD on the SotA [a]. Yet, the model is too large to fit on our hardware when access to model gradients is needed (which is the case for white-box attacks). The model [a] was trained on 32 NVIDIA Tesla V100. If you can refer us to a more light-weight model of your choice, we will gladly provide the evaluation. \n[a] Chen et al., Pre-Trained Image Processing Transformer (IPT), 2021.\n\n\n3. There seems to be a misconception: as specified in the contribution section, the contribution is not the improvement of adversarial training but proposing the first adversarial attack that provides a unified evaluation for diverse pixel-wise prediction tasks. Of course, adversarial attacks can be used for adversarial training (see our response to your Q1 for such results) and better adversarial attacks often result in better adversarial training. Our results above show that this is also the case for CosPGD.\n\nWe hope we were able to answer all your questions to your satisfaction. Please let us know if you have further questions or concerns.\n\nBest Regards\n\nAuthors of Paper #909"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission909/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700023804506,
                "cdate": 1700023804506,
                "tmdate": 1700023976143,
                "mdate": 1700023976143,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dlliAKg47Z",
                "forum": "ATaE46G1eJ",
                "replyto": "xq7zXPUG4a",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Gentle Reminder"
                    },
                    "comment": {
                        "value": "Dear Reviewer kcAq,\n\nWe were curious if you happened to find the time to read our official comments and incorporated changes in the revised version. If so, we would be glad to answer any further questions or doubts you might have.\n\nBest Regards,\n\nAuthors of Paper #909"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission909/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700511404270,
                "cdate": 1700511404270,
                "tmdate": 1700511404270,
                "mdate": 1700511404270,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "n0eqn2fZqr",
            "forum": "ATaE46G1eJ",
            "replyto": "ATaE46G1eJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission909/Reviewer_YMdT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission909/Reviewer_YMdT"
            ],
            "content": {
                "summary": {
                    "value": "This paper concentrates on adversarial attacks tailored for pixel-wise prediction tasks such as semantic segmentation, optical flow prediction, and image restoration. \nIt uncovers that PGD, a method commonly used in image classification, is not efficient for pixel-wise prediction tasks, and SegPGD, a method designed for semantic segmentation, is not applicable to other pixel-wise tasks. \nThe paper introduces CosPGD, an efficient white-box adversarial attack specifically designed for pixel-wise prediction tasks. It utilizes cosine similarity between prediction distributions and ground truth (or target, in the case of targeted attacks) to weight the loss value of each pixel, enabling more effective and nuanced attacks. \nExperimental results across various datasets and settings demonstrate CosPGD's superiority and versatility in assessing the robustness of models for pixel-wise prediction tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed CosPGD is a relatively simple modification of SegPGD, yet it significantly enhances effectiveness across multiple datasets. While SegPGD differentiates between pixels that are predicted correctly and those predicted incorrectly during the generation of adversarial examples, assigning different pre-defined weights to the loss terms of correctly and incorrectly predicted pixels, CosPGD replaces these pre-defined weights with cosine similarities between the predictions and ground truth at each pixel. Experimental results demonstrate that this modification results in a more effective attack.\n\n2. CosPGD is applicable to a variety of pixel-wise prediction tasks, including semantic segmentation, optical flow prediction, and image restoration. Unlike SegPGD, which is limited to pixel-wise classification tasks, CosPGD can be readily extended to both pixel-wise classification and regression tasks. Experimental results confirm the effectiveness of CosPGD on several pixel-wise prediction tasks.\n\n3. There are abundant ablation experiments regarding hyper-parameters such as perturbation bounds, step sizes, and iteration steps, all of which verify the effectiveness of CosPGD compared to previous methods like PGD and SegPGD."
                },
                "weaknesses": {
                    "value": "1. The paper does not provide sufficient comparisons and discussions related to recent works in pixel-wise prediction tasks, such as Qu et al. [1], and other applicable attacks in image classification, like C&W [2], and MI-FGSM [3].\n\n[1] Qu et al. \"A Certified Radius-Guided Attack Framework for Image Segmentation Models.\"\n[2] Carlini et al. \"Towards Evaluating the Robustness of Neural Networks.\"\n[3] Dong et al. \"Boosting Adversarial Attacks with Momentum.\"\n\n2. Why does using cosine similarity as a weight (in CosPGD) outperform predefined weights (in SegPGD)? Is there a detailed explanation?\n\n3. Why does the paper adopt different settings for the three tasks: non-targeted attacks for semantic segmentation and image restoration, and targeted attacks for optical flow prediction? What about the performance of targeted attacks for semantic segmentation and image restoration?\n\n4. The experimental results presented in Figures 14 and 15 make it challenging to discern the numerical values. Presenting the data in a tabular form would be more beneficial.\n\n5.There is a lack of a detailed definition for $L$ in equations (1), (5), and (6)."
                },
                "questions": {
                    "value": "See in weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission909/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission909/Reviewer_YMdT",
                        "ICLR.cc/2024/Conference/Submission909/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission909/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698799862917,
            "cdate": 1698799862917,
            "tmdate": 1700658320116,
            "mdate": 1700658320116,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mBrcpsh4m2",
                "forum": "ATaE46G1eJ",
                "replyto": "n0eqn2fZqr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Additional evaluations on C&W and MI-FGSM and answers to the questions"
                    },
                    "comment": {
                        "value": "Dear Reviewer YMdT,\n\nThank you very much for your insightful review. We hope to answer your questions in a satisfactory manner.\n\n1. Thank you for the suggestion. We provide the following evaluation on semantic segmentation on Pascal VOC 2012 using UNet for [2] and [3]. For C&W [2], we have been evaluating the default parameters (c=1) here but have a strong suspicion that tuning c will improve results. We experimented with c={0.5, 1, 2, 8} and it did not make an impact on the performance. Would you have a particular suggestion for the choice of c? \n\nFor MI-FGSM [3] 100 iterations, the evaluation did not finish within 24 hours, which was the time limit for our GPU usage, but we can report all other iterations.\nWe observe that CosPGD significantly outperforms all other attacks, across attack iterations and $l_p$ norms. For $l_{\\infty}$-norm attacks $\\alpha$=0.01 and $\\epsilon \\approx \\frac{8}{255}$. We add these results to Table 4 in Section B.3 in the revised version of the paper.\n\nFor $l_2$-norm attacks in the table, where applicable $\\alpha$=0.2 and $\\epsilon \\approx \\frac{128}{255}$.\nWe include this table in the revised version of the paper as Table 3 in Section B.2.1\n\n (here we report only the mIoU(%) for better readability)\n\n|Model|Attack|Norm|3 iterations|5 iterations|10 iterations|20 iterations|40 iterations|100 iterations|\n|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n|DeepLabV3|MI-FGSM|$l_{\\infty}$|10.86|7.75|6.95|6.67|6.57|\u2014|\n| |PGD|$l_{\\infty}$|10.69|8|7.02|6.84|6.79|7.01|\n| |SegPGD|$l_{\\infty}$|6.76|4.86|3.84|3.31|2.69|2.15|\n| |**CosPGD**|$l_{\\infty}$|**4.44**|**1.84**|**0.69**|**0.12**|**0.08**|**0.005**|\n| |CW (c=1)|$l_2$|72.35|72.02|71.87|71.81|71.78|71.77|\n| |PGD|$l_2$|41.81|34.5|27.61|23.73|21.47|19.84|\n| |SegPGD|$l_2$|37.51|29.9|22.72|19.2|16.8|14.77|\n| |**CosPGD**|$l_2$|**36.17**|**27.12**|**18.68**|**14.35**|**12.23**|**10.97**|\n\nAlso, thank you for the pointer to reference [1]. Our experiments focus on the wide applicability of CosPGD rather than on outperforming a particular, dedicated approach on a particular task. We will try to provide results comparing our method to [1] for the final version, which is however not trivial since [1] proposes a certified radius-guided attack framework and CosPGD is an epsilon-bounded attack. In any case, we cite the paper in the revised version. Please note that according to the ICLR guidelines, https://iclr.cc/Conferences/2024/ReviewerGuide, publications from recent conferences (\u201cpublished [...] within the last four months\u201d: \u201con or after May 28, 2023\u201d) are assumed to be contemporaneous work and a comparison is not required - this is the case for [1].\n\nAdditionally, we came across another interesting related work that we have now cited in the related work of the revised version of the paper. \nJia, J., Qu, W. and Gong, N., 2022. MultiGuard: Provably Robust Multi-label Classification against Adversarial Examples. Advances in Neural Information Processing Systems, 35, pp.10150-10163.\n\n2. The most important conceptual difference between SegPGD and CosPGD is that the weighting with fixed weights is applied after the argmax operation in SegPGD. This removes important information and makes the attack optimization unstable. As a remedy, SegPGD uses a linear combination of the weights and non-weighted loss terms, where the combination weight is a heuristic. The use of the cosine similarity is therefore more informative: we compute the softmax of the class scores for segmentation to preserve the continuous prediction information. For the resulting positive valued prediction vectors, the cosine similarity is particularly suitable. Additionally, it extends well to pixel-wise regression tasks like optical flow estimation, image restoration etc. If the reviewer suggests, we can add this discussion to the final paper."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission909/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700023073560,
                "cdate": 1700023073560,
                "tmdate": 1700023849948,
                "mdate": 1700023849948,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "10W1cSnlA1",
                "forum": "ATaE46G1eJ",
                "replyto": "n0eqn2fZqr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission909/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Additional Results"
                    },
                    "comment": {
                        "value": "Dear Reviewer YMdT,\n\nFollowing your suggestion in Weakness #4, we have now included **Table 8 in the revised version** to be included in Section C.3 later, which is an extension to results from Figures 14, 15, and 16 in the revised version (were Figures 13, 14, and 15 in the original submission) over 3 random seeds in a tabular form.\n\nFor ease of reading, in the following tables, we present Table 8: a comparison of the performance of CosPGD to PCFA as a targeted $l_2$-norm constrained attack for optical flow estimation over KITTI2015 and Sintel validation datasets using different optical flow models over 3 random seeds. Average $epe$ (AEE) values are compared, with respect to both, the **Target**  where a lower $epe$ indicates a better attack and **Initial flow prediction** (optical flow estimated by the model before any adversarial attack) where a higher $epe$ indicates a better attack. \nWe compare over both targets used by [4], i.e. zero vector $\\overrightarrow{0}$ and Negative of the Initial Flow.\nAs observed earlier in the respective figures, **the performance of CosPGD is at-par with the recently proposed Optical Flow specific attack**.\n\n\n|Model| | || | KITTI 2015 | | | |\n|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n| | | Negative Flow Target | | ||Zero Vector Target|  | |\n| |AEE wrt initial| |AEE wrt Target| |AEE wrt initial| |AEE wrt Target| |\n| |CosPGD|PCFA|CosPGD|PCFA|CosPGD|PCFA|CosPGD|PCFA|\n|GMA|47.00 \u00b1 0.40|47.08 \u00b1 0.69|19.22 \u00b1 0.53|19.20 \u00b1 0.57|28.69 \u00b1 0.12|28.67 \u00b1 0.17|3.89 \u00b1 0.09|3.89 \u00b1 0.15|\n|PWCNet|33.13 \u00b1 0.25|33.13 \u00b1 0.26|12.01 \u00b1 0.20|12.02 \u00b1 0.22|19.13 \u00b1 0.04|18.96 \u00b1 0.08|3.25 \u00b1 0.08|3.47 \u00b1 0.14|\n|RAFT|48.83 \u00b1 0.35|48.93 \u00b1 0.29|17.97 \u00b1 0.29|17.81 \u00b1 0.27|29.09 \u00b1 0.03|29.17 \u00b1 0.11|3.75 \u00b1 0.05|3.63 \u00b1 0.10|\n|SpyNet|12.10 \u00b1 0.02|12.08 \u00b1 0.05|16.47 \u00b1 0.03|16.44 \u00b1 0.05|9.00 \u00b1 0.01|9.01 \u00b1 0.03|5.31 \u00b1 0.01|5.35 \u00b1 0.06|\n\n\n|Model| | | | Sintel (clean)| | | | |\n|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n| | | Negative Flow Target|  | | | Zero Vector Target| | | \n| |AEE wrt initial| |AEE wrt Target| |AEE wrt initial| |AEE wrt Target| |\n| |CosPGD|PCFA|CosPGD|PCFA|CosPGD|PCFA|CosPGD|PCFA|\n|GMA|29.25 \u00b1 0.38|29.05 \u00b1 0.38|8.58 \u00b1 0.34|8.82 \u00b1 0.37|16.87 \u00b1 0.14|16.76 \u00b1 0.11|1.75 \u00b1 0.15|1.85 \u00b1 0.10|\n|PWCNet|20.57 \u00b1 0.21|20.43 \u00b1 0.21|13.20 \u00b1 0.13|13.21 \u00b1 0.29|12.20 \u00b1 0.21|12.18 \u00b1 0.07|4.87 \u00b1 0.17|4.75 \u00b1 0.12|\n|RAFT|29.01 \u00b1 0.11|29.20 \u00b1 0.01|7.67 \u00b1 0.11|7.47 \u00b1 0.05|16.42 \u00b1 0.03|16.46 \u00b1 0.05|1.69 \u00b1 0.04|1.65 \u00b1 0.06|\n|SpyNet|13.08 \u00b1 0.01|13.17 \u00b1 0.03|18.75 \u00b1 0.02|18.76 \u00b1 0.06|9.69 \u00b1 0.01|9.75 \u00b1 0.07|6.40 \u00b1 0.05|6.35 \u00b1 0.00|\n\n\n|Model| | | | Sintel (final)| | | | |\n|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n| | | Negative Flow Target| | | | Zero Vector Target| ||\n| |AEE wrt initial| |AEE wrt Target| |AEE wrt initial| |AEE wrt Target| |\n| |CosPGD|PCFA|CosPGD|PCFA|CosPGD|PCFA|CosPGD|PCFA|\n|GMA|32.11 \u00b1 0.20|32.04 \u00b1 0.24|4.57 \u00b1 0.22|4.64 \u00b1 0.24|17.34 \u00b1 0.07|17.31 \u00b1 0.11|0.53 \u00b1 0.07|0.54 \u00b1 0.11|\n|PWCNet|23.00 \u00b1 0.30|23.01 \u00b1 0.06|10.84 \u00b1 0.28|10.75 \u00b1 0.05|13.61 \u00b1 0.10|13.44 \u00b1 0.14|3.52 \u00b1 0.13|3.66 \u00b1 0.12|\n|RAFT|32.72 \u00b1 0.22|32.72 \u00b1 0.14|3.71 \u00b1 0.21|3.75 \u00b1 0.13|17.38 \u00b1 0.04|17.36 \u00b1 0.03|0.55 \u00b1 0.09|0.50 \u00b1 0.03|\n|SpyNet|16.51 \u00b1 0.01|16.55 \u00b1 0.06|16.52 \u00b1 0.01|16.47 \u00b1 0.05|11.56 \u00b1 0.01|11.59 \u00b1 0.03|4.97 \u00b1 0.01|4.97 \u00b1 0.01|\n\nPlease do let us know if you have any further questions or concerns, we would be glad to address them.\n\nBest Regards\n\nAuthors of Paper #909\n\n[4] Schmalfuss, Jenny, Philipp Scholze, and Andr\u00e9s Bruhn. \"A perturbation-constrained adversarial attack for evaluating the robustness of optical flow.\" European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2022."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission909/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700511177327,
                "cdate": 1700511177327,
                "tmdate": 1700511177327,
                "mdate": 1700511177327,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KrwzHOD8jQ",
                "forum": "ATaE46G1eJ",
                "replyto": "g6xBcgXRRd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission909/Reviewer_YMdT"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission909/Reviewer_YMdT"
                ],
                "content": {
                    "title": {
                        "value": "Feedback for Rebuttal"
                    },
                    "comment": {
                        "value": "Thanks for your solid rebuttal. I will slightly raise the score"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission909/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700658302392,
                "cdate": 1700658302392,
                "tmdate": 1700658302392,
                "mdate": 1700658302392,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]