[
    {
        "title": "Fine-Tuned Language Models Generate Stable Inorganic Materials as Text"
    },
    {
        "review": {
            "id": "4sXeMoNvDM",
            "forum": "vN9fpfqoP1",
            "replyto": "vN9fpfqoP1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5580/Reviewer_1Fky"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5580/Reviewer_1Fky"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes an approach to materials discovery by fine-tuning large language models (LLMs) on text-encoded atomistic data. The authors claim that this method can generate materials predicted to be metastable at a higher rate than competing diffusion models."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The paper is well-motivated, addressing the limitations of existing computational materials databases and the potential of generative models for materials discovery.\n* The proposed approach of fine-tuning large language models on text-encoded atomistic data is novel and unorthodox, offering a new perspective on materials generation.\n* The paper is well-written, providing clear background information and a thorough explanation of the proposed method."
                },
                "weaknesses": {
                    "value": "Related concerns are discussed in the questions section."
                },
                "questions": {
                    "value": "* Can the authors provide a more detailed comparison with existing generative models in materials discovery, discussing the advantages and limitations of the proposed LLM-based approach compared to other state-of-the-art methods?\n* Are there any potential drawbacks or limitations of using LLMs for materials discovery, such as computational complexity or interpretability of the generated structures?\n* In the paper, the authors mention that \"We chose not to augment the ordering of atoms because these variables often contained valuable information\". How to ensure that the atomic order will not change the results?\n* In the paper, the authors mention that \"we only run VASP calculations on materials that have already been predicted as metastable by M3GNet\", while in the caption of figure 3, \"we only run VASP on structures predicted to be stable by M3GNet.\" What are the differences between the \"stable\" and \"metastable\"?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5580/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698561386707,
            "cdate": 1698561386707,
            "tmdate": 1699636574544,
            "mdate": 1699636574544,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "P3SWuC5mSB",
                "forum": "vN9fpfqoP1",
                "replyto": "4sXeMoNvDM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5580/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5580/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Rebuttal to Reviewer 1Fky"
                    },
                    "comment": {
                        "value": "Thank you for your review and your supportive comments. We respond to your questions pointwise. Note we have a separate [general post](https://openreview.net/forum?id=vN9fpfqoP1&noteId=wbNkvYNin2) outlining the key contributions in the paper.\n\n**Existing generative models**\n\nState-of-the-art generative models of materials from recent work can be grouped in two categories (1) diffusion models trained to denoise atomic coordinates (2) language models trained from scratch on crystal data. \n\n**(1) Overview**\n\n- *Diffusion models*: Methods like CDVAE [1] and DiffCSP [2] learn a distribution over crystal structures by learning a neural network that takes noise-corrupted coordinates and/or lattice parameters and predicts the original input without noise. During sampling, examples are generated from noise through repeated applications of the denoising model. Because these methods operate on continuous representations of the coordinates and lattice (as opposed to discrete string representation), they can naturally incorporate symmetries into the architecture of the denoising model, for example translational equivariance. \n\n- *Language models*: Prior work on language models for crystals, e.g. [3,4], focuses on training models from scratch on crystal data. In these papers, GPT-2 style models with 10-100 million parameters are trained on custom vocabularies to represent element identities and atomic coordinates. [3] uses a relatively small dataset of around 50,000 materials while [4] uses millions of CIF files. [3] applies augmentations to encourage invariance in the model while [4] does not. \n\n- *Our method*: We finetune a pretrained large language model using a relatively small number of additional trainable parameters (between 3 and 35 million). We use LLaMA-2\u2019s default tokenizer, which allows us to train on both crystal data and English text prompts. We apply augmentations to encourage invariance and measure learned invariance with a new metric useful to many applications of LLMs on atomistic data.\n\n**(2) Capabilities**\n\n- *Diffusion models*: Because diffusion models are trained to correct noisy inputs, they are often directly applicable to infilling tasks, e.g. for editing a small part of an existing structure. Additionally, because diffusion models act directly on continuous representations of coordinates they often exhibit higher rates of structural validity because notions of distance between atoms are more easily accessible to the model. On the other hand, compared to autoregressive language models, diffusion models often display lower rates of compositional validity, likely because compositions are naturally discrete sequences, and autoregressive language models remain state of the art generative models for discrete sequence. \n\n- *Language models*: Because language models are commonly used for text processing, they naturally incorporate text-conditional generation, which is explored to a limited degree in [4] but not in [3]. By default, language models are slightly less natural for editing tasks, unless trained with carefully chosen prompts, which is not explored in prior work. Because language models operate on string representations of atomic coordinates, they often have lower rates of structural validity because notions of distance/overlapping atoms must be learned over discrete sequences.\n\n- *Our method*: By using pretrained language models and carefully engineered prompts, we can achieve the best of both worlds. Our models are capable of editing existing structures and conditioning on complex English prompts. Text pretraining also leads to models that more easily learn programmatic abstractions over text, e.g. for analyzing positions in 3D space. Thus we see that finetuned LLMs, especially larger models like LLaMA-2 70B, achieve high rates of both structural and compositional validity. \n\n**(3) Generality**\n\t\t\n- *Diffusion models*: Models like CDVAE [1] and DiffCSP [2] are tailored specifically to generating crystals. The same methodology can not be applied to other atomistic data without major changes to the architecture and training procedure. \n\n- *Language models*: Unlike the diffusion models above, the training procedures used for language modeling are easier to generalize across different forms of atomistic data, as shown in [3]. When using custom vocabularies, however, the model weights themselves cannot be shared, despite shared training and sampling procedures. \n\n- *Our method*: By using a general-purpose tokenization method and a pretrained language model, we create a procedure that applies equally to natural language and string-formatted atomistic data. Though we focused primarily on crystals, a single LLM could also be trained simultaneously on other data types, such as small organic molecules or proteins."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5580/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700512609493,
                "cdate": 1700512609493,
                "tmdate": 1700512609493,
                "mdate": 1700512609493,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UoagcGouJL",
                "forum": "vN9fpfqoP1",
                "replyto": "WpiiMAfMTj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5580/Reviewer_1Fky"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5580/Reviewer_1Fky"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their response. But I'm still confused about the atomic order problem. As the example shows, if the atomic order changes, such as \n```\nLattice\n    abc: 6.29 6.29 6.34\n    angles: 60.3 60.3 60.0\nCoordinates (fractional)\n    Pb (0.0, 0.0, 0.0)\n    Pd (0.5, 0.5, 0.0)\n    Pd (0.5, 0.0, 0.0)\n    Pd (0.0, 0.5, 0.0)\n    Pb (0.5, 0.5, 0.5)\n    Se (0.21, 0.21, 0.36)\n    Se (0.79, 0.79, 0.64)\n```\nThe two systems are indeedly same. Will the framework recognize it?"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5580/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700620081052,
                "cdate": 1700620081052,
                "tmdate": 1700620081052,
                "mdate": 1700620081052,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IIr8CDHXzf",
                "forum": "vN9fpfqoP1",
                "replyto": "4sXeMoNvDM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5580/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5580/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your follow-up question. To clarify, the two examples are not identical to our LLMs. The example you provided and the example that we provided will be assigned slightly different likelihoods. We found that encouraging the model to learn an exact invariance hurt overall sample quality, most likely for the reasons we explore in the rebuttal. If we look at the likelihood that the model assigns to each of these examples, however, we see that it is very nearly invariant to these types of changes (permutations of the ordering) by default. To demonstrate this invariance, let's consider two types of changes\n\n**(a) permutations of the ordering**, for example\n\n```\nLattice\n    abc: 6.29 6.29 6.34\n    angles: 60.3 60.3 60.0\nCoordinates (fractional)\n    Pd (0.5, 0.5, 0.0)\n    Pd (0.5, 0.0, 0.0)\n    Pd (0.0, 0.5, 0.0)\n    Pb (0.5, 0.5, 0.5)\n    Pb (0.0, 0.0, 0.0)\n    Se (0.21, 0.21, 0.36)\n    Se (0.79, 0.79, 0.64)\n```\nto \n```\nLattice\n    abc: 6.29 6.29 6.34\n    angles: 60.3 60.3 60.0\nCoordinates (fractional)\n    Pb (0.0, 0.0, 0.0)\n    Pd (0.5, 0.5, 0.0)\n    Pd (0.5, 0.0, 0.0)\n    Pd (0.0, 0.5, 0.0)\n    Pb (0.5, 0.5, 0.5)\n    Se (0.21, 0.21, 0.36)\n    Se (0.79, 0.79, 0.64)\n```\n\n**(b) permutations of the ordering and swapping elements**, for example\n\n```\nLattice\n    abc: 6.29 6.29 6.34\n    angles: 60.3 60.3 60.0\nCoordinates (fractional)\n    Pd (0.5, 0.5, 0.0)\n    Pd (0.5, 0.0, 0.0)\n    Pd (0.0, 0.5, 0.0)\n    Pb (0.5, 0.5, 0.5)\n    Pb (0.0, 0.0, 0.0)\n    Se (0.21, 0.21, 0.36)\n    Se (0.79, 0.79, 0.64)\n```\nto \n```\nLattice\n    abc: 6.29 6.29 6.34\n    angles: 60.3 60.3 60.0\nCoordinates (fractional)\n    Se (0.5, 0.5, 0.0)\n    Se (0.5, 0.0, 0.0)\n    Se (0.0, 0.5, 0.0)\n    Pb (0.21, 0.21, 0.36)\n    Pb (0.79, 0.79, 0.64)\n    Pd (0.5, 0.5, 0.5)\n    Pd (0.0, 0.0, 0.0)\n```\n\nTransformations of type **(a)** should be unimportant to the model while changes of type **(b)** can generate completely implausible structures and should therefore decrease the likelihood assigned by the model. If we sample 10 transformations of each type for the original example and obtain the log likelihoods of each transformed structure as assigned by LLaMA-2 70B we obtain the following average changes in log likelihood (from the starting example to the transformed example). \n\n| Transformation Type | Avg. Delta Log Likelihood |\n| -------- | -------- | \n| (a) | -0.077 | \n| (b) | -3.647 | \n\nFor permutations of the ordering, the log likelihood barely changes, while changes that swap element identities typically decrease the log likelihood significantly. Thus, while we do not explicitly enforce permutation invariance, we can see that our model learns that permutations are not very significant and that other types of transformations are."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5580/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700636776593,
                "cdate": 1700636776593,
                "tmdate": 1700636847169,
                "mdate": 1700636847169,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "arOLl3hw1p",
            "forum": "vN9fpfqoP1",
            "replyto": "vN9fpfqoP1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5580/Reviewer_iXqY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5580/Reviewer_iXqY"
            ],
            "content": {
                "summary": {
                    "value": "This paper propose a new application area for large language models (LLMs), i.e. LLaMA-2. The author leverages parameter-efficient fine-tuning to use LLMs. Based on domain expertise in material sciences, the author evaluated the proper tokenization methods for crystal structures and developed new metric to further include symmetric information into fine-tuning process."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. the author got good performance in the shown benchmarks.\n2. the method seems solid since it has been widely used in many other domains."
                },
                "weaknesses": {
                    "value": "1. While one anticipates good performance from LLMs on standard evaluation metrics, especially with the likes of LLaMA-70B, the critical matter lies in the practical application in experiments.\n\n2. Given that LLMs can sometimes produce hallucinations, it would be beneficial to comprehensively evaluate this behavior in large models, rather than merely touching upon it in the limitations section. Presenting failure examples could offer valuable insights.\n\n3. Regarding Figure 2, could the authors elucidate why larger models result in poorer coverage?"
                },
                "questions": {
                    "value": "See above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5580/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698638464279,
            "cdate": 1698638464279,
            "tmdate": 1699636574443,
            "mdate": 1699636574443,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "WNjSLBgnV9",
                "forum": "vN9fpfqoP1",
                "replyto": "arOLl3hw1p",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5580/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5580/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Rebuttal to Reviewer iXqY"
                    },
                    "comment": {
                        "value": "Thank you for your review. We engage with each of your questions individually below:\n\n> \u201cone anticipates good performance from LLMs on standard evaluation metrics, especially with the likes of LLaMA-70B\u201d \n\nAlthough LLMs and parameter-efficient finetuning have become popular for many tasks in vision and natural language processing, they are not commonly applied to problems in materials science, a field that typically does not typically utilize foundation models [1]. Our application is very nonstandard for language models and many researchers would not expect language models to perform well on this task because they are not designed with modeling 3D space in mind. Our paper is surprising and exciting because it shows that text pretraining allows LLMs to model physical constraints very effectively, with a small number of trainable parameters on par with domain-specific models trained from scratch (4.5 million trainable parameters for CDVAE [2] vs. 3.5 million trainable parameters for LLaMA-2 7B with LoRA). \n\n>\"the critical matter lies in the practical application in experiments\"\n\nWe strongly agree that practical performance is critical, and this belief was the motivation behind our extensive evaluations with DFT. These simulations verify that the model can generate plausible materials at a much higher rate than competing approaches and therefore requires less filtering before deployment in real physical experiments. The fact that LLMs consistently generate stable materials is very strong evidence that LLMs are learning fundamental properties of materials and not simply superficial correlations. The computational burden of our methods is also not prohibitive, as we detail in our general rebuttal note. Generation from our smallest LLaMA model requires only about 24 mins for 10,000 samples, while achieving better rates of metastability under M3GNet and comparable rates of stability under DFT. There are countless teams worldwide deploying real applications on top of LLaMA models of all sizes, and LLaMA-2 70B was downloaded 177,000 times from Hugging Face last month alone. Use of these models, therefore, doesn\u2019t preclude practical applications and can in fact make it easier to leverage general advances in training and deploying LLMs (e.g. the GPT-4 fine-tuning API).\n\n> \u201cPresenting failure examples could offer valuable insights\u201d \n\nWe first note that there is already a hallucination example displayed in Figure 4, which is discussed on page 8. In this example, the model hallucinates an element named \u201cLn\u201d. There is no such element on the periodic table, but \u201cLn\u201d is a common abbreviation for Lanthanide, a class of elements on the periodic table. Much like other hallucinations, this generation is plausible but ultimately incorrect.\n\n> \u201cGiven that LLMs can sometimes produce hallucinations, it would be beneficial to comprehensively evaluate this behavior in large models\u201d\n\nWhile hallucinations are challenging in many LLMs applications because of the challenges of verifying correct answers, we would like to clarify that the types of hallucinations described here are easy to deal with. There are two forms of hallucination that occur in our case: (a) hallucination of non-physical structures or compositions (b) hallucination of non-existent elements. As we show in the paper, hallucination of non-physical compositions actually occurs at a lower rate in our models compared to the baselines and the rate of non-physical structures approaches zero. Because we use LLaMA-2 tokens without modification, it is possible for the model to sample imaginary elements, but we found that this behavior became exceedingly rare in large models, and could be avoided altogether by only sampling tokens corresponding to known elements. In both cases, samples can be checked for validity in less than one second, making hallucinations in materials generation fundamentally different than in many other LLM applications. \n\nIt is also worth noting that while the term \u201challucination\u201d was coined for LLMs, unlikely or inconsistent samples can be an issue for all generative models [3]. For example, CDVAE commonly hallucinates combinations of elements that are physically implausible."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5580/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700513757088,
                "cdate": 1700513757088,
                "tmdate": 1700513757088,
                "mdate": 1700513757088,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "quLKKLfzP8",
                "forum": "vN9fpfqoP1",
                "replyto": "arOLl3hw1p",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5580/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5580/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Rebuttal to Reviewer iXqY (part 2)"
                    },
                    "comment": {
                        "value": "We believe our paper has many compelling and timely contributions. First and foremost, we observe near-perfect rates of validity and state-of-the-art rates of stability under DFT simulations. As we outline in the general rebuttal comment, the computation cost of obtaining state-of-the-art samples is on par with prior work, making the approach practically relevant. The use of pre-trained LLMs also unlocks an entirely new set of possibilities for generating crystals conditioned on text descriptions. There were several key methodological details that were carefully engineered, including the crystal formatting and data augmentation method. With an optimal formatting strategy, our method is easy to extend to any LLM, including systems like GPT-4. We hope that our work will demonstrate that LLMs are in fact incredibly general-purpose generative models and that their impact can extend to many tasks within materials science and chemistry. \n\nWe would welcome any further questions, and we hope that, in light of our detailed response and clarifications, you will consider raising your score to support acceptance of the paper. \n\n**References**\n\n[1] Zhang, Xuan, et al. \"Artificial intelligence for science in quantum, atomistic, and continuum systems.\" arXiv preprint arXiv:2307.08423 (2023).\n\n[2] Tian Xie, Xiang Fu, Octavian-Eugen Ganea, Regina Barzilay, and Tommi Jaakkola. Crystal diffusion variational autoencoder for periodic material generation. arXiv preprint arXiv:2110.06197, 2021.\n\n[3] Ji, Ziwei, et al. \"Survey of hallucination in natural language generation.\" ACM Computing Surveys 55.12 (2023): 1-38."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5580/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700513829876,
                "cdate": 1700513829876,
                "tmdate": 1700513858596,
                "mdate": 1700513858596,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "us6gszwH54",
            "forum": "vN9fpfqoP1",
            "replyto": "vN9fpfqoP1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5580/Reviewer_9VCZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5580/Reviewer_9VCZ"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed to use LLMs to model the materials. The main technical contribution comes from 1) a modified tokenization mechanism that is suitable for material data; 2) a data augmentation method that leverages the property of the materials; 3) the prompt designs. Experiments on benchmark datasets show that when tuned on LLAMA2, it is able to improve the performance compared to other baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Application on the material science domain is interesting\n- The adaptation of LLMs for the material science is reasonable\n- Empirical results are promising"
                },
                "weaknesses": {
                    "value": "- The technical contribution is relatively limited, where the tokenization, the prompt design and the objectives for pertaining are all well studied in the past.\n- Since the nature of the material data is quite different compared to the natural language data, I\u2019m wondering whether the pretrained LLAMA2 is offering any additional value. It would be helpful if one can show the performance with and without loading the pretrained checkpoint from LLAMA2 tasks."
                },
                "questions": {
                    "value": "I\u2019d like to see the author\u2019s response on the questions I listed in the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5580/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699429926101,
            "cdate": 1699429926101,
            "tmdate": 1699636574352,
            "mdate": 1699636574352,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Safo5EHZGA",
                "forum": "vN9fpfqoP1",
                "replyto": "us6gszwH54",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5580/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5580/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Rebuttal to Reviewer 9VCZ"
                    },
                    "comment": {
                        "value": "Thank you for your review. We would like to clarify that text pretraining is essential to our method for two reasons.\n1. It would be impractically expensive or computationally infeasible to train models with up to 70B parameters from scratch on our data. Using a pretrained model with LoRA [1] offers the benefits of model scale while maintaining tractability and limiting overfitting, as the actual number of trainable parameters can be relatively small.\n\n2. Pretraining on text data yields a model that can be conditioned on text for free, and text conditioning opens up a huge new realm of exciting possibilities, like conditioning samples on desired properties. It would be challenging to achieve a similar result from scratch without significantly expanding the size of the dataset (to improve general text understanding) and without essentially training a general-purpose language model in the process. \n\nTo better understand the first point, let\u2019s quickly review the exact details of the finetuning procedure. We are using low-rank adapters (LoRA), as opposed to end-to-end finetuning, and this means we are adding a small number of additional parameters to an existing, frozen model. The easiest way to see the difference between this approach and training a model from scratch (as in [2]) is to compare the training loss over the first few epochs of training.\n\n| Model | Epoch 1 | Epoch 2 | Epoch 3 | Epoch 4 | Epoch 5 |\n| -------- | -------- | -------- | -------- | -------- | -------- |\n| GPT-2 (from scratch) | 0.946 | 0.878 | 0.807 | 0.757 | 0.740 |\n| LLaMA-13B (LoRA) | 0.457 | 0.432 | 0.424 | 0.401 | 0.385 |\n| LLaMA-70B (LoRA) | 0.402 | 0.344 | 0.325 | 0.305 | 0.296 |\n\nIf we attempt to run LoRA finetuning with randomly initialized parameters for the LLaMA-2 7B model we observe an immediate and significant difference in the training losses:\n\n| Model | 1 Iter | 0.33 Epochs | 0.66 Epochs | 1 Epoch  |\n| -------- | -------- | -------- | -------- | -------- |\n| Random | 13.46 | 1.53 | 0.81 | 0.78 | \n| Pre-trained | 1.57 | 0.47 | 0.41 | 0.39 | \n\nWhile LoRA finetuning is tractable because 99.95% of the model is frozen, finetuning a LLaMA-2 model end-to-end in half-precision would require at least 4 times as many GPUs, making it infeasible for all but a handful of researchers. When using LoRA, even though the base models are large the number of trainable parameters is very small. In fact, the LLamA-2 7B model has less trainable parameters than one of the baseline methods we compared (CDVAE) [3]. The number of trainable parameters for each of our models and the baseline models is shown below:\n\n*CDVAE [3]*: 4.5 million trainable parameters (100% of total)\n\n*LM-CH/AC [2]*: 1-100 million trainable parameters (100% of total)\n\n*LLaMA-2 7B*: 3.5 million trainable parameters (0.05% of total)\n\n*LLaMA-2 13B*: 6.5 million trainable parameters (0.05% of total)\n\n*LLaMA-2 70B*: 35 million trainable parameters (0.05% of total)"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5580/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700514109618,
                "cdate": 1700514109618,
                "tmdate": 1700514109618,
                "mdate": 1700514109618,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gEcW3aOpSX",
                "forum": "vN9fpfqoP1",
                "replyto": "us6gszwH54",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5580/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5580/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Having clarified the significance of using pretraining, we now expand upon the unique facets of our method and their significance. While prompt design and tokenization are established research areas, they have not been extensively studied within generative models of materials, or generative models of molecules more broadly (e.g. protein structures). We cite two papers that use language models to sample novel materials, both of which were published within the last six months [2,4]. Neither of these papers explores prompt design, and only one ablates tokenization methods [2]. Both papers use models trained from scratch on domain-specific data. \n\n**Tokenization**\n\nNotably, our approach to tokenization is distinctly different from prior work on modeling atomic structures with language models. Instead of using a special vocabulary and training models from scratch, we use LLaMA-2\u2019s existing tokenizer. This choice allows us to easily process both encoded crystals and text data. In early experiments, we tried out many other approaches, including fine-tuning LLaMA-2 models with additional tokens specific to crystal data. These methods were more challenging to train and didn\u2019t lead to any improvements over using a shared tokenizer. We include a set of example training losses below:\n\n| | Epoch 1 | Epoch 2 | Epoch 3 | Epoch 4 | Epoch 5 |\n| -------- | -------- | -------- | -------- | -------- | -------- |\n| Special Crystal Tokens | 0.783 | 0.693 | 0.623 | 0.611 | 0.588 |\n| Shared Tokenization | 0.457 | 0.432 | 0.424 | 0.401 | 0.385 |\n\n**Prompt design**\n\nThere are many important decisions involved both in text formatting (e.g the choice of fractional or absolute coordinates) and augmentation of the input data (e.g. translation or permutation augmentations on coordinates). We refined our choices over weeks of training and evaluation. As a simple example, we provide average validity numbers (using low temperature sampling) from earlier experiments on LLaMA-2 7B models trained different formatting styles\n\n| Setting | Structural Validity | Compositional Validity |\n| -------- | -------- | -------- |\n| Fractional coords | 0.914 | 0.832 |\n| Absolute coords  | 0.908  | 0.805 |\n| No permutations | 0.925 | 0.829 |\n| With permutations | 0.892  | 0.817 |\n\nEven the phrasing of the instruction prompt can have a significant impact on the ultimate rates of validity, for example by providing proper context for element symbols:\n\n| Setting | Structural Validity | Compositional Validity |\n| -------- | -------- | -------- |\n| Prompt 1 | 0.877 | 0.795 |\n| Prompt 2 | 0.929 | 0.839 | \n| Prompt 3 | 0.957 | 0.875 | \n\nPrompt 1: \u201cBulk material description:\\n\u201d\n\nPrompt 2: \u201cBelow is a description of a bulk material, starting with a list of atom types for the elemental composition followed by the lengths and angles of the lattice vectors and finally the atom type and coordinates for each atom within the lattice:\\n\\n\"\n\nPrompt 3: \"Please provide the description of a stable bulk material, starting with a list of atom types for the elemental composition followed by the lengths and angles of the lattice vectors and finally the atom type and coordinates for each atom within the lattice.\\n\\nAn example of a bulk material description is:\\n\\n{example}\\n\\nInclude the new material description below:\\n\\n\"\n\nThe length of Prompt 3 was prohibitive, so we ultimately abandoned it, despite promising results. \n\n**In closing**\n\nUltimately, we think that simplicity is a virtue. Using our method, it is easy to adapt popular LLMs methods directly to improving generative models of materials. Because of the generality of our approach, it would also be straightforward to extend to other atomic structures, such as drug-like compounds, protein structures, or nucleic acids.\n\nWe hope that our rebuttal addresses the concerns outlined in your review. If you have remaining questions, we would be happy to discuss any details further. We would appreciate it if you would consider raising your score in light of our response.\n\n**References**\n\n[1] J. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. ArXiv, abs/2106.09685, 2021.\n\n[2] Daniel Flam-Shepherd and Al\u00e1n Aspuru-Guzik. Language models can generate molecules, materials, and protein binding sites directly in three dimensions as xyz, cif, and pdb files. arXiv preprint arXiv:2305.05708, 2023\n\n[3] Tian Xie, Xiang Fu, Octavian-Eugen Ganea, Regina Barzilay, and Tommi Jaakkola. Crystal diffusion variational autoencoder for periodic material generation. arXiv preprint arXiv:2110.06197, 2021.\n\n[4] Luis M Antunes, Keith T Butler, and Ricardo Grau-Crespo. Crystal structure generation with autoregressive large language modeling. arXiv preprint arXiv:2307.04340, 2023."
                    },
                    "title": {
                        "value": "Author Rebuttal to Reviewer 9VCZ (part 2)"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5580/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700514223335,
                "cdate": 1700514223335,
                "tmdate": 1700514252862,
                "mdate": 1700514252862,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]