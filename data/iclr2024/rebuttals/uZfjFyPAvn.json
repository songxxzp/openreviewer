[
    {
        "title": "Implicit Neural Representations and the Algebra of Complex Wavelets"
    },
    {
        "review": {
            "id": "SYQKPyDhZC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7842/Reviewer_ZxVa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7842/Reviewer_ZxVa"
            ],
            "forum": "uZfjFyPAvn",
            "replyto": "uZfjFyPAvn",
            "content": {
                "summary": {
                    "value": "This work studies the task of Implicit Neural Representations using neural networks with wavelet activation functions. Paper provides a theoretical framework for the approximation capabilities of such networks, and demonstrates how the theory can be helpful in designing the INR architectures. Experiments are provided on a few images."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The theory presented in the paper is a solid contribution for research and practice.\n\nPaper is well written. Arguments are clear."
                },
                "weaknesses": {
                    "value": "In my view, the weakness of this paper is its small set of experiments. I also think more details can be provided to interpret the experiments and to discuss the theory.\n\nI think providing more details and more discussions would make the paper more approachable for a broader audience.\n\n---------\n\nPossible typo in the abstract: band-pass -> high pass. In my understanding, the method decouples the low-pass parts from the high-pass...\n\n----------\n\nI would have liked to see experiments on more images. I only saw three examples. Specifically, I'd be interested to see more examples of how the method works on more images, its errors, and its possible failure modes.\n\nIt may be useful if authors present cases where one might encounter troubles in training -- and cases where the learned representation may be flawed. The first image in Figure 6 seems to be more of a challenge from the training convergence perspective. Are there images where the reduction of the training loss would be even more challenging?\n\nIn the right column of Figure 6, the curves seem to still have a positive slope even towards the end of the horizontal axis. Is that correct? If yes, how would the curve proceed if training is continued further?\n\nAuthors can consider presenting the likes of figure 6 for earlier stages of training, e.g., for 5, 10, 50 epochs. How would those images look like? The convergence curve (right column in Figure 6) seems to be overly compact, so it is not easy to see the particulars for the early epochs of training. It seems that for the parrot picture, the WMM initialization lags behind the random initialization at the early epochs.\n\nIn Figure 6, the WMM result for the parrot has error at the left corners of the image. It may be useful if authors interpret those errors. Specifically, the patterns at the top left corner seem to appear in that general area of the image. Why does that magnitude of error only happen at that top left corner and not in that whole green area?\n\nOverall, demonstrating results on more images would give a better understanding to a reader.\n\n---------\n\nI think the discussion in the context of wavelet literature could have been broader. For example, I did not see any discussions on the topic of Daubechies wavelets. Are Daubechies wavelets also progressive by the authors\u2019 definition?\n\n------\n\nIf authors think Shearlets may have any potential here, providing a discussion might be useful. Most of the approximation error for the pictures in Figure 6 appear to be at locations where the colors change in a small neighborhood. Could a shear matrix be potentially helpful in reducing the error because of its ability to extract anisotropic features?\n\n------\n\nA relevant prior work that authors may consider citing if they see fit:\n\n-- Grattarola, D. and Vandergheynst, P., 2022. Generalised implicit neural representations. Advances in Neural Information Processing Systems, 35, pp.30446-30458.\n\n-------\n\nUsing wavelets to study approximation properties of neural networks, and leveraging that to design the architecture of the network, is studied in the past, but I did not see a mention of that in the paper.\n\n-- Shaham, U., Cloninger, A. and Coifman, R.R., 2018. Provable approximation properties for deep neural networks. Applied and Computational Harmonic Analysis, 44(3), pp.537-557."
                },
                "questions": {
                    "value": "How can we interpret the result for the medical image in the bottom row of figure 6? To me, it seems that the error is more for the WMM case. Is that correct? If that is the case, the description in Appendix 5 may not be as accurate when it says \u201cWMM based initialization has limited advantages \u2026\u201d. This would be a disadvantage for WMM and not an advantage?\n\nIntuitively, how does the definition of progressive wavelets affect the approximation capability of a model? What would happen if we use a non-progressive wavelet to model the same images that authors present in Figures 1, 6, 7? We will lose the guarantees from the theorems, but how would that affect the learned representations? How would that empirically affect the error.\n\nIn Figure 6, how many parameters do the models have?\n\nHow could the theory and the method be used for image compression?\n\nPlease also see questions under weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7842/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7842/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7842/Reviewer_ZxVa"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7842/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697190506845,
            "cdate": 1697190506845,
            "tmdate": 1699636961123,
            "mdate": 1699636961123,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fPcL5x5el3",
                "forum": "uZfjFyPAvn",
                "replyto": "SYQKPyDhZC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7842/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7842/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your thorough review of our work. We address some of the weaknesses below, as well as in the updated manuscript."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7842/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700497141998,
                "cdate": 1700497141998,
                "tmdate": 1700497141998,
                "mdate": 1700497141998,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QC0xLcJCez",
                "forum": "uZfjFyPAvn",
                "replyto": "SYQKPyDhZC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7842/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7842/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Empirical Parts of the Paper"
                    },
                    "comment": {
                        "value": "1. Need for more experiments. How many parameters do the models have?\n\nTo address these remarks, we have added new comparative experiments to Section 4.3 showing the interaction between the use of complex wavelets as template functions and the proposed split INR architecture. We have also added experiments to Section 5 showing the advantage of the wavelet modulus maxima initialization scheme for a dataset of images. This resulted in the figure showing the training behavior of the networks being removed to make space for more substantive results.\n\nWe have added an appendix describing the models in greater detail, including the depths and widths of the networks."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7842/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700497158317,
                "cdate": 1700497158317,
                "tmdate": 1700497225520,
                "mdate": 1700497225520,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sHwxl4yJf7",
                "forum": "uZfjFyPAvn",
                "replyto": "SYQKPyDhZC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7842/Reviewer_ZxVa"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7842/Reviewer_ZxVa"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their clear and detailed response. The revised paper appears to me as a good contribution and my recommendation is acceptance.\n\nBelow are some comments that authors might find useful. I'm not asking the authors to provide a response as the rebuttal period is closing soon.\n\nComment 1: In the previous version of the paper, I found the error plots of the approximated images insightful, especially the one for the parrot image, but it seems that they are excluded in the revision. For the images in Figure 7, I can recognize some of the regions that are the source of error. Having the error plots would have made it easier to identify and compare those regions. I respect that authors might not want to include the error plots for some reason.\n\nComment 2: Again in Figure 7, the blurred parts in the reconstructed images vary across the columns (Gabor-random vs Gabor-WMM vs Gaussian). Perhaps this deserves further discussion in the appendix. What is the sensitivity of the resulting images.\n\nComment 3: For the images in Figure 7, if one compresses those images with a compression method such as JPEG, which parts of the images would be blurred, and how would the resulting blurred regions be different than the blurred regions obtained by authors' approximation method."
                    }
                },
                "number": 25,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7842/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700634266689,
                "cdate": 1700634266689,
                "tmdate": 1700634646963,
                "mdate": 1700634646963,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9g5xwUxPSD",
            "forum": "uZfjFyPAvn",
            "replyto": "uZfjFyPAvn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7842/Reviewer_rBV3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7842/Reviewer_rBV3"
            ],
            "content": {
                "summary": {
                    "value": "The article studies implicit neural representation models which typically uses sinusoidal activation functions and wavelet-based activation functions, in order to represent signals. This work develops theoretical understanding of such architectures and also a practical split architecture to capture singularities in target functions."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The theoretical analysis seems to be novel. By using Fourier analysis, theorem 1 gives an ide a about the effective time-frequency support of implicit neural representations. Numerical results such as in Fig 4 further support the theory."
                },
                "weaknesses": {
                    "value": "The overall clarity of the presentation still needs to be improved to make results accurate. See questions below."
                },
                "questions": {
                    "value": "-\tYour definition of the model in eq 1 seems to have some issue to me. Psi is a function of R^d -> C but somehow W^0 r and b^0 is in R^{F_1 x d}. Thus I do not understand the model. \n-\tThe notation inf Theorem 1 is not clear. What is the definition of the Fourier transform for functions in C_0^inf (U) in eq 2? What does this stand for C_0^inf (U)? What is the product_t from t=1 to t=F_1? Does hat beta_l depends on W^{l} and b^{l}? Is * a convolution, over which domain? As a consequence, the argument in Section 3.2 regarding the support of the product_t term in eq. 2 is not clear. Is W^T a typo of W_l^T? \n-\tIn Section 4.3, what does it mean to model a signal as a sum of a linear scaling INR and a nonlinear INR ?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7842/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7842/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7842/Reviewer_rBV3"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7842/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698659052005,
            "cdate": 1698659052005,
            "tmdate": 1700590850920,
            "mdate": 1700590850920,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "h8ewPqONN6",
                "forum": "uZfjFyPAvn",
                "replyto": "9g5xwUxPSD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7842/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7842/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your comments on our paper. We hope that the updates to the paper corresponding to our replies to your questions have improved the presentation of the work."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7842/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700497074870,
                "cdate": 1700497074870,
                "tmdate": 1700497074870,
                "mdate": 1700497074870,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iEyuK5iPnc",
                "forum": "uZfjFyPAvn",
                "replyto": "gV2v2PNaXh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7842/Reviewer_rBV3"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7842/Reviewer_rBV3"
                ],
                "content": {
                    "title": {
                        "value": "accept"
                    },
                    "comment": {
                        "value": "Dear authors, \nThanks for the clarification and your revised version. I am glad to accept the article as the algebra of the progressive wavelets is very nice to construct the INR model. I think this is the main novelty rather than your theorem 1 which seems to be a basic application of the convolution theorem. I did not understand your proof in Appendix A ... please make it more clear as much as you can."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7842/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700590813793,
                "cdate": 1700590813793,
                "tmdate": 1700590813793,
                "mdate": 1700590813793,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "sl6YcARtWa",
            "forum": "uZfjFyPAvn",
            "replyto": "uZfjFyPAvn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7842/Reviewer_ewcV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7842/Reviewer_ewcV"
            ],
            "content": {
                "summary": {
                    "value": "The study conducts a time-frequency analysis of INRs by leveraging polynomial approximations to delve into the behaviors of MLPs beyond the first layer. By decomposing a signal into its low-pass and high-pass segments using two INRs, motivated from the scaling and wavelet functions of the wavelet transform. This approach bridges the structure of complex wavelets and the application of INRs, which is a novel concept."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper presents a novel perspective on behaviors of INR models, including the decomposition of low and band-pass approximations, along with specific initialization methods, and enhances both the depth and practical relevance of the study."
                },
                "weaknesses": {
                    "value": "Although the performance of the proposed method was supported by several tests and analysis in the paper, it is suggested to include some practical applications such as regression tasks on images or other high-dimensional signals to justify its practicability."
                },
                "questions": {
                    "value": "The reviewer is curious if the proposed method and its theoretic analysis/intuition is valid, when the method is applied to practical applications."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7842/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698726666995,
            "cdate": 1698726666995,
            "tmdate": 1699636960873,
            "mdate": 1699636960873,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GaT1t21yt4",
                "forum": "uZfjFyPAvn",
                "replyto": "sl6YcARtWa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7842/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7842/Authors"
                ],
                "content": {
                    "title": {
                        "value": "New Experiments Added"
                    },
                    "comment": {
                        "value": "Thank you for your comments on our work. You are indeed in agreement with the other reviewers on the need for more numerical experiments to go with the paper, which we have addressed by updating Sections 4 and 5.\n\nWe would like to remark that the main point of this paper is not strictly methodological. Rather, the suggestion of using a split architecture for INRs that use progressive wavelets as template functions is something that follows from our analysis of such networks, as determined by the Theorem (now known as Lemma 1) and the following discussion.\n\nWith this in mind, we still see the need for more practical demonstrations to show the validity of the obtained insights. In Section 4.3, you can see a comparative study between the use of real and complex wavelets, the use of nonlinear hidden layers in INRs, and using scaling networks or not (i.e., the proposed split architecture).\n\nWe have also added new experiments on a dataset of images showing the advantage of initializing a complex Gabor INR using the wavelet modulus maxima over random initialization, as well as over other choices of template function."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7842/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700497044520,
                "cdate": 1700497044520,
                "tmdate": 1700497044520,
                "mdate": 1700497044520,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "gcB0IOoWEx",
            "forum": "uZfjFyPAvn",
            "replyto": "uZfjFyPAvn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7842/Reviewer_3UQT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7842/Reviewer_3UQT"
            ],
            "content": {
                "summary": {
                    "value": "The authors use Fourier analysis to study the properties and expressive power of implicit neural representations (INR). In particular, they analyze multi-layer INRs whose first-layer activations (which they call the template function) map from Euclidean space into the complex numbers and whose activations on all other layers are polynomials. \n\nThe authors show that when the template function is essentially a band-pass filter, the class of INRs they study also act essentially as band-pass filters. Based on this observation, the authors propose to model signals as a sum of two INRs instead, one that acts as a low-pass filter and one that acts as a high-pass filter.\n\nThe authors also suggest initializing INRs with wavelet template functions placed on estimate singular (i.e., non-smooth) points in the domain of the signal (e.g., edges in an image). They show that this careful initialization results in significantly improved performance compared to random initialization."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Analyzing the expressivity of multi-layer INRs, not just one-hidden-layer ones, is a very relevant problem; hence, any progress in the area is nice. I found the low-pass-high-pass decomposition idea and the suggestion to initialize the template function's biases to the signal's singular points interesting."
                },
                "weaknesses": {
                    "value": "As someone whose primary area of research or background is not in classical signal processing, I found the paper quite confusing. In particular, the authors provide little to no interpretation of their results and observations. This led me to feel that I was constantly expected to be able to interpret and understand them, which I failed to do in many cases. Moreover, it is unclear what mathematical level the authors expect of the reader. They state some quite elementary results rigorously while handwaving others (e.g., effective support, Minkowski sums). Finally, several technical signal processing terms (such as atoms, band-pass filters, and WIRE) are undefined, which makes reading the paper quite challenging.\n\nFor example, the authors showcase Thm 1 as one of their main results. However, Eq (2) is just the Fourier transform of a slightly rearranged definition of the INR architecture they are studying. On the other hand, some of the assumptions and both conclusions are unclear:\n- Why is restricting our focus to polynomial activations beyond the first layer interesting to study?\n- Why is the Fourier transform stated by considering multiplication by a smooth function $\\phi$?\n- How does the fact that the INR is composed of the sum of the template function's \"integer harmonics\" illustrate the expressivity of the INR?\n- \"Second, the support of these scaled and shifted atoms is preserved so that the output at a given coordinate $r$ is dependent only upon the atoms in the first layer whose support contains $r$.\" - How is this not a trivial statement? What is the relevance of this observation?\n\nSimilarly, what is the purpose of section 3.2? While I follow and agree with the argument, the whole discussion is informal, so it technically contains no actual results. More importantly, though, it's unclear what the insight is.\n\nHowever, Section 4 is perhaps the most confusing part of the paper. In the first paragraph, the authors state that in this section, they \"consider the advantages of using complex wavelets, or more precisely progressive wavelets.\" This sentence has two issues: first, it shows that the paper title is a misnomer because the authors actually only consider the algebra of progressive wavelets. Second, they don't demonstrate any advantages of using progressive wavelets. Perhaps most confusingly, even though the concept is featured in the paper title, the authors never actually make use of the fact that progressive wavelets form an algebra.\n\nEssentially, the authors spend the first two subsections defining a multivariate notion of a band-pass filter using weakly conic sets. Then, in the third section, the authors claim in Section 4.3: \"Based on this property of INRs preserving the band-pass properties of progressive template functions, it is well-motivated to approximate functions using a sum of two INRs: one to handle the low-pass components using a scaling function, and the other to handle the high-pass components using a wavelet.\" I do not follow this argument. I'm not saying it is not a good idea, but I do not see why it is well-motivated based on the multivariate notion of band-pass filters to decompose signals into a sum of a high-pass INR and a low-pass INR.\n\nFinally, the experimental section of the work is severely lacking. The authors only conducted one ablation study for their suggested initialization technique vs. random initialization by reconstructing three different images. Hence, it is unclear how the suggested signal decomposition into two INRs or the initialization technique helps with the usual tasks INRs solve in practice compared to other methods."
                },
                "questions": {
                    "value": "n/a"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7842/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7842/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7842/Reviewer_3UQT"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7842/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699015562288,
            "cdate": 1699015562288,
            "tmdate": 1700578378438,
            "mdate": 1700578378438,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wB5a6deyid",
                "forum": "uZfjFyPAvn",
                "replyto": "gcB0IOoWEx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7842/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7842/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your detailed review. Your comments in conjunction with the other reviewers have led us to restructure some aspects of the paper, as well as add in new experiments. We address your comments below."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7842/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700496512860,
                "cdate": 1700496512860,
                "tmdate": 1700496512860,
                "mdate": 1700496512860,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NIqnMbxwTY",
                "forum": "uZfjFyPAvn",
                "replyto": "gcB0IOoWEx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7842/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7842/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Terminology and Writing"
                    },
                    "comment": {
                        "value": "1. [For those whose ] background is not in classical signal processing, ... the paper [is] quite confusing. The authors provide little to no interpretation of their results and observations. It is unclear what mathematical level the authors expect of the reader. Several signal processing terms are undefined, which makes reading the paper quite challenging.\n\nThank you for pointing this out. While certain terminology is quite standard to the intended audience of our paper (broadly speaking, those that are well-acquainted with Fourier analysis and its applications), we would still like to avoid using excessive jargon. The updated paper has improved explanations behind the motivations for certain results and proposed methods. Additionally, based on your comments and comments from other reviewers, we have removed Section 3.2 to make more space for new results and exposition, which seemed to be a problematic section anyway."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7842/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700496573382,
                "cdate": 1700496573382,
                "tmdate": 1700496573382,
                "mdate": 1700496573382,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "b8LC7BA9XR",
                "forum": "uZfjFyPAvn",
                "replyto": "gcB0IOoWEx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7842/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7842/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Motivation for Proposed Methods and Experiments"
                    },
                    "comment": {
                        "value": "8. The authors state in [Section 4] that they \"consider the advantages of using complex wavelets, or more precisely progressive wavelets.\" ... Second, they don't demonstrate any advantages of using progressive wavelets. Most confusingly, ..., the authors never actually make use of the fact that progressive wavelets form an algebra.\n\nThank you for this comment: it has revealed some aspects of the paper that we should have made more clear to begin with. In conjunction with added comparative experiments, we have updated Section 4.3 to empirically demonstrate the advantages of using progressive wavelets over their real-valued counterparts. \n\nThe titling of the paper with the term \"complex wavelet\" rather than \"progressive wavelet\" was a stylistic choice, as \"progressive wavelet\" is not a universally-used term in the literature.  Many signal processing researchers will informally use the term \"complex wavelet\" to refer to what we call \"progressive wavelets\" in this paper, although it is certainly true that not all complex-valued wavelets are necessarily progressive. If the area chair and other reviewers also think that a change in title is appropriate, we are willing to do so.\n\nWe do make use of the fact that progressive wavelets form an algebra: Corollary 4 is a combination of Theorem 1 (now Lemma 1) and the algebraic closure of the space of progressive functions.\n\n9. The authors claim in Section 4.3: \"Based on this property on INRS... it is well-motivated to approximate functions using a sum of INRs...\"\n\nIndeed, we could have made this more clear from the start. We have updated Section 4.3 to address this in two ways. We have clarified why it is well-motivated to split the signal representation in this way by explaining that INRs using progressive wavelets are unable to easily generate low-frequency signal content. Additionally, we have noted the potential advantages of separating the low-pass and high-pass parts of the signal from a signal processing perspective. In line with this discussion, the added experiments show empirically the advantage of the split architecture with complex wavelets over alternative design choices.\n\n10. Finally, the experimental section of the work is severely lacking. ... it is unclear how the suggested signal decomposition into two INRs or the initialization technique helps with the usual tasks INRs solve in practice compared to the other methods.\n\nThank you for this comment. You are in agreement with the other reviewers that this work needs more empirical demonstrations. We have updated Section 4.3 with a comparative study of using the split architecture vs INRs that do not have a \"scaling network\" attached, as well as a discussion of why the split architecture with complex wavelets may outperform the other approaches.\n\nWe have also updated Section 5 with an experiment testing the initialization scheme on a larger dataset of images, comparing to other template functions from the literature, and showing how the initialization is helpful in denoising tasks."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7842/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700496886024,
                "cdate": 1700496886024,
                "tmdate": 1700496886024,
                "mdate": 1700496886024,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2fIDuaQT9h",
                "forum": "uZfjFyPAvn",
                "replyto": "b8LC7BA9XR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7842/Reviewer_3UQT"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7842/Reviewer_3UQT"
                ],
                "content": {
                    "title": {
                        "value": "Response to the authors"
                    },
                    "comment": {
                        "value": "I thank the authors for their elaborate response. I have skimmed through the updated version of the paper, spending more time on sections that I found unclear in the previous version. I am satisfied with the updated version, and am now happy to recommend its acceptance; I have increased my score to reflect this.\n\nIn my opinion, the authors have made their paper a great deal more accessible and also more interesting to the ICLR community by including more explanations and experiments on Kodak.\n\nAs a final point, I find that the authors' explanation for the relevance of Lemma 1 in the rebuttal is still clearer than the one in the paper. Hence, I think the authors could further strengthen the paper by incorporating more of the points they mention in the rebuttal into the camera-ready version."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7842/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700578340628,
                "cdate": 1700578340628,
                "tmdate": 1700578340628,
                "mdate": 1700578340628,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "2OlTgsCftV",
            "forum": "uZfjFyPAvn",
            "replyto": "uZfjFyPAvn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7842/Reviewer_ksCd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7842/Reviewer_ksCd"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies a type of Implicit Neural Representation based on a wavelet nonlinearity.\nAn implicit neural representation is a parameterization of a (usually) scalar function of a (low-dimensional variable), e.g. a function f: R^d->R using a neural network. In this setting, an image is a function R^2->R and the input to the function are pixel locations. This setup requires some reflection about the role of in particular the first non-linearity. Using ReLU will lead to lots of ramps, requiring their combination in intricate ways to represent usual real-world signals.\nHere the use of wavelets as first non-linearity is analyzed. The use of wavelets comes out of a line of research leading via sinusoidal components (e.g. SIREN) and presents itself as a clear follow-up. The setting studied here is a first layer with wavelet nonlinearity followed by several layers of pointwise mixing layers with polynomial nonlinearities.\n\nIn this context, using the Fourier convolutional theorem, the functions expressible by this architecture are characterized in Fourier space as essentially a collection of higher-order self-convolutions of affine-transformed versions of the base wavelets.\n\nIntroducing the notion of \"progressive wavelet\" which have their Fourier support on a cone (or a \"weak cone\" that is closed for factors >= 1), it is shown that the wavelet self-convolutions above never leave their cone, leading to a neat characterization of what functions can be matched using a particular wavelet.\n\nTo accommodate low-pass signal, a split of the INR is proposed into the sum of two INRs, one using a wavelet, the other using a low-pass filter. This decomposition is shown to be beneficial in fitting a signal.\n\nFurther, wavelet modulus maxima points are proposed to initialize the representation. It is shown that for certain signals the use of WMM points as initialization leads to a better fit."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is very clearly written and presents its contributions is a highly succinct way. It is a pleasure to read - in fact it reads a bit like an advanced chapter of a wavelet applications textbook. The illustrations contribute to the ease of understanding.\n\nThe paper gives a concise characterization of the function space spanned by the wavelet nonlinearity followed by layers of pointwise polynomial mixing. From this characterization it clearly identifies, using progressive wavelets, that a split into low-pass and wavelets is highly useful.\n\nIn short, it leads to a complete understanding of the particular setting introduced. The hope is that this understanding can extend to adjacent settings."
                },
                "weaknesses": {
                    "value": "The provable statements in the paper are not in any way non-obvious. Theorem 1 is a direct consequence of the Fourier convolution theorem.\n\nThe setting in which these proofs work are highly impoverished with respect to the setting of actual interest, which is that of non-polynomial nonlinearities, such as the ReLU, for the pointwise mixing layers. The shifting of frequencies along a cone does not hold for these, and complicated ringing processes emerge that can also define sharp boundaries by the rectifier suppressing negative values. (The effects of ReLU wrt wavelets are partially analyzed e.g. here https://arxiv.org/abs/1810.12136 but it looks intractable to integrate this in the current analysis).\n\nGiven the nature of the expressed function space, what is an obvious advantage of this particular implicit neural representation over a sparse continuous wavelet transform with a sufficiently expressive bank of filters (e.g. some base filters and some of their polynomial powers)? In particular, if one needs to use wavelet modulus maxima to initialize the representation. Could these advantages be concisely stated? (e.g. I can imagine that potentially the representation requires fewer parameters)\n\nIn general, could some numerical comparisons be done to place the analyzed method within context of other INRs? We are not looking for state of the art here, but to have an idea of whether the proposed setup is close or far from that. If it is close, this can also partially alleviate the expressivity concern mentioned above."
                },
                "questions": {
                    "value": "The term \"progressive wavelet\" was new to me. However, as far as I can tell, its definition fits exactly what I know as \"analytic wavelets\". Could the authors confirm this is the same and in that case justify the use of a new term, or explain in what way these concepts differ?\n\nThere are two more direct questions listed in the weaknesses section.\n\nRegarding the low-pass + progressive wavelet decomposition for images: Is it possible to show the smooth parts and the wavelet parts? A conjecture for this, if both INRs are allowed to output in RGB space, is that the smooth parts contain much more color than the wavelet parts. Would be interesting to see if that is the case for certain natural images."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7842/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699238008318,
            "cdate": 1699238008318,
            "tmdate": 1699636960619,
            "mdate": 1699636960619,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bcUi22s0ys",
                "forum": "uZfjFyPAvn",
                "replyto": "2OlTgsCftV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7842/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7842/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your detailed review of our paper; your comments have directly led to an improved presentation of the work. We address your comments and questions below, first addressing those from the weaknesses section, and then those from the questions section."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7842/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700496237581,
                "cdate": 1700496237581,
                "tmdate": 1700496237581,
                "mdate": 1700496237581,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "a1bBw0haCJ",
                "forum": "uZfjFyPAvn",
                "replyto": "2OlTgsCftV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7842/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7842/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Terminology Question"
                    },
                    "comment": {
                        "value": "6. Does the term \"progressive wavelet\" mean the same thing as \"analytic wavelet?\"\n\nYes indeed -- we chose to use the term \"progressive wavelet\" to avoid confusion with the \"analytic\" activation functions of the INR. The term progressive wavelet is used in this way in the literature, such as by\n\nGrossmann, Alexandre, Richard Kronland-Martinet, and J. Morlet. \"Reading and understanding continuous wavelet transforms.\" Wavelets: Time-Frequency Methods and Phase Space Proceedings of the International Conference, Marseille, France, December 14\u201318, 1987. Berlin, Heidelberg: Springer Berlin Heidelberg, 1990."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7842/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700496432276,
                "cdate": 1700496432276,
                "tmdate": 1700496432276,
                "mdate": 1700496432276,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]