[
    {
        "title": "Are Human-generated Demonstrations Necessary for In-context Learning?"
    },
    {
        "review": {
            "id": "9GDb26AodB",
            "forum": "frRDT6EOhg",
            "replyto": "frRDT6EOhg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1674/Reviewer_wk7D"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1674/Reviewer_wk7D"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes Self-Contemplation (SEC) as an alternative for human-generated prompts for in-context learning (ICL) in LLMs. This enables LLMs to generate their own demonstrations for ICL, rather than having to rely on hand-generated human demonstrations. The experiments across a diverse range of different tasks show that SEC can be a meaningful alternative to ICL in some settings, and is able to outperform the zero-shot performance despite not requiring any human demonstrations."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Proposing a method to move beyond hand-crafted demonstrations is a more scalable approach to ICL, where we no longer have to hand-craft domain-specific questions per task setting. Showing that this is able to match human-crafted demonstrations is an interesting finding, and the fact that it generally vastly outperforms the zero-shot setting shows that SEC should generally be used even in settings where we do not have access to high-quality human demonstrations.\n- The experimental results seem thorough and cover a wide range of standard tasks for evaluating LLMs."
                },
                "weaknesses": {
                    "value": "-  While finding that it is feasible for a model to generate its own examples (rather than having human-crafted demonstrations) is insightful, the applicability of this method seems limited to large model sizes that are less likely to make reasoning errors during the self-generation process. How much would the method performance drop if tested with less capable language models? The paper would be strengthened with more thorough evaluations of when exactly SEC is usable. \n- As a baseline, it would be helpful to have direct comparisons with \"Automatic chain of thought prompting in large language models. (Zhang et al., 2022).\" to place this method in context relative to prior work. While the authors note that Auto-CoT makes use of questions from the training dataset as few-shot examples, it would still be insightful to see what performance gap this additional information leads to.\n\nIn general, paper presentation could be further polished:\n- Nit: Clean up Figure 1 further \u2013 e.g. typos follwing -> following , Demonetration -> Demonstration, in the Input to LLM section for SEC Demonstration Generation\n- Nit: Table 2 is a little hard to read, maybe have larger spaces / break lines between different rows of strategies"
                },
                "questions": {
                    "value": "The authors note that ICL and SEC get different questions correct for GSM8K. Have they tried combining both methods? In other words, using ICL with human-crafted demonstrations combined with having the model additionally generate its own questions. Does this lead to better coverage in the correctly answered questions?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1674/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1674/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1674/Reviewer_wk7D"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1674/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698713175065,
            "cdate": 1698713175065,
            "tmdate": 1700651053307,
            "mdate": 1700651053307,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "E1DDpxLrAB",
                "forum": "frRDT6EOhg",
                "replyto": "9GDb26AodB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1674/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1674/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for their insightful comments and constructive feedback. We address each concern below:\n\n\n\n**Q1:** SEC\u2019s performance on less capable language models.\n\n\u2028\u2028**A1:** We appreciate your concern about SEC\u2019s applicability to smaller, less capable models. As reported in Section 4, SEC indeed shows a performance drop when applied to smaller models, which can struggle with instruction following and generating high-quality few-shot examples. This is a critical aspect of our ongoing research, and we plan to extend our evaluations to a wider range of models, including open-source ones. These additional experiments will provide deeper insights into SEC's scalability and effectiveness across different model sizes.\n\nHowever, it is important to highlight the growing trend towards larger and more capable language models in the field. As language models continue to scale up in size and sophistication, we anticipate that the importance and relevance of methods like SEC will increase correspondingly. The ability of SEC to autonomously generate demonstrations is likely to become more valuable as models become more adept at complex reasoning and generation tasks. Therefore, while we acknowledge the current limitations with smaller models, we believe that the scaling trend in language models will make SEC an increasingly crucial method in the future.\n\n**Q2:** Comparisons with \"Automatic chain of thought prompting in large language models (Zhang et al., 2022)\"\n\n**A2:** We recognize the importance of contextualizing SEC within the landscape of related work, such as Auto-CoT by Zhang et al. Our initial decision to exclude Auto-CoT from our baseline comparisons stemmed from its intensive querying and clustering requirements to generate demonstrations. This process can be particularly challenging, and even infeasible, for users dealing with single-question scenarios, which are common in practical applications.\u2028\u2028\n\nHowever, we appreciate the reviewer's suggestion to include a comparison with Auto-CoT. In our revised manuscript, we plan to incorporate a direct comparison between SEC and Auto-CoT on some classical benchmarks.\n\n**Q3:** Combining ICL and SEC\n\n**A3:** The suggestion to combine ICL with human-crafted demonstrations and SEC\u2019s model-generated questions is indeed intriguing. While we have not explored this combination, we recognize its potential for synergistically enhancing performance. We will initiate experiments combining these methods in the coming days. \n\nHowever, it's important to note that the primary contribution of this paper remains the introduction of SEC as a strong, novel and flexible zero-shot prompting method.\n\n**Q4:** Presentation and Figures\u2028\u2028\n\n**A4:** We thank the reviewer for pointing out the typographical errors in Figure 1 and the readability issue in Table 2. We will correct these in our revised version to enhance clarity and presentation quality.\n\nOnce again, we thank you for your valuable feedback and look forward to further improving our work."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1674/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699837748447,
                "cdate": 1699837748447,
                "tmdate": 1699920616109,
                "mdate": 1699920616109,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QfP62yoApH",
                "forum": "frRDT6EOhg",
                "replyto": "9GDb26AodB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1674/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1674/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Comparison between SEC and Auto-CoT"
                    },
                    "comment": {
                        "value": "We have carried out the experiments on Auto-CoT. CoT-SEC's performance is comparable to Auto-CoT, even without access to the full test dataset and additional clustering. \n\n|                        |   GSM8K  | ARC |\n|---------------------- |------|-------|\n|                       |      |       |\n| *Zero-shot CoT*       |   73.4 | 84.1  |\n| *CoT-ICL*             | 77.4 | 87.9  |\n| *Auto-CoT*            |77.5|87.8|\n| *CoT-SEC*             | 77.0|86.9|\n|                      | (-0.5)|(-0.9) |\n\nThe results in the table will later be added into the revised version of our paper."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1674/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700280158624,
                "cdate": 1700280158624,
                "tmdate": 1700280197930,
                "mdate": 1700280197930,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sJwRmTmOg3",
                "forum": "frRDT6EOhg",
                "replyto": "E1DDpxLrAB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1674/Reviewer_wk7D"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1674/Reviewer_wk7D"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the author response with additional experiments addressing my concerns. In particular, the baseline with Auto-CoT is helpful and the added experiment on an underrepresented task shows an interesting limitation of the method. I see that the authors are also revising the main contributions of the paper for clarity and focus on framing the method as a zero-shot method. I would also suggest updating the title to make this more clear. Overall, I am happy to update my score given these additional changes being incorporated into the paper."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1674/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700651019265,
                "cdate": 1700651019265,
                "tmdate": 1700651019265,
                "mdate": 1700651019265,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wZLPtU86hL",
            "forum": "frRDT6EOhg",
            "replyto": "frRDT6EOhg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1674/Reviewer_B8T2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1674/Reviewer_B8T2"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed a novel zero-shot learning framework, self-contemplation prompting strategy (SEC), that uses LLMs to generate demonstrations on a task and apply in-context learning (LCL) with the LLM-crafted demonstrations.\nInterestingly, extensive experiments in arithmetic reasoning, commonsense reasoning, multi-task language understanding, and code generation benchmarks, show that the SEC performance is competitive or outperforms ICL with the human-crafted demonstrations."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This is very interesting in the sense that it completely eliminates the effort of writing demonstrations in in-context learning. Although the idea itself is very simple, the experimental results obtained are also very impressive."
                },
                "weaknesses": {
                    "value": "What everyone probably cares about is whether the generated demonstration is correct. The authors analyze this point in Sec. 4 and Appendix B, but the number of predictions analyzed is very small (20 correct and 20 incorrect), making it difficult to reach a statistically consistent conclusion. \nIn particular, we need a clear hypothesis as to why the correct answer rate increases even though the generated demonstration is incorrect, and a sufficient amount of evidence to support it.\nAlso, using only a single LLM is used in the experiment makes it difficult to discuss whether the quality of the results is based on the properties of the language model itself, or whether it is simply a property that only GPT 3.5 has in the current version.  In particular, recent papers on prompting often try to analyze universal results by comparing multiple language models.\nAs a science, it is important to show universal results in LLM to some extent. \nThe Chain-of-Thought paper also provides results for multiple LLMs."
                },
                "questions": {
                    "value": "1. Can you analyze a sufficient number of results to prove your hypothesis regarding the following questions stated in your paper?\n\"Why incorrect few-shot demonstrations could lead to correct final predictions, while correct few-shot demonstrations could also lead to incorrect predictions?\"\n\n2.Can we analyze the generality of this result using multiple language models?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1674/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1674/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1674/Reviewer_B8T2"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1674/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698741808258,
            "cdate": 1698741808258,
            "tmdate": 1700644671914,
            "mdate": 1700644671914,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PNB54zAvra",
                "forum": "frRDT6EOhg",
                "replyto": "wZLPtU86hL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1674/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1674/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We greatly appreciate the constructive feedback and insightful suggestions provided by the reviewer. Our responses to the raised concerns are as follows:\n\n**Q1**: The statistically consistent conclusion on the correctness of demonstrations\n\n**A1**: Sorry for the confusion. We acknowledge the reviewer's concern about the correctness of demonstrations. However, previous study shows that in-context learning does not rely on the input-label mapping in the demonstrations to perform the task (Min, Sewon, et al.). The correctness of individual demonstrations is not the sole determinant of the overall quality, especially in the context of language models' ability to generalize from these inputs.\n\nThus, regarding the phenomenon that correct answer rate increases even though the generated demonstration is incorrect, a reasonable explanation is that strict correctness may not be the primary influencing factor in ICL's performance. Instead, language models might utilize other cues and patterns within demonstrations to arrive at correct conclusions.\n\n**Thus, the correctness of SEC's demonstration isn't a key factor of SEC's success.**\n\nMoreover, while our study involved 20 correct and 20 incorrect predictions, each case incorporated 5 demonstrations, resulting in an effective analysis of 200 demonstrations. This sample size, we believe, offers a reasonable overview of potential error types within demonstrations. Nevertheless, we recognize the importance of expanding this analysis and plan to include a larger dataset in future work to enhance the robustness of our conclusions.\n\n**Q2**: Generality of SEC using multiple language models\n\n**A2**: We concur with the reviewer on the importance of investigating SEC's applicability to multiple models. To this end, we intend to extend our experiments to include both open-source models and the newer GPT-4 architecture.\n\n\n\n[1] Min, Sewon, et al. \"Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?.\" Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. 2022."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1674/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700268956737,
                "cdate": 1700268956737,
                "tmdate": 1700538016527,
                "mdate": 1700538016527,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mENtO0Egf1",
                "forum": "frRDT6EOhg",
                "replyto": "wZLPtU86hL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1674/Reviewer_B8T2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1674/Reviewer_B8T2"
                ],
                "content": {
                    "title": {
                        "value": "Update score"
                    },
                    "comment": {
                        "value": "The author's reply and additional experiments seem reasonable to me. \nTherefore, I raise my score."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1674/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700644625664,
                "cdate": 1700644625664,
                "tmdate": 1700644625664,
                "mdate": 1700644625664,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "RY5TlcjAPG",
            "forum": "frRDT6EOhg",
            "replyto": "frRDT6EOhg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1674/Reviewer_fqq3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1674/Reviewer_fqq3"
            ],
            "content": {
                "summary": {
                    "value": "The paper propose \"self-contemplating (SEC)\" prompting strategy a variation of the more common in-context learning (ICL) approach. The proposed approach consists of two steps: First, use the LLM to generate demonstrations based on the query sample; Second; use the generated demonstrations together with the query sample to create the final prompt that is fed back to the same LLM. The potential benefit lies in the fact that no additional reference training data is needed for curating the set of demonstrations. Experiments show that SEC performs comparably to the traditional ICL approach using the gpt-3.5-turbo model. However, SEC underperforms on other GPT models."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper is well written and is easy to understand. The paper introduces an interesting idea of only relying on the target LLM for generating demonstrations based on the target query sample. Doing so results in generating demonstrations that are probably better suited for the query sample. Also, the proposed approach helps remove the need for curating hand-crafted demonstrations which is a time consuming task."
                },
                "weaknesses": {
                    "value": "1) The SEC method is only compared to the ICL approach where demonstrations are hand selected, i.e., not automatically selected. Several automated demonstration selection and curation approaches have been proposed in the last few years that should have been considered. SEC performs similar to hand-crafted ICL demonstrations. However, it is very likely that it might underperform once automated demonstration selection+curation approaches are introduced for comparison. Please look at the following papers and include them in your analysis:\n a) https://aclanthology.org/2023.findings-acl.273.pdf\n b) https://arxiv.org/abs/2211.04486\n c) https://arxiv.org/abs/2310.10707\n d) https://arxiv.org/abs/2302.05698\n e) https://arxiv.org/abs/2104.08786\n\n3) Relying on the LLM for generating demonstrations has the potential problem of propagating biases that exist in the model. The SEC method does not account for situations where model's bias can impact the final prediction and overall result.\n\n4) Only closed-source GPT-based models from OpenAI were considered. The authors should investigate if SEC can be extended to open-source models.\n\n5) The authors claim that quality of demonstrations generated by the SEC paradigm are better than hand-crafted demonstrations. A qualitative analysis should be done to verify this claim. However, it is surprising to see that SEC performance reduces as number of demonstrations is increased, thereby contradicting this claim."
                },
                "questions": {
                    "value": "Please see the above comments."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1674/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698803027791,
            "cdate": 1698803027791,
            "tmdate": 1699636095521,
            "mdate": 1699636095521,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0Cb1L2Wl3W",
                "forum": "frRDT6EOhg",
                "replyto": "RY5TlcjAPG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1674/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1674/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are thankful for the valuable insights and constructive feedback provided by the reviewer. We address each concern below:\n\nSorry for the confusion. First we want to clarify that SEC isn\u2019t a variant of in-context learning. Inherently, SEC is a zero-shot method which only relies on test input.\n\n**Q1**: Comparison with Automated Demonstration Selection Approaches\n\n**A1**: We apologize for any confusion. We acknowledge the reviewer's point on comparing SEC with automated demonstration selection and curation approaches. However, it's crucial to emphasize that **SEC inherently functions as a zero-shot method**, relying solely on test input, which sets it apart from ICL. Comparing SEC directly with automated demonstration selection approaches may not be entirely fair, **as the latter often requires a substantial pool of training examples for selection**. Our intention in comparing SEC with ICL was primarily illustrative, highlighting SEC's superiority over the zero-shot baseline.\n\nSEC substantially outperforms zero-shot baseline and reaches comparable performance with ICL methods which proof it\u2019s efficacy. To provide a more comprehensive comparison, we are currently adding experiments with Zero-shot CoT. Preliminary results indicate that on benchmarks like GSM8k and ARC, Zero-shot CoT's performance (73.39 on GSM8k and 84.04 on ARC) is outperformed by CoT-SEC (77.0 on GSM8k and 86.9 on ARC).\n\nFor the five paper you kindly provided, (a) focuses on exemplar selection from the view of explanations, (b) focuses on active example selection, (c) focuses on applying ICL to offensive content paraphrasing, (d) focuses on CEIL, an ICL example selection method, and (e) focuses addressing the order sensitivity in ICL. These approaches, indeed, improve upon vanilla ICL using training datasets. However, **our approach with SEC offers a novel perspective by achieving comparable ICL performance without relying on training data**. This difference in approach underscores SEC's flexibility and ease of use, presenting an alternative direction in the realm of language model prompting.\n\n**Q2**: Bias of SEC\n\n**A2**: We recognize the importance of addressing potential biases in LLM-generated demonstrations. While SEC demonstrates comparable performance to ICL in common benchmarks, we understand the need for further exploration, especially in tasks rare in training data. We plan to add such tasks in our revised version.\n\nAdditionally, it's crucial to note that human-crafted prompts are not immune to biases. As highlighted by Ma et al. (2023), human biases can inadvertently influence the crafting of prompts. Hence, both human-crafted and LLM-generated content require careful consideration regarding bias.\n\n**Q3**: Applicability to Open-Source Models\n\nOur initial study focused on closed-source GPT-based models due to their prevalent use and performance. However, we agree with the reviewer that investigating SEC's applicability to open-source models is essential. We plan to conduct additional experiments with open-source models to validate SEC's effectiveness across a wider range of language model architectures.\n\n**Q4**: Quality of Demonstrations and Performance with Increased Demonstrations\n\nA4: Sorry for the confusion. We acknowledge that SEC's performance may not always surpass that of human-crafted prompts. The example in Figure 20 of our paper illustrates this point.\n\nRegarding the observed decrease in performance with an increased number of demonstrations, **we hypothesize the existence of an optimal number of demonstrations for SEC**, akin to what Reynolds and McDonell (2021) observed for human-crafted prompts. **The tailored nature of SEC's demonstrations might necessitate a smaller number of examples compared to human-crafted ones for optimal performance.** Therefore, **the decline in performance after a certain number of shots should not be misconstrued as an indication of poor demonstration quality**.\n\nAlso, **we only observe this decrease in performance with an increased number of demonstrations on HumanEval dataset** while on other dataset (e.g. GSM8k), there doesn't exist such a decrease. \n\nBesides, we do include a **qualitative analysis on the correctness demonstrations in Section 4 and Appendix B** of our paper.\n\n[1] Ma, Huan, et al. \"Fairness-guided Few-shot Prompting for Large Language Models.\" arXiv preprint arXiv:2303.13217 (2023).\n\n[2] Reynolds, Laria, and Kyle McDonell. \"Prompt programming for large language models: Beyond the few-shot paradigm.\" Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. 2021."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1674/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700269791928,
                "cdate": 1700269791928,
                "tmdate": 1700591022419,
                "mdate": 1700591022419,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "qMQNcXGig4",
            "forum": "frRDT6EOhg",
            "replyto": "frRDT6EOhg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1674/Reviewer_yTZX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1674/Reviewer_yTZX"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes the self-contemplation prompting strategy (SEC) to let the LLM itself propose the demonstrations and then use the demonstrations to do downstream in-context learning. Experiments on different benchmarks show that the LLM itself can generate meaningful demonstrations to help improve performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper is quite clear and easy to follow.\n\n - The method is easy to understand.\n\n - The evaluation is well-designed."
                },
                "weaknesses": {
                    "value": "- The main concern is the significance of the paper. The proposed prompting method can be treated as a two-step chain-of-though prompting by letting the LLM (1) first think about the possible demonstration and then (2) use the demonstration to do in-context learning. Form this point of view, the prompting framework is one specific usage of CoT, which makes the contribution limited."
                },
                "questions": {
                    "value": "- I am curious about the limitations of the proposed method. Using LLM for self-improvement may suffer from performance degradation \u2013 Once the LLM generates some wrong correction, the overall performance may drop significantly. Have you noticed any domains experiencing performance declines when using LLMs to generate their prompts?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1674/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699333895960,
            "cdate": 1699333895960,
            "tmdate": 1699636095460,
            "mdate": 1699636095460,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LiercxDvob",
                "forum": "frRDT6EOhg",
                "replyto": "qMQNcXGig4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1674/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1674/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank the reviewer for the encouraging comments and address the concerns below.\n\n**Q1:** On the Significance of SEC as Another Form of CoT\n\n**A1:** Your observation that SEC may seem akin to an extension of the chain-of-thought (CoT) prompting is insightful. However, SEC distinguishes itself by enabling the model to perform analogical reasoning, which is a leap beyond the capabilities of traditional CoT methods. SEC is fundamentally a zero-shot prompting pipeline. To provide a more comprehensive comparison, we are currently adding experiments with Zero-shot CoT. Preliminary results indicate that on benchmarks like GSM8k and ARC, Zero-shot CoT's performance (73.39 on GSM8k and 84.04 on ARC) is outperformed by CoT-SEC (77.0 on GSM8k and 86.9 on ARC).\n\nThese findings reinforce our belief that SEC's performance cannot be easily replicated by existing CoT methods in a Zero-shot scenario. SEC's novelty, therefore, lies in its unique ability to autonomously generate meaningful demonstrations, which sets it apart from existing CoT approaches.\n\n**Q2:** The Limitations of SEC\n\n**A2:** We apologize for any confusion regarding the limitations of SEC. We recognize the potential for performance degradation with incorrect self-generated demonstrations. Our analysis indicates that large language models, particularly those with capacities at or above GPT-3.5, tend to be robust against minor errors in self-generated prompts for common tasks, maintaining performance comparable to that with human-crafted prompts.\n\nOur experiments across various reasoning tasks show that SEC generally achieves promising results. However, we recognize that in rare or abstract reasoning tasks, which have limited representation in training data, the model might encounter challenges. We plan to conduct further experiments in these domains to comprehensively understand SEC's limitations. Notably, in the domain of MATH, where LLMs typically struggle, CoT-SEC has outperformed CoT-ICL, reaffirming our observation about the robustness of larger models against minor prompt errors.\n\nIn Section 4, we have evaluated SEC\u2019s performance on smaller models and observed that its effectiveness diminishes with smaller model capacities. We are committed to extending our research with additional experiments using open-source models to further explore SEC\u2019s applicability and limitations across different model scales."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1674/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699816018653,
                "cdate": 1699816018653,
                "tmdate": 1699920172550,
                "mdate": 1699920172550,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yj2Yd3OuW3",
                "forum": "frRDT6EOhg",
                "replyto": "qMQNcXGig4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1674/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1674/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Updates to the previous response"
                    },
                    "comment": {
                        "value": "There are some updates to the response.\n\n**A1:** We have added zero-shot CoT as a part of our baseline methods to all our main experiments on GPT3.5, GPT4 and Llama2 34B. SEC consistently outperforms zero-shot CoT. \n\nThe distinctiveness of SEC lies in its ability to autonomously generate meaningful demonstrations, differentiating it significantly from traditional CoT methodologies. \u2028\u2028\n\n**A2:** On the experiments of 200 3-digit base-5 addition problems, we do observe slight performance degradation of SEC compared to ICL. Nevertheless, SEC still outperforms it\u2019s Zero-shot baselines in corresponding scenarios (Vanilla SEC to Zero-shot and CoT-SEC to Zero-shot CoT).\n\nContrary to what might be assumed, the incorrect demonstrations are not the primary cause of this performance drop, as supported by the research of (Min, Sewon, et al.). We hypothesize that the performance degradation may stem from the model's unfamiliarity with the task, leading it to generate question-answer pairs that deviate from the expected distribution. For instance, the model might produce answers containing digits like 6, 7, 8, 9, which are outside the scope of base-5 calculations.\n\n#### References\n#### [1] Min, Sewon, et al. \"Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?.\" Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. 2022."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1674/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700534380222,
                "cdate": 1700534380222,
                "tmdate": 1700534380222,
                "mdate": 1700534380222,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "S3KWiq70em",
                "forum": "frRDT6EOhg",
                "replyto": "yj2Yd3OuW3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1674/Reviewer_yTZX"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1674/Reviewer_yTZX"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the rebuttal"
                    },
                    "comment": {
                        "value": "I appreciate the author's detailed rebuttal, and my score remains unchanged."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1674/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687292037,
                "cdate": 1700687292037,
                "tmdate": 1700687292037,
                "mdate": 1700687292037,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]