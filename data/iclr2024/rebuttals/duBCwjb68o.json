[
    {
        "title": "Latent Consistency Models: Synthesizing High-Resolution Images with Few-step Inference"
    },
    {
        "review": {
            "id": "2mOxNYegDx",
            "forum": "duBCwjb68o",
            "replyto": "duBCwjb68o",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6819/Reviewer_SB2d"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6819/Reviewer_SB2d"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes to train consistency models using a pretrained large latent diffusion model (i.e., Stable Diffusion). The main difference between the original consistency models follows: (a) Consideration of augmented ODE with guidance scale $\\omega$ to enable the distillation in a single stage, (b) use skipping timesteps for distillation since pretrained Stable Diffusion uses larger timestep (1,000) than original consistency models that use EDM formulation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- The paper is generally well-written and easy to follow.\n- Compared with other efficient sampler or distillation methods, the proposed method shows a considerable performance improvement in a smaller sampling step regime."
                },
                "weaknesses": {
                    "value": "- My major concern is about the technical novelty and contribution of this work. The paper argues there are two main contributions: (a) usage of augmented ODE and (b) skipped timestep (e.g., $k=20$) for better distillation. For (a), it seems quite straightforward to consider augmented ODE since the Stable Diffusion uses cfg. For (b), it also seems straightforward since Stable Diffusion uses a large timestep ($T=1000$), unlike EDM formulation in the original consistency model paper, and thus, one can easily expect using consecutive timesteps for distillation is inefficient. In these respects, I think both (a) and (b) looks too straightforward and marginal technical contribution to be accepted at ICLR. \n-  Title -- \"Latent\" Consistency model? I expected the authors to consider unique aspects of the \"latent\" diffusion model in incorporating the concept of consistency models; for instance, the original consistency model paper argues using perceptual metrics is efficient for better distillation. However, it seems the proposed method does not depend on whether the pretrained model is a latent diffusion model or not; it can be applied to any diffusion model that uses a large timestep (e.g., $T=1000$); thus, I think including \"latent\" in the title is unnecessary. \n- For figures for qualitative illustrations, it's better to provide text prompts to show the image-text alignment as well."
                },
                "questions": {
                    "value": "- Why is the DDIM sampler mainly used for LCD (main experiments; Table 1 and 2)? What if the method uses a different ODE solver/sampler? \n- Which metric does LCD use for distillation? The original consistency model paper mainly uses the LPIPS score, but it seems such a metric is not applicable since this method deals with latent diffusion models."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6819/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698652847206,
            "cdate": 1698652847206,
            "tmdate": 1699636788660,
            "mdate": 1699636788660,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "J0llI5ZpkM",
                "forum": "duBCwjb68o",
                "replyto": "2mOxNYegDx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer SB2d"
                    },
                    "comment": {
                        "value": "We address your concerns below.\n\n### 1. About technical novelty and contribution of this work.\n\nWe understand the concerns raised about the perceived straightforwardness of our contribution. Still, we politely ask for a reevaluation of our paper contribution. To clarify:\n\n1) A key difference between the original consistency models [1] and LCM lies in the transformation of the **empirical PF-ODE** (Eq.24) from the original consistency model to a **more general PF-ODE** (Eq.8). This was not addressed in the original model [1]. We also adapted the Euler/Heun solver under EDM schedule [2] to a more compatible solver for Stable Diffusion (see Eq.18 and Appendix E, including DDIM, DPM, DPM++ solvers).  Our approach expands the original model's $x$-prediction (Eq.24) to include $\\epsilon$-prediction and $v$-prediction for Stable Diffusion, **offering broader parameterizations as shown in Eq. 9 and Appendix D**. These transformations and adaptations are **non-trivial and are critical** for LCM's success. However, we have weakened these difference in the main paper for readers much easier to read. \n\n2) Our method successfully combines latent consistency distillation (LCD), one-stage guided consistency distillation (CFG), and skipping-step techniques to achieve a highly efficient **single-stage** guided distillation for text-to-image tasks. This represents a significant advancement over previous two-stage methods like Guided-Distill [3]. With only 32 A100 GPU hours, we achieve impressive 2~4-step inference results, **demonstrating both efficiency and effectiveness**.\n\n**Simplicity and effectiveness**, far from being limitations, are vital principles in AI research. Our work not only identifies critical components for effective LDM distillation but also achieves remarkable few-step inference results, paving the way for real-time generative AI applications. **We strongly require a reevaluation of our paper, and believe firmly that LCM have made enough contribution to this field**.\n\n### 2. About title.\nWe thank the reviewer for their attention to the choice of terminology in our paper\u2019s title. The title ``Latent Consistency Models\" was chosen deliberately to acknowledge two prior seminal papers titled \u201cLatent Diffusion Models\u201d (Rombach et al.) and \u201cConsistency Models\u201d (Song et al.) and we believe our title is an accurate reflection of the essence of our work. The choice to include \u201clatent\u201d in the title emphasizes the context in which the consistency model is applied. In particular, our research is primarily based on the most widely used open-sourced latent diffusion models (i.e., Stable Diffusion). We utilize the same autoencoder framework as these models, which is central to our method. Furthermore, our experiments demonstrate that our models not only produce generation quality comparable to existing latent diffusion models but also significantly expedite the sampling process. While it is true that some of the methods we proposed (e.g., the skipping-step technique) could be adapted to other diffusion models, the effectiveness and efficiency of our approach are particularly pronounced in the latent space, as demonstrated by our experiments. Moreover, we think the inclusion of the word \u201clatent\u201d helps delineate our work from the original Consistency Model by Song et al, thereby avoiding potential confusion. In conclusion, we think our title is carefully chosen to honor prior works while accurately representing the core innovation of our work. We hope this clarifies our rationale and justifies the choice of our title\u2019s wording.\n\n### 3. About text prompts\n\nThanks for pointing out. We have updated the main paper. The text prompts of Figure 1 are provided in **Appendix.M**. Also we provide the LCM SD-XL [4] results in **Appendix.L (Figure.12)**.\n\n### 4. About experiments\n\n> 4.1. Why is the DDIM sampler mainly used for LCD for main experiments? What if the method uses a different ODE solver?\n\nIn Figure 3, We present the ablation results for different ODE solvers and the number of skipping steps. It is evident that under our chosen number of skipping steps (20 steps), DDIM, DPM-Solver, and DPM-Solver++ demonstrate similar experimental outcomes. As a result, we selected DDIM to complete our main experiments. We believe that the experimental results using DDIM as the ODE solver are sufficiently representative and effective in terms of the performance metrics achieved by our method. \n\n> 4.2 Which metric does LCD use for distillation.\n\nThank you for pointing out this issue. Since we have already employed an autoencoder to encode the original images into the latent space, the LPIPS metric used in the original Consistency Models paper [1] is not appropriate in the latent space. We used the L2 distance in the latent space as our distance metric. We have updated our paper to make this information more explicitly."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6819/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700413330129,
                "cdate": 1700413330129,
                "tmdate": 1700413402983,
                "mdate": 1700413402983,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rmdw3ZVTyv",
                "forum": "duBCwjb68o",
                "replyto": "2mOxNYegDx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reminder to Reviewer SB2d"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for reviewing our paper. We hope our responses have addressed your concerns. If so, we kindly ask if you could reconsider your score for our work.\n\nShould you have any further questions, we're ready to discuss and clarify.\n\nMany thanks for your time and effort."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6819/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700624275020,
                "cdate": 1700624275020,
                "tmdate": 1700624275020,
                "mdate": 1700624275020,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "42l0xqM4eN",
                "forum": "duBCwjb68o",
                "replyto": "2mOxNYegDx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Deadline coming. looking forward to your feedback."
                    },
                    "comment": {
                        "value": "Dear Reviewer SB2d, We kindly request your feedback as the rebuttal deadline is approaching in less than 1 days. We hope our previous feedback addresses your concern. We would like to thank you again for your time and previous review and we are looking forward to further discussions."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6819/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659155300,
                "cdate": 1700659155300,
                "tmdate": 1700659155300,
                "mdate": 1700659155300,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vGoj0Fi8DZ",
            "forum": "duBCwjb68o",
            "replyto": "duBCwjb68o",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6819/Reviewer_pn9B"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6819/Reviewer_pn9B"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes latent consistency models for fast high-resolution image generation. In addition, it provides a simple and efficient one-stage guided consistency distillation method for few-step (2\u223c4) or even 1-step sampling. Experiments show that the LCMs achieves state-of-the-art text-to-image generation performance with few-step inference."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The idea is novel and interesting. The author proposes latent consistency models that leverage consistency model in latent space, achieving few-step or even one-step sampling.\n2. The experimental results look impressive. The latent consistency model outperforms state-of-the-art methods by large margin especially with one step."
                },
                "weaknesses": {
                    "value": "1. The paper is not well-organized. The introduction of the proposed method in Sec.1 is too concise. The description and motivation for each design should be more detailed. Figure.1 takes up too much space and can be reduced appropriately. \n2. Insufficient content for related work.\n3. Lack of ablation studies. The authors should provide qualitative results of the ablation studies on the ODE solvers & skipping-step schedule as well as qualitative and quantitative results on guided consistency distillation."
                },
                "questions": {
                    "value": "1. What's the overall pipeline of the proposed method? It seems that the authors do not describe or show the pipeline in detail.\n2.  It is better to show the comparisons between training time and memory."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6819/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6819/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6819/Reviewer_pn9B"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6819/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698839072424,
            "cdate": 1698839072424,
            "tmdate": 1699636788540,
            "mdate": 1699636788540,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "q6x5FxBowu",
                "forum": "duBCwjb68o",
                "replyto": "vGoj0Fi8DZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer pn9B"
                    },
                    "comment": {
                        "value": "We thank the constructive feedback from you. We address your concerns below.\n\n### 1. The paper is not well-organized. .... Figure 1. takes up too much space.\n\nThanks for pointing out. We have updated the paper. Adding more content to the intro. And we add more details to the motivation, reducing the Figure.1 space.\n\n### 2. Insufficient content for related work.\n\nThanks for pointing out. We have added more related work content in the updated paper.\n\n### 3. Lack of ablation studies.\n\n> 3.1 Qualitative comparison of different ODE-solvers and skipping steps\n\nThanks. **Figure 3 clearly demonstrates the effects of using different ODE-solvers and skipping-step schedules**, making further visualization in the main paper somewhat redundant. Nonetheless, we've included updated qualitative ablation study results on these aspects in **Appendix.K (Figure 11)**, supporting conclusions similar to those in Section 5.2 and Figure 3, particularly the importance of step-skipping for faster training and the drawbacks of excessively large skipping steps.\n\n> 3.2 Qualitative and quantitative results on guided consistency distillation.\n\nThanks. Our qualitative and quantitative results on guided consistency distillation **are already presented in Figures 4 and 5**. It is important to note that using a very small Classifier-free guidance (CFG) scale is essentially equivalent to disabling CFG. From Figure 4, it is evident that a smaller CFG scale ($\\omega=2$) results in a lower CLIP Score compared to a larger scale. Moreover, an increased CFG scale significantly enhances image quality, as shown by the increasing CLIP Score in Figure 4 and the visualization results in Figure 5. In conclusion, our experimental results have clearly demonstrated the effectiveness of one-stage guided consistency distillation.\n\n### 4. About overall pipeline of LCM.\n\nThanks for asking. LCM's pipeline, mainly outlined in Algorithm 1, consists of three main steps: (1) Start with any pretrained LDM; (2) Apply the latent consistency distillation (LCD) method from Algorithm 1 to convert the LDM into an LCM; (3) Employ the multi-step inference method in Algorithm 3 for fast sampling from the LCM.\n\n### 5. better to show the comparisons between training time and memory.\n\nThank you for your suggestion. In terms of training time, both Guided Distill [1] and our LCM method are almost the same, each trained for the same number of iterations (100K, as detailed in Section 5.1) and use same batch sizes. Regarding memory usage, both methods exhibit similar requirements, with Guided Distill consuming approximately 71.1GB and LCM also using 71.3GB of memory for global batchsize=$72$ with 8 A100s. We would like to mention that LCM has potential for further training optimizations, such as mixed precision training and gradient checkpointing techniques. These considerations are beyond the current scope of our paper and left as future improvement.\n\nReferences:\n\n[1] Meng, et al. \"On distillation of guided diffusion models\" (2023)"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6819/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700412624628,
                "cdate": 1700412624628,
                "tmdate": 1700412714701,
                "mdate": 1700412714701,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "doBAvzTju0",
                "forum": "duBCwjb68o",
                "replyto": "vGoj0Fi8DZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reminder to Reviewer pn9B"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for reviewing our paper. We hope our responses have addressed your concerns. If so, we kindly ask if you could reconsider your score for our work.\n\nShould you have any further questions, we're ready to discuss and clarify.\n\nMany thanks for your time and effort."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6819/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700624240259,
                "cdate": 1700624240259,
                "tmdate": 1700624240259,
                "mdate": 1700624240259,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IxG2OdI0Pz",
                "forum": "duBCwjb68o",
                "replyto": "vGoj0Fi8DZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Deadline coming. looking forward to your feedback."
                    },
                    "comment": {
                        "value": "Dear Reviewer pn9B, We kindly request your feedback as the rebuttal deadline is approaching in less than 1 days. We hope our previous feedback addresses your concern. We would like to thank you again for your time and previous review and we are looking forward to further discussions."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6819/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659129738,
                "cdate": 1700659129738,
                "tmdate": 1700659129738,
                "mdate": 1700659129738,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "t8GzobMzOM",
            "forum": "duBCwjb68o",
            "replyto": "duBCwjb68o",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6819/Reviewer_24Xw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6819/Reviewer_24Xw"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors apply the consistency model to the latent diffusion, significantly reducing the inference steps in diffusion models. They also implement guided distillation, enhancing quality through classifier-free guidance, and introduce time step skipping to expedite the distillation process. The effectiveness is demonstrated through experiments on LAION subsets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The paper is well-written and the method is intuitive to understand.\n* The results are impressive. The proposed method can significantly reduce the sampling steps of the diffusion models while achieving a decent quality performance."
                },
                "weaknesses": {
                    "value": "* The authors should benchmark their approach against the single-step diffusion model [InstaFlow](https://github.com/gnobitab/InstaFlow) [1], and also include results from the original 50-step Stable Diffusion as a baseline. It's currently unclear how their method's speed gains affect performance.\n* The proposed latent consistency fine-tuning seems not working, as shown in Figure 6. On the Simpsons dataset, the quality of 30K finetuning is worse than the original LCM.\n* The paper lacks results on realistic photo generation, featuring only artistic illustrations. Including realistic photo results would strengthen the evaluation.\n* The paper's novelty appears limited. It primarily adapts consistency models to latent space and uses guided distillation in Meng et al. [2] to support Classifier-Free Guidance. While skipping time steps shows efficacy, it doesn't substantially elevate the paper's technical novelty. Are there some challenges of applying consistency models to latent space compared to pixel space?\n\n[1] InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation\n\n[2] On Distillation of Guided Diffusion Models"
                },
                "questions": {
                    "value": "* No corresponding text prompts in the visual results (e.g., Figure 1).\n* Typo. Section 3 Preliminaries -- Diffusion Models: \"origin data distribution\" -> \"original data distribution\""
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6819/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698865526609,
            "cdate": 1698865526609,
            "tmdate": 1699636788405,
            "mdate": 1699636788405,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PUmLt6kKVz",
                "forum": "duBCwjb68o",
                "replyto": "t8GzobMzOM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 24Xw"
                    },
                    "comment": {
                        "value": "We sincerely thank the constructive feedback from you. We address your concerns below.\n\n### 1. About benchmarking.\n\n> 1.1 should benchmark their approach against the single-step diffusion model InstaFlow.\n\nThank you for pointing out the InstaFlow paper. We acknowledge the significance of InstaFlow [1], which was released on September 12th, as indicated at https://arxiv.org/abs/2309.06380, just two weeks prior to the ICLR submission deadline. We became aware of this paper even a few days later. Due to such a short timeframe and the absence of publicly available code and pretrained models for InstaFlow, reproducing their work for a detailed comparison was not feasible within our project timeline.\nAdditionally, as per the guidelines provided in the ICLR FAQ section (https://iclr.cc/Conferences/2024/ReviewerGuide#FAQ), recent works published **within four months of the submission deadline are not required as baseline algorithms for comparison**. Given that InstaFlow appears to be submitted to the same ICLR24 conference, we consider it appropriate to regard it as concurrent work, aligning with standard academic practices.\nWe appreciate your understanding in this matter and are open to future comparisons with InstaFlow as part of our ongoing research, should the necessary resources become available.\n\n> 1.2 Include results from the original 50-step Stable Diffusion as a baseline.\n\nThanks for your suggestion. We include additional **50-Step DDIM Sampler** Stable Diffusion results here and we have also added it in the caption of Table 1 and 2.\n\n(512$\\times$512 Resolution) FID: 10.74 ,  CLIP-Score: 30.34  \n\n(768$\\times$768 Resolution) FID: 12.74 ,  CLIP-Score: 30.82\n\n> 1.3: Aboust speed gains comparison\n\nThanks for your suggestion. We also include the inference time in **Appendix.H (Figure.7)** for your reference. It can be noticed that LCM achieve at least **$4\\times$ acceleration** copmared with DPM-Solver++.\n\n### 2. About latent consistency fine-tuning.\n\nWe appreciate your interest in our approach to latent consistency fine-tuning (LCF). Upon reflection, we recognize that the Simpsons dataset may not have been the optimal choice for demonstrating fine-tuning capabilities. This is primarily because the original Stable Diffusion (SD) model already exhibits a strong proficiency in generating images in the distinctive style characteristic of the Simpsons. To provide a more comprehensive evaluation, we have supplemented our fine-tuning results **with two additional datasets**, the details of which can be found in **Section 5.3 (Figure.6)** and **Appendix.I (Figure.8)**. Moreover, it's important to highlight that our primary contribution lies in introducing LCF as a **viable alternative for fine-tuning LCM directly** instead of teacher diffusion model, showcasing its potential effectiveness. While there is certainly room for further refinement and improvements in LCF, we believe that these aspects represent exciting avenues for future research. Our current work lays the groundwork for such explorations.\n\n### 3. Lacks results of realistic photo generation.\n\nThank you for your valuable observation regarding the lack of results for realistic photo generation in our paper. We agree that this aspect is important for a comprehensive evaluation of our approach.\n\nTo clarify, the style of generative images in our study is significantly influenced by the choice of the teacher diffusion model. In Figure 1, we employed Dreamshaper-V7, a popular variant of Stable Diffusion that is fine-tuned specifically for artistic styles. Additionally, our testing utilized text prompts from LAION-5B-Aesthetic6.5+, a dataset that predominantly features aesthetically oriented prompts, resulting in a natural inclination toward artistic style generation in our results.\n\nWe acknowledge that Dreamshaper-V7, being fine-tuned on artistic images, is not the ideal model for generating realistic photos. To address this, we have included results of LCM applied to **SD-XL** [2], which represents a more challenging LDM, to demonstrate our method's capability in realistic image generation. These photo-realistic generation results with 4-step inference, underscore the effectiveness of LCM. You can find these additional results in **Appendix.L (Figure.12)**. We hope this addition adequately addresses your concern and highlights the broader applicability of LCM, including in scenarios requiring high-quality, photo realistic image generation."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6819/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700411146939,
                "cdate": 1700411146939,
                "tmdate": 1700411396299,
                "mdate": 1700411396299,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "b9QRDOBUwA",
                "forum": "duBCwjb68o",
                "replyto": "t8GzobMzOM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reminder to Reviewer 24Xw"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for reviewing our paper. We hope our responses have addressed your concerns. If so, we kindly ask if you could reconsider your score for our work.\n\nShould you have any further questions, we're ready to discuss and clarify.\n\nMany thanks for your time and effort."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6819/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700624194600,
                "cdate": 1700624194600,
                "tmdate": 1700624194600,
                "mdate": 1700624194600,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "boazoqaTy3",
                "forum": "duBCwjb68o",
                "replyto": "t8GzobMzOM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Deadline coming. looking forward to your feedback."
                    },
                    "comment": {
                        "value": "Dear Reviewer 24Xw, We kindly request your feedback as the rebuttal deadline is approaching in less than 1 days. We hope our previous feedback addresses your concern. We would like to thank you again for your time and previous review and we are looking forward to further discussions."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6819/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659101593,
                "cdate": 1700659101593,
                "tmdate": 1700659101593,
                "mdate": 1700659101593,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ZugqgLchb3",
                "forum": "duBCwjb68o",
                "replyto": "boazoqaTy3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6819/Reviewer_24Xw"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6819/Reviewer_24Xw"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment from Reviewer 24Xw"
                    },
                    "comment": {
                        "value": "Thank the authors for their response. Some of my concerns have been addressed, but I still have several questions:\n\n- Regarding Tables 1 and 2, could you elaborate on the experimental setup, particularly how you split the dataset into training and validation sets? It seems that you train LCM and evaluate the model on the same dataset. I am not sure if Guided-Diffusion follows the same protocol for evaluation and if the comparisons are fair.\n- For the COCO results, the photorealism in the generated images seems not that high. It would be nice if the authors could include the original SDXL results and also provide some quantitative evaluation on the COCO captions.\n- Equation 8 in your paper seems to come from Song et al. [1] and Lu et al. [2] as mentioned. What is the relation between it and Equation 24 or 7 in Consistency Model?\n\n[1] Score-based generative modeling through stochastic differential equations.\n\n[2] Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6819/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700709579948,
                "cdate": 1700709579948,
                "tmdate": 1700709579948,
                "mdate": 1700709579948,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SwF5xOcleZ",
                "forum": "duBCwjb68o",
                "replyto": "t8GzobMzOM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 24Xw"
                    },
                    "comment": {
                        "value": "Thanks for your feedback. We address your concerns below.\n\n> Regarding Tables 1 and 2, could you elaborate on the experimental setup, particularly how you split the dataset into training and validation sets? It seems that you train LCM and evaluate the model on the same dataset. I am not sure if Guided-Diffusion follows the same protocol for evaluation and if the comparisons are fair.\n\nWe conduct LCM experiment on Table 1 and Table 2 respectively. For Table 1, we use LAION-5B-Aesthetic-6.0+ dataset, containing 12M image-text pairs, and we train the LCM with $512\\times512$ on this dataset. For Table 2, we use the LAION-5B-Aesthetic-6.5+ dataset, containing 650M image-text pairs, and we train the LCM with $768\\times768$ resolution. For both dataset, we use 95\\% of the data set as the training set and the remaining 5\\% as the test set. We use 10,000 prompts from the test set for evaluation. The Guided-Distill follows the same protocal. We trained the Guided-Distill on the same dataset and use the same prompt for evaluation. The total training iteration and batch size is the same as LCM. The comparsions are totally fair and can reflect our LCM superiority.\n\n> For the COCO results, the photorealism in the generated images seems not that high. It would be nice if the authors could include the original SDXL results and also provide some quantitative evaluation on the COCO captions.\n\nIn Appendix N, we provide supplemental information detailing the qualitative results of images produced by both LCM-SDXL and SDXL with DPM Solver across various sampling steps. We can observe that LCM-SDXL is capable of generating images of comparable quality to that of the original SDXL's 25-step output with DPM Solver, in merely 4 steps, thus indicating a significant acceleration. However, due to the extensive overhead involved in the training process, we were unable to provide experimental results on the COCO dataset within such a short timeframe. On the other hand, LAION-5B is a more challenging dataset compared to COCO and the experimental results obtained from the LAION-5B dataset have demonstrated the effectiveness of our method.\n\n> Equation 8 in your paper seems to come from Song et al. [1] and Lu et al. [2] as mentioned. What is the relation between it and Equation 24 or 7 in Consistency Model?\n\nEquation (8) presents the general form of the PF-ODE, where the specific expressions for $f(t)$ and $g(t)$ in the equation vary depending on the noise schedule. When the EDM schedule [3] is chosen as done in the original Consistency Models by Song et al. [4], Equation (8) simplifies to Equation (24). By a straightforward discretization, we can get Equation (7) (the same as Equation (25).)\n\n[1] Score-based generative modeling through stochastic differential equations.\n\n[2] Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps.\n\n[3] Karras, Tero, et al. \"Elucidating the design space of diffusion-based generative models.\"\u00a0Advances in Neural Information Processing Systems\u00a035 (2022): 26565-26577.\n\n[4] Song, Yang, et al. \"Consistency models.\" (2023)."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6819/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700720385570,
                "cdate": 1700720385570,
                "tmdate": 1700726562478,
                "mdate": 1700726562478,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Vjg5pSy7eY",
            "forum": "duBCwjb68o",
            "replyto": "duBCwjb68o",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6819/Reviewer_dEPF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6819/Reviewer_dEPF"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes latent consistency models (LCMs) to swiftly inference with minimal steps on any pre-trained LDMs, e.g., Stable Diffusion. LCMs are designed to directly predict the solution of an augmented probability flow ODE in latent space to allow rapid, high-fidelity sampling. A latent consistency fine-tuning (LCF) is further introduced to fine-tune LCMs on customized image datasets. Experiments on the LAION-5B-Aesthetics dataset demonstrates the effectiveness of the proposed LCMs."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ The idea is interesting to view the guided reverse diffusion process as solving an augmented probability flow ODE.\n\n+ The performance looks good on both qualitative and quantitative results and in some cases the results of the proposed method with less steps are better than those of other methods with more steps.\n\n+ Some ablation studies are provided to facilitate the understanding of how the performance benefits from different components, including ODE solvers, skipping-step schedule and guidance scale."
                },
                "weaknesses": {
                    "value": "- Although the authors claim several contributions, it is not clear which ones have the most significant impact on efficiency and quality.\n\n- What is the computational complexity of solving augmented PF-ODE?\n\n- The experiments shows that the proposed method reduces the inference steps, however, how much faster is the inference time exactly compared with other methods?\n\n- What about the performance when the proposed LCMs are applied to other LDMs besides Stable Diffusion?"
                },
                "questions": {
                    "value": "1. It is not clear which contributions have the most significant impact on efficiency and quality.\n\n2. What is the computational complexity of solving augmented PF-ODE?\n\n3. How much faster is the inference time exactly compared with other methods?\n\n4. What about the performance when the proposed LCMs are applied to other LDMs besides Stable Diffusion?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6819/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698950497179,
            "cdate": 1698950497179,
            "tmdate": 1699636788284,
            "mdate": 1699636788284,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NirTPZ4d60",
                "forum": "duBCwjb68o",
                "replyto": "Vjg5pSy7eY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer dEPF"
                    },
                    "comment": {
                        "value": "We sincerely thank the constructive feedback from you. We address your concerns below.\n\n> 1. Not clear about which ones have the most significant impact on efficiency and quality.\n\nThanks for your question. Our skipping-step technique is the most critical component for speeding up the convergence (i.e., efficiency) and the one-stage guided consistency distillation algorithm has a significant impact on the quality of the generated images. The detailed ablation ablation study of skipping-step technique and one-stage guided consistency distillation can be found in Section 5.2. We briefly summarize the impact of skipping-step technique and one-stage guided consistency distillation below:\n\n**Skipping-Step Technique**: This method notably enhances convergence speed, a crucial aspect of efficiency. As quantitatively demonstrated in Figure 3 (DDIM sampler), the model's convergence speed with k=1 is significantly slower compared to other settings from k=5 to k=20. In specific, it shows that at 4000 training steps, the model with k=1 has a slower convergence, evidenced by a FID of 26.8, compared to k=20 with a significantly better FID of 13.3. Moreover, at k=20, the model reaches a FID of 14.4 in just 2000 steps, matching k=1 performance at 12000 steps, achieving at least **$6\\times$** convergence speed, strongly demonstrating the effectiveness of the skipping-step method.\n\n**One-stage guided consistency distillation**: Incorporating Classifier-Free Guidance (CFG) into the LCM significantly enhances image quality. Figures 4 and 5 illustrate that a larger CFG scale produces more realistic and higher-quality images. However, a very small CFG scale (which is equivalent to not using guided distillation), particularly at 2, results in lower quality generation. This enhancement in quality is validated by the CLIP scores in Figure 4 and the visibly superior image quality showcased in Figure 5.\n\n> 2. What is the computational complexity of solving augmented PF-ODE?\n\nThanks. We would like to clarify that we first view the guided reverse diffusion process as solving an augmented probability flow ODE (Augmented PF-ODE), then  LCM is designed to effectively to solve this PF-ODE during inference stage. The computational complexity of solving this Augmented PF-ODE is essentially \\textbf{equivalent} to (Number of inference steps, also named the number of function evaluation (NFE)) $\\times$ (Computational cost for each step). Table 1 and 2 show the superiority of LCM on solving the augmented PF-ODE in a few inference steps (1$\\sim$8). Additionally, since the classifier-free guidance (CFG) has already been distilled into LCM, we do not need to calculate the unconditional term $\\epsilon_\\theta(z_t,t,\\varnothing)$ during each inference steps, which further reduce the computational cost in each step, resulting in significantly faster speeds and reduced GPU memory usage during inference. **We also include the inference time in **Appendix. H (Figure.7)** for your reference**. We achieve at least **$4\\times$** acceleration compared with DPM-Solver++.\n\n> 3. How much faster is the inference time exactly compared with other methods?\n\nThanks for your suggestion. We report the inference speed/FID performance in **Appendix. H (Figure.7)**. It can be seen that we achieve at least **4$\\times$ acceleration** compared with DPM-Solver++.\n\n> 4.  LCMs applied to other LDMs besides Stable Diffusion?\n\nThanks for raising this point. We would like to emphasize that Stable Diffusion, recognized as one of the most advanced and extensively used LDMs in the AI researchers and artistic communities, serves as a challenging benchmark. The successful application of LCM to Stable Diffusion has already demonstrated our method's effectiveness and potential. Having established its performance on such challenging task, we believe additional validation on simpler LDM is not essential. To further highlight LCM's promise and superiority, we also undertook a more challenging experiment applying LCM to the **SD-XL** [1], which has three times as many parameters and a resolution of 1024x1024, compared to the original SD model. Detailed generation results in **Appendix.L (Figure. 12)** further demonstrate LCM's potential and impressive performance.\n\nReference: \n[1] Podel, et al. \"Sdxl: Improving latent diffusion models for high-resolution image synthesis\". arXiv preprint arXiv:2307.01952 (2023)."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6819/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700409945355,
                "cdate": 1700409945355,
                "tmdate": 1700411313052,
                "mdate": 1700411313052,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XBb0YO4MjS",
                "forum": "duBCwjb68o",
                "replyto": "Vjg5pSy7eY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reminder to Reviewer dEPF"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for reviewing our paper. We hope our responses have addressed your concerns. If so, we kindly ask if you could reconsider your score for our work.\n\nShould you have any further questions, we're ready to discuss and clarify.\n\nMany thanks for your time and effort."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6819/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700624144490,
                "cdate": 1700624144490,
                "tmdate": 1700624144490,
                "mdate": 1700624144490,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IlVvBapD0p",
                "forum": "duBCwjb68o",
                "replyto": "Vjg5pSy7eY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6819/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Deadline coming. looking forward to your feedback."
                    },
                    "comment": {
                        "value": "Dear Reviewer dEPF, We kindly request your feedback as the rebuttal deadline is approaching in less than 1 days. We hope our previous feedback addresses your concern. We would like to thank you again for your time and previous review and we are looking forward to further discussions."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6819/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659064571,
                "cdate": 1700659064571,
                "tmdate": 1700659064571,
                "mdate": 1700659064571,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]